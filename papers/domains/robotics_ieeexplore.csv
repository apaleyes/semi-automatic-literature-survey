doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ROBIO.2009.4913063,A bio-inspired haptic interface for tele-robotics applications,IEEE,Conferences,"This paper presents the design concept for a bio-inspired exoskeleton intended for applications in tele-robotics and virtual reality. We based the development on an attentive analysis of the human arm anatomy with the intent to synthesize a system that will be able to interface with the human limb in a natural way. Our main goal is to develop a multi contact-point haptic interface that does not restrict the arm mobility and therefore increases the operational workspace. We propose a simplified kinematic model of the human arm using a notation coming from the robotics field. To figure out the best kinematic architecture we employed real movement data, measured from a human subject, and integrated them with the kinematic model of the exoskeleton. This allows us to test the system before its construction and to formalize specific requirements. We also implemented and tested a first passive version of the shoulder joint.",https://ieeexplore.ieee.org/document/4913063/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/ETFA.1999.815411,Advanced control techniques based in artificial intelligence for robotics manipulators,IEEE,Conferences,"The performance quality in nonlinear model based control of mechanical manipulators is conditioned to the reliability of the mathematical model and precision in the knowledge of all the involved parameters. Control methods based on artificial intelligence techniques (learning algorithms, system identification and neural networks) can be applied to improve its performance. A neural control scheme is proposed, consisting basically of a neural network for learning the robot inverse dynamics and online generating the control signal. Also an online supervision based on optimisation techniques is designed and implemented for such neural control. Simulation results are provided to evaluate the alternative variations to the proposed central scheme.",https://ieeexplore.ieee.org/document/815411/,1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467),18-21 Oct. 1999,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICACITE51222.2021.9404749,Artificial Intelligence and Robotics: Impact &amp; Open issues of automation in Workplace,IEEE,Conferences,"In engineering province robotics is one of the cognitive perspective to human communication or it concern with synod of perception of action. In Today's Tech World Artificial Intelligence is an essential tool which provides effective analytical business solutions &amp; plays significant role in the domain of robotics and have several similarities like human behavior which may drive the real world. This paper shows the significant blend of Artificial Intelligence and robotics which transform entire industries, technological improvement of robotics application &amp; utilization. It also focuses on different aspects of targets like marketing, home appliances, medical science, Smart agriculture and many more which includes open issues and technological challenges arises by this combination and conclude that robotics with AI can work in real world with real objects. Further AI based robotics are very important area in economics and organizational consequence, implementation of automation in any organizational design give impact on overall economy and infrastructure provide a wider direction for further research on Robotics and IoT are two terms each covering a myriad of technologies and concepts.",https://ieeexplore.ieee.org/document/9404749/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/ICDL-EpiRob48136.2020.9278071,Bayesian Optimization for Developmental Robotics with Meta-Learning by Parameters Bounds Reduction,IEEE,Conferences,"In robotics, methods and softwares usually require optimizations of hyperparameters in order to be efficient for specific tasks, for instance industrial bin-picking from homogeneous heaps of different objects. We present a developmental framework based on long-term memory and reasoning modules (Bayesian Optimisation, visual similarity and parameters bounds reduction) allowing a robot to use meta-learning mechanism increasing the efficiency of such continuous and constrained parameters optimizations. The new optimization, viewed as a learning for the robot, can take advantage of past experiences (stored in the episodic and procedural memories) to shrink the search space by using reduced parameters bounds computed from the best optimizations realized by the robot with similar tasks of the new one (e.g. bin-picking from an homogenous heap of a similar object, based on visual similarity of objects stored in the semantic memory). As example, we have confronted the system to the constrained optimizations of 9 continuous hyperparameters for a professional software (Kamido) in industrial robotic arm bin-picking tasks, a step that is needed each time to handle correctly new object. We used a simulator to create bin-picking tasks for 8 different objects (7 in simulation and one with real setup, without and with meta-learning with experiences coming from other similar objects) achieving goods results despite a very small optimization budget, with a better performance reached when meta-learning is used (84.3 % vs 78.9 % of success overall, with a small budget of 30 iterations for each optimization) for every object tested (p-value=0.036).",https://ieeexplore.ieee.org/document/9278071/,2020 Joint IEEE 10th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),26-30 Oct. 2020,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/IROS.2001.977213,Computation principles for the development of visual skills in robotics,IEEE,Conferences,"Different working principles are often considered when different visual behaviors are implemented in an agent. This occurs basically because the physical interaction between the behavior and the environment is not studied in depth. The paper shows how apparently different visual behaviors share common theoretical principles for their working mechanism. In particular properties related to the navigation vector field they compute in the environment, provide a base to explain visual learning, guidance, topological navigation, sub goal placement, obstacle avoidance and navigation enhancement. To handle the mathematics of a vector field robust tools are needed. Techniques borrowed from computer vision literature provide the necessary mathematical tools. All behaviors described have been tested in real robots. On going research is still in progress for topological navigation and subgoal placement.",https://ieeexplore.ieee.org/document/977213/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/ROBIO49542.2019.8961433,CyberEarth: a Virtual Simulation Platform for Robotics and Cyber-Physical Systems,IEEE,Conferences,"The increasing sophisticated robot and intelligent system applications require universal visualization platforms which can guarantee the security and efficiency of task process execution in the situation of user-programming and using different kinds of automated equipment. In this paper, we present a universal visualization framework to build up program-driven simulation software of complex robots and intelligent systems by integrating several open-source technical modules, including Ubuntu Linux operation-system, QT Creator IDE environment, ROS robot operation system, OSG(OpenSceneGraph) 3D scene, osgEarth GIS(Geographic Information System)-based 3D scene, and also Python based user-programing robotic script language. Many complex visualization simulation systems of complex tasks in wide area and dynamic scenarios are realized by using this framework. Based on this framework, we built a virtual simulation platform CyberEarth for robotics and Cyber-Physical systems. The typical robotic simulation task, which is a visual coverage task for Multi-Agent/UAV, is also introduced to demonstration the universality of this platform.",https://ieeexplore.ieee.org/document/8961433/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/MWSCAS.2018.8624056,EMG-based hand gesture control system for robotics,IEEE,Conferences,"In this paper, a Electromyogram (EMG) based hand gesture control system is developed. A wearable human machine interface (HMI) device is designed for an in-home assistance service robot. An EMG-based control system utilizes MyoWave muscle sensor to acquire and amplify EMG signal. A microcontroller system is used to an artificial neural network (ANN) to classify the EMG signal. Based on different hand movements, commands are sent through WiFi to control the motor in a service robot. The on-board Camera system mounted the robot can capture video real-time. In addition, a web server is implemented to provide live video feedback for robot navigation and user instructions.",https://ieeexplore.ieee.org/document/8624056/,2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS),5-8 Aug. 2018,ieeexplore
,Engineering Safety in Swarm Robotics,IEEE,Conferences,"Robotics, artificial intelligence, and the Internet-of-Things are driving current research and development for the technology sector. Robotic and multi-robot systems are becoming pervasive and more and more lives rely on their proper functioning in transportation, medical systems, personal robotics, and manufacturing. Assuring the security and safety of these systems is of primary importance to guarantee the real-world applicability of current research, and we argue that it should be an integral part of system design. Current software standards for safety and security for critical systems (e.g. industrial and aerospace) are not directly applicable to the large distributed systems that are envisioned for the near future. In this paper, we propose to address safety and security of swarm robotics systems at the programming language level. We propose to extend the Buzz multi-robot scripting language with constructs and code analysis that allow the verification of safety and security during development. We believe that detecting and correcting issues with what are inherently emergent systems, i.e. where collective behavior might not be immediately apparent from a single robot's code, during development would allow for a more effective advancement of swarm robotics.",https://ieeexplore.ieee.org/document/8445818/,2018 IEEE/ACM 1st International Workshop on Robotics Software Engineering (RoSE),27 May-3 June 2018,ieeexplore
10.1109/SECON.2010.5453897,Enhancing student learning in artificial intelligence using robotics,IEEE,Conferences,"Artificial intelligence (AI) techniques may be applied to a variety of real-world problems. At Embry-Riddle Aeronautical University, CS 455: Artificial Intelligence was offered during the Spring 2008 semester in which students from all disciplines were invited to attend. Robot kits are incorporated into the course as a pedagogical tool to motivate and encourage learning by applying theoretically abstract algorithms to concrete real-world problems. This paper discusses the approach to incorporating robotics in the AI classroom. A set of commercial off-the-shelf robot kits are discussed and analyzed with respect to the students' work during the semester. Finally, recommendations for improvements on teaching AI to a multi-disciplinary audience with the help of robot kits will be discussed.",https://ieeexplore.ieee.org/document/5453897/,Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon),18-21 March 2010,ieeexplore
10.1109/IJCNN.2019.8852425,Exploring Deep Models for Comprehension of Deictic Gesture-Word Combinations in Cognitive Robotics,IEEE,Conferences,"In the early stages of infant development, gestures and speech are integrated during language acquisition. Such a natural combination is therefore a desirable, yet challenging, goal for fluid human-robot interaction. To achieve this, we propose a multimodal deep learning architecture, for comprehension of complementary gesture-word combinations, implemented on an iCub humanoid robot. This enables human-assisted language learning, with interactions like pointing at a cup and labelling it with a vocal utterance. We evaluate various depths of the Mask Regional Convolutional Neural Network (for object and wrist detection) and the Residual Network (for gesture classification). Validation is carried out with two deictic gestures across ten real-world objects on frames recorded directly from the iCub's cameras. Results further strengthen the potential of gesture-word combinations for robot language acquisition.",https://ieeexplore.ieee.org/document/8852425/,2019 International Joint Conference on Neural Networks (IJCNN),14-19 July 2019,ieeexplore
10.1109/ICRA.2019.8793593,"Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics",IEEE,Conferences,"Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.",https://ieeexplore.ieee.org/document/8793593/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/SPCA.2006.297452,From Robotics to Pervasive Computing Environments,IEEE,Conferences,"This talk proposes that the digital home is virtually identical to the software and hardware architecture used to construct mobile robots leading to the proposition that ""pervasive computing environments can be regarded as robots that we live inside"". The author argue that it is possible and rational to apply robotic techniques to pervasive computing problems in the digital home",https://ieeexplore.ieee.org/document/4079023/,2006 First International Symposium on Pervasive Computing and Applications,3-5 Aug. 2006,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/FIE.2006.322407,Incorporating an Affective Model to an Intelligent Tutor for Mobile Robotics,IEEE,Conferences,"Emotions have been identified as important players in motivation, and motivation is very important for learning. When a tutor recognizes the affective state of the student and responds accordingly, the tutor may be able to motivate students and improve the learning process. We propose a general affective behavior model which integrates information from the student's pedagogical state, affective state, and the tutorial situation, to decide the best tutorial action, considering the tutor preferences from a pedagogical and affective point of view. Our proposal is based on emotions models, personality theories and teachers' expertise. The affective model is implemented as a dynamic decision network, with utility measures on both learning and motivation, and is being incorporated to an intelligent tutor within a virtual laboratory for learning mobile robotics. This paper presents preliminary results in the construction of the affective behavior model",https://ieeexplore.ieee.org/document/4116913/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/AIMS.2014.35,Mobile Robot Performance in Robotics Challenges: Analyzing a Simulated Indoor Scenario and Its Translation to Real-World,IEEE,Conferences,"This paper discusses the pros and cons of using 3D simulators for testing the autonomous behavior of mobile robots in indoor environments. Major contribution of the paper is the discussion about which problems that can be faced using the simulator and those that cannot. We present the integration and calibration of a real non-commercial robot in a simulator, the characterization of the errors in sensing, navigation, and manipulation, and how these errors would impact in the real performance of the robot. The experimental support of the claims made in the paper has been developed using the gazebo simulator. RoCKIn competition rulebook defined the indoor restrictions.",https://ieeexplore.ieee.org/document/7102451/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/SECON.2014.6950737,Modified reinforcement learning for sequential action behaviors and its application to robotics,IEEE,Conferences,"When developing a robot or other automaton, the efficacy of the agent is highly dependent on the performance of the behaviors which underpin the control system. Especially in the case of agents which must act in real world or disorganized environments, the design of robust behaviors can be both difficult and time consuming, and often requires the use of sensitive tuning. In response to this need, we present a behavioral, goal-oriented, reinforcement-based machine learning strategy which is flexible, simple to implement, and designed for application in real-world environments, but with the capability of software-based training. In this paper, we will explain our design paradigms, the formal implementation thereof, and the algorithm proper. We will show that the algorithm is able to emulate standard reinforcement learning within comparable training time, and to extend the capabilities thereof as well. We also demonstrate extension of learning beyond the scope of training examples, and present an example of a physical robot which learns a sequential action behavior by experimentation.",https://ieeexplore.ieee.org/document/6950737/,IEEE SOUTHEASTCON 2014,13-16 March 2014,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/ROBOT.1991.132064,Proceedings. 1991 IEEE International Conference on Robotics and Automation (Cat. No.91CH2969-4),IEEE,Conferences,,https://ieeexplore.ieee.org/document/132064/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ACIIW.2019.8925192,Real-time pain detection in facial expressions for health robotics,IEEE,Conferences,"Automatic pain detection is an important challenge in health computing. In this paper we report on our efforts to develop a real-time, real-world pain detection system from human facial expressions. Although many studies addressed this challenge, most of them use the same dataset for training and testing. There is no cross-check with other datasets or implementation in real-time to check performance on new data. This is problematic, as evidenced in this paper, because the classifiers overtrain on dataset-specific features. This limits realtime, real-world usage. In this paper, we investigate different methods of real-time pain detection. The training data uses a combination of pain and emotion datasets, unlike other papers. The best model shows an accuracy of 88.4% on a dataset including pain and 7 non-pain emotional expressions. Results suggest that convolutional neural networks (CNN) are not the best methods in some cases as they easily overtrain if the dataset is biased. Finally we implemented our pain detection method on a humanoid robot for physiotherapy. Our work highlights the importance of cross-corpus evaluation &amp; real-time testing, as well as the need for a well balanced and ecologically valid pain dataset.",https://ieeexplore.ieee.org/document/8925192/,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),3-6 Sept. 2019,ieeexplore
10.1109/CEC.1999.781948,Realization of robust controllers in evolutionary robotics: a dynamically-rearranging neural network approach,IEEE,Conferences,"The evolutionary robotics approach has been attracting a lot of attention in the field of robotics and artificial life. In this approach, neural networks are widely used to construct controllers for autonomous mobile agents, since they intrinsically have generalization, noise-tolerant abilities and so on. However, there are still open questions: (1) the gap between simulated and real environments, (2) the evolutionary and learning phase are completely separated, and (3) the conflict between stability and evolvability/adaptability. In this paper, we try to overcome these problems by incorporating the concept of dynamic rearrangement function of biological neural networks with the use of neuromodulators. Simulation results show that the proposed approach is highly promising.",https://ieeexplore.ieee.org/document/781948/,Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406),6-9 July 1999,ieeexplore
10.1109/CIG.2009.5286456,Realtime execution of automated plans using evolutionary robotics,IEEE,Conferences,"Applying neural networks to generate robust agent controllers is now a seasoned practice, with time needed only to isolate particulars of domain and execution. However we are often constrained to local problems due to an agents inability to reason in an abstract manner. While there are suitable approaches for abstract reasoning and search, there is often the issues that arise in using offline processes in real-time situations. In this paper we explore the feasibility of creating a decentralised architecture that combines these approaches. The approach in this paper explores utilising a classical automated planner that interfaces with a library of neural network actuators through the use of a Prolog rule base. We explore the validity of solving a variety of goals with and without additional hostile entities as well as added uncertainty in the the world. The end results providing a goal driven agent that adapts to situations and reacts accordingly.",https://ieeexplore.ieee.org/document/5286456/,2009 IEEE Symposium on Computational Intelligence and Games,7-10 Sept. 2009,ieeexplore
10.1109/ICIS.2017.7959982,Robotics data real-time management based on NoSQL solution,IEEE,Conferences,"In nowadays, robotics database management systems are increasing. These systems ensure good storage of data and with big data analytic, a new approach demands new structures and methods for collecting, recording, and analyzing enterprise data. This paper work deals with the NoSQL databases which are the secret of the continual progression data that new data management solutions have been emerged. They crossed several areas as personalization, profile management, big data in real-time, content management, catalogue, view of customers, mobile applications, internet of things, digital communication and fraud detection. Machine learning, for example, thrives on more data, so smart machines can learn more and faster, the Robotics are our use of case to focus on our Test. The implementation of NoSQL for Robotics wrestle all the data they acquire into usable form because with the ordinary type of Robotics we are facing very big limits to manage and find the exact information in real-time. Our original proposed approach was demonstrated by experimental studies and running example used as a use case.",https://ieeexplore.ieee.org/document/7959982/,2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS),24-26 May 2017,ieeexplore
10.1109/DSN.2019.00027,SOTER: A Runtime Assurance Framework for Programming Safe Robotics Systems,IEEE,Conferences,"The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third-party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software, and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",https://ieeexplore.ieee.org/document/8809550/,2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),24-27 June 2019,ieeexplore
10.1109/URAI.2016.7734049,Secure robotics,IEEE,Conferences,"Security is an under-studied problem within robotics and Internet of Things. Part of the reason for this is that currently most robots and IoT devices remain in the lab at all times. Recent trends show more robots and IoT devices moving “out into the wild” with no humans to protect them. This creates vulnerabilities beyond the well known and well studied network/internet based threat. These threats include external network, local network, software, physical access, tricking the artificial intelligence, and intellectual property theft. This document discribes the above and shows our current work towards detection and mitigation.",https://ieeexplore.ieee.org/document/7734049/,2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),19-22 Aug. 2016,ieeexplore
10.1109/ICCVW.2017.84,SkiMap++: Real-Time Mapping and Object Recognition for Robotics,IEEE,Conferences,"We introduce SkiMap++, an extension to the recently proposed SkiMap mapping framework for robot navigation [1]. The extension deals with enriching the map with semantic information concerning the presence in the environment of certain objects that may be usefully recognized by the robot, e.g. for the sake of grasping them. More precisely, the map can accommodate information about the spatial locations of certain 3D object features, as determined by matching the visual features extracted from the incoming frames through a random forest learned off-line from a set of object models. Thereby, evidence about the presence of object features is gathered from multiple vantage points alongside with the standard geometric mapping task, so to enable recognizing the objects and estimating their 6 DOF poses. As a result, SkiMap++ can reconstruct the geometry of large scale environments as well as localize some relevant objects therein (Fig.1) in real-time on CPU. As an additional contribution, we present an RGB-D dataset featuring ground-truth camera and object poses, which may be deployed by researchers interested in pursuing SLAM alongside with object recognition, a topic often referred to as Semantic SLAM<sup>1</sup>.",https://ieeexplore.ieee.org/document/8265293/,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),22-29 Oct. 2017,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/ROBOT.2004.1308800,The artificial ecosystem: a distributed approach to service robotics,IEEE,Conferences,"We propose a multiagent, distributed approach to autonomous mobile robotics which is an alternative to most existing systems in literature: robots are thought of as mobile units within an intelligent environment where they coexist and co-operate with fixed, intelligent devices that are assigned different roles: helping the robot to localize itself, controlling automated doors and elevators, detecting emergency situations, etc. To achieve this, intelligent sensors and actuators (i.e. physical agents) are distributed both onboard the robot and throughout the environment, and they are handled by Real-Time software agents which exchange information on a distributed message board. The paper outlines the benefits of the approach in terms of efficiency and Real-Time responsiveness.",https://ieeexplore.ieee.org/document/1308800/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/CSCI46756.2018.00293,"Timing and its Implementation in a Language, Communication, and Systems Integration SDK and Platform for Intelligent Entities and Robotics",IEEE,Conferences,"A framework to integrate different artificial intelligence and machine learning algorithms is combined with an execution framework to create a powerful cloud computing system development platform. By providing an execution framework and control software that is native to cloud architectures and supports interactivity and time synchronization, the true utility of cloud computing and Big Data systems can be increased. Many Big Data software systems are not interactive, automated, or able to run in real-time. An integration example is provided.",https://ieeexplore.ieee.org/document/8947742/,2018 International Conference on Computational Science and Computational Intelligence (CSCI),12-14 Dec. 2018,ieeexplore
10.1109/ROMAN.2017.8172430,"Towards the use of consumer-grade electromyographic armbands for interactive, artistic robotics performances",IEEE,Conferences,"In recent years, gesture-based interfaces have been explored in order to control robots in non-traditional ways. These require the use of systems that are able to track human body movements in 3D space. Deploying Mo-cap or camera systems to perform this tracking tend to be costly, intrusive, or require a clear line of sight, making them ill-adapted for artistic performances. In this paper, we explore the use of consumer-grade armbands (Myo armband) which capture orientation information (via an inertial measurement unit) and muscle activity (via electromyography) to ultimately guide a robotic device during live performances. To compensate for the drop in information quality, our approach rely heavily on machine learning and leverage the multimodality of the sensors. In order to speed-up classification, dimensionality reduction was performed automatically via a method based on Random Forests (RF). Online classification results achieved 88% accuracy over nine movements created by a dancer during a live performance, demonstrating the viability of our approach. The nine movements are then grouped into three semantically-meaningful moods by the dancer for the purpose of an artistic performance achieving 94% accuracy in real-time. We believe that our technique opens the door to aesthetically-pleasing sequences of body motions as gestural interface, instead of traditional static arm poses.",https://ieeexplore.ieee.org/document/8172430/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ACCESS.2020.3007064,Drive Through Robotics: Robotic Automation for Last Mile Distribution of Food and Essentials During Pandemics,IEEE,Journals,"The COVID-19 pandemic unraveled the weak points in the global supply chain for goods. Specifically, people all over the world, including those in the most advanced nations have had to go without medical supplies and personal protective equipment. Scarcity of essentials increases anxiety and uncertainty exacerbating unproductive behaviors like hoarding and price gouging. Left to market forces, such unfair practices are likely to aggravate hardships and increase the loss of lives. Thus, there is a critical need to ensure safe distribution of food and essential supplies to all citizens to sustain them through challenging times. To this end, we propose a simple, affordable and contact-less robotic system for preparing and dispensing food and survival-kits at community scale. The system has provisions to prevent hoarding and price gouging. Design, simulation, and, validation of the system has been completed to ensure readiness for real world implementation. This project is part of an open-source program and detailed designs are available upon request to entities interested in using it to serve their communities.",https://ieeexplore.ieee.org/document/9133423/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2019.2938366,Grasping Objects From the Floor in Assistive Robotics: Real World Implications and Lessons Learned,IEEE,Journals,"This paper presents a system enabling a mobile robot to autonomously pick-up objects a human is pointing at from the floor. The system does not require object models and is designed to grasp unknown objects. The robot decides by itself if an object is suitable for grasping by considering measures of size, position and the environment suitability. The implementation is built on the second prototype of the home care robot Hobbit, thereby verifying that complex robotic manipulation tasks can be performed with economical hardware. The presented system was already tested in real apartments with elderly people. We highlight this by discussing the additional complexity for complete autonomous behavior in apartments compared with tests in labs.",https://ieeexplore.ieee.org/document/8819885/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/TLT.2018.2833111,Inquiry-Based Learning With RoboGen: An Open-Source Software and Hardware Platform for Robotics and Artificial Intelligence,IEEE,Journals,"It has often been found that students appreciate hands-on work, and find that they learn more with courses that include a project than those relying solely on conventional lectures and tests. This type of project driven learning is a key component of “Inquiry-based learning” (IBL), which aims at teaching methodology as well as content by incorporating the student as an actor rather than a spectator. Robotics applications are especially well-suited for IBL due to the value of trial and error experience, the multiple possibilities for students to implement their own ideas, and the importance of programming, problem-solving, and electro-mechanical skills in real world engineering and science jobs. Furthermore, robotics platforms can be useful teaching media and learning tools for a variety of topics. Here, we present RoboGen: an open-source, web-based, software, and hardware platform for Robotics and Artificial Intelligence with a particular focus on Evolutionary Robotics. We describe the platform in detail, compare it to existing alternatives, and present results of its use as a platform for Inquiry-based learning within a master's level course at the Ecole Polytechnique Fédérale de Lausanne.",https://ieeexplore.ieee.org/document/8354804/,IEEE Transactions on Learning Technologies,1 July-Sept. 2019,ieeexplore
10.1109/TIE.2016.2597119,Multidimensional Modeling of Physiological Tremor for Active Compensation in Handheld Surgical Robotics,IEEE,Journals,"Precision, robustness, dexterity, and intelligence are the design indices for current generation surgical robotics. To augment the required precision and dexterity into normal microsurgical work-flow, handheld robotic instruments are developed to compensate physiological tremor in real time. The hardware (sensors and actuators) and software (causal linear filters) employed for tremor identification and filtering introduces time-varying unknown phase delay that adversely affects the device performance. The current techniques that focus on three-dimensions (3-D) tip position control involves modeling and canceling the tremor in three axes (x-, y-, and z -axes) separately. Our analysis with the tremor recorded from surgeons and novice subjects shows that there exists significant correlation in tremor across the dimensions. Based on this, a new multidimensional modeling approach based on extreme learning machines is proposed in this paper to correct the phase delay and to accurately model 3-D tremor simultaneously. Proposed method is evaluated through both simulations and experiments. Comparison with the state-of-the art techniques highlight the suitability and better performance of the proposed approach for tremor compensation in handheld surgical robotics.",https://ieeexplore.ieee.org/document/7529172/,IEEE Transactions on Industrial Electronics,Feb. 2017,ieeexplore
10.1109/TSMCB.2008.920227,Multihierarchical Interactive Task Planning: Application to Mobile Robotics,IEEE,Journals,"To date, no solution has been proposed to human-machine interactive task planning that deals simultaneously with two important issues: 1) the capability of processing large amounts of information in planning (as it is needed in any real application) and 2) being efficient in human-machine communication (a proper set of symbols for human-machine interaction may not be suitable for efficient automatic planning and vice versa). In this paper, we formalize a symbolic model of the environment to solve these issues in a natural form through a human-inspired mechanism that structures knowledge in multiple hierarchies. Planning with a hierarchical model may be efficient even in cases where the lack of hierarchical information would make it intractable. However, in addition, our multihierarchical model is able to use the symbols that are most familiar to each human user for interaction, thus achieving efficiency in human-machine communication without compromising the task-planning performance. We formalize here a general interactive task-planning process which is then particularized to be applied to a mobile robotic application. The suitability of our approach has been demonstrated with examples and experiments.",https://ieeexplore.ieee.org/document/4505426/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2008,ieeexplore
10.1109/JPROC.2018.2856739,Navigating the Landscape for Real-Time Localization and Mapping for Robotics and Virtual and Augmented Reality,IEEE,Journals,"Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",https://ieeexplore.ieee.org/document/8436423/,Proceedings of the IEEE,Nov. 2018,ieeexplore
10.1109/13.485240,Robotics laboratory exercises,IEEE,Journals,"The authors report new laboratory exercises in robotic manipulation, computer vision, artificial intelligence, and mechatronics, four areas that are central to any robotics curriculum. The laboratory exercises supply the student with hands-on experience that complements classroom lectures and software development. Through this experience, the student confronts the hard realities of robot systems and learns to deal with them. Such hands-on experience is essential for a sound robotics education, because many critical lessons about the real world can only be learned through personal experience.",https://ieeexplore.ieee.org/document/485240/,IEEE Transactions on Education,Feb. 1996,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TASE.2019.2938316,Semiautomatic Labeling for Deep Learning in Robotics,IEEE,Journals,"In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35 000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets. Note to Practitioners-This article was motivated by the lack of a simple and effective solution for the generation of data sets usable to train a data-driven model, such as a modern deep neural network, so as to make them accessible in an industrial environment. Specifically, a deep learning robot guidance vision system would require such a large amount of manually labeled images that it would be too expensive and impractical for a real use case, where system reconfigurability is a fundamental requirement. With our system, on the other hand, especially in the field of industrial robotics, the cost of image labeling can be reduced, for the first time, to nearly zero, thus paving the way for self-reconfiguring systems with very high performance (as demonstrated by our experimental results). One of the limitations of this approach is the need to use a manual method for the detection of objects of interest in the preliminary stages of the pipeline (ARP or graphical interface). A feasible extension, related to the field of collaborative robotics, could be used to exploit the robot itself, manually moved by the user, even for this preliminary stage, so as to eliminate any source of inaccuracy.",https://ieeexplore.ieee.org/document/8844069/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/ICCCYB.2004.1437628,2004 International Conference on Computational Cybernetics Proceedings,IEEE,Conferences,The following topics are dealt with: cybernetics; control; hardware architectures; vision systems; genetic algorithms; evolutionary computing; sensors; real-time systems; multiagents systems; robotics; software engineering; intelligent systems; learning; fractional-order systems; and engineering systems,https://ieeexplore.ieee.org/document/1437628/,"Second IEEE International Conference on Computational Cybernetics, 2004. ICCC 2004.",30 Aug.-1 Sept. 2004,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/ICIT.2006.372290,3D Modelling from Multi-view Registered Range Images Using K-means Clustering,IEEE,Conferences,"3D modelling from range images captured using laser scanning systems finds a wide range of applications in computer vision and industrial robotics. However due to the presence of scanning noise, accumulative registration errors, and improper data fusion, the reconstructed surfaces from multiple registered range images captured from different viewpoints are often distorted with thick patches, false connections and blurred features. Moreover, the existing integration methods are often expensive in the sense of computational time and data storage. These shortcomings will hinder the wide applications of 3D modelling using the latest laser scanning systems. In this paper, the k-means clustering approach from the pattern recognition and machine learning literatures is employed to optimally fuse the overlapping areas between two range images captured from two neighbouring viewpoints and to iteratively minimize the integration error. The final fused point set is then triangulated using an improved Delaunay method, guaranteeing a watertight surface. The new method is theoretically guaranteed to converge. A comparative study based on real images shows that the proposed algorithm is computationally efficient and significantly reduces the integration error, while desirably retaining geometric details of object surface.",https://ieeexplore.ieee.org/document/4237612/,2006 IEEE International Conference on Industrial Technology,15-17 Dec. 2006,ieeexplore
10.1109/3DV50981.2020.00038,3D-Aware Ellipse Prediction for Object-Based Camera Pose Estimation,IEEE,Conferences,"In this paper, we propose a method for coarse camera pose computation which is robust to viewing conditions and does not require a detailed model of the scene. This method meets the growing need of easy deployment of robotics or augmented reality applications in any environments, especially those for which no accurate 3D model nor huge amount of ground truth data are available. It exploits the ability of deep learning techniques to reliably detect objects regardless of viewing conditions. Previous works have also shown that abstracting the geometry of a scene of objects by an ellipsoid cloud allows to compute the camera pose accurately enough for various application needs. Though promising, these approaches use the ellipses fitted to the detection bounding boxes as an approximation of the imaged objects. In this paper, we go one step further and propose a learning-based method which detects improved elliptic approximations of objects which are coherent with the 3D ellipsoid in terms of perspective projection. Experiments prove that the accuracy of the computed pose significantly increases thanks to our method and is more robust to the variability of the boundaries of the detection boxes. This is achieved with very little effort in terms of training data acquisition - a few hundred calibrated images of which only three need manual object annotation.",https://ieeexplore.ieee.org/document/9320405/,2020 International Conference on 3D Vision (3DV),25-28 Nov. 2020,ieeexplore
10.1109/AIVR.2018.00028,A Benchmark of Four Methods for Generating 360° Saliency Maps from Eye Tracking Data,IEEE,Conferences,"Modeling and visualization of user attention in Virtual Reality is important for many applications, such as gaze prediction, robotics, retargeting, video compression, and rendering. Several methods have been proposed to model eye tracking data as saliency maps. We benchmark the performance of four such methods for 360° images. We provide a comprehensive analysis and implementations of these methods to assist researchers and practitioners. Finally, we make recommendations based on our benchmark analyses and the ease of implementation.",https://ieeexplore.ieee.org/document/8613647/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/KSE.2018.8573394,A Comparative Study on Detection and Estimation of a 3-D Object Model in a Complex Scene,IEEE,Conferences,"In this paper, we tackle the approaches to detect and estimate 3-D object model in a complex scene. Although it is fundamental research in the computer vision and robotics community, this task still has many challenges especially when the scene is complex with contaminated or occluded data. To do this, we compare three common approaches including two conventional ways (e.g., geometrical and appearance-based techniques) and the proposed scheme. While geometrical approaches tend to directly detect and estimate objects without any learning procedure, the appearance-based required a training process to model the interested object. We show that a combination of recent advantages of deep learning (e.g., RCNN, Yolo) could resolve the detection task, while the geometrical based approaches estimate full 3-D model. The evaluation utilizes two different dataset. One from a public available, second one is our self-prepared dataset. Difference scenarios are considered in the evaluation. The results confirmed that the proposed technique achieves the best performances. As a consequence, it suggests to deploy real application supporting visually impaired people in detecting and grasping common objects in their activities of daily living.",https://ieeexplore.ieee.org/document/8573394/,2018 10th International Conference on Knowledge and Systems Engineering (KSE),1-3 Nov. 2018,ieeexplore
10.1109/CODESISSS51650.2020.9244038,A Fast Design Space Exploration Framework for the Deep Learning Accelerators: Work-in-Progress,IEEE,Conferences,"The Capsule Networks (CapsNets) is an advanced form of Convolutional Neural Network (CNN), capable of learning spatial relations and being invariant to transformations. CapsNets requires complex matrix operations which current accelerators are not optimized for, concerning both <sub>training</sub> and <sub>inference</sub> passes. Current state-of-the-art simulators and design space exploration (DSE) tools for DNN hardware neglect the modeling of training operations, while requiring long exploration times that slow down the complete design flow. These impediments restrict the real-world applications of CapsNets (e.g., autonomous driving and robotics) as well as the further development of DNNs in life-long learning scenarios that require training on low-power embedded devices. Towards this, we present <sub>XploreDL</sub>, a novel framework to perform fast yet high-fidelity DSE for both inference and training accelerators, supporting both CNNs and CapsNets operations. <sub>XploreDL</sub> enables a resource-efficient DSE for accelerators, focusing on power, area, and latency, highlighting Pareto-optimal solutions which can be a green-lit to expedite the design flow. <sub>XploreDL</sub> can reach the same fidelity as ARM's SCALE-sim, while providing 600x speedup and having a 50x lower memory-footprint. Preliminary results with a deep CapsNet model on MNIST for training accelerators show promising Pareto-optimal architectures with up to 0.4 TOPS/squared-mm and 800 fJ/op efficiency. With inference accelerators for AlexNet the Pareto-optimal solutions reach up to 1.8 TOPS/squared-mm and 200 fJ/op efficiency.",https://ieeexplore.ieee.org/document/9244038/,2020 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS),20-25 Sept. 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN52387.2021.9534180,A Lightweight sequence-based Unsupervised Loop Closure Detection,IEEE,Conferences,"Stable, effective and lightweight loop closure detection is an always pursued goal in real-time SLAM systems, that can be ported on embedded processors and deployed on autonomous robotics. Deep learning methods have extended the expressive ability and adaptability of the descriptor, and sequence-based methods can greatly improve the matching accuracy. However, the increased computation complexity and storage bandwidth requirements of matching calculations for high-dimensional descriptor make it infeasible for real-time deployment, especially for robots that navigate in relatively big maps. To address this challenge, we propose a lightweight sequence-based unsupervised loop closure detection scheme. To be specific, Principal Component Analysis (PCA) is applied to squeeze the descriptor dimensions while maintaining sufficient expressive ability. Additionally, with the consideration of the image sequence and combining linear query with fast approximate nearest neighbor search to further reduce the execution time and improve the efficiency of sequence matching. We implement our method on CALC, a state-of-the-art unsupervised solution, and conduct experiments on NVIDIA TX2, results demonstrate that the accuracy has been improved by 5%, while the execution speed is 2× faster. Source code is available at https://github.com/Mingrui-Yu/Seq-CALC.",https://ieeexplore.ieee.org/document/9534180/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/SMC.2019.8914519,A Multimodal Perception System for Detection of Human Operators in Robotic Work Cells,IEEE,Conferences,"Workspace monitoring is a critical hw/sw component of modern industrial work cells or in service robotics scenarios, where human operators share their workspace with robots. Reliability of human detection is a major requirement not only for safety purposes but also to avoid unnecessary robot stops or slowdowns in case of false positives. The present paper introduces a novel multimodal perception system for human tracking in shared workspaces based on the fusion of depth and thermal images. A machine learning approach is pursued to achieve reliable detection performance in multi-robot collaborative systems. Robust experimental results are finally demonstrated on a real robotic work cell.",https://ieeexplore.ieee.org/document/8914519/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/ICARM52023.2021.9536056,A Review of Bilateral Teleoperation Control Strategies with Soft Environment,IEEE,Conferences,"In the past two decades, bilateral teleoperation with haptic feedback has attracted great research and application interests in both robotics and other areas. Initially triggered by the need to handle dangerous and remote distance tasks such as nuclear materials manipulation and space exploration, bilateral teleoperation has found its way into other applications as a result of development of control theory, robotic technology (both hardware and software) and latest breakthrough in artificial intelligence and machine learning. Consequently, bilateral teleoperation is found facing new challenges brought by these new applications. One major and obvious change is the working environment for the slave manipulator: different from rigid or solid contact environments which are reasonably assumed in early applications in industrial, nuclear and aerospace applications, the slave environment is now more complex and often the objects in contact are much softer in term of stiffness and can not be described by simple elastic model if good teleoperation performance (accurate and transparent) is expected. In this paper, the research of bilateral teleoperation system considering soft environment in recent 20 years has been surveyed for the first time in literature, to the knowledge of the authors. Following the difference in real applications, in this review the definition of soft environment covers linear elastic environment with much lower stiffness than conventional industrial environment and nonlinear complex soft environment with/out time-varying characteristics. Accordingly, the surveyed control strategies and structures in recent literature to improve the stability and accuracy of bilateral teleoperation with soft environment are classified and explained. Finally, the main applications, current challenges and future perspectives of bilateral teleoperation with soft environment are discussed.",https://ieeexplore.ieee.org/document/9536056/,2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2021,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA48506.2021.9561722,A Scavenger Hunt for Service Robots,IEEE,Conferences,"Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",https://ieeexplore.ieee.org/document/9561722/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2018.8593714,A Software Framework for Planning Under Partial Observability,IEEE,Conferences,"Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.",https://ieeexplore.ieee.org/document/8593714/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBIO.2009.4913063,A bio-inspired haptic interface for tele-robotics applications,IEEE,Conferences,"This paper presents the design concept for a bio-inspired exoskeleton intended for applications in tele-robotics and virtual reality. We based the development on an attentive analysis of the human arm anatomy with the intent to synthesize a system that will be able to interface with the human limb in a natural way. Our main goal is to develop a multi contact-point haptic interface that does not restrict the arm mobility and therefore increases the operational workspace. We propose a simplified kinematic model of the human arm using a notation coming from the robotics field. To figure out the best kinematic architecture we employed real movement data, measured from a human subject, and integrated them with the kinematic model of the exoskeleton. This allows us to test the system before its construction and to formalize specific requirements. We also implemented and tested a first passive version of the shoulder joint.",https://ieeexplore.ieee.org/document/4913063/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/IROS.2016.7759384,A convolutional neural network for robotic arm guidance using sEMG based frequency-features,IEEE,Conferences,"Recently, robotics has been seen as a key solution to improve the quality of life of amputees. In order to create smarter robotic prosthetic devices to be used in an everyday context, one must be able to interface them seamlessly with the end-user in an inexpensive, yet reliable way. In this paper, we are looking at guiding a robotic device by detecting gestures through measurement of the electrical activity of muscles captured by surface electromyography (sEMG). Reliable sEMG-based gesture classifiers for end-users are challenging to design, as they must be extremely robust to signal drift, muscle fatigue and small electrode displacement without the need for constant recalibration. In spite of extensive research, sophisticated sEMG classifiers for prostheses guidance are not yet widely used, as systems often fail to solve these issues simultaneously. We propose to address these problems by employing Convolutional Neural Networks. Specifically as a first step, we demonstrate their viability to the problem of gesture recognition for a low-cost, low-sampling rate (200Hz) consumer-grade, 8-channel, dry electrodes sEMG device called Myo armband (Thalmic Labs) on able-bodied subjects. To this effect, we assessed the robustness of this machine learning oriented approach by classifying a combination of 7 hand/wrist gestures with an accuracy of ~97.9% in real-time, over a period of 6 consecutive days with no recalibration. In addition, we used the classifier (in conjunction with orientation data) to guide a 6DoF robotic arm, using the armband with the same speed and precision as with a joystick. We also show that the classifier is able to generalize to different users by testing it on 18 participants.",https://ieeexplore.ieee.org/document/7759384/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/MWSCAS.2016.7870095,A framework for teaching robotic control using a novel visual programming language,IEEE,Conferences,"This paper proposes an education robotic platform that aims to improve teaching methods of programming and robotics skills, for both beginner and advanced users. We propose an innovative platform that consists of a versatile set of sensors and actuators, controlled by utilizing a user-friendly visual programming language through a mobile phone interface, or by utilizing a representational state transfer application programming interface for more advanced users. Suggested methods form the foundation of problem-based learning, by emphasizing hands-on experimental assignments and activities, and collaborative learning. We present the software and hardware architecture of the system, and case studies for utilizing different control modes. Consequently, students can improve their understanding of basic robotic concepts by observing real-time response and feedback of the actuator and sensor modules integrated in the robotic platform.",https://ieeexplore.ieee.org/document/7870095/,2016 IEEE 59th International Midwest Symposium on Circuits and Systems (MWSCAS),16-19 Oct. 2016,ieeexplore
10.1109/IJCNN.1989.118696,A general purpose analog neural computer,IEEE,Conferences,"The design of a programmable analog neural computer and simulator is described. The machine is intended for real-world real-time computations such as vision, acoustics, or robotics and the development of special-purpose neural nets. The computer is scalable and composed of interconnected switches. It runs entirely in analog mode but connection architecture, synaptic gains, and time constants as well as neuron parameters are set digitally. Each neuron has a limited number of inputs and can be connected to any but not all other neurons. For the implementation of learning algorithms the neuron outputs are multiplexed and converted to digital form. Even at the moderate size of 10/sup 3/ to 10/sup 5/ neurons the computational speed is expected to exceed that of any current digital computer.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/118696/,International 1989 Joint Conference on Neural Networks, 1989,ieeexplore
10.1109/ICARSC.2018.8374189,A generic visual perception domain randomisation framework for Gazebo,IEEE,Conferences,"The impressive results of applying deep neural networks in tasks such as object recognition, language translation, and solving digital games are largely attributed to the availability of massive amounts of high quality labelled data. However, despite numerous promising steps in incorporating these techniques in robotic tasks, the cost of gathering data with a real robot has halted the proliferation of deep learning in robotics. In this work, a plugin for the Gazebo simulator is presented, which allows rapid generation of synthetic data. By introducing variations in simulator-specific or irrelevant aspects of a task, one can train a model which exhibits some degree of robustness against those aspects, and ultimately narrow the reality gap between simulated and real-world data. To show a use-case of the developed software, we build a new dataset for detection and localisation of three object classes: box, cylinder and sphere. Our results in the object detection and localisation task demonstrate that with small datasets generated only in simulation, one can achieve comparable performance to that achieved when training on real-world images.",https://ieeexplore.ieee.org/document/8374189/,2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),25-27 April 2018,ieeexplore
10.1109/IROS.2014.6942859,A machine learning approach for real-time reachability analysis,IEEE,Conferences,"Assessing reachability for a dynamical system, that is deciding whether a certain state is reachable from a given initial state within a given cost threshold, is a central concept in controls, robotics, and optimization. Direct approaches to assess reachability involve the solution to a two-point boundary value problem (2PBVP) between a pair of states. Alternative, indirect approaches involve the characterization of reachable sets as level sets of the value function of an appropriate optimal control problem. Both methods solve the problem accurately, but are computationally intensive and do no appear amenable to real-time implementation for all but the simplest cases. In this work, we leverage machine learning techniques to devise query-based algorithms for the approximate, yet real-time solution of the reachability problem. Specifically, we show that with a training set of pre-solved 2PBVP problems, one can accurately classify the cost-reachable sets of a differentially-constrained system using either (1) locally-weighted linear regression or (2) support vector machines. This novel, query-based approach is demonstrated on two systems: the Dubins car and a deep-space spacecraft. Classification errors on the order of 10% (and often significantly less) are achieved with average execution times on the order of milliseconds, representing 4 orders-of-magnitude improvement over exact methods. The proposed algorithms could find application in a variety of time-critical robotic applications, where the driving factor is computation time rather than optimality.",https://ieeexplore.ieee.org/document/6942859/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1109/ICSMC.1991.169859,A neural computer architecture for data exploration,IEEE,Conferences,"The authors' approach to problem-solving does not require a formal, symbolic mathematical model. It is based on interactive experimentation, interrelating the result data into IF-THEN units, data generalization and data-driven reasoning. It can be applied to the exploration of real-word hard-to-formalize data-intensive problems such as traffic control, environmental forecasting, military reconnaissance, technical and medical diagnosis, robotics, software debugging, and system maintenance. The data-based model, in contrast to a symbolic one, can be stepwise refined using additional input-output pairs to match any given precision or other constraints, a possibility hard to realize in the case of symbolic mathematical models.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/169859/,"Conference Proceedings 1991 IEEE International Conference on Systems, Man, and Cybernetics",13-16 Oct. 1991,ieeexplore
10.1109/CNE.2003.1196858,A neuro-controller for robotic manipulators based on biologically-inspired visuo-motor co-ordination neural models,IEEE,Conferences,"This paper presents a novel scheme for sensor-based control of robotics manipulators by means of artificial neural networks. The system is able to control simple reaching tasks by only fusing visual and proprioceptive sensory data, without computational kinematic modeling of the arm structure, Thanks to the generalization features typical of the neural approach, the same neurocontroller has been easily adapted and successfully validated for controlling different manipulators with different mechanical structures, i.e. number of degrees of freedom, link length and weight, etc. The proposed scheme is directly inspired to research results in the field of neuroscience, specifically on nervous structures and physiological mechanisms involved in sensory motor coordination. From a psychological point of view J. Piaget (1976) explained visuo-motor associations in his scheme of circular reaction. He observed how, by making endogenous movements and correlating the resulting arm and hand spatial locations, the brain allows an auto-association to be created between visual and proprioceptive sensing. The work presented in this paper is derived from the more recent DIRECT model proposed D. Bullock et al. (1993). Significant and original modifications of such model have been introduced by the authors to increase, at the same time, both system performance and the biological coherence. The proposed neurocontroller has been first simulated both in the 2-dimensional and the 3-dimensional case, and then implemented for experimental trials on two real robotic manipulators.",https://ieeexplore.ieee.org/document/1196858/,"First International IEEE EMBS Conference on Neural Engineering, 2003. Conference Proceedings.",20-22 March 2003,ieeexplore
10.1109/SACI.2013.6608963,A new NIR camera for gesture control of electronic devices,IEEE,Conferences,"Since the introduction Gesture Control technology in the electronic gaming technology a series of attempts have been made to deploy it also on other domains such as robotics, teaching, medical, automotive and many others. Human gesture used for Man-Machine Interaction became attractive as it offers a simpler way of controlling sophisticated devices, in a sci-fi-like scenario, in return of an increasingly computational power required by the artificial intelligence algorithms needed to detect, track and recognize them. There have been attempts to bring a solution to it by using 2D or 3D based image processing methods. There is a clear balance incline towards 3D methods in the consumer product as besides the almost insurmountable difficulties for producing robust and stable results, the price constraint added supplementary hurdles. As perfect illumination conditions are core factors in obtaining the above results, the infrared light was unanimously adopted by the domain technologies. In this paper, a novel real-time depth-mapping principle and a corresponding hardware solution for an IR depth-mapping camera is introduced. The new IR camera architecture comprises an illuminator module which is pulsed and modulated via a monotonic function using a phase-locked loop control for the laser intensity, while the reflected infrared light is captured during the increasing and decreasing monotonic function. A reconfigurable hardware architecture (RHA) unit calculates the depth and controls the IR waves in synchronism with the infrared sensor. The resolution of the depth map is variable depending on the resolution and gating possibilities of the image sensor. A sensor of 1 megapixel is used, providing a resolution of 1024×1024. Images of real objects are reconstructed in 3D based on the data obtained by the laser controlled by the RHA. A corresponding image processing algorithm builds the 3D map of the object in real-time. In this paper the camera is used to control consumer electronic products such as TV sets, laptops and others.",https://ieeexplore.ieee.org/document/6608963/,2013 IEEE 8th International Symposium on Applied Computational Intelligence and Informatics (SACI),23-25 May 2013,ieeexplore
10.1109/ISCAS.2000.856157,A new board for CNN stereo vision algorithm,IEEE,Conferences,Artificial vision for environment recognition is a very useful tool in autonomous robotics. Specifically the use of stereo vision algorithms implemented via a hardware neural architecture allows real time scene reconstruction. In this paper the follow-on of previous work on an analogue hardware Cellular Neural Network implementation of the algorithm is presented. In this paper a new CNN based PCI electronic board is presented.,https://ieeexplore.ieee.org/document/856157/,2000 IEEE International Symposium on Circuits and Systems (ISCAS),28-31 May 2000,ieeexplore
10.1109/FTC.2016.7821768,A non-biological AI approach towards natural language understanding,IEEE,Conferences,"The problem being addressed in this paper is that using brute force in Natural Language Processing and Machine Learning combined with advanced statistics will only approximate meaning and thus will not deliver in terms of real text understanding. Counting words and tracking word order or parsing by syntax will also result in probability and guesswork at best. Their vendors struggle in delivering accurate quality and this results in ill-functioning applications. The newer generation methodologies like Deep Learning and Cognitive Computing are breaking barriers in the (Big Data) fields of Internet of Things, Robotics and Image/Video Recognition but cannot be successfully deployed for text without huge amounts of training and sample data. In the short term, we believe non-biological Artificial Intelligence will produce the best results for text understanding. Miia applied advanced Linguistic and Semantic Technologies combined with ConceptNet modeling and Machine Learning to successfully cater deep intelligent and cross-language quality to several industries.",https://ieeexplore.ieee.org/document/7821768/,2016 Future Technologies Conference (FTC),6-7 Dec. 2016,ieeexplore
10.1109/FUZZY.1994.343709,A real time fuzzy dynamic image understanding system on general roads,IEEE,Conferences,"The purpose of this study is to realize a real time robotics vision system for, e.g. an ALV (autonomous land vehicle), in a cost effective way using fuzzy technology, that can be used in various circumstances (on general roads in Japan) such as from early morning till late evening and under the sunshine or in the rain. The presented system consists of an image processing part, knowledge base part, and a hardwired implementation part with VHDL. The image processing part is concerned with a dynamic image preprocessing based on mainly a conventional image processing technique. The knowledge base part employs a fuzzy frame knowledge base to express ambiguous information and natural language using fuzzy slot values. The hardwired implementation part designs hardware circuits using VHDL for high speed processing realization.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/343709/,Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference,26-29 June 1994,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ICARCV.2012.6485305,A robust real-time tracking system based on an adaptive selection mechanism for mobile robots,IEEE,Conferences,"Extensive research has been conducted in the domain of object tracking. Among the existing tracking methods, most of them mainly focus on using various cues such as color, texture, contour, features, motion as well as depth information to achieve a robust tracking performance. The tracking methods themselves are highly emphasized while properties of the objects to be tracked are usually not exploited enough. In this paper, we first propose a novel adaptive tracking selection mechanism dependent on the properties of the objects. The system will automatically choose the optimal tracking algorithm after examining the textureness of the object. In addition, we propose a robust tracking algorithm for uniform objects based on color information which can cope with real world constraints. In the mean time, we deployed a textured object tracking algorithm which combines the Lucas-Kanade tracker and a model based tracker using the Random Forests classifier. The whole system was tested and the experimental results on a variety of objects show the effectiveness of the adaptive tracking selection mechanism. Moreover, the promising tracking performance shows the robustness of the proposed tracking algorithm. The computation cost of the algorithm is very low, which proves that it can be further used in various real-time robotics applications.",https://ieeexplore.ieee.org/document/6485305/,2012 12th International Conference on Control Automation Robotics & Vision (ICARCV),5-7 Dec. 2012,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/ROBOT.2010.5509310,An Inertia-Based Surface Identification System,IEEE,Conferences,"In many robotics applications, knowing the material properties around a robot is often critical for the robot's successful performance. For example, in mobility, knowledge about the ground surface may determine the success of a robot's gait. In manipulation, the physical properties of an object may dictate the results of a grasping strategy. Thus, a reliable surface identification system would be invaluable for these applications. This paper presents an Inertia-Based Surface Identification System (ISIS) based on accelerometer sensor data. Using this system, a robot actively “knocks” on a surface with an accelerometer-equipped device (e.g., hand or leg), collects the accelerometer data in real-time, and then analyzes and extracts three critical physical properties, the hardness, the elasticity, and the stiffness, of the surface. A lookup table and k-nearest neighbors techniques are used to classify the surface material based on a database of previously known materials. This technique is low-cost and efficient in computation. It has been implemented on the modular and self-reconfigurable SuperBot and has achieved high accuracy (95% and 85%) in several identification experiments with real-world material.",https://ieeexplore.ieee.org/document/5509310/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/DCOSS.2019.00111,An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs,IEEE,Conferences,"Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8804776/,2019 15th International Conference on Distributed Computing in Sensor Systems (DCOSS),29-31 May 2019,ieeexplore
10.1109/WCICA.2000.859945,An agent team for RoboCup simulator league,IEEE,Conferences,"RoboCup is an attempt to promote AI and robotics research by providing a common task, soccer playing, for evaluation of various theories, algorithms and agent architectures. RoboCup consists of both the real robot league and the simulator league, where the soccer server is a standard software platform. A wide range of key issues on AI research emerges when designing simulator teams, such as the agent architecture, multi-agent teamwork, machine learning, etc. These issues are what we concerned most when developing our simulator team. Our team participated the first RoboCup tournament in China, and won the second place in the competition.",https://ieeexplore.ieee.org/document/859945/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ICARCV.2002.1235010,An autonomous mobile robot with fuzzy obstacle avoidance behaviors and a visual landmark recognition system,IEEE,Conferences,"Multi-sensor fusion has been a hot topic in the field of robotics. Inspired by the modern philosophy's spirit, the behavior-based systems interact with the real world directly. In this study, a fully autonomous mobile robot is developed that extracts all its knowledge from physical sensors and expresses all its goals and desires as physical action to affect its environment. The control software implements behavior-based artificial intelligence, where the coordination between various sensors are realized by layers of several simple and primitive behaviors similar to those observed in animals. In the developed mobile robot, each module itself generates behaviors. Behaviors corresponding to different sensors have different priorities, where the vision system has the lowest priority, and the ultrasonic sensors and bumper sensors have higher priority. The effectiveness of the developed system is demonstrated by experimental studies.",https://ieeexplore.ieee.org/document/1235010/,"7th International Conference on Control, Automation, Robotics and Vision, 2002. ICARCV 2002.",2-5 Dec. 2002,ieeexplore
10.1109/ROBIO.2013.6739426,An improved neuro-dynamics-based approach to online path planning for multi-robots in unknown dynamic environments,IEEE,Conferences,"Online path planning for multi-robots in complicated and dynamic environments is a difficult and hot issue in the field of robotics. Many traditional path planning methods cannot meet the requirements of online and real-time processing. Neuro-dynamics-based method has an aptitude for online and real-time path planning in complicated and dynamic environments. However, this method still has shortcomings. In this paper, an improved neuro-dynamics-based method is proposed with advantages. It has conducted efficient performance and easier realization with much less computational time complexity. Meanwhile, by entering “repulsion” mechanism, the improved method is capable of fair allocation and load balancing on the limited resources. Both simulated experiments and theoretical analysis demonstrate the feasibility and availability of the improved method in the paper.",https://ieeexplore.ieee.org/document/6739426/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/ROBOT.2010.5509935,An insect-based method for learning landmark reliability using expectation reinforcement in dynamic environments,IEEE,Conferences,"Navigation in unknown dynamic environments still remains a major challenge in robotics. Whereas insects like the desert ant with very limited computing and memory capacities solve this task with great efficiency. Thus, the understanding of the underlying neural mechanisms of insect navigation can inform us on how to build simpler yet robust autonomous robots. Based on recent developments in insect neuroethology and cognitive psychology, we propose a method for landmark navigation in dynamic environments. Our method enables the navigator to learn the reliability of landmarks using an expectation reinforcement method. For that end, we implemented a real-time neuronal model based on the Distributed Adaptive Control framework. The results demonstrate that our model is capable of learning the stability of landmarks by reinforcing its expectations. Also, the proposed mechanism allows the navigator to optimally restore its confidence when its expectations are violated. We also perform navigational experiments with real ants to compare with the results of our model. The behavior of the proposed autonomous navigator closely resembles real ant navigational behavior. Moreover, our model explains navigation in dynamic environments as a memory consolidation process, harnessing expectations and their violations.",https://ieeexplore.ieee.org/document/5509935/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/SYSCON.2018.8369547,An interactive architecture for industrial scale prediction: Industry 4.0 adaptation of machine learning,IEEE,Conferences,"According to wiki definition, there are four design principles in Industry 4.0. These principles support companies in identifying and implementing Industry 4.0 scenarios, namely, Interoperability, Information transparency, Technical assistance, Decentralized decisions. In this paper we have discussed our work on an implementation of a machine learning based interactive architecture for industrial scale prediction for dynamic distribution of water resources across the continent, keeping the four corners of Industry 4.0 in place. We report the possibility of producing most probable high resolution estimation regarding the water balance in any region within Australia by implementation of an intelligent system that can integrate spatial-temporal data from various independent sensors and models, with the ground truth data produced by 250 practitioners from the irrigation industry across Australia. This architectural implementation on a cloud computing platform linked with a freely distributed mobile application, allowing interactive ground truthing of a machine learning model on a continental scale, shows accuracy of 90% with 85% sensitivity of correct surface soil moisture estimation with end users at its complete control. Along with high level of information transparency and interoperability, providing on-demand technical supports and motivating users by allowing them to customize and control their own local predictive models, show the successfulness of principles in Industry 4.0 in real environmental issues in the future adaptation in various industries starting from resource management to modern generation soft robotics.",https://ieeexplore.ieee.org/document/8369547/,2018 Annual IEEE International Systems Conference (SysCon),23-26 April 2018,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ACIT47987.2019.8991028,Application of Fuzzy Neural Networks in Robotic Path Planning,IEEE,Conferences,This paper essentially discusses different methodologies of Fuzzy Neural Networks which are implemented to robust the functionality of mobile robots in dynamic and static environment. Fusion of algorithms is important to increase the working of any system provided. Different kind of mobile robots along with various algorithms frameworks are taken as case studies for this paper. Due to the reason that typical mathematical models used to make robots mobile in real environment were not very useful as they were not catering for the limitation of robotic system memory. Thus new methodologies are being discussed and implemented by robotics research community.,https://ieeexplore.ieee.org/document/8991028/,2019 International Arab Conference on Information Technology (ACIT),3-5 Dec. 2019,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/IVS.2018.8500457,Artificial Intelligence Course Design: iSTREAM-based Visual Cognitive Smart Vehicles,IEEE,Conferences,"New intelligent era calls for new learners and thus urgently needs a series of artificial intelligence. As a good educational platform for teaching artificial intelligence, smart cars have aroused concern and practices of all parties. However, at present, most courses and training pay more attention to basic knowledge and technology of smart cars, seldom to training based on artificial intelligence curriculum system and comprehensive competency integrating science, technology, art and management. Therefore, based on concept of iSTREAM (intelligence for Science, Technology, Robotics, Engineering, Art, and Management) and Raspberry intelligent vehicle teaching platform, this paper introduced a smart car-themed artificial intelligence courses including basic courses, specialized courses, specialized technical courses and elective courses. This course can guide learners to develop smart cars based on visual cognition, in-depth learning, VR and 3D printing integrated artistic creativity. It combines disciplines such as science, technology, art, games and management to upgrade a single knowledge and technology course into a comprehensive competency course that integrates knowledge, skills, emotion and management. Practice in Beijing NO.13 and NO.101 High School shows that this course allows students to experience scientific research process, learn artificial intelligence related knowledge and skills, understand scientific way of thinking and scientific research methods, stimulate learners' responsibility and scientific passion, and cultivate leadership skills through self-learning and partly project management.",https://ieeexplore.ieee.org/document/8500457/,2018 IEEE Intelligent Vehicles Symposium (IV),26-30 June 2018,ieeexplore
10.1109/ICACITE51222.2021.9404749,Artificial Intelligence and Robotics: Impact &amp; Open issues of automation in Workplace,IEEE,Conferences,"In engineering province robotics is one of the cognitive perspective to human communication or it concern with synod of perception of action. In Today's Tech World Artificial Intelligence is an essential tool which provides effective analytical business solutions &amp; plays significant role in the domain of robotics and have several similarities like human behavior which may drive the real world. This paper shows the significant blend of Artificial Intelligence and robotics which transform entire industries, technological improvement of robotics application &amp; utilization. It also focuses on different aspects of targets like marketing, home appliances, medical science, Smart agriculture and many more which includes open issues and technological challenges arises by this combination and conclude that robotics with AI can work in real world with real objects. Further AI based robotics are very important area in economics and organizational consequence, implementation of automation in any organizational design give impact on overall economy and infrastructure provide a wider direction for further research on Robotics and IoT are two terms each covering a myriad of technologies and concepts.",https://ieeexplore.ieee.org/document/9404749/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore
10.1109/SIBCON50419.2021.9438884,Assessment of Map Construction in vSLAM,IEEE,Conferences,"Vision-based Simultaneous Localization and Mapping (vSLAM) is a challenging task in modern computer vision. vSLAM is particularly important as mobile robotics application. It allows to localize the robot and build the map of unknown environment in 3D in real-time. During research and development of new methods, it needs extensive evaluation on trajectory and map quality compared to known methods. In this work we focus on map quality estimation. We develop the simulated ground-truth data in photo-realistic environment and introduce new metrics in order to estimate map quality. We evaluate neural network based vSLAM methods with our framework in order to show that it fits map quality estimation more than standard approaches. Open-source implementation of our map metrics is available at https://github.com/CnnDepth/slam_comparison.",https://ieeexplore.ieee.org/document/9438884/,2021 International Siberian Conference on Control and Communications (SIBCON),13-15 May 2021,ieeexplore
10.1109/SMC.2018.00655,Automated Training Plan Generation for Athletes,IEEE,Conferences,"In sports, athletes need detailed and individualised training plans for maintaining and improving their skills in order to achieve their best performance in competitions. This presents a considerable workload for coaches, who besides setting objectives have to formulate extremely detailed training plans. Automated Planning, which has already been successfully deployed in many real-world applications such as space exploration, robotics, and manufacturing processes, embodies a useful mechanism that can be exploited for generating training plans for athletes. In this paper, we propose the use of Automated Planning techniques for generating individual training plans, which consist of exercises the athlete has to perform during training, given the athlete's current performance, period of time, and target performance that should be achieved. Our experimental analysis, which considers general training of kickboxers, shows that apart of considerable less planning time, training plans automatically generated by the proposed approach are more detailed and individualised than plans prepared manually by an expert coach.",https://ieeexplore.ieee.org/document/8616652/,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",7-10 Oct. 2018,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ICAMIMIA47173.2019.9223365,Autonomous Car Simulation Using Evolutionary Neural Network Algorithm,IEEE,Conferences,"Automation with artificial intelligence (AI) has widely implemented in robotics, transportation and manufacture. AI has become a powerful technology that change human life and help human more flexible doing something. In this paper, it will show a result of simulation from an autonomous car using the evolutionary neural network algorithm which combines genetic algorithm and neural network. The purpose of the simulation is to test the model that we develop to know the right direction based on the track, so the evolutionary neural network that implemented to the autonomous car be able to deliver the best solution before it implements in the real machine or car technology. Genetic algorithm combines with a neural network to reach an evolution condition. The evolution process is achieved through crossover, mutation and selection process, so the algorithm will give the best result from the iteration of the experiment. The result of our experiment shows that evolutionary neural network algorithm give the best result within 3 layer architecture, with iteration average is 14.5 reach finish point (check point) 3 in the track simulation. Based on the simulation, our car model can find out the right direction.",https://ieeexplore.ieee.org/document/9223365/,"2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation (ICAMIMIA)",9-10 Oct. 2019,ieeexplore
10.1109/IROS.2017.8202143,Autonomous skill-centric testing using deep learning,IEEE,Conferences,Software testing is an important tool to ensure software quality. This is a hard task in robotics due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and/or simulation-based testing to overcome these problems. We propose model-free skill-centric testing in which a robot autonomously executes skills in the real world and compares it to previous experiences. The skills are selected by maximising the expected information gain on the distribution of erroneous software functions. We use deep learning to model the sensor data observed during previous successful skill executions and to detect irregularities. Sensor data is connected to function call profiles such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or task-specific models.,https://ieeexplore.ieee.org/document/8202143/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ICDL-EpiRob48136.2020.9278071,Bayesian Optimization for Developmental Robotics with Meta-Learning by Parameters Bounds Reduction,IEEE,Conferences,"In robotics, methods and softwares usually require optimizations of hyperparameters in order to be efficient for specific tasks, for instance industrial bin-picking from homogeneous heaps of different objects. We present a developmental framework based on long-term memory and reasoning modules (Bayesian Optimisation, visual similarity and parameters bounds reduction) allowing a robot to use meta-learning mechanism increasing the efficiency of such continuous and constrained parameters optimizations. The new optimization, viewed as a learning for the robot, can take advantage of past experiences (stored in the episodic and procedural memories) to shrink the search space by using reduced parameters bounds computed from the best optimizations realized by the robot with similar tasks of the new one (e.g. bin-picking from an homogenous heap of a similar object, based on visual similarity of objects stored in the semantic memory). As example, we have confronted the system to the constrained optimizations of 9 continuous hyperparameters for a professional software (Kamido) in industrial robotic arm bin-picking tasks, a step that is needed each time to handle correctly new object. We used a simulator to create bin-picking tasks for 8 different objects (7 in simulation and one with real setup, without and with meta-learning with experiences coming from other similar objects) achieving goods results despite a very small optimization budget, with a better performance reached when meta-learning is used (84.3 % vs 78.9 % of success overall, with a small budget of 30 iterations for each optimization) for every object tested (p-value=0.036).",https://ieeexplore.ieee.org/document/9278071/,2020 Joint IEEE 10th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),26-30 Oct. 2020,ieeexplore
10.1109/BigComp48618.2020.00-21,Benchmarking Jetson Platform for 3D Point-Cloud and Hyper-Spectral Image Classification,IEEE,Conferences,"Modern innovations of embedded system platforms (hardware accelerations) play a vital role in revolutionizing deep learning into practical scenarios, transforming human efforts into an automated intelligent system such as autonomous driving, robotics, IoT (Internet-of-Things) and many other useful applications. NVIDIA Jetson platform provides promising performance in terms of energy efficiency, favorable accuracy, and throughput for running deep learning algorithms. In this paper, we present benchmarking of Jetson platforms (Nano, TX1, and Xavier) by evaluating its performance based on computationally expensive deep learning algorithms. Previously, most of the benchmark results were based on 2-D images with conventional deep learning models for image processing. However, the implementation of many other complex data types at Jetson platform has remained a challenge. We also showed the practical impact of optimizing the algorithm vs improving the hardware accelerations by deploying a diverse range of dense and intensive deep learning architectures at all three aforementioned Jetson platforms, to make a better comparison of performance. In this regard, we have used two entirely different data-types, namely (i) ModelNet-40(Princeton-3D point-cloud) data-set along with PointNet deep learning architecture for classification of 3D point-cloud, and (ii) hyperspectral images (HSI) datasets (KSC and Pavia) alongside stacked autoencoders(SAE) to classify HSI correspondingly. This will broaden the scope of edge-devices to handle 3-D and HSI data whilst real-time classification will be processed at edge-server under the umbrella of edge-computing. The selection of (i) was made to exploit GPU heavily as the code uses TensorFlowgpu whereas (ii) was chosen to challenge the CPU cores of each platform as the code is based on Theano and may suffer from under-utilizing the GPU cores. We have presented the detailed evaluation exclusively in term of performance indices as inference time, the maximum number of concurrent processes, resource utilization per process and efficiency",https://ieeexplore.ieee.org/document/9070378/,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),19-22 Feb. 2020,ieeexplore
10.1109/IROS40897.2019.8967694,Benchmarking and Workload Analysis of Robot Dynamics Algorithms,IEEE,Conferences,"Rigid body dynamics calculations are needed for many tasks in robotics, including online control. While there currently exist several competing software implementations that are sufficient for use in traditional control approaches, emerging sophisticated motion control techniques such as nonlinear model predictive control demand orders of magnitude more frequent dynamics calculations. Current software solutions are not fast enough to meet that demand for complex robots. The goal of this work is to examine the performance of current dynamics software libraries in detail. In this paper, we (i) survey current state-of-the-art software implementations of the key rigid body dynamics algorithms (RBDL, Pinocchio, Rigid-BodyDynamics.jl, and RobCoGen), (ii) establish a methodology for benchmarking these algorithms, and (iii) characterize their performance through real measurements taken on a modern hardware platform. With this analysis, we aim to provide direction for future improvements that will need to be made to enable emerging techniques for real-time robot motion control. To this end, we are also releasing our suite of benchmarks to enable others to help contribute to this important task.",https://ieeexplore.ieee.org/document/8967694/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/ICCE-Berlin.2018.8576251,CNN Inference: Dynamic and Predictive Quantization,IEEE,Conferences,"Deep Learning techniques like Convolutional Neural Networks (CNN) are the de-facto method for image classification with broad usage spanning across automotive, industrial, medicine, robotics etc. Efficient implementation of CNN inference on embedded device requires a quantization method, which minimizes the accuracy loss, ability to generalize across deployment scenarios as well as real-time processing. Existing literature doesn't address all these three requirements simultaneously. In this paper, we propose a novel quantization algorithm to overcome above mentioned challenges. The proposed solution dynamically selects the scale for quantizing activations and uses Kalman filter to predict quantization scale to reduce accuracy loss. The proposed solution exploits the range statistics from previous inference processes to estimate quantization scale, enabling real-time solution. The proposed solution is implemented on TI's TDA family of embedded automotive processors. The proposed solution is running real time semantic segmentation on TDA2x processor within 0.1% accuracy loss compared floating point algorithm. The solution performs well across multiple deployment scenarios (e.g. rain, snow, night etc) demonstrating generalization capability of the solution.",https://ieeexplore.ieee.org/document/8576251/,2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin),2-5 Sept. 2018,ieeexplore
10.23919/ACC.1989.4790240,CONDOR: A Coarse-grained Parallel Architecture for Robot Control,IEEE,Conferences,"This paper presents an overview of the CONDOR, a real-time development environment designed for robotics research applications. The architecture is based on standard hardware components consisting of upto eight microprocessors interconnected through a shared memory bus, and is coupled with a powerful software environment based on message passing that enables the development of control programs for complicated robots. The hardware is extremely easy to set up since it uses standard components. Besides program libraries tuned for real-time control, the software utilities include a multi-processor pseudo-terminal emulator, a file-server and a flexible symbolic debugger that greatly enhance programmer productivity.",https://ieeexplore.ieee.org/document/4790240/,1989 American Control Conference,21-23 June 1989,ieeexplore
10.1109/ICECCME52200.2021.9591113,Cobots for FinTech,IEEE,Conferences,"Embedded devices enabling payments transaction processing in Financial Services industry cannot have any margin for error. These devices need to be tested &amp; validated by replicating production like environment to the extent possible. This means literally handling payments related events like swiping a credit card, tapping a mobile phone or pressing buttons amongst many other things like in real world. Embedded Software development is time consuming as it involves multiple man-machine interactions and dependencies such as managing and handling embedded devices, operating devices (Push buttons, interpret display panels, read receipt printouts etc.) and sharing devices for collaboration within team. During the current pandemic, it was impossible for software teams to travel to office, share devices or even procure necessary devices on time for project related tasks. This caused delay to project delivery and increased Time to market. The paper describes how the team used Capgemini's flexible Robotics as a Service (RaaS) platform that helped during pandemic to automate feasible man-machine interactions using Robotic arms. The paper provides details of the work done by the team that involves internet of things (IoT), Artificial Intelligence (AI) to remotely handle and operate hardware and devices thereby completing embedded software development life cycles faster and well within budget while ensuring superior product quality and importantly ensuring team's health and safety. This is novel in Financial Services space.",https://ieeexplore.ieee.org/document/9591113/,"2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)",7-8 Oct. 2021,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IVCNZ51579.2020.9290542,Comparison of Face Detection Algorithms on Mobile Devices,IEEE,Conferences,"Face detection is a fundamental task for many computer vision applications such as access control, security, advertisement, automatic payment, and healthcare. Due to technological advances mobile robots are becoming increasingly common in such applications (e.g. healthcare and security robots) and consequently there is a need for efficient and effective face detection methods on such platforms. Mobile robots have different hardware configurations and operating conditions from desktop applications, e.g. unreliable network connections and the need for lower power consumption. Hence results for face detection methods on desktop platforms cannot be directly translated to mobile platforms.We compare four common face detection algorithms, Viola-Jones, HOG, MTCNN and MobileNet-SSD, for use in mobile robotics using different face data bases. Our results show that for a typical mobile configuration (Nvidia Jetson TX2) Mobile-NetSSD performed best with 90% detection accuracy for the AFW data set and a frame rate of almost 10 fps with GPU acceleration. MTCNN had the highest precision and was superior for more difficult face data sets, but did not achieve real-time performance with the given implementation and hardware configuration.",https://ieeexplore.ieee.org/document/9290542/,2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ),25-27 Nov. 2020,ieeexplore
10.1109/MI-STA52233.2021.9464484,Comparison of PID and Artificial Neural Network Controller in on line of Real Time Industrial Temperature Process Control System,IEEE,Conferences,"Due to its simple structure and robustness, the traditional proportional-integral-derivative (PID) controller is commonly used in the field of industrial automation and process control, but it does not function well with nonlinear systems, time-delayed linear systems and time-varying systems. A new type of PID controller based on artificial neural networks and evolutionary algorithms is presented in this paper. An powerful instrument for a highly nonlinear system is the Artificial Neural Network. The interest in the study of the nonlinear system has increased through the implementation of a high-speed computer system,. In complex systems such as robotics and process control systems, the Neuro Control Algorithm is often applied. Systems of process management is also nonlinear and hard to control consistently.. This paper presents a comprehensive analysis in Which is offline trained by a multilayered feed forward back propagation neural network to act as a process control system controller, That is to say, a temperature control device without prior knowledge of its dynamics. Via the implementation of a range of input vectors to the neural network, the inverse dynamics model is developed. Based on these input vectors, the output of the neural network It is being studied by explicitly configuring it to monitor the operation. In this paper, based on set-point adjustment, impact of disturbances in load and variable dead time, compassion between the PID controller and ANN is conducted. The outcome shows that ANN outperforms the controller of the PID.",https://ieeexplore.ieee.org/document/9464484/,2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering MI-STA,25-27 May 2021,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
,Corporate Social Responsibility Challenges and Risks of Industry 4.0 technologies: A review,VDE,Conferences,"The fourth industrial revolution arrived with many enabling technologies that would impact important sociological aspects in the industry. Some of the Industry 4.0 technologies are already running in different industrial application, and other are still as a paradigm state. The social, economic, and environmental acceptance of Industry 4.0 technologies is still under discussion, which open new opportunities to execute various analysis about the possible implications of the implementation of such technologies. This article refers to an exploratory analysis and identification of the different challenges and risks of this new Industry 4.0 paradigm and its related technologies. The technologies under review were Internet of Things, Artificial Intelligence, Cloud Computing, cybersecurity, bid data, blockchain, 5G, robotics, adding manufacturing, unmanned systems, autonomous vehicles, virtual reality, and augmented reality. As a result, different social challenges and risks were identified for each technology, starting from vulnerability, implementation cost, until social aspects such as education and unemployment caused by those new technologies. In conclusion, Industry 4.0 arrived with a lot of benefits to the industry business, but companies should not stop thinking about sustainable development.",https://ieeexplore.ieee.org/document/8835964/,"Smart SysTech 2019; European Conference on Smart Objects, Systems and Technologies",4-5 June 2019,ieeexplore
10.1109/ROBIO49542.2019.8961433,CyberEarth: a Virtual Simulation Platform for Robotics and Cyber-Physical Systems,IEEE,Conferences,"The increasing sophisticated robot and intelligent system applications require universal visualization platforms which can guarantee the security and efficiency of task process execution in the situation of user-programming and using different kinds of automated equipment. In this paper, we present a universal visualization framework to build up program-driven simulation software of complex robots and intelligent systems by integrating several open-source technical modules, including Ubuntu Linux operation-system, QT Creator IDE environment, ROS robot operation system, OSG(OpenSceneGraph) 3D scene, osgEarth GIS(Geographic Information System)-based 3D scene, and also Python based user-programing robotic script language. Many complex visualization simulation systems of complex tasks in wide area and dynamic scenarios are realized by using this framework. Based on this framework, we built a virtual simulation platform CyberEarth for robotics and Cyber-Physical systems. The typical robotic simulation task, which is a visual coverage task for Multi-Agent/UAV, is also introduced to demonstration the universality of this platform.",https://ieeexplore.ieee.org/document/8961433/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/ICECS46596.2019.8964645,Data-Driven Video Grasping Classification for Low-Power Embedded System,IEEE,Conferences,"Video-based hand grasp analysis can support both robotics and prosthetics. Indeed, computational aspects represent a major issue, as hand grasp analysis is expected to support grasping systems that are hosted on low-power embedded systems. This paper proposes a framework for video-based grasping classification that is designed for implementation on resource-constrained devices. The framework adopts a fully data-driven strategy and relies on deep learning to deal with advanced analysis of video signals. Nonetheless, the overall design takes advantage of CNN architectures that can cope with the constraints imposed by embedded systems. The experimental session involved a real-world dataset containing daily life activities collected using egocentric perspective. In addition, the complete inference system is implemented on a NVIDIA Jetson-TX2 obtaining real time performances. The results confirm that the proposed system can suitably balance the trade off between accuracy and computational costs.",https://ieeexplore.ieee.org/document/8964645/,"2019 26th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",27-29 Nov. 2019,ieeexplore
10.1109/AERO.2018.8396547,Data-driven quality prognostics for automated riveting processes,IEEE,Conferences,"Technologies based in robotics and automatics are reshaping the aerospace industry. Aircraft manufacturers and top-tier suppliers now rely on robotics to perform most of its operational tasks. Over the years, a succession of implemented mobile robots has been developed with the mission of automating important industrial processes such as welding, material handling or assembly procedures. However, despite the progress achieved, a major limitation is that the process still requires human supervision and an extensive quality control process. An approach to address this limitation is to integrate machine learning methods within the quality control process. The idea is to develop algorithms that can direct manufacturing experts towards critical areas requiring human supervision and quality control. In this paper we present an application of machine learning to a concrete industrial problem involving the quality control of a riveting machine. The proposal consists of an intelligent predictive model that can be integrated within the existing real time sensing and pre-processing sub-systems at the equipment level. The framework makes use of several data-driven techniques for pre-processing and feature engineering, combined with the most accurate algorithms, validated through k-folds cross validation technique which also estimates prediction errors. The model is able to classify the manufacturing process of the machine as nominal or anomalous according to a real-world data set of design requirements and operational data. Several machine learning algorithms are compared such as linear regression, nearest neighbor, support vector machines, decision trees, random forests and extreme gradient boost. Results obtained from the case study suggest that the proposed model produces accurate predictions which meet industrial standards.",https://ieeexplore.ieee.org/document/8396547/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IV48863.2021.9575616,Deep Reinforcement Learning based control algorithms: Training and validation using the ROS Framework in CARLA Simulator for Self-Driving applications,IEEE,Conferences,"This paper presents a Deep Reinforcement Learning (DRL) framework adapted and trained for Autonomous Vehicles (AVs) purposes. To do that, we propose a novel software architecture for training and validating DRL based control algorithms that exploits the concepts of standard communication in robotics using the Robot Operating System (ROS), the Docker approach to provide the system with portability, isolation and flexibility, and CARLA (CAR Learning to Act) as our hyper-realistic open-source simulation platform. First, the algorithm is introduced in the context of Self-Driving and DRL tasks. Second, we highlight the steps to merge the proposed algorithm with ROS, Docker and the CARLA simulator, as well as how the training stage is carried out to generate our own model, specifically designed for the AV paradigm. Finally, regarding our proposed validation architecture, the paper compares the trained model with other state-of-the-art traditional control approaches, demonstrating the full strength of our DL based control algorithm, as a preliminary stage before implementing it in our real-world autonomous electric car.",https://ieeexplore.ieee.org/document/9575616/,2021 IEEE Intelligent Vehicles Symposium (IV),11-17 July 2021,ieeexplore
10.23919/SoftCOM50211.2020.9238313,Deep Semantic Image Segmentation for UAV-UGV Cooperative Path Planning: A Car Park Use Case,IEEE,Conferences,"Navigation of Unmanned Ground Vehicles (UGV) in unknown environments is an active area of research for mobile robotics. A main hindering factor for UGV navigation is the limited range of the on-board sensors that process only restricted areas of the environment at a time. In addition, most existing approaches process sensor information under the assumption of a static environment. This restrains the exploration capability of the UGV especially in time-critical applications such as search and rescue. The cooperation with an Unmanned Aerial Vehicle (UAV) can provide the UGV with an extended perspective of the environment which enables a better-suited path planning solution that can be adjusted on demand. In this work, we propose a UAV-UGV cooperative path planning approach for dynamic environments by performing semantic segmentation on images acquired from the UAV's view via a deep neural network. The approach is evaluated in a car park scenario, with the goal of providing a path plan to an empty parking space for a ground-based vehicle. The experiments were performed on a created dataset of real-world car park images located in Croatia and Germany, in addition to images from a simulated environment. The segmentation results demonstrate the viability of the proposed approach in producing maps of the dynamic environment on demand and accordingly generating path plans for ground-based vehicles.",https://ieeexplore.ieee.org/document/9238313/,"2020 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)",17-19 Sept. 2020,ieeexplore
10.1109/ICCSP.2017.8286790,Design framework for general purpose object recognition on a robotic platform,IEEE,Conferences,"The advancement in the broader field of Computer Vision is consequential, through past few decades. Therefore, a considerable improvement in object detection and tagging using convolutional neural networks has given way to accurate yet complex methods, which can identify objects in real-time. However, the growth in the area of implementing the algorithms on low powered portable devices has been relatively slow. This paper aims to converge the fields of computer vision and robotics, focusing on implementation of image description applications on an embedded system platform. We aim to integrate Neural Network powered object recognition system `YOLO v2' with a robotic platform to explore the potential applications in the advancing domain of service and personal robotics.",https://ieeexplore.ieee.org/document/8286790/,2017 International Conference on Communication and Signal Processing (ICCSP),6-8 April 2017,ieeexplore
10.1109/CNNA.2000.876849,Design of a dedicated CNN chip for autonomous robot navigation,IEEE,Conferences,"Obstacle avoidance is the main issue in autonomous robotics. It requires a three-dimensional effective environment sensing in real time. Among the others, the stereo vision approach to environmental information extraction seems to be very appealing, even if it leads an extremely high computational cost. However, a high performance implementation of this algorithm on a cellular neural network is able to overcome these difficulties. In the paper, the design of a CNN chip well suited for this algorithm is presented. This chip, performing a real time processing of the stereo vision data, will improve the cruising speed of a robotic platform.",https://ieeexplore.ieee.org/document/876849/,Proceedings of the 2000 6th IEEE International Workshop on Cellular Neural Networks and their Applications (CNNA 2000) (Cat. No.00TH8509),25-25 May 2000,ieeexplore
10.1109/SECON.2008.4494306,Design of an integrated environment for operation and control of robotic arms (non-reviewed),IEEE,Conferences,"As more advanced control algorithms are becoming available for the control of robotic arms, traditional fixed controller boards and associated code generators are becoming less convenient way to test such control algorithms in real-time. The process of using such boards is complex, time consuming, and inflexible. In this work, an integrated hardware-software environment was developed and presented where researchers can simply use any Matlab/Simulink basic function block and/or toolbox, such as fuzzy logic or neural network, to design, implement, and test different controller algorithms in realtime for robotic arm operations. The hardware includes a computer, the dSPACE-ds1103 digital processing board, an amplifier board, and the Zebra-ZERO robotics arm as a test-bed. Also, Matlab GUI, m-file, Matlab/Simulink blocks, and dSPACE interface functions are combined together to form the software environment. Control algorithms can be designed in the Matlab/Simulink then converted to c-code and download to the dSPACE processing board. The Matlab m-file are used to code the arm inverse kinematics model and the path planning to calculate the joint angles then send them to the dSPACE processing board using the dSPACE interface functions. Finally, the dSPACE processing board generates physical signal to control the robot arm in real-time. The proposed hardware-software components are developed and integrated together, and several control algorithms can be tested on it. The development steps and some of the realtime testing results conducted on the hardware are explained next in this extended abstract. Typically, controllers are designed to run on dedicated hardware and researchers need different hardware to test different control strategies. This can be costly and time consuming where one has to develop different control environment for every control strategy to be tested. In this work, an integrated hardware-software environment was developed for implementation and testing of different control algorithms in real-time. The integrated system is composed of a computer, a power supply, the DS1103 dSPACE controller board, an amplifier, and the Zebra- Zero force robotics arm. The computer is used to send commands to the DS1103 dSPACE controller board.Inside the DS1103 dSPACE controller board, a Texas instruments DSP micro-controller performs the necessary calculation to determine the PWM signal to be generated and sent to the amplifier. The amplifier then generates the control signals that are applied to dc-motors that drive the links. The motor encoders provide feedback position signals as output. To develop the software environment, the Matlab programming environment (m-file), Matlab's graphical user interface, Simulink, and the toolbox are all employed. A user graphical interface (GUI) was designed for user convenience. The robot can be moved to the ready position then, the forward or inverse kinematical model is chosen according to the type of input data. The links begin to move when the Move button is pressed. The user can also select different movement speed for each link. Finally, when link movement has ceased, the joint trajectories are displayed on the GUI. Trajectory planning files for position, velocity and acceleration references are also developed and implemented in the environment. Two types of trajectories are made available according to different requirements; second order polynomial and third-order polynomial trajectory. The second order polynomial trajectory is recommended for links with large angular position difference. For purpose of testing and verification, the Zebra-Zero robotics arm was used. The Lagrangian mechanics is used to develop the dynamic equations for the Zebra-Zero robotic arm. Some of the arm parameters are calculated while others are determined experimentally, e.g., the link inertias and masses. A Simulink model of the robotic arm dynamic was developed. To test the environment a control algorithm was also designed then automatically converted to C programming language and downloaded to the DS1103 dSPACE controller board. The user enters commands using the Matlab GUI. Based on input, positions or final location and orientation, the forward or inverse kinematical model is selected. In this work a PID control algorithm was designed and tested on the Zebra- Zero robotics arm. To verify the controller performance, Matlab toolbox was used to simulate the Zebra-Zero robotic arm dynamics model. The results were very comparable with the actual Zebra-Zero robotic arm hardware performance.",https://ieeexplore.ieee.org/document/4494306/,IEEE SoutheastCon 2008,3-6 April 2008,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/ICCSPN46366.2019.9150190,Developing A Framework for A Tactile Internet Enabled Robot Assisted Real-Time Interactive Medical System,IEEE,Conferences,"In this paper we outline a high-level framework and architecture for a robotic assisted real time interactive medical system for use in developing countries to help cure the acute shortage of qualified skill medical personnel in the health sector in of an internet of skills domain. We explore the application of new and innovative advancements in technological areas such as AI, 5G mobile networks, the tactile internet networks, robotics and haptic technology to aid in the digital transfer of medical expertise over a wide geographical area. We describe and propose technical specifications of such systems and review existing literature and current technologies in these areas. We interrogate the potential benefits and challenges facing the deployment of these technologies.",https://ieeexplore.ieee.org/document/9150190/,"2019 International Conference on Communications, Signal Processing and Networks (ICCSPN)",29-31 May 2019,ieeexplore
10.1109/MHS.2000.903293,Developing Khepera robot applications in a Webots environment,IEEE,Conferences,"Khepera is a high performance mini-robot. Its compact power allows an efficient experimentation using a real robot and applying the basic simulation tools. Webots is a high quality Khepera simulator used in the fields of autonomous systems, intelligent robotics, evolutionary robotics, machine learning, computer vision, and artificial intelligence. The simulation program can be transferred to the real robots easily. The aim of this article is to support the development of Khepera applications in the Webots environment. Starting from the introduction of Khepera robot and its development methodologies, the paper presents and analyses an application example of Khepera robot in the Webots environment. Finally, current applications and future research directions are presented.",https://ieeexplore.ieee.org/document/903293/,MHS2000. Proceedings of 2000 International Symposium on Micromechatronics and Human Science (Cat. No.00TH8530),22-25 Oct. 2000,ieeexplore
10.1109/INTERCON.2019.8853573,Development of a hand pose recognition system on an embedded computer using Artificial Intelligence,IEEE,Conferences,"The recognition of hand gestures is a very interesting research topic due to the growing demand in recent years in robotics, virtual reality, autonomous driving systems, human-machine interfaces and in other new technologies. Despite several approaches for a robust recognition system, gesture recognition based on visual perception has many advantages over devices such as sensors, or electronic gloves. This paper describes the implementation of a visual-based recognition system on a embedded computer for 10 hand poses recognition. Hand detection is achieved using a tracking algorithm and classification by a light convolutional neural network. Results show an accuracy of 94.50%, a low power consumption and a near real-time response. Thereby, the proposed system could be applied in a large range of applications, from robotics to entertainment.",https://ieeexplore.ieee.org/document/8853573/,"2019 IEEE XXVI International Conference on Electronics, Electrical Engineering and Computing (INTERCON)",12-14 Aug. 2019,ieeexplore
10.1109/ICVES.2009.5400189,Digital implementation of fuzzy logic controller for wide range speed control of brushless DC motor,IEEE,Conferences,"The brushless DC motors find wide applications such as in battery operated vehicles, wheel chairs, automotive fuel pumps, robotics, machine tools, aerospace and in many industrial applications due to their superior electrical and mechanical characteristics and its capability to operate in hazardous environment. Conventional controllers fail to yield desired performance in BLDC motor control systems due to the non-linearity arising out of variation in the system parameters and change in load. The main focus is now on the application of artificial intelligent techniques such as fuzzy logic to solve this problem. Another great challenge is to reduce the size and cost of the drive system without compromising the performance. In this paper, the design and digital implementation of fuzzy logic controller using a versatile ADUC812 microcontroller, and low-cost, compact, superior performance components are used in order to reduce the cost and size of the drive system. The experimental results are presented to prove the flexibility of the control scheme in real time.",https://ieeexplore.ieee.org/document/5400189/,2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES),11-12 Nov. 2009,ieeexplore
10.1109/CRV50864.2020.00024,Domain Generalization via Optical Flow: Training a CNN in a Low-Quality Simulation to Detect Obstacles in the Real World,IEEE,Conferences,"Many applications in robotics and autonomous systems benefit from machine learning applied to computer vision, but often the acquisition and preparation of data for training is complex and time-consuming. Simulation can significantly reduce the effort and potential risk of data collection, thereby allowing faster prototyping. However, the ability of a data-driven system to generalize from simulated data to the real world is far from obvious and often leading to inconsistent real-world results. This paper demonstrates that some properties of optical flow can be exploited to address this generalization problem. In this work, we train a neural network to detect collisions with simulated optical flow data. Our network, FlowDroNet, is able to correctly predict up to 89 percent of the collisions of a realworld dataset and easily achieves a higher detection accuracy when compared to a network trained on a similar dataset of realworld collisions. We release our code, models and a real-world dataset for collision avoidance as open-source. We also explore the relationship between the complexity of the input information and the ability to generalize to unseen environments, and show that in some situations, optical flow is an interesting tool to bridge the reality gap.",https://ieeexplore.ieee.org/document/9108671/,2020 17th Conference on Computer and Robot Vision (CRV),13-15 May 2020,ieeexplore
10.1109/SCCC.2001.972633,Domain-dependent option policies in autonomous robot learning,IEEE,Conferences,"In control-related applications such as robotics, determination of optimal solutions is made very difficult for many reasons. Among these stands the difficulty in finding out an appropriate model of the domain, as defined by the control agent (robot), environment where it acts and their interaction. Reinforcement learning is a theory which defines a collection of algorithms for determination of control actions under model-free assumptions, which allows control agents to learn optimal actions in an autonomous way. In reinforcement learning, a cost functional to be optimised is determined in advance. The agent then learns how to perform this optimisation via trial and error on its environment. A trial corresponds to execution of actions chosen by the agent, and the error is the immediate result (a real-valued reinforcement) of this action. In the work reported, we consider trials by a learning robotic agent which are not based on low level actions, but instead on sequences of actions (options or macro-operators). We analysed the performance both in terms of learning speed and quality of learned control-for options that correspond to mappings from states to action policies (O/sub /spl Pi// options). Experimental results show that careful (domain-dependent) selection of options (via methods such as discretised potential fields) produce much faster learning for option-based robots when compared to their action-based counterparts. Of critical importance, however, is the option mapping in regions of the state space where the options are not assumed to be necessary: as performance of reinforcement learning algorithms is strongly dependent on sufficient exploration of the state space, even in such regions a careful, ad-hoc selection of actions is of foremost importance.",https://ieeexplore.ieee.org/document/972633/,SCCC 2001. 21st International Conference of the Chilean Computer Science Society,9-9 Nov. 2001,ieeexplore
10.1109/BIOROB.2014.6913811,EEG-based classification of upper-limb ADL using SNN for active robotic rehabilitation,IEEE,Conferences,"Repetitive activities of daily living (ADL) and robotic active training are commonly practised in the rehabilitation of paralyzed patients, both of which have been proven rather effective to recover the locomotor function of impaired limbs. ADL classification based on electroencephalogram (EEG) is of great significance to perform active robotic rehabilitation for patients with complete spinal cord injury (SCI) who lose locomotion of affected limbs absolutely, where surface electromyography (sEMG) or active force signal can hardly be detected. It is a challenge to achieve a satisfying result in neuro-rehabilitation robotics using EEG signals due to the high randomness of the EEG data. A classification method is proposed based on spiking neural networks (SNN) to identify the upper-limb ADL of three classes with 14-channel EEG data. The continuous real-number signals are firstly encoded into spike trains through Ben's Spike Algorithm (BSA). The generated spikes are then submitted into a 3-D brain-mapped SNN reservoir called NeuCube trained by Spike Timing Dependant Plasticity (STDP). Spike trains from all neurons of the trained reservoir are finally classified using one version of dynamic evolving spiking neuron networks (deSNN) - deSNNs. Classifications are presented with and without NeuCube respectively on the same EEG data set. Results indicate that using the reservoir improves identification accuracy which turns out pretty promising despite that EEG data is highly noisy, low frequently sampled, and only from 14 channels. The classification technique reveals a great potential for the further implementation of active robotic rehabilitation to the sufferers of complete SCI.",https://ieeexplore.ieee.org/document/6913811/,5th IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics,12-15 Aug. 2014,ieeexplore
10.1109/FCCM51124.2021.00046,Edge Accelerator for Lifelong Deep Learning using Streaming Linear Discriminant Analysis,IEEE,Conferences,"Lifelong deep learning models are expected to continuously adapt and acquire new knowledge in dynamic environments. This capability is essential for numerous vision tasks in robotics and drones, and the models must be deployed on the edge to achieve real-time performance. We propose a FPGA accelerator of a streaming classifier for lifelong deep learning, which is based on streaming linear discriminant analysis (SLDA). When combined with a frozen Convolutional Neural Network (CNN) model, the proposed system is capable of class incremental lifelong learning for object classification.",https://ieeexplore.ieee.org/document/9444094/,2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),9-12 May 2021,ieeexplore
10.1109/WiSPNET51692.2021.9419475,Emotion based Media Playback System using PPG Signal,IEEE,Conferences,"The study involved identifying human emotions and integrates the identified emotion with the music system. The idea is to develop a complete product to utilize the detected emotion in a real-time application and also to achieve more accuracy and less memory. Human emotions are identified using physiological signals such as electrocardiography, electromyography, photoplethysmography, respiration, skin temperature, etc. Obtaining photoplethysmography (PPG) from the sensor is a simple, cost-effective, and non-invasive method. PPG sensors are capable of providing accurate heart-rate (HR) by detecting the variations in the blood flow. Signals are acquired using wearable technology from a personal whereas not compromising comfort and privacy. The attributes of Heart Rate Variability are analyzed to describe emotions, namely happy, calm, unhappy (sad), and fear using Machine learning technology. We deployed this recognized emotion to automate the music system associated with its emotion. To bring this, we built an Android app to communicate with the smart wearable utilized. Totally 150 members from both genders have participated. The accuracy of 91.81% is achieved. This emotion recognition system can be used in various fields like robotics, medicine, virtual reality, and gaming, advertising, education, automotive working conditions and safety, home appliances.",https://ieeexplore.ieee.org/document/9419475/,"2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",25-27 March 2021,ieeexplore
10.1109/ROMAN.2013.6628436,Emotional evaluation of bandit problems,IEEE,Conferences,"In this paper, we discuss an approach to evaluate decisions made during a multi-armed bandit learning experiment. Usually, the results of machine learning algorithms applied on multi-armed bandit scenarios are rated in terms of earned reward and optimal decisions taken. These criteria are valuable for objective comparison in finite experiments. But learning algorithms used in real scenarios, for example in robotics, need to have instantaneous criteria to evaluate their actual decisions taken. To overcome this problem, in our approach each decision updates the Zürich model which emulates the human sense of feeling secure and aroused. Combining these two feelings results in an emotional evaluation of decision policies and could be used to model the emotional state of an intelligent agent.",https://ieeexplore.ieee.org/document/6628436/,2013 IEEE RO-MAN,26-29 Aug. 2013,ieeexplore
10.1109/ICRA48506.2021.9561889,End-to-End Semi-supervised Learning for Differentiable Particle Filters,IEEE,Conferences,"Recent advances in incorporating neural networks into particle filters provide the desired flexibility to apply particle filters in large-scale real-world applications. The dynamic and measurement models in this framework are learnable through the differentiable implementation of particle filters. Past efforts in optimising such models often require the knowledge of true states which can be expensive to obtain or even unavailable in practice. In this paper, in order to reduce the demand for annotated data, we present an end-to-end learning objective based upon the maximisation of a pseudo-likelihood function which can improve the estimation of states when large portion of true states are unknown. We assess performance of the proposed method in state estimation tasks in robotics with simulated and real-world datasets.",https://ieeexplore.ieee.org/document/9561889/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/SECON.2010.5453897,Enhancing student learning in artificial intelligence using robotics,IEEE,Conferences,"Artificial intelligence (AI) techniques may be applied to a variety of real-world problems. At Embry-Riddle Aeronautical University, CS 455: Artificial Intelligence was offered during the Spring 2008 semester in which students from all disciplines were invited to attend. Robot kits are incorporated into the course as a pedagogical tool to motivate and encourage learning by applying theoretically abstract algorithms to concrete real-world problems. This paper discusses the approach to incorporating robotics in the AI classroom. A set of commercial off-the-shelf robot kits are discussed and analyzed with respect to the students' work during the semester. Finally, recommendations for improvements on teaching AI to a multi-disciplinary audience with the help of robot kits will be discussed.",https://ieeexplore.ieee.org/document/5453897/,Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon),18-21 March 2010,ieeexplore
10.1109/ROMAN.2003.1251857,Exploiting value statistics for similar continuing tasks,IEEE,Conferences,"In this paper, we try to consider interaction design for adaptation from the viewpoint of transfer of knowledge. Advancements in robotics are amazing, and their interaction processes with outside world (including human) are getting to be longer in time scale. We investigate these matters in an abstract agent that faces multiple learning tasks within its lifetime, transferring past learning experiences to improve its performance. We formulize the multitask reinforcement learning problem at first, and then we present two ways of incorporating past learning experiences into the agent's learning algorithm.",https://ieeexplore.ieee.org/document/1251857/,"The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.",2-2 Nov. 2003,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/ICUAS48674.2020.9214045,Extensions of the open-source framework Aerostack 3.0 for the development of more interactive flights between UAVs,IEEE,Conferences,"The basis for properly verified R&amp;D works is to provide reliable prototyping tools at three most important stages: computer simulation, laboratory tests and real-world experiments. In the laboratory-limited conditions, particular importance is attributed to the first two stages, especially in the context of the safety development of autonomous flights of unmanned aerial vehicle (UAV) groups in various missions. The open-source framework Aerostack support those needs and its effectiveness has been proven in the International Micro Air Vehicle Indoor Competitions (IMAV 2013, 2016, 2017) and Mohammed Bin Zayed International Robotics Challenge (MBZIRC 2020). In the paper, the exemplary functionalities for the new version of Aerostack Version 3.0 Distribution Sirocco (Aerial robotics framework for the industry), extended additionally with a library of new behaviors, are presented. The mission of UAVs can be developed fast and effectively in order to conduct test flights with real drones in lab, before one will decide to fly autonomously outdoor. The representative results obtained for low-cost AR.Drone 2.0 UAV models in two missions, are presented. The first mission is autonomous patrolling the area by a pair of UAVs, the second - intercepting the intruder in guarded area by the guard UAV.",https://ieeexplore.ieee.org/document/9214045/,2020 International Conference on Unmanned Aircraft Systems (ICUAS),1-4 Sept. 2020,ieeexplore
10.1109/ICECS49266.2020.9294790,FPGA Implementation of Simplified Spiking Neural Network,IEEE,Conferences,"Spiking Neural Networks (SNN) are third generation Artificial Neural Networks (ANN), which are close to the biological neural system. In recent years SNN has become popular in the area of robotics and embedded applications, therefore, it has become imperative to explore its real-time and energy-efficient implementations. SNNs are more powerful than their predecessors because of their ability to encode temporal information and to use biologically plausible plasticity rules. In this paper, a simpler and computationally efficient SNN model is described. The proposed model is implemented and validated utilizing a Xilinx Virtex 6 FPGA. It is demonstrated that the proposed model analyzes a fully connected network consisting of 800 neurons and 12,544 synapses in real-time.",https://ieeexplore.ieee.org/document/9294790/,"2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",23-25 Nov. 2020,ieeexplore
10.1109/SACI.2007.375494,FPGA Parallel Implementation of CMAC Type Neural Network with on Chip Learning,IEEE,Conferences,"The hardware implementation of neural networks is a new step in the evolution and use of neural networks in practical applications. The CMAC cerebellar model articulation controller is intended especially for hardware implementation, and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA's has several benefits, with emphasis on parallelism and the real time capabilities. This paper discusses the hardware implementation of the CMAC type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor.",https://ieeexplore.ieee.org/document/4262496/,2007 4th International Symposium on Applied Computational Intelligence and Informatics,17 Yearly-18 May 2007,ieeexplore
10.1109/WiSPNET51692.2021.9419438,Faster Training of Edge-attention Aided 6D Pose Estimation Model using Transfer Learning and Small Customized Dataset,IEEE,Conferences,"Computer Vision is the field of machine learning that deals with computers gaining knowledge from digital images/videos and performing tasks that human vision is capable of doing. It is widely used in the field of robotics for designing guidance systems where objects in the robot's field of view are identified and located. This research work is an application-specific project enabling a half-humanoid to find the 6D pose and bounding boxes of its hand and other objects within its field of view. We add an edge prediction head to the NOCS (Normalised Object Coordinate Space) model, which predicts the edges of each object from the predicted instance maps. An additional edge-agreement-loss found from the predicted edges is added to the total loss. This increases the attention to the edges and improves the accuracy of prediction of the instance masks. This edge-attention aided model is initialized with pre-trained weights of CAMERA and REAL dataset using transfer learning. The backbone layers of the model are frozen and the head layers alone are trained using a synthetic dataset (HAND dataset) we created using a software called blender. The model gives promising results when tested with objects kept in varying lighting conditions and at different distances from the camera. The use of transfer learning in models as large as the NOCS model allows us to train the model for a new class by only training the top few layers with a significantly small dataset.",https://ieeexplore.ieee.org/document/9419438/,"2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",25-27 March 2021,ieeexplore
10.1109/SSCI.2017.8280891,Fault diagnosis in robot swarms: An adaptive online behaviour characterisation approach,IEEE,Conferences,"The need for an active approach to fault tolerance in swarm robotics systems is well established. This will necessarily include an approach to fault diagnosis if robot swarms are to retain long-term autonomy. This paper proposes a novel method for fault diagnosis, based around behavioural feature vectors, that incorporates real-time learning and memory. Initial results are encouraging, and show that an unsupervised learning approach is able to diagnose common electro-mechanical fault types, and arrive at an appropriate recovery option in the majority of the cases tested.",https://ieeexplore.ieee.org/document/8280891/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/SBR-LARS.2012.57,Fixed-Point Neural Network Ensembles for Visual Navigation,IEEE,Conferences,"Visual navigation is an important research field in robotics because of the low cost and the high performance that is usually achieved by visual navigation systems. Pixel classification as a road pixel or a non-road pixel is a task that can be well performed by Artificial Neural Networks. In the case of real-time instances of the image classification problem, as when applied to autonomous vehicles navigation, it is interesting to achieve the best possible execution time. Hardware implementations of these systems can achieve fast execution times but the floating-point implementation of Neural Networks are commonly complex and resource intensive. This work presents the implementation and analysis of a fixed-point Neural Network Ensemble for image classification. The system is composed by six fixed-point Neural Networks verified with cross-validation technique, using some proposed voting schemes and analyzed considering the execution time, precision, memory consumption and accuracy for hardware implementation. The results show that the fixed-point implementation is faster, consumes less memory and has an acceptable precision compared to the floating-point implementation. This fact suggests that the fixed point implementation should be used in systems that need a fast execution time. Some questions about ensembles and voting have to be reviewed for fixed-point Neural Network Ensembles.",https://ieeexplore.ieee.org/document/6363361/,2012 Brazilian Robotics Symposium and Latin American Robotics Symposium,16-19 Oct. 2012,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
10.1109/3ICT.2019.8910276,Ground Operations Management using a Data Governance Dashboard,IEEE,Conferences,"An incident involving the use of chemical, biological, radiological, and nuclear (CBRN) materials might represent a significant challenge for crime scene investigators. The paper presents a full system architecture to assess the hazardous situations resulting from CBRN materials. This issue is crucial since there were a number of incidents that occurred in which forensics people could not reach the location either due to being unreachable or due to harmful emissions. The proposed solution integrates various inputs including data from sensors, video streaming, geo-data along with using Artificial Intelligence (AI) for good decision-making and data analysis. A geo-dashboard was also designed to demonstrate, in real-time, the collected data from several angles and according to various queries. It also monitors the performance in real-time. The topic is not new however the novelty of the proposed solution is the integration of multiple sources of data, applying deep neural nets and projecting the data and data analytics in real-time on a dashboard that displays the analysis and data from different perspectives considering the viewpoint of the individuals who will use that system. The paper also presents how the ROCSAFE multidisciplinary research project addresses the identified scenario. The project combines topics from robotics, sensor technology, analytical and situation awareness software, transforming data into knowledgeable insights to support the decision-making process.",https://ieeexplore.ieee.org/document/8910276/,"2019 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)",22-23 Sept. 2019,ieeexplore
10.1109/SII46433.2020.9025951,Gym-Ignition: Reproducible Robotic Simulations for Reinforcement Learning,IEEE,Conferences,"This paper presents Gym-Ignition, a new framework to create reproducible robotic environments for reinforcement learning research. It interfaces with the new generation of Gazebo, part of the Ignition Robotics suite, which provides three main improvements for reinforcement learning applications compared to the alternatives: 1) the modular architecture enables using the simulator as a C++ library, simplifying the interconnection with external software; 2) multiple physics and rendering engines are supported as plugins, simplifying their selection during the execution; 3) the new distributed simulation capability allows simulating complex scenarios while sharing the load on multiple workers and machines. The core of Gym-Ignition is a component that contains the Ignition Gazebo simulator and exposes a simple interface for its configuration and execution. We provide a Python package that allows developers to create robotic environments simulated in Ignition Gazebo. Environments expose the common OpenAI Gym interface, making them compatible out-of-the-box with third-party frameworks containing reinforcement learning algorithms. Simulations can be executed in both headless and GUI mode, the physics engine can run in accelerated mode, and instances can be parallelized. Furthermore, the Gym-Ignition software architecture provides abstraction of the Robot and the Task, making environments agnostic on the specific runtime. This abstraction allows their execution also in a real-time setting on actual robotic platforms, even if driven by different middlewares.",https://ieeexplore.ieee.org/document/9025951/,2020 IEEE/SICE International Symposium on System Integration (SII),12-15 Jan. 2020,ieeexplore
10.1109/ISIC.1992.225127,Hierarchical architecture for multi-sensor robot cell operation,IEEE,Conferences,"The authors describe a hierarchical architecture designed to carry out experiments in multisensor integration and sensor-based control in robotics. The hierarchical model is composed of three major levels: a high-level information processing and planning structure at the top, a logic-branching control structure at the intermediate level, and a real-time continuous sensory feedback loop at the bottom level. The two lower control structures are addressed. The principal submodules of the intermediate structure are described, with particular emphasis on communication issues and on the available software mechanisms for configuration and online maintenance of the robot cell. The architecture of the real-time continuous control structure that composes the bottom level is also described. The application of the adaptive self-tuning scheme in controlling position and force, specified in task-space coordinates, is discussed. Practical issues and experimental results are summarized.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/225127/,Proceedings of the 1992 IEEE International Symposium on Intelligent Control,11-13 Aug. 1992,ieeexplore
10.1109/ROBOT.1999.770002,High-speed navigation using the global dynamic window approach,IEEE,Conferences,"Many applications in mobile robotics require the safe execution of a collision-free motion to a goal position. Planning approaches are well suited for achieving a goal position in known static environments, while real-time obstacle avoidance methods allow reactive motion behavior in dynamic and unknown environments. This paper proposes the global dynamic window approach as a generalization of the dynamic window approach. It combines methods from motion planning and real-time obstacle avoidance to result in a framework that allows robust execution of high-velocity, goal-directed reactive motion for a mobile robot in unknown and dynamic environments. The global dynamic window approach is applicable to nonholonomic and holonomic mobile robots.",https://ieeexplore.ieee.org/document/770002/,Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C),10-15 May 1999,ieeexplore
10.1109/ICCICC50026.2020.9450269,Human Capability Augmentation through Cognitive and Autonomous Systems,IEEE,Conferences,"The Covid-19 pandemic reminds us again about our limited knowledge and understanding in the nature including both micro and macro worlds. We have been developing a variety of tools such as automation, robotics, internet, and artificial intelligence (AI), etc. to augment human capability for improved safety, quality, and productivity in work and life, but human lives are still vulnerable over 100 years since the last Spanish Flu in 1918. We are even more vulnerable when the tools we developed (e.g., automation and AI) do not understand human intent or follow human instructions. Recent accidents to the Boeing 737 Max passengers ring the alarm again about the imperative needs of appropriate design concepts and scientific methodologies for developing safety critical cognitive and/or autonomous systems or AI functions and collaborative partnership of human and intelligent systems. With AI and its related technologies reach their bottleneck, it is even more vital to follow scientific and systematic methodology to understand well about capacity and limitation of both human intelligence and machine intelligence so that their strengths can be optimized for a collaborative partnership when dealing with safety critical situations. This talk discusses about the needs for the researchers, designers, developers, and all practitioners who are interested in building and using 21st century human-autonomy symbiosis technologies (Why). It touches the topics of proper analytical methodologies for functional requirements of the intelligent systems, design methodologies, implementation strategies, evaluation approaches, and trusted relationships (How). These aspects will be explained with real-world examples when considering contextual constraints of technology, human capability and limitations, and functionalities that AI and autonomous systems should achieve (When). Audience will gain insights of context-based and interaction-centered design approach for developing a safe, trusted, and collaborative partnership between human and technology by optimizing the interaction between human intelligence and AI. The challenges and potential issues will also be discussed for guiding future research and development activities when augmenting human capabilities with AI, and cognitive and/or autonomous systems.",https://ieeexplore.ieee.org/document/9450269/,2020 IEEE 19th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),26-28 Sept. 2020,ieeexplore
10.1109/ROBIO.2012.6491182,Human recognition with a hardware-accelerated multi-prototype learning and classification system,IEEE,Conferences,"This paper reports a hardware-accelerated multi-prototype learning and classification system which is suitable for real-time recognition systems. The real-world applicability of robotics or surveillance systems is dependent upon their real-time performance. Hardware based solutions can meet the needs for real-time limited problems; however, hardware-friendly solutions have lacked the flexibility to handle a large range of complex tasks. Software based solutions have been used to tackle complex tasks and allow for greater flexibility but lack the speeds which hardware systems can provide. The developed multi-prototype learning and classification system surmounts these limitations and is applied to the problem of human recognition for demonstrating its capabilities. A fully digital Euclidian distance searching circuit is developed in order to reduce the computational cost within the learning and classification process. The system outperforms other implementations by significantly reducing training times and attains a per sample recognition speed of 1.03 μs.",https://ieeexplore.ieee.org/document/6491182/,2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),11-14 Dec. 2012,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/ROMAN.1992.253866,Hybrid architectures for intelligent robotic systems,IEEE,Conferences,"Hybrid architectures, based on combinations of analogic, symbolic, and neural methods, are well suited for real-time applications in advanced robotics. Real-time industrial applications are mainly based on the correction of preplanned programs. So far, the planning and control modules of these kind of applications are often unable to react and/or classify un-expected events. The approach described attempts to integrate the sensor-based analogic method and the neural method into a multiple-level architecture that operates on an analogic world model, so that the action planning can be performed in a smart, reactive way. Given the task, the system builds the world model of the scenario. The reasoning and planning modules act both at the strategic as well as reactive levels, and the activated sensor-based motor strategies handle the sensorial data inputs and drive the robot controller module in the execution of the stream of motor commands. The interaction between the different levels is mainly based on the idea of maintaining and updating in real-time the world model, so that each module can locally operate on specific parts of the whole world model.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/253866/,[1992] Proceedings IEEE International Workshop on Robot and Human Communication, 1992,ieeexplore
10.1109/CCECE.2002.1013006,IEEE CCECE2002. Canadian Conference on Electrical and Computer Engineering. Conference Proceedings (Cat. No.02CH37373),IEEE,Conferences,"The following topics are dealt with: power system modelling, planning and operation; power electronics and machines; electromagnetics and optics; antenna theory, design and applications; remote sensing; SAR ; acoustic ranging; microelectronics and VLSI; nanotechnology and micromachining; instrumentation and sensors; circuits and systems; robotics and mechatronics; reliability engineering; computers and digital hardware; real-time systems; software and information technology; computational intelligence; neural networks; genetic algorithms and fuzzy logic; pattern recognition; image processing; video processing; signal processing and filter design; biomedical engineering; health-care systems; communications systems; computer networks; wireless networks; telecommunication traffic analysis; QoS; industrial applications.",https://ieeexplore.ieee.org/document/1013006/,IEEE CCECE2002. Canadian Conference on Electrical and Computer Engineering. Conference Proceedings (Cat. No.02CH37373),12-15 May 2002,ieeexplore
10.1109/ICECCME52200.2021.9590955,Impact of Real-World Market Conditions on Returns of Deep Learning based Trading Strategies,IEEE,Conferences,"Based on recent advancements in natural language processing, computer vision and robotics, a growing number of researchers and traders attempt to predict future asset prices using deep learning techniques. Typically, the goal is to find a profitable and at the same time low-risk trading strategy. However, it is not straightforward to evaluate a found trading strategy. Evaluating solely on historic price data neglects important factors arising in real markets. In this paper, we analyze the impact of real-world market conditions in terms of trading fees, borrow interests, slippage and spreads on trading returns. For that, we propose a deep learning trading bot based on Temporal Convolutional Networks, which is deployed to a real cryptocurrency exchange. We compare the results obtained in the real market with simulated returns and investigate the impact of the different real-world market conditions. Our results show that besides trading fees (which have the biggest impact on returns), factors like slippage and spread also affect the returns of the trading strategy.",https://ieeexplore.ieee.org/document/9590955/,"2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)",7-8 Oct. 2021,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/FIE.2006.322407,Incorporating an Affective Model to an Intelligent Tutor for Mobile Robotics,IEEE,Conferences,"Emotions have been identified as important players in motivation, and motivation is very important for learning. When a tutor recognizes the affective state of the student and responds accordingly, the tutor may be able to motivate students and improve the learning process. We propose a general affective behavior model which integrates information from the student's pedagogical state, affective state, and the tutorial situation, to decide the best tutorial action, considering the tutor preferences from a pedagogical and affective point of view. Our proposal is based on emotions models, personality theories and teachers' expertise. The affective model is implemented as a dynamic decision network, with utility measures on both learning and motivation, and is being incorporated to an intelligent tutor within a virtual laboratory for learning mobile robotics. This paper presents preliminary results in the construction of the affective behavior model",https://ieeexplore.ieee.org/document/4116913/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/DEVLRN.2014.6983001,Incremental training of Restricted Boltzmann Machines using information driven saccades,IEEE,Conferences,"In the context of developmental robotics, a robot has to cope with complex sensorimotor spaces by reducing their dimensionality. In the case of sensor space reduction, classical approaches for pattern recognition use either hardcoded feature detection or supervised learning. We believe supervised learning and hard-coded feature extraction must be extended with unsupervised learning of feature representations. In this paper, we present an approach to learn representations using space-variant images and saccades. The saccades are driven by a measure of quantity of information in the visual scene, emerging from the activations of Restricted Boltzmann Machines (RBMs). The RBM, a generative model, is trained incrementally on locations where the system saccades. Our approach is implemented using real data captured by a NAO robot in indoor conditions.",https://ieeexplore.ieee.org/document/6983001/,4th International Conference on Development and Learning and on Epigenetic Robotics,13-16 Oct. 2014,ieeexplore
10.1109/CASE48305.2020.9216902,Industrial Robot Grasping with Deep Learning using a Programmable Logic Controller (PLC),IEEE,Conferences,"Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95% with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world's largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",https://ieeexplore.ieee.org/document/9216902/,2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),20-21 Aug. 2020,ieeexplore
10.1109/CADCG.2007.4407908,Intelligent Robotic Peg-in-Hole Insertion Learning Based on Haptic Virtual Environment,IEEE,Conferences,A new approach is explored to transfer human manipulation skills to a robotics system. A skill acquisition algorithm utilizes the position and contact force/torque data generated in the virtual environment combined with a priori knowledge about the task to generate the skills required to perform such a task. Such skills are translated into actual robotic trajectories for implementation in real time. The peg-in-hole insertion problem is used as a case study. The results are reported.,https://ieeexplore.ieee.org/document/4407908/,2007 10th IEEE International Conference on Computer-Aided Design and Computer Graphics,15-18 Oct. 2007,ieeexplore
10.1109/ISDA.2010.5687225,Intelligent online case-based planning agent model for real-time strategy games,IEEE,Conferences,"Research in learning and planning in real-time strategy (RTS) games is very interesting in several industries such as military industry, robotics, and most importantly game industry. A recent published work on online case-based planning in RTS Games does not include the capability of online learning from experience, so the knowledge certainty remains constant, which leads to inefficient decisions. In this paper, an intelligent agent model based on both online case-based planning (OLCBP) and reinforcement learning (RL) techniques is proposed. In addition, the proposed model has been evaluated using empirical simulation on Wargus (an open-source clone of the well known RTS game Warcraft 2). This evaluation shows that the proposed model increases the certainty of the case base by learning from experience, and hence the process of decision making for selecting more efficient, effective and successful plans.",https://ieeexplore.ieee.org/document/5687225/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/CIMCA.2006.133,International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce - Title,IEEE,Conferences,"The following topics are dealt with: intelligent agents and ontologies; data mining, knowledge discovery and decision making; intelligent systems; Web technologies and Web services; virtual reality and games; image processing and image understanding techniques; adaptive control and automation; modelling, prediction and control; multi-agent systems and computational intelligence; agent systems, personal assistant agents and profiling; fuzzy systems for industrial automation; control strategies; neural network applications; clustering, classification, data mining and risk analysis; dynamics systems; innovative control systems, hardware design and implementation; robotics and automation; e-business, e-commerce, innovative Web applications; Web databases; diagnosis and medical applications; learning systems; optimization, hybrid systems, genetic algorithms and evolutionary computation control applications; online learning and ERP; knowledge acquisition and classification; nanomechatronics; simulation and control; mobile network applications; information retrieval; Bayesian networks; human computer interaction; cognitive science; mobile agents; knowledge management; intelligent control; e-search and navigation; security.",https://ieeexplore.ieee.org/document/4052645/,2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06),28 Nov.-1 Dec. 2006,ieeexplore
10.1109/CCWC51732.2021.9376024,Joint Activity Localization and Recognition with Ultra Wideband based on Machine Learning and Compressed Sensing,IEEE,Conferences,"Joint human activity localization and recognition has broad application prospects in human-computer interaction, virtual reality, smart healthcare system, security monitoring and robotics. Ultra-wideband (UWB) is an emerging technology adopted in real-time location system (RTLS) and has shown satisfactory performance in the task of human activity localization. However, few studies have been carried out to simultaneously recognize human activities based on UWB RTLS, which limits the use of UWB RTLS in many applications. In this study, we develop a RTLS based on UWB for the joint task of activity localization and recognition. A compressed sensing-based activity recognition approach is proposed for the task of activity recognition and several machine learning methods are designed to further improve the activity localization accuracy for the task of activity localization. The experimental results show that our UWB RTLS achieves good performance in this joint task.",https://ieeexplore.ieee.org/document/9376024/,2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC),27-30 Jan. 2021,ieeexplore
10.1109/ICCTA48790.2019.9478839,Keynote Speech II: Readiness for the Impact of Emerging Technologies,IEEE,Conferences,"Throughout history, technical innovation has always been the key driver of human progress. The use of new technologies brings positive changes to people and societies. It makes life easier, more pleasant, raises the standard of living, and improves human wellbeing, health and life expectancy. It also changes social frameworks, business dynamics, job types, and wealth distribution.The introduction of digital technology a few decades ago has spurred a series of transformations that have significantly changed the way we live, work, transact, and interact. Innovation continues to accelerate in a large set of technologies and applications. New hardware, software, and algorithmic tools allow us to process information much faster and in much larger volumes. Moreover, the digital world is becoming increasingly intertwined with the physical world of machines, to which it is bringing ubiquitous intelligence and a perpetual flow of information.These trends are driving us towards a very different future. That future has already started. A new wave of social, economic, and psychological changes is expected to abruptly affect almost everything we do. With change, many opportunities come along. Those who anticipate the course of the future, and prepare for it, will be ready to seize these opportunities and will come out winners. Those who chose to ignore the signs of change, will risk losing their livelihood and eventually hurting their families, businesses, and societies. Those who see the storm coming but react by standing still in panic, disgruntlement, and lamentation will be defenseless when the inevitable waves hit their shores.This presentation overviews the trends in technology and applications, including Artificial Intelligence, Big Data Analytics, Robotics, Internet of Things, Industry 4.0, etc. The impact that such advances are likely to have on the hightech as well as the low-tech job markets is outlined. Some actions and initiatives are proposed and discussed, with the purpose of triggering a larger debate on how individuals, businesses, academic institutions, and governments should prepare for the anticipated massive changes that are already beginning to affect our world.",https://ieeexplore.ieee.org/document/9478839/,2019 29th International Conference on Computer Theory and Applications (ICCTA),29-31 Oct. 2019,ieeexplore
10.1109/ISORCW.2012.36,Knowledge Representation for Cognitive Robotic Systems,IEEE,Conferences,"Cognitive robotics are autonomous systems capable of artificial reasoning. Such systems can be achieved with a logical approach, but still AI struggles to connect the abstract logic with real-world meanings. Knowledge representation and reasoning help to resolve this problem and to establish the vital connection between knowledge, perception, and action of a robot. Cognitive robots must use their knowledge against the perception of their world and generate appropriate actions in that world in compliance with some goals and beliefs. This paper presents an approach to multi-tier knowledge representation for cognitive robots, where ontologies are integrated with rules and Bayesian networks. The approach allows for efficient and comprehensive knowledge structuring and awareness based on logical and statistical reasoning.",https://ieeexplore.ieee.org/document/6196117/,2012 IEEE 15th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops,11-11 April 2012,ieeexplore
10.1109/CIS.2013.6782155,Knowledge representation with KnowLang the marXbot case study,IEEE,Conferences,"Intelligent systems are capable of AI exhibited via knowledge representation and reasoning, which helps to connect abstract knowledge symbols to real-world meanings. This paper presents a formal language for knowledge representation called KnowLang. The language implies a multi-tier specification model emphasizing knowledge corpuses, knowledge base operators and inference primitives. The approach allows for efficient and comprehensive knowledge structuring where ontologies are integrated with rules and Bayesian networks. The paper presents the KnowLang specification constructs formally along with a case study based on a mobile robotics platform.",https://ieeexplore.ieee.org/document/6782155/,2012 IEEE 11th International Conference on Cybernetic Intelligent Systems (CIS),23-24 Aug. 2012,ieeexplore
10.1109/IROS.2010.5649358,LCM: Lightweight Communications and Marshalling,IEEE,Conferences,"We describe the Lightweight Communications and Marshalling (LCM) library for message passing and data marshalling. The primary goal of LCM is to simplify the development of low-latency message passing systems, especially for real-time robotics research applications. Messages can be transmitted between different processes using LCM's publish/subscribe message-passing system. A platformand language-independent type specification language separates message description from implementation. Message specifications are automatically compiled into language-specific bindings, eliminating the need for users to implement marshalling code while guaranteeing run-time type safety. LCM is notable in providing a real-time deep traffic inspection tool that can decode and display message traffic with minimal user effort and no impact on overall system performance. This and other features emphasize LCM's focus on simplifying both the development and debugging of message passing systems. In this paper, we explain the design of LCM, evaluate its performance, and describe its application to a number of autonomous land, underwater, and aerial robots.",https://ieeexplore.ieee.org/document/5649358/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ICRA.2018.8460502,Learning Motion Predictors for Smart Wheelchair Using Autoregressive Sparse Gaussian Process,IEEE,Conferences,"Constructing a smart wheelchair on a commercially available powered wheelchair (PWC) platform avoids a host of seating, mechanical design and reliability issues but requires methods of predicting and controlling the motion of a device never intended for robotics. Analog joystick inputs are subject to black-box transformations which may produce intuitive and adaptable motion control for human operators, but complicate robotic control approaches; furthermore, installation of standard axle mounted odometers on a commercial PWC is difficult. In this work, we present an integrated hardware and software system for predicting the motion of a commercial PWC platform that does not require any physical or electronic modification of the chair beyond plugging into an industry standard auxiliary input port. This system uses an RGB-D camera and an Arduino interface board to capture motion data, including visual odometry and joystick signals, via ROS communication. Future motion is predicted using an autoregressive sparse Gaussian process model. We evaluate the proposed system on real-world short-term path prediction experiments. Experimental results demonstrate the system's efficacy when compared to a baseline neural network model.",https://ieeexplore.ieee.org/document/8460502/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/ICSMC.1997.633274,Learning and reasoning method using fuzzy coloured Petri nets under uncertainty,IEEE,Conferences,"Petri nets have been widely used to model computer systems. Manufacturing systems, robotics systems, knowledge-based systems, and other kinds of engineering applications. Further, to present complex real-world knowledge fuzzy Petri net models have been proposed to perform fuzzy reasoning automatically. However, in Petri nets one has to represent all kinds of processes by separate subnets even though the process has the same behavior as another. Real-world knowledge often contains many parts which are similar, but not identical. This means that the total number of Petri nets becomes very large. Therefore, it becomes difficult to see the similarities and the differences among the individual subnets representing similar parts. The problems may be annoying for a small system, and catastrophic for the description of a large-scale system. To avoid this kind of problem the authors propose a learning and reasoning method using fuzzy coloured Petri nets (FCPN) under uncertainty. For the correction of rules of the knowledge-based system a hand-built classifier and empirical learning method based on domain theory have been proposed as machine learning methods, where there is a significant gap between the knowledge-intensive approach in the former and the virtually knowledge-free approach in the letter. To resolve such problems simultaneously they propose a hybrid learning method which is built on top of the knowledge-based fuzzy coloured Petri net and genetic algorithms.",https://ieeexplore.ieee.org/document/633274/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.23919/ACC.1992.4792313,Learning for Skill Acquisition and Refinement: Toward Exploring Everyday Physics,IEEE,Conferences,"The present talk claims that ""robotics"" is not a test bed for AI but should involve a research frontier, which attempts to account for intelligibility of everyday physics underlying human activities such as perception, remembrance, planning, practices, and skill. In addition to traditional AI and neuro-network approaches, more of new domains that can account for any aspect of human intellectual behaviors must be exploited, and also more of new tools that actualize real implementation of intelligence in machines need to be devised. To aim at going on an expedition in this direction, this talk introduces one new domain and another new tool. The former is practice-based learning for skill refinement and the latter is a design tool of signal-based structured information base for skill acquirement.",https://ieeexplore.ieee.org/document/4792313/,1992 American Control Conference,24-26 June 1992,ieeexplore
10.1109/IROS.1991.174419,Learning for skill refinement,IEEE,Conferences,"It is claimed that 'robotics' is not a test bed for AI but should involve a research frontier relating to the physics underlying human activities such as perception, remembering, planning, practice, and skill. In addition to traditional AI and neural network approaches, other domains that can account for any aspect of human intellectual behavior must be exploited, and tools that actualize real implementation of intelligence in machines need to be devised. A practice-based learning domain for skill refinement and a design tool for a signal-based structured information base for skill acquisition are presented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174419/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ICCIC.2015.7435795,Learning mechanism for RT task scheduling,IEEE,Conferences,"The fascinations of Internet of Things (IoT) necessitate a large number of devices are to be integrated with the existing IoT. These devices are very difficult to manage in a large distributed environment without a careful management design. These location based devices generate data at fixed intervals of time and need configure these devices to software platform to analyze data and understand environment in better way. So, learning capability should incorporate within the system as the environment of system changes dynamically. As the Internet of Things continues to develop, further potential is estimated by a combination with related technology approaches and concepts such as Cloud Computing, Future Internet, Big Data, Robotics and Semantic Technologies. The idea is becomes now evident as those related concepts have started to reveal synergies by combining them.",https://ieeexplore.ieee.org/document/7435795/,2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC),10-12 Dec. 2015,ieeexplore
10.1109/ICIP.2019.8803544,Lightweight Monocular Depth Estimation Model by Joint End-to-End Filter Pruning,IEEE,Conferences,"Convolutional neural networks (CNNs) have emerged as the state-of-the-art in multiple vision tasks including depth estimation. However, memory and computing power requirements remain as challenges to be tackled in these models. Monocular depth estimation has significant use in robotics and virtual reality that requires deployment on low-end devices. Training a small model from scratch results in a significant drop in accuracy and it does not benefit from pre-trained large models. Motivated by the literature of model pruning, we propose a lightweight monocular depth model obtained from a large trained model. This is achieved by removing the least important features with a novel joint end-to-end filter pruning. We propose to learn a binary mask for each filter to decide whether to drop the filter or not. These masks are trained jointly to exploit relations between filters at different layers as well as redundancy within the same layer. We show that we can achieve around 5x compression rate with small drop in accuracy on the KITTI driving dataset. We also show that masking can improve accuracy over the baseline with fewer parameters, even without enforcing compression loss.",https://ieeexplore.ieee.org/document/8803544/,2019 IEEE International Conference on Image Processing (ICIP),22-25 Sept. 2019,ieeexplore
10.1109/CVPRW.2019.00218,Live Demonstration: Digit Recognition on Pixel Processor Arrays,IEEE,Conferences,"In this demo, we will showcase recent work on implementing convolutional neural networks directly on pixel processor arrays (PPA). As CNNs demonstrate enhanced performance across tasks from classification to image synthesis, it becomes essential to find the most adequate ways to realize them especially for embedded, real-time and reactive tasks in areas across Computer Vision and Robotics. The PPA concept is one architecture that pairs sensing and massively parallel processing at the focal plane level and allow mid to high level tasks to be run wholly embedded within them. They allow operation at high framerates and low energy consumption (≤ 2W), and without the need for external signal interpretation or processing. In this demo we will showcase our recent work on the implementation of CNNs on the SCAMP5 architecture [2] as a step towards true end-to-end operation on flexibly programmable PPA hardware. In particular, we will showcase live how our modifications to CNNs allow them to run tasks such as handwritten number classification from image capture to classification wholly embedded on the PPA.",https://ieeexplore.ieee.org/document/9025698/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),16-17 June 2019,ieeexplore
10.1109/DICTA.2015.7371280,Localized Deep Extreme Learning Machines for Efficient RGB-D Object Recognition,IEEE,Conferences,"Existing RGB-D object recognition methods either use channel specific handcrafted features, or learn features with deep networks. The former lack representation ability while the latter require large amounts of training data and learning time. In real-time robotics applications involving RGB-D sensors, we do not have the luxury of both. In this paper, we propose Localized Deep Extreme Learning Machines (LDELM) that efficiently learn features from RGB-D data. By using localized patches, not only is the problem of data sparsity solved, but the learned features are robust to occlusions and viewpoint variations. LDELM learns deep localized features in an unsupervised way from random patches of the training data. Each image is then feed-forwarded, patch-wise, through the LDELM to form a cuboid of features. The cuboid is divided into cells and pooled to get the final compact image representation which is then used to train an ELM classifier. Experiments on the benchmark Washington RGB-D and 2D3D datasets show that the proposed algorithm not only is significantly faster to train but also outperforms state-of-the-art methods in terms of accuracy and classification time.",https://ieeexplore.ieee.org/document/7371280/,2015 International Conference on Digital Image Computing: Techniques and Applications (DICTA),23-25 Nov. 2015,ieeexplore
10.1109/ICM48031.2019.9021904,Low power CNN hardware FPGA implementation,IEEE,Conferences,"A convolution Neural Networks (CNN) goes under the wide umbrella of Deep Neural Networks (DNN) whose applications are widely used. For example, the later are used in robotics and different applications of recognition like speech recognition and facial recognition, also nowadays in autonomous cars. Therefore the aim of implementing the CNN is to be used in real time applications. As a result of that, Graphics processing units (GPUs) are used but their worst disadvantage is it's high power consumption which can't be used in daily used equipments. The target of this paper is to solve the power consumption problem by using Field Programmable Array (FPGA) which has low power consumption, and flexible architecture. The implementation architecture of Alex Network, which consists of three fully connected layers and five convolution layers, on FPGA will depend on two main techniques parallelism of resources, and pipelining inside of some layers.",https://ieeexplore.ieee.org/document/9021904/,2019 31st International Conference on Microelectronics (ICM),15-18 Dec. 2019,ieeexplore
10.1109/CCWC.2017.7868418,"Low-cost, real-time obstacle avoidance for mobile robots",IEEE,Conferences,"The goal of this project<sup>1</sup> is to advance the field of automation and robotics by utilizing recently-released, low-cost sensors and microprocessors to develop a mechanism that provides depth-perception and autonomous obstacle avoidance in a plug-and-play fashion. We describe the essential hardware components that can enable such a low-cost solution and an algorithm to avoid static obstacles present in the environment. The mechanism utilizes a novel single-point LIDAR module that affords more robustness and invariance than popular approaches, such as Neural Networks and Stereo. When this hardware is coupled with the proposed efficient obstacle avoidance algorithm, this mechanism is able to accurately represent environments through point clouds and construct obstacle-free paths to a destination, in a small timeframe. A prototype mechanism has been installed on a quadcopter for visualization on how actual implementation may take place<sup>2</sup>. We describe experimental results based on this prototype.",https://ieeexplore.ieee.org/document/7868418/,2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC),9-11 Jan. 2017,ieeexplore
10.23919/SPA.2019.8936736,Machine Learning for Embodied Agents: From Signals to Symbols and Actions,IEEE,Conferences,"The aim of this tutorial lecture is to show the role of machine learning and some other AI-related techniques in embodied autonomous agents, and autonomous robots in particular. In this tutorial we bring to the forefront the aspects of robotics that are closely related to computer science. We believe that the progress in algorithms and data processing methods together with the rapid increase in the available computing power were the driving forces behind the successes of modern robotics in the last decade. During this period robots of various classes migrated from university laboratories to commercial companies and then to our everyday life, as now everybody can buy an autonomous vacuum cleaner or lawnmower, while self-driving cars and drones for goods delivery are waiting for proper legal regulations to enter the market. Robotics and Artificial Intelligence already went a long path of mutual inspiration and common development, starting from the symbolic AI (aka Good Old-Fashioned Artificial Intelligence) and its extensive use in early autonomous robots, such as Shakey the robot, created in SRI International by Nils Nilsson, considered one of the ""fathers"" of modern AI. We briefly characterize the range of the most important applications of typical AI methods in modern robotics, including motion planning algorithms [2,3], interpretation of sensory data leading to creation of a world model [4 ,5], and classical learning methods, such as reinforcement learning [6]. However, what made robotics a part of the new wave of AI applications was the recent ""revolution"" of machine learning, mostly grounded in the enormous success of the deep learning paradigm and its many variants that proved to outclass classic methods in a broad range of problems related to the processing of images and other types of signals. The quick adoption of the recent advances in Machine Learning (ML) in robotics seems to be motivated by the fact that ML gives the possibility to infer solutions from data, as opposed to the classic model-based paradigm that was for decades used in robotics. Whereas the modelbased solutions are mathematically elegant and theoretically provable (with respect to stability, convergence, etc.) they often fail once confronted with real-world problems and real sensory data, as their underlying mathematical models are only a very rough approximation of the real world. Therefore, a wider adoption of ML in robotics gives a chance to make robots more robust and adaptive. On the other hand, we should try to use the new techniques without discarding the knowledge and expertise we already have - machine learning methods can benefit a lot from the prior knowledge and the known structure of the problem that has to be solved by learning. This knowledge and structure can be adopted from the model-based methods that a re already well-established in robotics. In the lecture robots are understood in a broad sense, as all embodied agents that have means to physically interact with the environment. They can be either manipulators, mobile robots, aerial vehicles, self-driving cars, and various ""smart"" devices and sensors. In the second part of the lecture attention is paid to specific problems that appear in application of machine learning to embodied agents, such as the need to search a for solution in huge, multi-dimensional spaces (""curse of dimensionality""), and the ever-present problem of representation and incorporation of uncertainty in the processing of real-world data. Some examples of applications of autonomous robots are given, which were successful due to the use of AI - in particular the probabilistic representation of knowledge and machine learning. The most prominent examples are the DARPA competitions: ""Grand Challenge"", ""Urban Challenge"" and ""Robotics Challenge"" (DRC), and the ""Amazon Picking Challenge"", which proves the interest of large corporations in the development of AI-based robotics [7]. In the third part of the lecture new research directions offered by machine learning and the increased availability of training data are discussed. An overview of the most popular application areas of ML in robotics and other autonomous systems is presented along with the typical machine learning paradigms applied in these areas. The focus is on deep learning, mostly using convolutional neural networks to process various sensory data. We discuss three aspects of embodied agents that make machine learning in robotics quite specific with respect to other application areas, such as medical images or natural language processing. The first aspect is dealing with the ""open world"", in which autonomous robots usually operate. This situation breaks the assumptions underlying some popular ML methods, and creates the need to face the problem of unknown classes identification [8] incremental learning [9], and the uncertainty of sensory data [10]. We also stress out that an embodied agent has the ability to actively acquire information [11]. The second aspect is the inference about the scene seen by the agent, where in the case of robotics, semantics and geometry intermingle [12], because the robot has to work in a three-dimensional world, although it often perceives it through twodimensional images [13,14]. The third aspect of our analysis is related to the most important feature of robots that distinguishes them from all other learning agents (software-based). Robots are embodied agents, that is they have a physical ""body"", and are subject to physical constraints, such as the maximum speed of motion or maximum range of perception. Therefore, in ML for robots analysis of the spatio-temporal dependencies in data is very important [15]. Robots support advanced learning methods thanks to the possibility of interaction with the environment - a simple example is active vision with moving camera, a much more complex one is manipulation with active testing of the behavior of objects (repositioning, pushing) [16]. At the end of the lecture, in the context of specific needs and limitations characteristic to the applications of ML in robotics, new concepts of machine learning (e.g. deep reinforcement learning [17], interactive perception [18]) are presented. The lecture is summarized with a brief discussion of the most important challenges and open problems of ML applied to embodied agents.",https://ieeexplore.ieee.org/document/8936736/,"2019 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",18-20 Sept. 2019,ieeexplore
10.1109/CVPRW53098.2021.00141,MarkerPose: Robust Real-time Planar Target Tracking for Accurate Stereo Pose Estimation,IEEE,Conferences,"Despite the attention marker-less pose estimation has attracted in recent years, marker-based approaches still provide unbeatable accuracy under controlled environmental conditions. Thus, they are used in many fields such as robotics or biomedical applications but are primarily implemented through classical approaches, which require lots of heuristics and parameter tuning for reliable performance under different environments. In this work, we propose MarkerPose, a robust, real-time pose estimation system based on a planar target of three circles and a stereo vision system. MarkerPose is meant for high-accuracy pose estimation applications. Our method consists of two deep neural networks for marker point detection. A SuperPoint-like network for pixel-level accuracy keypoint localization and classification, and we introduce EllipSegNet, a lightweight ellipse segmentation network for sub-pixel-level accuracy keypoint detection. The marker’s pose is estimated through stereo triangulation. The target point detection is robust to low lighting and motion blur conditions. We compared MarkerPose with a detection method based on classical computer vision techniques using a robotic arm for validation. The results show our method provides better accuracy than the classical technique. Finally, we demonstrate the suitability of MarkerPose in a 3D freehand ultrasound system, which is an application where highly accurate pose estimation is required. Code is available in Python and C++ at https://github.com/jhacsonmeza/MarkerPose.",https://ieeexplore.ieee.org/document/9523117/,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),19-25 June 2021,ieeexplore
10.1109/IECON.2012.6389520,Matlab/Simulink software implementation and interfacing of a strap-down inertial attitude method,IEEE,Conferences,"The paper presents a software tool used to calculate the angular attitude of a vehicle starting from the readings of a strap-down gyro triad. Firstly, the problem statement is presented and the implied mathematical equations are shown. The theoretical model is based on the discretized form of a matrix differential equation solution, and focuses on its first six truncation order. In order to have an easier communication between the user and the software, especially in the off-line data processing applications, a Graphical User Interface is developed. The obtained software is validated by using an integrated INS/GPS navigation system as reference system, the inputs of our software being the outputs of the gyro sensors in the strap-down INS. The tool can be used in all strap-down inertial systems application fields like aerospace, naval and automotive navigation, robotics, as well as in medicine surgery. Also, the developed software can be used in the real time applications or in the off-line processing of the navigation inertial sensors recorded data.",https://ieeexplore.ieee.org/document/6389520/,IECON 2012 - 38th Annual Conference on IEEE Industrial Electronics Society,25-28 Oct. 2012,ieeexplore
10.1109/ICCCI50826.2021.9402304,Maze Solving with humanoid robot NAO using Real-Time object detection,IEEE,Conferences,"In a future that is not too distant from today, humanoids are surely going to be an integral part of both our professional and private lives, assisting us with various tasks. Unlike normal robots that we may encounter in our everyday lives, humanoids are designed in specific manners to give them more human-like capabilities that enable them to perform complex tasks such as climbing a flight of stairs. In this paper, we present a Maze-Solving Algorithm which is a software developed specifically for the humanoid robot, NAO, and gives it the capability to enter and exit a maze autonomously. NAO is a next-gen humanoid bot developed by SoftBank Robotics using the power of AI. The bot is equipped with numerous sensors and cameras. Though various quantitative approaches were considered and experimented with, we stuck onto the one which had the least average time complexity of all after a thorough comparative study. We suggest an approach where the humanoid can detect and localize objects from a distance and take programmable decisions based on them. AI constantly tries to give robots human-thinking capabilities to make their decision-making skills similar to those of humans, if not better than them. This algorithm was developed taking into consideration how a human intellect would react rationally if he is stuck in a maze. The methodology used revolves primarily around the combined use of SONAR(Sound navigation ranging) and tactical sensors, and cameras equipped within the bot. The output values from this hardware were then evaluated to judge the distance from a wall and the reactions from the bot were calculated by the suggested algorithm accordingly.",https://ieeexplore.ieee.org/document/9402304/,2021 International Conference on Computer Communication and Informatics (ICCCI),27-29 Jan. 2021,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/OCEANS.1998.724376,Model development of an underwater manipulator for coordinated arm-vehicle control,IEEE,Conferences,"This paper presents research on the hydrodynamic modeling of a manipulator for an autonomous underwater scientific vehicle. The focus is on improving the modeling accuracy of the in-line hydrodynamic coupling between a two-link manipulator and a small, free-floating vehicle in order to achieve better control for coordinated motion of the combined system. Loads predicted using existing models for underwater arms were determined to be off by as much as 25% when applied to a real, two-link arm in a test tank. In this new approach, an experimentally-determined model has been developed that takes into account the 3D flow effects that have previously not been included. The end result is a model that provides accurate predictions for the joint torques of a two-link arm in a form simple enough to be implemented in algorithms for precision planning and control. This project is part of a joint program between the Aerospace Robotics Laboratory at Stanford University and the Monterey Bay Aquarium Research Institute.",https://ieeexplore.ieee.org/document/724376/,IEEE Oceanic Engineering Society. OCEANS'98. Conference Proceedings (Cat. No.98CH36259),28 Sept.-1 Oct. 1998,ieeexplore
10.1109/ROBOT.1996.503841,Modeling hybrid systems as the limit of discrete computational processes,IEEE,Conferences,This paper outlines a new formalism for hybrid systems in which continuous dynamics are represented as the limit of a discrete computational process. Hybrid systems are systems which are composed of continuous and discrete components. Such systems often arise in robotics where operations in the continuous real world are controlled by a discrete software system. Most existing hybrid formalisms treat their continuous and discrete components as distinct types of process. This new approach brings the two together and provides a platform for the investigation of the transition between continuous change and discrete events.,https://ieeexplore.ieee.org/document/503841/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/IROS45743.2020.9341372,Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer,IEEE,Conferences,"Learning-based approaches often outperform hand-coded algorithmic solutions for many problems in robotics. However, learning long-horizon tasks on real robot hardware can be intractable, and transferring a learned policy from simulation to reality is still extremely challenging. We present a novel approach to model-free reinforcement learning that can leverage existing sub-optimal solutions as an algorithmic prior during training and deployment. During training, our gated fusion approach enables the prior to guide the initial stages of exploration, increasing sample-efficiency and enabling learning from sparse long-horizon reward signals. Importantly, the policy can learn to improve beyond the performance of the sub-optimal prior since the prior's influence is annealed gradually. During deployment, the policy's uncertainty provides a reliable strategy for transferring a simulation-trained policy to the real world by falling back to the prior controller in uncertain states. We show the efficacy of our Multiplicative Controller Fusion approach on the task of robot navigation and demonstrate safe transfer from simulation to the real world without any fine-tuning. The code for this project is made publicly available at https://sites.google.com/view/mcf-nav/home.",https://ieeexplore.ieee.org/document/9341372/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICUAS.2016.7502665,Natural user interfaces for human-drone multi-modal interaction,IEEE,Conferences,"Personal drones are becoming part of every day life. To fully integrate them into society, it is crucial to design safe and intuitive ways to interact with these aerial systems. The recent advances on User-Centered Design (UCD) applied to Natural User Interfaces (NUIs) intend to make use of human innate features, such as speech, gestures and vision to interact with technology in the way humans would with one another. In this paper, a Graphical User Interface (GUI) and several NUI methods are studied and implemented, along with computer vision techniques, in a single software framework for aerial robotics called Aerostack which allows for intuitive and natural human-quadrotor interaction in indoor GPS-denied environments. These strategies include speech, body position, hand gesture and visual marker interactions used to directly command tasks to the drone. The NUIs presented are based on devices like the Leap Motion Controller, microphones and small size monocular on-board cameras which are unnoticeable to the user. Thanks to this UCD perspective, the users can choose the most intuitive and effective type of interaction for their application. Additionally, the strategies proposed allow for multi-modal interaction between multiple users and the drone by being able to integrate several of these interfaces in one single application as is shown in various real flight experiments performed with non-expert users.",https://ieeexplore.ieee.org/document/7502665/,2016 International Conference on Unmanned Aircraft Systems (ICUAS),7-10 June 2016,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/OPTIM.2008.4602496,Neural control based on RBF network implemented on FPGA,IEEE,Conferences,"The RBF radial basis function network is intended especially for hardware implementation and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA has several benefits, with emphasis on parallelism and the real time capabilities. This paper discusses the hardware implementation of the RBF type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor.",https://ieeexplore.ieee.org/document/4602496/,2008 11th International Conference on Optimization of Electrical and Electronic Equipment,22-24 May 2008,ieeexplore
10.1109/ISCAS.1991.176692,Neural implementation of Karmarkar algorithm,IEEE,Conferences,"The Karmarkar algorithm performs a sequence of projective transformations each followed by optimization over an inscribed sphere and then inverse projective transformation. These steps are implemented on the authors' model with two neural-like circuits, one embedded inside the other. The inner circuit finds least square error solutions using the complementary slackness condition. The outer circuit finds a novel interior primal solution using the delta rule by making use of the error in the computation of dual solution. This circuit exhibits potential for applications where real-time optimization is required-as is the case in robotics, satellite guidance, etc.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/176692/,"1991., IEEE International Sympoisum on Circuits and Systems",11-14 June 1991,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/SOFA.2009.5254883,Neurodynamic optimization with its application for model predictive control,IEEE,Conferences,"Summary form only given. Optimization problems arise in a wide variety of scientific and engineering applications. It is computationally challenging when optimization procedures have to be performed in real time to optimize the performance of dynamical systems. For such applications, classical optimization techniques may not be competent due to the problem dimensionality and stringent requirement on computational time. One very promising approach to dynamic optimization is to apply artificial neural networks. Because of the inherent nature of parallel and distributed information processing in neural networks, the convergence rate of the solution process is not decreasing as the size of the problem increases. Neural networks can be implemented physically in designated hardware such as ASICs where optimization is carried out in a truly parallel and distributed manner. This feature is particularly desirable for dynamic optimization in decentralized decision-making situations arising frequently in control and robotics. In this talk, the author presents the historic review and the state of the art of neurodynamic optimization models and selected applications in robotics and control. Specifically, starting from the motivation of neurodynamic optimization, we will review various recurrent neural network models for optimization. Theoretical results about the stability and optimality of the neurodynamic optimization models will be given along with illustrative examples and simulation results. It will be shown that many problems in control systems, such model predictive control, can be readily solved by using the neurodynamic optimization models. Specifically, linear and nonlinear model predictive control based on neurodynamic optimization will be delineated.",https://ieeexplore.ieee.org/document/5254883/,2009 3rd International Workshop on Soft Computing Applications,29 July-1 Aug. 2009,ieeexplore
10.1109/NGCT.2015.7375178,Neuronal Logic gates realization using Vedic mathematics,IEEE,Conferences,"Gates are the fundamental building block of all logic circuits. Artificial neural networks (ANN) have processing capabilities in a parallel architecture, and due to this they are useful in applications like pattern recognition, system identification, prediction problems, robotics, and control problems. Boolean logic realization using artificial neural network is known as Neuronal Logic. Simple and low precision computations are the basic requirements of ANN which can be performed faster. This can be implemented on cheap and low precision hardware. Neural network involves enormous number of multiplication and addition calculations. It has been already proved that multipliers based on Vedic mathematics are faster in speed than the standard multipliers. In this paper, the possibility of hardware realization of neuronal logic gates using Vedic multipliers herein referred to as Vedic neuron has been explored. This is achieved by performing the neural network computations using Vedic mathematics rather than the conventional multiplication process. Basic logic gates like AND, OR and AND-NOT have been studied and its hardware implementation using neural network has been simulated using VHDL. A comparative study was carried out on the computation speed of neuronal logic gates implemented using conventional multipliers as well as neuronal logic gates implemented using Vedic multipliers. The increase in processing speed with Vedic neuron implementation has been observed which can be of use in several real time operations where speed is critical.",https://ieeexplore.ieee.org/document/7375178/,2015 1st International Conference on Next Generation Computing Technologies (NGCT),4-5 Sept. 2015,ieeexplore
10.1109/CNN53494.2021.9580216,Neuropunk revolution and its implementation via real-time neurosimulations and their integrations,IEEE,Conferences,"In this paper I present the perspectives of the “neuropunk revolution” technologies. One could understand the “neuropunk revolution” as the integration of real-time neurosimulations into biological nervous/motor system via neurostimulation or artificial robotic systems via integration with actuators. I see the added value of the real-time neurosimulations as bridge technology for the set of developed technologies: BCI, neuroprosthetics, AI, robotics to provide bio-compatible integration into biological or artificial limbs. Here I present the three types of integration of the “neuropunk revolution” technologies as inbound, outbound and closed-loop in-outbound systems. I see the shift of the perspective how we see now the set of technologies including AI, BCI, neuroprosthetics and robotics due to the proposed concept for example the integration of external to a body simulated part of nervous system back into the biological nervous system or muscles.",https://ieeexplore.ieee.org/document/9580216/,2021 Third International Conference Neurotechnologies and Neurointerfaces (CNN),13-15 Sept. 2021,ieeexplore
10.1109/HUMANOIDS.2018.8625038,NimbRo-OP2X: Adult-Sized Open-Source 3D Printed Humanoid Robot,IEEE,Conferences,"Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreál, Canada, where it won all possible awards in the Humanoid AdultSize class.",https://ieeexplore.ieee.org/document/8625038/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/ICRA.2016.7487351,Object discovery and grasp detection with a shared convolutional neural network,IEEE,Conferences,"Grasp an object from a stack of objects in real-time is still a challenge in robotics. This requires the robot to have the ability of both fast object discovery and grasp detection: a target object should be picked out from the stack first and then a proper grasp configuration is applied to grasp the object. In this paper, we propose a shared convolutional neural network (CNN) which can simultaneously implement these two tasks in real-time. The processing speed of the model is about 100 frames per second on a GPU which largely satisfies the requirement. Meanwhile, we also establish a labeled RGBD dataset which contains scenes of stacked objects for robotic grasping. At last, we demonstrate the implementation of our shared CNN model on a real robotic platform and show that the robot can accurately discover a target object from the stack and successfully grasp it.",https://ieeexplore.ieee.org/document/7487351/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS.2016.7759720,Object identification from few examples by improving the invariance of a Deep Convolutional Neural Network,IEEE,Conferences,"The development of reliable and robust visual recognition systems is a main challenge towards the deployment of autonomous robotic agents in unconstrained environments. Learning to recognize objects requires image representations that are discriminative to relevant information while being invariant to nuisances, such as scaling, rotations, light and background changes, and so forth. Deep Convolutional Neural Networks can learn such representations from large web-collected image datasets and a natural question is how these systems can be best adapted to the robotics context where little supervision is often available. In this work, we investigate different training strategies for deep architectures on a new dataset collected in a real-world robotic setting. In particular we show how deep networks can be tuned to improve invariance and discriminability properties and perform object identification tasks with minimal supervision.",https://ieeexplore.ieee.org/document/7759720/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/ROBIO.2009.4913200,Object orientation recognition based on SIFT and SVM by using stereo camera,IEEE,Conferences,"The goal of this research is to recognize an object and its orientation in space by using stereo camera. The principle of object orientation recognition in this paper was based on the scale invariant feature transform (SIFT) and support vector machine (SVM). SIFT has been successfully implemented on object recognition but it had a problem recognizing the object orientation. For many autonomous robotics applications, such as using a vision-guided industrial robot to grab a product, not only correct object recognition will be needed in this process but also object orientation recognition is required. In this paper we used SVM to recognize object orientation. SVM has been known as a promising method for classification accuracy and its generalization ability. The stereo camera system adopted in this research provided more useful information compared to single camera one. The object orientation recognition technique was implemented on an industrial robot in a real application. The proposed camera system and recognition algorithms were used to recognize a specific object and its orientation and then guide the industrial robot to perform some alignment operations on the object.",https://ieeexplore.ieee.org/document/4913200/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ICTAACS48474.2019.8988124,Online Adversarial Planning in μRTS : A Survey,IEEE,Conferences,"Online planning is an important research area focusing on the problem of real-time decision making, using information extracted from the environment. The aim is to compute, at each decision point, the best decision possible that contributes to the realization of a fixed objective. Relevant application domains include robotics, control engineering and computer games. Real-time strategy (RTS) games pose considerable challenges to artificial intelligence techniques, due to their dynamic, complex and adversarial aspects, where online planning plays a prominent role. They also constitute an ideal research platform and test-bed for online planning. μRTS is an open-source AI research platform that features a minimalistic, yet complete RTS implementation, used by AI researchers for developing and testing intelligent RTS game-playing agents. The unique characteristics of μRTS helped for the emergence of interesting online adversarial planning techniques, dealing with multiple levels of abstraction. This paper presents the major μRTS online planning approaches to date, categorized by the degree of abstraction, in fully and partially observable environments.",https://ieeexplore.ieee.org/document/8988124/,2019 International Conference on Theoretical and Applicative Aspects of Computer Science (ICTAACS),15-16 Dec. 2019,ieeexplore
10.1109/IROS.2017.8202247,Online learning for human classification in 3D LiDAR-based tracking,IEEE,Conferences,"Human detection and tracking are essential aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online learned human classifier matches and in some cases outperforms its offline version.",https://ieeexplore.ieee.org/document/8202247/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/INFOTEH48170.2020.9066274,Ontology-Driven Generation of Interactive 3D Worlds,IEEE,Conferences,"In this paper, the ontology-driven approach to automated generation of interactive 3D applications is presented. The ontologies describing both static and dynamic application properties combined with domain-specific knowledge are leveraged. The approach is evaluated in two case studies: smart city simulator and virtual robotics testbed. The generated output is JavaScript code using Three.js library. According to the achieved results, the adoption of ontologies dramatically speeds up the development time compared to manual process.",https://ieeexplore.ieee.org/document/9066274/,2020 19th International Symposium INFOTEH-JAHORINA (INFOTEH),18-20 March 2020,ieeexplore
10.1109/IJCNN.2014.6889837,Optimising the overall power usage on the SpiNNaker neuromimetic platform,IEEE,Conferences,"Simulations of biological tissue have been extensively used to replicate phenomena observed by in-vivo and in-vitro experiments as an alternative methodology for explaining how computations could take place in a brain region. Additional benefits of simulated neural networks over in-vivo experiments include greater observability, experimental control and reproducibility. General-purpose supercomputers provide the computational power and parallelism required to implement highly complex neural models, but this comes at the expense of high power requirements and communication overheads. Moreover, there are certain cases where real-time simulation performance is a desirable feature, for example in the field of cognitive robotics where embodied agents need to interact with their environment through biologically inspired asynchronous sensors. The SpiNNaker neuromimetic platform is a scalable architecture that has been designed to enable energy-efficient, large-scale simulations of spiking neurons in biological realtime. This work is based on a recent study which revealed that while they are generally energy efficient, SpiNNaker chips dissipate significant amount of power whilst in the idle state. In this paper we perform a systematic investigation into the overall energy consumption of a SpiNNaker system and propose a number of optimised suspend modes in order to reduce this. The proposed implementation is 60% more energy efficient in the idle state, 50% in the uploading and 52% in the downloading phases, while the power dissipation of the whole simulation is reduced by 52%. For demonstration purposes, we run a neural network simulation comprising thousands of neurons and millions of complex synapses on a 48-chip SpiNNaker board, generating millions of synaptic events per second.",https://ieeexplore.ieee.org/document/6889837/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/FormaliSE.2019.00012,Parallelizable Reachability Analysis Algorithms for Feed-Forward Neural Networks,IEEE,Conferences,"Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",https://ieeexplore.ieee.org/document/8807491/,2019 IEEE/ACM 7th International Conference on Formal Methods in Software Engineering (FormaliSE),27-27 May 2019,ieeexplore
10.1109/CRV52889.2021.00019,PathBench: A Benchmarking Platform for Classical and Learned Path Planning Algorithms,IEEE,Conferences,"Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Operating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source <sup>1</sup>.",https://ieeexplore.ieee.org/document/9469507/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/FPA.1994.636094,Perception systems implemented in analog VLSI for real-time applications,IEEE,Conferences,"We point out that analog VLSI can now be considered as the ideal medium to implement computational systems intended to carry out real time perceptive or even cognitive tasks that are not well handled by traditional computers. By exploiting the analog features of the transistors, only a few devices are needed to realise most of the elementary functions required to implement perceptive systems, resulting in very dense, sophisticated circuits and low power consumption. Elementary artificial retinas in silicon based on their biological counterparts have already been successfully used in industrial applications. Artificial cochleas and noses are also under development. This new enabling technology is of great interest over a wide range of industrial sectors, including robotics, automotive, surveillance and food industry.",https://ieeexplore.ieee.org/document/636094/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/GloSIC.2018.8570124,Probabilistic Estimations of Increasing Expected Reliability and Safety for Intelligent Manufacturing,IEEE,Conferences,"In the near future the possibilities of the modern probabilistic models, artificial intelligence and machine learning methods can provide an intelligent support of making decisions by an operator in real time. An agile recovery of intelligent manufacturing integrity can be implemented owing to the development of industrial robotics. For intelligent manufacturing it means the expected reliability and safety may be in the near future at the expense of intelligent support of decision making and the agile recovery of integrity. To answer the question “How much essential may be this increasing?” here are proposed: general analytical approaches for a probabilistic estimation of the expected reliability and safety for every monitored element or the system of intelligent manufacturing on a level of probability distribution functions (PDF) of the time between the losses of system integrity; estimations of increasing the expected reliability and safety for intelligent manufacturing at the expense of the intelligent support of decision making and agile recovery of integrity; the comparisons of the estimations on a prognostic period up to 10 years using the identical model in applications to expected reliability and safety. The applications of the proposed approaches allow the customers, designers, developers, users and experts of Industry 4.0 intelligent manufacturing to be guided by the proposed probabilistic estimations for solving problems of reliability and safety in the system life cycle. The results are demonstrated by examples.",https://ieeexplore.ieee.org/document/8570124/,2018 Global Smart Industry Conference (GloSIC),13-15 Nov. 2018,ieeexplore
10.1109/ICRC.2016.7738697,Processor-in-memory support for artificial neural networks,IEEE,Conferences,"Hardware acceleration of artificial neural network (ANN) processing has potential for supporting applications benefiting from real time and low power operation, such as autonomous vehicles, robotics, recognition and data mining. Most interest in ANNs targets acceleration of deep multi-layered ANNs that can require days of offline training to converge on a desired network behavior. Interest has grown in ANNs capable of supporting unsupervised training, where networks can learn new information from unlabeled data dynamically without the need for offline training. These ANNs require large memories with bandwidths much higher than supported in modern GPGPUs. Custom hardware acceleration and memory co-design holds the potential to provide real-time performance in cases where the performance requirements cannot be met by modern GPGPUs. This work presents a custom processor solution to accelerate two hetero-associative memories (Sparsey and HTM) capable of unsupervised and one-hot learning. This custom processor is implemented as an expandable ASIP built upon a configurable SIMD engine for exploiting parallelism. Functional specialization is implemented utilizing processor-in-memory techniques, which results in up to a 20× speedup and a 2000× reduction in energy per frame compared to a software implementation operating on a dataset for recognition of human actions.",https://ieeexplore.ieee.org/document/7738697/,2016 IEEE International Conference on Rebooting Computing (ICRC),17-19 Oct. 2016,ieeexplore
10.1109/ICRoM.2015.7367861,ReMoRo; A mobile robot platform based on distributed I/O modules for research and education,IEEE,Conferences,"We present our recent work on the electrical and hardware design of the mobile robot platform ReMoRo that is based on distributed input/output modules. We have designed three generation of this platform with different specifications, which it help us to design more compatible and applied mobile robot. Nevertheless, the goal of this project was to develop a low-cost and robust but extensible modular robot platform for research and educational purposes. In this paper we describe a new affordable robot structure that enables large-scale innovative, new curriculum, multi robot research and multi-robotics outreach to computer and artificial intelligent students. We introduce the ReMoRo platform, which offers a balance between capabilities, accessibility, cost and an opendesign. All of electrical devices like sensors module, motor drivers and device communication manager are designed based on ARM Cortex M3 microcontrollers that runs under Real-Time Operating System (freeRTOS) for manages each modules internal scheduling and activation control in communication bus. With a range of different sensors, cylindrical manipulator and omnidirectional locomotion system, RoMeRo can interact with environment in multiple ways, handle common objects and therefore be used in various service robot scenarios like warehouse robots or multi agent mobile robots. We demonstrate the usability of our concept by quantifying the object-handling task and also briefly describe the software design based on ROS framework for educational usage.",https://ieeexplore.ieee.org/document/7367861/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/ICRA48506.2021.9562075,Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy,IEEE,Conferences,"We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",https://ieeexplore.ieee.org/document/9562075/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/TENCON.1991.753906,Real Time Video Frame Grabber,IEEE,Conferences,Computer vision forms one of the most fascinating and rapidly developing fields of Artificial Intelligence with major applications in areas like Robotics and Image Processing.,https://ieeexplore.ieee.org/document/753906/,"TENCON '91. Region 10 International Conference on EC3-Energy, Computer, Communication and Control Systems",28-30 Aug. 1991,ieeexplore
10.1109/ICCCE.2008.4580693,Real time implementation of NARMA L2 feedback linearization and smoothed NARMA L2 controls of a single link manipulator,IEEE,Conferences,"Robotics is a field of modern technology which requires knowledge in vast areas such as electrical engineering, mechanical engineering, computer science as well as finance. Nonlinearities and parametric uncertainties are unavoidable problems faced in controlling robots in industrial plants. Tracking control of a single link manipulator driven by a permanent magnet brushed DC motor is a nonlinear dynamics due to effects of gravitational force, mass of the payload, posture of the manipulator and viscous friction coefficient. Furthermore uncertainties arise because of changes of the rotor resistance with temperature and random variations of friction while operating. Due to this fact classical PID controller can not be used effectively since it is developed based on linear system theory. Neural network control schemes for manipulator control problem have been proposed by researchers; in which their competency is validated through simulation studies. On the other hand, actual real time applications are rarely established. Instead of simulation studies, this paper is aimed to implement neural network controller in real time for controlling a DC motor driven single link manipulator. The work presented in this paper is concentrating on neural NARMA L2 control and its improvement called to as Smoothed NARMA L2 control. As proposed by K. S Narendra and Mukhopadhyay, Narma L2 control is one of the popular neural network architectures for prediction and control. The real time experimentation showed that the Smoothed NARMA L2 is effective for controlling the single link manipulator for both point-to-point and continuous path motion control.",https://ieeexplore.ieee.org/document/4580693/,2008 International Conference on Computer and Communication Engineering,13-15 May 2008,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/ICTAI.2008.143,Real-Time Classification of Streaming Sensor Data,IEEE,Conferences,"The last decade has seen a huge interest in classification of time series. Most of this work assumes that the data resides in main memory and is processed offline. However, recent advances in sensor technologies require resource-efficient algorithms that can be implemented directly on the sensors as real-time algorithms. We show how a recently introduced framework for time series classification, time series bitmaps, can be implemented as efficient classifiers which can be updated in constant time and space in the face of very high data arrival rates. We describe results from a case study of an important entomological problem, and further demonstrate the generality of our ideas with an example from robotics.",https://ieeexplore.ieee.org/document/4669683/,2008 20th IEEE International Conference on Tools with Artificial Intelligence,3-5 Nov. 2008,ieeexplore
10.1109/ICRA.2019.8794220,Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations,IEEE,Conferences,"Deployment of deep learning models in robotics as sensory information extractors can be a daunting task to handle, even using generic GPU cards. Here, we address three of its most prominent hurdles, namely, i) the adaptation of a single model to perform multiple tasks at once (in this work, we consider depth estimation and semantic segmentation crucial for acquiring geometric and semantic understanding of the scene), while ii) doing it in real-time, and iii) using asymmetric datasets with uneven numbers of annotations per each modality. To overcome the first two issues, we adapt a recently proposed real-time semantic segmentation network, making changes to further reduce the number of floating point operations. To approach the third issue, we embrace a simple solution based on hard knowledge distillation under the assumption of having access to a powerful `teacher' network. We showcase how our system can be easily extended to handle more tasks, and more datasets, all at once, performing depth estimation and segmentation both indoors and outdoors with a single model. Quantitatively, we achieve results equivalent to (or better than) current state-of-the-art approaches with one forward pass costing just 13ms and 6.5 GFLOPs on 640×480 inputs. This efficiency allows us to directly incorporate the raw predictions of our network into the SemanticFusion framework [1] for dense 3D semantic reconstruction of the scene.",https://ieeexplore.ieee.org/document/8794220/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS45743.2020.9341473,Real-World Human-Robot Collaborative Reinforcement Learning,IEEE,Conferences,"The intuitive collaboration of humans and intelligent robots (embodied AI) in the real-world is an essential objective for many desirable applications of robotics. Whilst there is much research regarding explicit communication, we focus on how humans and robots interact implicitly, on motor adaptation level. We present a real-world setup of a human-robot collaborative maze game, designed to be non-trivial and only solvable through collaboration, by limiting the actions to rotations of two orthogonal axes, and assigning each axes to one player. This results in neither the human nor the agent being able to solve the game on their own. We use deep reinforcement learning for the control of the robotic agent, and achieve results within 30 minutes of real-world play, without any type of pre-training. We then use this setup to perform systematic experiments on human/agent behaviour and adaptation when co-learning a policy for the collaborative game. We present results on how co-policy learning occurs over time between the human and the robotic agent resulting in each participant's agent serving as a representation of how they would play the game. This allows us to relate a person's success when playing with different agents than their own, by comparing the policy of the agent with that of their own agent.",https://ieeexplore.ieee.org/document/9341473/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ECMR.2019.8870936,Real-time Vision-based Depth Reconstruction with NVidia Jetson,IEEE,Conferences,"Vision-based depth reconstruction is a challenging problem extensively studied in computer vision but still lacking universal solution. Reconstructing depth from single image is particularly valuable to mobile robotics as it can be embedded to the modern vision-based simultaneous localization and mapping (vSLAM) methods providing them with the metric information needed to construct accurate maps in real scale. Typically, depth reconstruction is done nowadays via fully-convolutional neural networks (FCNNs). In this work we experiment with several FCNN architectures and introduce a few enhancements aimed at increasing both the effectiveness and the efficiency of the inference. We experimentally determine the solution that provides the best performance/accuracy tradeoff and is able to run on NVidia Jetson with the framerates exceeding 16FPS for 320 × 240 input. We also evaluate the suggested models by conducting monocular vSLAM of unknown indoor environment on NVidia Jetson TX2 in real-time. Open-source implementation of the models and the inference node for Robot Operating System (ROS) are available at https://github.com/CnnDepth/tx2_fcnn_node.",https://ieeexplore.ieee.org/document/8870936/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/EFTA.2007.4416888,Real-time architecture for mobile assistant robots,IEEE,Conferences,"Mobile robotics is a challenging research area, with produced results that were unthinkable several years ago. There exist algorithms and methods capable of performing difficult tasks such as detect/classify objects, skill learning and SLAM. From the initial design steps, the real-time software architecture of a robotic platform requires great attention. The problem is difficult, because various components, such as sensing, perception, localization, and motor control, are required to operate and interact in real-time. This makes the system a very complex one. This paper presents a real-time control architecture designed for mobile robots and intelligent vehicles. Moreover, an example of application of the control structure consisting on a system for learning to classify places, using laser range data, is reported.",https://ieeexplore.ieee.org/document/4416888/,2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007),25-28 Sept. 2007,ieeexplore
10.1109/RTOSS.1994.292553,Real-time platforms and environments for time constrained flexible manufacturing,IEEE,Conferences,"The Spring Kernel and associated algorithms, languages, and tools provide system support for static or dynamic real-time applications that require predictable operation. Spring currently consists of two major parts: (1) the development environment, where application and target systems are described, preprocessed and downloaded, and (2) the run-time environment, where the operating system, the Spring Kernel, creates and ensures predictable executions of application tasks. We have integrated our real-time systems technology with component technologies from robotics, computer vision, and real-time artificial intelligence, to develop a test platform for flexible manufacturing. The results being produced are generic so that they should be in many other real-time applications such as air traffic control and chemical plants. We describe this platform, identify new features developed, and comment on some lessons learned to date from this experiment.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292553/,Proceedings of 11th IEEE Workshop on Real-Time Operating Systems and Software,18-19 May 1994,ieeexplore
10.1109/CEC.1999.781948,Realization of robust controllers in evolutionary robotics: a dynamically-rearranging neural network approach,IEEE,Conferences,"The evolutionary robotics approach has been attracting a lot of attention in the field of robotics and artificial life. In this approach, neural networks are widely used to construct controllers for autonomous mobile agents, since they intrinsically have generalization, noise-tolerant abilities and so on. However, there are still open questions: (1) the gap between simulated and real environments, (2) the evolutionary and learning phase are completely separated, and (3) the conflict between stability and evolvability/adaptability. In this paper, we try to overcome these problems by incorporating the concept of dynamic rearrangement function of biological neural networks with the use of neuromodulators. Simulation results show that the proposed approach is highly promising.",https://ieeexplore.ieee.org/document/781948/,Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406),6-9 July 1999,ieeexplore
10.1109/ICCCT.2010.5640434,Recognizing &amp; interpreting Indian Sign Language gesture for Human Robot Interaction,IEEE,Conferences,"This paper describes a novel approach towards recognizing of Indian Sign Language (ISL) gestures for Humanoid Robot Interaction (HRI). An extensive approach is being introduced for classification of ISL gesture which imparts an elegant way of interaction between humanoid robot HOAP-2 and human being. ISL gestures are being considered as a communicating agent for humanoid robot which is being used in this context explicitly. It involves different image processing techniques followed by a generic algorithm for feature extraction process. The classification technique deals with the Euclidean distance metric. The concrete HRI system has been established for initiation based learning mechanism. The Real time robotics simulation software, WEBOTS has been adopted to simulate the classified ISL gestures on HOAP-2 robot. The JAVA based software has been developed to deal with the entire HRI process.",https://ieeexplore.ieee.org/document/5640434/,2010 International Conference on Computer and Communication Technology (ICCCT),17-19 Sept. 2010,ieeexplore
10.1109/SNPD.2017.8022704,Recovering camera motion from points and lines in stereo images: A recursive model-less approach using trifocal tensors,IEEE,Conferences,"Estimating the 3-D motion of a moving camera from images is a common task in robotics and augmented reality. Most existing marker-less approaches make use of either points or lines. Taking the advantages of both kinds of features in an unknown environment is more attractive due to their availability and differences in characteristics. A novel model-less method is presented in this paper to tackle the 3-D motion tracking problem. Two Bayesian filters, one for point measurements while another for line measurements, are embedded in the Interacting Probabilistic Switching (IPS) framework. They compensate for the weaknesses in one another by utilizing both kinds of features in the stereo images. The proposed method is able to obtain the 3D motion given as little as two line or two point correspondences in consecutive images with the use of multiple trifocal tensors. Our method outperformed two recent methods in terms of accuracy and the problem of drifting was very little in real scenarios.",https://ieeexplore.ieee.org/document/8022704/,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",26-28 June 2017,ieeexplore
10.1109/ICARM52023.2021.9536145,Reducing the Dimension of the Configuration Space with Self Organizing Neural Networks,IEEE,Conferences,"For robotics, especially industrial applications, it is crucial to reactively plan safe motions through efficient algorithms. Planning is more powerful in the configuration space than the task space. However, for robots with many degrees of freedom, this is challenging and computationally expensive. Sophisticated techniques for motion planning such as the Wavefront algorithm are limited by the high dimensionality of the configuration space, especially for robots with many degrees of freedom. For a neural implementation of the Wavefront algorithm in the configuration space, neurons represent discrete configurations and synapses are used for path planning. In order to decrease the complexity, we reduce the search space by pruning superfluous neurons and synapses. We present different models of self-organizing neural networks for this reduction. The approach takes real-life human motion data as input and creates a representation with reduced dimension. We compare six different neural network models and adapt the Wavefront algorithm to the different structures of the reduced output spaces. The method is backed up by an extensive evaluation of the reduced spaces, including their suitability for path planning by the Wavefront algorithm.",https://ieeexplore.ieee.org/document/9536145/,2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2021,ieeexplore
10.1109/DIS.2006.63,Remote Programming of Multirobot Systems within the UPC-UJI Telelaboratories: System Architecture and Agent-Based Multirobot Control,IEEE,Conferences,"One of the areas that needs more improvement within the e-learning environments via Internet (in fact they suppose a very big effort to be accomplished) is allowing students to access and practice real experiments is a real laboratory, instead of using simulations in Marin, R. et al. (2003). Real laboratories allow students to acquire methods, skills and experience related to real equipment, in a manner that is very close to the way they are being used in industry. The purpose of the project is the study, development and implementation of an e-learning environment to allow undergraduate students to practice subjects related to Robotics and Artificial Intelligence. The system, which is now at a preliminary stage, will allow the remote experimentation with real robotic devices (i.e. robots, cameras, etc.). It will enable the student to learn in a collaborative manner (remote participation with other students) where it will be possible to combine the on-site activities (performed ""in-situ"" within the real lab during the normal practical sessions), with the ""online"" one (performed remotely from home via the Internet). Moreover, the remote experiments within the e-laboratory to control the real robots can be performed by both, students and even scientist. This project is under development and it is carried out jointly by two Universities (UPC and UJI). In this article we present the system architecture and the way students and researchers have been able to perform a remote programming of multirobot systems via Web",https://ieeexplore.ieee.org/document/1633445/,IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence and Its Applications (DIS'06),15-16 June 2006,ieeexplore
10.1109/IROS.1997.656813,RoboCup as a research program,IEEE,Conferences,"An overview of RoboCup (The World Cup Robot Soccer), which offers opportunities for AI and robotics research by providing an attractive but formidable challenge. It also provides a range of challenge programs which is designed to evaluate specific technical issues. The challenge program will be up-dated and new challenges will be offered as technology progresses. Along with other programs such as an education program, RoboCup offers a comprehensive research program which promotes AI and robotics.",https://ieeexplore.ieee.org/document/656813/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBOT.2001.933270,Robotic Antarctic meteorite search: outcomes,IEEE,Conferences,"Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",https://ieeexplore.ieee.org/document/933270/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/IROS.2015.7354310,Robotic agents capable of natural and safe physical interaction with human co-workers,IEEE,Conferences,"Many future application scenarios of robotics envision robotic agents to be in close physical interaction with humans: On the factory floor, robotic agents shall support their human co-workers with the dull and health threatening parts of their jobs. In their homes, robotic agents shall enable people to stay independent, even if they have disabilities that require physical help in their daily life - a pressing need for our aging societies. A key requirement for such robotic agents is that they are safety-aware, that is, that they know when actions may hurt or threaten humans and actively refrain from performing them. Safe robot control systems are a current research focus in control theory. The control system designs, however, are a bit paranoid: programmers build “software fences” around people, effectively preventing physical interactions. To physically interact in a competent manner robotic agents have to reason about the task context, the human, and her intentions. In this paper, we propose to extend cognition-enabled robot control by introducing humans, physical interaction events, and safe movements as first class objects into the plan language. We show the power of the safety-aware control approach in a real-world scenario with a leading-edge autonomous manipulation platform. Finally, we share our experimental recordings through an online knowledge processing system, and invite the reader to explore the data with queries based on the concepts discussed in this paper.",https://ieeexplore.ieee.org/document/7354310/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/ICIS.2017.7959982,Robotics data real-time management based on NoSQL solution,IEEE,Conferences,"In nowadays, robotics database management systems are increasing. These systems ensure good storage of data and with big data analytic, a new approach demands new structures and methods for collecting, recording, and analyzing enterprise data. This paper work deals with the NoSQL databases which are the secret of the continual progression data that new data management solutions have been emerged. They crossed several areas as personalization, profile management, big data in real-time, content management, catalogue, view of customers, mobile applications, internet of things, digital communication and fraud detection. Machine learning, for example, thrives on more data, so smart machines can learn more and faster, the Robotics are our use of case to focus on our Test. The implementation of NoSQL for Robotics wrestle all the data they acquire into usable form because with the ordinary type of Robotics we are facing very big limits to manage and find the exact information in real-time. Our original proposed approach was demonstrated by experimental studies and running example used as a use case.",https://ieeexplore.ieee.org/document/7959982/,2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS),24-26 May 2017,ieeexplore
10.1109/ICRA.2013.6631400,Robust real-time visual odometry for dense RGB-D mapping,IEEE,Conferences,"This paper describes extensions to the Kintinuous [1] algorithm for spatially extended KinectFusion, incorporating the following additions: (i) the integration of multiple 6DOF camera odometry estimation methods for robust tracking; (ii) a novel GPU-based implementation of an existing dense RGB-D visual odometry algorithm; (iii) advanced fused realtime surface coloring. These extensions are validated with extensive experimental results, both quantitative and qualitative, demonstrating the ability to build dense fully colored models of spatially extended environments for robotics and virtual reality applications while remaining robust against scenes with challenging sets of geometric and visual features.",https://ieeexplore.ieee.org/document/6631400/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBOT.2009.5152197,Robust servo-control for underwater robots using banks of visual filters,IEEE,Conferences,"We present an application of machine learning to the semi-automatic synthesis of robust servo-trackers for underwater robotics. In particular, we investigate an approach based on the use of Boosting for robust visual tracking of color objects in an underwater environment. To this end, we use AdaBoost, the most common variant of the Boosting algorithm, to select a number of low-complexity but moderately accurate color feature trackers and we combine their outputs. The novelty of our approach lies in the design of this family of weak trackers, which enhances a straightforward color segmentation tracker in multiple ways. From a large and diverse family of possible filters, we select a small subset that optimizes the performance of our trackers. The tracking process applies these trackers on the input video frames, and the final tracker output is chosen based on the weights of the final array of trackers. By using computationally inexpensive, but somewhat accurate trackers as members of the ensemble, the system is able to run at quasi real-time, and thus, is deployable on-board our underwater robot. We present quantitative cross-validation results of our spatio-chromatic visual tracker, and conclude by pointing out some difficulties faced and subsequent shortcomings in the experiments we performed, along with directions of future research in the area of ensemble tracking in real-time.",https://ieeexplore.ieee.org/document/5152197/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/DSN.2019.00027,SOTER: A Runtime Assurance Framework for Programming Safe Robotics Systems,IEEE,Conferences,"The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third-party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software, and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",https://ieeexplore.ieee.org/document/8809550/,2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),24-27 June 2019,ieeexplore
10.1109/RTAS.2018.00028,S^3DNN: Supervised Streaming and Scheduling for GPU-Accelerated Real-Time DNN Workloads,IEEE,Conferences,"Deep Neural Networks (DNNs) are being widely applied in many advanced embedded systems that require autonomous decision making, e.g., autonomous driving and robotics. To handle resource-demanding DNN workloads, graphic processing units (GPUs) have been used as the main acceleration engine. Although much research has been conducted to algorithmically optimize the efficiency of applying DNN to applications such as object recognition, limited attention has been given to optimizing the execution of GPU-accelerated DNN workloads at the system level. In this paper, we propose S^3DNN, a system solution that optimizes the execution of DNN workloads on GPU in a real-time multi-tasking environment, which simultaneously optimizes the two (sometimes) conflicting goals of real-time correctness and throughput. S^3DNN contains a governor that selectively gathers system-wide DNN requests to perform smart data fusion, and a novel supervised streaming and scheduling framework that combines a deadline-aware scheduler with the concurrency-enabled CUDA stream technique. To simultaneously maximize concurrency-induced benefits and real-time performance, S^3DNN explores a rather interesting and unique characteristic of DNN workloads, where multiple layers of a DNN instance often exhibit a gradually decreased GPU resource utilization pattern. We have fully implemented S^3DNN in a GPU-accelerated system and have conducted extensive sets of experiments evaluating the efficacy of S^3DNN under a wide range of system and workload scenarios. The results show that S^3DNN significantly improves upon state-of-the-art GPU-accelerated DNN processing frameworks, e.g., up to 37% and over 40% improvements in real-time performance and throughput, respectively.",https://ieeexplore.ieee.org/document/8430082/,2018 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS),11-13 April 2018,ieeexplore
10.1109/FCCM48280.2020.00067,Scalable Full Hardware Logic Architecture for Gradient Boosted Tree Training,IEEE,Conferences,"Gradient Boosted Tree is most effective and standard machine learning algorithm in many fields especially with various type of tabular dataset. Besides, recent industry field and robotics field require high-speed, power efficient and real-time training with enormous data. FPGA is effective device which enable custom domain specific approach to give acceleration as well as power efficiency. We introduce a scalable full hardware implementation of Gradient Boosted Tree training with high performance and flexibility of hyper parameterization. Experimental work shows that our hardware implementation achieved 11-33 times faster than state-of-art GPU acceleration even with small gates and low power FPGA device.",https://ieeexplore.ieee.org/document/9114741/,2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),3-6 May 2020,ieeexplore
10.1109/EMWRTS.1995.514298,Scheduling algorithms for improving the response in intelligent real-time environments,IEEE,Conferences,"Over the last few years, the usefulness and maturity of artificial intelligence technologies, and in particular of knowledge-based systems, have been demonstrated by the ever growing number of commercial applications using them. In the domain of real-time control systems (process control, avionics, robotics, ...), these techniques have been considered with a renewed interest, as they appear as a promising approach to cope with the increasing complexity of the systems to be controlled. The integration of nonpredictable methods in real time systems is one of the crucial points. A task model allowing the representation of activities with optional parts and several scheduling algorithms to incorporate them into real time systems is described.",https://ieeexplore.ieee.org/document/514298/,Proceedings Seventh Euromicro Workshop on Real-Time Systems,14-16 June 1995,ieeexplore
10.1109/URAI.2016.7734049,Secure robotics,IEEE,Conferences,"Security is an under-studied problem within robotics and Internet of Things. Part of the reason for this is that currently most robots and IoT devices remain in the lab at all times. Recent trends show more robots and IoT devices moving “out into the wild” with no humans to protect them. This creates vulnerabilities beyond the well known and well studied network/internet based threat. These threats include external network, local network, software, physical access, tricking the artificial intelligence, and intellectual property theft. This document discribes the above and shows our current work towards detection and mitigation.",https://ieeexplore.ieee.org/document/7734049/,2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),19-22 Aug. 2016,ieeexplore
10.1109/ICNNB.2005.1614810,Security Assurance Using Face Recognition &amp; Detection System Based On Neural Networks,IEEE,Conferences,"In this paper, we have proposed a new method of implementing an assurance system using the facial information of the people, this is a different approach to the conventional security system which uses biometric information or cryptography for assurance, here we use an efficient self-scaling face recognition system supported with a face detection system, the system is capable enough to extract the human faces from a real time video and to recognize the people using a face recognition system, we are designing the framework for face recognition system with a hybrid RBF neural network, the real advantage of the system lies in its capability to inculcate some basic features of the self organizing map (SOM) so that the system can scale on its own and it doesn't get outdated with time, for the face detection system we use a content based face detection algorithm, the facial feature so detected is inputted into the face recognition system, if the person's information is already present in the system, authentication can be accomplished, this system can be used in public places like airports and supermarkets, the information of criminals can be stored in the system and in case any of the criminals are detected by the system, the security personnel can be signaled, this system can also be implemented in robotics, the system can help the computer to identify individual users distinctly, our facial recognition system has been tested and found to be persistent in recognizing the individual even if the input facial image is of different gesture or holds some extra lineament like beard, moustache or spectacles so we can definitely state that the system is reliable and efficient",https://ieeexplore.ieee.org/document/1614810/,2005 International Conference on Neural Networks and Brain,13-15 Oct. 2005,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN.2016.7727359,Self-repairing mobile robotic car using astrocyte-neuron networks,IEEE,Conferences,"A self-repairing robot utilising a spiking astrocyte-neuron network is presented in this paper. It uses the output spike frequency of neurons to control the motor speed and robot activation. A software model of the astrocyte-neuron network previously demonstrated self-detection of faults and its self-repairing capability. In this paper the application demonstrator of mobile robotics is employed to evaluate the fault-tolerant capabilities of the astrocyte-neuron network when implemented in a hardware-based robotic car system. Results demonstrated that when 20% or less synapses associated with a neuron are faulty, the robot car can maintain system performance and complete the task of forward motion correctly. If 80% synapses are faulty, the system performance shows a marginal degradation, however this degradation is much smaller than that of conventional fault-tolerant techniques under the same levels of faults. This is the first time that astrocyte cells merged within spiking neurons demonstrates a self-repairing capabilities in the hardware system for a real application.",https://ieeexplore.ieee.org/document/7727359/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/ICRA.2019.8793595,Semi Supervised Deep Quick Instance Detection and Segmentation,IEEE,Conferences,"In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd rd, 4th and 5 th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC'17 where novel features such as instance detection and online learning has been added.",https://ieeexplore.ieee.org/document/8793595/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/RO-MAN50785.2021.9515358,Sequential Prediction with Logic Constraints for Surgical Robotic Activity Recognition,IEEE,Conferences,"Many real-world time-sensitive and high-stake applications (e.g., surgical, rescue, and recovery robotics) exhibit sequential nature; thus, applying Recurrent Neural Network (RNN)-based sequential models is an attractive approach to detect robotic activity. One limitation of such approaches is data scarcity. As a result, limited training samples may lead to over-fitting, producing incorrect predictions during deployment. Nevertheless, abundant domain knowledge may still be available, which may help formulate logic constraints. In this paper, we propose a novel way to integrate domain knowledge into RNN-based sequential prediction. We build a Markov Logic Network (MLN)-based classifier that automatically learns constraint weights from data. We propose two methods to incorporate this MLN-based prediction: (i) PriorLayer, in which the values of the hidden layer of the RNN are combined with weights learned from logic constraints in an additional neural network layer, and (ii) Conflation, in which class probabilities from RNN predictions and constraint weights are combined based on the conflation of class probabilities. We evaluate robotic activity classification methods on a simulated OpenAI Gym environment and a real-world DESK dataset for surgical robotics. We observe that our proposed MLN-based approaches boost the performance of LSTM-based networks. In particular, MLN boosts the accuracy of LSTM from 71% to 84% on the Gym dataset and from 68% to 72% on the Taurus robot dataset. Furthermore, MLN (i.e., PriorLayer) shows regularization capability where it improves accuracy in initial LSTM training while avoiding over-fitting early, thus improves the final classification accuracy on unseen data. The code is available at https://github.com/masud99r/prediction-with-logic-constraints.",https://ieeexplore.ieee.org/document/9515358/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ITSC.2018.8569569,ShadowCam: Real-Time Detection of Moving Obstacles Behind A Corner For Autonomous Vehicles,IEEE,Conferences,"Moving obstacles occluded by corners are a potential source for collisions in mobile robotics applications such as autonomous vehicles. In this paper, we address the problem of anticipating such collisions by proposing a vision-based detection algorithm for obstacles which are outside of a vehicle's direct line of sight. Our method detects shadows of obstacles hidden around corners and automatically classifies these unseen obstacles as “dynamic” or “static”. We evaluate our proposed detection algorithm on real-world corners and a large variety of simulated environments to assess generalizability in different challenging surface and lighting conditions. The mean classification accuracy on simulated data is around 80% and on real-world corners approximately 70%. Additionally, we integrate our detection system on a full-scale autonomous wheelchair and demonstrate its feasibility as an additional safety mechanism through real-world experiments. We release our real-time-capable implementation of the proposed ShadowCam algorithm and the dataset containing simulated and real-world data under an open-source license.",https://ieeexplore.ieee.org/document/8569569/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/DICTA.2018.8615804,Similar Gesture Recognition using Hierarchical Classification Approach in RGB Videos,IEEE,Conferences,"Recognizing human actions from the video streams has become one of the very popular research areas in computer vision and deep learning in the recent years. Action recognition is wildly used in different scenarios in real life, such as surveillance, robotics, healthcare, video indexing and human-computer interaction. The challenges and complexity involved in developing a video-based human action recognition system are manifold. In particular, recognizing actions with similar gestures and describing complex actions is a very challenging problem. To address these issues, we study the problem of classifying human actions using Convolutional Neural Networks (CNN) and develop a hierarchical 3DCNN architecture for similar gesture recognition. The proposed model firstly combines similar gesture pairs into one class, and classify them along with all other class, as a stage-1 classification. In stage-2, similar gesture pairs are classified individually, which reduces the problem to binary classification. We apply and evaluate the developed models to recognize the similar human actions on the HMDB51 dataset. The result shows that the proposed model can achieve high performance in comparison to the state-of-the-art methods.",https://ieeexplore.ieee.org/document/8615804/,2018 Digital Image Computing: Techniques and Applications (DICTA),10-13 Dec. 2018,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ICIEM51511.2021.9445285,Simulation based vehicle movement tracking using Kalman Filter algorithm for Autonomous vehicles,IEEE,Conferences,"In the domain of Software automotive industry, one of the most widely used algorithms for performing analysis of driving operations is the Kalman filter algorithm. In today's world of advanced machine learning, the Kalman filter remains an important tool to fuse measurements from several sensors to estimate the real time state of robotics systems such as a self-driving vehicle. Kalman filter is able to update an estimate of evolving nature of continuously changing states of the common filters to take a probabilistic estimate. The driving scenario results are updated in real time using 2-steps update and correction method. In this paper, we have described the process of Kalman filter and its variant to estimate about the detection of moving object in a given traffic scenario using advance toolboxes of MATLAB. Results have been shown for multiple changing parameters.",https://ieeexplore.ieee.org/document/9445285/,2021 2nd International Conference on Intelligent Engineering and Management (ICIEM),28-30 April 2021,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/UBMK.2019.8907108,Smart Class Applications for Education,IEEE,Conferences,"We use technological developments in education and adapt technology to education. Educational computers, tablets, smart phones and other technological devices that integrate with these devices aim to increase the quality of education within the scope of computer-aided training. At the same time, with the development of the Internet, it has become much easier to access resources. The environments where the hardware and software technologies used in education are used together can be considered as intelligent classes. Video conferencing and live broadcasts used in the first smart classrooms have now turned into different applications. Intelligent classes that support learning with robotics, mobile learning, virtual reality and augmented reality applications, and different learning environments and materials are used today to improve the quality of education. The Individualized Smart Class (BAS) application proposed in this study is designed in two steps, hardware and software. It is envisaged to use laptop computers, microphones, headphones, tablets and virtual reality glasses in the classroom as hardware. At the same time the broadband of the classes will be ensured to have the internet. Even in this class, wireless network systems such as infrared, Bluetooth, Wi-Fi can be used. As a software, a class that can be included in the virtual classes with cloud architecture and can use the increased reality applications is considered. In addition, mobile applications that provide virtual reality will enrich the course materials. With this application, equality of opportunity will be provided for disadvantaged students in education and training, quality of education will be improved and it will be beneficial for the development of our country in this context.",https://ieeexplore.ieee.org/document/8907108/,2019 4th International Conference on Computer Science and Engineering (UBMK),11-15 Sept. 2019,ieeexplore
10.1109/ISC2.2016.7580798,SmartSEAL: A ROS based home automation framework for heterogeneous devices interconnection in smart buildings,IEEE,Conferences,"With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",https://ieeexplore.ieee.org/document/7580798/,2016 IEEE International Smart Cities Conference (ISC2),12-15 Sept. 2016,ieeexplore
10.1109/ICRA40945.2020.9197523,SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference,IEEE,Conferences,"Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&amp;R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.",https://ieeexplore.ieee.org/document/9197523/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/ICSTW.2019.00028,Software Testing: According to Plan!,IEEE,Conferences,"Automated planning and scheduling represents a branch of classical artificial intelligence (AI) research. Although initially used in robotics and intelligent agents, the use of planning for testing purposes has increased over the years. There sequences of actions representing interactions with the system under test guide the test execution towards reaching a test purpose. A planning problem is formally defined as a model that resembles the interaction with a real system under test (SUT). The obtained solutions are generated, i.e., the plans, directly correspond to test cases. The planning model offers the possibility to generate test cases with a great variety of interactions without the need for an extensive model definition. Until now, planning has proven to be efficient in detecting both functional and non-functional issues. The second play a major role in uncovering vulnerabilities in software. In fact, testing of any domain can be specified as a planning problem. The purpose of this paper is to summarize previous research in the domain of planning for testing including discussing examples from multiple domains.",https://ieeexplore.ieee.org/document/8728938/,"2019 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)",22-23 April 2019,ieeexplore
10.1109/ITMS52826.2021.9615342,Speaker Identification using Triplet Loss Function Combined with Clustering Techniques,IEEE,Conferences,"Speaker identification plays a critical role in many applications like robotics specially the applications that focus on humanoid robotics. The speaker identification includes comparing unknown utterances against pre-stored utterances of speakers. In general, the encoded features are stored from the pre-known speakers database and 1:N comparisons between the extracted encoded features of the unknown utterances and the pre-stored N known speakers are implemented. Different techniques can be used for these types of comparisons of which cosine similarity is the most used one. However, the more the number of the pre-stored known speakers, the longer the execution time the model will need to finish these comparisons, and hence it may not be suitable for real-time applications. In this paper, we combined previously published Triple Neural Network for speaker identification with clustering techniques on the speakers dataset. We employed different clustering techniques and presented two different methods for comparing unknown utterances against pre-stored utterances. The obtained results showed a significant enhancement in the comparisons time with a few reductions in the obtained accuracy. The proposed approach provided a framework that can represent a trade-off between execution time and obtained accuracy.",https://ieeexplore.ieee.org/document/9615342/,2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS),14-15 Oct. 2021,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/DEVLRN.2002.1011859,Statistical imitative learning from perceptual data,IEEE,Conferences,"Imitative learning has recently piqued the interest of various fields, including neuroscience, cognitive science and robotics. In computational behavior modeling and development, it promises an accessible framework for rapidly forming behavior models without tedious supervision or reinforcement. Given the availability of low-cost wearable sensors, the robustness of real-time perception algorithms and the feasibility of archiving large amounts of audio-visual data, it is possible to unobtrusively archive the daily activities of a human teacher and his responses to external stimuli. We combine this data acquisition/representation process with statistical learning machinery (hidden Markov models) as well as discriminative estimation algorithms to form a behavioral model of a human teacher directly from the data set. The resulting system learns audio-visual interactive behavior from the human and his environment to produce an interactive autonomous agent. The agent subsequently exhibits simple audio-visual behaviors that appear coupled to real-world test stimuli.",https://ieeexplore.ieee.org/document/1011859/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/AIMS.2013.4,Table of contents,IEEE,Conferences,"The following topics are dealt with: artificial intelligence; neural networks and fuzzy systems; evolutionary computation; bioinformatics and bioengineering; data and semantic mining; games, VR and visualization; intelligent systems and applications; systems intelligence; control intelligence; e-science and e-systems; robotics, cybernetics, engineering, and manufacturing; operations research; discrete-event and real-time systems; image, speech and signal processing; industry, business, management, human factors and social issues; energy, power, transport, logistics, harbour, shipping and marine simulation; parallel, distributed, and software architectures and systems; mobile-ad hoc wireless networks, Mobicast, sensor placement, and target tracking; performance engineering of computer and communications systems; and circuits and devices.",https://ieeexplore.ieee.org/document/6959881/,"2013 1st International Conference on Artificial Intelligence, Modelling and Simulation",3-5 Dec. 2013,ieeexplore
10.1109/UKSim.2014.9,Table of contents,IEEE,Conferences,The following topics are dealt with: computer modeling; computer simulation; neural networks; evolutionary computation; adaptive dynamic programming; reinforcement learning; bioinformatics; bioengineering; computational finance; computational economics; data mining; semantics mining; computer games; virtual reality; data visualization; artificial intelligence; soft computing; robotics; discrete event systems; realtime systems; operations research; image processing; speech processing; signal processing; natural language processing; social sciences; business management; parallel processing; distributed processing; software architecture; semantic Web; ontologies; ad hoc wireless networks; mobile networks; target tracking; circuits; and sensors.,https://ieeexplore.ieee.org/document/7045641/,2014 UKSim-AMSS 16th International Conference on Computer Modelling and Simulation,26-28 March 2014,ieeexplore
10.1109/CIMSim.2013.4,Table of contents,IEEE,Conferences,The following topics are dealt with: computational intelligence; neural networks; evolutionary computation; bioinformatics; bioengineering; virtual reality; data visualization; computer game; intelligent systems; soft computing; robotics; cybernetics; operations research; discrete event systems; real-time systems; signal processing; natural language processing; business issues; social issues; human factors; logistics; marine simulation; shipping; distributed software architectures; mobile ad hoc wireless networks; sensor placement; and target tracking.,https://ieeexplore.ieee.org/document/6663147/,"2013 Fifth International Conference on Computational Intelligence, Modelling and Simulation",24-25 Sept. 2013,ieeexplore
10.1109/ICSAI.2012.6223663,Table of contents,IEEE,Conferences,The following topics are dealt with: control system theory; control system applications; human-machine interface; computer vision; robotics; computer control; power systems; energy systems; fuel cells; electrical vehicles; power electronics; wind energy; solar energy; nuclear energy; smart grids; power management; intelligent systems; pattern recognition; autonomous systems; knowledge engineering; computational intelligence; artificial intelligence; computer systems; distributed systems; grid computing; cloud computing; services computing; parallel computing; embedded systems; VLSI; nanocomputing; nanomaterials; aerospace engineering; biomedical engineering; biotechnology; computational sciences; ad hoc networking; sensor networking; wireless networking; Internet; system security; QoS; optical networks; communication theory; signal processing; video processing; image processing; remote sensing; computer graphics; animation; virtual reality; multimedia; data mining; bioinformatics; medical informatics; data engineering; and software engineering.,https://ieeexplore.ieee.org/document/6223663/,2012 International Conference on Systems and Informatics (ICSAI2012),19-20 May 2012,ieeexplore
10.1109/T4E.2014.65,Table of contents,IEEE,Conferences,The following topics are dealt with: mobile app; software tutors; Android programming; assistive learning; board game; software engineering; remote learning; education programs; engineering curricula; e-learning; virtual labs; Web page optimization; robotics competition; context-aware language learning; online learning; virtual classroom; rehabilitation centres; semantic Web; AI course; and Web portal.,https://ieeexplore.ieee.org/document/7009521/,2014 IEEE Sixth International Conference on Technology for Education,18-21 Dec. 2014,ieeexplore
10.1109/CEC.2011.5949582,Table of contents,IEEE,Conferences,The following topics are dealt with: structural design; complex problems; distribution algorithm estimation; artificial bee colony algorithm; evolutionary robotics; evolutionary computation theory; finance decision making; bio-inspired architectures; bio-inspired systems; evolutionary computer vision; computational intelligence; bioinformatics; computational biology; many-core architecture; clustering; data mining; evolvable hardware; evolvable software; fitness landscapes; nature-inspired constrained optimization; ant approach; evolutionary algorithms; real-world numerical optimization problems; art; music; genetic programming; memetic algorithms; cultural algorithms; immune algorithms; developmental systems; generative systems; meta-heuristic method; global continuous optimization; operators; learning classifier systems; TSP; routing problems; multi-objective optimization; greedy selection; autonomous agent learning; statistical learning techniques; machine learning techniques; PSO algorithms; medical image analysis; evolutionary programming; differential evolution; evolutionary games; evolved neural networks; complex networks; multi-agent systems; biometrics; biomedical applications; hyper heuristics; coevolutionary systems; artificial ecology and artificial life.,https://ieeexplore.ieee.org/document/5949582/,2011 IEEE Congress of Evolutionary Computation (CEC),5-8 June 2011,ieeexplore
10.1109/CLEI.2017.8226366,Table of contents,IEEE,Conferences,The following topics are dealt with: computer science education; medical image processing; robotics; programming languages; virtual reality; optical network; GSO network; LEO network; computer vision; graph coloring; machine learning; vehicle routing; neural network; computer aided instruction; data mining; service-oriented architecture; software development; social network; e-health; bioinformatics; and business process.,https://ieeexplore.ieee.org/document/8226366/,2017 XLIII Latin American Computer Conference (CLEI),4-8 Sept. 2017,ieeexplore
10.1109/ICCEA.2010.4,Table of contents - Volume 1,IEEE,Conferences,The following deals with the following topics: algorithms; artificial intelligence; software engineering; bioinformatics; computer graphics; computer architecture; information systems; computer aided instruction; computer games; virtual reality; data security; digital simulation; computer aided design; ethical aspects; database systems; digital libraries; signal processing; image processing; logic design; e-commerce; human computer interaction; embedded systems; Internet; mobile computing; multimedia systems; natural language processing; neural networks; programming languages; robotics; control systems; theoretical computer science; and wireless sensor networks.,https://ieeexplore.ieee.org/document/5445635/,2010 Second International Conference on Computer Engineering and Applications,19-21 March 2010,ieeexplore
10.1109/ICCRD.2011.5764067,Table of contents vol. 01,IEEE,Conferences,The following topics are dealt with: computer research and development; event driven programming; artificial intelligence; expert systems; algorithm analysis; high performance computing; automated software engineering; human computer interaction; bioinformatics; scientific computing; image processing; information retrieval; compilers; interpreters; computational intelligence; computer architecture; embedded systems; computer animation; Internet; Web applications; communication/networking; knowledge data engineering; computer system implementation; logics; VLSI; mathematical software; information systems; computer based education; mathematical logic; mobile computing; computer games; multimedia applications; computer graphics; virtual reality; natural language processing; neural networks; computer modeling; parallel computing; distributed computing; computer networks; pattern recognition; computer security; computer simulation; computer vision; probability; statistics; performance evaluation; computer aided design/manufacturing; computing ethics; programming languages; problem complexity; control systems; physical sciences; engineering; discrete mathematics; reconfigurable computing systems; data communications; robotics; automation; system security; cryptography; data compression; data encryption; data mining; database systems; document processing; text processing; educational technology; digital library; technology management; digital signal processing; theoretical computer science; digital systems; logic design; ubiquitous computing; and visualizations.,https://ieeexplore.ieee.org/document/5764067/,2011 3rd International Conference on Computer Research and Development,11-13 March 2011,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/GHTC.2018.8601597,The EDNA Public Safety Drone: Bullet-Stopping Lifesaving,IEEE,Conferences,"Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending “Predictive Probable Cause” technology. The EDNA drone is designed to provide automated real-time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed--to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets-functionality which has obvious benefits for humanitarian deployment.",https://ieeexplore.ieee.org/document/8601597/,2018 IEEE Global Humanitarian Technology Conference (GHTC),18-21 Oct. 2018,ieeexplore
10.1109/CT.1997.617707,The Intelligent Room project,IEEE,Conferences,"At the MIT Artificial Intelligence Laboratory, we have been working on technologies for an Intelligent Room. Rather than pull people into the virtual world of the computer, we are trying to pull the computer out into the real world of people. To do this, we are combining robotics and vision technology with speech understanding systems and agent-based architectures to provide ready-at-hand computation and information services for people engaged in day-to-day activities, both on their own and in conjunction with others. We have built a layered architecture where, at the bottom level, vision systems track people and identify their activities and gestures, and, through word spotting, decide whether people in the room are talking to each other or to the room itself. At the next level, an agent architecture provides a uniform interface to such specially-built systems, and to other off-the-shelf software, such as Web browsers, etc. At the highest level, we are able to build application systems that provide occupants of the room with specialized services; examples we have built include systems for command-and-control situations rooms and as a room for giving presentations.",https://ieeexplore.ieee.org/document/617707/,Proceedings Second International Conference on Cognitive Technology Humanizing the Information Age,25-28 Aug. 1997,ieeexplore
10.1109/ROBOT.2004.1308800,The artificial ecosystem: a distributed approach to service robotics,IEEE,Conferences,"We propose a multiagent, distributed approach to autonomous mobile robotics which is an alternative to most existing systems in literature: robots are thought of as mobile units within an intelligent environment where they coexist and co-operate with fixed, intelligent devices that are assigned different roles: helping the robot to localize itself, controlling automated doors and elevators, detecting emergency situations, etc. To achieve this, intelligent sensors and actuators (i.e. physical agents) are distributed both onboard the robot and throughout the environment, and they are handled by Real-Time software agents which exchange information on a distributed message board. The paper outlines the benefits of the approach in terms of efficiency and Real-Time responsiveness.",https://ieeexplore.ieee.org/document/1308800/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IEMC.1998.727776,The importance of artificial intelligence-expert systems in computer integrated manufacturing,IEEE,Conferences,"In order to maintain their competitiveness, companies feel compelled to adopt productivity increasing measures. Yet, they cannot relinquish the flexibility their production cycles need in order to improve their response, and thus, their positioning in the market. To achieve this, companies must combine these two seemingly opposed principles. Thanks to new technological advances, this combination is already a working reality in some companies. It is made possible today by the implementation of computer integrated manufacturing (CIM) and artificial intelligence (AI) techniques, fundamentally by means of expert systems (ES) and robotics. Depending on how these (AI/CIM) techniques contribute to automation, their immediate effects are an increase in productivity and cost reductions. Yet also, the system's flexibility allows for easier adaptation and, as a result, an increased ability to generate value, in other words, competitiveness is improved. The authors have analyzed three studies to identify the possible benefits or advantages, as well as the inconveniences, that this type of technique may bring to companies, specifically in the production field. Although the scope of the studies and their approach differ from one to the other, their joint contribution can be of unquestionable value in order to understand a little better the importance of ES within the production system.",https://ieeexplore.ieee.org/document/727776/,IEMC '98 Proceedings. International Conference on Engineering and Technology Management. Pioneering New Technologies: Management Issues and Challenges in the Third Millennium (Cat. No.98CH36266),11-13 Oct. 1998,ieeexplore
10.1109/ROBOT.2007.364220,Towards Mapping of Cities,IEEE,Conferences,"Map learning is a fundamental task in mobile robotics because maps are required for a series of high level applications. In this paper, we address the problem of building maps of large-scale areas like villages or small cities. We present our modified car-like robot which we use to acquire the data about the environment. We introduce our localization system which is based on an information filter and is able to merge the information obtained by different sensors. We furthermore describe out mapping technique that is able to compactly model three-dimensional scenes and allows us efficient and accurate incremental map learning. We additionally apply a global optimization techniques in order to accurately close loops in the environment. Our approach has been implemented and deeply tested on a real car equipped with a series of sensors. Experiments described in this paper illustrate the accuracy and efficiency of the presented techniques.",https://ieeexplore.ieee.org/document/4209838/,Proceedings 2007 IEEE International Conference on Robotics and Automation,10-14 April 2007,ieeexplore
10.1109/DEVLRN.2005.1490968,Towards Robot Soccer Team Behaviours Through Approximate Simulation,IEEE,Conferences,"Robot soccer is now recognized as one of the most popular and efficient testbeds for intelligent robotics. It involves many challenges for computation, mechanics, control, software engineering, machine learning, and other fields. The international RoboCup initiative supports research into robot soccer and provides an excellent environment to investigate machine learning for robotics in simulation and the real world",https://ieeexplore.ieee.org/document/1490968/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/IJCNN.2017.7966054,Towards real-time robot simulation on uneven terrain using neural networks,IEEE,Conferences,"Simulation is a valuable tool for robotics research and development, and various simulation packages have been proposed. However, we are aware of no freely-available packages which implement the required fidelity to accurately model earth-moving robots that manipulate the terrain itself. The software which does exist for this is difficult if not impossible to run in real-time while achieving the desired accuracy. This paper proposes a simulation system in which a neural network is trained using data generated in a 3D high-fidelity, non-real-time simulator. The resulting neural network is used to accurately predict the motion of a robot in a 2D simulator, while also taking into consideration a height-field representing a 3D terrain. Using a trained neural network to drive the new simulation provides considerable speedup over the high-fidelity 3D simulation, allowing behaviour to be simulated in real-time while still capturing the physics of the agents and the environment.",https://ieeexplore.ieee.org/document/7966054/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/SECON.2017.7925321,Towards real-time segmentation of 3D point cloud data into local planar regions,IEEE,Conferences,"This article describes an algorithm for efficient segmentation of point cloud data into local planar surface regions. This is a problem of generic interest to researchers in the computer graphics, computer vision, artificial intelligence and robotics community where it plays an important role in applications such as object recognition, mapping, navigation and conversion from point clouds representations to 3D surface models. Prior work on the subject is either computationally burdensome, precluding real time applications such as robotic navigation and mapping, prone to error for noisy measurements commonly found at long range or requires availability of coregistered color imagery. The approach we describe consists of 3 steps: (1) detect a set of candidate planar surfaces, (2) cluster the planar surfaces merging redundant plane models, and (3) segment the point clouds by imposing a Markov Random Field (MRF) on the data and planar models and computing the Maximum A-Posteriori (MAP) of the segmentation labels using Bayesian Belief Propagation (BBP). In contrast to prior work which relies on color information for geometric segmentation, our implementation performs detection, clustering and estimation using only geometric data. Novelty is found in the fast clustering technique and new MRF clique potentials that are heretofore unexplored in the literature. The clustering procedure removes redundant detections of planes in the scene prior to segmentation using BBP optimization of the MRF to improve performance. The MRF clique potentials dynamically change to encourage distinct labels across depth discontinuities. These modifications provide improved segmentations for geometry-only depth images while simultaneously controlling the computational cost. Algorithm parameters are tunable to enable researchers to strike a compromise between segmentation detail and computational performance. Experimental results apply the algorithm to depth images from the NYU depth dataset which indicate that the algorithm can accurately extract large planar surfaces from depth sensor data.",https://ieeexplore.ieee.org/document/7925321/,SoutheastCon 2017,30 March-2 April 2017,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/VLSID.2018.20,Tutorial T2A: Safe Autonomous Systems: Real-Time Error Detection and Correction in Safety-Critical Signal Processing and Control Algorithms,IEEE,Conferences,"While the last two decades have seen revolutions in computing and communications systems, the next few decades will see a revolution in the use of every-day robotics and artificial intelligence in broad societal applications. Examples of such systems include sensor networks, the smart power grid, self-driven cars and autonomous drones. Such systems are driven by signal processing, control and learning algorithms that process sensor data, actuate control functions and learn about the environment in which these systems operate. The trustworthiness and safety of such systems is of paramount importance and has significant impact on the commercial viability of the underlying technology. As a consequence, anomalies in system operation due to computation errors in on-board processors, degradation and failure of embedded sensors, actuators and electro-mechanical subsystems and unforeseen changes in their operation environment need to detected with minimum latency. Such anomalies also need to be mitigated in ways that ensure the safety of such systems under all possible failure scenarios. Many future systems will be selflearning in the field. It is necessary to ensure that such learning does not compromise the safety of all human personnel involved in the operation of such systems. To enable safe operation of such systems, the underlying hardware needs to be tuned in the field to maximize performance, reliability and error-resilience while minimizing power consumption. To enable such dynamic adaptation, device operating conditions and the onset of soft errors are sensed using post-manufacture and real-time checking mechanisms. These mechanisms rely on the use of built-in sensors and/or low-overhead function encoding techniques to detect anomalies in system functions. A key capability is that of being able to deduce multiple performance parameters of the system-under-test using compact optimized stimulus using learning algorithms. The sensors and function encodings assess the loss in performance of the relevant systems due to workload uncertainties, manufacturing process imperfections, soft errors and hardware malfunction and failures induced by electromechanical degradation. These are then mitigated through the use of algorithm-through-circuit level compensation techniques based on pre-deployment simulation and post-deployment self-learning. These techniques continuously trade off performance vs. power of the individual software and hardware modules in such a way as to deliver the end-to-end desired application level Quality of Service (QoS), while minimizing energy/power consumption and maximizing reliability and safety. Applications to signal processing, and control algorithms for example autonomous systems will be discussed.",https://ieeexplore.ieee.org/document/8326883/,2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID),6-10 Jan. 2018,ieeexplore
10.1109/ETFA.2016.7733537,UAV degradation identification for pilot notification using machine learning techniques,IEEE,Conferences,"Unmanned Aerial Vehicles are currently investigated as an important sub-domain of robotics, a fast growing and truly multidisciplinary research field. UAVs are increasingly deployed in real-world settings for missions in dangerous environments or in environments which are challenging to access. Combined with autonomous flying capabilities, many new possibilities, but also challenges, open up. To overcome the challenge of early identification of degradation, machine learning based on flight features is a promising direction. Existing approaches build classifiers that consider their features to be correlated. This prevents a fine-grained detection of degradation for the different hardware components. This work presents an approach where the data is considered uncorrelated and, using machine learning techniques, allows the precise identification of UAV's damages.",https://ieeexplore.ieee.org/document/7733537/,2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA),6-9 Sept. 2016,ieeexplore
10.1109/M2VIP.2018.8600864,Unsupervised Video Prediction Network with Spatio-temporal Deep Features,IEEE,Conferences,"Predicting the future states of things is an important performance form of intelligence and it is also of vital importance in real-time systems such as autonomous cars and robotics. This paper aims to tackle a video prediction task. Previous methods for future frame prediction are always subject to restrictions from environment, leading to poor accuracy and blurry prediction details. In this work, we present an unsupervised video prediction framework which iteratively anticipates the raw RGB pixel values in future video frames. Extensive experiments are implemented on advanced datasets - KTH and KITTI. The results demonstrate that our method achieves a good performance.",https://ieeexplore.ieee.org/document/8600864/,2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),20-22 Nov. 2018,ieeexplore
10.1109/IDAACS-SWS50031.2020.9297062,Using a COTS Smartphone to Control an Autonomous Self-Driving Platform,IEEE,Conferences,"Recent interest in self-driving cars has boosted related fields like autonomous systems and robotics. This paper describes a simple and inexpensive small-scale self driving platform called ASV, which is based on a lowcost microcontroller and a COTS smartphone connected via WiFi. The camera of the phone, which is fixed to the platform, acquires images which are processed in a Convolutional Neural Network (CNN) inspired by the Nvidia's PilotNet. The network is trained in end-to-end learning to produce steering command to follow highway style lanes with markers on both sides. On the microcontroller, the steering commands are used for motor actuation and control of the physical movement of the platform. This paper presents the structure and implementation of ASV and evaluates its real-time performance and latency. For typical speeds encountered in small-scale systems, the performance is found more than sufficient for lane following with the CNN, leaving plenty of room for extensions. The platform's simplicity allows it to be used in research, education, and to spark interest in self-driving systems and neural networks. It can form the basis for general robot control.",https://ieeexplore.ieee.org/document/9297062/,2020 IEEE 5th International Symposium on Smart and Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS),17-18 Sept. 2020,ieeexplore
10.1109/IEEECONF51394.2020.9443272,VLSI Hardware Architecture for Gaussian Process,IEEE,Conferences,"Gaussian process (GP) is a popular machine learning technique that is widely used in many application domains, especially in robotics. However, GP is very computation intensive and time consuming during the inference phase, thereby bringing severe challenges for its large-scale deployment in real-time applications. In this paper, we propose two efficient hardware architecture for GP accelerator. One architecture targets for general GP inference, and the other architecture is specifically optimized for the scenario when the data point is gradually observed. Evaluation results show that the proposed hardware accelerator provides significant hardware performance improvement than the general-purpose computing platform.",https://ieeexplore.ieee.org/document/9443272/,"2020 54th Asilomar Conference on Signals, Systems, and Computers",1-4 Nov. 2020,ieeexplore
10.1109/ICRA.2019.8793556,VPE: Variational Policy Embedding for Transfer Reinforcement Learning,IEEE,Conferences,"Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.",https://ieeexplore.ieee.org/document/8793556/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/EEEI.2014.7005895,Verification of safety for autonomous unmanned ground vehicles,IEEE,Conferences,"The existing tools for hardware and software reliability and safety engineering do not supply sufficient solutions regarding AI (Artificial Intelligent) adaptive and learning algorithms, which are being used in autonomous robotics and massively rely on designer experience and include methods such as Heuristic, Rules based decision, Fuzzy Logic, Neural Networks, and Genetic Algorithms, Bayes Networks, etc. Since it is obvious that only this kind of algorithms can deal with the complexity and the uncertainty of the real world environment, suitable safety validation methodology is required. In this paper we present the limitation of the existing reliability and safety engineering tools in dealing with autonomous systems and propose a novel methodology based on statistical testing in simulated environment.",https://ieeexplore.ieee.org/document/7005895/,2014 IEEE 28th Convention of Electrical & Electronics Engineers in Israel (IEEEI),3-5 Dec. 2014,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/IROS.1999.811679,What we learned from RoboCup-97 and RoboCup-98,IEEE,Conferences,"RoboCup is an increasingly successful attempt to promote the full integration of robotics and AI research. The most prominent feature of RoboCup is that it provides the researchers with the opportunity to demonstrate their research results as a form of competition in a dynamically changing hostile environment, defined as the international standard game definition, in which the gamut of intelligent robotics research issues are naturally involved. The article describes what we have learned from the past RoboCup activities, and overview the future perspectives of RoboCup in the next century, mainly focusing on the real robot leagues. Finally, we introduce the new leagues, one of which will have been held at RoboCup-99 in Stockholm.",https://ieeexplore.ieee.org/document/811679/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/ICSMC.2011.6083632,[Copyright notice],IEEE,Conferences,The following topics are dealt with: brain-machine interface; machine learning technology; service systems; homeland security systems; virtual reality; agent-based modeling; human centered transportation systems; awareness science and engineering; soft computing; enterprise information systems; social signal processing; infrastructure system; manufacturing systems; pattern recognition; medical mechatronics; minimally invasive surgery; medical robotics; medical technology; intelligent power systems; discrete event systems; Petri nets; biometrics; bioinformatics; computational intelligence; supply chain management; shared control; fault diagnosis; systems engineering; Internet; support vector machines; knowledge acquisition; cloud computing; grey systems; humanoid robots; redundant manipulators; formal methods; granular computing; wireless sensor networks; nonlinear control systems; gesture-based interaction; software engineering; multi-agent systems; cognitive computing; social robotics; natural language processing; conflict resolution; intelligent transportation systems; human-robot interaction; image processing; medical informatics; decision support systems; assistive technology; human-centered design; data mining; and anti-terrorism applications.,https://ieeexplore.ieee.org/document/6083632/,"2011 IEEE International Conference on Systems, Man, and Cybernetics",9-12 Oct. 2011,ieeexplore
10.1109/UKSim.2012.123,[Cover art],IEEE,Conferences,The following topics are dealt with: neural networks; evolutionary computation; adaptive dynamic programming; re-enforcement learning; bio-informatics; bio-engineering; computational finance; economics; semantic mining; data mining; virtual reality; data visualization; intelligent systems; soft computing; hybrid computing; e-science; e-systems; robotics; cybernetics; manufacturing; engineering; operations research; discrete event systems; real time systems; image processing; speech processing; signal processing; industry; business; social issues; human factors; marine simulation; power systems; logistics;parallel systems; distributed systems; software architectures;Internet modelling; semantic Web; ontologies; mobile ad hoc wireless networks; Mobicast; sensor placement; target tracking; circuits; sensors and devices.,https://ieeexplore.ieee.org/document/6205540/,2012 UKSim 14th International Conference on Computer Modelling and Simulation,28-30 March 2012,ieeexplore
10.1109/INES.2015.7329762,[Front cover],IEEE,Conferences,The following topics are dealt with: learning; Web; urban water-supply system; IP Core; DCI approach; real-time sensor network; linked open data source; process mining; image coding; deep neural network architecture; human computer interaction; social human-robot interaction; VANET; authorized V2V communication; MIMO system; surgical robotics; ontologies; genetic algorithm; image reconstruction; mobile robot; artificial neural network; fuzzy reasoning; heat exchanger; fuzzy controller design; mobile device; human machine interface design; decision support system; data mining technique; discrete-time SISO system; augmented reality; visual analysis; content management system; Androids; nonlinear MPC; collaborative filtering; recommendation; wireless sensor networks;; humidity control; temperature control and stability.,https://ieeexplore.ieee.org/document/7329762/,2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES),3-5 Sept. 2015,ieeexplore
10.1109/SISY.2010.5647094,[Front cover],IEEE,Conferences,The following topics are dealt with: computational intelligence; machine learning; genetic algorithms; neural nets; neuro fuzzy control; knowledge based systems; expert systems; intelligent robotics; flexible arm control; perception; recognition; reasoning; human robotic interaction; service robots; surgery robots; machine vision; intelligent mechatronics; sensor data fusion; motion control; intelligent actuators; CAD/CAM/CAE Systems; product modeling; manufacturing process planning; advanced modeling techniques; shape modeling; intelligent manufacturing systems; flexible manufacturing systems; production planning; system simulation; rapid prototyping; concurrent engineering; virtual reality; informatics; digital culture; databases; graphics; digital audio; photography; operating systems; security software engineering; healthcare informatics; teaching informatics; and informatics in education process.,https://ieeexplore.ieee.org/document/5647094/,IEEE 8th International Symposium on Intelligent Systems and Informatics,10-11 Sept. 2010,ieeexplore
10.1109/AIMS.2015.1,[Title page i],IEEE,Conferences,The following topics are dealt with: artificial intelligence; neural networks; fuzzy systems; evolutionary computation; bioinformatics; bioengineering; data mining; semantic mining; games; VR; visualization; intelligent systems applications; hybrid computing; soft computing; intelligent systems control; control intelligence; e-science; e-systems; robotics; cybernetics; manufacturing system; operations research; discrete event systems; real time systems; signal processing; speech processing; image processing; natural language processing; human factors; social issues; shipping; marine simulation; transport; logistics; mobile ad hoc wireless networks; Mobicast; sensor placement; target tracking; software architectures; distributed systems; parallel systems; power simulation; performance engineering; communication systems; and circuits.,https://ieeexplore.ieee.org/document/7604531/,"2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)",2-4 Dec. 2015,ieeexplore
10.1109/UKSim.2013.1,[Title page i],IEEE,Conferences,The following topics are dealt with: neural networks; fuzzy systems; evolutionary computation; dynamic programming; reinforcement learning; bioinformatics; bioengineering; computational finance; computational economics; computer games; virtual reality; data visualization; computer networks; intelligent systems; soft computing; intelligent control; e-science; e-systems; robotics; cybernetics; manufacturing systems; operations research; discrete event systems; realtime systems; image processing; speech processing; signal processing; natural language processing; business management; human factors; renewable energy; logistics; parallel architecture; distributed architecture; software architecture; Internet; ontologies; wireless networks; target tracking; performance engineering; circuits; and sensors.,https://ieeexplore.ieee.org/document/6527370/,2013 UKSim 15th International Conference on Computer Modelling and Simulation,10-12 April 2013,ieeexplore
10.1109/UKSim.2015.1,[Title page i],IEEE,Conferences,The following topics are dealt with: neural networks; fuzzy systems; evolutionary computation; bioinformatics; bioengineering; data mining; semantic mining; games; VR; visualization; emergent technologies; intelligent systems; control intelligence; e-science; e-systems; robotics; cybernetics; manufacturing; operations research; discrete event systems; real time systems; image processing; speech processing; signal processing; natural language processing; language technologies; human factors; social issues; energy; power; transport; logistics; harbour; shipping; marine simulation; parallel architectures; distributed architectures; software architectures; Internet modelling; semantic Web; ontologies; mobile ad hoc wireless networks; mobicast; sensor placement and target tracking.,https://ieeexplore.ieee.org/document/7576501/,2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim),25-27 March 2015,ieeexplore
10.1109/ICCET.2010.5486348,[Title page],IEEE,Conferences,The following topics are dealt with: artificial intelligence; automated software engineering; bioinformatics; scientific computing; biomedical engineering; compilers; interpreters; computational intelligence; computer animation; computer architecture; VLSI; information systems; computer based education; computer games; digital systems; distributed systems; parallel processing; e-commerce; e-governance; event driven programming; expert systems; human computer interaction; image processing; information retrieval; embedded systems; Internet; Web application; knowledge data engineering; virtual reality; mobile computing; multimedia applications; computer modeling; natural language processing; computer networks; neural networks; computer security; computer simulation; pattern recognition; computer vision; performance evaluation; computer aided design; programming languages; computing ethics; robotics; control systems; cryptography; data communication; software engineering; system security; data compression; data encryption; data mining; digital library; wireless sensor networks; ubiquitous computing; technology management.,https://ieeexplore.ieee.org/document/5486348/,2010 2nd International Conference on Computer Engineering and Technology,16-18 April 2010,ieeexplore
10.1109/IROS45743.2020.9340956,robo-gym – An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots,IEEE,Conferences,"Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and reduce the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym<sup>1</sup>. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to application on the robot. We showcase the capabilities and the effectiveness of the framework with two real world applications featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally, we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.",https://ieeexplore.ieee.org/document/9340956/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/JIOT.2019.2917066,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,IEEE,Journals,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8715489/,IEEE Internet of Things Journal,Oct. 2019,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2018.2835302,A Fast and Deterministic Algorithm for Consensus Set Maximization,IEEE,Journals,"With the current booming applications of virtual reality, augmented reality, and robotics, efficiently extracting the maximum consensus set among large-scale corrupted data has become a critical challenge. However, existing methods typically focus on optimization and are rarely concerned about the running time. In this paper, we propose a new fast and deterministic algorithm to address the consensus set maximization problem. First, we propose a novel formulation that transforms the original problem into a sequence of decision problems (DPs). Second, we propose an efficient algorithm to assess the feasibility of these DPs. Comprehensive experiments on linear hyper-plane regression and non-linear homography matrix estimation show that our approach is fully deterministic and can effectively process large-scale and highly corrupted data without any special initialization. Under a pure MATLAB implementation and a laptop CPU, our method can successfully determine the maximum consensus set from 1000 input data points (with 70% of them being outliers) at 30 Hz.",https://ieeexplore.ieee.org/document/8360018/,IEEE Access,2018,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2020.3038605,A Gentle Introduction to Reinforcement Learning and its Application in Different Fields,IEEE,Journals,"Due to the recent progress in Deep Neural Networks, Reinforcement Learning (RL) has become one of the most important and useful technology. It is a learning method where a software agent interacts with an unknown environment, selects actions, and progressively discovers the environment dynamics. RL has been effectively applied in many important areas of real life. This article intends to provide an in-depth introduction of the Markov Decision Process, RL and its algorithms. Moreover, we present a literature review of the application of RL to a variety of fields, including robotics and autonomous control, communication and networking, natural language processing, games and self-organized system, scheduling management and configuration of resources, and computer vision.",https://ieeexplore.ieee.org/document/9261348/,IEEE Access,2020,ieeexplore
10.1109/TCSVT.2017.2726564,A Hardware Architecture for Cell-Based Feature-Extraction and Classification Using Dual-Feature Space,IEEE,Journals,"Many computer-vision and machine-learning applications in robotics, mobile, wearable devices, and automotive domains are constrained by their real-time performance requirements. This paper reports a dual-feature-based object recognition coprocessor that exploits both histogram of oriented gradient (HOG) and Haar-like descriptors with a cell-based parallel sliding-window recognition mechanism. The feature extraction circuitry for HOG and Haar-like descriptors is implemented by a pixel-based pipelined architecture, which synchronizes to the pixel frequency from the image sensor. After extracting each cell feature vector, a cell-based sliding window scheme enables parallelized recognition for all windows, which contain this cell. The nearest neighbor search classifier is, respectively, applied to the HOG and Haar-like feature space. The complementary aspects of the two feature domains enable a hardware-friendly implementation of the binary classification for pedestrian detection with improved accuracy. A proof-of-concept prototype chip fabricated in a 65-nm SOI CMOS, having thin gate oxide and buried oxide layers (SOTB CMOS), with 3.22-mm<sup>2</sup> core area achieves an energy efficiency of 1.52 nJ/pixel and a processing speed of 30 fps for 1024 × 1616-pixel image frames at 200-MHz recognition working frequency and 1-V supply voltage. Furthermore, multiple chips can implement image scaling, since the designed chip has image-size flexibility attributable to the pixel-based architecture.",https://ieeexplore.ieee.org/document/7979565/,IEEE Transactions on Circuits and Systems for Video Technology,Oct. 2018,ieeexplore
10.1109/TNSRE.2020.3044113,A Novel Point-in-Polygon-Based sEMG Classifier for Hand Exoskeleton Systems,IEEE,Journals,"In the early 2000s, data from the latest World Health Organization estimates paint a picture where one-seventh of the world population needs at least one assistive device. Fortunately, these years are also characterized by a marked technological drive which takes the name of the Fourth Industrial Revolution. In this terrain, robotics is making its way through more and more aspects of everyday life, and robotics-based assistance/rehabilitation is considered one of the most encouraging applications. Providing high-intensity rehabilitation sessions or home assistance through low-cost robotic devices can be indeed an effective solution to democratize services otherwise not accessible to everyone. However, the identification of an intuitive and reliable real-time control system does arise as one of the critical issues to unravel for this technology in order to land in homes or clinics. Intention recognition techniques from surface ElectroMyoGraphic (sEMG) signals are referred to as one of the main ways-to-go in literature. Nevertheless, even if widely studied, the implementation of such procedures to real-case scenarios is still rarely addressed. In a previous work, the development and implementation of a novel sEMG-based classification strategy to control a fully-wearable Hand Exoskeleton System (HES) have been qualitatively assessed by the authors. This paper aims to furtherly demonstrate the validity of such a classification strategy by giving quantitative evidence about the favourable comparison to some of the standard machine-learning-based methods. Real-time action, computational lightness, and suitability to embedded electronics will emerge as the major characteristics of all the investigated techniques.",https://ieeexplore.ieee.org/document/9291412/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1109/ACCESS.2016.2571058,A Review of Theoretical and Practical Challenges of Trusted Autonomy in Big Data,IEEE,Journals,"Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally, and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus this paper on the trust component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three subtopics: (1) reviewing and positioning the trust modeling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enable trusted autonomous systems to become a reality. This paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.",https://ieeexplore.ieee.org/document/7480763/,IEEE Access,2016,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/TRO.2011.2119910,A Simple Tactile Probe for Surface Identification by Mobile Robots,IEEE,Journals,"This paper describes a tactile probe designed for surface identification in a context of all-terrain low-velocity mobile robotics. The proposed tactile probe is made of a small metallic rod with a single-axis accelerometer attached near its tip. Surface identification is based on analyzing acceleration patterns induced at the tip of this mechanically robust tactile probe, while it is passively dragged along a surface. A training dataset was collected over ten different indoor and outdoor surfaces. Classification results for an artificial neural network were positive, with an 89.9% and 94.6% success rate for 1- and 4-s time windows of data, respectively. We also demonstrated that the same tactile probe can be used for unsupervised learning of terrains. For 1-s time windows of data, the classification success rate was only reduced to 74.1%. Finally, a blind mobile robot, performing real-time classification of surfaces, demonstrated the feasibility of this tactile probe as a guidance mechanism.",https://ieeexplore.ieee.org/document/5752869/,IEEE Transactions on Robotics,June 2011,ieeexplore
10.1109/ACCESS.2020.3001277,"A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals, Technology Integration, and State-of-the-Art",IEEE,Journals,"Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.",https://ieeexplore.ieee.org/document/9113305/,IEEE Access,2020,ieeexplore
10.1109/TRO.2004.833801,A hybrid strategy to solve the forward kinematics problem in parallel manipulators,IEEE,Journals,"A parallel manipulator is a closed kinematic structure with the necessary rigidity to provide a high payload to self-weight ratio suitable for many applications in manufacturing, flight simulation systems, and medical robotics. Because of its closed structure, the kinematic control of such a mechanism is difficult. The inverse kinematics problem for such manipulators has a mathematical solution; however, the forward kinematics problem (FKP) is mathematically intractable. This work addresses the FKP and proposes a neural-network-based hybrid strategy that solves the problem to a desired level of accuracy, and can achieve the solution in real time. Two neural-network (NN) concepts using a modified form of multilayered perceptrons with backpropagation learning were implemented. The better performing concept was then combined with a standard Newton-Raphson numerical technique to yield a hybrid solution strategy. Simulation studies were carried out on a flight simulation syystem to check the validity o the approach. Accuracy of close to 0.01 mm and 0.01/spl deg/ in the position and orientation parameters was achieved in less than two iterations and 0.02 s of execution time for the proposed strategy.",https://ieeexplore.ieee.org/document/1391011/,IEEE Transactions on Robotics,Feb. 2005,ieeexplore
10.1109/TITB.2004.840062,A tele-operated mobile ultrasound scanner using a light-weight robot,IEEE,Journals,"This paper presents a new tele-operated robotic chain for real-time ultrasound image acquisition and medical diagnosis. This system has been developed in the frame of the Mobile Tele-Echography Using an Ultralight Robot European Project. A light-weight six degrees-of-freedom serial robot, with a remote center of motion, has been specially designed for this application. It holds and moves a real probe on a distant patient according to the expert gesture and permits an image acquisition using a standard ultrasound device. The combination of mechanical structure choice for the robot and dedicated control law, particularly nearby the singular configuration allows a good path following and a robotized gesture accuracy. The choice of compression techniques for image transmission enables a compromise between flow and quality. These combined approaches, for robotics and image processing, enable the medical specialist to better control the remote ultrasound probe holder system and to receive stable and good quality ultrasound images to make a diagnosis via any type of communication link from terrestrial to satellite. Clinical tests have been performed since April 2003. They used both satellite or Integrated Services Digital Network lines with a theoretical bandwidth of 384 Kb/s. They showed the tele-echography system helped to identify 66% of lesions and 83% of symptomatic pathologies.",https://ieeexplore.ieee.org/document/1402447/,IEEE Transactions on Information Technology in Biomedicine,March 2005,ieeexplore
10.1109/ACCESS.2020.2996576,An Embedded System for Collection and Real-Time Classification of a Tactile Dataset,IEEE,Journals,"Tactile perception of the material properties in real-time using tiny embedded systems is a challenging task and of grave importance for dexterous object manipulation such as robotics, prosthetics and augmented reality. As the psychophysical dimensions of the material properties cover a wide range of percepts, embedded tactile perception systems require efficient signal feature extraction and classification techniques to process signals collected by tactile sensors in real-time. For this purpose, we developed two embedded systems, one that served as a vibrotactile stimulator system and one that recorded and classified the vibrotactile signals collected by its sensors. The quality of the collected data was first verified offline using Fourier transform for feature extraction and then applying powerful machine learning classifiers such as support vector machines and neural networks. We implemented the proposed memory-less signal feature extraction method in order to achieve real-time processing as the data is being collected. The experimental results have shown that the proposed method significantly reduces the computational complexity of feature extraction and still has led to high classification accuracy even when fed to the less complex classifiers such as random forests that can be easily implemented on embedded systems. Finally, we have also shown that low-cost, highly accurate, and real-time tactile texture classification can be achieved using the proposed approach with an ensemble of sensors.",https://ieeexplore.ieee.org/document/9098886/,IEEE Access,2020,ieeexplore
10.1109/3477.931510,"An approach to the design of reinforcement functions in real world, agent-based applications",IEEE,Journals,"The success of any reinforcement learning (RL) application is in large part due to the design of an appropriate reinforcement function. A methodological framework to support the design of reinforcement functions has not been defined yet, and this critical and often underestimated activity is left to the ability of the RL application designer. We propose an approach to support reinforcement function design in RL applications concerning learning behaviors for autonomous agents. We define some dimensions along which we can describe reinforcement functions; we consider the distribution of reinforcement values, their coherence and their matching with the designer's perspective. We give hints to define measures that objectively describe the reinforcement function; we discuss the trade-offs that should be considered to improve learning and we introduce the dimensions along which this improvement can be expected. The approach we are presenting is general enough to be adopted in a large number of RL projects. We show how to apply it in the design of learning classifier systems (LCS) applications. We consider a simple, but quite complete case study in evolutionary robotics, and we discuss reinforcement function design issues in this sample context.",https://ieeexplore.ieee.org/document/931510/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2001,ieeexplore
10.1109/72.485630,Analog VLSI implementation for stereo correspondence between 2-D images,IEEE,Journals,"Many robotics and navigation systems utilizing stereopsis to determine depth have rigid size and power constraints and require direct physical implementation of the stereo algorithm. The main challenges lie in managing the communication between image sensor and image processor arrays, and in parallelizing the computation to determine stereo correspondence between image pixels in real-time. This paper describes the first comprehensive system level demonstration of a dedicated low-power analog VLSI (very large scale integration) architecture for stereo correspondence suitable for real-time implementation. The inputs to the implemented chip are the ordered pixels from a stereo image pair, and the output is a two-dimensional disparity map. The approach combines biologically inspired silicon modeling with the necessary interfacing options for a complete practical solution that can be built with currently available technology in a compact package. Furthermore, the strategy employed considers multiple factors that may degrade performance, including the spatial correlations in images and the inherent accuracy limitations of analog hardware, and augments the design with countermeasures.",https://ieeexplore.ieee.org/document/485630/,IEEE Transactions on Neural Networks,March 1996,ieeexplore
10.1109/ACCESS.2021.3093233,Assessment of a Robotic Assistant for Supporting Homework Activities of Children With ADHD,IEEE,Journals,"Robotics, Artificial Intelligence (AI), and the Internet of Things (IoT) support various processes in many scenarios of modern life such as e-health and psychological treatments. This article presents the design, development, implementation, and assessment of a Robotic Assistant (RA), named “Atent@”, as a support tool in the homework activities of children with Attention Deficit Hyperactivity Disorder (ADHD). Interacting with the children the RA helps them correct their bad habits and misbehavior caused by the disorder. Its features and functionalities were designed by therapists, implementing AI algorithms to process information and make decisions in real-time to help children to be focused on their homework. This RA interacts with smart objects deployed at home, which are associated with the activity under observation (desk and chair). This solution allows therapists to receive more accurate information about the homework sessions inside the home. At the same time, remote interaction with the child is made possible (through the RA) to provide new instructions and support him/her along with the sessions. This RA is a significant evolution of an earlier version. All the improvements brought to the project by the modifications in technical and qualitative features are explained. Furthermore, the experiment and its results are presented to illustrate the clinical potential. This project shows that the RA can not only make observations with a high degree of precision like an expert (teacher/therapist) but also positively influences the homework performance of children with and without ADHD.",https://ieeexplore.ieee.org/document/9466828/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2019.2925087,Automatic Gauge Detection via Geometric Fitting for Safety Inspection,IEEE,Journals,"For safety considerations in electrical substations, the inspection robots are recently deployed to monitor important devices and instruments with the presence of skilled technicians in the high-voltage environments. The captured images are transmitted to a data station and are usually analyzed manually. Toward automatic analysis, a common task is to detect gauges from captured images. This paper proposes a gauge detection algorithm based on the methodology of geometric fitting. We first use the Sobel filters to extract edges which usually contain the shapes of gauges. Then, we propose to use line fitting under the framework of random sample consensus (RANSAC) to remove straight lines that do not belong to gauges. Finally, the RANSAC ellipse fitting is proposed to find most fitted ellipse from the remaining edge points. The experimental results on a real-world dataset captured by the GuoZi Robotics demonstrate that our algorithm provides more accurate gauge detection results than several existing methods.",https://ieeexplore.ieee.org/document/8746263/,IEEE Access,2019,ieeexplore
10.1109/LRA.2017.2737046,Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing,IEEE,Journals,"We demonstrate a low-cost telerobotic system that leverages commercial virtual reality (VR) technology and integrates it with existing robotics control infrastructure. The system runs on a commercial gaming engine using off-the-shelf VR hardware and can be deployed on multiple network architectures. The system is based on the homunculus model of mind wherein we embed the user in a VR control room. The control room allows for multiple sensor displays, and dynamic mapping between the user and robot. This dynamic mapping allows for selective engagement between the user and the robot. We compared our system with state-of-the-art automation algorithms and standard VR-based telepresence systems by performing a user study. The study showed that new users were faster and more accurate than the automation or a direct telepresence system. We also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",https://ieeexplore.ieee.org/document/8003431/,IEEE Robotics and Automation Letters,Jan. 2018,ieeexplore
10.1109/TNN.2010.2060352,"Clifford Support Vector Machines for Classification, Regression, and Recurrence",IEEE,Journals,"This paper introduces the Clifford support vector machines (CSVM) as a generalization of the real and complex-valued support vector machines using the Clifford geometric algebra. In this framework, we handle the design of kernels involving the Clifford or geometric product. In this approach, one redefines the optimization variables as multivectors. This allows us to have a multivector as output. Therefore, we can represent multiple classes according to the dimension of the geometric algebra in which we work. We show that one can apply CSVM for classification and regression and also to build a recurrent CSVM. The CSVM is an attractive approach for the multiple input multiple output processing of high-dimensional geometric entities. We carried out comparisons between CSVM and the current approaches to solve multiclass classification and regression. We also study the performance of the recurrent CSVM with experiments involving time series. The authors believe that this paper can be of great use for researchers and practitioners interested in multiclass hypercomplex computing, particularly for applications in complex and quaternion signal and image processing, satellite control, neurocomputation, pattern recognition, computer vision, augmented virtual reality, robotics, and humanoids.",https://ieeexplore.ieee.org/document/5586658/,IEEE Transactions on Neural Networks,Nov. 2010,ieeexplore
10.1109/ACCESS.2021.3105136,Cocktail Glass Network: Fast Depth Estimation Using Channel to Space Unrolling,IEEE,Journals,"Depth-estimation from a single input image can be used in applications such as robotics and autonomous driving. Recently, depth-estimation networks with UNet encoder/decoder structures have been widely used. In these decoders, operations are repeated to gradually increase the image resolution, while decreasing the channel size. If the upsampling operation at a high magnification can be processed at once, the amount of computation in the decoder can be dramatically reduced. To achieve this, we propose a new network structure, i.e., a cocktail glass network. In this network, convolution layers in the decoder are reduced, and a novel fast upsampling method is used that is known as channel-to-space unrolling, which converts thick channel data into high-resolution data. The proposed method can be easily implemented using simple reshaping operations; therefore, it is suitable for reducing the depth-estimation network. Considering the experimental results based on the NYU V2 and KITTI datasets, we demonstrate that the proposed method reduces the amount of computation in the decoder by half, while maintaining the same level of accuracy; it can be used in both lightweight and large-model-capacity networks.",https://ieeexplore.ieee.org/document/9514839/,IEEE Access,2021,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/TSMC.2020.2967936,Deep Q-Learning With Q-Matrix Transfer Learning for Novel Fire Evacuation Environment,IEEE,Journals,"Deep reinforcement learning (RL) is achieving significant success in various applications like control, robotics, games, resource management, and scheduling. However, the important problem of emergency evacuation, which clearly could benefit from RL, has been largely unaddressed. Indeed, emergency evacuation is a complex task that is difficult to solve with RL. An emergency situation is highly dynamic, with a lot of changing variables and complex constraints that make it challenging to solve. Also, there is no standard benchmark environment available that can be used to train RL agents for evacuation. A realistic environment can be complex to design. In this article, we propose the first fire evacuation environment to train RL agents for evacuation planning. The environment is modeled as a graph capturing the building structure. It consists of realistic features like fire spread, uncertainty, and bottlenecks. The implementation of our environment is in the OpenAI gym format, to facilitate future research. We also propose a new RL approach that entails pretraining the network weights of a DQN-based agent [DQN/Double-DQN (DDQN)/Dueling-DQN] to incorporate information on the shortest path to the exit. We achieved this by using tabular <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-learning to learn the shortest path on the building model’s graph. This information is transferred to the network by deliberately overfitting it on the <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-matrix. Then, the pretrained DQN model is trained on the fire evacuation environment to generate the optimal evacuation path under time varying conditions due to fire spread, bottlenecks, and uncertainty. We perform comparisons of the proposed approach with state-of-the-art RL algorithms like DQN, DDQN, Dueling-DQN, PPO, VPG, state-action-reward-state-action (SARSA), actor–critic method, and ACKTR. The results show that our method is able to outperform state-of-the-art models by a huge margin including the original DQN-based models. Finally, our model is tested on a large and complex real building consisting of 91 rooms, with the possibility to move to any other room, hence giving 8281 actions. In order to reduce the action space, we propose a strategy that involves one step simulation. That is, an action importance vector is added to the final output of the pretrained DQN and acts like an attention mechanism. Using this strategy, the action space is reduced by 90.1%. In this manner, the model is able to deal with large action spaces. Hence, our model achieves near optimal performance on the real world emergency environment.",https://ieeexplore.ieee.org/document/8989970/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Dec. 2021,ieeexplore
10.1109/LRA.2020.2965415,DeepFactors: Real-Time Probabilistic Dense Monocular SLAM,IEEE,Journals,"The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. Different approaches have been proposed that vary in scene geometry representation (sparse landmarks, dense maps), the consistency metric used for optimising the multi-view problem, and the use of learned priors. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance. This is achieved through the use of a learned compact depth map representation and reformulating three different types of errors: photometric, reprojection and geometric, which we make use of within standard factor graph software. We evaluate our system on trajectory estimation and depth reconstruction on realworld sequences and present various examples of estimated dense geometry.",https://ieeexplore.ieee.org/document/8954779/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TNSRE.2013.2294685,"Demonstration of a Semi-Autonomous Hybrid Brain–Machine Interface Using Human Intracranial EEG, Eye Tracking, and Computer Vision to Control a Robotic Upper Limb Prosthetic",IEEE,Journals,"To increase the ability of brain-machine interfaces (BMIs) to control advanced prostheses such as the modular prosthetic limb (MPL), we are developing a novel system: the Hybrid Augmented Reality Multimodal Operation Neural Integration Environment (HARMONIE). This system utilizes hybrid input, supervisory control, and intelligent robotics to allow users to identify an object (via eye tracking and computer vision) and initiate (via brain-control) a semi-autonomous reach-grasp-and-drop of the object by the MPL. Sequential iterations of HARMONIE were tested in two pilot subjects implanted with electrocortico-graphic (ECoG) and depth electrodes within motor areas. The subjects performed the complex task in 71.4% (20/28) and 67.7% (21/31) of trials after minimal training. Balanced accuracy for detecting movements was 91.1% and 92.9%, significantly greater than chance accuracies (p &lt;; 0.05). After BMI-based initiation, the MPL completed the entire task 100% (one object) and 70% (three objects) of the time. The MPL took approximately 12.2 s for task completion after system improvements implemented for the second subject. Our hybrid-BMI design prevented all but one baseline false positive from initiating the system. The novel approach demonstrated in this proof-of-principle study, using hybrid input, supervisory control, and intelligent robotics, addresses limitations of current BMIs.",https://ieeexplore.ieee.org/document/6683036/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,July 2014,ieeexplore
10.1109/LRA.2021.3062323,Differentiable Simulation for Physical System Identification,IEEE,Journals,"Simulating frictional contacts remains a challenging research topic in robotics. Recently, differentiable physics emerged and has proven to be a key element in model-based Reinforcement Learning (RL) and optimal control fields. However, most of the current formulations deploy coarse approximations of the underlying physical principles. Indeed, the classic simulators loose precision by casting the Nonlinear Complementarity Problem (NCP) of frictional contact into a Linear Complementarity Problem (LCP) to simplify computations. Moreover, such methods deploy non-smooth operations and cannot be automatically differentiated. In this letter, we propose (i) an extension of the staggered projections algorithm for more accurate solutions of the problem of contacts with friction. Based on this formulation, we introduce (ii) a differentiable simulator and an efficient way to compute the analytical derivatives of the involved optimization problems. Finally, (iii) we validate the proposed framework with a set of experiments to present a possible application of our differentiable simulator. In particular, using our approach we demonstrate accurate estimation of friction coefficients and object masses both in synthetic and real experiments.",https://ieeexplore.ieee.org/document/9363565/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TPDS.2020.3006238,GPU-Accelerated Real-Time Stereo Estimation With Binary Neural Network,IEEE,Journals,"Depth estimation from stereo images is essential to many applications such as robotics and autonomous vehicles, most of which ask for the real-time response, high energy and storage efficiency. Recent work has shown deep neural networks (DNN) perform extremely well for stereo estimation. However, these state-of-the-art DNN based algorithms are challenging to be deployed into real-world applications due to the high computational complexities of DNNs. Most of them are too slow for real-time inference and require several seconds of GPU computation to process image frames. In this article, we address the problem of fast stereo estimation and propose an efficient and light-weighted stereo matching system, called StereoBit, to produce a disparity map in a real-time manner while achieving close to state-of-the-art accuracy. To achieve this goal, we propose a binary neural network to generate weighted Hamming distance for an efficient similarity join in stereo estimation. In addition, we propose a novel approximation approach to derive StereoBit network directly from the well-trained network with the cosine similarity. Our approximation strategies enable a significant speedup while maintaining almost the same accuracy compared to the network with the cosine similarity. Furthermore, we present an optimization framework for fully exploiting the computing power of StereoBit. The framework provides a significant speedup of stereo estimation routines, and at the same time, reduces the memory usage for storing parameters. The effectiveness of StereoBit is evaluated by comprehensive experiments. StereoBit can achieve 60 frames per second on an NVIDIA TITAN Xp GPU on KITTI 2012 benchmark while achieving 3-pixel non-occluded stereo error 3.56 percent.",https://ieeexplore.ieee.org/document/9130887/,IEEE Transactions on Parallel and Distributed Systems,1 Dec. 2020,ieeexplore
10.1109/TLA.2019.9011550,Gate Detection for Micro Aerial Vehicles using a Single Shot Detector,IEEE,Journals,"Object detection has become an essential tool in aerial robotics thanks to the use of onboard cameras in drones that enables find objects using techniques of vision. However, vision algorithms may become unreliable presenting drawback by the illumination changes. Deep learning has been used to solve tasks of classification, segmentation and detection using traditional Convolutional Neural Network (CNN) like VGG16, YOLO and AlexNet. This paper presents a gates detector system in a real-time using CNN based on a Single Shot Detector Network (SSD) for drone racing circuits. For the latter, we have adopted the SSD7 architecture to modified and present an implementation with five layers, reducing the prediction time and improve detection velocity in comparison with other architectures. For evaluation purpose, we selected three environments: simulation, indoors and outdoors to compare the prediction time, average fps and the confidence obtained in the detections of the gates.",https://ieeexplore.ieee.org/document/9011550/,IEEE Latin America Transactions,December 2019,ieeexplore
10.1109/ACCESS.2021.3109733,Hardware-Aware Affordance Detection for Application in Portable Embedded Systems,IEEE,Journals,"Affordance detection in computer vision allows segmenting an object into parts according to functions that those parts afford. Most solutions for affordance detection are developed in robotics using deep learning architectures that require substantial computing power. Therefore, these approaches are not convenient for application in embedded systems with limited resources. For instance, computer vision is used in smart prosthetic limbs, and in this context, affordance detection could be employed to determine the graspable segments of an object, which is a critical information for selecting a grasping strategy. This work proposes an affordance detection strategy based on hardware-aware deep learning solutions. Experimental results confirmed that the proposed solution achieves comparable accuracy with respect to the state-of-the-art approaches. In addition, the model was implemented on real-time embedded devices obtaining a high FPS rate, with limited power consumption. Finally, the experimental assessment in realistic conditions demonstrated that the developed method is robust and reliable. As a major outcome, the paper proposes and characterizes the first complete embedded solution for affordance detection in embedded devices. Such a solution could be used to substantially improve computer vision based prosthesis control but it is also highly relevant for other applications (e.g., resource-constrained robotic systems).",https://ieeexplore.ieee.org/document/9527234/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2019.2895653,High-Quality 3D Reconstruction With Depth Super-Resolution and Completion,IEEE,Journals,"The 3D reconstruction is an important topic in computer vision with many applications, such as robotics and augmented reality. Since the raw depth images captured by consumer RGB-D cameras are often low resolution (LR), noisy, and incomplete. How to obtain high-quality 3D models with a consumer RGB-D camera is still a challenge for the existing systems. In this paper, we propose a new depth super-resolution and completion method implemented in a deep learning framework and build a high-quality 3D reconstruction system. We first improve the resolution of LR depth image with a depth super-resolution network and remove the outliers in high-resolution (HR) depth image based on gradient saliency. To further enhance the quality of HR depth image with the guide of HR color image, we learn surface normal and occlusion boundary images from the corresponding HR color image through two deep fully convolutional networks. In particular, the blurriness of HR color image is also detected and pixel-wise quantized. Finally, we obtain a completed HR depth image by optimizing the HR depth image with the surface normal, occlusion boundary, and color image blurriness. We have carried out qualitative and quantitative evaluations with baseline methods on public datasets. The experimental results demonstrate that our method has better performance both on single depth image enhancement and 3D reconstruction.",https://ieeexplore.ieee.org/document/8628990/,IEEE Access,2019,ieeexplore
10.1109/LRA.2021.3061336,Imitation Learning of Hierarchical Driving Model: From Continuous Intention to Continuous Trajectory,IEEE,Journals,"One of the challenges to reduce the gap between the machine and the human level driving is how to endow the system with the learning capacity to deal with the coupled complexity of environments, intentions, and dynamics. In this letter, we propose a hierarchical driving model with explicit models of continuous intention and continuous dynamics, which decouples the complexity in the observation-to-action reasoning in the human driving data. Specifically, the continuous intention module takes perception to generate a potential map encoded with obstacles and intentions. Then, the potential map is regarded as a condition, together with the current dynamics, to generate a continuous trajectory as output by a continuous function approximator network, whose derivatives can be used for supervision without additional parameters. Finally, our method is validated by both datasets and stimulation, demonstrating that our method has higher prediction accuracy of displacement and velocity and generates smoother trajectories. Our method is also deployed on the real vehicle with loop latency, validating its effectiveness. To the best of our knowledge, this is the first work to produce the driving trajectory using a continuous function approximator network. Our code is available at https://github.com/ZJU-Robotics-Lab/CICT.",https://ieeexplore.ieee.org/document/9361054/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TLT.2018.2833111,Inquiry-Based Learning With RoboGen: An Open-Source Software and Hardware Platform for Robotics and Artificial Intelligence,IEEE,Journals,"It has often been found that students appreciate hands-on work, and find that they learn more with courses that include a project than those relying solely on conventional lectures and tests. This type of project driven learning is a key component of “Inquiry-based learning” (IBL), which aims at teaching methodology as well as content by incorporating the student as an actor rather than a spectator. Robotics applications are especially well-suited for IBL due to the value of trial and error experience, the multiple possibilities for students to implement their own ideas, and the importance of programming, problem-solving, and electro-mechanical skills in real world engineering and science jobs. Furthermore, robotics platforms can be useful teaching media and learning tools for a variety of topics. Here, we present RoboGen: an open-source, web-based, software, and hardware platform for Robotics and Artificial Intelligence with a particular focus on Evolutionary Robotics. We describe the platform in detail, compare it to existing alternatives, and present results of its use as a platform for Inquiry-based learning within a master's level course at the Ecole Polytechnique Fédérale de Lausanne.",https://ieeexplore.ieee.org/document/8354804/,IEEE Transactions on Learning Technologies,1 July-Sept. 2019,ieeexplore
10.1109/LRA.2018.2870466,Introduction to the Special Issue on AI for Long-Term Autonomy,IEEE,Journals,"The papers in this special section focus on the use of artificial intelligence (AI) for long term autonomy. Autonomous systems have a long history in the fields of AI and robotics. However, only through recent advances in technology has it been possible to create autonomous systems capable of operating in long-term, real-world scenarios. Examples include autonomous robots that operate outdoors on land, in air, water, and space; and indoors in offices, care homes, and factories. Designing, developing, and maintaining intelligent autonomous systems that operate in real-world environments over long periods of time, i.e. weeks, months, or years, poses many challenges. This special issue focuses on such challenges and on ways to overcome them using methods from AI. Long-term autonomy can be viewed as both a challenge and an opportunity. The challenge of long-term autonomy requires system designers to ensure that an autonomous system can continue operating successfully according to its real-world application demands in unstructured and semi-structured environments. This means addressing issues related to hardware and software robustness (e.g., gluing in screws and profiling for memory leaks), as well as ensuring that all modules and functions of the system can deal with the variation in the environment and tasks that is expected to occur over its operating time. ",https://ieeexplore.ieee.org/document/8478420/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2020.3013937,Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning,IEEE,Journals,"Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].",https://ieeexplore.ieee.org/document/9158366/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/JETCAS.2020.3033135,<italic>Learning to Walk</italic>: Bio-Mimetic Hexapod Locomotion via Reinforcement-Based Spiking Central Pattern Generation,IEEE,Journals,"Online learning for the legged robot locomotion under performance and energy constraints remains to be a challenge. Methods such as stochastic gradient, deep reinforcement learning (RL) have been explored for bipeds, quadrupeds and hexapods. These techniques are computationally intensive and thus difficult to implement on edge computing platforms. These methods are also inefficient in energy consumption and throughput because of their reliance on complex sensors and pre-processing of data. On the other hand, neuromorphic computing paradigms, such as spiking neural networks (SNN), become increasingly favorable in low power computing on edge intelligence. SNN has exhibited the capability of performing reinforcement learning mechanisms with biomimetic spike time-dependent plasticity (STDP) of synapses. However, training a legged robot to walk in the synchronized gait patterns generated by a central pattern generator (CPG) in an SNN framework has not yet been explored. Such a method can combine the efficiency of SNNs with the synchronized locomotion of CPG based systems - providing breakthrough performance improvement of end-to-end learning in mobile robotics. In this paper, we propose a reinforcement based stochastic learning technique for training a spiking CPG for a hexapod robot which learns to walk using bio-inspired tripod gait without prior knowledge. The whole system is implemented on a lightweight raspberry pi platform with integrated sensors. Our method opens new opportunities for online learning with limited edge computing resources.",https://ieeexplore.ieee.org/document/9235477/,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,Dec. 2020,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/LRA.2020.2970679,Low to High Dimensional Modality Hallucination Using Aggregated Fields of View,IEEE,Journals,"Real-world robotics systems deal with data from a multitude of modalities, especially for tasks such as navigation and recognition. The performance of those systems can drastically degrade when one or more modalities become inaccessible, due to factors such as sensors' malfunctions or adverse environments. Here, we argue modality hallucination as one effective way to ensure consistent modality availability and thereby reduce unfavorable consequences. While hallucinating data from a modality with richer information, e.g., RGB to depth, has been researched extensively, we investigate the more challenging low-to-high modality hallucination with interesting use cases in robotics and autonomous systems. We present a novel hallucination architecture that aggregates information from multiple fields of view of the local neighborhood to recover the lost information from the extant modality. The process is implemented by capturing a non-linear mapping between the data modalities and the learned mapping is used to aid the extant modality to mitigate the risk posed to the system in the adverse scenarios which involve modality loss. We also conduct extensive classification and segmentation experiments on UWRGBD and NYUD datasets and demonstrate that hallucination allays the negative effects of the modality loss. Implementation and models: https://github.com/kausic94/Hallucination.",https://ieeexplore.ieee.org/document/8977350/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TIM.2018.2884450,Low-order Nonlinear Finite-Impulse Response Soft Sensors for Ionic Electroactive Actuators Based on Deep Learning,IEEE,Journals,"This paper introduces a soft sensor (SS) for the estimation of the deflection of a polymeric mechanical actuator. The actuator is based on ionic polymer-metal composites (IPMCs). Applications of IPMCs have been proposed in fields such as robotics, surgery, and aerospace, to mention the most interesting ones. In such application fields, both the complexity and the size of the actuating system are of chief importance. An SS can be, therefore, preferred to hardware measuring the actuator output, for estimating the actuator motion. Also, low-order models are of interest to limit the computational load, which can be a constraint in real-time applications. To this aim, several data-driven nonlinear finite-impulse response (NFIR) models have been investigated. Data, used for the model identification, have been acquired, in controlled environmental conditions, by using swept signals as the input to the IPMC actuator. Linear and nonlinear models, based on principal component analysis, shallow, and deep neural networks (NNs), have been investigated, for different model orders. The best results have been obtained by an SS based on a fifth-order NFIR model, implemented by a deep belief NN.",https://ieeexplore.ieee.org/document/8584087/,IEEE Transactions on Instrumentation and Measurement,May 2019,ieeexplore
10.1109/TPAMI.2008.260,Monocular Pedestrian Detection: Survey and Experiments,IEEE,Journals,"Pedestrian detection is a rapidly evolving area in computer vision with key applications in intelligent vehicles, surveillance, and advanced robotics. The objective of this paper is to provide an overview of the current state of the art from both methodological and experimental perspectives. The first part of the paper consists of a survey. We cover the main components of a pedestrian detection system and the underlying models. The second (and larger) part of the paper contains a corresponding experimental study. We consider a diverse set of state-of-the-art systems: wavelet-based AdaBoost cascade, HOG/linSVM, NN/LRF, and combined shape-texture detection. Experiments are performed on an extensive data set captured onboard a vehicle driving through urban environment. The data set includes many thousands of training samples as well as a 27-minute test sequence involving more than 20,000 images with annotated pedestrian locations. We consider a generic evaluation setting and one specific to pedestrian detection onboard a vehicle. Results indicate a clear advantage of HOG/linSVM at higher image resolutions and lower processing speeds, and a superiority of the wavelet-based AdaBoost cascade approach at lower image resolutions and (near) real-time processing speeds. The data set (8.5 GB) is made public for benchmarking purposes.",https://ieeexplore.ieee.org/document/4657363/,IEEE Transactions on Pattern Analysis and Machine Intelligence,Dec. 2009,ieeexplore
10.1109/TIE.2016.2597119,Multidimensional Modeling of Physiological Tremor for Active Compensation in Handheld Surgical Robotics,IEEE,Journals,"Precision, robustness, dexterity, and intelligence are the design indices for current generation surgical robotics. To augment the required precision and dexterity into normal microsurgical work-flow, handheld robotic instruments are developed to compensate physiological tremor in real time. The hardware (sensors and actuators) and software (causal linear filters) employed for tremor identification and filtering introduces time-varying unknown phase delay that adversely affects the device performance. The current techniques that focus on three-dimensions (3-D) tip position control involves modeling and canceling the tremor in three axes (x-, y-, and z -axes) separately. Our analysis with the tremor recorded from surgeons and novice subjects shows that there exists significant correlation in tremor across the dimensions. Based on this, a new multidimensional modeling approach based on extreme learning machines is proposed in this paper to correct the phase delay and to accurately model 3-D tremor simultaneously. Proposed method is evaluated through both simulations and experiments. Comparison with the state-of-the art techniques highlight the suitability and better performance of the proposed approach for tremor compensation in handheld surgical robotics.",https://ieeexplore.ieee.org/document/7529172/,IEEE Transactions on Industrial Electronics,Feb. 2017,ieeexplore
10.1109/JPROC.2018.2856739,Navigating the Landscape for Real-Time Localization and Mapping for Robotics and Virtual and Augmented Reality,IEEE,Journals,"Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",https://ieeexplore.ieee.org/document/8436423/,Proceedings of the IEEE,Nov. 2018,ieeexplore
10.1162/089976602760407955,Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations,MIT Press,Journals,"A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.",https://ieeexplore.ieee.org/document/6789852/,Neural Computation,1 Nov. 2002,ieeexplore
10.1109/13.485240,Robotics laboratory exercises,IEEE,Journals,"The authors report new laboratory exercises in robotic manipulation, computer vision, artificial intelligence, and mechatronics, four areas that are central to any robotics curriculum. The laboratory exercises supply the student with hands-on experience that complements classroom lectures and software development. Through this experience, the student confronts the hard realities of robot systems and learns to deal with them. Such hands-on experience is essential for a sound robotics education, because many critical lessons about the real world can only be learned through personal experience.",https://ieeexplore.ieee.org/document/485240/,IEEE Transactions on Education,Feb. 1996,ieeexplore
10.1109/TASE.2019.2940543,Robust Visual Localization in Dynamic Environments Based on Sparse Motion Removal,IEEE,Journals,"Visual localization has been well studied in recent decades and applied in many fields as a fundamental capability in robotics. However, the success of the state of the arts usually builds on the assumption that the environment is static. In dynamic scenarios where moving objects are present, the performance of the existing visual localization systems degrades a lot due to the disturbance of the dynamic factors. To address this problem, we propose a novel sparse motion removal (SMR) model that detects the dynamic and static regions for an input frame based on a Bayesian framework. The similarity between the consecutive frames and the difference between the current frame and the reference frame are both considered to reduce the detection uncertainty. After the detection process is finished, the dynamic regions are eliminated while the static ones are fed into a feature-based visual simultaneous localization and mapping (SLAM) system for further visual localization. To verify the proposed method, both qualitative and quantitative experiments are performed and the experimental results have demonstrated that the proposed model can significantly improve the accuracy and robustness for visual localization in dynamic environments.&lt;;/p&gt;&lt;;p&gt;&lt;;italic&gt;Note to Practitioners&lt;;/italic&gt;-This article was motivated by the visual localization problem in dynamic environments. Visual localization is well applied in many robotic fields such as path planning and exploration as the basic capability for a mobile robot. In the GPS-denied environments, one robot needs to localize itself through perceiving the unknown environment based on a visual sensor. In real-world scenes, the existence of the moving objects will significantly degrade the localization accuracy, which makes the robot implementation unreliable. In this article, an SMR model is designed to handle this problem. Once receiving a frame, the proposed model divides it into dynamic and static regions through a Bayesian framework. The dynamic regions are eliminated, while the static ones are maintained and fed into a feature-based visual SLAM system for further visual localization. The proposed method greatly improves the localization accuracy in dynamic environments and guarantees the robustness for robotic implementation.",https://ieeexplore.ieee.org/document/8855084/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/TASE.2019.2938316,Semiautomatic Labeling for Deep Learning in Robotics,IEEE,Journals,"In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35 000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets. Note to Practitioners-This article was motivated by the lack of a simple and effective solution for the generation of data sets usable to train a data-driven model, such as a modern deep neural network, so as to make them accessible in an industrial environment. Specifically, a deep learning robot guidance vision system would require such a large amount of manually labeled images that it would be too expensive and impractical for a real use case, where system reconfigurability is a fundamental requirement. With our system, on the other hand, especially in the field of industrial robotics, the cost of image labeling can be reduced, for the first time, to nearly zero, thus paving the way for self-reconfiguring systems with very high performance (as demonstrated by our experimental results). One of the limitations of this approach is the need to use a manual method for the detection of objects of interest in the preliminary stages of the pipeline (ARP or graphical interface). A feasible extension, related to the field of collaborative robotics, could be used to exploit the robot itself, manually moved by the user, even for this preliminary stage, so as to eliminate any source of inaccuracy.",https://ieeexplore.ieee.org/document/8844069/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/JSYST.2008.925270,Sonar-Based Rover Navigation for Single or Multiple Platforms: Forward Safe Path and Target Switching Approach,IEEE,Journals,"In this paper, we have proposed a sensor fusion scheme along with the geometrical modeling of mobile robot navigation path in an unknown environment. In this scheme, the physical placement of sonars, their ranging limits and beam opening angles are considered. A simple 2-D axis transformation is proposed to relate local robot frame with the actual navigation environment. forward safe path (FSP) and target switching approach (TSA) are proposed for efficient obstacle avoidance and target tracking of mobile robot. FSP greatly simplifies the environment conditions as sensed by the robot and also provides minimum turning path during avoidance of obstacles. This method also removes the ldquooscillationrdquo in the mobile robot navigation path. TSA technique gives highest priority on the target tracking during the obstacle avoidance and seeks minimum distance path towards the target. These methods remove unnecessary turning of mobile robot during navigation. A scheme for target directional motion is also proposed. So, mobile robot takes the minimum turning path required towards the target. These methods also ensure the avoidance of ldquodead cycle problemrdquo. These schemes are successfully implemented on a model of <i>PatrolBot</i> mobile robot from <i>ActivMedia</i> Robotics. The overview of current research work on multi-domain robotic system namely system-of-systems is also presented. This paper also describes the Global Positioning System-based navigation of rovers. Results of real-time experiments with Pioneer II P2AT-8 from <i>ActivMedia</i> are included in this paper to show the future aspect of this research work.",https://ieeexplore.ieee.org/document/4550588/,IEEE Systems Journal,June 2008,ieeexplore
10.1109/ACCESS.2019.2934998,Survey on Collaborative Smart Drones and Internet of Things for Improving Smartness of Smart Cities,IEEE,Journals,"Smart cities contain intelligent things which can intelligently automatically and collaboratively enhance life quality, save people's lives, and act a sustainable resource ecosystem. To achieve these advanced collaborative technologies such as drones, robotics, artificial intelligence, and Internet of Things (IoT) are required to increase the smartness of smart cities by improving the connectivity, energy efficiency, and quality of services (QoS). Therefore, collaborative drones and IoT play a vital role in supporting a lot of smart-city applications such as those involved in communication, transportation, agriculture,safety and security, disaster mitigation, environmental protection, service delivery, energy saving, e-waste reduction, weather monitoring, healthcare, etc. This paper presents a survey of the potential techniques and applications of collaborative drones and IoT which have recently been proposed in order to increase the smartness of smart cities. It provides a comprehensive overview highlighting the recent and ongoing research on collaborative drone and IoT in improving the real-time application of smart cities. This survey is different from previous ones in term of breadth, scope, and focus. In particular, we focus on the new concept of collaborative drones and IoT for improving smart-city applications. This survey attempts to show how collaborative drones and IoT improve the smartness of smart cities based on data collection, privacy and security, public safety, disaster management, energy consumption and quality of life in smart cities. It mainly focuses on the measurement of the smartness of smart cities, i.e., environmental aspects, life quality, public safety, and disaster management.",https://ieeexplore.ieee.org/document/8795473/,IEEE Access,2019,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/TC.2020.3038286,Task Splitting and Load Balancing of Dynamic Real-Time Workloads for Semi-Partitioned EDF,IEEE,Journals,"Many real-time software systems, such as those commonly found in the context of multimedia, cloud computing, robotics, and real-time databases, are characterized by a dynamic workload, where applications can join and leave the system at runtime. Global schedulers can transparently support dynamic workload without requiring any off-line task-allocation phase, thus providing advantages to the system designer. Nevertheless, such schedulers exhibit poor worst-case performance when compared to semi-partitioned schedulers, which instead can achieve near-optimal schedulability performance when used in conjunction with smart task splitting and partitioning techniques, and they are also lighter in terms of run-time overhead. This article proposes an approach to efficiently schedule dynamic real-time workloads on multiprocessor systems by means of semi-partitioned scheduling. A linear-time approximation scheme for the C=D splitting algorithm under partitioned EDF scheduling is proposed. Then, a load-balancing algorithm is presented to admit new real-time workloads with a limited number of re-allocations. The article finally reports on a large-scale experimental study showing that (i) the linear-time approximation is characterized by a very limited utilization loss compared with the corresponding exact approach (that has a much higher complexity), and that (ii) the whole approach allows achieving considerable improvements with respect to global and partitioned EDF scheduling.",https://ieeexplore.ieee.org/document/9261105/,IEEE Transactions on Computers,1 Dec. 2021,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TCDS.2018.2826921,The Perception of Emotion in Artificial Agents,IEEE,Journals,"Given recent technological developments in robotics, artificial intelligence, and virtual reality, it is perhaps unsurprising that the arrival of emotionally expressive and reactive artificial agents is imminent. However, if such agents are to become integrated into our social milieu, it is imperative to establish an understanding of whether and how humans perceive emotion in artificial agents. In this review, we incorporate recent findings from social robotics, virtual reality, psychology, and neuroscience to examine how people recognize and respond to emotions displayed by artificial agents. First, we review how people perceive emotions expressed by an artificial agent, such as facial and bodily expressions. Second, we evaluate the similarities and differences in the consequences of perceived emotions in artificial compared to human agents. Besides accurately recognizing the emotional state of an artificial agent, it is critical to understand how humans respond to those emotions. Does interacting with an angry robot induce the same responses in people as interacting with an angry person? Similarly, does watching a robot rejoice when it wins a game elicit similar feelings of elation in the human observer? Here, we provide an overview of the current state of emotion expression and perception during interactions with artificial agents, as well as a clear articulation of the challenges and guiding principles to be addressed as we move ever closer to truly emotional artificial agents.",https://ieeexplore.ieee.org/document/8341761/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2018,ieeexplore
10.1109/TPAMI.2004.1262308,The writer independent online handwriting recognition system frog on hand and cluster generative statistical dynamic time warping,IEEE,Journals,"In this paper, we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach, which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general, scalable, HMM-based method for variable-sized, sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is significantly higher than reported results of other handwriting recognition systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq iPAQ embedded device.",https://ieeexplore.ieee.org/document/1262308/,IEEE Transactions on Pattern Analysis and Machine Intelligence,March 2004,ieeexplore
10.1109/ACCESS.2019.2939195,Toward a Clustering-Based Approach for Self-Adjusting Impact Factors in Robotic Control Model,IEEE,Journals,"In mobile robotic control models, control parameters are always generated by sensors' information and a set of Impact Factors (IFs, such as the P-value in the PID model). The IFs take forms of fixed coefficients in control models and need to be pre-defined at design-time. However, when operating in an open environment, IFs of the control model are expected to be adjusted automatically at run-time in order to adapt to the environment changes and improve the operation of robotics. This paper presents a clustering-based approach to continuously updating the IFs in robot control model. The proposed approach utilizes the density-based clustering method to classify environmental changes based on the effects of these changes on robots. In each cluster, the regression method is designed to learn the relationship between IFs and environment changes, and therefore generate corresponding IF adjustment model. Such approach can decrease the mutual interference of environmental changes and enhance the rationality of robotic actions. The paper presents the self-adjusting framework and designs corresponding IFs update algorithms. This paper develops robotics path-following scenario and object-following scenario in open environment and conducts experiments to evaluate the effectiveness of the proposed approach. The results show that the proposed approach has faster response to environmental changes than DQN and MPC approaches, along with a lower deviation of robot's actions.",https://ieeexplore.ieee.org/document/8822939/,IEEE Access,2019,ieeexplore
10.1109/LRA.2021.3123374,Uncertainty for Identifying Open-Set Errors in Visual Object Detection,IEEE,Journals,"Deployed into an open world, object detectors are prone to open-set errors, false positive detections of object classes not present in the training dataset.We propose GMM-Det, a real-time method for extracting epistemic uncertainty from object detectors to identify and reject open-set errors. GMM-Det trains the detector to produce a structured logit space that is modelled with class-specific Gaussian Mixture Models. At test time, open-set errors are identified by their low log-probability under all Gaussian Mixture Models. We test two common detector architectures, Faster R-CNN and RetinaNet, across three varied datasets spanning robotics and computer vision. Our results show that GMM-Det consistently outperforms existing uncertainty techniques for identifying and rejecting open-set detections, especially at the low-error-rate operating point required for safety-critical applications. GMM-Det maintains object detection performance, and introduces only minimal computational overhead. We also introduce a methodology for converting existing object detection datasets into specific <italic>open-set</italic> datasets to evaluate open-set performance in object detection.",https://ieeexplore.ieee.org/document/9591346/,IEEE Robotics and Automation Letters,Jan. 2022,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/SNPD.2013.12,A Fast Genetic SLAM Approach for Mobile Robots,IEEE,Conferences,"This paper presents a new SLAM (simultaneous localization and mapping) method using genetic algorithm (GA) for mobile robots. A laser range finder (LRF) is installed on a mobile robot for collecting point-distance information about the surroundings. From the LRF points, several important ones are extracted for describing the main features of the surroundings. A new form of chromosomes for representing the changes of feature LRF points that are caused by the robot's movement is designed. The matching of current LRF features and the robot's possible movement is done by a fast genetic algorithm. A restart mechanism that re-initializes all chromosomes for increasing the diversity of solutions is developed and works with the matching process. Some constrains are developed for filtering out irrational chromosomes after the operation of crossover and mutation. With these mechanisms and constrains, our proposed method generates feasible solutions in several hundreds of GA iterations. Experiments are conducted on a real mobile robot. The experimental results show that our proposed method is efficient and effective for SLAM.",https://ieeexplore.ieee.org/document/6598520/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore
10.1109/UR49135.2020.9144789,A Markerless Deep Learning-based 6 Degrees of Freedom Pose Estimation for Mobile Robots using RGB Data,IEEE,Conferences,"Augmented Reality has been subject to various integration efforts within industries due to its ability to enhance human machine interaction and understanding. Neural networks have achieved remarkable results in areas of computer vision, which bear great potential to assist and facilitate an enhanced Augmented Reality experience. However, most neural networks are computationally intensive and demand huge processing power, thus are not suitable for deployment on Augmented Reality devices. In this work, we propose a method to deploy state of the art neural networks for real time 3D object localization on augmented reality devices. As a result, we provide a more automated method of calibrating the AR devices with mobile robotic systems. To accelerate the calibration process and enhance user experience, we focus on fast 2D detection approaches which are extracting the 3D pose of the object fast and accurately by using only 2D input. The results are implemented into an Augmented Reality application for intuitive robot control and sensor data visualization. For the 6D annotation of 2D images, we developed an annotation tool, which is, to our knowledge, the first open source tool to be available. We achieve feasible results which are generally applicable to any AR device, thus making this work promising for further research in combining high demanding neural networks with Internet of Things devices.",https://ieeexplore.ieee.org/document/9144789/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ICRA48506.2021.9561722,A Scavenger Hunt for Service Robots,IEEE,Conferences,"Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",https://ieeexplore.ieee.org/document/9561722/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/iCREATE.2014.6828372,A comparison of various robotic control architectures for autonomous navigation of mobile robots,IEEE,Conferences,"For mobile robots, the most fundamental and pressing issue is that of autonomous navigation. Successful navigation of mobile robots is closely dependent on four vitals i.e. perception, localization, cognition and motion control. Implementation of each of these vital blocks requires consideration of at least one of the two well-known control architectures Deliberative Navigation Control and Reactive Navigation Control or a combination of the two, also known as a Hybrid Navigation Control. This paper compares each of these control architectures on the basis of their flexibility, ease of implementation, reactivity, robustness, efficiency and many other architecture specifications. The paper concludes with suggesting the schema that seems to be the best of each of these control schemes, on the basis of the analysis made, in order to cope with unknown and dynamic navigation problems encountered in real life scenarios.",https://ieeexplore.ieee.org/document/6828372/,2014 International Conference on Robotics and Emerging Allied Technologies in Engineering (iCREATE),22-24 April 2014,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1049/cp:19940180,A novel neural adaptive controller for robots,IET,Conferences,"Existing industrial robotic manipulators have proven to be limited in many applications, e.g. both their payload capability and manipulation speeds are limited. This paper presents a novel neural adaptive controller-intelligent gain scheduling-(IGS) for robotic manipulators. It advances the idea of mapping the nonlinear relationship between robot working conditions (e.g. payload, speed, etc.) and its controller gains. This scheme is simple, inexpensive, and especially, attractive for its possible implementation in real-time. Simulation has shown promising results.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/327097/,1994 International Conference on Control - Control '94.,21-24 March 1994,ieeexplore
10.1109/AIM.2001.936513,A radial basis function networks approach for the tracking problem of mobile robots,IEEE,Conferences,Proposes a radial basis function network (RBFN) approach to the solution of the tracking problem for mobile robots. RBFN-based controllers are investigated in order to introduce some degree of robustness in the control system and to avoid the main disadvantage of multilayer neural networks (MNN) to be highly nonlinear in the parameters. The training of the nets and the control performances analysis have been done in a real experimental setup. The proposed solutions are implemented on a PC-based control architecture for the real-time control of the LabMate mobile base and are compared with MNN-based control schemes. The experimental results are satisfactory in terms of tracking errors and computational efforts.,https://ieeexplore.ieee.org/document/936513/,2001 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Proceedings (Cat. No.01TH8556),8-12 July 2001,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ICARCV.2012.6485305,A robust real-time tracking system based on an adaptive selection mechanism for mobile robots,IEEE,Conferences,"Extensive research has been conducted in the domain of object tracking. Among the existing tracking methods, most of them mainly focus on using various cues such as color, texture, contour, features, motion as well as depth information to achieve a robust tracking performance. The tracking methods themselves are highly emphasized while properties of the objects to be tracked are usually not exploited enough. In this paper, we first propose a novel adaptive tracking selection mechanism dependent on the properties of the objects. The system will automatically choose the optimal tracking algorithm after examining the textureness of the object. In addition, we propose a robust tracking algorithm for uniform objects based on color information which can cope with real world constraints. In the mean time, we deployed a textured object tracking algorithm which combines the Lucas-Kanade tracker and a model based tracker using the Random Forests classifier. The whole system was tested and the experimental results on a variety of objects show the effectiveness of the adaptive tracking selection mechanism. Moreover, the promising tracking performance shows the robustness of the proposed tracking algorithm. The computation cost of the algorithm is very low, which proves that it can be further used in various real-time robotics applications.",https://ieeexplore.ieee.org/document/6485305/,2012 12th International Conference on Control Automation Robotics & Vision (ICARCV),5-7 Dec. 2012,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ROBIO.2009.5420410,AMF: A novel reactive approach for motion planning of mobile robots in unknown dynamic environments,IEEE,Conferences,"This paper presents a new approach based on Artificial Potential Fields (APF) which provides real-time and very effective methodology for practical motion planners in unknown dynamic environments. The Maxwell's equations are exploited to define Artificial Magnetoquasistatic Fields (AMF) as an extension of APF, which provides a predictive, intelligent, and natural behavior in contrast with other approaches. The essential aim of the AMF is dealing with moving obstacles, as well as static ones. The main idea is to consider an electrical current in the direction of each moving obstacle which induces magnetic field around it. These moving obstacles could be arbitrary in shape, size, and number. Neither the motion-trajectory of the moving obstacles nor the model of their motion is known. The only available information is their instantaneous velocity at each time step. In this method, the magnetoquasistatic approximation is used to obtain the electric and magnetic fields around robot. Next, using Lorentz equation, the necessary force can be calculated which should be applied to robot to avoid the collision with obstacles. A path planner based on this approach has been implemented and tested by various scenarios containing both static and moving obstacles. Simulations and experimental results illustrate the efficacy of the proposed method.",https://ieeexplore.ieee.org/document/5420410/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/DevLrn.2012.6400818,ASP+POMDP: Integrating non-monotonic logic programming and probabilistic planning on robots,IEEE,Conferences,"Mobile robots equipped with multiple sensors and deployed in real-world domains frequently find it difficult to process all sensor inputs, or to operate without any human input and domain knowledge. At the same time, robots cannot be equipped with all relevant domain knowledge in advance, and humans are unlikely to have the time and expertise to provide elaborate and accurate feedback. This paper presents a novel framework that addresses these challenges by integrating high-level logical inference with low-level probabilistic sequential decision-making. Specifically, Answer Set Programming (ASP), a non-monotonic logic programming paradigm, is used to represent, reason with and revise domain knowledge obtained from sensor inputs and high-level human feedback, while hierarchical partially observable Markov decision processes (POMDPs) are used to automatically adapt visual sensing and information processing to the task at hand. Furthermore, a psychophysics-inspired strategy is used to merge the output of logical inference with probabilistic beliefs. All algorithms are evaluated in simulation and on wheeled robots localizing target objects in indoor domains.",https://ieeexplore.ieee.org/document/6400818/,2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL),7-9 Nov. 2012,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/ISCID.2008.170,An Emotion Generation Model for Interactive Virtual Robots,IEEE,Conferences,"Making a computer generate its own emotion is an important part of the affective computing, and this would have wide applications in human-computer interaction and artificial intelligence. In this paper, we will describe an emotion generation model for a multimodal virtual human. The relationship among the emotion, mood and personality are discussed firstly, and the PAD (pleasure-arousal-dominance) emotion space is used to define the emotion and the mood. Then, we use a random graphical model to generate emotion based on the evaluation of the overall influence of mood, previous emotion and the outside stimulations. Finally, a 3D virtual human head with facial expressions is designed to show the emotion generation outputs. Experimental results demonstrate that the emotion generation model based on random graphs works effectively and meets the basic principle of human emotion generation.",https://ieeexplore.ieee.org/document/4725498/,2008 International Symposium on Computational Intelligence and Design,17-18 Oct. 2008,ieeexplore
10.1109/COASE.2018.8560532,An EtherCAT-Based Real-Time Control System Architecture for Humanoid Robots,IEEE,Conferences,"The design of humanoid robots naturally requires the simultaneous control of a high number of joints. Moreover, the performance of the overall robot is strongly determined by the low-level control system as all high-level software e.g. for locomotion planning and control is built on top of it. In order to achieve high update rates and high bandwidth for the joint control, an advanced real-time control system architecture is required. However, outdated communication protocols with associated limits in the achievable update rates are still used in nowadays humanoid robots. Moreover, the performance of the low-level control systems is not analyzed in detail or the systems rely on specialized hardware, which lacks reliability and persistence. We present a reliable and high-performance control system architecture for humanoid robots based on the ETHERCAT technology. To the authors' knowledge this is the only system, which operates at control rates beyond 2 khz and input/output latencies below 1 ms. Our control architecture includes a learning-based feedforward control strategy to improve joint tracking performance. The improved joint control method and the communication system are evaluated on our humanoid robot LOLA. Our software framework is available online to allow other researchers to benefit from our experiences.",https://ieeexplore.ieee.org/document/8560532/,2018 IEEE 14th International Conference on Automation Science and Engineering (CASE),20-24 Aug. 2018,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/CCECE.1993.332425,An adaptive control scheme for robots with unknown dynamics,IEEE,Conferences,"In this paper, a stable adaptive control scheme for robot manipulators with unknown dynamics is proposed. It consists of an off-line least-mean-square (LMS) type identifier to identify structured system dynamics and an online dynamic compensator to compensating for dynamic uncertainties. Taking advantage of the unique structure of the robot regressor dynamics, the former uses an LMS type algorithm to identify, using a set of trial data, the structured dynamic parameters of the robot while the latter uses an online stable parameter updating mechanism determined using Lyapunov theory to compensate for both unknown and uncertain dynamics. The off-line identified parameters we used as initial values for the online dynamic parameter estimation. Since both identifier and compensator are implemented using the regressor dynamics, the recursive formula, for the computation of robot regressor dynamics previously proposed can be used to achieve high computational efficiency in real-time implementations. An illustrative simulation example is included to show the proposed adaptive control algorithm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/332425/,Proceedings of Canadian Conference on Electrical and Computer Engineering,14-17 Sept. 1993,ieeexplore
10.1109/ROBIO.2013.6739426,An improved neuro-dynamics-based approach to online path planning for multi-robots in unknown dynamic environments,IEEE,Conferences,"Online path planning for multi-robots in complicated and dynamic environments is a difficult and hot issue in the field of robotics. Many traditional path planning methods cannot meet the requirements of online and real-time processing. Neuro-dynamics-based method has an aptitude for online and real-time path planning in complicated and dynamic environments. However, this method still has shortcomings. In this paper, an improved neuro-dynamics-based method is proposed with advantages. It has conducted efficient performance and easier realization with much less computational time complexity. Meanwhile, by entering “repulsion” mechanism, the improved method is capable of fair allocation and load balancing on the limited resources. Both simulated experiments and theoretical analysis demonstrate the feasibility and availability of the improved method in the paper.",https://ieeexplore.ieee.org/document/6739426/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/ISMS.2010.32,Application of Feed-Forward Neural Network and MMI-Supervised Vector Quantizer to the Task of Content Based Audio Segmentation by Co-operative Unmanned Flying Robots,IEEE,Conferences,"This paper deals with the preliminary experiments on general audio segmentation using a MMI-supervised tree-based vector quantizer and feed-forward neural network. This method has been tested with the aim of detection of environmental sounds and speech in a sound stream. The segmentation of an audio stream is needed for successful localization of speech or environmental sounds in a stream and their possible future classification or even separation. This method has been developed as a preliminary solution of the task of real-world audio signal segmentation by a set of co-operative unmanned flying robots. Application of the proposed method has been tested in simulating software NESCUAR 1.0. (Natural Environment Simulator for Cooperative Unmanned Aerial Robots, version 1.0), a simulating software tool developed by the authors of this paper. The presented method can be also applied separately; its application is not dependent on the simulating software NESCUAR 1.0.",https://ieeexplore.ieee.org/document/5416111/,"2010 International Conference on Intelligent Systems, Modelling and Simulation",27-29 Jan. 2010,ieeexplore
10.1109/RTSE.1998.766515,Application of mobile autonomous robots to artificial intelligence and information systems curricula,IEEE,Conferences,"Applies pedagogical ideas of teaching curricula by using strategies of themes and breadth-first coverage, together with the technology of intelligent agents (e.g. mobile autonomous robots), to a system of courses in computer science (artificial intelligence) and information systems (systems engineering). The project brings the issues and constraints of real-time systems, especially the programming component, to students in computer science and information systems curricula. This project's background started in June 1997 and continued during the first part of the 1997-1998 academic year. The actual project work started in January 1998 and is still continuing.",https://ieeexplore.ieee.org/document/766515/,Proceedings Real-Time Systems Education III,21-21 Nov. 1998,ieeexplore
10.1109/ROBOT.1993.291974,Application of neural network with real-time training to robust position/force control of multiple robots,IEEE,Conferences,A robust controller that compensates the uncertainties of the dynamic system of the multiple robotic system in order to obtain good tracking performance of position and force simultaneously while satisfying the constraint conditions is presented. A neural network architecture is proposed as one approach to its design and implementation. An online learning rule is provided for repeatedly assigned tasks so that the system is robust to the structured and unstructured uncertainties and the controller adjusts itself repeatedly to improve the performance progressively for each repeated task.&lt;<ETX>&gt;</ETX>,https://ieeexplore.ieee.org/document/291974/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/IROS45743.2020.9341340,Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots,IEEE,Conferences,"The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",https://ieeexplore.ieee.org/document/9341340/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/FIE.2006.322654,Autonomous Robots as a Generic Teaching Tool,IEEE,Conferences,"An undergraduate bioengineering laboratory course using small autonomous robots has been developed to demonstrate control theory, learning, and behavior. The lab consists of several modules that demonstrate concepts in classical control theory, fuzzy logic, neural network control, and genetic algorithms. The autonomous agents are easy-to-build, inexpensive kit robots. Each robot functions independently in a real-world environment. Students program and retrieve data wirelessly using handheld computers. The hands-on nature of the lab modules engages students in ways that lectures, readings and software simulations cannot. By interacting with these robots, students directly experience the effects of unexpected environmental factors on designs and deviations from software simulations. The robots are easily adapted for use in many different aspects of two-year college and K-12 STEM education. Students are motivated to understand engineering, math and science principles in order to control the robots. Examples of use of the robots and modules by a local community college are presented",https://ieeexplore.ieee.org/document/4117154/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/AERO47225.2020.9172804,Autonomous Search for Underground Mine Rescue Using Aerial Robots,IEEE,Conferences,"In this paper we present a comprehensive solution for autonomous underground mine rescue using aerial robots. In particular, a new class of Micro Aerial Vehicles are equipped with the ability to localize and map in subterranean settings, explore unknown mine environments on their own, and perform detection and localization of objects of interest for the purposes of mine rescue (i.e., “human survivors” and associated objects such as “backpacks”, “smartphones” or “tools”). For the purposes of GPS-denied localization and mapping in the visually-degraded underground environments (e.g., a smoke-filled mine during an accident) the solution relies on the fusion of LiDAR data with thermal vision frames and inertial cues. Autonomous exploration is enabled through a graph-based search algorithm and an online volumetric representation of the environment. Object search is then enabled through a deep learning-based classifier, while the associated location is queried using the online reconstructed map. The complete software framework runs onboard the aerial robots utilizing the integrated embedded processing resources. The overall system is extensively evaluated in real-life deployments in underground mines.",https://ieeexplore.ieee.org/document/9172804/,2020 IEEE Aerospace Conference,7-14 March 2020,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/SSCI.2018.8628809,Bidirectional Fuzzy Brain Emotional Learning Control for Aerial Robots,IEEE,Conferences,This paper proposes a Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control system to control Aerial Robots. The proposed controller is based on the emotional and logical processing of the brain. The proposed control system merges fuzzy inference and a bidirectional brain emotional learning algorithm. The Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control can learn from scratch and adapt rapidly in real-time to control the system without much prior information. The proposed controller is tested against simulations of both a 1-Degree-Of-Freedom (DOF) flapping wing and a 6DOF flapping wing model and successfully implemented on a 1DOF flapping wing experiment which showcases the learning and adaptation capability in a real-time environment.,https://ieeexplore.ieee.org/document/8628809/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/IECON.2007.4460382,Biomimetics Robots From Bio-inspiration to Implementation,IEEE,Conferences,"Biomimetics focuses on making nature as a model of inspiration that would immensely help conscious abstraction of new principles and ideas, foster innovative design collections, find out new techniques and functionalities, seek new paradigms and methods, develop new materials, and design new streams of intelligent machines, robots, systems, devices, algorithms, etc. Biomimetics incorporates materials, concepts and techniques drawn from naturally made substances, and resembles biological systems in structure, mechanism and/or function as necessary. Smart materials are the foundation supporting the development of new biomimetic based technology. Wide range of biologically inspired robots and intelligent systems has been developed. However, engineering such biomimetic intelligent creatures were hampered by physical and technological constraints, and it is still a challenge. Making robots and intelligent machines that are actuated by biologically inspired artificial muscles would create new reality with great potentials. This paper provides the concept and the importance of Biomimetic as an interdisciplinary field. In addition, the paper introduces and discusses scientific ideas and directions of research activities in the field. The paper presents key development in the field of Biomimetic robots, and finally it underlines the potential of the field and the challenges facing it.",https://ieeexplore.ieee.org/document/4460382/,IECON 2007 - 33rd Annual Conference of the IEEE Industrial Electronics Society,5-8 Nov. 2007,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/ROMAN.2005.1513816,Cognitive robots: perceptual associative memory and learning,IEEE,Conferences,"In this position paper we attempt to derive an architecture and mechanism for perceptual associative memory and learning for software agents and cognitive robots from what is known, or believed, about the same faculties in human and other animal cognition. Based on that of the IDA model of global workspace theory, a conceptual and computational model of cognition, this architecture, together with its mechanisms, offers the real possibility of autonomous software agents and cognitive robots learning their own ontologies during a developmental period. Thus the onerous chore of designing and implementing such an ontology can be avoided.",https://ieeexplore.ieee.org/document/1513816/,"ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",13-15 Aug. 2005,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ROBOT.1998.677351,Cooperative behavior acquisition in multi-mobile robots environment by reinforcement learning based on state vector estimation,IEEE,Conferences,"This paper proposes a method that acquires robots' behaviors based on the estimation of the state vectors. In order to acquire the cooperative behaviors in multi-robot environments, each learning robot estimates the local predictive model between the learner and the other objects separately. Based on the local predictive models, the robots learn the desired behaviors using reinforcement learning. The proposed method is applied to a soccer playing situation, where a rolling ball and other moving robots are well modeled and the learner's behaviors are successfully acquired by the method. Computer simulations and real experiments are shown and a discussion is given.",https://ieeexplore.ieee.org/document/677351/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ISIC.2000.882949,Cooperative learning and planning for multiple robots,IEEE,Conferences,"The paper deals with the the subject of learning and planning for real mobile robots, using Sutton's (1991) Dyna algorithm. The Dyna algorithm integrates reinforcement learning, planning and reactive execution. We present an extension of the Dyna algorithm which includes symmetric and cooperative learning with multiple robots. We applied the extended version of the algorithm to a population of two real robots. Practical problems associated with the implementation of the algorithm on a real setup are solved. Results obtained from simulations and real experiments are presented and discussed.",https://ieeexplore.ieee.org/document/882949/,Proceedings of the 2000 IEEE International Symposium on Intelligent Control. Held jointly with the 8th IEEE Mediterranean Conference on Control and Automation (Cat. No.00CH37147),19-19 July 2000,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICRA48506.2021.9562019,Decentralized Circle Formation Control for Fish-like Robots in the Real-world via Reinforcement Learning,IEEE,Conferences,"In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",https://ieeexplore.ieee.org/document/9562019/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/ICUAS.2019.8797770,Deep learning based semantic situation awareness system for multirotor aerial robots using LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots, based on 2D LIDAR measurements, targeting the understanding of the environment and assuming to have a precise robot localization as an input of our algorithm. Our proposed situation awareness system calculates a semantic map of the objects of the environment as a list of circles represented by their radius, and the position and the velocity of their center in world coordinates. Our proposed algorithm includes three main parts. First, the LIDAR measurements are preprocessed and an object segmentation clusters the candidate objects present in the environment. Secondly, a Convolutional Neural Network (CNN) that has been designed and trained using an artificially generated dataset, computes the radius and the position of the center of individual circles in sensor coordinates. Finally, an indirect-EKF provides the estimate of the semantic map in world coordinates, including the velocity of the center of the circles in world coordinates.We have quantitative and qualitative evaluated the performance of our proposed situation awareness system by means of Software-In-The-Loop simulations using VRep with one and multiple static and moving cylindrical objects in the scene, obtaining results that support our proposed algorithm. In addition, we have demonstrated that our proposed algorithm is capable of handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) and moving (i.e. a person) objects.",https://ieeexplore.ieee.org/document/8797770/,2019 International Conference on Unmanned Aircraft Systems (ICUAS),11-14 June 2019,ieeexplore
10.1109/ISORC.2019.00025,DeepNNCar: A Testbed for Deploying and Testing Middleware Frameworks for Autonomous Robots,IEEE,Conferences,"This demo showcases the features of an adaptive middleware framework for resource constrained autonomous robots like DeepNNCar (Figure 1). These robots use Learning Enabled Components (LECs), trained with deep learning models to perform control actions. However, these LECs do not provide any safety guarantees and testing them is challenging. To overcome these challenges, we have developed an adaptive middleware framework that (1) augments the LEC with safety controllers that can use different weighted simplex strategies to improve the systems safety guarantees, and (2) includes a resource manager to monitor the resource parameters (temperature, CPU Utilization), and offload tasks at runtime. Using DeepNNCar we will demonstrate the framework and its capability to adaptively switch between the controllers and strategies based on its safety and speed performance.",https://ieeexplore.ieee.org/document/8759365/,2019 IEEE 22nd International Symposium on Real-Time Distributed Computing (ISORC),7-9 May 2019,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/CMCSN.2012.100,Experimental Study on Long-Range Navigation Behavior of Agricultural Robots,IEEE,Conferences,"In this paper, we study on the navigating bahevior of CRFNFP[1]-based agricultual robots in real scenes. We designed two sets of experiments and three navigating system with different configuration of software for comparative study. The experimental results indicate that, compared to the traditional local-map-based navigating systems, the CRFNFP-based navigating system does enhance the long-range perception for mobile robots and helps planning more efficient paths for the navigation.",https://ieeexplore.ieee.org/document/6245858/,"2012 International Conference on Computing, Measurement, Control and Sensor Network",7-9 July 2012,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/ICSyS47076.2019.8982469,FPGA-enabled Binarized Convolutional Neural Networks toward Real-time Embedded Object Recognition System for Service Robots,IEEE,Conferences,"In this presentation, we report the results of applying a binarized Convolutional Neural Network (CNN) and a Field Programmable Gate Array (FPGA) for image-based object recognition. While the demand rises for robots with robust object recognition implemented with Neural Networks, a tradeoff between data processing rate and power consumption persists. Some applications utilise Graphics Processing Units (GPU), which results in high power consumption, thus undesirable for embedded systems, while the others communicate with cloud computers to minimise computational resources at the clients' side, i.e. robots, raising another concern that the robots are unable to perform object recognition without the servers and network connections. To overcome these difficulties, we propose an embedded object recognition system implemented with a binarized CNN and an FPGA. FPGAs consist of a matrix of reconfigurable logic gates allowing parallel computing which befit most image processing algorithms such as the CNN. We train the binarized CNN on one of our datasets that contain images of several kinds of food and beverages. The results of the experiments show that the binarized CNN with an FPGA maintains high accuracy as well as real-time computation, suggesting that the proposed system is suitable for robots to perform their tasks in a real-world environment without needing to communicate with a server.",https://ieeexplore.ieee.org/document/8982469/,2019 IEEE International Circuits and Systems Symposium (ICSyS),18-19 Sept. 2019,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
,Giving robots a flexible persona: The five factor model of artificial personality in action,IEEE,Conferences,"A computational framework for artificial personality in cognitive robots is introduced. While every robot has some form of personality, the framework reported here is flexible and enables the exploration of different behaviors on the same robotic platform. The framework described here maintains a probabilistic representation of an internal state that includes emotion, motivation, sensing, and previous action. The next action is computed by using a massive number of rules implemented using Bayes Rule. This flexible Bayesian representation of personality allows the robots personality to be designed by a personality generator algorithm. The authors present results in a real robot and compare the behavior of robots with differing personalities.",https://ieeexplore.ieee.org/document/6393419/,"2012 12th International Conference on Control, Automation and Systems",17-21 Oct. 2012,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/CEC.2009.4983067,HyperNEAT controlled robots learn how to drive on roads in simulated environment,IEEE,Conferences,"In this paper we describe simulation of autonomous robots controlled by recurrent neural networks, which are evolved through indirect encoding using HyperNEAT algorithm. The robots utilize 180 degree wide sensor array. Thanks to the scalability of the neural network generated by HyperNEAT, the sensor array can have various resolution. This would allow to use camera as an input for neural network controller used in real robot. The robots were simulated using software simulation environment. In the experiments the robots were trained to drive with imaximum average speed. Such fitness forces them to learn how to drive on roads and avoid collisions. Evolved neural networks show excellent scalability. Scaling of the sensory input breaks performance of the robots, which should be gained back with re-training of the robot with a different sensory input resolution.",https://ieeexplore.ieee.org/document/4983067/,2009 IEEE Congress on Evolutionary Computation,18-21 May 2009,ieeexplore
10.1109/AIIoT52608.2021.9454183,Image Classification with Knowledge-Based Systems on the Edge for Real-Time Danger Avoidance in Robots,IEEE,Conferences,"Mobile robots are increasingly common in society and are increasingly being used for complex and high-stakes tasks such as search and rescue. The growing requirements for these robots demonstrate a need for systems which can review and react in real time to environmental hazards, which will allow robots to handle environments that are both dynamic and dangerous. We propose and test a system which allows mobile robots to reclassify environmental objects during operation in conjunction with an edge system. We train an image classification model with 99 percent accuracy and deploy it in conjunction with an edge server and JSON-based ruleset to allow robots to react to and avoid hazards.",https://ieeexplore.ieee.org/document/9454183/,2021 IEEE World AI IoT Congress (AIIoT),10-13 May 2021,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/IJCNN.2014.6889647,Intelligent Facial Action and emotion recognition for humanoid robots,IEEE,Conferences,"This research focuses on the development of a realtime intelligent facial emotion recognition system for a humanoid robot. In our system, Facial Action Coding System is used to guide the automatic analysis of emotional facial behaviours. The work includes both an upper and a lower facial Action Units (AU) analyser. The upper facial analyser is able to recognise six AUs including Inner and Outer Brow Raiser, Upper Lid Raiser etc, while the lower facial analyser is able to detect eleven AUs including Upper Lip Raiser, Lip Corner Puller, Chin Raiser, etc. Both of the upper and lower analysers are implemented using feedforward Neural Networks (NN). The work also further decodes six basic emotions from the recognised AUs. Two types of facial emotion recognisers are implemented, NN-based and multi-class Support Vector Machine (SVM) based. The NN-based facial emotion recogniser with the above recognised AUs as inputs performs robustly and efficiently. The Multi-class SVM with the radial basis function kernel enables the robot to outperform the NN-based emotion recogniser in real-time posed facial emotion detection tasks for diverse testing subjects.",https://ieeexplore.ieee.org/document/6889647/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/CCWC.2017.7868418,"Low-cost, real-time obstacle avoidance for mobile robots",IEEE,Conferences,"The goal of this project<sup>1</sup> is to advance the field of automation and robotics by utilizing recently-released, low-cost sensors and microprocessors to develop a mechanism that provides depth-perception and autonomous obstacle avoidance in a plug-and-play fashion. We describe the essential hardware components that can enable such a low-cost solution and an algorithm to avoid static obstacles present in the environment. The mechanism utilizes a novel single-point LIDAR module that affords more robustness and invariance than popular approaches, such as Neural Networks and Stereo. When this hardware is coupled with the proposed efficient obstacle avoidance algorithm, this mechanism is able to accurately represent environments through point clouds and construct obstacle-free paths to a destination, in a small timeframe. A prototype mechanism has been installed on a quadcopter for visualization on how actual implementation may take place<sup>2</sup>. We describe experimental results based on this prototype.",https://ieeexplore.ieee.org/document/7868418/,2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC),9-11 Jan. 2017,ieeexplore
10.1109/LARS.2008.23,MecaTeam Framework: An Infrastructure for the Development of Soccer Agents for Simulated Robots,IEEE,Conferences,"This paper presents the MecaTeam framework, a solution to reduce the effort on developing new soccer teams of robots for the 2D simulation category of the RoboCup. MecaTeam is an object-oriented framework based on features of two robot soccer teams: the MecaTeam 2006 and Uva Trilearn. The architecture of the proposed framework is presented and aspects of its use are discussed. Besides facilitating the development of new teams, the use of the MecaTeam framework may decrease the impact of changes in chunks of related code. Finally, the MecaTeam framework can be used by new researchers interested in simulated robots for soccer games.",https://ieeexplore.ieee.org/document/4812639/,2008 IEEE Latin American Robotic Symposium,29-30 Oct. 2008,ieeexplore
10.1109/IJCNN.2001.938487,Neuro-controller for high performance induction motor drives in robots,IEEE,Conferences,"Presents an approach to the speed control of an induction motor (IM) as a robust high performance drive (HPD) using an online self-tuning adapted artificial neural network (ANN). Based on motor dynamics and nonlinear unknown load characteristics such as robot systems, a neuro speed controller is developed. The proposed controller is very simple and serves as an identifier and a controller at the same time. The combination of the adaptive learning rate with the epochs used through the online training offers a unique feature of system identification and adaptive control. The performance of the controller was evaluated under various operating conditions to track different speed trajectories. The results validate the efficacy of the ANN for the precise tracking control of IM. Furthermore the use of the ANN makes the drive system robust, accurate, and insensitive to parameter variations. Also the drive system is implemented in real-time using a digital signal processor (DSP) TMS320C31.",https://ieeexplore.ieee.org/document/938487/,IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222),15-19 July 2001,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ICRA40945.2020.9196769,Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure,IEEE,Conferences,"In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",https://ieeexplore.ieee.org/document/9196769/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.23919/ACC45564.2020.9147898,Optimal Control of Wheeled Mobile Robots: From Simulation to Real World,IEEE,Conferences,"We study the problem of taking simulations to the real world (RW) for autonomous robotic systems with dynamic uncertainties and unknown disturbances while maintaining the optimal performance and stability of the designed controller designed in simulation. In general, an optimal and robust controller that is designed through simulation often does not perform similarly when deployed in the RW. We focus on using simulations to generate an optimal control policy utilizing the Memetic algorithm (MA) iteratively. The simulation-to-RW performance and stability are realized by using an adaptive fuzzy system to learn the uncertain part of the dynamic model, disturbance and noises. We demonstrate experimentally that this method permits the development of optimal control design in simulations and integrates adaptive learning rules to enable precise and repetitive trajectory tracking for the wheeled mobile robot (WMR) with disturbances and uncertainties.",https://ieeexplore.ieee.org/document/9147898/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/ICRA48506.2021.9561387,Pointing at Moving Robots: Detecting Events from Wrist IMU Data,IEEE,Conferences,"We propose a practical approach for detecting the event that a human wearing an IMU-equipped bracelet points at a moving robot; the approach uses a learned classifier to verify if the robot motion (as measured by its odometry) matches the wrist motion, and does not require that the relative pose of the operator and robot is known in advance. To train the model and validate the system, we collect datasets containing hundreds of real-world pointing events. Extensive experiments quantify the performance of the classifiers and relevant metrics of the resulting detectors; the approach is implemented in a real-world demonstrator that allows users to land quadrotors by pointing at them.",https://ieeexplore.ieee.org/document/9561387/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO49542.2019.8961870,Probabilistic Inferences on Quadruped Robots: An Experimental Comparison,IEEE,Conferences,"Due to the reality gap, computer software cannot fully model the physical robot in its environment, with noise, ground friction, and energy consumption. Consequently, a limited number of researchers work on applying machine learning in real-world robots. In this paper, we use two intelligent black-box optimization algorithms, Bayesian Optimization (BO) and Covariance Matrix Adaptation Evolution Strategy (CMA-ES), to solve a quadruped robot gait's parametric search problem in 10 dimensions, and compare these two methods to find which one is more suitable for legged robots' controller parameters tuning. Our results show that both methods can find an optimal solution in 130 iterations. BO converges faster than CMA-ES within its constrained range, while CMA-ES finds the optimum in the continuous space. Compared with the specific controller parameters of two methods, we also find that for quadruped robot's oscillators, the angular amplitude is the most important parameter. Thus, it is very beneficial for the quick parametric search of legged robots' controllers and avoids time-consuming manual tuning.",https://ieeexplore.ieee.org/document/8961870/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/IJCNN.1999.832705,Programming robots with associative memories,IEEE,Conferences,"Today, there are several drawbacks that impede the necessary and much needed use of robot learning techniques in real applications. First, the time needed to achieve the synthesis of any behavior is prohibitive. Second, the robot behavior during the learning phase is by definition bad, it may even be dangerous. Third, except within the lazy learning approach, a new behavior implies a new learning phase. We propose in this paper to use self-organizing maps to encode the nonexplicit model of the robot-world interaction sampled by the lazy memory, and then generate a robot behavior by means of situations to be achieved, i.e., points on the self-organizing maps. Any behavior can instantaneously be synthesized by the definition of a goal situation. Its performance will be minimal (not evidently bad) and will improve by the mere repetition of the behavior.",https://ieeexplore.ieee.org/document/832705/,IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339),10-16 July 1999,ieeexplore
10.1109/ICARCV.2014.7064347,RSAW: A situation awareness system for autonomous robots,IEEE,Conferences,"Services and technologies are in evolution in order to develop a new generation of robotic systems that might operate in dynamic real-world environments. In this paper, we focus on the ability of robot to understand and to surpass the blocked situations autonomously without operator intervention. Such situations may occur when the robot cannot succeed the current action and cannot move to the next one. We remark that in the literature, the operator has a crucial role consisting in providing all information about the environment and in making interpretations. In this paper, we propose an RSAW (Robot Situation AWareness) system, developed in order to help a robot to surpass a blocked situation and accomplish its goal whilst minimizing the operator intervention. RSAW is a new general system aiming to increase the autonomy of the robot; It is inspired by the notion of Situation Awareness (SA). In fact, RSAW defines a knowledge representation using ontologies and a process in order to surpass a blocked situation. RSAW is designed according to the Model Driven Engineering (MDE) methodology. This choice is done to preserve the generality of our system. This paper focalizes on the process of the RSAW system and the interaction between the process and the knowledge representation. The experimentations conducted in real environment with the Smart Autonomous Majordomo (SAM) robot, have shown the robustness and the efficiency of the proposed system.",https://ieeexplore.ieee.org/document/7064347/,2014 13th International Conference on Control Automation Robotics & Vision (ICARCV),10-12 Dec. 2014,ieeexplore
10.1109/SmartWorld.2018.00106,Real-Time Data Processing Architecture for Multi-Robots Based on Differential Federated Learning,IEEE,Conferences,"The emergency of ubiquitous intelligence in various things has become the ultimate cornerstone in building a smart interconnection of the physical world and the human world, which also caters to the idea of Internet of Things (IoT). Nowadays, robots as a new type of ubiquitous IoT devices have gained much attention. With the increasing number of distributed multi-robots, such smart environment generates unprecedented amounts of data. Robotic applications are faced with challenges of such big data: the serious real-time assurance and data privacy. Therefore, in order to obtain the big data values via knowledge sharing under the premise of ensuring the real-time data processing and data privacy, we propose a real-time data processing architecture for multi-robots based on the differential federated learning, called RT-robots architecture. A global shared model with differential privacy protection is trained on the cloud iteratively and distributed to multiple edge robots in each round, and the robotic tasks are processed locally in real time. Our implementation and experiments demonstrate that our architecture can be applied on multiple robotic recognition tasks, balance the trade-off between the performance and privacy.",https://ieeexplore.ieee.org/document/8560084/,"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",8-12 Oct. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/EFTA.2007.4416888,Real-time architecture for mobile assistant robots,IEEE,Conferences,"Mobile robotics is a challenging research area, with produced results that were unthinkable several years ago. There exist algorithms and methods capable of performing difficult tasks such as detect/classify objects, skill learning and SLAM. From the initial design steps, the real-time software architecture of a robotic platform requires great attention. The problem is difficult, because various components, such as sensing, perception, localization, and motor control, are required to operate and interact in real-time. This makes the system a very complex one. This paper presents a real-time control architecture designed for mobile robots and intelligent vehicles. Moreover, an example of application of the control structure consisting on a system for learning to classify places, using laser range data, is reported.",https://ieeexplore.ieee.org/document/4416888/,2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007),25-28 Sept. 2007,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/ICMLA.2017.0-161,Realistic Traffic Generation for Web Robots,IEEE,Conferences,"Critical to evaluating the capacity, scalability, and availability of web systems are realistic web traffic generators. Web traffic generation is a classic research problem, no generator accounts for the characteristics of web robots or crawlers that are now the dominant source of traffic to a web server. Administrators are thus unable to test, stress, and evaluate how their systems perform in the face of ever increasing levels of web robot traffic. To resolve this problem, this paper introduces a novel approach to generate synthetic web robot traffic with high fidelity. It generates traffic that accounts for both the temporal and behavioral qualities of robot traffic by statistical and Bayesian models that are fitted to the properties of robot traffic seen in web logs from North America and Europe. We evaluate our traffic generator by comparing the characteristics of generated traffic to those of the original data. We look at session arrival rates, inter-arrival times and session lengths, comparing and contrasting them between generated and real traffic. Finally, we show that our generated traffic affects cache performance similarly to actual traffic, using the common LRU and LFU eviction policies.",https://ieeexplore.ieee.org/document/8260631/,2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA),18-21 Dec. 2017,ieeexplore
10.1109/ICAMechS49982.2020.9310129,Reinforcement Learning based Method for Autonomous Navigation of Mobile Robots in Unknown Environments,IEEE,Conferences,"The Reinforcement Learning is a subset of machine learning that deals with learning decisions from rewards given by the environment. The model classic reinforcement learning (RL) algorithms are usually applied to small sets of states and an action. However, in real applications, the state spaces are of a large scale and this will bring the problems in the generalization and the curse of dimensionality. In this research, authors integrate neural networks into reinforcement learning methods to generalize the value of all the states. The simulation results on the Gazebo software framework show the feasibility of the model proposed method algorithm. The robot can safely navigate an unprotected work environment and becomes a truly intelligent system with the ability to learn and adapt itself to the model.",https://ieeexplore.ieee.org/document/9310129/,2020 International Conference on Advanced Mechatronic Systems (ICAMechS),10-13 Dec. 2020,ieeexplore
10.1109/ROMAN.2006.314459,Reinforcement Learning with Human Teachers: Understanding How People Want to Teach Robots,IEEE,Conferences,"While reinforcement learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a robot a task through reinforcement learning: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback -possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. In conclusion, we discuss future extensions to RL to accommodate these lessons",https://ieeexplore.ieee.org/document/4107833/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1109/ICORR.2017.8009451,Representing high-dimensional data to intelligent prostheses and other wearable assistive robots: A first comparison of tile coding and selective Kanerva coding,IEEE,Conferences,"Prosthetic devices have advanced in their capabilities and in the number and type of sensors included in their design. As the space of sensorimotor data available to a conventional or machine learning prosthetic control system increases in dimensionality and complexity, it becomes increasingly important that this data be represented in a useful and computationally efficient way. Well structured sensory data allows prosthetic control systems to make informed, appropriate control decisions. In this study, we explore the impact that increased sensorimotor information has on current machine learning prosthetic control approaches. Specifically, we examine the effect that high-dimensional sensory data has on the computation time and prediction performance of a true-online temporal-difference learning prediction method as embedded within a resource-limited upper-limb prosthesis control system. We present results comparing tile coding, the dominant linear representation for real-time prosthetic machine learning, with a newly proposed modification to Kanerva coding that we call selective Kanerva coding. In addition to showing promising results for selective Kanerva coding, our results confirm potential limitations to tile coding as the number of sensory input dimensions increases. To our knowledge, this study is the first to explicitly examine representations for realtime machine learning prosthetic devices in general terms. This work therefore provides an important step towards forming an efficient prosthesis-eye view of the world, wherein prompt and accurate representations of high-dimensional data may be provided to machine learning control systems within artificial limbs and other assistive rehabilitation technologies.",https://ieeexplore.ieee.org/document/8009451/,2017 International Conference on Rehabilitation Robotics (ICORR),17-20 July 2017,ieeexplore
10.1109/AIM.2019.8868670,Rhino: An Open-source Embedded Motherboard Design Enabling Complex Behavior of Intelligent Robots,IEEE,Conferences,"In recent years, Robot Operating System (ROS) has become a de facto standard for many robotic systems. However, there lacks a general-purpose control hardware to perfectly support ROS applications in an embedded fashion. In this paper, we take a hardware/software co-design methodology and a loosely coupled design methodology to develop a ROSoriented motherboard dedicatedly for facilitating high-end intelligent robotic applications. First, orienting around the ROS computational graph level, the hardware/software co-design is proposed to realize a mirrored modular design paradigm. Second, an open-source ROS motherboard, namely the ""Rhino"", is accordingly designed with the highlight of accelerating the embedded neuromorphic computation. Third, real-time performance and feasibility of Rhino are validated at different scales. Experimentation shows that the open-source prototype motherboard is eligible for ROS-based robot development and outperforms the conventional IPC and tailor-made control board. ROS-oriented hardware/software codesign paradigm complements the ROS ecosystem with an open-source AI-enabled motherboard for developing intelligent robots.",https://ieeexplore.ieee.org/document/8868670/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICSMC.1997.635206,Robots as responsible agents,IEEE,Conferences,"The quest for real autonomous robots leads us to discuss the problem about the best possible control architecture enabling that important characteristic. It has been broadly accepted that a hybrid architecture, i.e. putting together both reactive and deliberative paradigms is needed to efficiently execute tasks in realistic dynamic environments. Our proposal, which is being implemented to control a Robuterll mobile platform, involves the use of a two-layers architecture. Using symbolic representation for knowledge and goals at the deliberative level and sub-symbolic neural networks for implementing the behaviors at the reactive level. One of the main problems we are now addressing is how to make these two levels to communicate, to interact without being completely dependent on each other. The multi-agent system framework gives a flexible strategy for single agents cooperation and enables a set of behaviours to have a certain degree of autonomy. This reactive layer works together with the cognitive control agent where goals and commitments are logically represented through simple modal logic.",https://ieeexplore.ieee.org/document/635206/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBOT.2009.5152197,Robust servo-control for underwater robots using banks of visual filters,IEEE,Conferences,"We present an application of machine learning to the semi-automatic synthesis of robust servo-trackers for underwater robotics. In particular, we investigate an approach based on the use of Boosting for robust visual tracking of color objects in an underwater environment. To this end, we use AdaBoost, the most common variant of the Boosting algorithm, to select a number of low-complexity but moderately accurate color feature trackers and we combine their outputs. The novelty of our approach lies in the design of this family of weak trackers, which enhances a straightforward color segmentation tracker in multiple ways. From a large and diverse family of possible filters, we select a small subset that optimizes the performance of our trackers. The tracking process applies these trackers on the input video frames, and the final tracker output is chosen based on the weights of the final array of trackers. By using computationally inexpensive, but somewhat accurate trackers as members of the ensemble, the system is able to run at quasi real-time, and thus, is deployable on-board our underwater robot. We present quantitative cross-validation results of our spatio-chromatic visual tracker, and conclude by pointing out some difficulties faced and subsequent shortcomings in the experiments we performed, along with directions of future research in the area of ensemble tracking in real-time.",https://ieeexplore.ieee.org/document/5152197/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/ICUAS48674.2020.9214063,Semantic situation awareness of ellipse shapes via deep learning for multirotor aerial robots with a 2D LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots equipped with a 2D LIDAR sensor, focusing on the understanding of the environment, provided to have a drift-free precise localization of the robot (e.g. given by GNSS/INS or motion capture system). Our algorithm generates in real-time a semantic map of the objects of the environment as a list of ellipses represented by their radii, and their pose and velocity, both in world coordinates. Two different Convolutional Neural Network (CNN) architectures are proposed and trained using an artificially generated dataset and a custom loss function, to detect ellipses in a segmented (i.e. with one single object) LIDAR measurement. In cascade, a specifically designed indirect-EKF estimates the ellipses based semantic map in world coordinates, as well as their velocity. We have quantitative and qualitatively evaluated the performance of our proposed situation awareness system. Two sets of Software-In-The-Loop simulations using CoppeliaSim with one and multiple static and moving cylindrical objects are used to evaluate the accuracy and performance of our algorithm. In addition, we have demonstrated the robustness of our proposed algorithm when handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) objects and moving persons.",https://ieeexplore.ieee.org/document/9214063/,2020 International Conference on Unmanned Aircraft Systems (ICUAS),1-4 Sept. 2020,ieeexplore
10.1109/KIMAS.2003.1245110,Sharing learning policies between multiple mobile robots,IEEE,Conferences,"Learning of a complex task usually requires a long learning period. In order to reduce the time of learning, the task is divided into several subtasks. Multiple agents can be used to serve a complex task by learning these subtasks concurrently. With a good knowledge sharing mechanism, the learning policy can be shared or exchanged among these agents and can enhance their learning efficiency. The learning policy is a mapping from system states to actions. The mechanism of sharing or exchanging learning knowledge among multiagent system is proposed. An index of expertise, which indicates the skill level of each learning agent, is presented. This index is used to select the best preferable advice among multiple advices, which can increase the probability of finding solution in the search space. The experiment in which the learning knowledge is exchanged between a mobile robot and a computer simulated agent is implemented in order to verify the validity of the proposed algorithm. The experimental results show that the learning efficiency of the advisor agent is increased and the advisee robot can use the given advice for avoiding collision with obstacle successfully in the real world implementation.",https://ieeexplore.ieee.org/document/1245110/,IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change (IEEE Cat. No.03CH37502),30 Sept.-4 Oct. 2003,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/IROS45743.2020.9341328,Software Development Framework for Cooperating Robots with High-level Mission Specification,IEEE,Conferences,"In recent years, there has been a growing interest in multiple robots performing a single task through different types of collaboration. There are two software challenges when deploying collaborative robots: how to specify a cooperative mission and how to program each robot to accomplish its mission. In this paper, we propose a novel software development framework to support distributed robot systems, swarm robots, and their hybrid. We extend the service-oriented and model-based (SeMo) framework [1] to improve the robustness, scalability, and flexibility of robot collaboration. To enable a casual user to specify various types of cooperative missions easily, the high-level mission scripting language is extended with new features such as team hierarchy, group service, one-to-many communication. The script program is refined to the robot codes through two intermediate steps, strategy description and task graph generation, in the proposed framework. The viability of the proposed framework is evidenced by two preliminary experiments using real robots and a robot simulator.",https://ieeexplore.ieee.org/document/9341328/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IROS.1996.570655,Specification and validation of a control architecture for autonomous mobile robots,IEEE,Conferences,"We describe the specification of a software control architecture for autonomous mobile robots. The architecture, designed to provide the robot (in a task-dependent context) with the capacity to react to events but also to intelligently anticipate the future and plan its actions, is based on the decomposition of the robot system into a functional and a decisional level. The article is mainly focused on some aspects of the organisation and of the operation of the system such as execution control, inter-levels communication, reactivity. An important aspect that is developed is the possibility to prove some temporal and logical properties of parts of the system.",https://ieeexplore.ieee.org/document/570655/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/PADSW.2000.884672,Teleoperation system for real world robots-adaptive robot navigation based on sensor fusion,IEEE,Conferences,"The authors propose a teleoperation system with an autonomous robot which is able to solve tasks even without a large load for the operator and the system. Most teleoperation systems require skilled operators and expensive interfaces to solve tasks because they assume that the operator controls a robot completely. For these problems, we propose a teleoperation system which consists of an operation system and an autonomous robot. The operation system has a man-machine interface and allows a user to specify the working space and the tasks to be done. The autonomous robot follows the instruction from the operation system to solve the specific tasks. The paper focuses on navigation problems of the autonomous robot as an essential part of the proposed system. Namely, the autonomous robot should keep on the instructed paths in the real world to achieve a goal of the tasks. Our approach is based on a sensor fusion method based on two learning schemes: self-organizing map (SOM) and reinforcement learning. These learning schemes allow the system to be able to solve the tasks in an unreliable environment such as outdoors. Computational simulations reveal the effectiveness and robustness of the proposed method in the navigation problem.",https://ieeexplore.ieee.org/document/884672/,Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops,4-7 July 2000,ieeexplore
10.1109/IRI-05.2005.1506505,The behavior evolving model and application of virtual robots,IEEE,Conferences,"We suggest a model that evolves the behavioral knowledge of a virtual robot. The knowledge is represented in classification rules and a neural network, and is learned by a genetic algorithm. The model consists of a virtual robot with behavior knowledge, an environment that it moves in, and an evolution performer that includes a genetic algorithm. We have also applied our model to an environment where the robots gather food into a nest. When comparing our model with the conventional method on various test cases, our model showed superior overall learning.",https://ieeexplore.ieee.org/document/1506505/,"IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.",15-17 Aug. 2005,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IECON.2016.7793038,Tool compensation in walk-through programming for admittance-controlled robots,IEEE,Conferences,"This paper describes a walk-through programming technique, based on admittance control and tool dynamics compensation, to ease and simplify the process of trajectory learning in common industrial setups. In the walk-through programming, the human operator grabs the tool attached at the robot end-effector and “walks” the robot through the desired positions. During the teaching phase, the robot records the positions and then it will be able to interpolate them to reproduce the trajectory back. In the proposed control architecture, the admittance control allows to provide a compliant behavior during the interaction between the human operator and the robot end-effector, while the algorithm of compensation of the tool dynamics allows to directly use the real tool in the teaching phase. In this way, the setup used for the teaching can directly be the one used for performing the reproduction task. Experiments have been performed to validate the proposed control architecture and a pick and place example has been implemented to show a possible application in the industrial field.",https://ieeexplore.ieee.org/document/7793038/,IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society,23-26 Oct. 2016,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/ROBOT.1990.126044,Towards a real-time architecture for obstacle avoidance and path planning in mobile robots,IEEE,Conferences,"The design and partial implementation of a real-time architecture for a mobile robot, aimed particularly towards a vehicle developed for factory automation, is described. The authors develop a layered design to equip the robot with a number of behavioral competences. They examine sensing and a potential field algorithm especially to achieve modification of behavior at a speed close to the robot's operational speed. It is shown how the layered architecture interfaces to the original onboard architecture, which provided sophisticated localization but no ability to deal with environmental exceptions.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126044/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/CIRA.1999.810023,Towards focused plan monitoring: a technique and an application to mobile robots,IEEE,Conferences,"Until recently, techniques for AI plan generation relied on highly restrictive assumptions that were almost always violated in real-world environments; consequently, robot designers adopted reactive architectures and avoided AI planning techniques. Some recent research efforts have focused on obviating such assumptions by developing techniques that enable the generation and execution of plans in dynamic, uncertain environments. In this paper, we discuss one such technique, rationale-based monitoring, originally introduced by Veloso, Pollack, and Cox (1998), and describe our use of it in a simple mobile robot environment. We review the original approach, describe how it can be adapted for a causal-link planner, and provide experimental results demonstrating that it can lead to improved plans without consuming excessive overhead. We also describe our use of rationale-based monitoring in a mobile robot office-assistant project currently in progress.",https://ieeexplore.ieee.org/document/810023/,Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375),8-9 Nov. 1999,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/IJCNN.2011.6033258,Towards the grounding of abstract words: A Neural Network model for cognitive robots,IEEE,Conferences,"In this paper, a model based on Artificial Neural Networks (ANNs) extends the symbol grounding mechanism to abstract words for cognitive robots. The aim of this work is to obtain a semantic representation of abstract concepts through the grounding in sensorimotor experiences for a humanoid robotic platform. Simulation experiments have been developed on a software environment for the iCub robot. Words that express general actions with a sensorimotor component are first taught to the simulated robot. During the training stage the robot first learns to perform a set of basic action primitives through the mechanism of direct grounding. Subsequently, the grounding of action primitives, acquired via direct sensorimotor experience, is transferred to higher-order words via linguistic descriptions. The idea is that by combining words grounded in sensorimotor experience the simulated robot can acquire more abstract concepts. The experiments aim to teach the robot the meaning of abstract words by making it experience sensorimotor actions. The iCub humanoid robot will be used for testing experiments on a real robotic architecture.",https://ieeexplore.ieee.org/document/6033258/,The 2011 International Joint Conference on Neural Networks,31 July-5 Aug. 2011,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/CDS49703.2020.00012,Welding Seam Recognition Robots Based on Edge Computing,IEEE,Conferences,"In order to meet the requirements of the accuracy and real-time performance during the working process of underwater welding robots, a scheme of welding seam recognition robots system based on the edge computing is proposed in this paper. A number of pre-processing methods for capturing welding seam image were designed, including Thresholding, Filtering and Edge Detect. A Convolutional Neural Network(CNN) model for welding seam recognition was also created. In the experiments, the image pre-processing and CNN algorithms were integrated in and deployed to the robots, and the learning and training algorithms of the CNN were deployed to the cloud servers. The image pre-processing methods filtered the interference in underwater operations and achieved the image compression and feature extraction. The cloud servers fulfilled the training and parameter optimization of the CNN, which improved the accuracy of welding seam image recognition.",https://ieeexplore.ieee.org/document/9275963/,2020 International Conference on Computing and Data Science (CDS),1-2 Aug. 2020,ieeexplore
10.1109/IROS45743.2020.9340956,robo-gym – An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots,IEEE,Conferences,"Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and reduce the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym<sup>1</sup>. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to application on the robot. We showcase the capabilities and the effectiveness of the framework with two real world applications featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally, we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.",https://ieeexplore.ieee.org/document/9340956/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2021.3061477,A Cloud-Based Platform for Big Data-Driven CPS Modeling of Robots,IEEE,Journals,"This paper proposes an improved cyber-physical systems (CPS) architecture for a smart robotic factory based on an industrial cloud platform driven by big data based on the traditional CPS architecture. This paper uses the architecture analysis and design language to model and design a total of three scales for the underlying cell-level robot, the system-level robot shop, and the overall robotic smart factory CPS, respectively, to complete the conceptual scheme for building a robotic smart factory from a local to an overall CPS system. Using the advantages of cloud computing and combining robotic CPS with cloud computing, an architecture for an industrial management system for CPS cloud computing is proposed. Base based distributed storage architecture with Storm based distributed real-time processing architecture. In terms of modeling, the advantages and disadvantages of using AADL, structural analysis, and design language, and modelers, a physical device modeling language, are combined to analyze the advantages and disadvantages of architecture analysis &amp; design language (AADL) for modeling CPS and propose a CPS analysis and design based on AADL and applicable to it. The paper also investigates the use of LeNet models for state identification in the HSV color space. The algorithm was verified on a self-built power equipment indicator dataset with a 100% detection rate and 99.8% state recognition accuracy after four consecutive frames of fusion detection. Simulink simulation of the trolley was carried out in terms of a cell-level robotic trolley CPS system to demonstrate the effectiveness of the design of a robotic CPS system driven by soaring data based on the industrial cloud platform proposed in this paper.",https://ieeexplore.ieee.org/document/9360827/,IEEE Access,2021,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/TRO.2011.2119910,A Simple Tactile Probe for Surface Identification by Mobile Robots,IEEE,Journals,"This paper describes a tactile probe designed for surface identification in a context of all-terrain low-velocity mobile robotics. The proposed tactile probe is made of a small metallic rod with a single-axis accelerometer attached near its tip. Surface identification is based on analyzing acceleration patterns induced at the tip of this mechanically robust tactile probe, while it is passively dragged along a surface. A training dataset was collected over ten different indoor and outdoor surfaces. Classification results for an artificial neural network were positive, with an 89.9% and 94.6% success rate for 1- and 4-s time windows of data, respectively. We also demonstrated that the same tactile probe can be used for unsupervised learning of terrains. For 1-s time windows of data, the classification success rate was only reduced to 74.1%. Finally, a blind mobile robot, performing real-time classification of surfaces, demonstrated the feasibility of this tactile probe as a guidance mechanism.",https://ieeexplore.ieee.org/document/5752869/,IEEE Transactions on Robotics,June 2011,ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/JIOT.2020.3004339,AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,IEEE,Journals,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",https://ieeexplore.ieee.org/document/9123492/,IEEE Internet of Things Journal,Sept. 2020,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/56.802,Dynamic multi-sensor data fusion system for intelligent robots,IEEE,Journals,"The objective of the authors is to develop an intelligent robot workstation capable of integrating data from multiple sensors. The investigation is based on a Unimation PUMA 560 robot and various external sensors. These include overhead vision, eye-in-hand vision, proximity, tactile array, position, force/torque, cross-fire, overload, and slip-sensing devices. The efficient fusion of data from different sources will enable the machine to respond promptly in dealing with the 'real world'. Towards this goal, the general paradigm of a sensor data fusion system has been developed, and some simulation results, as well as results from the actual implementation of certain concepts of sensor data fusion, have been demonstrated.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/802/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/TII.2019.2936167,End-to-End Navigation Strategy With Deep Reinforcement Learning for Mobile Robots,IEEE,Journals,"In this article, we develop a navigation strategy based on deep reinforcement learning (DRL) for mobile robots. Because of the large difference between simulation and reality, most of the trained DRL models cannot be directly migrated into real robots. Moreover, how to explore in a sparsely rewarded environment is also a long-standing problem of DRL. This article proposes an end-to-end navigation planner that translates sparse laser ranging results into movement actions. Using this highly abstract data as input, agents trained by simulation can be extended to the real scene for practical application. For map-less navigation across obstacles and traps, it is difficult to reach the target via random exploration. Curiosity is used to encourage agents to explore the state of an environment that has not been visited and as an additional reward for exploring behavior. The agent relies on the self-supervised model to predict the next state, based on the current state and the executed action. The prediction error is used as a measure of curiosity. The experimental results demonstrate that without any manual design features and previous demonstrations, the proposed method accomplishes map-less navigation in complex environments. Through a reward signal that is enhanced by intrinsic motivation, the agent explores more efficiently, and the learned strategy is more reliable.",https://ieeexplore.ieee.org/document/8807287/,IEEE Transactions on Industrial Informatics,April 2020,ieeexplore
10.1109/TCDS.2019.2954289,Human-in-the-Loop Control Strategy of Unilateral Exoskeleton Robots for Gait Rehabilitation,IEEE,Journals,"In this article, a human-in-the-loop control methodology is proposed for the gait rehabilitation of patients with hemiplegia. It utilizes a unilateral exoskeleton system consisting of a unilateral lower limb exoskeleton and a real-time robot follower, such that the affected legs can be coordinated with the healthy legs with the assistance of the exoskeleton robot. In order to achieve immersive training during the physical therapy, the human-in-the-loop controller is developed. Furthermore, a region-based barrier Lyapunov function (BLF) is designed to separate the task workspace of the exoskeleton into a human region and a robot region, enabling the human leg to follow the desired motion trajectory in a compliant region, and the motion control of the exoskeleton is determined by humans; while in the robot region, the exoskeleton dominates the movement of human subjects. In order to make the motion control transit smoothly between the robot region and the human region, an adaptive controller is exploited to counteract the system's nonlinear uncertainties. Both the theoretical analysis and experimental results support the effectiveness and practicability on hemiplegic patients of our control strategy.",https://ieeexplore.ieee.org/document/8906035/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/41.704895,Modeling of ultrasonic range sensors for localization of autonomous mobile robots,IEEE,Journals,"This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",https://ieeexplore.ieee.org/document/704895/,IEEE Transactions on Industrial Electronics,Aug. 1998,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/JPROC.2019.2898267,"On Proactive, Transparent, and Verifiable Ethical Reasoning for Robots",IEEE,Journals,"Previous work on ethical machine reasoning has largely been theoretical, and where such systems have been implemented, it has, in general, been only initial proofs of principle. Here, we address the question of desirable attributes for such systems to improve their real world utility, and how controllers with these attributes might be implemented. We propose that ethically critical machine reasoning should be proactive, transparent, and verifiable. We describe an architecture where the ethical reasoning is handled by a separate layer, augmenting a typical layered control architecture, ethically moderating the robot actions. It makes use of a simulation-based internal model and supports proactive, transparent, and verifiable ethical reasoning. To do so, the reasoning component of the ethical layer uses our Python-based belief-desire-intention (BDI) implementation. The declarative logic structure of BDI facilitates both transparency, through logging of the reasoning cycle, and formal verification methods. To prove the principles of our approach, we use a case study implementation to experimentally demonstrate its operation. Importantly, it is the first such robot controller where the ethical machine reasoning has been formally verified.",https://ieeexplore.ieee.org/document/8648363/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/ACCESS.2018.2882875,RL and ANN Based Modular Path Planning Controller for Resource-Constrained Robots in the Indoor Complex Dynamic Environment,IEEE,Journals,"Traditional Reinforcement Learning (RL) approaches are designed to work well in static environments. In many real-world scenarios, the environments are complex and dynamic, in which the performance of traditional RL approaches may drastically degrade. One of the factors which results in the dynamicity and complexity of the environment is a change in the position and number of obstacles. This paper presents a path planning approach for autonomous mobile robots in a complex dynamic indoor environment, where the dynamic pattern of obstacles will not drastically affect the performance of RL models. Two independent modules, collision avoidance without considering the goal position and goal-seeking without considering obstacles avoidance, are trained independently using artificial neural networks and RL to obtain their best control policies. Then, a switching function is used to combine the two trained modules for realizing the obstacle avoidance and global path planning in a complex dynamic indoor environment. Furthermore, this control system is designed with a special focus on the computational and memory requirements of resource-constrained robots. The design was tested in a real-world environment on a mini-robot with constrained resources. Along with the static and dynamic obstacles' avoidance, this system has the ability to achieve both static and dynamic targets. This control system can also be used to train a robot in the real world using RL when the robot cannot afford to collide. Robot behavior in the real ground shows a very strong correlation with the simulation results.",https://ieeexplore.ieee.org/document/8543176/,IEEE Access,2018,ieeexplore
10.1109/TSMCB.2012.2192107,Robust Multiperson Detection and Tracking for Mobile Service and Social Robots,IEEE,Journals,"This paper proposes an efficient system which integrates multiple vision models for robust multiperson detection and tracking for mobile service and social robots in public environments. The core technique is a novel maximum likelihood (ML)-based algorithm which combines the multimodel detections in mean-shift tracking. First, a likelihood probability which integrates detections and similarity to local appearance is defined. Then, an expectation-maximization (EM)-like mean-shift algorithm is derived under the ML framework. In each iteration, the E-step estimates the associations to the detections, and the M-step locates the new position according to the ML criterion. To be robust to the complex crowded scenarios for multiperson tracking, an improved sequential strategy to perform the mean-shift tracking is proposed. Under this strategy, human objects are tracked sequentially according to their priority order. To balance the efficiency and robustness for real-time performance, at each stage, the first two objects from the list of the priority order are tested, and the one with the higher score is selected. The proposed method has been successfully implemented on real-world service and social robots. The vision system integrates stereo-based and histograms-of-oriented-gradients-based human detections, occlusion reasoning, and sequential mean-shift tracking. Various examples to show the advantages and robustness of the proposed system for multiperson tracking from mobile robots are presented. Quantitative evaluations on the performance of multiperson tracking are also performed. Experimental results indicate that significant improvements have been achieved by using the proposed method.",https://ieeexplore.ieee.org/document/6187748/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2012,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/21.61208,Satisficing feedback strategies for local navigation of autonomous mobile robots,IEEE,Journals,"A general approach to the local navigation problem for autonomous mobile robots (AMRs) is presented and its application to omnidirectional and conventionally steered wheelbases is described. The problem of driving an AMR to a goal in an unknown environment is formulated as a dynamic feedback control problem in which local feedback information is used to make steering decisions while the AMR is moving. To obtain a computationally tractable algorithm, a class of satisficing feedback strategies that generate reasonable, collision-free trajectories to the goal using simplified representations of the AMR dynamics and constrains is proposed. Realizations of the feedback strategy are presented and illustrated by simulation under the assumptions of perfect feedback information and zero servo error. Straightforward extensions of the approach to handle uncertainties in real systems are briefly described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/61208/,"IEEE Transactions on Systems, Man, and Cybernetics",Nov.-Dec. 1990,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/IJCNN48605.2020.9207496,"""I’m Sorry Dave, I’m Afraid I Can’t Do That"" Deep Q-Learning from Forbidden Actions",IEEE,Conferences,"The use of Reinforcement Learning (RL) is still restricted to simulation or to enhance human-operated systems through recommendations. Real-world environments (e.g. industrial robots or power grids) are generally designed with safety constraints in mind implemented in the shape of valid actions masks or contingency controllers. For example, the range of motion and the angles of the motors of a robot can be limited to physical boundaries. Violating constraints thus results in rejected actions or entering in a safe mode driven by an external controller, making RL agents incapable of learning from their mistakes. In this paper, we propose a simple modification of a state-of-the-art deep RL algorithm (DQN), enabling learning from forbidden actions. To do so, the standard Q-learning update is enhanced with an extra safety loss inspired by structured classification. We empirically show that it reduces the number of hit constraints during the learning phase and accelerates convergence to near-optimal policies compared to using standard DQN. Experiments are done on a Visual Grid World Environment and the TextWorld domain.",https://ieeexplore.ieee.org/document/9207496/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/WCICA.2016.7578819,3D vision based fast badminton localization with prediction and error elimination for badminton robot,IEEE,Conferences,"In this paper, the problem of fast badminton localization problem is investigated for a class of badminton robots. More precisely, a manifold-learning based localization method is implemented for the improvement of hitting accuracy and effectiveness. Based on the localization results, a novel badminton trajectory prediction algorithm is designed based on 3D Vision in the real world. Furthermore, clock-synchronization combined with motion compensation methods are also proposed to better localization error elimination. In the end, the validity and usefulness of our proposed algorithm is demonstrated by numerical experiments.",https://ieeexplore.ieee.org/document/7578819/,2016 12th World Congress on Intelligent Control and Automation (WCICA),12-15 June 2016,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ISSCC.2009.4977352,A 201.4GOPS 496mW real-time multi-object recognition processor with bio-inspired neural perception engine,IEEE,Conferences,"The visual attention mechanism, which is the way humans perform object recognition, was applied to the implementation of a high performance object recognition chip. Even though the previous chip achieved 50% gain of computational cost, it could recognize only one object in a frame so that it is not suitable for advanced multi-object recognition applications such as video surveillance, intelligent robots, and autonomous vehicle",https://ieeexplore.ieee.org/document/4977352/,2009 IEEE International Solid-State Circuits Conference - Digest of Technical Papers,8-12 Feb. 2009,ieeexplore
10.1109/ICRA40945.2020.9197155,A 3D-Deep-Learning-based Augmented Reality Calibration Method for Robotic Environments using Depth Sensor Data,IEEE,Conferences,"Augmented Reality and mobile robots are gaining increased attention within industries due to the high potential to make processes cost and time efficient. To facilitate augmented reality, a calibration between the Augmented Reality device and the environment is necessary. This is a challenge when dealing with mobile robots due to the mobility of all entities making the environment dynamic. On this account, we propose a novel approach to calibrate Augmented Reality devices using 3D depth sensor data. We use the depth camera of a Head Mounted Augmented Reality Device, the Microsoft Hololens, for deep learning-based calibration. Therefore, we modified a neural network based on the recently published VoteNet architecture which works directly on raw point cloud input observed by the Hololens. We achieve satisfying results and eliminate external tools like markers, thus enabling a more intuitive and flexible work flow for Augmented Reality integration. The results are adaptable to work with all depth cameras and are promising for further research. Furthermore, we introduce an open source 3D point cloud labeling tool, which is to our knowledge the first open source tool for labeling raw point cloud data.",https://ieeexplore.ieee.org/document/9197155/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/WI-IAT.2010.210,A Biologically-Inspired Cognitive Agent Model Integrating Declarative Knowledge and Reinforcement Learning,IEEE,Conferences,"The paper proposes a biologically-inspired cognitive agent model, known as FALCON-X, based on an integration of the Adaptive Control of Thought (ACT-R) architecture and a class of self-organizing neural networks called fusion Adaptive Resonance Theory (fusion ART). By replacing the production system of ACT-R by a fusion ART model, FALCON-X integrates high-level deliberative cognitive behaviors and real-time learning abilities, based on biologically plausible neural pathways. We illustrate how FALCON-X, consisting of a core inference area interacting with the associated intentional, declarative, perceptual, motor and critic memory modules, can be used to build virtual robots for battles in a simulated RoboCode domain. The performance of FALCON-X demonstrates the efficacy of the hybrid approach.",https://ieeexplore.ieee.org/document/5616152/,2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,31 Aug.-3 Sept. 2010,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/IMTC.1998.679788,A CNN-based passive optical range finder for real time robotic applications,IEEE,Conferences,"The paper presents a new CNN for real-time stereo vision, useful as a passive optical range finder for autonomous robots and vehicles. The stereo matching as energy minimization is discussed and former neural approaches to the problem are analyzed. Experimental results with the new CNN both with synthetic and real images are reported, demonstrating the performance of the system.",https://ieeexplore.ieee.org/document/679788/,IMTC/98 Conference Proceedings. IEEE Instrumentation and Measurement Technology Conference. Where Instrumentation is Going (Cat. No.98CH36222),18-21 May 1998,ieeexplore
10.1109/RTCSA.2018.00012,A Case Study of Cyber-Physical System Design: Autonomous Pick-and-Place Robot,IEEE,Conferences,"Although modern robots in warehousing systems can perform adequately in a goods-to-person model using hand-designed algorithms that are specialized to a particular environment, developing a robotic system that is capable of handling new products at an inexpensive cost remains a challenge. A conspicuous example of this challenge is seen in Amazon's use of autonomous robots to fetch customers' orders in their massive warehouses. To encourage advance in this technology, Amazon organized the competition, Amazon Picking Challenge that asked participants to develop their own hardware and software for the general task of picking a designated set of products from inventory shelves and then placing them at a target location (called a pick-and-place task). Current technology for pick-and-place tasks is still insufficient to meet the demand for low-cost automation. Handling awkward or oddly shaped object must still depend on hand-programming or specialized robotic systems, making manufacturing automation less flexible and expensive. In this paper, we shall present the design and implementation of a software system that is a step in advancing the technology toward full automation at reasonable costs. Our system integrates a set of state-of-the-art techniques in computer vision, deep-learning, trajectory optimization, visual servoing to create a library of skills that can be composed to perform a variety of robotic tasks. We demonstrate the capability of our system for performing autonomous pick-and-place tasks with an implementation using Hoppy, an industrial robotic arm in an environment similar to the Amazon Picking Challenge.",https://ieeexplore.ieee.org/document/8607230/,2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA),28-31 Aug. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/ICRITO51393.2021.9596550,A Comparative Study on Shortest Path Visualization using Artificial Intelligence,IEEE,Conferences,"In the modern computation system, that rely on various aspects to obtain the optimal results in easy manner appears more deterministic. There are several algorithms available that can distinguish a probable shortest path between two points, which helps students actively study algorithms with visualization. Therefore, in this study, we developed the GUI based shortest path finding tool consists of Dijkstra and A* algorithm. Further, in this study, the obtained shortest path results were graphically visualised and tabular output are stored in the database. The implementation of the algorithm and visualization was developed using Java AWT API and SWING package of Java. The Dijkstra and A* algorithm comparative analysis showed that the checks value and path length in terms of the A* algorithm is comparatively less than Dijkstra. Thus, it is affirmative that A * approach produces faster results and appeared as more efficient in terms of destination path finding than Dijkstra algorithm. Path finding is a fundamental feature of many significant applications and can be applied in static, interactive, and real-time situations. Such information shed light on the efficient application for computer gaming, robots, logistics, and crowd simulation.",https://ieeexplore.ieee.org/document/9596550/,"2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",3-4 Sept. 2021,ieeexplore
10.1109/FDL53530.2021.9568376,A Container-based Design Methodology for Robotic Applications on Kubernetes Edge-Cloud architectures,IEEE,Conferences,"Programming modern Robots' missions and behavior has become a very challenging task. The always increasing level of autonomy of such platforms requires the integration of multi-domain software applications to implement artificial intelligence, cognition, and human-robot/robot-robot interaction applications. In addition, to satisfy both functional and nonfunctional requirements such as reliability and energy efficiency, robotic SW applications have to be properly developed to take advantage of heterogeneous (Edge-Fog-Cloud) architectures. In this context, containerization and orchestration are becoming a standard practice as they allow for better information flow among different network levels as well as increased modularity in the use of software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de-facto development standards (i.e., robotic operating system - ROS - compliancy for robotic applications) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The design methodology allows for (i) integration and verification of multi-domain components since early in the design flow, (ii) task-to-container mapping techniques to guarantee minimum overhead in terms of performance and memory footprint, and (iii) multi-domain verification of functional and non-functional constraints before deployment. We present the results obtained in a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. The source code of the mobile robot is publicly available on GitHub.",https://ieeexplore.ieee.org/document/9568376/,2021 Forum on specification & Design Languages (FDL),8-10 Sept. 2021,ieeexplore
10.1109/ACSOS-C51401.2020.00067,A Deep Domain-Specific Model Framework for Self-Reproducing Robotic Control Systems,IEEE,Conferences,"As robots play more critical roles in diverse and complex scenarios in the real world, monomorphic robots are limited to repeating and rather simple tasks. How to achieve a robust, flexible, and scalable multi-robot system becomes essential research. Model-driven software development (MDSD) provides a sturdy methodology for robotic programming using multilevel domain-specific languages (DSLs). These DSLs lay a solid foundation for the design, integration, and extensibility of robotic applications. In this paper, we propose a deep domain-specific model framework for the self-reproducing robotic control system to escort reliable, versatile tasks of heterogeneous robots.",https://ieeexplore.ieee.org/document/9196470/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C),17-21 Aug. 2020,ieeexplore
10.1109/SNPD.2013.12,A Fast Genetic SLAM Approach for Mobile Robots,IEEE,Conferences,"This paper presents a new SLAM (simultaneous localization and mapping) method using genetic algorithm (GA) for mobile robots. A laser range finder (LRF) is installed on a mobile robot for collecting point-distance information about the surroundings. From the LRF points, several important ones are extracted for describing the main features of the surroundings. A new form of chromosomes for representing the changes of feature LRF points that are caused by the robot's movement is designed. The matching of current LRF features and the robot's possible movement is done by a fast genetic algorithm. A restart mechanism that re-initializes all chromosomes for increasing the diversity of solutions is developed and works with the matching process. Some constrains are developed for filtering out irrational chromosomes after the operation of crossover and mutation. With these mechanisms and constrains, our proposed method generates feasible solutions in several hundreds of GA iterations. Experiments are conducted on a real mobile robot. The experimental results show that our proposed method is efficient and effective for SLAM.",https://ieeexplore.ieee.org/document/6598520/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore
10.1109/IJCNN48605.2020.9207308,A Few-shot Dynamic Obstacle Avoidance Strategy in Unknown Environments,IEEE,Conferences,"Obstacle avoidance is one of the basic capabilities of intelligent mobile robots. With the diversification of the application environment, mobile robots are required to avoid obstacles with higher generality. Benefit from the development of mobile platform and deep learning algorithm in recent years, we conceive a few-shot dynamic obstacle avoidance strategy to meet this higher generality demand. Under this metric-based meta-learning method, mobile robots can quickly adapt to unknown environments by learning from several samples. In order to verify its effectiveness, we use this strategy to train a model and deploy it to the mobile robot and run multiple obstacle avoidance recognition tests in the real-world environment. The results of experiments performed on the mobile robot platform illustrates a good performance and verifies our proposed strategy. In addition to analyzing the experimental results, the advantages, disadvantages as well as application potential of the proposed strategy as a decision aid are also discussed.",https://ieeexplore.ieee.org/document/9207308/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/IJCNN52387.2021.9534180,A Lightweight sequence-based Unsupervised Loop Closure Detection,IEEE,Conferences,"Stable, effective and lightweight loop closure detection is an always pursued goal in real-time SLAM systems, that can be ported on embedded processors and deployed on autonomous robotics. Deep learning methods have extended the expressive ability and adaptability of the descriptor, and sequence-based methods can greatly improve the matching accuracy. However, the increased computation complexity and storage bandwidth requirements of matching calculations for high-dimensional descriptor make it infeasible for real-time deployment, especially for robots that navigate in relatively big maps. To address this challenge, we propose a lightweight sequence-based unsupervised loop closure detection scheme. To be specific, Principal Component Analysis (PCA) is applied to squeeze the descriptor dimensions while maintaining sufficient expressive ability. Additionally, with the consideration of the image sequence and combining linear query with fast approximate nearest neighbor search to further reduce the execution time and improve the efficiency of sequence matching. We implement our method on CALC, a state-of-the-art unsupervised solution, and conduct experiments on NVIDIA TX2, results demonstrate that the accuracy has been improved by 5%, while the execution speed is 2× faster. Source code is available at https://github.com/Mingrui-Yu/Seq-CALC.",https://ieeexplore.ieee.org/document/9534180/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/RoSE52553.2021.00011,A Modeling Tool for Reconfigurable Skills in ROS,IEEE,Conferences,"Known attempts to build autonomous robots rely on complex control architectures, often implemented with the Robot Operating System platform (ROS). The implementation of adaptable architectures is very often ad hoc, quickly gets cumbersome and expensive. Reusable solutions that support complex, runtime reasoning for robot adaptation have been seen in the adoption of ontologies. While the usage of ontologies significantly increases system reuse and maintainability, it requires additional effort from the application developers to translate requirements into formal rules that can be used by an ontological reasoner. In this paper, we present a design tool that facilitates the specification of reconfigurable robot skills. Based on the specified skills, we generate corresponding runtime models for self-adaptation that can be directly deployed to a running robot that uses a reasoning approach based on ontologies. We demonstrate the applicability of the tool in a real robot performing a patrolling mission at a university campus.",https://ieeexplore.ieee.org/document/9474550/,2021 IEEE/ACM 3rd International Workshop on Robotics Software Engineering (RoSE),2-2 June 2021,ieeexplore
10.1109/ISMR48331.2020.9312950,A Multi-Modal Learning System for On-Line Surgical Action Segmentation,IEEE,Conferences,"Surgical action recognition and temporal segmentation is a building block needed to provide some degrees of autonomy to surgical robots. In this paper, we present a deep learning model that relies on videos and kinematic data to output in real-time the current action in a surgical procedure. The proposed neural network architecture is composed of two sub-networks: a Spatial-Kinematic Network, which produces high-level features by processing images and kinematic data, and a Temporal Convolutional Network, which filters such features temporally over a sliding window to stabilize their changes over time. Since we are interested in applications to real-time supervisory control of robots, we focus on an efficient and causal implementation, i.e. the prediction at sample k only depends on previous observations. We tested our causal architecture on the publicly available JIGSAWS dataset, outperforming comparable state-of-the-art non-causal algorithms up to 8.6% in the edit score.",https://ieeexplore.ieee.org/document/9312950/,2020 International Symposium on Medical Robotics (ISMR),18-20 Nov. 2020,ieeexplore
10.1109/ICICSP54369.2021.9611881,A Multi-agent Reinforcement Learning Routing Protocol in Mobile Robot Network,IEEE,Conferences,"Robots are now essential in unreachable, repeated, and dangerous real-world applications where they take place of human beings. One of the important capabilities of a multi-robot system is that it should be able to form an autonomous robot network to transmit information. However, due to the limited communication capability of a single robot, the highly variable environment where robots work, and the mobility of the robots, it is difficult for them to exchange information with each other in need. In this article, we propose a novel robot network routing protocol based on multi-agent reinforcement learning called MAQR. The robot nodes can deliver packets cooperatively. The mobility factor, buffer status, and packet delay of neighbor nodes are taken into consideration. We design a reliability model for a robot agent to make reliable routing decisions. We also design an adaptive exploration-exploitation method to balance the convergence speed, solution space as well as network fluctuation. The routing algorithm has been implemented and evaluated in simulation. Results show that MAQR can provide less packet delay, less average queue length and higher delivery ratio than other Q-learning based routing protocol.",https://ieeexplore.ieee.org/document/9611881/,2021 4th International Conference on Information Communication and Signal Processing (ICICSP),24-26 Sept. 2021,ieeexplore
10.1109/SMC.2019.8914519,A Multimodal Perception System for Detection of Human Operators in Robotic Work Cells,IEEE,Conferences,"Workspace monitoring is a critical hw/sw component of modern industrial work cells or in service robotics scenarios, where human operators share their workspace with robots. Reliability of human detection is a major requirement not only for safety purposes but also to avoid unnecessary robot stops or slowdowns in case of false positives. The present paper introduces a novel multimodal perception system for human tracking in shared workspaces based on the fusion of depth and thermal images. A machine learning approach is pursued to achieve reliable detection performance in multi-robot collaborative systems. Robust experimental results are finally demonstrated on a real robotic work cell.",https://ieeexplore.ieee.org/document/8914519/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/FUZZ48607.2020.9177557,A Novel Self-Organizing PID Approach for Controlling Mobile Robot Locomotion,IEEE,Conferences,"A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID) control system is proposed in this paper. The proposed system consists of a pair of control and reference models, both of which are implemented by a first-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. The SOF-PID controller self-organizes and self-updates the structures and meta-parameters of both the control and reference models during the control process ""on the fly"". This gives the SOF-PID control system the capability of quickly adapting to entirely new operating environments without a full re-training. Moreover, the SOF-PID control system is free from user- and problem-specific parameters and is entirely data-driven. Simulations and real-world experiments with mobile robots demonstrate the effectiveness and validity of the proposed SOF-PID control system.",https://ieeexplore.ieee.org/document/9177557/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/CISDA.2007.368137,A Review of Intelligent Systems Software for Autonomous Vehicles,IEEE,Conferences,"The need for intelligent unmanned vehicles has been steadily increasing. These vehicles could be air-, ground-, space-, or sea-based. This paper will review some of the most common software systems and methods that could be used for controlling such vehicles. Early attempts at mobile robots were confined to simple laboratory environments. For vehicles to operate in real-world noisy and uncertain environments, they need to include numerous sensors and they need to include both reactive and deliberative features. The most effective software systems have been hierarchical or multi-layered. Many of these systems mimic biological systems. This paper reviews several software approaches for autonomous vehicles. While there are similarities, there are differences as well. Most of these software systems are very difficult to use, and few of them have the ability to learn. Autonomous vehicles promise remarkable capabilities for both civilian and military applications, but much work remains to develop intelligent systems software which can be used for a wide range of applications. In particular there is a need for reliable open-source software that can be used on inexpensive autonomous vehicles",https://ieeexplore.ieee.org/document/4219084/,2007 IEEE Symposium on Computational Intelligence in Security and Defense Applications,1-5 April 2007,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA48506.2021.9561722,A Scavenger Hunt for Service Robots,IEEE,Conferences,"Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",https://ieeexplore.ieee.org/document/9561722/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.23919/ChiCC.2019.8865929,A Speech Interaction System Based on Cloud Service under ROS,IEEE,Conferences,"With the recent development of technologies such as artificial intelligence and cloud computing, intelligent service robots are more and more widely used, and current users are paying more attention to the speech interaction function of robots. In this paper, we design a cloud-based intelligent speech interaction system under ROS to enhance the human-robot interaction experience, and carry out related tests on the laptop. The system we designed runs stably and smoothly, and has high real-time performance, which can satisfy user's requirements.",https://ieeexplore.ieee.org/document/8865929/,2019 Chinese Control Conference (CCC),27-30 July 2019,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/iCREATE.2014.6828372,A comparison of various robotic control architectures for autonomous navigation of mobile robots,IEEE,Conferences,"For mobile robots, the most fundamental and pressing issue is that of autonomous navigation. Successful navigation of mobile robots is closely dependent on four vitals i.e. perception, localization, cognition and motion control. Implementation of each of these vital blocks requires consideration of at least one of the two well-known control architectures Deliberative Navigation Control and Reactive Navigation Control or a combination of the two, also known as a Hybrid Navigation Control. This paper compares each of these control architectures on the basis of their flexibility, ease of implementation, reactivity, robustness, efficiency and many other architecture specifications. The paper concludes with suggesting the schema that seems to be the best of each of these control schemes, on the basis of the analysis made, in order to cope with unknown and dynamic navigation problems encountered in real life scenarios.",https://ieeexplore.ieee.org/document/6828372/,2014 International Conference on Robotics and Emerging Allied Technologies in Engineering (iCREATE),22-24 April 2014,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ROBIO.2007.4522431,A fast robot feedback decision algorithm,IEEE,Conferences,"Intelligence decision is an important subject for robotic intelligence system. This paper presents an experimental research work about robotic intelligence decision, where a fast information reduction with feedback features is proposed to solve robot intelligent decision and judgement issue. We have investigated the properties satisfied by the robotic information processing and decision process: if an attribute is the only discerning of multiple information objects, this attribute can be taken as the first core attribute, and can be reused in an iterative information reduction process to get another core attribute; furthermore, a feedback method can be used to enhance this iterative processing capability in real-time robots cooperative systems. Out feedback control method is somewhat dynamical and iterative process, and the investigated properties are utilized to design the feedback control laws. We have set up the relative experimental platform, and the experimental results show that our fast robot feedback decision algorithm is efficient and effective, which can be used in multiple robots collaborative missions.",https://ieeexplore.ieee.org/document/4522431/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICAL.2010.5585308,A framework for coordination and navigation of multi-robot systems,IEEE,Conferences,"In this paper, a novel framework is proposed to incorporate task assignment, path planning, and tracking control of a multi-robot system. The dynamic task assignment of multi-robots is achieved using a self-organizing map based feature. The real-time collision-free robot path is generated from a neuro-dynamics network through sensor measurement and responding immediately to dynamic elements in the environment including the robot, the target, and obstacles. The tracking control is accomplished by a neuro-dynamics and back-stepping based model. This type of control is able to generate smooth, bounded acceleration control signals for a non-holonomic mobile robot to track the reference path generated by the path planner. Experiments under various situations demonstrated the effectiveness of this integrated system.",https://ieeexplore.ieee.org/document/5585308/,2010 IEEE International Conference on Automation and Logistics,16-20 Aug. 2010,ieeexplore
10.1109/IROS.2013.6696771,A learning-based approach to robust binaural sound localization,IEEE,Conferences,"Sound source localization is an important feature designed and implemented on robots and intelligent systems. Like other artificial audition tasks, it is constrained to multiple problems, notably sound reflections and noises. This paper presents a sound source azimuth estimation approach in reverberant environments. It exploits binaural signals in a humanoid robotic context. Interaural Time and Level Differences (ITD and ILD) are extracted on multiple frequency bands and combined with a neural network-based learning scheme. A cue filtering process is used to reduce the reverberations effects. The system has been evaluated with simulation and real data, in multiple aspects covering realistic robot operating conditions, and was proven satisfying and effective as will be shown and discussed in the paper.",https://ieeexplore.ieee.org/document/6696771/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1109/SBRN.1998.730998,A neural-network based approach for recognition of pose and motion gestures on a mobile robot,IEEE,Conferences,"Since a variety of changes in both robotic hardware and software suggests that service robots will soon become possible, to find ""natural"" ways of communication between human and robots is of fundamental importance for the robotic field. The paper describes a gesture-based interface for human-robot interaction, which enables people to instruct robots through easy-to-perform arm gestures. Such gestures might be static pose gestures, which involve only a specific configuration of the person's arm, or they might be dynamic motion gestures, that is, they involve motion (such as waving). Gestures are recognized in real-time at approximate frame rate, using neural networks. A fast, color-based tracking algorithm enables the robot to track and follow a person reliably through office environments with drastically changing lighting conditions. Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned, and the robot picks up trash which it then delivers to the nearest trash-bin.",https://ieeexplore.ieee.org/document/730998/,Proceedings 5th Brazilian Symposium on Neural Networks (Cat. No.98EX209),9-11 Dec. 1998,ieeexplore
10.1109/CIG.2011.6032027,A neuronal global workspace for human-like control of a computer game character,IEEE,Conferences,"This paper describes a system that uses a global workspace architecture implemented in spiking neurons to control an avatar within the Unreal Tournament 2004 (UT2004) computer game. This system is designed to display human-like behaviour within UT2004, which provides a good environment for comparing human and embodied AI behaviour without the cost and difficulty of full humanoid robots. Using a biologically-inspired approach, the architecture is loosely based on theories about the high level control circuits in the brain, and it is the first neural implementation of a global workspace that is embodied in a dynamic real time environment. At its current stage of development the system can navigate through UT2004 and shoot opponents. We are currently completing the implementation and testing in preparation for the human-like bot competition at CIG 2011 in September.",https://ieeexplore.ieee.org/document/6032027/,2011 IEEE Conference on Computational Intelligence and Games (CIG'11),31 Aug.-3 Sept. 2011,ieeexplore
10.1109/ICVES.2016.7548165,A new hopfield-type neural network approach to multi-goal vehicle navigation in unknown environments,IEEE,Conferences,"A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",https://ieeexplore.ieee.org/document/7548165/,2016 IEEE International Conference on Vehicular Electronics and Safety (ICVES),10-12 July 2016,ieeexplore
10.1109/WINCOM50532.2020.9272477,A new middleware for managing heterogeneous robot in ubiquitous environments,IEEE,Conferences,"Heterogeneity is one of the main issues for the deployment of the Industry 4.0. This is due to the diversity in the available robots and the IIoT devices. These equipments use different programming languages and communication protocols. To make the integration of such equipments easy, we propose TalkRoBots, a middleware that allows heterogeneous robots and IIoT devices to communicate together and exchange data in a transparent way. The middleware was experimented in a real scenario with different robots that demonstrate its efficiency.",https://ieeexplore.ieee.org/document/9272477/,2020 8th International Conference on Wireless Networks and Mobile Communications (WINCOM),27-29 Oct. 2020,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/HAPTICS.2014.6775492,A novel haptic interface and control algorithm for robotic rehabilitation of stoke patients,IEEE,Conferences,"Rehabilitation robots are gradually becoming popular for stroke rehabilitation to improve motor recovery. By using a robot, the patient may perform the training more frequently on their own, but they must be motivated to do so. Therefore, this project develops a set of rehabilitation training programs with different haptic modalities on Compact Rehabilitation Robot (CR2) - a robot used to train upper and lower limbs reaching movement. The paper present the developed haptic interface, Haptic Sense with five configurable haptic modalities that include sensations of weight, wall, spring, sponge and visual amplification. A combination of several haptic modalities was implemented into virtual reality games, Water Drop - a progressive training game with up to nine levels of difficulties that requires user to move the cup to collect the water drops.",https://ieeexplore.ieee.org/document/6775492/,2014 IEEE Haptics Symposium (HAPTICS),23-26 Feb. 2014,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/AIM.2001.936513,A radial basis function networks approach for the tracking problem of mobile robots,IEEE,Conferences,Proposes a radial basis function network (RBFN) approach to the solution of the tracking problem for mobile robots. RBFN-based controllers are investigated in order to introduce some degree of robustness in the control system and to avoid the main disadvantage of multilayer neural networks (MNN) to be highly nonlinear in the parameters. The training of the nets and the control performances analysis have been done in a real experimental setup. The proposed solutions are implemented on a PC-based control architecture for the real-time control of the LabMate mobile base and are compared with MNN-based control schemes. The experimental results are satisfactory in terms of tracking errors and computational efforts.,https://ieeexplore.ieee.org/document/936513/,2001 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Proceedings (Cat. No.01TH8556),8-12 July 2001,ieeexplore
10.1109/ICAMechS.2013.6681701,A real-time walking robot control system based on Linux RTAI,IEEE,Conferences,"This study developed a real-time control system for a walking robot. The control system for the walking robot should have a real-time operating system, a small size, and extendable IO cards. The PC104 computer is selected due to its small size, reliability and availability of many IO cards. The Linux RTAI is selected because it is an open-source, efficient and hard real-time operating system. The Turbo PMAC PC104 card is used to control motor drivers because its small size, multi-axis synchronization and powerful control functions. Compared with CAN or EtherCAT bus control scheme, this system can easily support motor drivers from different companies. The software is reusable to different robots due to its independence on communication bus protocols and motor drivers. The motor control experiments are provided to show the satisfactory real-time control performance.",https://ieeexplore.ieee.org/document/6681701/,Proceedings of the 2013 International Conference on Advanced Mechatronic Systems,25-27 Sept. 2013,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/ITCA49981.2019.00057,A two-level stacking model for detecting abnormal users in Wechat activities,IEEE,Conferences,"Machine learning algorithms are widely employed in plenty of classification or regression problems. While in real business world, it is confronted with huge and disorder data pattern. To recognize different kinds of users on the internet accurately and fast becomes a challenge. In a Wechat online bargain activity, the staff found that some strange users are highly like robots or malicious users. Thus we tried a two-level stacking model to detect them. This design got a good result of 0.98 accuracy after the training phase and an accuracy of 0.90 in a new term of the testing set. Moreover, this model is adaptable to linear and nonlinear datasets because of its diverse stacking of first-level classifiers. Therefore, this paper indicates a potential of the stacking classification model in big data times.",https://ieeexplore.ieee.org/document/9092496/,2019 International Conference on Information Technology and Computer Application (ITCA),20-22 Dec. 2019,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/FUZZ48607.2020.9177654,AI-FML Agent for Robotic Game of Go and AIoT Real-World Co-Learning Applications,IEEE,Conferences,"In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world.",https://ieeexplore.ieee.org/document/9177654/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/SIBGRAPI.2001.963057,ARENA and WOXBOT: first steps towards virtual world simulations,IEEE,Conferences,"This paper reports new results of a project to build virtual worlds aimed at the graphic simulation of an arena where small mobile robots can perform requested tasks while behaving according to their own motivation and reasoning. Each robot is an intelligent agent that perceives the virtual environment via a simulated vision system and reacts to translating or rotating its body by driving its own wheels. The conception and specification of the robots and the environment are developed to create an open distributed object architecture that could serve as a testbed freely available and ready to use for testing theories in some computational areas such as evolutionary computation, artificial life, pattern recognition, artificial intelligence, cognitive neurosciences and distributed object architectures.",https://ieeexplore.ieee.org/document/963057/,Proceedings XIV Brazilian Symposium on Computer Graphics and Image Processing,15-18 Oct. 2001,ieeexplore
10.1109/DevLrn.2012.6400818,ASP+POMDP: Integrating non-monotonic logic programming and probabilistic planning on robots,IEEE,Conferences,"Mobile robots equipped with multiple sensors and deployed in real-world domains frequently find it difficult to process all sensor inputs, or to operate without any human input and domain knowledge. At the same time, robots cannot be equipped with all relevant domain knowledge in advance, and humans are unlikely to have the time and expertise to provide elaborate and accurate feedback. This paper presents a novel framework that addresses these challenges by integrating high-level logical inference with low-level probabilistic sequential decision-making. Specifically, Answer Set Programming (ASP), a non-monotonic logic programming paradigm, is used to represent, reason with and revise domain knowledge obtained from sensor inputs and high-level human feedback, while hierarchical partially observable Markov decision processes (POMDPs) are used to automatically adapt visual sensing and information processing to the task at hand. Furthermore, a psychophysics-inspired strategy is used to merge the output of logical inference with probabilistic beliefs. All algorithms are evaluated in simulation and on wheeled robots localizing target objects in indoor domains.",https://ieeexplore.ieee.org/document/6400818/,2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL),7-9 Nov. 2012,ieeexplore
10.1109/IEEECONF49454.2021.9382693,Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player,IEEE,Conferences,"This paper presents a sensor-level mapless collision avoidance algorithm for use in mobile robots that map raw sensor data to linear and angular velocities and navigate in an unknown environment without a map. An efficient training strategy is proposed to allow a robot to learn from both human experience data and self-exploratory data. A game format simulation framework is designed to allow the human player to tele-operate the mobile robot to a goal and human action is also scored using the reward function. Both human player data and self-playing data are sampled using prioritized experience replay algorithm. The proposed algorithm and training strategy have been evaluated in two different experimental configurations: Environment 1, a simulated cluttered environment, and Environment 2, a simulated corridor environment, to investigate the performance. It was demonstrated that the proposed method achieved the same level of reward using only 16% of the training steps required by the standard Deep Deterministic Policy Gradient (DDPG) method in Environment 1 and 20% of that in Environment 2. In the evaluation of 20 random missions, the proposed method achieved no collision in less than 2 h and 2.5 h of training time in the two Gazebo environments respectively. The method also generated smoother trajectories than DDPG. The proposed method has also been implemented on a real robot in the real-world environment for performance evaluation. We can confirm that the trained model with the simulation software can be directly applied into the real-world scenario without further fine-tuning, further demonstrating its higher robustness than DDPG. The video and code are available: https://youtu.be/BmwxevgsdGc https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance.",https://ieeexplore.ieee.org/document/9382693/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/FPA.1994.636089,"Active perception, navigation, homing, and grasping: an autonomous perspective",IEEE,Conferences,"Perception is needed for action, not for the pure sake of the construction of abstract representations, although it does not exclude the role of internal representations for mediating complex behaviours. We think that, for the purpose of building autonomous robots, active perception requires specific recipes for three related aspects: the design of the physical sensory system, the modality and type of information extracted, and the structure and functioning of the control system. We outline a set of solutions for these three aspects and describe their implementation on a real mobile robot through a set of three different experiments using a combination of neural networks and genetic algorithms. The results show that active perception is a useful feature that is exploited by autonomous agents. The experiments shout that the combination of genetic algorithms and neural networks is a feasible and fruitful technique for the development of active perception in autonomous agents.",https://ieeexplore.ieee.org/document/636089/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/WCICA.2006.1713761,An Embedded Platform for Intelligent Mobile Robot,IEEE,Conferences,"To overcome the limitations of the special architectures adopted by traditional industrial robots, an embedded intelligent robot platform based on Windows CE.NET is established by customizing the operating system. On this intelligent robot platform, all major necessary sensors are included, and abundant control interfaces and driver modules are available, such as movement control interface, USB camera driver, laser driver, etc. Besides, various testing software and application modules for intelligent robot are designed, such as multi-sensor data fusion, path planning, speech recognition, wireless network communication and graphic human-robot interface. The platform is modularized, extensible, transplantable and customizable. Compared to the previous robot platform, it also has many advantages such as more compact hardware, lower-power consumption, better real-time performance and higher reliability",https://ieeexplore.ieee.org/document/1713761/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/IJCNN.2018.8489157,An Embedded Tracking System with Neural Network Accelerator,IEEE,Conferences,"With robots and unmanned aerial vehicles (UAVs) being more and more employed in real-life scenarios for monitoring and surveillance, there is a increasing demand for deploying various video processing applications in mobile systems. However, with limited on-board computational resources and power consumption, the application in this domain requires that the tracking platforms equipped should have outstanding computing power to handle the tasks in real-time with high-accuracy, while at the same time, fit the highly constrained environment of small size, light weight, and low power consumption (SWaP) for the purpose of long-term surveillance. In this paper, we proposed a new autonomous object tracking system based on an embedded platform, leveraging the emerging neural network hardware which is capable of massive parallel pattern recognition processing and demands only a low level power consumption. Further, a prototype of the tracking system that combines a low-power neural network chip, CogniMem, and an embedded development board, BeagleBone, is developed. Our experimental results show that the power consumption for the entire system is only about 2. 25W, which signifies a promising future of applying ultra-low-power neuromorphic hardware as a accelerator in recognition tasks.",https://ieeexplore.ieee.org/document/8489157/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/COASE.2018.8560532,An EtherCAT-Based Real-Time Control System Architecture for Humanoid Robots,IEEE,Conferences,"The design of humanoid robots naturally requires the simultaneous control of a high number of joints. Moreover, the performance of the overall robot is strongly determined by the low-level control system as all high-level software e.g. for locomotion planning and control is built on top of it. In order to achieve high update rates and high bandwidth for the joint control, an advanced real-time control system architecture is required. However, outdated communication protocols with associated limits in the achievable update rates are still used in nowadays humanoid robots. Moreover, the performance of the low-level control systems is not analyzed in detail or the systems rely on specialized hardware, which lacks reliability and persistence. We present a reliable and high-performance control system architecture for humanoid robots based on the ETHERCAT technology. To the authors' knowledge this is the only system, which operates at control rates beyond 2 khz and input/output latencies below 1 ms. Our control architecture includes a learning-based feedforward control strategy to improve joint tracking performance. The improved joint control method and the communication system are evaluated on our humanoid robot LOLA. Our software framework is available online to allow other researchers to benefit from our experiences.",https://ieeexplore.ieee.org/document/8560532/,2018 IEEE 14th International Conference on Automation Science and Engineering (CASE),20-24 Aug. 2018,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/MWSCAS.2014.6908370,An efficient implementation of deep convolutional neural networks on a mobile coprocessor,IEEE,Conferences,"In this paper we present a hardware accelerated real-time implementation of deep convolutional neural networks (DCNNs). DCNNs are becoming popular because of advances in the processing capabilities of general purpose processors. However, DCNNs produce hundreds of intermediate results whose constant memory accesses result in inefficient use of general purpose processor hardware. By using an efficient routing strategy, we are able to maximize utilization of available hardware resources but also obtain high performance in real world applications. Our system, consisting of an ARM Cortex-A9 processor and a coprocessor, is capable of a peak performance of 40 G-ops/s while consuming less than 4W of power. The entire platform is in a small form factor which, combined with its high performance at low power consumption makes it feasible to use this hardware in applications like micro-UAVs, surveillance systems and autonomous robots.",https://ieeexplore.ieee.org/document/6908370/,2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS),3-6 Aug. 2014,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
10.1109/ROBIO.2013.6739426,An improved neuro-dynamics-based approach to online path planning for multi-robots in unknown dynamic environments,IEEE,Conferences,"Online path planning for multi-robots in complicated and dynamic environments is a difficult and hot issue in the field of robotics. Many traditional path planning methods cannot meet the requirements of online and real-time processing. Neuro-dynamics-based method has an aptitude for online and real-time path planning in complicated and dynamic environments. However, this method still has shortcomings. In this paper, an improved neuro-dynamics-based method is proposed with advantages. It has conducted efficient performance and easier realization with much less computational time complexity. Meanwhile, by entering “repulsion” mechanism, the improved method is capable of fair allocation and load balancing on the limited resources. Both simulated experiments and theoretical analysis demonstrate the feasibility and availability of the improved method in the paper.",https://ieeexplore.ieee.org/document/6739426/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
,An incremental behavior learning based on reinforcement learning with schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. However it can so far only demonstrate preprogrammed motions according to external stimuli. In contrast, humans can learn new motions such as catching a ball, in spite of his/her high dimensional sensorimotor DOF. In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schemata (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1324279/,SICE 2003 Annual Conference (IEEE Cat. No.03TH8734),4-6 Aug. 2003,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/ROBOT.2010.5509935,An insect-based method for learning landmark reliability using expectation reinforcement in dynamic environments,IEEE,Conferences,"Navigation in unknown dynamic environments still remains a major challenge in robotics. Whereas insects like the desert ant with very limited computing and memory capacities solve this task with great efficiency. Thus, the understanding of the underlying neural mechanisms of insect navigation can inform us on how to build simpler yet robust autonomous robots. Based on recent developments in insect neuroethology and cognitive psychology, we propose a method for landmark navigation in dynamic environments. Our method enables the navigator to learn the reliability of landmarks using an expectation reinforcement method. For that end, we implemented a real-time neuronal model based on the Distributed Adaptive Control framework. The results demonstrate that our model is capable of learning the stability of landmarks by reinforcing its expectations. Also, the proposed mechanism allows the navigator to optimally restore its confidence when its expectations are violated. We also perform navigational experiments with real ants to compare with the results of our model. The behavior of the proposed autonomous navigator closely resembles real ant navigational behavior. Moreover, our model explains navigation in dynamic environments as a memory consolidation process, harnessing expectations and their violations.",https://ieeexplore.ieee.org/document/5509935/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ITRE.2004.1393663,An integrated programming environment for undergraduate computing courses,IEEE,Conferences,"The Computing Division of the Business School at University College Worcester provides computing and information technology education to a range of undergraduate students. Topics include various approaches to programming, artificial intelligence, operating systems and digital technologies. Each of these has its own potentially conflicting requirements for a pedagogically sound programming environment. This paper describes an endeavor to develop a common programming paradigm across all topics. This involves the combined use of autonomous robots and Java simulations.",https://ieeexplore.ieee.org/document/1393663/,ITRE 2004. 2nd International Conference Information Technology: Research and Education,28 June-1 July 2004,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ICC.2018.8422231,Anticipatory Mobility Management by Big Data Analytics for Ultra-Low Latency Mobile Networking,IEEE,Conferences,"Massive deployment of autonomous vehicles, un- manned aerial vehicles, and robots, brings in a new technology challenge to establish ultra-low end-to-end latency mobile networking to enable holistic computing mechanisms. With the aid of open-loop wireless communication and proactive network association in vehicle-centric heterogeneous network architecture, anticipatory mobility management relying on inference and learning from big vehicular data plays a key role to facilitate such a new technological paradigm. Anticipatory mobility management aims to predict APs to be connected in the next time instant and in a real-time manner, such that ultra-low latency downlink open-loop communication can be realized with proactive network association. In this paper, we successfully respond this technology challenge using big data analytics with location-based learning and inference tech- niques, to achieve satisfactory performance of predicting APs. Real vehicular movement data have been used to verify that the proposed prediction methods are effective for the purpose of anticipatory mobility management and thus ultra-low latency mobile networking.",https://ieeexplore.ieee.org/document/8422231/,2018 IEEE International Conference on Communications (ICC),20-24 May 2018,ieeexplore
10.1109/ISMS.2010.32,Application of Feed-Forward Neural Network and MMI-Supervised Vector Quantizer to the Task of Content Based Audio Segmentation by Co-operative Unmanned Flying Robots,IEEE,Conferences,"This paper deals with the preliminary experiments on general audio segmentation using a MMI-supervised tree-based vector quantizer and feed-forward neural network. This method has been tested with the aim of detection of environmental sounds and speech in a sound stream. The segmentation of an audio stream is needed for successful localization of speech or environmental sounds in a stream and their possible future classification or even separation. This method has been developed as a preliminary solution of the task of real-world audio signal segmentation by a set of co-operative unmanned flying robots. Application of the proposed method has been tested in simulating software NESCUAR 1.0. (Natural Environment Simulator for Cooperative Unmanned Aerial Robots, version 1.0), a simulating software tool developed by the authors of this paper. The presented method can be also applied separately; its application is not dependent on the simulating software NESCUAR 1.0.",https://ieeexplore.ieee.org/document/5416111/,"2010 International Conference on Intelligent Systems, Modelling and Simulation",27-29 Jan. 2010,ieeexplore
10.1109/ACIT47987.2019.8991028,Application of Fuzzy Neural Networks in Robotic Path Planning,IEEE,Conferences,This paper essentially discusses different methodologies of Fuzzy Neural Networks which are implemented to robust the functionality of mobile robots in dynamic and static environment. Fusion of algorithms is important to increase the working of any system provided. Different kind of mobile robots along with various algorithms frameworks are taken as case studies for this paper. Due to the reason that typical mathematical models used to make robots mobile in real environment were not very useful as they were not catering for the limitation of robotic system memory. Thus new methodologies are being discussed and implemented by robotics research community.,https://ieeexplore.ieee.org/document/8991028/,2019 International Arab Conference on Information Technology (ACIT),3-5 Dec. 2019,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/CYBER53097.2021.9588269,Application of YOLO Object Detection Network In Weld Surface Defect Detection,IEEE,Conferences,"As industrial production becomes more modern and intelligent today, the inspection of product quality of the workshop is becoming more and more accustomed to replacing the old manual visual inspection methods with automated inspection systems. In the welding field, automated welding robots are not only used in traditional large-scale automobile assembly lines. In more general welding work, welding robots also plays an important role. The inspection of the welding quality of the welding robot is mainly to detect the four main types of weld defects. Compared to traditional defect classification based on support vector machines and defect detection based on template matching, this paper uses a welding surface defect detection system designed based on deep learning methods. By working with workshop welding experts, a large-scale image of nearly 5000 pictures is built. Large-scale weld defect datasets, while using the real-time and accuracy of the YOLO series of deep learning object detection frameworks, the weld defects detection model reaches 75.5% mean average precision(mAP) in constructed weld defect data set. In addition, the construction cost of the detection model and the deployment time of the detection system are greatly reduced. During the field test of the system in the workshop, among a batch of welding workpieces provided by the factory, the detection accuracy of weld defects reached 71%, which initially met the requirements of the workshop for an automated defect detection system.",https://ieeexplore.ieee.org/document/9588269/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/RTSE.1998.766515,Application of mobile autonomous robots to artificial intelligence and information systems curricula,IEEE,Conferences,"Applies pedagogical ideas of teaching curricula by using strategies of themes and breadth-first coverage, together with the technology of intelligent agents (e.g. mobile autonomous robots), to a system of courses in computer science (artificial intelligence) and information systems (systems engineering). The project brings the issues and constraints of real-time systems, especially the programming component, to students in computer science and information systems curricula. This project's background started in June 1997 and continued during the first part of the 1997-1998 academic year. The actual project work started in January 1998 and is still continuing.",https://ieeexplore.ieee.org/document/766515/,Proceedings Real-Time Systems Education III,21-21 Nov. 1998,ieeexplore
10.1109/ICAICTA.2016.7803114,Applications of artificial intelligence control for Parallel Discrete-Manipulators,IEEE,Conferences,"Parallel Discrete-Manipulators are a special kind of force regulated manipulators which can undergo continuous motions despite being commanded through a large but finite number of states only. Real-time control of such systems requires very fast and efficient methods for solving their inverse static analysis. In this paper, artificial intelligence techniques (AI) are investigated for addressing the inverse static analysis of a planar parallel array featuring ten three-state force actuators and two applications using 3D Massively Parallel Robots (MPRs) with one and two layers. In particular, the research method used simulation software and hardware testing with the case of parallel manipulator with two level discrete pneumatic actuators. Simulations with typical desired displacement inputs are presented and a good performance of the results compared to AI is obtained. The comparison showed that the parallel manipulator has the Root Mean Squared Error (RMSE) has less than 10% and can be used for controlling the ternary states of discrete manipulators via AI.",https://ieeexplore.ieee.org/document/7803114/,"2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA)",16-19 Aug. 2016,ieeexplore
10.1109/IROS45743.2020.9341340,Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots,IEEE,Conferences,"The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",https://ieeexplore.ieee.org/document/9341340/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IJCNN.2015.7280807,Applying the canonical distributed Embodied Evolution algorithm in a collective indoor navigation task,IEEE,Conferences,"The automatic design of control systems for multi-robot teams that operate in real time is not affordable with traditional evolutionary algorithms mainly due to the huge computational requirements they imply. Embodied Evolution (EE) is an evolutionary paradigm that aims to address this problem through the embodiment of the individuals that make up the population in the physical robots. The interest for this type of evolutionary approach has been increasing steadily, leading to different algorithms and variations adapted to solve very specific practical cases. In a previous work, the authors started the implementation of a standard canonical EE algorithm that captures the more general principles of this paradigm and that can be applied to any distributed optimization problem. This canonical algorithm has been characterized already over a set of theoretical fitness landscapes corresponding to representative examples of the basic casuistry found in collective tasks. The current paper goes one step ahead in this research line, and the canonical algorithm is applied here in a collective navigation task in which a fleet of Micro Aerial Vehicles (MAVs) has to gather red rocks in an indoor scenario. The objective is to confirm that the characterization conclusions are generalizable to a practical case and to show that the canonical algorithm can be configured to operate as a specific algorithm easily.",https://ieeexplore.ieee.org/document/7280807/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/SAHCN.2014.6990347,Area coverage under low sensor density,IEEE,Conferences,"This paper presents a solution to the problem of monitoring a region of interest (RoI) using a set of nodes that is not sufficient to achieve the required degree of monitoring coverage. In particular, sensing coverage of wireless sensor networks (WSNs) is a crucial issue in projects due to failure of sensors. This scenario of limited funding hinders the traditional method of using mobile robots to move around the RoI to collect readings. Instead, our solution employs supervised neural networks to produce the values of the uncovered locations by extracting the non-linear relation among randomly deployed sensor nodes throughout the area. Moreover, we apply a hybrid backpropagation method to accelerate the learning convergence speed to a local minimum solution. We use a real-world data set from meteorological deployment for experimental validation and analysis.",https://ieeexplore.ieee.org/document/6990347/,"2014 Eleventh Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)",30 June-3 July 2014,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/AIVR46125.2019.00061,Augmented Reality for Human-Robot Cooperation in Aircraft Assembly,IEEE,Conferences,"Augmented Reality (AR) is often discussed as one of the enabling technologies in Industrie 4.0. In this paper, we describe a practical application, where Augmented Reality glasses are used not only for assembly assistance, but also as a means of communication to enable the orchestration of a hybrid team consisting of a human worker and two mobile robotic systems. The task of the hybrid team is to rivet so-called stringers onto an aircraft hull. While the two robots do the physically demanding, unergonomic and possibly hazardous tasks (squeezing and sealing rivets), the human takes over those responsibilities that need experience, multi-sensory sensitiveness and specialist knowledge. We describe the working scenario, the overall architecture and give design and implementation details on the AR application.",https://ieeexplore.ieee.org/document/8942239/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/FIE.2006.322654,Autonomous Robots as a Generic Teaching Tool,IEEE,Conferences,"An undergraduate bioengineering laboratory course using small autonomous robots has been developed to demonstrate control theory, learning, and behavior. The lab consists of several modules that demonstrate concepts in classical control theory, fuzzy logic, neural network control, and genetic algorithms. The autonomous agents are easy-to-build, inexpensive kit robots. Each robot functions independently in a real-world environment. Students program and retrieve data wirelessly using handheld computers. The hands-on nature of the lab modules engages students in ways that lectures, readings and software simulations cannot. By interacting with these robots, students directly experience the effects of unexpected environmental factors on designs and deviations from software simulations. The robots are easily adapted for use in many different aspects of two-year college and K-12 STEM education. Students are motivated to understand engineering, math and science principles in order to control the robots. Examples of use of the robots and modules by a local community college are presented",https://ieeexplore.ieee.org/document/4117154/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/AMS.2017.22,Autonomous Rover Navigation Using GPS Based Path Planning,IEEE,Conferences,"Nowadays, with the constant evolution of Artificial Intelligence and Machine Learning, robots are getting more perceptive than ever. For this quality they are being used in varying circumstances which humans cannot control. Rovers are special robots, capable of traversing through areas that are too difficult for humans. Even though it is a robust bot, lack of proper intelligence and automation are its basic shortcomings. As the main purpose of a rover is to traverse through areas of extreme difficulties, therefore an intelligent path generation and following system is highly required. Our research work aimed at developing an algorithm for autonomous path generation using GPS (Global Positioning System) based coordinate system and implementation of this algorithm in real life terrain, which in our case is MDRS, Utah, USA. Our prime focus was the development of a robust but easy to implement system. After developing such system, we have been able to successfully traverse our rover through that difficult terrain. It uses GPS coordinates of target points that will be fed into the rover from a control station. The rover capturing its own GPS signal generates a path between the current location and the destination location on its own. It then finds the deviation in its current course of direction and position. And eventually it uses Proportional Integral Derivative control loop feedback mechanism (PID control algorithm) for compensating the error or deviation and thus following that path and reach destination. A low cost on board computer (Raspberry Pi in our case) handles all the calculations during the process and drives the rover fulfilling its task using an microcontroller (Arduino).",https://ieeexplore.ieee.org/document/8424312/,2017 Asia Modelling Symposium (AMS),4-6 Dec. 2017,ieeexplore
10.1109/AERO47225.2020.9172804,Autonomous Search for Underground Mine Rescue Using Aerial Robots,IEEE,Conferences,"In this paper we present a comprehensive solution for autonomous underground mine rescue using aerial robots. In particular, a new class of Micro Aerial Vehicles are equipped with the ability to localize and map in subterranean settings, explore unknown mine environments on their own, and perform detection and localization of objects of interest for the purposes of mine rescue (i.e., “human survivors” and associated objects such as “backpacks”, “smartphones” or “tools”). For the purposes of GPS-denied localization and mapping in the visually-degraded underground environments (e.g., a smoke-filled mine during an accident) the solution relies on the fusion of LiDAR data with thermal vision frames and inertial cues. Autonomous exploration is enabled through a graph-based search algorithm and an online volumetric representation of the environment. Object search is then enabled through a deep learning-based classifier, while the associated location is queried using the online reconstructed map. The complete software framework runs onboard the aerial robots utilizing the integrated embedded processing resources. The overall system is extensively evaluated in real-life deployments in underground mines.",https://ieeexplore.ieee.org/document/9172804/,2020 IEEE Aerospace Conference,7-14 March 2020,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IES53407.2021.9594013,Ball Position Transformation with Artificial Intelligence Based on Tensorflow Libraries,IEEE,Conferences,Research on wheeled soccer robots has been carried out by several researchers. This is due to the existence of national and international competitions. Previous research was to create a ball position transformation system with a modified method of neural network architecture. This research was developed by building an intelligent transformation system with the Tensorflow library. This transformation system aims to be able to directly measure the distance of objects in real terms without first changing the environmental image from an omni field to a flat plane with conventional camera calibration techniques. This process can replace manual calibration with a variety of field size changes The system can transform with mean error 0.0000026 on epoch 10000 using “conda-tensorflowneural network” libraries. It can transform the position of the ball from the omni space to the cartesian space. This system was implemented on wheeled soccer robot as keeper.,https://ieeexplore.ieee.org/document/9594013/,2021 International Electronics Symposium (IES),29-30 Sept. 2021,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/IROS40897.2019.8967694,Benchmarking and Workload Analysis of Robot Dynamics Algorithms,IEEE,Conferences,"Rigid body dynamics calculations are needed for many tasks in robotics, including online control. While there currently exist several competing software implementations that are sufficient for use in traditional control approaches, emerging sophisticated motion control techniques such as nonlinear model predictive control demand orders of magnitude more frequent dynamics calculations. Current software solutions are not fast enough to meet that demand for complex robots. The goal of this work is to examine the performance of current dynamics software libraries in detail. In this paper, we (i) survey current state-of-the-art software implementations of the key rigid body dynamics algorithms (RBDL, Pinocchio, Rigid-BodyDynamics.jl, and RobCoGen), (ii) establish a methodology for benchmarking these algorithms, and (iii) characterize their performance through real measurements taken on a modern hardware platform. With this analysis, we aim to provide direction for future improvements that will need to be made to enable emerging techniques for real-time robot motion control. To this end, we are also releasing our suite of benchmarks to enable others to help contribute to this important task.",https://ieeexplore.ieee.org/document/8967694/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/SSCI.2018.8628809,Bidirectional Fuzzy Brain Emotional Learning Control for Aerial Robots,IEEE,Conferences,This paper proposes a Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control system to control Aerial Robots. The proposed controller is based on the emotional and logical processing of the brain. The proposed control system merges fuzzy inference and a bidirectional brain emotional learning algorithm. The Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control can learn from scratch and adapt rapidly in real-time to control the system without much prior information. The proposed controller is tested against simulations of both a 1-Degree-Of-Freedom (DOF) flapping wing and a 6DOF flapping wing model and successfully implemented on a 1DOF flapping wing experiment which showcases the learning and adaptation capability in a real-time environment.,https://ieeexplore.ieee.org/document/8628809/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IECON.2007.4460382,Biomimetics Robots From Bio-inspiration to Implementation,IEEE,Conferences,"Biomimetics focuses on making nature as a model of inspiration that would immensely help conscious abstraction of new principles and ideas, foster innovative design collections, find out new techniques and functionalities, seek new paradigms and methods, develop new materials, and design new streams of intelligent machines, robots, systems, devices, algorithms, etc. Biomimetics incorporates materials, concepts and techniques drawn from naturally made substances, and resembles biological systems in structure, mechanism and/or function as necessary. Smart materials are the foundation supporting the development of new biomimetic based technology. Wide range of biologically inspired robots and intelligent systems has been developed. However, engineering such biomimetic intelligent creatures were hampered by physical and technological constraints, and it is still a challenge. Making robots and intelligent machines that are actuated by biologically inspired artificial muscles would create new reality with great potentials. This paper provides the concept and the importance of Biomimetic as an interdisciplinary field. In addition, the paper introduces and discusses scientific ideas and directions of research activities in the field. The paper presents key development in the field of Biomimetic robots, and finally it underlines the potential of the field and the challenges facing it.",https://ieeexplore.ieee.org/document/4460382/,IECON 2007 - 33rd Annual Conference of the IEEE Industrial Electronics Society,5-8 Nov. 2007,ieeexplore
10.1109/INES.2018.8523877,Body State Recognition for a Quadruped Mobile Robot,IEEE,Conferences,"The body states must be tracked by the onboard software on the robot to make good decisions. A human can pick up this machine or if the robot encounters anomalies (e.g. fall over) during locomotion, the state changes must be identified to execute the necessary responses. The authors of this paper developed a machine learning model which can recognize four states (normal, pick-up, fall over, poked) of a Sony AIBO robot. A deep neural network classifier with these predictors achieved 98% accuracy on unseen data and actual test runs on the robot proved the practical use with real-time execution speed. These properties made the proposed method a good candidate for adaption to other legged robots.",https://ieeexplore.ieee.org/document/8523877/,2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES),21-23 June 2018,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.23919/ACC.1989.4790240,CONDOR: A Coarse-grained Parallel Architecture for Robot Control,IEEE,Conferences,"This paper presents an overview of the CONDOR, a real-time development environment designed for robotics research applications. The architecture is based on standard hardware components consisting of upto eight microprocessors interconnected through a shared memory bus, and is coupled with a powerful software environment based on message passing that enables the development of control programs for complicated robots. The hardware is extremely easy to set up since it uses standard components. Besides program libraries tuned for real-time control, the software utilities include a multi-processor pseudo-terminal emulator, a file-server and a flexible symbolic debugger that greatly enhance programmer productivity.",https://ieeexplore.ieee.org/document/4790240/,1989 American Control Conference,21-23 June 1989,ieeexplore
10.1109/ISVLSI49217.2020.00-12,CPSoSaware: Cross-Layer Cognitive Optimization Tools &amp; Methods for the Lifecycle Support of Dependable CPSoS,IEEE,Conferences,"Cyber-physical Systems of Systems (CPSoS) are large complex systems where physical elements interact with and are controlled by a large number of distributed and networked computing elements as well as human users. Their increasingly stringent demands on efficient use of resources, high service and product quality levels and, of course low cost and competitiveness on the world market introduce big challenges related to the design operation continuum of dependable connected CPSs. The CPSoSaware project aims at developing the models and software tools to allocate computational power/resources to the CPS end devices and autonomously determining what cyber-physical processes will be handled by the devices' heterogeneous components (CPUs, GPUs, FPGA fabric, software stacks). The project relies on Artificial Intelligence (AI) support to strengthen reliability, fault tolerance and security at system level and also to lead to CPS designs that work in a decentralized way, collaboratively, in an equilibrium, by sharing tasks and data with minimal central intervention. The CPSoSaware system will interact with the human users/operators through extended reality visual and touchable interfaces increasing situational awareness. The CPSoSaware system will be evaluated: i) in the automotive sector, in mixed traffic environments with semi-autonomous connected vehicles and ii) in the manufacturing industry where inspection and repair scenarios are employed using collaborative robots.",https://ieeexplore.ieee.org/document/9155036/,2020 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),6-8 July 2020,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/IJCNN52387.2021.9533738,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,IEEE,Conferences,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",https://ieeexplore.ieee.org/document/9533738/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/ICRA48506.2021.9561926,Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs,IEEE,Conferences,"Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 °/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",https://ieeexplore.ieee.org/document/9561926/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA40945.2020.9197336,CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning,IEEE,Conferences,"Visual navigation tasks in real-world environments often require both self-motion and place recognition feedback. While deep reinforcement learning has shown success in solving these perception and decision-making problems in an end-to-end manner, these algorithms require large amounts of experience to learn navigation policies from high-dimensional data, which is generally impractical for real robots due to sample complexity. In this paper, we address these problems with two main contributions. We first leverage place recognition and deep learning techniques combined with goal destination feedback to generate compact, bimodal image representations that can then be used to effectively learn control policies from a small amount of experience. Second, we present an interactive framework, CityLearn, that enables for the first time training and deployment of navigation algorithms across city-sized, realistic environments with extreme visual appearance changes. CityLearn features more than 10 benchmark datasets, often used in visual place recognition and autonomous driving research, including over 100 recorded traversals across 60 cities around the world. We evaluate our approach on two CityLearn environments, training our navigation policy on a single traversal per dataset. Results show our method can be over 2 orders of magnitude faster than when using raw images, and can also generalize across extreme visual changes including day to night and summer to winter transitions.",https://ieeexplore.ieee.org/document/9197336/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICIP42928.2021.9506200,Classification of RIGID and Non-Rigid Transformations with Autoencoder Representations,IEEE,Conferences,"Feature matching in transformed images is critical to many fields of computer science, from autonomous robots to video analysis. However, most widely used feature matching algorithms vary in their ability to track features depending on whether rigid or non-rigid image transformations occur. This makes it critical, especially in real-time calculations, to be able to identify what kind of transformation is taking place quickly in order to deploy the best feature matching algorithm for that type of transformation. The proposed research uses a combined autoencoder and neural network classification model to classify rigid or non-rigid transformations in order to improve feature matching on the image pairs. This system is the first to perform this kind of analysis with representation learning and opens new ways to improving feature matching performance. We show that using this method improves the amount of feature matches found between correctly identified image pairs.",https://ieeexplore.ieee.org/document/9506200/,2021 IEEE International Conference on Image Processing (ICIP),19-22 Sept. 2021,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROMAN.2005.1513816,Cognitive robots: perceptual associative memory and learning,IEEE,Conferences,"In this position paper we attempt to derive an architecture and mechanism for perceptual associative memory and learning for software agents and cognitive robots from what is known, or believed, about the same faculties in human and other animal cognition. Based on that of the IDA model of global workspace theory, a conceptual and computational model of cognition, this architecture, together with its mechanisms, offers the real possibility of autonomous software agents and cognitive robots learning their own ontologies during a developmental period. Thus the onerous chore of designing and implementing such an ontology can be avoided.",https://ieeexplore.ieee.org/document/1513816/,"ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",13-15 Aug. 2005,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IVCNZ51579.2020.9290542,Comparison of Face Detection Algorithms on Mobile Devices,IEEE,Conferences,"Face detection is a fundamental task for many computer vision applications such as access control, security, advertisement, automatic payment, and healthcare. Due to technological advances mobile robots are becoming increasingly common in such applications (e.g. healthcare and security robots) and consequently there is a need for efficient and effective face detection methods on such platforms. Mobile robots have different hardware configurations and operating conditions from desktop applications, e.g. unreliable network connections and the need for lower power consumption. Hence results for face detection methods on desktop platforms cannot be directly translated to mobile platforms.We compare four common face detection algorithms, Viola-Jones, HOG, MTCNN and MobileNet-SSD, for use in mobile robotics using different face data bases. Our results show that for a typical mobile configuration (Nvidia Jetson TX2) Mobile-NetSSD performed best with 90% detection accuracy for the AFW data set and a frame rate of almost 10 fps with GPU acceleration. MTCNN had the highest precision and was superior for more difficult face data sets, but did not achieve real-time performance with the given implementation and hardware configuration.",https://ieeexplore.ieee.org/document/9290542/,2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ),25-27 Nov. 2020,ieeexplore
10.1109/IROS.2001.977213,Computation principles for the development of visual skills in robotics,IEEE,Conferences,"Different working principles are often considered when different visual behaviors are implemented in an agent. This occurs basically because the physical interaction between the behavior and the environment is not studied in depth. The paper shows how apparently different visual behaviors share common theoretical principles for their working mechanism. In particular properties related to the navigation vector field they compute in the environment, provide a base to explain visual learning, guidance, topological navigation, sub goal placement, obstacle avoidance and navigation enhancement. To handle the mathematics of a vector field robust tools are needed. Techniques borrowed from computer vision literature provide the necessary mathematical tools. All behaviors described have been tested in real robots. On going research is still in progress for topological navigation and subgoal placement.",https://ieeexplore.ieee.org/document/977213/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/ROBOT.1988.12090,Condor: a revised architecture for controlling the Utah-MIT hand,IEEE,Conferences,"A fast architecture for controlling the Utah-MIT hand and other such complex robots is reviewed. These robots are characterized by a large number of joints and consequently demand powerful computer architectures to be controlled and utilized effectively. The version of the architecture derives its power from a novel bus-to-bus adaptor to couple a development host running a time-sharing operating system with a multimicroprocessor system devoted to real-time computations. The software is characterized by a few simple design concepts but provides the facilities out of which powerful utilities like a multiprocessor pseudoterminal emulator, a transparent fast file server, and a truly flexible powerful symbolic debugger could be constructed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/12090/,Proceedings. 1988 IEEE International Conference on Robotics and Automation,24-29 April 1988,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223341,Context Dependent Trajectory Generation using Sequence-to-Sequence Models for Robotic Toilet Cleaning,IEEE,Conferences,"A robust, easy-to-deploy robot for service tasks in a real environment is difficult to construct. Record-and-playback (R&amp;P) is a method used to teach motor-skills to robots for performing service tasks. However, R&amp;P methods do not scale to challenging tasks where even slight changes in the environment, such as localization errors, would either require trajectory modification or a new demonstration. In this paper, we propose a Sequence-to-Sequence (Seq2Seq) based neural network model to generate robot trajectories in configuration space given a context variable based on real-world measurements in Cartesian space. We use the offset between a target pose and the actual pose after localization as the context variable. The model is trained using a few expert demonstrations collected using teleoperation. We apply our proposed method to the task of toilet cleaning where the robot has to clean the surface of a toilet bowl using a compliant end-effector in a constrained toilet setting. In the experiments, the model is given a novel offset context and it generates a modified robot trajectory for that context. We demonstrate that our proposed model is able to generate trajectories for unseen setups and the executed trajectory results in cleaning of the toilet bowl.",https://ieeexplore.ieee.org/document/9223341/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/WHC.2011.5945522,Control of a desktop mobile haptic interface,IEEE,Conferences,"Most haptic devices share two main limits: they are grounded and they have limited workspace. A possible solution is to create haptic interfaces by combining mobile robots and standard grounded force-feedback devices, the so called Mobile Haptic Interfaces (MHIs). However, MHIs are characterized by dynamical limitations due to performance of the employed devices. This paper focuses on basic design issues and presents a novel (prototype) Mobile Haptics Platform that employs the coordination of numerically controlled wheel torques to render forces to a user handle placed on the top of the device. The interface, consisting in a small omni-directional robot, is link-less, fully portable and it has been designed to support home-rehabilitation exercises. In the present paper we shall review relevant choices concerning the functional aspects and the control design. In particular a specific embedded sensor fusion was implemented to allow the device to move on a desk without drifting. The sensor fusion algorithm has been optimized to provide users with a quality force feedback while ensuring accurate position tracking. The two requirements are in contrast each other and a specific variant of the Extended Kalman Filter (EKF) was required to allow the device working.",https://ieeexplore.ieee.org/document/5945522/,2011 IEEE World Haptics Conference,21-24 June 2011,ieeexplore
10.1109/IROS.2012.6385803,Control of contact forces: The role of tactile feedback for contact localization,IEEE,Conferences,"This paper investigates the role of precise estimation of contact points in force control. This analysis is motivated by scenarios in which robots make contacts, either voluntarily or accidentally, with different parts of their body. Control paradigms that are usually implemented in robots with no tactile system, make the hypothesis that contacts occur at the end-effectors only. In this paper we try to investigate what happens when this assumption is not verified. First we consider a simple feedforward force control law, and then we extend it by introducing a proportional feedback term. For both controllers we find the error in the resulting contact force, that is induced by a hypothetic error in the estimation of the contact point. We show that, depending on the geometry of the contact, incorrect estimation of contact points can induce undesired joint accelerations. We validate the presented analysis with tests on a simulated robot arm. Moreover we consider a complex real world scenario, where most of the assumptions that we make in our analytical derivation do not hold. Through tests on the iCub humanoid robot we see how errors in contact localization affect the performance of a parallel force/position controller. In order to estimate contact points and contact forces on the forearm of the iCub we do not use any model of the environment, but we exploit its 6-axis force/torque sensor and its sensorized skin.",https://ieeexplore.ieee.org/document/6385803/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROBOT.1998.677351,Cooperative behavior acquisition in multi-mobile robots environment by reinforcement learning based on state vector estimation,IEEE,Conferences,"This paper proposes a method that acquires robots' behaviors based on the estimation of the state vectors. In order to acquire the cooperative behaviors in multi-robot environments, each learning robot estimates the local predictive model between the learner and the other objects separately. Based on the local predictive models, the robots learn the desired behaviors using reinforcement learning. The proposed method is applied to a soccer playing situation, where a rolling ball and other moving robots are well modeled and the learner's behaviors are successfully acquired by the method. Computer simulations and real experiments are shown and a discussion is given.",https://ieeexplore.ieee.org/document/677351/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ISIC.2000.882949,Cooperative learning and planning for multiple robots,IEEE,Conferences,"The paper deals with the the subject of learning and planning for real mobile robots, using Sutton's (1991) Dyna algorithm. The Dyna algorithm integrates reinforcement learning, planning and reactive execution. We present an extension of the Dyna algorithm which includes symmetric and cooperative learning with multiple robots. We applied the extended version of the algorithm to a population of two real robots. Practical problems associated with the implementation of the algorithm on a real setup are solved. Results obtained from simulations and real experiments are presented and discussed.",https://ieeexplore.ieee.org/document/882949/,Proceedings of the 2000 IEEE International Symposium on Intelligent Control. Held jointly with the 8th IEEE Mediterranean Conference on Control and Automation (Cat. No.00CH37147),19-19 July 2000,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/LARC.2011.6086817,Coordination mechanisms for a multi-agent robotic system applied to search and target location,IEEE,Conferences,"In this paper we consider the problem of searching an unknown number of targets in static environment by a team of robots. As the targets positions and distribution are uncertain; the goal is to minimize the overall exploration time. Using cell maps, the key problem can be solved choosing the suitable cell for the individual robots so that they simultaneously explore different regions of the environment. We present an intelligent approach for the coordination of multiple robots, in which contrast to previous approaches, able to perform task allocations taking into account the trade-off between the costs of reaching the cell and its utility. This utility function has been modeled using neural networks and optimized with genetic algorithms. Besides, if the task produces some conflict between robots, a negotiation algorithm is used to collision avoidance. The proposed approach has been implemented in real-world experiments and its performance tested in simulation runs. The results given in this paper demonstrate that our coordination mechanism significantly reduces the exploration time and increase the effectiveness compared to previous approaches.",https://ieeexplore.ieee.org/document/6086817/,"IX Latin American Robotics Symposium and IEEE Colombian Conference on Automatic Control, 2011 IEEE",1-4 Oct. 2011,ieeexplore
10.1109/DICTA.2018.8615819,Crack-pot: Autonomous Road Crack and Pothole Detection,IEEE,Conferences,"With the advent of self-driving cars and autonomous robots, it is imperative to detect road impairments like cracks and potholes and to perform necessary evading maneuvers to ensure fluid journey for on-board passengers or equipment. We propose a fully autonomous robust real-time road crack and pothole detection algorithm which can be deployed on any GPU based conventional processing boards with an associated camera. The approach is based on a deep neural net architecture which detects cracks and potholes using texture and spatial features. We also propose pre-processing methods which ensure real-time performance. The novelty of the approach lies in using texture-based features to differentiate between crack surfaces and sound roads. The approach performs well in large viewpoint changes, background noise, shadows, and occlusion. The efficacy of the system is shown on standard road crack datasets.",https://ieeexplore.ieee.org/document/8615819/,2018 Digital Image Computing: Techniques and Applications (DICTA),10-13 Dec. 2018,ieeexplore
10.1109/WSE.2011.6081830,Cracking the Smart ClickBot,IEEE,Conferences,"Nowadays, almost every task involving Web traversing and information retrieval recurs to Web robots. Web robots are software programs that automatically traverse the Web's hypertext structure. They proliferate rapidly aside with the growth of the Web and are extremely valuable and important means not only for the large search engines, but also for many specialized services such as investment portals, competitive intelligence tools, etc. While many web robots serve useful purposes, recently, there have been cases linked to fraudulent activities committed by these Web robots. Click fraud, which is the act of generating illegitimate clicks, is one of them. This paper details the architecture and functionality of the Smart ClickBot, a sophisticated software bot that is designed to commit click fraud. It was first detected and reported by NetMosaics Inc. in March, 2010, a real time click fraud detection and prevention solution provider. We discuss the machine learning algorithms used, to identify all clicks exhibiting Smart ClickBot like patterns. We constructed a Bayesian classifier that automatically classifies server log data as being Smart ClickBot or not. We also introduce a Benchmark data set for Smart ClickBot. We disclose the results of our investigation of this bot to educate the security research community and provide information regarding the novelties of the attack.",https://ieeexplore.ieee.org/document/6081830/,2011 13th IEEE International Symposium on Web Systems Evolution (WSE),30-30 Sept. 2011,ieeexplore
10.1109/IROS.2003.1248914,Creation and analysis of a scenario based universal sensory driver layer with real-time fault tolerant properties,IEEE,Conferences,"Sensor fusion and sensor integration is becoming an increasingly popular approach in dealing with complex sensor systems in autonomous mobile robots (AMR). However, the procedure for the sensor integration and sensor fusion is a non-trivial process. This paper presents a scenario based approach to sensor fusion based on the autonomous evolution of sensory and actuator driver layers through environmental constraints (AEDEC) [T.A Choi, 2002]. Using the scenario based approach, the programmer's work of creating a sensory driver will be eliminated by having the AMR learn the driver on its own. In the process of creating each scenario, sensor fusion is automatically implemented. If sensors change or even if the sensor configuration changes, the driver can be updated by having the AMR relearn the driver over again. Due to the tabular structure of the scenario based sensory drivers, malfunctioning sensors can not only be detected, but the driver can automatically adapt to the malfunctioning sensor in real-time. Furthermore, different AMR's trained using AEDEC architecture will have similar interpretations of its environment. This is guaranteed by having the AMR learn the driver in the same highly structured training environment. The behavioral coding is simplified by eliminating any reference to hardware dependent parameters. Finally, the level of abstraction and the consistency of the highly structured environment allows for coding portability.",https://ieeexplore.ieee.org/document/1248914/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/ROBIO49542.2019.8961433,CyberEarth: a Virtual Simulation Platform for Robotics and Cyber-Physical Systems,IEEE,Conferences,"The increasing sophisticated robot and intelligent system applications require universal visualization platforms which can guarantee the security and efficiency of task process execution in the situation of user-programming and using different kinds of automated equipment. In this paper, we present a universal visualization framework to build up program-driven simulation software of complex robots and intelligent systems by integrating several open-source technical modules, including Ubuntu Linux operation-system, QT Creator IDE environment, ROS robot operation system, OSG(OpenSceneGraph) 3D scene, osgEarth GIS(Geographic Information System)-based 3D scene, and also Python based user-programing robotic script language. Many complex visualization simulation systems of complex tasks in wide area and dynamic scenarios are realized by using this framework. Based on this framework, we built a virtual simulation platform CyberEarth for robotics and Cyber-Physical systems. The typical robotic simulation task, which is a visual coverage task for Multi-Agent/UAV, is also introduced to demonstration the universality of this platform.",https://ieeexplore.ieee.org/document/8961433/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/AERO.2018.8396547,Data-driven quality prognostics for automated riveting processes,IEEE,Conferences,"Technologies based in robotics and automatics are reshaping the aerospace industry. Aircraft manufacturers and top-tier suppliers now rely on robotics to perform most of its operational tasks. Over the years, a succession of implemented mobile robots has been developed with the mission of automating important industrial processes such as welding, material handling or assembly procedures. However, despite the progress achieved, a major limitation is that the process still requires human supervision and an extensive quality control process. An approach to address this limitation is to integrate machine learning methods within the quality control process. The idea is to develop algorithms that can direct manufacturing experts towards critical areas requiring human supervision and quality control. In this paper we present an application of machine learning to a concrete industrial problem involving the quality control of a riveting machine. The proposal consists of an intelligent predictive model that can be integrated within the existing real time sensing and pre-processing sub-systems at the equipment level. The framework makes use of several data-driven techniques for pre-processing and feature engineering, combined with the most accurate algorithms, validated through k-folds cross validation technique which also estimates prediction errors. The model is able to classify the manufacturing process of the machine as nominal or anomalous according to a real-world data set of design requirements and operational data. Several machine learning algorithms are compared such as linear regression, nearest neighbor, support vector machines, decision trees, random forests and extreme gradient boost. Results obtained from the case study suggest that the proposed model produces accurate predictions which meet industrial standards.",https://ieeexplore.ieee.org/document/8396547/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/ICRA48506.2021.9562019,Decentralized Circle Formation Control for Fish-like Robots in the Real-world via Reinforcement Learning,IEEE,Conferences,"In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",https://ieeexplore.ieee.org/document/9562019/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA48506.2021.9561066,Decentralized Connectivity Maintenance with Time Delays using Control Barrier Functions,IEEE,Conferences,"Connectivity maintenance is crucial for the real world deployment of multi-robot systems, as it ultimately allows the robots to communicate, coordinate and perform tasks in a collaborative way. A connectivity maintenance controller must keep the multi-robot system connected independently from the system’s mission and in the presence of undesired real world effects such as communication delays, model errors, and computational time delays, among others. In this paper we present the implementation, on a real robotic setup, of a connectivity maintenance control strategy based on Control Barrier Functions. During experimentation, we found that the presence of communication delays has a significant impact on the performance of the controlled system, with respect to the ideal case. We propose a heuristic to counteract the effects of communication delays, and we verify its efficacy both in simulation and with physical robot experiments.",https://ieeexplore.ieee.org/document/9561066/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2016.7487617,Decentralized multi-agent exploration with online-learning of Gaussian processes,IEEE,Conferences,"Exploration is a crucial problem in safety of life applications, such as search and rescue missions. Gaussian processes constitute an interesting underlying data model that leverages the spatial correlations of the process to be explored to reduce the required sampling of data. Furthermore, multi-agent approaches offer well known advantages for exploration. Previous decentralized multi-agent exploration algorithms that use Gaussian processes as underlying data model, have only been validated through simulations. However, the implementation of an exploration algorithm brings difficulties that were not tackle yet. In this work, we propose an exploration algorithm that deals with the following challenges: (i) which information to transmit to achieve multi-agent coordination; (ii) how to implement a light-weight collision avoidance; (iii) how to learn the data's model without prior information. We validate our algorithm with two experiments employing real robots. First, we explore the magnetic field intensity with a ground-based robot. Second, two quadcopters equipped with an ultrasound sensor explore a terrain profile. We show that our algorithm outperforms a meander and a random trajectory, as well as we are able to learn the data's model online while exploring.",https://ieeexplore.ieee.org/document/7487617/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/ICBBE.2008.696,Decoding Hand Kinematics and Neural States Using Gaussian Process Model,IEEE,Conferences,"Probabilistic modeling of correlated neural population firing activity is central to understanding the neural code and building practical decoding algorithms, the accurate reconstruction of a continuous motion signal is necessary for the control of devices such as computer cursors, robots, or a patient's own paralyzed limbs. For such applications we developed a realtime system that uses Gaussian process techniques to estimate hand motion from the firing rates of multiple neurons. Gaussian Processes for Machine Learning presents one of the most important Bayesian machine learning approaches based on a particularly effective method for placing a prior distribution over the space of functions. Decoding was performed using Gaussian processes model which gives an efficient method for Bayesian inference when the firing rates and hand kinematics are nonlinear. Gaussian processes provide a principled, practical, probabilistic approach to learning in noisy measurements. In off-line experiments, the Gaussian processes model reconstructions of hand trajectory were more accurate than previously reported results. The resulting decoding algorithm provides a principled probabilistic model of motor-cortical coding, decodes hand motion in real time, provides an estimate of uncertainty, and is straight to implement. Additionally the formulation unifies and extends previous models of neural coding while providing insights into the motor-cortical code.",https://ieeexplore.ieee.org/document/4535576/,2008 2nd International Conference on Bioinformatics and Biomedical Engineering,16-18 May 2008,ieeexplore
10.1109/IROS40897.2019.8967874,Deep Dive into Faces: Pose &amp; Illumination Invariant Multi-Face Emotion Recognition System,IEEE,Conferences,"One of the advancements in humanization of robots is its ability to recognize human emotions. Facial expression plays a key role in identifying human emotions relative to other cues. In this research, an intelligent network capable of real-time emotion recognition from multiple faces using deep learning technique is presented. The proposed network is based on Convolution Neural Network (CNN) in which three blocks of Convolution layers for feature extraction and two blocks of Dense layers for classification are used. The novelty of this method lies in recognizing emotions from multiple faces simultaneously in real time and its invariance to head pose, illumination and age factor. Most of reported work in literature for multiple faces is for frontal face without illumination variation. The proposed emotion recognition system is deployed on Raspberry Pi3 B+ for human robot interaction applications and achieved an average accuracy of 95.8% in real time.",https://ieeexplore.ieee.org/document/8967874/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IJCNN.2018.8489239,Deep Learning-based Cooperative Trail Following for Multi-Robot System,IEEE,Conferences,"Following trails in the wild is an essential capability of out-door autonomous mobile robots. Recently, deep learning-based approaches have made great advancements in this field. However, the existing research only focuses on the trail following with a single robot. In contrast, many robotic tasks in the reality, such as search and patrolling, are conducted by a group of robots. While these robots are grouped to move in the wild, they can cooperate to significantly promote the trail following accuracy, for example, by sharing images of different view angles or real-time decision fusion. This paper proposes such an approach named DL-Cooper that enables multi-robot vision-based trail following based on deep learning algorithms. It allows each robot to make a decision respectively with deep neural network and then fusion the decisions on the collective level with the support of back-end cloud computing infrastructure. It also takes Quality of Service (QoS) assurance, a very essential property of robotic software, into consideration. By limiting the condition to fusion decisions, the time latency can be minimally sacrificed. Experiments on the real-world dataset show that our approach has significantly improved the accuracy of the single-robot system.",https://ieeexplore.ieee.org/document/8489239/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/ICARSC52212.2021.9429811,Deep Reinforcement Multi-Directional Kick-Learning of a Simulated Robot with Toes,IEEE,Conferences,"This paper describes a thorough analysis of using PPO to learn kick behaviors with simulated NAO robots in the simspark environment. The analysis includes an investigation of the influence of PPO hyperparameters, network size, training setups and performance in real games. We believe to improve the state of the art mainly in four points: first, the kicks are learned with a toed version of the NAO robot, second, we improve the reliability with respect to kickable area and avoidance of falls, third, the kick can be parameterized with desired distance and direction as input to the deep network and fourth, the approach allows to integrate the learned behavior seamlessly into soccer games. The result is a significant improvement of the general level of play.",https://ieeexplore.ieee.org/document/9429811/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/ICUAS.2019.8797770,Deep learning based semantic situation awareness system for multirotor aerial robots using LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots, based on 2D LIDAR measurements, targeting the understanding of the environment and assuming to have a precise robot localization as an input of our algorithm. Our proposed situation awareness system calculates a semantic map of the objects of the environment as a list of circles represented by their radius, and the position and the velocity of their center in world coordinates. Our proposed algorithm includes three main parts. First, the LIDAR measurements are preprocessed and an object segmentation clusters the candidate objects present in the environment. Secondly, a Convolutional Neural Network (CNN) that has been designed and trained using an artificially generated dataset, computes the radius and the position of the center of individual circles in sensor coordinates. Finally, an indirect-EKF provides the estimate of the semantic map in world coordinates, including the velocity of the center of the circles in world coordinates.We have quantitative and qualitative evaluated the performance of our proposed situation awareness system by means of Software-In-The-Loop simulations using VRep with one and multiple static and moving cylindrical objects in the scene, obtaining results that support our proposed algorithm. In addition, we have demonstrated that our proposed algorithm is capable of handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) and moving (i.e. a person) objects.",https://ieeexplore.ieee.org/document/8797770/,2019 International Conference on Unmanned Aircraft Systems (ICUAS),11-14 June 2019,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ISORC.2019.00025,DeepNNCar: A Testbed for Deploying and Testing Middleware Frameworks for Autonomous Robots,IEEE,Conferences,"This demo showcases the features of an adaptive middleware framework for resource constrained autonomous robots like DeepNNCar (Figure 1). These robots use Learning Enabled Components (LECs), trained with deep learning models to perform control actions. However, these LECs do not provide any safety guarantees and testing them is challenging. To overcome these challenges, we have developed an adaptive middleware framework that (1) augments the LEC with safety controllers that can use different weighted simplex strategies to improve the systems safety guarantees, and (2) includes a resource manager to monitor the resource parameters (temperature, CPU Utilization), and offload tasks at runtime. Using DeepNNCar we will demonstrate the framework and its capability to adaptively switch between the controllers and strategies based on its safety and speed performance.",https://ieeexplore.ieee.org/document/8759365/,2019 IEEE 22nd International Symposium on Real-Time Distributed Computing (ISORC),7-9 May 2019,ieeexplore
10.1109/ICMLA51294.2020.00201,Defending Against Localized Adversarial Attacks on Edge-Deployed Monocular Depth Estimators,IEEE,Conferences,"Estimation of depth from a single image is an important scene understanding task in computer vision. With the advent of Deep Learning and Convolutional Neural Networks, staggeringly high accuracies have been achieved in this task. With advancements in model optimization, it has been possible to deploy these models on edge devices, allowing for efficient depth estimation in safety-critical applications in robots, rovers, drones and even self-driving vehicles. However, these models are susceptible to attacks from malicious adversaries, which aim to distort the output of the model for a seemingly clean image by adding minute perturbations. In the real-world scenario, the most plausible attack is the adversarial patch, which can be printed and used as a physical adversarial attack against Deep Learning models. In the case of Monocular Depth Estimation, we show that small adversarial patches, which range from 0.7% to 5% of the image size, greatly worsen model performance. It is thus essential that these models are made robust using defense mechanisms, to defend against malicious inputs while also not reducing performance on clean images. Moreover, it is essential that the defense mechanism be computationally efficient, for real-time inference on edge devices. In this work, we propose the first defense mechanism against adversarial patches for a regression network, in the context of Monocular Depth Estimation on an edge device. The defense mechanism adds very little overhead time of 38 milliseconds on a Raspberry Pi 3 Model B, maintaining performance on clean images while also achieving near clean image levels of performance on adversarial inputs.",https://ieeexplore.ieee.org/document/9356303/,2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),14-17 Dec. 2020,ieeexplore
10.1109/BDAI52447.2021.9515251,Design and Simulation of Tracked Mobile Robot Path Planning,IEEE,Conferences,"Aiming at the problem of autonomous navigation of robots in unknown environments, the robot operating system ROS is used as a development platform, and an autonomous navigation system is designed based on open source function packages such as Gmapping and Navigation, so that robots equipped with this system can learn map information in unknown environments. And based on the map to achieve positioning, path planning, obstacle avoidance and other functions. The 3D physical simulation software Gazebo simulates the environment and loads the designed URDF robot model to simulate and verify the autonomous navigation system. The results show that the autonomous navigation system can enable the robot to achieve accurate mapping, positioning, real-time obstacle avoidance and path planning in an unknown environment.",https://ieeexplore.ieee.org/document/9515251/,2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI),2-4 July 2021,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/AEMCSE51986.2021.00262,Design of Motion Control System of Handling Robot,IEEE,Conferences,"Handling robots are very important for improving productivity, reducing work intensity, improving the surrounding environment, and ensuring work safety. Based on the kinematics analysis of a two-degree-of-freedom manipulator based on a slider mechanism, this paper uses an open motion controller as a development platform to carry out hardware design and software development to realize the flexible control of the handling robot, with simple structure and real-time control, open structure, standard programming and rich man-machine interface, etc. which can be widely used in material destacking and palletizing handling.",https://ieeexplore.ieee.org/document/9513197/,"2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)",26-28 March 2021,ieeexplore
10.1109/IROS.2018.8594335,Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline,IEEE,Conferences,"In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.",https://ieeexplore.ieee.org/document/8594335/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.23919/ICAC50006.2021.9594118,Deterministic Planning for Flexible Intralogistics,IEEE,Conferences,"An automated planning unit that enables the user to deterministically schedule transportation tasks for intralogistics use cases is proposed. The developed solution aims at inducing a high degree of determinism into transportation task planning in manufacturing industries while at the same time providing the user with the opportunity to flexibly react to rapidly changing constraints, such as updated order situations. The main objective of the software tool is to facilitate the order management process and ensure conflict-free path planning and following of a centrally guided fleet of mobile robots serving transportation tasks. Furthermore, in order to meet customer demands in terms of responsiveness to altered circumstances, the system is able to re-allocate already planned transportation tasks in favor of more urgent ones that may come in without further notice. This is achieved by adopting concepts commonly used in real-time operating systems to the complex problem of intralogistics task scheduling. Sporadically incoming transportation tasks are scheduled dynamically with regard to deadlines, priority levels, available resources as well as estimated execution effort. Flexibility and system responsiveness are increased noticeable by applying on-line task migration mechanisms. The eligibility of the adapted concepts is demonstrated by deploying the proposed solution to test cases within a simulation environment. For this purpose a scalable Key Performance Indicator (KPI) function is proposed as well.",https://ieeexplore.ieee.org/document/9594118/,2021 26th International Conference on Automation and Computing (ICAC),2-4 Sept. 2021,ieeexplore
10.1109/MHS.2000.903293,Developing Khepera robot applications in a Webots environment,IEEE,Conferences,"Khepera is a high performance mini-robot. Its compact power allows an efficient experimentation using a real robot and applying the basic simulation tools. Webots is a high quality Khepera simulator used in the fields of autonomous systems, intelligent robotics, evolutionary robotics, machine learning, computer vision, and artificial intelligence. The simulation program can be transferred to the real robots easily. The aim of this article is to support the development of Khepera applications in the Webots environment. Starting from the introduction of Khepera robot and its development methodologies, the paper presents and analyses an application example of Khepera robot in the Webots environment. Finally, current applications and future research directions are presented.",https://ieeexplore.ieee.org/document/903293/,MHS2000. Proceedings of 2000 International Symposium on Micromechatronics and Human Science (Cat. No.00TH8530),22-25 Oct. 2000,ieeexplore
10.1109/RO-MAN50785.2021.9515353,Developing an Engagement-Aware System for the Detection of Unfocused Interaction,IEEE,Conferences,"We introduce a perception system for social robots that is able to detect a person’s engagement in an interaction from nonverbal cues independently of principal user activity. This was achieved by the introduction of a set of proxemics, body posture and attention features relevant for human-human interaction. The features were extracted from RGB-D image data of a single Kinect and utilized to train two separate machine learning models. Multiple system configurations and feature combinations were tested, and their impact on the detection of user engagement evaluated. Combining all features, our perception system reaches an F1-score of 81% when estimating an observed person’s interaction intent through binary classification. Regression of a user’s level of availability deviates from the given ground truth values by 13.27% on average. Finally, a prototype was implemented which is able to simultaneously run both previous estimates in real-time using a shared feature vector. In the following, the proposed system shall be used to design robots whose behavior shows their awareness of user engagement.",https://ieeexplore.ieee.org/document/9515353/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/IntelliSys.2017.8324230,Developing video games with elementary adaptive artificial intelligence in unity: An intelligent systems approach,IEEE,Conferences,"Video games have increasingly demonstrated a great deal of audiovisual realism, in par with the massive performance improvement of computer systems. At the same time, their Artificial Intelligence (AI) component falls short in terms of realism because it is usually based on non-adaptive methods. Adaptive AI mechanisms can help increase video game realism allowing the game to adapt in real-time to the game progress and the user behavior. Following a short overview of the progress of AI in video games in the past years, this paper highlights the creation of modern video games with basic and elementary adaptive game AI using the Unity game development framework. Particular emphasis is on the details of the AI component. First, a shooter game with basic AI is created. Finally, an action-adventure video game is created featuring elementary case-based adaptive AI. The objective in this game is to create enemies which are able to perceive changes in the environment and adapt their strategies accordingly. Proposed AI practices can migrate into relevant real world applications, such as video surveillance and intrusion detection systems, mission critical autonomous networked patrolling and/or save and rescue robots, vision and hearing assistive applications, intelligent video and behavioral analytics to detect and predict threats etc.",https://ieeexplore.ieee.org/document/8324230/,2017 Intelligent Systems Conference (IntelliSys),7-8 Sept. 2017,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ROBOT.2004.1307521,Development and deployment of a line of sight virtual sensor for heterogeneous teams,IEEE,Conferences,"For a team of cooperating robots, geometry plays a vital role in operation. Knowledge of line of sight to local obstacles and adjacent teammates is critical in both the movement and planning stages to avoid collisions, maintain formation and localize the team. However, determining if other robots are within the line of sight of one another is difficult with existing sensor platforms - especially as the scale of the robot is reduced. We describe a method of exploiting collective team information to generate a virtual sensor that provides line of sight determination, greater range and resolution and the ability to generalize local sensing. We develop this sensor and apply it to the control of a tightly coupled, resource-limited robot team called Millibots.",https://ieeexplore.ieee.org/document/1307521/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/ICRAIE51050.2020.9358310,Development of a Neural Network Library for Resource Constrained Speech Synthesis,IEEE,Conferences,"Machine learning frameworks, like Tensorflow and PyTorch, use GPU hardware acceleration to deliver the needed performance. Since GPUs require a lot of power (and space) to operate, typical use cases involve high-performance servers, with the final deployment available as a cloud service. To address limitations of this approach, AI Accelerators have been proposed. In this context, we have designed and implemented a library of neural network algorithms, to efficiently run on “edge devices”, with AI Accelerators. Moreover, a unified interface has been provided, to allow easy experimentation with various neural networks applied to the same dataset. Here, let us stress that we do not propose new algorithms, but port known ones to, resource restricted, edge devices. The context is provided by a speech synthesis application for edge devices that is deployed on an NVIDIA Jetson Nano. This application is to be used by social robots for real-time off-cloud text-to-speech processing.",https://ieeexplore.ieee.org/document/9358310/,2020 5th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE),1-3 Dec. 2020,ieeexplore
10.1109/FarEastCon.2018.8602651,Development of a Transport Robot for Automated Warehouses,IEEE,Conferences,"Industrial robots and manipulators are widely used as transport-loading devices in automated production. It is possible to combine equipment into coordinated production complexes of various sizes with the help of robots and they will not be bound by rigid planning and the number of installed units. Transport robots have proven themselves as flexible automated means of realizing intra-shop and interoperation material connections. More and more companies are developing technologies for vehicles through which they can communicate with each other and use real-time data from production infrastructure facilities. Electric vehicles and unmanned vehicles have become a new technological trend. In this regard, the paper deals with a prototype of an innovative transport robot, created for automated warehouses. It is proposed to use a computer vision system with image recognition based on the embedded software for the transport robot positioning inside the production facilities. The algorithm of deep machine learning was adapted to solve this problem. Using this algorithm, the prototype tests were performed successfully.",https://ieeexplore.ieee.org/document/8602651/,2018 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon),3-4 Oct. 2018,ieeexplore
10.1109/ICSSE.2011.5961891,Development of simulator for kid-sized humanoid soccer in RoboCup,IEEE,Conferences,"The robot soccer game system is a challenge for real-time control, which can be moderately abstracted from the standpoint of AI (Artificial Intelligence) and multi-agent systems. This simulator is developed for RoboCup Soccer Humanoid League. A humanoid robot belongs to highly intelligent system. The intelligent technologies of the humanoid robots include mechanism design, vision system, and algorithms in software programming. Therefore, its competitions can encourage creativity and technical development. To facilitate the strategy testing of these humanoid robot soccer competitions, a strategy simulator for kid-sized humanoid soccer in RoboCup is proposed. In this simulator, strategies compiled to DLL files may be explicitly loaded at run-time.",https://ieeexplore.ieee.org/document/5961891/,Proceedings 2011 International Conference on System Science and Engineering,8-10 June 2011,ieeexplore
10.1109/CCDC.2019.8832952,Digital Implementation of the Spiking Neural Network and Its Digit Recognition,IEEE,Conferences,"Motivated by biological principles of neural systems, spiking neural network (SNN) shows a tremendous potential in solving pattern recognition and cognitive tasks in recent years. In this study, a biologically inspired SNN composed of three layers is implemented on a reconfigurable FPGA with high computational efficiency and low hardware cost. The proposed SNN is consists of spiking neurons simulated by leaky-integrate-and-fire neuron model. In addition, spiking-time-dependent-plasticity based on event-driven is utilized to train the constructed network. The real-time hardware realization of the proposed SNN demonstrates powerful and efficient learning scheme. Results on different datasets shows that the proposed SNN implementation has the merit of capability of coping with pattern recognition tasks. Furthermore, the proposed implementation with remarkable performance could be applied and embed in bio-inspired neuromorphic platform such as robots for recognition tasks and on-line applications.",https://ieeexplore.ieee.org/document/8832952/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/NCA.2013.21,Distributed and Dynamic Map-less Self-reconfiguration for Microrobot Networks,IEEE,Conferences,"MEMS micro robots are low-power and low memory capacity devices that can sense and act. One of the most challenges in MEMS micro robot applications is the self-reconfiguration, especially when the efficiency and the scalability of the algorithm are required. In the literature, if we want a self-reconfiguration of micro robots to a target shape consisting of P positions, each micro robot should have a memory capacity of P positions. Therefore, if P equals to millions, each node should have a memory capacity of millions of positions. Therefore, this is not scalable. In this paper, nodes do not record any position, we present a self-reconfiguration method where a set of micro robots are unaware of their current position and do not have the map of the target shape. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to O(1). An algorithm of self-reconfiguration to optimize the communication is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots) of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6623641/,2013 IEEE 12th International Symposium on Network Computing and Applications,22-24 Aug. 2013,ieeexplore
10.1109/SCCC.2001.972633,Domain-dependent option policies in autonomous robot learning,IEEE,Conferences,"In control-related applications such as robotics, determination of optimal solutions is made very difficult for many reasons. Among these stands the difficulty in finding out an appropriate model of the domain, as defined by the control agent (robot), environment where it acts and their interaction. Reinforcement learning is a theory which defines a collection of algorithms for determination of control actions under model-free assumptions, which allows control agents to learn optimal actions in an autonomous way. In reinforcement learning, a cost functional to be optimised is determined in advance. The agent then learns how to perform this optimisation via trial and error on its environment. A trial corresponds to execution of actions chosen by the agent, and the error is the immediate result (a real-valued reinforcement) of this action. In the work reported, we consider trials by a learning robotic agent which are not based on low level actions, but instead on sequences of actions (options or macro-operators). We analysed the performance both in terms of learning speed and quality of learned control-for options that correspond to mappings from states to action policies (O/sub /spl Pi// options). Experimental results show that careful (domain-dependent) selection of options (via methods such as discretised potential fields) produce much faster learning for option-based robots when compared to their action-based counterparts. Of critical importance, however, is the option mapping in regions of the state space where the options are not assumed to be necessary: as performance of reinforcement learning algorithms is strongly dependent on sufficient exploration of the state space, even in such regions a careful, ad-hoc selection of actions is of foremost importance.",https://ieeexplore.ieee.org/document/972633/,SCCC 2001. 21st International Conference of the Chilean Computer Science Society,9-9 Nov. 2001,ieeexplore
10.1109/VDAT50263.2020.9190415,DynRP- Non-Intrusive Profiler for Dynamic Reconfigurability,IEEE,Conferences,"Emerging technological areas such as machine learning, speech recognition, computer vision, autonomous robots, AI, bioinformatics involving big data, require implementation in complex heterogeneous accelerator platforms, to be able to handle data explosion with higher efficiency, lower power, and better performance. Dynamic reconfiguration in such platforms can help in run-time optimization to meet the design goals. The required optimal platform configuration can be achieved by a flexible design space exploration and appropriate task partitioning obtained through profiling computation and communication of processes in application code. This paper focuses on profiling, it being the key to the success of obtaining optimal platform configurations. It points to existing profiling techniques, their pros and cons vis-à-vis dynamic reconfigurable architectures, and the challenges in their design for obtaining optimal profiling performance. It further outlines desirable specifications for a profiler to allow dynamic real-time profiling for effective use of dynamic reconfiguration. DynRP, a non-intrusive hardware profiler for dynamic reconfiguration is proposed based on the desirable specifications, followed by its design and implementation details.",https://ieeexplore.ieee.org/document/9190415/,2020 24th International Symposium on VLSI Design and Test (VDAT),23-25 July 2020,ieeexplore
10.1109/ICRA48506.2021.9560730,Dynamic Object Aware LiDAR SLAM based on Automatic Generation of Training Data,IEEE,Conferences,"Highly dynamic environments, with moving objects such as cars or humans, can pose a performance challenge for LiDAR SLAM systems that assume largely static scenes. To overcome this challenge and support the deployment of robots in real world scenarios, we propose a complete solution for a dynamic object aware LiDAR SLAM algorithm. This is achieved by leveraging a real-time capable neural network that can detect dynamic objects, thus allowing our system to deal with them explicitly. To efficiently generate the necessary training data which is key to our approach, we present a novel end-to-end occupancy grid based pipeline that can automatically label a wide variety of arbitrary dynamic objects. Our solution can thus generalize to different environments without the need for expensive manual labeling and at the same time avoids assumptions about the presence of a predefined set of known objects in the scene. Using this technique, we automatically label over 12000 LiDAR scans collected in an urban environment with a large amount of pedestrians and use this data to train a neural network, achieving an average segmentation IoU of 0.82. We show that explicitly dealing with dynamic objects can improve the LiDAR SLAM odometry performance by 39.6% while yielding maps which better represent the environments. A supplementary video<sup>1</sup> as well as our test data<sup>2</sup> are available online.",https://ieeexplore.ieee.org/document/9560730/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICPR.1992.201790,Dynamic neural estimation for autonomous vehicles driving,IEEE,Conferences,"Mobile robots and vehicles may be driven by dynamical neural networks which utilize image data of real-world scenes collected through a TV camera for learning and performance. An innovative system for road direction detection is proposed which is comprised of three specialized blocks performing edge extraction, image-segments detection, and road direction estimation. The road direction estimation block is implemented as a feedback neural network.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201790/,"Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems",30 Aug.-3 Sept. 1992,ieeexplore
10.1109/UIC-ATC.2013.107,Dynamicity to Save Energy in Microrobots Reconfiguration,IEEE,Conferences,"In this paper we present a dynamic self reconfiguration protocol for MEMS micro robots. The protocol presented in this paper is without map of the target shape which makes it efficient and scalable. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to a constant complexity. An algorithm of self-reconfiguration is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots)of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6726216/,2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing,18-21 Dec. 2013,ieeexplore
10.1109/IROS.2004.1389805,Dynamics from patterns: creating neural controllers with SENMP,IEEE,Conferences,"In this paper we show how simple laterally interacting computational entities, i.e. neurons, can be guided by a selectionist process into spatial patterns that show interesting and purposeful dynamics with regard to a particular utility measure. In other words, if a suitable population of laterally interacting mobile entities exist, it is possible to gradually arrange the entities into a spatial pattern that exhibits the desired dynamics. In this paper, the selectionist process is implemented with the stochastic evolutionary neuron migration process (SENMP) and approach is used to evolve dynamic recurrent neural networks (DRNNs) for controlling complex dynamic systems such as autonomous mobile robots, for example. The feasibility and advantages of the approach are demonstrated by evolving neural controllers for solving a non-Markovian double pole balancing problem. In addition, we have earlier used SENMP to evolve navigation behaviors for mobile robots in complex simulated and real environments.",https://ieeexplore.ieee.org/document/1389805/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/EH.2001.937964,Early experiments on the CAM-Brain Machine (CBM),IEEE,Conferences,"This paper presents results of some of the first evolution experiments undertaken on an actual CAM-Brain Machine (CBM), using the hardware itself and not software simulations. A CBM is a specialised piece of programmable (evolvable) hardware that uses Xilinx XC6264 programmable FPGA chips to grow and evolve, at electronic speeds, 3D cellular automata (CA) based neural network circuit modules of some 1000 neurons each. A complete run of a genetic algorithm (e.g. with 100 generations and a population size of 100) is executed in a few seconds. 64000 of these modules can be evolved separately according to the fitness definitions of human ""EEs"" (evolutionary engineers) and downloaded one by one into a gigabyte of RAM. Human ""BAs"" (brain architects) then interconnect these modules ""by hand"" according to their artificial brain architectures. The CBM then updates the binary neural signaling of the artificial brain (with 64000 ""hand"" interconnected modules, i.e. 75 million neurons) at a rate of 130 billion CA cell updates a second, which is fast enough for real time control of robots. Before such multi-moduled artificial brains can be constructed. It is essential that the quality of the evolution (the ""evolvability"") of individual modules be adequate. This paper reports on the first evolution results obtained on CBM hardware.",https://ieeexplore.ieee.org/document/937964/,Proceedings Third NASA/DoD Workshop on Evolvable Hardware. EH-2001,12-14 July 2001,ieeexplore
10.1109/SNPD.2008.97,Early-Life Cycle Reuse Approach for Component-Based Software of Autonomous Mobile Robot System,IEEE,Conferences,"Applying software reuse to many embedded realtime systems, such as autonomous mobile robot system poses significant challenges to industrial software processes due to the resource-constrained and realtime requirements of the systems. An approach for early life-cycle systematic reuse for component-based software engineering (ELCRA) of autonomous mobile robot software is developed. The approach allows reuse at the early stage of software development process by integrating analysis patterns, component model, and component-oriented programming framework. The results of applying the approach in developing software for real robots show that the strategies and processes proposed in the approach can fulfill requirements for self-contained, platform-independent and real-time predictable mobile robot.",https://ieeexplore.ieee.org/document/4617381/,"2008 Ninth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing",6-8 Aug. 2008,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/SII.2019.8700376,Emotion Recognition from Speech for an Interactive Robot Agent,IEEE,Conferences,"Speech is one of the fundamental approaches for human to human interaction. Given this, it should be the main approach for robot human interaction as well. Towards this, the research presented here focuses on emotion recognition from human speech to aid the interaction between humans and robots. There are various steps involved in developing emotion recognition system for an interactive robot agent. The first step is to choose a suitable dataset that is Berlin database for training and testing the models developed. The second important step is extraction and choice of suitable features related to emotions. The third step is to make an appropriate classification scheme. The performance of each classifier is analyzed and acomparison among multiple frameworks of emotion recognition is made. In response to the findings in these preliminary studies, a prototype application was developed to allow the recognition of emotions from speech in real-time for future use on an interactive robot. On a preliminary test set, the application achieved performance levels between 81% and 92%. The approach offers the integration of speech collection hardware, emotion recognition software, mobile devices and robotic systems to aid assist human-robot interaction.",https://ieeexplore.ieee.org/document/8700376/,2019 IEEE/SICE International Symposium on System Integration (SII),14-16 Jan. 2019,ieeexplore
10.1109/RO-MAN46459.2019.8956327,End-User Programming of Low-and High-Level Actions for Robotic Task Planning,IEEE,Conferences,"Programming robots for general purpose applications is extremely challenging due to the great diversity of end-user tasks ranging from manufacturing environments to personal homes. Recent work has focused on enabling end-users to program robots using Programming by Demonstration. However, teaching robots new actions from scratch that can be reused for unseen tasks remains a difficult challenge and is generally left up to robotic experts. We propose iRoPro, an interactive Robot Programming framework that allows end-users to teach robots new actions from scratch and reuse them with a task planner. In this work we provide a system implementation on a two-armed Baxter robot that (i) allows simultaneous teaching of low-and high-level actions by demonstration, (ii) includes a user interface for action creation with condition inference and modification, and (iii) allows creating and solving previously unseen problems using a task planner for the robot to execute in real-time. We evaluate the generalisation power of the system on six benchmark tasks and show how taught actions can be easily reused for complex tasks. We further demonstrate its usability with a user study (N=21), where users completed eight tasks to teach the robot new actions that are reused with a task planner. The study demonstrates that users with any programming level and educational background can easily learn and use the system.",https://ieeexplore.ieee.org/document/8956327/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/CEC45853.2021.9504892,Evolutionary Inherited Neuromodulated Neurocontrollers with Objective Weighted Ranking,IEEE,Conferences,"In the physical world, individuals compete against others within their own population or separately evolving populations. Robotic agents will soon face this coevolutionary and adversarial reality. Many challenges not encountered in the evolution of single populations are encountered in adversarial coevolution. These challenges can render single evolutionary approaches either less effective or ineffective. Most problems have a fundamental goal, but also feature secondary desirable objectives. Here, evader agents in the pursuit-evasion game that do not elude capture are effectively useless. Secondly, when applied to evolve real robots online in a coevolutionary context, non-optimal robots can be erratic and cause damage. Objective hierarchy can be used to define the importance of each objective, and promote quicker optimization of primary objectives such as evasion. The Evolutionary Inherited Neuromodulated Neurocontroller (EINN) method incorporates objective weighted ranking (OWR), a novel objective hierarchy method that promotes optimization of the primary objective in simultaneous multi-objective optimization. EINN is compared to the previously demonstrated Lamarckian-inherited Neuromodulated MultiObjective Evolutionary Neurocontroller (LNMOEN), and shown to be effective in a single evolutionary context.",https://ieeexplore.ieee.org/document/9504892/,2021 IEEE Congress on Evolutionary Computation (CEC),28 June-1 July 2021,ieeexplore
10.1109/CAIA.1989.49141,Experiences with the subsumption architecture,IEEE,Conferences,"A subsumption architecture has been proposed as an effective approach for the construction of robust, real-time control systems for mobile robots. To investigate its strengths and weaknesses, a simulation of the architecture was developed called the Subsumption Architecture Tool (SAT). This simulation allows various models of system behavior to be quickly built and tested. During the building and testing of the SAT, issues related to some architectural features became evident: level of commitment of each layer; code redundancy; problem decomposition and programming style; complexity of large system; and abstract reasoning capabilities. The effects of these issues are presented with respect to the design and implementation choices of two sample layers of behavior. These layers are used to illustrate considerations that need to be taken into account when a project team is considering the use of the subsumption architecture or when a subsumption-architecture-based system is being designed and implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/49141/,[1989] Proceedings. The Fifth Conference on Artificial Intelligence Applications,6-10 March 1989,ieeexplore
10.1109/CMCSN.2012.100,Experimental Study on Long-Range Navigation Behavior of Agricultural Robots,IEEE,Conferences,"In this paper, we study on the navigating bahevior of CRFNFP[1]-based agricultual robots in real scenes. We designed two sets of experiments and three navigating system with different configuration of software for comparative study. The experimental results indicate that, compared to the traditional local-map-based navigating systems, the CRFNFP-based navigating system does enhance the long-range perception for mobile robots and helps planning more efficient paths for the navigation.",https://ieeexplore.ieee.org/document/6245858/,"2012 International Conference on Computing, Measurement, Control and Sensor Network",7-9 July 2012,ieeexplore
10.1109/ICRA.2019.8793829,Exploiting Trademark Databases for Robotic Object Fetching,IEEE,Conferences,"Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.",https://ieeexplore.ieee.org/document/8793829/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIM.2019.8868536,Exploiting the ACCuracy-ACCeleration tradeoff: VINS-assisted real-time object detection on moving systems,IEEE,Conferences,"In recent years, Convolutional Neural Networks (CNNs) have repeatedly shown state-of-the-art performance for their accuracy in the task of object detection, but their heavy computational costs impede their ability for real-time detection when the supporting system is moving, particularly when it is accelerating. At the same time, recent progress on visual inertial systems takes great advantage of movement information to robustly estimate the robot state and its surrounding. This paper proposes to exploit the advantages of inertial odometry research for the purpose of real-time object detection system on mobile robots. We combine a CNN detector with VINS-Mono, a moving visual odometry system, and show reliable improvement in the detection process, especially when the robot accelerates or decelerates. Our system is ready-to-use in that it has very low deployment cost and requires no calibration. The resulting system allows for simultaneous robot state estimation and object detection, as well as object tracking. Lastly, this architecture proves to be flexible because not restrained to a specific object type or detector.",https://ieeexplore.ieee.org/document/8868536/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/ICSyS47076.2019.8982469,FPGA-enabled Binarized Convolutional Neural Networks toward Real-time Embedded Object Recognition System for Service Robots,IEEE,Conferences,"In this presentation, we report the results of applying a binarized Convolutional Neural Network (CNN) and a Field Programmable Gate Array (FPGA) for image-based object recognition. While the demand rises for robots with robust object recognition implemented with Neural Networks, a tradeoff between data processing rate and power consumption persists. Some applications utilise Graphics Processing Units (GPU), which results in high power consumption, thus undesirable for embedded systems, while the others communicate with cloud computers to minimise computational resources at the clients' side, i.e. robots, raising another concern that the robots are unable to perform object recognition without the servers and network connections. To overcome these difficulties, we propose an embedded object recognition system implemented with a binarized CNN and an FPGA. FPGAs consist of a matrix of reconfigurable logic gates allowing parallel computing which befit most image processing algorithms such as the CNN. We train the binarized CNN on one of our datasets that contain images of several kinds of food and beverages. The results of the experiments show that the binarized CNN with an FPGA maintains high accuracy as well as real-time computation, suggesting that the proposed system is suitable for robots to perform their tasks in a real-world environment without needing to communicate with a server.",https://ieeexplore.ieee.org/document/8982469/,2019 IEEE International Circuits and Systems Symposium (ICSyS),18-19 Sept. 2019,ieeexplore
10.1109/RCAR52367.2021.9517650,FT-MSTC*: An Efficient Fault Tolerance Algorithm for Multi-robot Coverage Path Planning,IEEE,Conferences,"Fault tolerance is very important for multi-robot systems, especially for those operated in remote environments. The ability to tolerate failures, allows robots effectively to continue performing tasks without the need for immediate human intervention. In this paper, we present a new efficient fault tolerance algorithm for multi-robot coverage path planning (mCPP). The entire coverage path is considered as a topological task loop. The ideal mCPP problem is handled by partitioning this task loop and assign each partition to individual robot. When a faulty robot is detected, we use an optimization method to minimize the overall maximum coverage cost while considering both the tasks accomplished before robot failures and the remaining tasks. We perform various experiments for regular grid maps and real field terrains. We compare our algorithm against other coverage path planning algorithms and our algorithm outperforms existing spiral-STC-based methods in terms of the overall maximum coverage cost.",https://ieeexplore.ieee.org/document/9517650/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ICRA.2019.8793593,"Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics",IEEE,Conferences,"Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.",https://ieeexplore.ieee.org/document/8793593/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2004.1389583,"Fast, reliable, adaptive, bimodal people tracking for indoor environments",IEEE,Conferences,"We present a real-time system for a mobile robot that can reliably detect and track people in uncontrolled indoor environments. The system uses a combination of leg detection based on distance information from a laser range sensor and visual face detection based on an analogical algorithm implemented on specialized hardware (the CNN universal machine). Results from tests in a variety of environments with different lighting conditions, a different number of appearing and disappearing people, and different obstacles are reported to demonstrate that the system can find and subsequently track several, possibly people simultaneously in indoor environments. Applications of the system include in particular service robots for social events.",https://ieeexplore.ieee.org/document/1389583/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ICMLC.2004.1380629,Fault tolerance for communication-based multirobot formation,IEEE,Conferences,"This paper investigates the ability of fault tolerance for multirobot formation, which is important for practical formation in complex environment. Our model enables mobile robots group to continue to complete given tasks by reorganizing their formation, when some members are in failure. First, to build such model, a multi-agent architecture is presented, which is implemented through communication. Second, we introduce the hierarchy graph of multirobot formation to be the theoretical foundation of the fault tolerance system. The graph analysis is suitable for general leader-follower formation format. And then, the failure detection mechanism for formation is discussed. Finally, integrated fault tolerance algorithm is investigated, including supplement for faulty robots and formation reconfiguration. The improved agent architecture adding the fault tolerance module is also presented. The experiments on real multiple mobile robots demonstrate our design is feasible.",https://ieeexplore.ieee.org/document/1380629/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/CYBER53097.2021.9588329,Fault-Aware Robust Control via Adversarial Reinforcement Learning,IEEE,Conferences,"Robots have limited adaptation ability compared to humans and animals in the case of damage. However, robot damages are prevalent in realworld applications, especially for robots deployed in extreme environments. The fragility of robots greatly limits their widespread application. We propose an adversarial reinforcement learning framework, which significantly increases robot robustness over joint damage cases in both manipulation tasks and locomotion tasks. The agent is trained iteratively under the joint damage cases where it has poor performance. We validate our algorithm on a three-fingered robot hand and a quadruped robot. Our algorithm can be trained only in simulation and directly deployed on a real robot without any fine-tuning. It also demonstrates exceeding success rates over arbitrary joint damage cases.",https://ieeexplore.ieee.org/document/9588329/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/ICARSC52212.2021.9429801,Few-Shot Visual Grounding for Natural Human-Robot Interaction,IEEE,Conferences,"Natural Human-Robot Interaction (HRI) is one of the key components for service robots to be able to work in human-centric environments. In such dynamic environments, the robot needs to understand the intention of the user to accomplish a task successfully. Towards addressing this point, we propose a software architecture that segments a target object from a crowded scene, indicated verbally by a human user. At the core of our system, we employ a multi-modal deep neural network for visual grounding. Unlike most grounding methods that tackle the challenge using pre-trained object detectors via a two-stepped process, we develop a single stage zero-shot model that is able to provide predictions in unseen data. We evaluate the performance of the proposed model on real RGB-D data collected from public scene datasets. Experimental results showed that the proposed model performs well in terms of accuracy and speed, while showcasing robustness to variation in the natural language input.",https://ieeexplore.ieee.org/document/9429801/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/SPCA.2006.297452,From Robotics to Pervasive Computing Environments,IEEE,Conferences,"This talk proposes that the digital home is virtually identical to the software and hardware architecture used to construct mobile robots leading to the proposition that ""pervasive computing environments can be regarded as robots that we live inside"". The author argue that it is possible and rational to apply robotic techniques to pervasive computing problems in the digital home",https://ieeexplore.ieee.org/document/4079023/,2006 First International Symposium on Pervasive Computing and Applications,3-5 Aug. 2006,ieeexplore
10.1109/IROS.2016.7759701,From indoor GIS maps to path planning for autonomous wheelchairs,IEEE,Conferences,"This work focuses on how to compute trajectories for an autonomous wheelchair based on indoor GIS maps, in particular on IndoorGML maps, which set the standard in this context. Good wheelchair trajectories are safe and comfortable for the user and the people sharing the space with him, turn gently, are high legible, and smooth (at least G<sup>2</sup> continuos). We derive a navigation graph from a given IndoorGML map. We define and solve an optimization problem to find the desired path: given a succession of cells to traverse, the path corresponds to the best composite Bézier trajectory for the wheelchair. We discuss a related multi-objective path planning problem. Experimental results and an implementation on real robots show the planner performance.",https://ieeexplore.ieee.org/document/7759701/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/ICCI-CC.2014.6921432,From information revolution to intelligence revolution: Big data science vs. intelligence science,IEEE,Conferences,"The hierarchy of human knowledge is categorized at the levels of data, information, knowledge, and intelligence. For instance, given an AND-gate with 1,000-input pins, it may be described very much differently at various levels of perceptions in the knowledge hierarchy. At the data level on the bottom, it represents a 2<sup>1,000</sup> state space, known as `big data' in recent terms, which appears to be a big issue in engineering. However, at the information level, it just represents 1,000 bit information that is equivalent to the numbers of inputs. Further, at the knowledge level, it expresses only two rules that if all inputs are one, the output is one; and if any input is zero, the output is zero. Ultimately, at the intelligence level, it is simply an instance of the logical model of an AND-gate with arbitrary inputs. This problem reveals that human intelligence and wisdom are an extremely efficient and a fast convergent induction mechanism for knowledge and wisdom elicitation and abstraction where data are merely factual materials and arbitrary instances in the almost infinite state space of the real world. Although data and information processing have been relatively well studied, the nature, theories, and suitable mathematics underpinning knowledge and intelligence are yet to be systematically studied in cognitive informatics and cognitive computing. This will leads to a new era of human intelligence revolution following the industrial, computational, and information revolutions. This is also in accordance with the driving force of the hierarchical human needs from low-level material requirements to high-level ones such as knowledge, wisdom, and intelligence. The trend to the emerging intelligent revolution is to meet the ultimate human needs. The basic approach to intelligent revolution is to invent and embody cognitive computers, cognitive robots, and cognitive systems that extend human memory capacity, learning ability, wisdom, and creativity. Via intelligence revolution, an interconnected cognitive intelligent Internet will enable ordinary people to access highly intelligent systems created based on the latest development of human knowledge and wisdom. Highly professional systems may help people to solve typical everyday problems. Towards these objectives, the latest advances in abstract intelligence and intelligence science investigated in cognitive informatics and cognitive computing are well positioned at the center of intelligence revolution. A wide range of applications of cognitive computers have been developing in ICIC [http://www.ucalgary.ca/icic/] such as, inter alia, cognitive computers, cognitive robots, cognitive learning engines, cognitive Internet, cognitive agents, cognitive search engines, cognitive translators, cognitive control systems, cognitive communications systems, and cognitive automobiles.",https://ieeexplore.ieee.org/document/6921432/,2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing,18-20 Aug. 2014,ieeexplore
10.1109/CDC40024.2019.9029916,From self-tuning regulators to reinforcement learning and back again,IEEE,Conferences,"Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",https://ieeexplore.ieee.org/document/9029916/,2019 IEEE 58th Conference on Decision and Control (CDC),11-13 Dec. 2019,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/ICSAI.2017.8248355,Fully convolutional denoising autoencoder for 3D scene reconstruction from a single depth image,IEEE,Conferences,"In this work, we propose a 3D scene reconstruction algorithm based on a fully convolutional 3D denoising autoencoder neural network. The network is capable of reconstructing a full scene from a single depth image by creating a 3D representation of it and automatically filling holes and inserting hidden elements. We exploit the fact that our neural network is capable of generalizing object shapes by inferring similarities in geometry. Our fully convolutional architecture enables the network to be unconstrained by a fixed 3D shape, and so it is capable of successfully reconstructing arbitrary scene sizes. Our algorithm was evaluated on a real word dataset of tabletop scenes acquired using a Kinect and processed using KinectFusion software in order to obtain ground truth for network training and evaluation. Extensive measurements show that our deep neural network architecture outperforms the previous state of the art both in terms of precision and recall for the scene reconstruction task. The network has been broadly profiled in terms of memory footprint, number of floating point operations, inference time and power consumption in CPU, GPU and embedded devices. Its small memory footprint and its low computation requirements enable low power, memory constrained, real time always-on embedded applications such as autonomous vehicles, warehouse robots, interactive gaming controllers and drones.",https://ieeexplore.ieee.org/document/8248355/,2017 4th International Conference on Systems and Informatics (ICSAI),11-13 Nov. 2017,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/IROS40897.2019.8967785,GQ-STN: Optimizing One-Shot Grasp Detection based on Robustness Classifier,IEEE,Conferences,"Grasping is a fundamental robotic task needed for the deployment of household robots or furthering warehouse automation. However, few approaches are able to perform grasp detection in real time (frame rate). To this effect, we present Grasp Quality Spatial Transformer Network (GQ-STN), a one-shot grasp detection network. Being based on the Spatial Transformer Network (STN), it produces not only a grasp configuration, but also directly outputs a depth image centered at this configuration. By connecting our architecture to an externally-trained grasp robustness evaluation network, we can train efficiently to satisfy a robustness metric via the backpropagation of the gradient emanating from the evaluation network. This removes the difficulty of training detection networks on sparsely annotated databases, a common issue in grasping. We further propose to use this robustness classifier to compare approaches, being more reliable than the traditional rectangle metric. Our GQ-STN is able to detect robust grasps on the depth images of the Dex-Net 2.0 dataset with 92.4 % accuracy in a single pass of the network. We finally demonstrate in a physical benchmark that our method can propose robust grasps more often than previous sampling-based methods, while being more than 60 times faster.",https://ieeexplore.ieee.org/document/8967785/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICMA.2007.4303585,Genetic Programming in Robot Exploration,IEEE,Conferences,"Exploration using mobile robots is an active research area. In general, an optimal robot exploration strategy is difficult to obtain. In this paper an investigation is conducted using genetic programming (GP) to solve this problem. GP is a form of artificial intelligence capable of automatically creating and developing computer programs to solve problems using the theory of evolution. However, like many other learning algorithms, GP is a computationally expensive and time-consuming process. This characteristic can impede its application where learning time is limited, such as in real-time robotic control applications. Therefore, this paper further investigates the possibility of developing a time-efficient GP algorithm to reduce evolution time. This is done by directly incorporating the amount of time evolved solutions take to form into the fitness function, in order to encourage time efficient problem solving. Experimental results have shown that while the time efficient aspect of the proposed GP algorithm is not conclusive, the robot exploration using GP produces promising outcomes.",https://ieeexplore.ieee.org/document/4303585/,2007 International Conference on Mechatronics and Automation,5-8 Aug. 2007,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/IROS.2008.4651150,High-dimensional underactuated motion planning via task space control,IEEE,Conferences,"Kinodynamic planning algorithms have the potential to find feasible control trajectories which accomplish a task even in very nonlinear or constrained dynamical systems. Underactuation represents a particular form of a dynamic constraint, inherently present in many machines of interest (e.g., walking robots), and necessitates planning for long-term control solutions. A major limitation in motion planning techniques, especially for real-time implementation, is that they are only practical for relatively low degree-of-freedom problems. Here we present a model-based dimensionality reduction technique based on an extension of partial feedback linearization control into a task-space framework. This allows one to plan motions for a complex underactuated robot directly in a low-dimensional task-space, and to resolve redundancy with lower-priority tasks. We illustrate the potential of this approach with an extremely simple motion planning system which solves the swing-up problem for multi-link underactuated pendula, and discuss extensions to the control of walking.",https://ieeexplore.ieee.org/document/4651150/,2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,22-26 Sept. 2008,ieeexplore
10.1109/ROBOT.1999.770002,High-speed navigation using the global dynamic window approach,IEEE,Conferences,"Many applications in mobile robotics require the safe execution of a collision-free motion to a goal position. Planning approaches are well suited for achieving a goal position in known static environments, while real-time obstacle avoidance methods allow reactive motion behavior in dynamic and unknown environments. This paper proposes the global dynamic window approach as a generalization of the dynamic window approach. It combines methods from motion planning and real-time obstacle avoidance to result in a framework that allows robust execution of high-velocity, goal-directed reactive motion for a mobile robot in unknown and dynamic environments. The global dynamic window approach is applicable to nonholonomic and holonomic mobile robots.",https://ieeexplore.ieee.org/document/770002/,Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C),10-15 May 1999,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/IWSSIP.2015.7314233,How humans can help computers to solve an artificial problem?,IEEE,Conferences,"The idea of using CAPTCHA (Completely Automated Public Turing Test to Tell Computers and Humans Apart) was to protect websites from attacks initiated by the automated computer scripts or computer robots (bots). One of the most important issues about CAPTCHAs is that the test has to be designed in a way that makes it too hard or almost impossible for the computer programs to break the test however, at the same time it should be fairly easy for human users to solve. ReCAPTCHA is known as one of the most popular CAPTCHA models which is being used by the majority of well-known websites such as Yahoo!, Google, Facebook and etc. ReCAPTCHA is being used in order to help digitizing old text books and notes. In this paper we investigate the algorithm behind reCAPTCHA more in depth and find out how basically a simple script-based computer program can get use of real human users in order to solve an artificial problem for the machines. We also review some of the most important security accepts of the reCAPTCHA model.",https://ieeexplore.ieee.org/document/7314233/,"2015 International Conference on Systems, Signals and Image Processing (IWSSIP)",10-12 Sept. 2015,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/CEC.2009.4983067,HyperNEAT controlled robots learn how to drive on roads in simulated environment,IEEE,Conferences,"In this paper we describe simulation of autonomous robots controlled by recurrent neural networks, which are evolved through indirect encoding using HyperNEAT algorithm. The robots utilize 180 degree wide sensor array. Thanks to the scalability of the neural network generated by HyperNEAT, the sensor array can have various resolution. This would allow to use camera as an input for neural network controller used in real robot. The robots were simulated using software simulation environment. In the experiments the robots were trained to drive with imaximum average speed. Such fitness forces them to learn how to drive on roads and avoid collisions. Evolved neural networks show excellent scalability. Scaling of the sensory input breaks performance of the robots, which should be gained back with re-training of the robot with a different sensory input resolution.",https://ieeexplore.ieee.org/document/4983067/,2009 IEEE Congress on Evolutionary Computation,18-21 May 2009,ieeexplore
10.1109/AIIoT52608.2021.9454183,Image Classification with Knowledge-Based Systems on the Edge for Real-Time Danger Avoidance in Robots,IEEE,Conferences,"Mobile robots are increasingly common in society and are increasingly being used for complex and high-stakes tasks such as search and rescue. The growing requirements for these robots demonstrate a need for systems which can review and react in real time to environmental hazards, which will allow robots to handle environments that are both dynamic and dangerous. We propose and test a system which allows mobile robots to reclassify environmental objects during operation in conjunction with an edge system. We train an image classification model with 99 percent accuracy and deploy it in conjunction with an edge server and JSON-based ruleset to allow robots to react to and avoid hazards.",https://ieeexplore.ieee.org/document/9454183/,2021 IEEE World AI IoT Congress (AIIoT),10-13 May 2021,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/ICCSP.2018.8524377,Implementation of Robotic Vision to Perform Threaded Assembly,IEEE,Conferences,"In manufacturing of mechanical parts and assemblies, proper thread-engagement between a bolt and a nut is vital for the performance and reliability of the product. Typically, this is a precision work, requiring repetitive manual operations. In this paper, we explain how such assembly operations can be carried out by collaborative robots (co-bots) by monitoring the position and orientation of the nut and bolt using an image-sensor (camera). The focus of our discussion is the assembly-operation of bolting of a nut by the grippers of a co-bot. Slips and misalignment, leading to wrong positioning of the nut and the bolt, are identified by capturing the images of the two components in real time using Microsoft Kinect camera-sensor. 3D Reconstruction of the image captured by the camera-sensor is carried out using the Kinect Fusion application. The reconstructed image is in the form of a polygonal mesh which is further converted to 3D Point Cloud data which is less sensitive to noise. Thereafter, the Point Cloud is segmented by dividing the entire scene into many clusters in order to distinguish the objects of the scene as grippers and nut and bolt. These clusters can be used for the training of the co-bot for the proposed operation. This method of extracting object-boundaries leading to recognition of objects is a vital operation in the field of robotic vision. We provide baseline description of various machine learning techniques that can be applied to realize proper assembly of a nut and a bolt.",https://ieeexplore.ieee.org/document/8524377/,2018 International Conference on Communication and Signal Processing (ICCSP),3-5 April 2018,ieeexplore
10.1109/CIBDA50819.2020.00024,Implementation of Water Quality Management Platform for Aquaculture Based on Big Data,IEEE,Conferences,"In order to ensure the quality and quantity of aquaculture, aquaculture farmers need to grasp the water quality in time. However, most farmers have to collect water quality data manually at present, and cannot store and reuse that information rapidly. This paper aims to use SpringBoot framework and JPA framework to build a big data platform of acquisition automation and visualization, which realizes the data analysis and display of heterogeneous water quality and breeding information. The platform can make the water quality prediction and real-time warning. Meanwhile, it realizes the management of robots, users and breeding experts. The application of this platform will bring better social benefits to aquaculture farmers.",https://ieeexplore.ieee.org/document/9148352/,2020 International Conference on Computer Information and Big Data Applications (CIBDA),17-19 April 2020,ieeexplore
10.1109/CNNA.2010.5430286,Implementation of a drosophila-inspired orientation model on the Eye-Ris platform,IEEE,Conferences,"A behavioral model, recently derived from experiments on fruit-flies, was implemented, with successful comparative experiments on orientation control in real robots. This model has been firstly implemented in a standard CNN structure, using an algorithm based on classical, space-invariant templates. Subsequently, the Eye-Ris platform was utilised for the implementation of the whole strategy, at the aim to constitute a stand alone smart sensor for orientation control in bio-inspired robotic platforms. The Eye-Ris vl.2 is a visual system, made by Anafocus, that employs a fully-parallel mixed-signal array sensor-processor chip. Some experiments are reported using a commercial roving platform, the Pioneer P3-AT, showing the reliability of the proposed implementation and usefulness in higher level perceptual tasks.",https://ieeexplore.ieee.org/document/5430286/,2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010),3-5 Feb. 2010,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/IROS45743.2020.9341029,Improving Unimodal Object Recognition with Multimodal Contrastive Learning,IEEE,Conferences,"Robots perceive their environment using various sensor modalities, e.g., vision, depth, sound or touch. Each modality provides complementary information for perception. However, while it can be assumed that all modalities are available for training, when deploying the robot in real-world scenarios the sensor setup often varies. In order to gain flexibility with respect to the deployed sensor setup we propose a new multimodal approach within the framework of contrastive learning. In particular, we consider the case of learning from RGB-D images while testing with one modality available, i.e., exclusively RGB or depth. We leverage contrastive learning to capture high-level information between different modalities in a compact feature embedding. We extensively evaluate our multimodal contrastive learning method on the Falling Things dataset and learn representations that outperform prior methods for RGB-D object recognition on the NYU-D dataset. Our code and details on the used datasets are available at: https://github.com/meyerjo/MultiModalContrastiveLearning.",https://ieeexplore.ieee.org/document/9341029/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/IROS.2013.6696336,Inferring categories to accelerate the learning of new classes,IEEE,Conferences,"On-the-fly learning systems are necessary for the deployment of general purpose robots. New training examples for such systems are often supplied by mentor interactions. Due to the cost of acquiring such examples, it is desirable to reduce the number of necessary interactions. Transfer learning has been shown to improve classification results for classes with small numbers of training examples by pooling knowledge from related classes. Standard practice in these works is to assume that the relationship between the transfer target and related classes is already known. In this work, we explore how previously learned categories, or related groupings of classes, can be used to transfer knowledge to novel classes without explicitly known relationships to them. We demonstrate an algorithm for determining the category membership of a novel class, focusing on the difficult case when few training examples are available. We show that classifiers trained via this method outperform classifiers optimized to learn the novel class individually when evaluated on both synthetic and real-world datasets.",https://ieeexplore.ieee.org/document/6696336/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/INFOCOM41043.2020.9155528,Informative Path Planning for Mobile Sensing with Reinforcement Learning,IEEE,Conferences,"Large-scale spatial data such as air quality, thermal conditions and location signatures play a vital role in a variety of applications. Collecting such data manually can be tedious and labour intensive. With the advancement of robotic technologies, it is feasible to automate such tasks using mobile robots with sensing and navigation capabilities. However, due to limited battery lifetime and scarcity of charging stations, it is important to plan paths for the robots that maximize the utility of data collection, also known as the informative path planning (IPP) problem. In this paper, we propose a novel IPP algorithm using reinforcement learning (RL). A constrained exploration and exploitation strategy is designed to address the unique challenges of IPP, and is shown to have fast convergence and better optimality than a classical reinforcement learning approach. Extensive experiments using real-world measurement data demonstrate that the proposed algorithm outperforms state-of-the-art algorithms in most test cases. Interestingly, unlike existing solutions that have to be re-executed when any input parameter changes, our RL-based solution allows a degree of transferability across different problem instances.",https://ieeexplore.ieee.org/document/9155528/,IEEE INFOCOM 2020 - IEEE Conference on Computer Communications,6-9 July 2020,ieeexplore
10.1109/CEC.2001.934451,Initial evolvability experiments on the CAM-brain machines (CBMs),IEEE,Conferences,"Presents the results of some of the first evolvability experiments undertaken on CAM (content-addressable memory) brain machines (CBMs), using the hardware itself (not software simulations). A CBM is a specialised piece of programmable (evolvable) hardware that uses Xilinx XC6264 programmable FPGA chips to grow and evolve, at electronic speeds, 3D cellular automata (CA) based neural network circuit modules of some 1,000 neurons each. A complete run of a genetic algorithm (e.g. with 100 generations and a population size of 100) is executed in a few seconds. 64,000 of these modules can be evolved separately according to the fitness definitions of human evolutionary engineers and downloaded, one by one, into a gigabyte of RAM. Human brain architects then interconnect these modules ""by hand"" according to their artificial brain architectures. The CBM then updates the binary neural signaling of the artificial brain (with 64,000 ""hand"" interconnected modules, i.e. 75 million neurons) at a rate of 130 billion CA cell updates a second, which is fast enough for the real-time control of robots. Before such multi-module artificial brains can be constructed, it is essential that the quality of the evolution (the ""evolvability"") of the individual modules should be adequate. This paper reports on the initial evolvability results obtained on CBM hardware.",https://ieeexplore.ieee.org/document/934451/,Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546),27-30 May 2001,ieeexplore
10.1109/ICIT.2010.5472498,Intelligent control and evolutionary strategies applied to multirobotic systems,IEEE,Conferences,"This paper describes the modeling, implementation, and evaluation of RoBombeiros multirobotic system. The robotic task in this paper is performed over a natural disaster, simulated as a forest fire. The simulator supports several features to allow realistic simulation, like irregular terrains, natural processes (e.g. fire, wind) and physical constraint in the creation and application of mobile robots. The proposed system relies on two steps: (i) group formation planning and (ii) intelligent techniques to perform robots navigation for fire fighting. For planning, we used genetic algorithms to evolve positioning strategies for firefighting robots performance. For robots operation, physically simulated fire-fighting robots were built, and the sensory information of each robot (e.g. GPS, compass, sonar) was used in the input of an artificial neural network (ANN). The ANN controls the vehicle (robot) actuators and allows navigation with obstacle avoidance. Simulation results show that the ANN satisfactorily controls the mobile robots; the genetic algorithm adequately configures the fire fighting strategy and the proposed multi-robotic system can have an essential hole in the planning and execution of fire fighting in real forests.",https://ieeexplore.ieee.org/document/5472498/,2010 IEEE International Conference on Industrial Technology,14-17 March 2010,ieeexplore
10.1109/ICCCYB.2004.1437660,Intelligent control application on sample identification,IEEE,Conferences,"An intelligent control implementation is proposed for sample differentiation with Raman spectroscopy, which can be used to characterize various samples for decision-making and medical diagnosis. Raman spectra are weak signals whose features are inevitably affected by numerous noises during the calibration process. These noises must be eliminated to an acceptable level. Fuzzy control has been widely used to solve uncertainty, imprecision and vague phenomena, so fuzzy logic can be used for noise filtering. The resulting intrinsic Raman spectrum has been trained using artificial neural networks. Both unsupervised learning and supervised learning are to be conducted in this preliminary research on sample identification. For unsupervised training, principal component analysis (PCA) is exploited, which is based on Hebbian rule and single value decomposition (SVD) approach, respectively. For supervised training, radial basis function (RBF) is presented. A complete procedure for sample identification consists of Raman spectra calibration, noise filtering, unsupervised classification and supervised neural network training. A systematic intelligent control approach is formulated in consequence for sample identification. The long-term objective is to create a real-time approach for sample analysis using a Raman spectrometer directly mounted at the end-effector of the medical robots to enhance robotic remote surgery",https://ieeexplore.ieee.org/document/1437660/,"Second IEEE International Conference on Computational Cybernetics, 2004. ICCC 2004.",30 Aug.-1 Sept. 2004,ieeexplore
10.1109/HUMANOIDS.2012.6651596,Interactive symbol generation of task planning for daily assistive robot,IEEE,Conferences,"For the development of both hardware and software, task plannings become more and more important for robots to perform various tasks. Applying task planning to robotic system for working in real environments has difficulties. Estimating required symbols before planning is difficult because real environments are partially observable. In this paper, we proposed a method for task planning in partially observable environments with unknown objects. To construct conditional plans used in these environments, we extend the description of actions to multi-effect actions, and to deal with unknown objects, robots get new symbols generated by human interaction on demand. Additionally we show experiments of Willow Garage's PR2 executing the task in the real environment with unknown objects.",https://ieeexplore.ieee.org/document/6651596/,2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012),29 Nov.-1 Dec. 2012,ieeexplore
10.1109/WPNC.2016.7822857,Introducing a novel marker-based geometry model in monocular vision,IEEE,Conferences,"A spherical marker-based distance capture concept using monocular vision is presented in this paper. A novel method is explored, within the concept of a virtual sphere, which shows how to improve the reading measurements of the distance of a moving object from low resolution digital images, and from a single viewpoint. The aim here is to be able to track accurately the object at a furthest possible position. A conclusion with experimental simulations carried out using 3D modeling of markers and representing the real world showing the potency of the marker's geometry on improving the accuracy of the measurements. A potential application field of the proposed method is the implementation of tracking object in mobile robots, marker-based localization, and field of topography.",https://ieeexplore.ieee.org/document/7822857/,"2016 13th Workshop on Positioning, Navigation and Communications (WPNC)",19-20 Oct. 2016,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/ISORCW.2012.36,Knowledge Representation for Cognitive Robotic Systems,IEEE,Conferences,"Cognitive robotics are autonomous systems capable of artificial reasoning. Such systems can be achieved with a logical approach, but still AI struggles to connect the abstract logic with real-world meanings. Knowledge representation and reasoning help to resolve this problem and to establish the vital connection between knowledge, perception, and action of a robot. Cognitive robots must use their knowledge against the perception of their world and generate appropriate actions in that world in compliance with some goals and beliefs. This paper presents an approach to multi-tier knowledge representation for cognitive robots, where ontologies are integrated with rules and Bayesian networks. The approach allows for efficient and comprehensive knowledge structuring and awareness based on logical and statistical reasoning.",https://ieeexplore.ieee.org/document/6196117/,2012 IEEE 15th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops,11-11 April 2012,ieeexplore
10.1109/ROBIO.2018.8665255,Knowledge-Driven Deep Deterministic Policy Gradient for Robotic Multiple Peg-in-Hole Assembly Tasks,IEEE,Conferences,"It remains a formidable challenge for traditional control strategies to perform automatic multiple peg-in-hole assembly tasks due to the complicated and dynamic contact states. Inspired by that human could generalize the learned skills to perform the different assembly tasks well, a general learning-based algorithm based on deep deterministic policy gradient (DDPG) is proposed. To make robots learn the multiple peg-in-hole assembly skills from experience efficiently and stably, the learning process is driven by the basic knowledge like PD force control strategy. To achieve a fast learning process in the real-world assembly tasks, a hybrid exploration strategy is applied to drive a efficient exploration during policy search phase. A dual peg-in-hole assembly simulation and real-world experiments are implemented to verify the effectiveness of the proposed algorithm. The performance measured by the assembly time and the maximum contact forces demonstrates that the multiple peg-in-hole assembly skills could be improved only after 150 training episodes in dual peg-in-hole assembly task.",https://ieeexplore.ieee.org/document/8665255/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/INDIN.2015.7281881,Knowledge-driven finite-state machines. Study case in monitoring industrial equipment,IEEE,Conferences,Traditionally state machines are implemented by coding the desired behavior of a given system. This work proposes the use of ontological models to describe and perform computations on state machines by using SPARQL queries. This approach represents a paradigm shift relating to the customary manner in which state machines are stored and computed. The main contribution of the work is an ontological model to represent state machines and a set of generic queries that can be used in any knowledge-driven state machine to compute valuable information. The approach was tested in a study case were the state machines of industrial robots in a manufacturing line were modeled as ontological models and used for monitoring the behavior of these devices on real time.,https://ieeexplore.ieee.org/document/7281881/,2015 IEEE 13th International Conference on Industrial Informatics (INDIN),22-24 July 2015,ieeexplore
10.1109/IROS.2010.5649358,LCM: Lightweight Communications and Marshalling,IEEE,Conferences,"We describe the Lightweight Communications and Marshalling (LCM) library for message passing and data marshalling. The primary goal of LCM is to simplify the development of low-latency message passing systems, especially for real-time robotics research applications. Messages can be transmitted between different processes using LCM's publish/subscribe message-passing system. A platformand language-independent type specification language separates message description from implementation. Message specifications are automatically compiled into language-specific bindings, eliminating the need for users to implement marshalling code while guaranteeing run-time type safety. LCM is notable in providing a real-time deep traffic inspection tool that can decode and display message traffic with minimal user effort and no impact on overall system performance. This and other features emphasize LCM's focus on simplifying both the development and debugging of message passing systems. In this paper, we explain the design of LCM, evaluate its performance, and describe its application to a number of autonomous land, underwater, and aerial robots.",https://ieeexplore.ieee.org/document/5649358/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/SMC.2019.8914406,Learning Locomotion Skills via Model-based Proximal Meta-Reinforcement Learning,IEEE,Conferences,"Model-based reinforcement learning methods provide a promising direction for a range of automated applications, such as autonomous vehicles and legged robots, due to their sample-efficiency. However, their asymptotic performance is usually inferior compared to the state-of-the-art model-free reinforcement learning methods in locomotion control domains. One main challenge of model-based reinforcement learning is learning a dynamics model that is accurate enough for planning. This paper mitigates this issue by meta-reinforcement learning from an ensemble of dynamics models. A policy learns from dynamics models that hold different beliefs of a real environment. This procedure improves its adaptability and inaccuracy-tolerance ability. A proximal meta-reinforcement learning algorithm is introduced to improve computational efficiency and reduces variance of higher-order gradient estimation. A heteroscedastic noise is added to the training dataset, thus leading to a robust and efficient model learning. Subsequently, proximal meta-reinforcement learning maximizes the expected returns by sampling “imaginary” trajectories from the learned dynamics, which does not require real environment data and can be deployed on many servers in parallel to speed up the whole learning process. The aim of this work is to reduce the sample-complexity and computational cost of reinforcement learning in robot locomotion tasks. Simulation experiments show that the proposed algorithm achieves an asymptotic performance compared with the state-of-the-art model-free reinforcement learning methods with significantly fewer samples, which confirm our theoretical results.",https://ieeexplore.ieee.org/document/8914406/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/IROS45743.2020.9341458,Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments,IEEE,Conferences,"In this paper, we present an approach and an implemented pipeline for transferring data acquired from observing humans in virtual environments onto robots acting in the real world, and adapting the data accordingly to achieve successful task execution. We demonstrate our pipeline by inferring seven different symbolic and subsymbolic motion parameters of mobile pick and place actions, which allows the robot to set a simple breakfast table. We propose an approach to learn general motion parameter models and discuss, which parameters can be learned at which abstraction level.",https://ieeexplore.ieee.org/document/9341458/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROMAN.2010.5598659,Learning grasp stability based on tactile data and HMMs,IEEE,Conferences,"In this paper, the problem of learning grasp stability in robotic object grasping based on tactile measurements is studied. Although grasp stability modeling and estimation has been studied for a long time, there are few robots today able of demonstrating extensive grasping skills. The main contribution of the work presented here is an investigation of probabilistic modeling for inferring grasp stability based on learning from examples. The main objective is classification of a grasp as stable or unstable before applying further actions on it, e.g. lifting. The problem cannot be solved by visual sensing which is typically used to execute an initial robot hand positioning with respect to the object. The output of the classification system can trigger a regrasping step if an unstable grasp is identified. An off-line learning process is implemented and used for reasoning about grasp stability for a three-fingered robotic hand using Hidden Markov models. To evaluate the proposed method, experiments are performed both in simulation and on a real robot system.",https://ieeexplore.ieee.org/document/5598659/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/ROBOT.2001.932897,Learning momentum: integration and experimentation,IEEE,Conferences,"We further study the effects of learning momentum as defined by Arkin, Clark and Ram (1992) on robots, both simulated and real, attempting to traverse obstacle fields in order to reach a goal. Integration of these results into a large-scale software architecture, MissionLab, provides the ability to exercise these algorithms in novel ways. Insight is also sought in reference to when different learning momentum strategies should be used.",https://ieeexplore.ieee.org/document/932897/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/DEVLRN.2002.1011867,Learning movement sequences from demonstration,IEEE,Conferences,"Presents a control and learning architecture for humanoid robots designed for acquiring movement skills in the context of imitation learning. Multiple levels of movement abstraction occur across the hierarchical structure of the architecture, finally leading to the representation of movement sequences within a probabilistic framework. As its substrate, the framework uses the notion of visuo-motor primitives, modules capable of recognizing as well as executing similar movements. This notion is heavily motivated by the neuroscience evidence for motor primitives and mirror neurons. Experimental results from an implementation of the architecture are presented involving learning and representation of demonstrated movement sequences from synthetic as well as real human movement data.",https://ieeexplore.ieee.org/document/1011867/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ICCVW.2019.00309,Learning to Navigate Robotic Wheelchairs from Demonstration: Is Training in Simulation Viable?,IEEE,Conferences,"Learning from demonstration (LfD) enables robots to learn complex relationships between their state, perception and actions that are hard to express in an optimization framework. While people intuitively know what they would like to do in a given situation, they often have difficulty representing their decision process precisely enough to enable an implementation. Here, we are interested in robots that carry passengers, such as robotic wheelchairs, where user preferences, comfort and the feeling of safety are important for autonomous navigation. Balancing these requirements is not straightforward. While robots can be trained in an LfD framework in which users drive the robot according to their preferences, performing these demonstrations can be time-consuming, expensive, and possibly dangerous. Inspired by recent efforts for generating synthetic data for training autonomous driving systems, we investigate whether it is possible to train a robot based on simulations to reduce the time requirements, cost and potential risk. A key characteristic of our approach is that the input is not images, but the locations of people and obstacles relative to the robot. We argue that this allows us to transfer the classifier from the simulator to the physical world and to previously unseen environments that do not match the appearance of the training set. Experiments with 14 subjects providing physical and simulated demonstrations validate our claim.",https://ieeexplore.ieee.org/document/9022271/,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),27-28 Oct. 2019,ieeexplore
10.1109/ICEC.1995.487489,Learning to achieve co-operation by temporal-spatial fitness sharing,IEEE,Conferences,"We propose a co-operative GA-based learning system that would make real-world heterogeneous agents feasible with the minimum amount of communication hardware. The problem is identical to a distributed GA implemented on processors connected by local and very slow communication lines. We have developed an extension of the fitness sharing method that incorporates sharing over temporally-spatially distributed populations. Restricting an agent's task to the inter-agent conflict avoidance, this sharing is realised by exchanging estimated fitness values over all agents. The mechanism of finding conflict avoidance actions is similar to that of a self-organisation mechanism of a Kohonen-type network. Our results from simulations of a bump-avoidance task for multiple mobile robots show that it elicits a notable performance improvement compared to normal classifier systems.",https://ieeexplore.ieee.org/document/487489/,Proceedings of 1995 IEEE International Conference on Evolutionary Computation,29 Nov.-1 Dec. 1995,ieeexplore
10.1109/ICSMC.1993.390770,Learning to coordinate behaviors for real-time path planning of autonomous systems,IEEE,Conferences,"We present a neural network (NN) system which learns the appropriate simultaneous activation of primitive behaviors in order to execute more complex robot behaviors. The NN implementation is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviors in a simultaneous or concurrent fashion. We use a supervised learning technique with a human trainer generating appropriate training for the simultaneous activation of behavior in a simulated environment. The NN implementation has been tested within OPMOR, a simulation environment for mobile robots and several results are presented. The performance of the neural network is adequate. Portions of this work has been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/390770/,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,17-20 Oct. 1993,ieeexplore
10.1109/ITSC45102.2020.9294425,Learning-to-Fly: Learning-based Collision Avoidance for Scalable Urban Air Mobility,IEEE,Conferences,"With increasing urban population, there is global interest in Urban Air Mobility (UAM), where hundreds of autonomous Unmanned Aircraft Systems (UAS) execute missions in the airspace above cities. Unlike traditional human-inthe-loop air traffic management, UAM requires decentralized autonomous approaches that scale for an order of magnitude higher aircraft densities and are applicable to urban settings. We present Learning-to-Fly (L2F), a decentralized on-demand airborne collision avoidance framework for multiple UAS that allows them to independently plan and safely execute missions with spatial, temporal and reactive objectives expressed using Signal Temporal Logic. We formulate the problem of predictively avoiding collisions between two UAS without violating mission objectives as a Mixed Integer Linear Program (MILP). This however is intractable to solve online. Instead, we develop L2F, a two-stage collision avoidance method that consists of: 1) a learning-based decision-making scheme and 2) a distributed, linear programming-based UAS control algorithm. Through extensive simulations, we show the real-time applicability of our method which is ≈6000× faster than the MILP approach and can resolve 100% of collisions when there is ample room to maneuver, and shows graceful degradation in performance otherwise. We also compare L2F to two other methods and demonstrate an implementation on quad-rotor robots.",https://ieeexplore.ieee.org/document/9294425/,2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC),20-23 Sept. 2020,ieeexplore
10.1109/IIAI-AAI50415.2020.00021,Library Intelligent Book Recommendation System Using Facial Expression Recognition,IEEE,Conferences,"To solve the problem of information overload, the recommendation system has developed in various fields. Faced with a variety of forms and rich masses of books, the book recommendation system based on various recommendation methods is applied in the library. In the traditional book recommendation system, there are some problems, such as single recommendation mode, lack of pertinence, too centralized recommended books and so on. In order to solve these problems, this paper proposes a personalized book recommendation system. Through user expression recognition to obtain user preferences, according to user preferences to recommend books to user. Facial expression recognition is realized by using convolution neural network model. This kind of recommendation method has real-time and authenticity. The book recommendation system based on facial expression recognition can improve users' sense of use when applied to library robots.",https://ieeexplore.ieee.org/document/9430442/,2020 9th International Congress on Advanced Applied Informatics (IIAI-AAI),1-15 Sept. 2020,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.1109/INFOCOM.2018.8485910,MV-Sports: A Motion and Vision Sensor Integration-Based Sports Analysis System,IEEE,Conferences,"Recently, intelligent sports analytics is becoming a hot area in both industry and academia for coaching, practicing tactic and technical analysis. With the growing trend of bringing sports analytics to live broadcasting, sports robots and common playfield, a low cost system that is easy to deploy and performs real-time and accurate sports analytics is very desirable. However, existing systems, such as Hawk-Eye, cannot satisfy these requirements due to various factors. In this paper, we present MV-Sports, a cost-effective system for real-time sports analysis based on motion and vision sensor integration. Taking tennis as a case study, we aim to recognize player shot types and measure ball states. For fine-grained player action recognition, we leverage motion signal for fast action highlighting and propose a long short term memory (LSTM)-based framework to integrate MV data for training and classification. For ball state measurement, we compute the initial ball state via motion sensing and devise an extended kalman filter (EKF)-based approach to combine ball motion physics-based tracking and vision positioning-based tracking to get more accurate ball state. We implement MV-Sports on commercial off-the-shelf (COTS) devices and conduct real-world experiments to evaluate the performance of our system. The results show our approach can achieve accurate player action recognition and ball state measurement with sub-second latency.",https://ieeexplore.ieee.org/document/8485910/,IEEE INFOCOM 2018 - IEEE Conference on Computer Communications,16-19 April 2018,ieeexplore
10.1109/HPCC/SmartCity/DSS.2019.00339,Machine Learning Based CloudBot Detection Using Multi-Layer Traffic Statistics,IEEE,Conferences,"With the rapid development of e-commerce services and online transactions, an increasing number of advanced web robots are utilized by speculators and hackers in underground economy to perform click fraud, register fake accounts and commit other kinds of frauds, seriously harming the profit of businesses and the fairness of online activities. There is solid evidence that the vast majority of such malicious bot traffic comes from data centers. The malicious bot deployed on the hosts of data centers is referred to as a CloudBot. How to detect and block CloudBots effectively has become an urgent problem in practice, while the research on it can be seldom seen in public. To this end, we propose a traffic-based quasi-real-time method for CloudBot detection using machine learning, which exploits a new sample partitioning approach, as well as innovative multi-layer features that reveal the essential difference between CloudBots and human traffic. Our method achieves 93.4% precision in the experiment and performs well on the real-world dataset, which proves to be effective to detect unknown CloudBots and combat the concept drift caused by varying time. Besides, the approach is also privacy-preserving without using any specific application layer information. We believe our work can benefit network economy security and fairness in practice.",https://ieeexplore.ieee.org/document/8855536/,2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),10-12 Aug. 2019,ieeexplore
10.23919/SPA.2019.8936736,Machine Learning for Embodied Agents: From Signals to Symbols and Actions,IEEE,Conferences,"The aim of this tutorial lecture is to show the role of machine learning and some other AI-related techniques in embodied autonomous agents, and autonomous robots in particular. In this tutorial we bring to the forefront the aspects of robotics that are closely related to computer science. We believe that the progress in algorithms and data processing methods together with the rapid increase in the available computing power were the driving forces behind the successes of modern robotics in the last decade. During this period robots of various classes migrated from university laboratories to commercial companies and then to our everyday life, as now everybody can buy an autonomous vacuum cleaner or lawnmower, while self-driving cars and drones for goods delivery are waiting for proper legal regulations to enter the market. Robotics and Artificial Intelligence already went a long path of mutual inspiration and common development, starting from the symbolic AI (aka Good Old-Fashioned Artificial Intelligence) and its extensive use in early autonomous robots, such as Shakey the robot, created in SRI International by Nils Nilsson, considered one of the ""fathers"" of modern AI. We briefly characterize the range of the most important applications of typical AI methods in modern robotics, including motion planning algorithms [2,3], interpretation of sensory data leading to creation of a world model [4 ,5], and classical learning methods, such as reinforcement learning [6]. However, what made robotics a part of the new wave of AI applications was the recent ""revolution"" of machine learning, mostly grounded in the enormous success of the deep learning paradigm and its many variants that proved to outclass classic methods in a broad range of problems related to the processing of images and other types of signals. The quick adoption of the recent advances in Machine Learning (ML) in robotics seems to be motivated by the fact that ML gives the possibility to infer solutions from data, as opposed to the classic model-based paradigm that was for decades used in robotics. Whereas the modelbased solutions are mathematically elegant and theoretically provable (with respect to stability, convergence, etc.) they often fail once confronted with real-world problems and real sensory data, as their underlying mathematical models are only a very rough approximation of the real world. Therefore, a wider adoption of ML in robotics gives a chance to make robots more robust and adaptive. On the other hand, we should try to use the new techniques without discarding the knowledge and expertise we already have - machine learning methods can benefit a lot from the prior knowledge and the known structure of the problem that has to be solved by learning. This knowledge and structure can be adopted from the model-based methods that a re already well-established in robotics. In the lecture robots are understood in a broad sense, as all embodied agents that have means to physically interact with the environment. They can be either manipulators, mobile robots, aerial vehicles, self-driving cars, and various ""smart"" devices and sensors. In the second part of the lecture attention is paid to specific problems that appear in application of machine learning to embodied agents, such as the need to search a for solution in huge, multi-dimensional spaces (""curse of dimensionality""), and the ever-present problem of representation and incorporation of uncertainty in the processing of real-world data. Some examples of applications of autonomous robots are given, which were successful due to the use of AI - in particular the probabilistic representation of knowledge and machine learning. The most prominent examples are the DARPA competitions: ""Grand Challenge"", ""Urban Challenge"" and ""Robotics Challenge"" (DRC), and the ""Amazon Picking Challenge"", which proves the interest of large corporations in the development of AI-based robotics [7]. In the third part of the lecture new research directions offered by machine learning and the increased availability of training data are discussed. An overview of the most popular application areas of ML in robotics and other autonomous systems is presented along with the typical machine learning paradigms applied in these areas. The focus is on deep learning, mostly using convolutional neural networks to process various sensory data. We discuss three aspects of embodied agents that make machine learning in robotics quite specific with respect to other application areas, such as medical images or natural language processing. The first aspect is dealing with the ""open world"", in which autonomous robots usually operate. This situation breaks the assumptions underlying some popular ML methods, and creates the need to face the problem of unknown classes identification [8] incremental learning [9], and the uncertainty of sensory data [10]. We also stress out that an embodied agent has the ability to actively acquire information [11]. The second aspect is the inference about the scene seen by the agent, where in the case of robotics, semantics and geometry intermingle [12], because the robot has to work in a three-dimensional world, although it often perceives it through twodimensional images [13,14]. The third aspect of our analysis is related to the most important feature of robots that distinguishes them from all other learning agents (software-based). Robots are embodied agents, that is they have a physical ""body"", and are subject to physical constraints, such as the maximum speed of motion or maximum range of perception. Therefore, in ML for robots analysis of the spatio-temporal dependencies in data is very important [15]. Robots support advanced learning methods thanks to the possibility of interaction with the environment - a simple example is active vision with moving camera, a much more complex one is manipulation with active testing of the behavior of objects (repositioning, pushing) [16]. At the end of the lecture, in the context of specific needs and limitations characteristic to the applications of ML in robotics, new concepts of machine learning (e.g. deep reinforcement learning [17], interactive perception [18]) are presented. The lecture is summarized with a brief discussion of the most important challenges and open problems of ML applied to embodied agents.",https://ieeexplore.ieee.org/document/8936736/,"2019 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",18-20 Sept. 2019,ieeexplore
10.1109/ICRA.2019.8793485,Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks,IEEE,Conferences,"Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",https://ieeexplore.ieee.org/document/8793485/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/DDCLS52934.2021.9455635,Mask-based Object Pose Estimation with Domain Transfer,IEEE,Conferences,"Object pose estimation is important for robots to understand and interact with the real world. This problem is challenging because the various objects, clutter and occlusions between objects in the scene. Deep learning methods show better performances than traditional problems in this problem but training a convolutional neural network needs lots of annotated data which is expensive to obtain. This paper proposes a general method by using domain transfer technology to efficiently solve object pose estimation problem. Besides, the proposed method obtains mask to achieve high quality performance by combing an instance segmentation framework, Mask R-CNN. We present the results of our experiments with the LineMOD dataset. We also deploy our method to robotic grasp object based on the estimated pose.",https://ieeexplore.ieee.org/document/9455635/,2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS),14-16 May 2021,ieeexplore
10.1109/ICCCI50826.2021.9402304,Maze Solving with humanoid robot NAO using Real-Time object detection,IEEE,Conferences,"In a future that is not too distant from today, humanoids are surely going to be an integral part of both our professional and private lives, assisting us with various tasks. Unlike normal robots that we may encounter in our everyday lives, humanoids are designed in specific manners to give them more human-like capabilities that enable them to perform complex tasks such as climbing a flight of stairs. In this paper, we present a Maze-Solving Algorithm which is a software developed specifically for the humanoid robot, NAO, and gives it the capability to enter and exit a maze autonomously. NAO is a next-gen humanoid bot developed by SoftBank Robotics using the power of AI. The bot is equipped with numerous sensors and cameras. Though various quantitative approaches were considered and experimented with, we stuck onto the one which had the least average time complexity of all after a thorough comparative study. We suggest an approach where the humanoid can detect and localize objects from a distance and take programmable decisions based on them. AI constantly tries to give robots human-thinking capabilities to make their decision-making skills similar to those of humans, if not better than them. This algorithm was developed taking into consideration how a human intellect would react rationally if he is stuck in a maze. The methodology used revolves primarily around the combined use of SONAR(Sound navigation ranging) and tactical sensors, and cameras equipped within the bot. The output values from this hardware were then evaluated to judge the distance from a wall and the reactions from the bot were calculated by the suggested algorithm accordingly.",https://ieeexplore.ieee.org/document/9402304/,2021 International Conference on Computer Communication and Informatics (ICCCI),27-29 Jan. 2021,ieeexplore
10.1109/LARS.2008.23,MecaTeam Framework: An Infrastructure for the Development of Soccer Agents for Simulated Robots,IEEE,Conferences,"This paper presents the MecaTeam framework, a solution to reduce the effort on developing new soccer teams of robots for the 2D simulation category of the RoboCup. MecaTeam is an object-oriented framework based on features of two robot soccer teams: the MecaTeam 2006 and Uva Trilearn. The architecture of the proposed framework is presented and aspects of its use are discussed. Besides facilitating the development of new teams, the use of the MecaTeam framework may decrease the impact of changes in chunks of related code. Finally, the MecaTeam framework can be used by new researchers interested in simulated robots for soccer games.",https://ieeexplore.ieee.org/document/4812639/,2008 IEEE Latin American Robotic Symposium,29-30 Oct. 2008,ieeexplore
10.1109/RO-MAN47096.2020.9223436,Migratable AI: Effect of identity and information migration on users' perception of conversational AI agents,IEEE,Conferences,"Conversational AI agents are proliferating, embodying a range of devices such as smart speakers, smart displays, robots, cars, and more. We can envision a future where a personal conversational agent could migrate across different form factors and environments to always accompany and assist its user to support a far more continuous, personalized and collaborative experience. This opens the question of what properties of a conversational AI agent migrates across forms, and how it would impact user perception. To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task. We validated the system by designing a 2x2 between-subjects study to explore the effects of information migration and identity migration on user perceptions of trust, competence, likeability and social presence. Our results suggest that identity migration had a positive effect on trust, competence and social presence, while information migration had a positive effect on trust, competence and likeability. Overall, users report highest trust, competence, likeability and social presence towards the conversational agent when both identity and information were migrated across embodiments.",https://ieeexplore.ieee.org/document/9223436/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/AIMS.2014.35,Mobile Robot Performance in Robotics Challenges: Analyzing a Simulated Indoor Scenario and Its Translation to Real-World,IEEE,Conferences,"This paper discusses the pros and cons of using 3D simulators for testing the autonomous behavior of mobile robots in indoor environments. Major contribution of the paper is the discussion about which problems that can be faced using the simulator and those that cannot. We present the integration and calibration of a real non-commercial robot in a simulator, the characterization of the errors in sensing, navigation, and manipulation, and how these errors would impact in the real performance of the robot. The experimental support of the claims made in the paper has been developed using the gazebo simulator. RoCKIn competition rulebook defined the indoor restrictions.",https://ieeexplore.ieee.org/document/7102451/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/ISSNIP.2005.1595615,Mobile Sensor Systems Robotic Platforms and Smart Sensors,IEEE,Conferences,"Mobile robots must adapt to react safely with other robots, the environment and their mission. Adaptive behaviors for multiple mission scenarios require multi-level controls and the ability to modify controls at many levels. In many sensing and operational scenarios, deterministic solutions are not practical. Due to the inherent complexity of real world operations changes within even a single mission scenario, can cause major software revisions. Soft Computing techniques, expert systems, neural networks and other adaptive learning techniques are a potential solution to reduce cost and risk.",https://ieeexplore.ieee.org/document/1595615/,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",5-8 Dec. 2005,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/VLSI-TSA.2018.8403807,Mobile/embedded DNN and AI SoCs,IEEE,Conferences,"Summary form only. Recently, Deep Neural Networks are changing not only the technology paradigm in electronics but also the society itself with Artificial Intelligence technologies. In this presentation, firstly, the status of AI and DNN SoCs will be reviewed from two perspectives; the data-center oriented and the mobile and embedded AIs. This dichotomy shows clearly the possible application areas for the emerging future AIs. Especially, mobile and embedded deep learning hardware will be introduced together with CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network). In addition, real CMOS chip implementation results of mobile/embedded DNNs will be explained with measurement results. Secondly, KAIST's approach integrating both sides of brain, right-brain for ""approximation and adaptation hardware"" and left-brain for""precise and programmable Von Neumann architecture"", will be explained with novel design methodology. The deep neural networks and the specialized intelligent hardware (mimicking right brain) capable of statistical processing or learning and the multi-core processors (mimicking left brain) performing the precise computations including software AI are integrated on the same SoC. Based on this brain-mimicking SoCs, the object recognition and the augmented reality applications are implemented with low-power and high-performance for wearable devices such as smart glasses, autonomous vehicles, and intelligent robots.",https://ieeexplore.ieee.org/document/8403807/,"2018 International Symposium on VLSI Technology, Systems and Application (VLSI-TSA)",16-19 April 2018,ieeexplore
10.1109/VLSI-DAT.2018.8373285,Mobile/embedded DNN and AI SoCs,IEEE,Conferences,"Recently, Deep Neural Networks are changing not only the technology paradigm in electronics but also the society itself with Artificial Intelligence technologies. In this presentation, firstly, the status of AI and DNN SoCs will be reviewed from two perspectives; the data-center oriented and the mobile and embedded AIs. This dichotomy shows clearly the possible application areas for the emerging future AIs. Especially, mobile and embedded deep learning hardware will be introduced together with CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network). In addition, real CMOS chip implementation results of mobile/embedded DNNs will be explained with measurement results. Secondly, KAIST's approach integrating both sides of brain, right-brain for ""approximation and adaptation hardware"" and left-brain for ""precise and programmable Von Neumann architecture"", will be explained with novel design methodology. The deep neural networks and the specialized intelligent hardware (mimicking right brain) capable of statistical processing or learning and the multi-core processors (mimicking left brain) performing the precise computations including software AI are integrated on the same SoC. Based on this brain-mimicking SoCs, the object recognition and the augmented reality applications are implemented with low-power and high-performance for wearable devices such as smart glasses, autonomous vehicles, and intelligent robots.",https://ieeexplore.ieee.org/document/8373285/,"2018 International Symposium on VLSI Design, Automation and Test (VLSI-DAT)",16-19 April 2018,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ICRA.2016.7487661,Model-predictive control with stochastic collision avoidance using Bayesian policy optimization,IEEE,Conferences,"Robots are increasingly expected to move out of the controlled environment of research labs and into populated streets and workplaces. Collision avoidance in such cluttered and dynamic environments is of increasing importance as robots gain more autonomy. However, efficient avoidance is fundamentally difficult since computing safe trajectories may require considering both dynamics and uncertainty. While heuristics are often used in practice, we take a holistic stochastic trajectory optimization perspective that merges both collision avoidance and control. We examine dynamic obstacles moving without prior coordination, like pedestrians or vehicles. We find that common stochastic simplifications lead to poor approximations when obstacle behavior is difficult to predict. We instead compute efficient approximations by drawing upon techniques from machine learning. We propose to combine policy search with model-predictive control. This allows us to use recent fast constrained model-predictive control solvers, while gaining the stochastic properties of policy-based methods. We exploit recent advances in Bayesian optimization to efficiently solve the resulting probabilistically-constrained policy optimization problems. Finally, we present a real-time implementation of an obstacle avoiding controller for a quadcopter. We demonstrate the results in simulation as well as with real flight experiments.",https://ieeexplore.ieee.org/document/7487661/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IJCNN.2017.7965938,Modeling direction selective visual neural network with ON and OFF pathways for extracting motion cues from cluttered background,IEEE,Conferences,"The nature endows animals robust vision systems for extracting and recognizing different motion cues, detecting predators, chasing preys/mates in dynamic and cluttered environments. Direction selective neurons (DSNs), with preference to certain orientation visual stimulus, have been found in both vertebrates and invertebrates for decades. In this paper, with respect to recent biological research progress in motion-detecting circuitry, we propose a novel way to model DSNs for recognizing movements on four cardinal directions. It is based on an architecture of ON and OFF visual pathways underlies a theory of splitting motion signals into parallel channels, encoding brightness increments and decrements separately. To enhance the edge selectivity and speed response to moving objects, we put forth a bio-plausible spatial-temporal network structure with multiple connections of same polarity ON/OFF cells. Each pair-wised combination is filtered with dynamic delay depending on sampling distance. The proposed vision system was challenged against image streams from both synthetic and cluttered real physical scenarios. The results demonstrated three major contributions: first, the neural network fulfilled the characteristics of a postulated physiological map of conveying visual information through different neuropile layers; second, the DSNs model can extract useful directional motion cues from cluttered background robustly and timely, which hits at potential of quick implementation in vision-based micro mobile robots; moreover, it also represents better speed response compared to a state-of-the-art elementary motion detector.",https://ieeexplore.ieee.org/document/7965938/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ICRA.2015.7139899,Modeling of movement control architectures based on motion primitives using domain-specific languages,IEEE,Conferences,"This paper introduces a model-driven approach for engineering complex movement control architectures based on motion primitives, which in recent years have been a central development towards adaptive and flexible control of complex and compliant robots. We consider rich motor skills realized through the composition of motion primitives as our domain. In this domain we analyze the control architectures of representative example systems to identify common abstractions. It turns out that the introduced notion of motion primitives implemented as dynamical systems with machine learning capabilities, provide the computational building block for a large class of such control architectures. Building on the identified concepts, we introduce domain-specific languages that allow the compact specification of movement control architectures based on motion primitives and their coordination respectively. Using a proper tool chain, we show how to employ this model-driven approach in a case study for the real world example of automatic laundry grasping with the KUKA LWR-IV, where executable source-code is automatically generated from the domain-specific language specification.",https://ieeexplore.ieee.org/document/7139899/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ROMAN.2005.1513775,Modularity and integration in the design of a socially interactive robot,IEEE,Conferences,"Designing robots that are capable of interacting with humans in real life settings is a challenging task. One key issue is the integration of multiple modalities (e.g., mobility, physical structure, navigation, vision, audition, dialogue, reasoning) into a coherent framework. Taking the AAAI mobile robot challenge (making a robot attend the national conference on artificial intelligence) as the experimental context, we are currently addressing hardware, software and computation integration issues involved in designing a robot capable of sophisticated interaction with humans. This paper reports on our design solutions and the current status of the work, along with the potential impacts this design on human-robot interaction research.",https://ieeexplore.ieee.org/document/1513775/,"ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",13-15 Aug. 2005,ieeexplore
10.1109/IROS.2018.8593871,"Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning",IEEE,Conferences,"Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.",https://ieeexplore.ieee.org/document/8593871/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICAR.2013.6766513,Move and the robot will learn: Vision-based autonomous learning of object models,IEEE,Conferences,"As robots are increasingly deployed in complex real-world domains, visual object recognition continues to be an open problem. Existing algorithms for learning and recognizing objects are predominantly computationally expensive, and require considerable training or domain knowledge. Our algorithm enables robots to use motion cues to identify and focus on a set of interesting objects, automatically extracting appearance-based and contextual cues from a small number of images to efficiently learn representative models of these objects. Learned models exploit complementary strengths of: (a) relative spatial arrangement of gradient features; (b) graph-based models of neighborhoods of gradient features; (c) parts-based models of image segments; (d) color distributions; and (e) mixture models of local context. The learned models are used in conjunction with an energy minimization algorithm and a generative model of information fusion for reliable and efficient recognition in novel scenes. The algorithm is evaluated on mobile robots in indoor and outdoor domains, and on images from benchmark datasets.",https://ieeexplore.ieee.org/document/6766513/,2013 16th International Conference on Advanced Robotics (ICAR),25-29 Nov. 2013,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/IROS.2001.977153,Multi-robot path planning for dynamic environments: a case study,IEEE,Conferences,"Most multi-robot navigation planning methods make assumptions about the kind of navigation problems they are to solve and the capabilities of the robots they are to control. In this paper, we propose to select problem-adequate navigation planning methods based on empirical investigations, that is, the robots should learn by experimentation to use the best planning methods. To support this development strategy we provide software tools that enable the robots to automatically learn predictive models for the performance of different navigation planning methods in a given application domain. We show, in the context of robot soccer, that the hybrid planning method which selects planning methods based on a learned predictive model outperforms the individual planning methods. The results are validated in extensive experiments using a realistic and accurate robot simulator that has learned the dynamic model of the real robots.",https://ieeexplore.ieee.org/document/977153/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/SECON.2000.845570,Navigational task-planning of distributed cooperative robotic vehicles,IEEE,Conferences,"Real time obstacle avoidance is one of the intelligent tasks for intelligent mobile robots. Mobile robots should possess the ability to act autonomously in the presence of uncertainty and to adjust their action based on sensed information. They also should be capable of accepting high level mission oriented commands, integrate several kinds of data, including task specification, able to handle information about their own state and the state of the environment too, and be capable of reasoning under uncertainty without human intervention. The proposed technique is a behavior-based approach that blends subset navigational behaviors such as reflexive, potential field and wall following techniques. We discuss each approach separately and present a technique for adaptive navigational behavior switching that is conditional based on the availability of sensory information locally and globally. Our navigation control strategies are developed fully in the FMCell environment. We present some simulation results from FMCell software.",https://ieeexplore.ieee.org/document/845570/,Proceedings of the IEEE SoutheastCon 2000. 'Preparing for The New Millennium' (Cat. No.00CH37105),9-9 April 2000,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/ICIT.2004.1490796,Neural network based control of a four rotor helicopter,IEEE,Conferences,"In this paper the design and development of an intelligent controller based on neural networks for a hoverable flying robot to be capable of achieving vertical take off and landing and to be able to sustain a specified attitude is presented. The ability to be able to autonomously navigate through a predefined path was designated for a future phase. This work is different from most autonomous flying robots as it focuses on a four-propeller configuration. This is a very rare helicopter design because of its inherent instability and it is believed that an autonomous robot of this configuration has not yet been successfully developed. In addition, this project uses fixed pitch propellers instead of variable pitch rotors resulting in a greatly reduced cost and mechanical complexity. The downside is that this introduces significant additional challenges in the control. Relative stability was achieved in three axis and all the supporting modules were successfully designed and implemented. However, significant challenges were encountered including the complexities of creating a neural networks controller (NNC) to work in real-time in a slow microcontroller as well as to develop the training process.",https://ieeexplore.ieee.org/document/1490796/,"2004 IEEE International Conference on Industrial Technology, 2004. IEEE ICIT '04.",8-10 Dec. 2004,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1145/2830772.2830789,Neuromorphic accelerators: A comparison between neuroscience and machine-learning approaches,IEEE,Conferences,"A vast array of devices, ranging from industrial robots to self-driven cars or smartphones, require increasingly sophisticated processing of real-world input data (image, voice, radio, ...). Interestingly, hardware neural network accelerators are emerging again as attractive candidate architectures for such tasks. The neural network algorithms considered come from two, largely separate, domains: machine-learning and neuroscience. These neural networks have very different characteristics, so it is unclear which approach should be favored for hardware implementation. Yet, few studies compare them from a hardware perspective. We implement both types of networks down to the layout, and we compare the relative merit of each approach in terms of energy, speed, area cost, accuracy and functionality. Within the limit of our study (current SNN and machine learning NN algorithms, current best effort at hardware implementation efforts, and workloads used in this study), our analysis helps dispel the notion that hardware neural network accelerators inspired from neuroscience, such as SNN+STDP, are currently a competitive alternative to hardware neural networks accelerators inspired from machine-learning, such as MLP+BP: not only in terms of accuracy, but also in terms of hardware cost for realistic implementations, which is less expected. However, we also outline that SNN+STDP carry potential for reduced hardware cost compared to machine-learning networks at very large scales, if accuracy issues can be controlled (or for applications where they are less important). We also identify the key sources of inaccuracy of SNN+STDP which are less related to the loss of information due to spike coding than to the nature of the STDP learning algorithm. Finally, we outline that for the category of applications which require permanent online learning and moderate accuracy, SNN+STDP hardware accelerators could be a very cost-efficient solution.",https://ieeexplore.ieee.org/document/7856622/,2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),5-9 Dec. 2015,ieeexplore
10.1109/HUMANOIDS.2018.8625038,NimbRo-OP2X: Adult-Sized Open-Source 3D Printed Humanoid Robot,IEEE,Conferences,"Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreál, Canada, where it won all possible awards in the Humanoid AdultSize class.",https://ieeexplore.ieee.org/document/8625038/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ICDARW.2019.30062,OctShuffleMLT: A Compact Octave Based Neural Network for End-to-End Multilingual Text Detection and Recognition,IEEE,Conferences,"In recent years, scene text detection has witnessed rapid progress especially with the recent development of convolutional neural networks. However, there still exist many challenges in applying very deep networks to many real-world applications, that have hardware limitations, such as robots, and smartphones. To address these challenges, in this paper, we propose the OctShuffleMLT, an effective fully convolutional neural network, with fewer layers and parameters, which can precisely detect multilingual scene text. Our proposed model is based on the Octave Convolutions that use compact blocks, which reduces memory inference by 13.16%, FLOPS by 71.86%, and the number of parameters by 34.04% when compared to the baseline system. Extensive experiments were conducted on ICDAR 2015 and ICDAR 2017 datasets. Experimental results show that our model can produce accurate detection recognition results on both datasets. The code for the paper is made available on the GitHub repository https://github.com/victoic/OctShuffle-MLT.",https://ieeexplore.ieee.org/document/8892934/,2019 International Conference on Document Analysis and Recognition Workshops (ICDARW),22-25 Sept. 2019,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/COGINF.2008.4639192,On Visual Semantic Algebra (VSA) and the cognitive process of pattern recognition,IEEE,Conferences,"A new form of denotational mathematics known as visual semantic algebra (VSA) is presented for abstract visual object and architecture manipulation. The cognitive theories for pattern recognition, such as cognitive principles of visual perception and basic mechanisms of object and pattern recognition, are explored. A number of case studies on VSA in pattern recognition are presented to demonstrate VAS' expressive power for algebraic manipulation of visual objects. The cognitive process of pattern recognition is rigorously modeled using VSA and real-time process algebra (RTPA), which reveals the fundamental mechanisms of natural pattern recognition by the brain. The theories and case studies demonstrate that VSA can be applied not only in machine visual and spatial reasoning, but also in computational intelligence system designs as a powerful man-machine language for representing and manipulating visual geometrical systems. On the basis of VSA, computational intelligence systems such as robots and cognitive computers may process and inference visual and image object rigorously and efficiently.",https://ieeexplore.ieee.org/document/4639192/,2008 7th IEEE International Conference on Cognitive Informatics,14-16 Aug. 2008,ieeexplore
10.1109/AIMS.2014.23,Online Tool for Benchmarking of Simulated Intervention Autonomous Underwater Vehicles: Evaluating Position Controllers in Changing Underwater Currents,IEEE,Conferences,"Benchmarking is nowadays an issue on robotic research platforms, due to the fact that it is not easy to reproduce previous experiments and knowing in detail in which real conditions other algorithms have been performed. Having a web-based tool to configure and execute benchmarks opens the door to new opportunities as the design of virtual tele-laboratories that permit the implementation of new algorithms using specific and detailed constraints. This is fundamental for designing benchmarks that allow the experiments to be made in a more scientific manner, taking into account that these experiments should be able to be reproduced again by other people under the same circumstances. In the context of underwater interventions with semi-autonomous robots, the situation gets even more interesting, specially those performed on real sea scenarios, which are expensive, and difficult to perform and reproduce. This paper presents the recent advances in the online configuration tool for benchmarking, a tool that is continuously being improved in our laboratory. Our last contribution focuses on evaluating position controllers for changing underwater currents and the possibility for the user to upload its own controllers to the benchmarking tool to get online performance results.",https://ieeexplore.ieee.org/document/7102468/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/IROS.2017.8206344,Online multi-target learning of inverse dynamics models for computed-torque control of compliant manipulators,IEEE,Conferences,"Inverse dynamics models are applied to a plethora of robot control tasks such as computed-torque control, which are essential for trajectory execution. The analytical derivation of such dynamics models for robotic manipulators can be challenging and depends on their physical characteristics. This paper proposes a machine learning approach for modeling inverse dynamics and provides information about its implementation on a physical robotic system. The proposed algorithm can perform online multi-target learning, thus allowing efficient implementations on real robots. Our approach has been tested both offline, on datasets captured from three different robotic systems and online, on a physical system. The proposed algorithm exhibits state-of-the-art performance in terms of generalization ability and convergence. Furthermore, it has been implemented within ROS for controlling a Baxter robot. Evaluation results show that its performance is comparable to the built-in inverse dynamics model of the robot.",https://ieeexplore.ieee.org/document/8206344/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ICCE-Berlin47944.2019.8966156,Optimizing Deep Learning Based Semantic Video Segmentation on Embedded GPUs,IEEE,Conferences,"Decision making in many industries today is being improved drastically thanks to artificial intelligence and deep learning. New algorithms address challenges such as genome mapping, medical diagnostics, self-driving cars, autonomous robots and more. Deep learning in embedded systems requires high optimization due to the high computational demand, given that power, heat dissipation, size and price constraints are numerous. In this paper we analyze several acceleration methods which include utilization of GPUs for most complex variants of deep learning, such as semantic video segmentation operating in real time. Specifically, we propose mapping of acceleration routines commonly present within deep learning SDKs to different network layers in semantic segmentation. Finally, we evaluate one implementation utilizing the enumerated techniques for semantic segmentation of front camera in autonomous driving front view.",https://ieeexplore.ieee.org/document/8966156/,2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin),8-11 Sept. 2019,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.23919/ICINS43215.2020.9134006,Path Planning with Improved Artificial Potential Field Method Based on Decision Tree,IEEE,Conferences,"Path planning is one of the key research directions in the field of mobile robots. It ensures that moving objects can reach the target point safely and without collision in a complex obstacle environment. The path planning is to search an optimal path from the starting point to the target point for the mobile robot in an environment with obstacles, according to certain evaluation criteria (such as the time, the best path, the minimum energy consumption, etc.). The path planning based on artificial potential field method has been paid more and more attention because of its advantages such as convenient calculation, simple implementation of hardware and outstanding real-time performance. However, the artificial potential field method has some limitations, such as the local minimum, the oscillation of moving objects among obstacles and so on. To solve these problems, we can introduce the idea of decision tree into the artificial potential field method for improvement. In machine learning, decision tree is usually used for classification. It is a prediction model, which represents a mapping relationship between object attributes and object values. By utilizing the advantages of decision tree in rule expression and extraction, an improved artificial potential field path planning model based on decision tree is constructed, which can realize real-time and accurate identification of current behavior and fast decision-making of next time behavior in path planning. Aiming at the dynamic path planning problem of mobile robots in indoor complex environment, based on the traditional artificial potential field method, this paper introduces the distance term into the potential field function, and proposes an improved artificial potential field method based on the idea of decision tree, to solve the local minimum, the oscillation between obstacles and concave obstacle problems. According to repulsion coefficient, deflection angle of resultant force and velocity, a reasonable classification decision is made to meet the needs of different obstacle distribution scenarios, and the effectiveness of the proposed method is verified by simulation experiments. Simulation results show that, compared with the traditional artificial potential field method, the planning time of improved algorithm is reduced by 50%, and the smoothness of path planning by the improved algorithm is increased by 43.3%.",https://ieeexplore.ieee.org/document/9134006/,2020 27th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS),25-27 May 2020,ieeexplore
10.1109/ICCEAI52939.2021.00074,Pedestrian Recognition System for Smart Security Robot using Pedestrian Re-identification Algorithm,IEEE,Conferences,"The security system is an important guarantee for the safety of citizens' lives and property. In recent years, security robots have been more and more widely used in security systems. At present, domestic security robots generally lack of pedestrian recognition ability under complex circumstances. Therefore, this paper designs and implements pedestrian recognition system for smart security robots using improved pedestrian re-identification algorithm. Experiment result shows that the system has success rate of 90 % and response speed compliance rate of 94.4% under real circumstances, which is much better than traditional system.",https://ieeexplore.ieee.org/document/9544430/,2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI),27-29 Aug. 2021,ieeexplore
10.1109/ICSMC.1999.816641,"Perception, reasoning and learning of multiple agent systems for robot soccer",IEEE,Conferences,"Presents a supervisory control strategy for coordination of soccer playing mobile robots. Within the framework of a hierarchical control structure, three layered components of supervisor, coordinator, and executor emulate the basic three concepts of human intelligence, perception, reasoning, and learning. A small size discrete event system model is derived and implemented in the supervisor and coordinator for state-action reasoning and coordination of multiple robotic agents for a successful soccer game. Experimental results of real soccer games are given to demonstrate the feasibility and effectiveness of the developed supervisory control strategy in terms of structural simplicity and computational speed for real-time control.",https://ieeexplore.ieee.org/document/816641/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/ICBSII51839.2021.9445124,Positioning the 5-DOF Robotic Arm using Single Stage Deep CNN Model,IEEE,Conferences,"In teleoperation mechanism, the surgical robots are controlled using hand gestures from remote location. The remote location robotic arm control using hand gesture recognition is a challenging computer vision problem. The hand action recognition under complex environment (cluttered background, lighting variation, scale variation etc.) is a difficult and time consuming process. In this paper, a light weight Convolutional Neural Network (CNN) model Single Shot Detector (SSD) Lite MobileNet-V2 is proposed for real-time hand gesture recognition. SSD Lite versions tend to run hand gesture recognition applications on low-power computing devices like Raspberry Pi due to its light weight and timely recognition. The model is deployed using a Camera and two Raspberry Pi Controllers For the hand gesture recognition and data transfer to the cloud server, the Raspberry Pi controller 1 is used. The Raspberry Pi Controller 2 receives the cloud information and controls the Robotic arm operations. The performance of the proposed model is also compared with a SSD Inception-V2 model for the MITI Hand dataset-II (MITI HD-II). The average precision, average recall and F1-score for SSD Lite MobileNet-V2 and SSD Inception-V2 models are analyzed by training and testing the model with the learning rate of 0.0002 using Adam optimizer. SSD MobileNet-V2 model obtained an Average precision of 98.74% and SSD Inception-V2 model as 99.27%, The prediction time for SSD Lite MobileNet-V2 model using Raspberry Pi controller takes only 0.67s whereas, 1.2s for SSD Inception-V2 Model.",https://ieeexplore.ieee.org/document/9445124/,"2021 Seventh International conference on Bio Signals, Images, and Instrumentation (ICBSII)",25-27 March 2021,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ROBIO49542.2019.8961870,Probabilistic Inferences on Quadruped Robots: An Experimental Comparison,IEEE,Conferences,"Due to the reality gap, computer software cannot fully model the physical robot in its environment, with noise, ground friction, and energy consumption. Consequently, a limited number of researchers work on applying machine learning in real-world robots. In this paper, we use two intelligent black-box optimization algorithms, Bayesian Optimization (BO) and Covariance Matrix Adaptation Evolution Strategy (CMA-ES), to solve a quadruped robot gait's parametric search problem in 10 dimensions, and compare these two methods to find which one is more suitable for legged robots' controller parameters tuning. Our results show that both methods can find an optimal solution in 130 iterations. BO converges faster than CMA-ES within its constrained range, while CMA-ES finds the optimum in the continuous space. Compared with the specific controller parameters of two methods, we also find that for quadruped robot's oscillators, the angular amplitude is the most important parameter. Thus, it is very beneficial for the quick parametric search of legged robots' controllers and avoids time-consuming manual tuning.",https://ieeexplore.ieee.org/document/8961870/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/WACV45572.2020.9093599,Probabilistic Object Detection: Definition and Evaluation,IEEE,Conferences,"We introduce Probabilistic Object Detection, the task of detecting objects in images and accurately quantifying the spatial and semantic uncertainties of the detections. Given the lack of methods capable of assessing such probabilistic object detections, we present the new Probability-based Detection Quality measure (PDQ). Unlike AP-based measures, PDQ has no arbitrary thresholds and rewards spatial and label quality, and foreground/background separation quality while explicitly penalising false positive and false negative detections. We contrast PDQ with existing mAP and moLRP measures by evaluating state-of-the-art detectors and a Bayesian object detector based on Monte Carlo Dropout. Our experiments indicate that conventional object detectors tend to be spatially overconfident and thus perform poorly on the task of probabilistic object detection. Our paper aims to encourage the development of new object detection approaches that provide detections with accurately estimated spatial and label uncertainties and are of critical importance for deployment on robots and embodied AI systems in the real world.",https://ieeexplore.ieee.org/document/9093599/,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),1-5 March 2020,ieeexplore
10.1109/IJCNN.2014.6889947,Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk,IEEE,Conferences,"Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk.",https://ieeexplore.ieee.org/document/6889947/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/IROS40897.2019.8968072,Quickly Inserting Pegs into Uncertain Holes using Multi-view Images and Deep Network Trained on Synthetic Data,IEEE,Conferences,"This paper explores the use of robots to autonomously assemble parts with variations in colors and textures. Specifically, we focus on peg-in-hole assembly with some initial position uncertainty and holes located on surfaces of different colors and textures. Two in-hand cameras and a force-torque sensor are used to account for the position uncertainty. A program sequence comprising learning-based visual servoing, spiral search, and impedance control is implemented to perform the peg-in-hole task with feedback from the above sensors. Contributions are mainly made in the learning-based visual servoing component of the sequence, where a deep neural network is trained with various sets of synthetic data generated using the concept of domain randomization to predict where a hole is. In the experiments and analysis section, the network is analyzed and compared, and a real-world robotic system to insert pegs to holes using the proposed method is implemented. The results show that the implemented peg-in-hole assembly system can perform successful peg-in-hole insertions on surfaces with various colors and textures. It can generally speed up the entire peg-in-hole process, especially when the initial position uncertainty is large.",https://ieeexplore.ieee.org/document/8968072/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROMAN.2002.1045636,RG mapping: learning compact and structured 2D line maps of indoor environments,IEEE,Conferences,"In this paper we present region and gateway (RG) mapping, a novel approach to laser-based 2D line mapping of indoor environments. RG mapping is capable of acquiring very compact, structured, and semantically annotated maps. We present and empirically analyze the method based on map acquisition experiments with autonomous mobile robots. The experiments show that RG mapping drastically compresses the data contained in line scan maps without substantial loss of accuracy.",https://ieeexplore.ieee.org/document/1045636/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/ICRA48506.2021.9561277,Rapid Pose Label Generation through Sparse Representation of Unknown Objects,IEEE,Conferences,"Deep Convolutional Neural Networks (CNNs) have been successfully deployed on robots for 6-DoF object pose estimation through visual perception. However, obtaining labeled data on a scale required for the supervised training of CNNs is a difficult task - exacerbated if the object is novel and a 3D model is unavailable. To this end, this work presents an approach for rapidly generating real-world, pose-annotated RGB-D data for unknown objects. Our method not only circumvents the need for a prior 3D object model (textured or otherwise) but also bypasses complicated setups of fiducial markers, turntables, and sensors. With the help of a human user, we first source minimalistic labelings of an ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then, by solving an optimization problem, we combine these labels under a world frame to recover a sparse, keypoint-based representation of the object. The sparse representation leads to the development of a dense model and the pose labels for each image frame in the set of scenes. We show that the sparse model can also be efficiently used for scaling to a large number of new scenes. We demonstrate the practicality of the generated labeled dataset by training a CNN based 6-DoF object pose estimator.",https://ieeexplore.ieee.org/document/9561277/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ICRoM.2015.7367861,ReMoRo; A mobile robot platform based on distributed I/O modules for research and education,IEEE,Conferences,"We present our recent work on the electrical and hardware design of the mobile robot platform ReMoRo that is based on distributed input/output modules. We have designed three generation of this platform with different specifications, which it help us to design more compatible and applied mobile robot. Nevertheless, the goal of this project was to develop a low-cost and robust but extensible modular robot platform for research and educational purposes. In this paper we describe a new affordable robot structure that enables large-scale innovative, new curriculum, multi robot research and multi-robotics outreach to computer and artificial intelligent students. We introduce the ReMoRo platform, which offers a balance between capabilities, accessibility, cost and an opendesign. All of electrical devices like sensors module, motor drivers and device communication manager are designed based on ARM Cortex M3 microcontrollers that runs under Real-Time Operating System (freeRTOS) for manages each modules internal scheduling and activation control in communication bus. With a range of different sensors, cylindrical manipulator and omnidirectional locomotion system, RoMeRo can interact with environment in multiple ways, handle common objects and therefore be used in various service robot scenarios like warehouse robots or multi agent mobile robots. We demonstrate the usability of our concept by quantifying the object-handling task and also briefly describe the software design based on ROS framework for educational usage.",https://ieeexplore.ieee.org/document/7367861/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/ICCCE.2008.4580693,Real time implementation of NARMA L2 feedback linearization and smoothed NARMA L2 controls of a single link manipulator,IEEE,Conferences,"Robotics is a field of modern technology which requires knowledge in vast areas such as electrical engineering, mechanical engineering, computer science as well as finance. Nonlinearities and parametric uncertainties are unavoidable problems faced in controlling robots in industrial plants. Tracking control of a single link manipulator driven by a permanent magnet brushed DC motor is a nonlinear dynamics due to effects of gravitational force, mass of the payload, posture of the manipulator and viscous friction coefficient. Furthermore uncertainties arise because of changes of the rotor resistance with temperature and random variations of friction while operating. Due to this fact classical PID controller can not be used effectively since it is developed based on linear system theory. Neural network control schemes for manipulator control problem have been proposed by researchers; in which their competency is validated through simulation studies. On the other hand, actual real time applications are rarely established. Instead of simulation studies, this paper is aimed to implement neural network controller in real time for controlling a DC motor driven single link manipulator. The work presented in this paper is concentrating on neural NARMA L2 control and its improvement called to as Smoothed NARMA L2 control. As proposed by K. S Narendra and Mukhopadhyay, Narma L2 control is one of the popular neural network architectures for prediction and control. The real time experimentation showed that the Smoothed NARMA L2 is effective for controlling the single link manipulator for both point-to-point and continuous path motion control.",https://ieeexplore.ieee.org/document/4580693/,2008 International Conference on Computer and Communication Engineering,13-15 May 2008,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/SmartWorld.2018.00106,Real-Time Data Processing Architecture for Multi-Robots Based on Differential Federated Learning,IEEE,Conferences,"The emergency of ubiquitous intelligence in various things has become the ultimate cornerstone in building a smart interconnection of the physical world and the human world, which also caters to the idea of Internet of Things (IoT). Nowadays, robots as a new type of ubiquitous IoT devices have gained much attention. With the increasing number of distributed multi-robots, such smart environment generates unprecedented amounts of data. Robotic applications are faced with challenges of such big data: the serious real-time assurance and data privacy. Therefore, in order to obtain the big data values via knowledge sharing under the premise of ensuring the real-time data processing and data privacy, we propose a real-time data processing architecture for multi-robots based on the differential federated learning, called RT-robots architecture. A global shared model with differential privacy protection is trained on the cloud iteratively and distributed to multiple edge robots in each round, and the robotic tasks are processed locally in real time. Our implementation and experiments demonstrate that our architecture can be applied on multiple robotic recognition tasks, balance the trade-off between the performance and privacy.",https://ieeexplore.ieee.org/document/8560084/,"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",8-12 Oct. 2018,ieeexplore
10.1109/CNSI.2011.67,Real-Time Face-Detection Engine for Robustness to Variable Illumination and Rotated Faces,IEEE,Conferences,"In this paper, we proposes a novel hardware architecture and FPGA implementation method of high performance real-time face-detection engine for robustness to variable illumination and rotation. The proposed face detection algorithm improved its performance by using MCT (Modified Census Transform), rotation transformation and AdaBoost learning algorithm. For implementation, we used a QVGA class camera, LCD display, and Virtex5 LX330 FPGA made by Xilinx Corporation. The verification results showed that it is possible to detect at least 32 faces in a wide variety of sizes at a maximum speed of 43 frames per second in real time. This finding can be applied to artificial intelligence robots for human recognition, conventional security systems for identity certification, and cutting-edge digital cameras using image processing techniques.",https://ieeexplore.ieee.org/document/5954277/,"2011 First ACIS/JNU International Conference on Computers, Networks, Systems and Industrial Engineering",23-25 May 2011,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/IROS45743.2020.9341473,Real-World Human-Robot Collaborative Reinforcement Learning,IEEE,Conferences,"The intuitive collaboration of humans and intelligent robots (embodied AI) in the real-world is an essential objective for many desirable applications of robotics. Whilst there is much research regarding explicit communication, we focus on how humans and robots interact implicitly, on motor adaptation level. We present a real-world setup of a human-robot collaborative maze game, designed to be non-trivial and only solvable through collaboration, by limiting the actions to rotations of two orthogonal axes, and assigning each axes to one player. This results in neither the human nor the agent being able to solve the game on their own. We use deep reinforcement learning for the control of the robotic agent, and achieve results within 30 minutes of real-world play, without any type of pre-training. We then use this setup to perform systematic experiments on human/agent behaviour and adaptation when co-learning a policy for the collaborative game. We present results on how co-policy learning occurs over time between the human and the robotic agent resulting in each participant's agent serving as a representation of how they would play the game. This allows us to relate a person's success when playing with different agents than their own, by comparing the policy of the agent with that of their own agent.",https://ieeexplore.ieee.org/document/9341473/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/CRV50864.2020.00032,Real-time Motion Planning for Robotic Teleoperation Using Dynamic-goal Deep Reinforcement Learning,IEEE,Conferences,"We propose Dynamic-goal Deep Reinforcement Learning (DGDRL) method to address the problem of robot arm motion planning in telemanipulation applications. This method intuitively maps human hand motions to a robot arm in real-time, while avoiding collisions, joint limits and singularities. We further propose a novel hardware setup, based on the HTC VIVE VR system, that enables users to smoothly control the robot tool position and orientation with hand motions, while monitoring its movements in a 3D virtual reality environment. A VIVE controller captures 6D hand movements and gives them as reference trajectories to a deep neural policy network for controlling the robot's joint movements. Our DGDRL method leverages the state-of-art Proximal Policy Optimization (PPO) algorithm for deep reinforcement learning to train the policy network with the robot joint values and reference trajectory observed at each iteration. Since training the network on a real robot is time-consuming and unsafe, we developed a simulation environment called RobotPath which provides kinematic modeling, collision analysis and a 3D VR graphical simulation of industrial robots. The deep neural network trained using RobotPath is then deployed on a physical robot (ABB IRB 120) to evaluate its performance. We show that the policies trained in the simulation environment can be successfully used for trajectory planning on a real robot. The the codes, data and video presenting our experiments are available at https://github.com/kavehkamali/ppoRobotPath.",https://ieeexplore.ieee.org/document/9108691/,2020 17th Conference on Computer and Robot Vision (CRV),13-15 May 2020,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/CCA.2007.4389266,Real-time Obstacle Avoidance Strategy for Mobile Robot Based On Improved Coordinating Potential Field with Genetic Algorithm,IEEE,Conferences,"To overcome the problems during navigation of mobile robots in dynamic environment using the traditional artificial potential field (APF) method, a novel improved method called coordinating potential field (CPF) is proposed. The local potential field is constructed by using local subgoals, which obtained by updating dynamic windows. The questions of local minima, oscillation between multiple obstacles and real-time dynamic obstacle avoidance are solved. At last multi-objective parameter optimization is implemented by using adaptive genetic algorithm. Simulation results indicate that this strategy is practicable and effective.",https://ieeexplore.ieee.org/document/4389266/,2007 IEEE International Conference on Control Applications,1-3 Oct. 2007,ieeexplore
10.1109/EFTA.2007.4416888,Real-time architecture for mobile assistant robots,IEEE,Conferences,"Mobile robotics is a challenging research area, with produced results that were unthinkable several years ago. There exist algorithms and methods capable of performing difficult tasks such as detect/classify objects, skill learning and SLAM. From the initial design steps, the real-time software architecture of a robotic platform requires great attention. The problem is difficult, because various components, such as sensing, perception, localization, and motor control, are required to operate and interact in real-time. This makes the system a very complex one. This paper presents a real-time control architecture designed for mobile robots and intelligent vehicles. Moreover, an example of application of the control structure consisting on a system for learning to classify places, using laser range data, is reported.",https://ieeexplore.ieee.org/document/4416888/,2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007),25-28 Sept. 2007,ieeexplore
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/IRIA53009.2021.9588681,Real-time gesture control UAV with a low resource framework,IEEE,Conferences,"This study showcases a low-resource framework that enables people with no technical know-how to interact with drones, it also explores the capabilities of 2D- computer vision and deep learning techniques for gesture based interface systems on a low-cost micro drone with an onboard RGB camera. This Human-Robot Interaction system processes the real-time human pose to allow a user to command the drone, i.e., by providing direction to move and execute actions. A linear PD controller and image processing techniques are implemented to track humans whilst maintaining a safe distance from the user by perceiving depth information through pose estimation. We incorporated the gesture recognition results into a drone using the Robot Operating System (ROS) and evaluated system performance indoor and outdoor. This low computation framework can be applied further to control robotic arms or mobile robots.",https://ieeexplore.ieee.org/document/9588681/,2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA),20-22 Sept. 2021,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/ROBOT.1993.291973,Real-time implementation of neural network learning control of a flexible Space manipulator,IEEE,Conferences,"A neural network approach to online learning control and real-time implementation for a flexible space robot manipulator is presented. An overview of the motivation and system development of the self-mobile space modulator (SM/sup 2/) is given. The neural network learns control by updating feedforward dynamics based on feedback control input. Implementation issues associated with online training strategies are addressed and a single stochastic training scheme is presented. A recurrent neural network architecture with improved performance is proposed. Using the proposed learning scheme, the manipulator tracking error is reduced by 85% compared to that of conventional proportional-integral-derivative (PID) control. The approach possesses a high degree of generality and adaptability to various applications. It will be a valuable learning control method for robots working in unconstructed environments.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/291973/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/ETS.2017.7968218,Real-time self-learning for control law adaptation in nonlinear systems using encoded check states,IEEE,Conferences,"With the wide proliferation of autonomous sense-and-control real-time systems (such as robots and self-driven cars), a key research objective is rapid recovery from the effects of anomalies and impairments arising from performance degradation of sensors and actuators and electro-mechanical subsystems due to field wear and tear. This must be achieved with minimal impact on system performance while maintaining low implementation overhead and high coverage of multi-parameter failure mechanisms. In this work, we propose a reinforcement learning framework for on-line control law adaptation in autonomous nonlinear systems assisted by system state encodings. These encodings are exploited to generate time-varying error signals whose (transient) waveforms in relation to the input stimulus, contain root-cause diagnostic information. This establishes a statistical correlation between the transient waveforms and the parameters of the optimal nonlinear controller under arbitrary multi-parameter perturbations of sensor/actuator and subsystem performances. Consequently this correlation is tapped, using pre-deployment supervised learning algorithms, to predict near-optimal controller parameter values whenever sufficiently large parameter deviations are detected (due to non-zero error signals). From these near-optimal starting conditions, an actor-critic reinforcement learning controller for nonlinear systems quickly converges to the optimal control law for the parameter-perturbed system (up to 10× faster than for systems not assisted by the diagnostic information provided by the state encoding driven error signal above). We implement the proposed methodology on two nonlinear systems demonstrating fast performance recovery in real time.",https://ieeexplore.ieee.org/document/7968218/,2017 22nd IEEE European Test Symposium (ETS),22-26 May 2017,ieeexplore
10.1109/ICMLA.2017.0-161,Realistic Traffic Generation for Web Robots,IEEE,Conferences,"Critical to evaluating the capacity, scalability, and availability of web systems are realistic web traffic generators. Web traffic generation is a classic research problem, no generator accounts for the characteristics of web robots or crawlers that are now the dominant source of traffic to a web server. Administrators are thus unable to test, stress, and evaluate how their systems perform in the face of ever increasing levels of web robot traffic. To resolve this problem, this paper introduces a novel approach to generate synthetic web robot traffic with high fidelity. It generates traffic that accounts for both the temporal and behavioral qualities of robot traffic by statistical and Bayesian models that are fitted to the properties of robot traffic seen in web logs from North America and Europe. We evaluate our traffic generator by comparing the characteristics of generated traffic to those of the original data. We look at session arrival rates, inter-arrival times and session lengths, comparing and contrasting them between generated and real traffic. Finally, we show that our generated traffic affects cache performance similarly to actual traffic, using the common LRU and LFU eviction policies.",https://ieeexplore.ieee.org/document/8260631/,2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA),18-21 Dec. 2017,ieeexplore
10.1109/SII.2010.5708353,Realization and analysis of giant-swing motion using Q-Learning,IEEE,Conferences,"Many research papers have reported studies on sports robots that realize giant-swing motion. However, almost all these robots were controlled using trajectory planning methods, and few robots realized giant-swing motion by learning. Consequently, in this study, we attempted to construct a humanoid robot that realizes giant-swing motion by Q-learning, a reinforcement learning technique. The significant aspect of our study is that few robotic models were constructed beforehand; the robot learns giant-swing motion only by interaction with the environment during simulations. Our implementation faced several problems such as imperfect perception of the velocity state and robot posture issues caused by using only the arm angle. However, our real robot realized giant-swing motion by averaging the Q value and by using rewards - the absolute angle of the foot angle and the angular velocity of the arm angle-in the simulated learning data; the sampling time was 250 ms. Furthermore, the feasibility of generalization of learning for realizing selective motion in the forward and backward rotational directions was investigated; it was revealed that the generalization of learning is feasible as long as it does not interfere with the robot's motions.",https://ieeexplore.ieee.org/document/5708353/,2010 IEEE/SICE International Symposium on System Integration,21-22 Dec. 2010,ieeexplore
10.1109/ICARM52023.2021.9536145,Reducing the Dimension of the Configuration Space with Self Organizing Neural Networks,IEEE,Conferences,"For robotics, especially industrial applications, it is crucial to reactively plan safe motions through efficient algorithms. Planning is more powerful in the configuration space than the task space. However, for robots with many degrees of freedom, this is challenging and computationally expensive. Sophisticated techniques for motion planning such as the Wavefront algorithm are limited by the high dimensionality of the configuration space, especially for robots with many degrees of freedom. For a neural implementation of the Wavefront algorithm in the configuration space, neurons represent discrete configurations and synapses are used for path planning. In order to decrease the complexity, we reduce the search space by pruning superfluous neurons and synapses. We present different models of self-organizing neural networks for this reduction. The approach takes real-life human motion data as input and creates a representation with reduced dimension. We compare six different neural network models and adapt the Wavefront algorithm to the different structures of the reduced output spaces. The method is backed up by an extensive evaluation of the reduced spaces, including their suitability for path planning by the Wavefront algorithm.",https://ieeexplore.ieee.org/document/9536145/,2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2021,ieeexplore
10.1109/ICRA.2019.8793627,Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT,IEEE,Conferences,"The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.",https://ieeexplore.ieee.org/document/8793627/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AI4I46381.2019.00027,Reinforcement Learning of a Robot Cell Control Logic using a Software-in-the-Loop Simulation as Environment,IEEE,Conferences,"This paper introduces a method for automatic robot programming of industrial robots using reinforcement learning on a Software-in-the-loop simulation. The focus of the the paper is on the higher levels of a hierarchical robot programming problem. While the lower levels the skills are stored as domain specific program code, the combination of the skills into a robot control program to solve a specific task is automated. The reinforcement learning learning approach allows the shopfloor workers and technicians just to define the end result of the manufacturing process through a reward function. The programming and process optimization is done within the learning procedure. The Software-in-the-loop simulation with the robot control software makes it possible to to interpret the real program code and generate the exact motion. The exact motion of the robot is needed in order to find not just an optimal but also a collision-free policy.",https://ieeexplore.ieee.org/document/9027783/,2019 Second International Conference on Artificial Intelligence for Industries (AI4I),25-27 Sept. 2019,ieeexplore
10.1109/IROS45743.2020.9340948,Reinforcement co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware,IEEE,Conferences,"Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep rein-forcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other's limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel's Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",https://ieeexplore.ieee.org/document/9340948/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1109/ICMA.2005.1626784,Reinforcement learning based group navigation approach for multiple autonomous robotic system,IEEE,Conferences,"In several complex applications, the use of multiple autonomous robotic systems (ARS) becomes necessary to achieve different tasks such as foraging and transport of heavy and large objects with less cost and more efficiency. They have to achieve a high level of flexibility, adaptability and efficiency in real environments. In this paper, a reinforcement learning (RL) based group navigation approach for multiple ARS is suggested. Indeed, the robots must have the ability to form geometric figures and navigate without collisions while maintaining the formation. Thus, each robot must learn how to take its place in the formation and avoid obstacles and other ARS from its interaction with the environment. This approach must provide ARS with capability to acquire the group navigation approach among several ARS from elementary behaviors by learning with trial and error search. Then, simulation results display the ability of the suggested approach to provide ARS with capability to navigate in a group formation in dynamic environments.",https://ieeexplore.ieee.org/document/1626784/,"IEEE International Conference Mechatronics and Automation, 2005",29 July-1 Aug. 2005,ieeexplore
10.1049/cp.2012.1301,Relevance Vector Machine based multi-feature integration for semantic place recogntion,IET,Conferences,"In order to work in realistic scenarios, it is a desirable feature for autonomous robots to extract semantic concepts from environments. In this paper, A Relevance Vector Machine (RVM) based approach is presented for the task of visual semantic place recognition. The high sparsity and Bayesian property makes this approach capable of obtaining probabilistic confidence estimation, and computationally efficient during the online prediction stage. Meanwhile, in order to take advantage of discriminative powers of different feature descriptors, a multiple kernel technique is introduced in our system, resulting in a very flexible model where arbitrary feature descriptors can be integrated smoothly. In this paper we choose three popular descriptors for our implementation. Experiments carried out on real typical office environment datasets show the feasibility and robustness of our approach.",https://ieeexplore.ieee.org/document/6492908/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/DIS.2006.63,Remote Programming of Multirobot Systems within the UPC-UJI Telelaboratories: System Architecture and Agent-Based Multirobot Control,IEEE,Conferences,"One of the areas that needs more improvement within the e-learning environments via Internet (in fact they suppose a very big effort to be accomplished) is allowing students to access and practice real experiments is a real laboratory, instead of using simulations in Marin, R. et al. (2003). Real laboratories allow students to acquire methods, skills and experience related to real equipment, in a manner that is very close to the way they are being used in industry. The purpose of the project is the study, development and implementation of an e-learning environment to allow undergraduate students to practice subjects related to Robotics and Artificial Intelligence. The system, which is now at a preliminary stage, will allow the remote experimentation with real robotic devices (i.e. robots, cameras, etc.). It will enable the student to learn in a collaborative manner (remote participation with other students) where it will be possible to combine the on-site activities (performed ""in-situ"" within the real lab during the normal practical sessions), with the ""online"" one (performed remotely from home via the Internet). Moreover, the remote experiments within the e-laboratory to control the real robots can be performed by both, students and even scientist. This project is under development and it is carried out jointly by two Universities (UPC and UJI). In this article we present the system architecture and the way students and researchers have been able to perform a remote programming of multirobot systems via Web",https://ieeexplore.ieee.org/document/1633445/,IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence and Its Applications (DIS'06),15-16 June 2006,ieeexplore
10.1109/ICMA.2019.8816557,Research on V-SLAM Methods,IEEE,Conferences,"With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.",https://ieeexplore.ieee.org/document/8816557/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICIME.2010.5477962,Research on the embedded system of facial expression recognition based on HMM,IEEE,Conferences,"With the rapid development of artificial intelligence, how to make robots have feelings has become a research highlight today. A portable device for facial expression recognition has been designed, based on the hardware platform of Intel embedded processor PXA270, and the software platform of embedded operation system Linux. The functions of video capture, image processing and face tracking have been achieved, through the application of the USB, Video4Linux programming technology, image processing technology, and artificial psychology theory. At the same time, an emotion model more consistent with the characteristics of human emotions is proposed under the theoretical framework of HMM according to the characteristics of human emotions. A new real-time facial expression recognition method is proposed based on the face detection and facial feature detection technology. Experimental results show that, the effect of face recognition is satisfactory, and the method is effective.",https://ieeexplore.ieee.org/document/5477962/,2010 2nd IEEE International Conference on Information Management and Engineering,16-18 April 2010,ieeexplore
10.1109/ICRA40945.2020.9197386,Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies For Deployment in Unknown Environments,IEEE,Conferences,"In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRRN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world. The code and training environment for this project is made publicly available at https://sites.google.com/view/srrn/home.",https://ieeexplore.ieee.org/document/9197386/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ACII.2013.88,Reversal Learning Based on Somatic Markers,IEEE,Conferences,"One of the main aspects in the field of Artificial Intelligence is the creation of agents with the ability to learn like human beings do. Based on made experiences humans are able to adapt their behaviour in order to solve tasks. Another important aspect of human decision making is the ability to discard learned behaviour when the usual decisions, concerning a stimulus, lead to a bad outcome. For robots intended to be embedded in a social environment, the adaptability of behaviour is an important factor. Research of human decision behaviour shows, that emotions play a decisive role, even for learning and reversal learning. In this paper, improvements and further results of a previously presented framework for decision making based on an emotional memory are presented. The improvements include the reduction of the amount of previous knowledge that has to be implemented and an evaluation concerning reversal learning. For evaluation purposes, a typical reversal learning task, performed by real subjects, has been used. The results show that this framework allows the adaption of behaviour comparable to human subjects and offers decisive improvements, which lead to better results in reversal learning tasks without the need to directly declare a task as such one.",https://ieeexplore.ieee.org/document/6681479/,2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,2-5 Sept. 2013,ieeexplore
10.1109/AIM.2019.8868670,Rhino: An Open-source Embedded Motherboard Design Enabling Complex Behavior of Intelligent Robots,IEEE,Conferences,"In recent years, Robot Operating System (ROS) has become a de facto standard for many robotic systems. However, there lacks a general-purpose control hardware to perfectly support ROS applications in an embedded fashion. In this paper, we take a hardware/software co-design methodology and a loosely coupled design methodology to develop a ROSoriented motherboard dedicatedly for facilitating high-end intelligent robotic applications. First, orienting around the ROS computational graph level, the hardware/software co-design is proposed to realize a mirrored modular design paradigm. Second, an open-source ROS motherboard, namely the ""Rhino"", is accordingly designed with the highlight of accelerating the embedded neuromorphic computation. Third, real-time performance and feasibility of Rhino are validated at different scales. Experimentation shows that the open-source prototype motherboard is eligible for ROS-based robot development and outperforms the conventional IPC and tailor-made control board. ROS-oriented hardware/software codesign paradigm complements the ROS ecosystem with an open-source AI-enabled motherboard for developing intelligent robots.",https://ieeexplore.ieee.org/document/8868670/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/ICRA.2015.7139395,RoboSherlock: Unstructured information processing for robot perception,IEEE,Conferences,"We present RoboSherlock, an open source software framework for implementing perception systems for robots performing human-scale everyday manipulation tasks. In RoboSherlock, perception and interpretation of realistic scenes is formulated as an unstructured information management (UIM) problem. The application of the UIM principle supports the implementation of perception systems that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate the potential of the proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of RoboSherlock.",https://ieeexplore.ieee.org/document/7139395/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/∼cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBOT.2000.845355,Robot improv: using drama to create believable agents,IEEE,Conferences,"Believable agents usually depend upon explicit, model-based simulations of human emotions. This work appeals instead to the sensibilities of dramatic acting to create agents that are believable. The chosen task is that of comedy improvisation as it provides a solid demonstration of the agents' believability in the context of a high-level deliberative goal. Furthermore, this work employs physical robots as the actors, employing the real-time sensor values from the robots as inputs into the acting process. This paper describes the dramatic approach to acting that we used and describes the Java-based implementation on two Nomad Scout robots. Actual, improvised scripts created by the robots are included and analyzed.",https://ieeexplore.ieee.org/document/845355/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/VRAIS.1993.380761,Robotic graphics: a new approach to force feedback for virtual reality,IEEE,Conferences,"A new conceptual solution is presented for the problem of providing force feedback for virtual reality, concentrating on potential CAD/CAM applications. The essential concept is that force feedback is provided by interactions between the human operator and specialized external (as opposed to worn) robots. This is called ""robotic graphics"" to express the analogy between robots simulating the feel of an object, and graphics displays simulating its appearance. This is illustrated by introducing the derivative concepts of ""robotic shape displays"" and ""roboxels."".&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/380761/,Proceedings of IEEE Virtual Reality Annual International Symposium,18-22 Sept. 1993,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICSMC.1997.635206,Robots as responsible agents,IEEE,Conferences,"The quest for real autonomous robots leads us to discuss the problem about the best possible control architecture enabling that important characteristic. It has been broadly accepted that a hybrid architecture, i.e. putting together both reactive and deliberative paradigms is needed to efficiently execute tasks in realistic dynamic environments. Our proposal, which is being implemented to control a Robuterll mobile platform, involves the use of a two-layers architecture. Using symbolic representation for knowledge and goals at the deliberative level and sub-symbolic neural networks for implementing the behaviors at the reactive level. One of the main problems we are now addressing is how to make these two levels to communicate, to interact without being completely dependent on each other. The multi-agent system framework gives a flexible strategy for single agents cooperation and enables a set of behaviours to have a certain degree of autonomy. This reactive layer works together with the cognitive control agent where goals and commitments are logically represented through simple modal logic.",https://ieeexplore.ieee.org/document/635206/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/AICAI.2019.8701333,Robust LQR Based ANFIS Control of x-z Inverted Pendulum,IEEE,Conferences,"Inverted pendulum is a highly unstable, nonlinear and an under-actuated system. Its dynamics resembles many real-time systems such as segways, self-balancing robots, vertical take-off and landing aircraft (VTOL) and crane lifting containers etc. These real-time applications demand the need of a robust controller. In literature, many different control strategies have been discussed to stabilize an inverted pendulum, out of them, the most robust being fuzzy control and sliding mode control. The former is difficult to tune and has a problem of rule explosion for multivariable system, whereas the latter has a problem of discontinuity and chattering. To address the issues in fuzzy controller, a novel robust linear quadratic regulator (LQR) based adaptive-network fuzzy inference system (ANFIS) controller is proposed and implemented on the stabilization of x-z inverted pendulum. The proposed controller is able to solve the problem of robustness in the LQR controller as well as the difficulty in tuning along with rule explosion in fuzzy controller. Furthermore, the designed controller is tested for different pendulum masses and the results show that as compared with conventional PID controller, the proposed controller gives better performance in achieving lesser overshoot and settling time along with better robustness properties.",https://ieeexplore.ieee.org/document/8701333/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/SII.2011.6147636,Robust localization system using online / offline hybrid learning,IEEE,Conferences,"In this paper, we propose an online motion model parameter estimation method. To achieve accurate localization, accurate estimation of motion model parameters is needed. However, the true values of motion model parameters change sequentially according to alteration of surrounding environments. Therefore the online estimation is absolutely imperative. As a typical method to estimate motion model parameters sequentially, Augmented Kalman Filter (AKF) is there. AKF achieves parameter estimation through Kalman filtering algorithm. However, AKF has serious problems to be implemented in real robot operation. These problems are the accuracy of observation and the limitation to motion control of robots. To solve these problems and achieve accurate motion model parameter estimation, proposed method introduces discriminative training. The introduction of discriminative training increases the convergence performance and stability of parameter estimation through AKF. The proposal method achieves accurate motion model parameter estimation in real robot operation. This paper describes the efficiency of our technique through simulations and an outdoor experiment.",https://ieeexplore.ieee.org/document/6147636/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/IROS.2017.8206604,Robust real-time visual tracking using dual-frame deep comparison network integrated with correlation filters,IEEE,Conferences,"In recent years, applications of visual tracking algorithms has seen a substantial growth with deployments in intelligent robots such as drones for human tracking. The algorithms for such tasks has to be efficient in terms of computational cost while been robust, accurate and fast. Object tracking algorithms based on handcrafted heuristics and constraints are widely used in uav applications. The handcrafted heuristics are mostly implemented for task-oriented applications which limits the extensions in uav's capability beyond the predefined functions. This paper considers the challenges of tracking and landing an autonomous uav on a speed high moving target, and presents a visual tracking algorithm that integrates correlation filters with deep comparison network for real-time tracking with state-of-the-art accuracy. The method first tracks the target upto translation using an online learnt model via local search technique. The changes in scale is estimated by a deep comparison network (DCN) instead of the commonly used pyramidal approach. In a single network evaluation, DCN can estimate the changes in scale as well as compensate the drifting of the tracker by refining the object region estimated by the correlation filters. The network is end-to-end trained which attempts to learn a powerful matching function for object localization using a known template. Generally, the integrated framework can be viewed as coarse-to-fine level motion estimation. Moreover, the framework can redetect the lost target without a need for a separate detector.",https://ieeexplore.ieee.org/document/8206604/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/SNPD.2013.86,RvGIST: A Holistic Road Feature for Real-Time Road-Scene Understanding,IEEE,Conferences,"Image-based road scene understanding is a critical issue for intelligent vehicles and autonomous mobile robots. It is challenging to deal with varying road conditions in a dynamic environment in real time. This paper presents an effective while simple approach to classify road types and locate the road-related elements through the analysis of a holistic visual road feature. The feature is abstracted from responses of Gabor-filter-set and grouped into super-pixel grids, consisting of road-scene textural context and dominant orientation distribution. From this feature we successively deduce the information of horizon line, road type and coarse locations of road surface, lanes, on-road obstacles and off-road regions. Experiments show that the proposed analyzing method based on the new holistic feature is beneficial to road estimation and vehicle detection in complex road scenes, achieving improvements in both accuracy and efficiency.",https://ieeexplore.ieee.org/document/6598534/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore
10.1109/DSN.2019.00027,SOTER: A Runtime Assurance Framework for Programming Safe Robotics Systems,IEEE,Conferences,"The recent drive towards achieving greater autonomy and intelligence in robotics has led to high levels of complexity. Autonomous robots increasingly depend on third-party off-the-shelf components and complex machine-learning techniques. This trend makes it challenging to provide strong design-time certification of correct operation. To address these challenges, we present SOTER, a robotics programming framework with two key components: (1) a programming language for implementing and testing high-level reactive robotics software, and (2) an integrated runtime assurance (RTA) system that helps enable the use of uncertified components, while still providing safety guarantees. SOTER provides language primitives to declaratively construct a RTA module consisting of an advanced, high-performance controller (uncertified), a safe, lower-performance controller (certified), and the desired safety specification. The framework provides a formal guarantee that a well-formed RTA module always satisfies the safety specification, without completely sacrificing performance by using higher performance uncertified components whenever safe. SOTER allows the complex robotics software stack to be constructed as a composition of RTA modules, where each uncertified component is protected using a RTA module. To demonstrate the efficacy of our framework, we consider a real-world case-study of building a safe drone surveillance system. Our experiments both in simulation and on actual drones show that the SOTER-enabled RTA ensures the safety of the system, including when untrusted third-party components have bugs or deviate from the desired behavior.",https://ieeexplore.ieee.org/document/8809550/,2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),24-27 June 2019,ieeexplore
10.1109/SSRR.2019.8848957,Sample Efficient Reinforcement Learning for Navigation in Complex Environments,IEEE,Conferences,"Navigation of mobile robots in unstructured, time-varying environments is challenging. It becomes even more complicated in disaster scenarios where logistical difficulties, as well as technical issues such as reactive and time-varying obstacles, exist. These scenarios are too complex for classical obstacle avoidance methods to navigate through successfully. This paper presents a sample efficient reinforcement learning algorithm for navigation in complex environments. The approach augments training data with randomly generated target location data to accelerate learning. A Q-learning approach is implemented, which is capable of quick training with limited episodes. The procedure is tested in four scenarios in Gazebo and one scenario in a real-world experiment. In the two simulation scenarios with no obstacles, the method can learn to navigate towards the target in fewer than 200 episodes. For environments with moving obstacles, training takes slightly longer, but the process is still able to learn an effective policy quickly.",https://ieeexplore.ieee.org/document/8848957/,"2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)",2-4 Sept. 2019,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/URAI.2016.7734049,Secure robotics,IEEE,Conferences,"Security is an under-studied problem within robotics and Internet of Things. Part of the reason for this is that currently most robots and IoT devices remain in the lab at all times. Recent trends show more robots and IoT devices moving “out into the wild” with no humans to protect them. This creates vulnerabilities beyond the well known and well studied network/internet based threat. These threats include external network, local network, software, physical access, tricking the artificial intelligence, and intellectual property theft. This document discribes the above and shows our current work towards detection and mitigation.",https://ieeexplore.ieee.org/document/7734049/,2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),19-22 Aug. 2016,ieeexplore
10.1109/CCIOT45285.2018.9032441,Segmental Deployment of Neural Network in Cloud Robotic System,IEEE,Conferences,"In this paper, we describe a new method for ep neural networks in the field of computer vision, which can effectively solve the difficulty of applying deep learning in the cloud robotic system. By segmenting the trained network, most of the computing tasks can be cut out and offloaded to the cloud. By effective feature extraction and compression methods, the computing power of robot and cloud can be integrated and coordinated. A method of selecting the split points of the network model and a method of data transmission and compression in the communication between robots and cloud after segmenting are given based on the characteristics of machine vision tasks, and the theoretical analysis is carried out. In the experiment, the effectiveness of all the above methods is verified by comparing the compression capability, response time and network performance of the actual network model. The experimental results show that with the use of segmental methods in cloud robotic system, the task of deep network is processed in real time, while the performance is almost guaranteed.",https://ieeexplore.ieee.org/document/9032441/,2018 IEEE 3rd International Conference on Cloud Computing and Internet of Things (CCIOT),20-21 Oct. 2018,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/FUZZY.1997.616432,Selecting behaviors using fuzzy logic,IEEE,Conferences,"Behavior-based systems, i.e. systems that use behaviors as a way of decomposing the control policy needed for accomplishing a task, are very useful in making robots cope with the dynamics of real-world environments. However, these systems still need to be extended to design robots having multiple and possibly conflicting goals, requiring planning, and getting more out of their behaviors. One way of doing that is to allow behaviors to be selected dynamically and to blend their actions in order to get more complex behaviors. This paper addresses these issues by presenting a control architecture that, when using fuzzy logic, allows behaviors to be efficiently selected by different sources. A simulated world for mobile robots is used to illustrate these ideas.",https://ieeexplore.ieee.org/document/616432/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/ROMAN.2008.4600739,Semantic category acquisition in dialogue for interactive object learning,IEEE,Conferences,"An important aspect of humanoid robots in a natural environment is the ability to acquire new knowledge through learning mechanisms, which enhances an artificial system with the ability to adapt to a changing or new environment. In contrast to most learning algorithms applied in machine learning today, which mainly work with offline learning on training samples, such learning mechanisms need to be performed autonomously and through interaction with the environment or with other agents/humans. In this paper we describe a learning algorithm as a dialogue approach for learning semantic categories and object description in object learning. New objects are introduced to the robot and learning dialogues are conducted as a means of information acquisition. In dialogue, the robot can acquire semantic categories, type and properties of objects, learn new words for object descriptions and learn and association to visual identification from object recognition. In contrast to existing work, this approach combines recognition of real objects, new words learning and semantic categories in one learning dialogue. The presented approach has been implemented in a dialogue system and evaluated on the humanoid robot Armar III.",https://ieeexplore.ieee.org/document/4600739/,RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,1-3 Aug. 2008,ieeexplore
10.1109/ICUAS48674.2020.9214063,Semantic situation awareness of ellipse shapes via deep learning for multirotor aerial robots with a 2D LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots equipped with a 2D LIDAR sensor, focusing on the understanding of the environment, provided to have a drift-free precise localization of the robot (e.g. given by GNSS/INS or motion capture system). Our algorithm generates in real-time a semantic map of the objects of the environment as a list of ellipses represented by their radii, and their pose and velocity, both in world coordinates. Two different Convolutional Neural Network (CNN) architectures are proposed and trained using an artificially generated dataset and a custom loss function, to detect ellipses in a segmented (i.e. with one single object) LIDAR measurement. In cascade, a specifically designed indirect-EKF estimates the ellipses based semantic map in world coordinates, as well as their velocity. We have quantitative and qualitatively evaluated the performance of our proposed situation awareness system. Two sets of Software-In-The-Loop simulations using CoppeliaSim with one and multiple static and moving cylindrical objects are used to evaluate the accuracy and performance of our algorithm. In addition, we have demonstrated the robustness of our proposed algorithm when handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) objects and moving persons.",https://ieeexplore.ieee.org/document/9214063/,2020 International Conference on Unmanned Aircraft Systems (ICUAS),1-4 Sept. 2020,ieeexplore
10.1109/CVPR.2019.01165,Sim-Real Joint Reinforcement Transfer for 3D Indoor Navigation,IEEE,Conferences,"There has been an increasing interest in 3D indoor navigation, where a robot in an environment moves to a target according to an instruction. To deploy a robot for navigation in the physical world, lots of training data is required to learn an effective policy. It is quite labour intensive to obtain sufficient real environment data for training robots while synthetic data is much easier to construct by render-ing. Though it is promising to utilize the synthetic environments to facilitate navigation training in the real world, real environment are heterogeneous from synthetic environment in two aspects. First, the visual representation of the two environments have significant variances. Second, the houseplans of these two environments are quite different. There-fore two types of information,i.e. visual representation and policy behavior, need to be adapted in the reinforce mentmodel. The learning procedure of visual representation and that of policy behavior are presumably reciprocal. We pro-pose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy. Specifically, our method employs an adversarial feature adaptation model for visual representation transfer anda policy mimic strategy for policy behavior imitation. Experiment shows that our method outperforms the baseline by 19.47% without any additional human annotations.",https://ieeexplore.ieee.org/document/8953924/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/IJCNN.2000.859462,"Simulating the evolution of 2D pattern recognition on the CAM-Brain Machine, an evolvable hardware tool for building a 75 million neuron artificial brain",IEEE,Conferences,"This paper presents some simulation results of the evolution of 2D visual pattern recognizers to be implemented very shortly on real hardware, namely the ""CAM-Brain Machine"" (CBM), an FPGA based piece of evolvable hardware which implements a genetic algorithm (GA) to evolve a 3D cellular automata (CA) based neural network circuit module, of approximately 1,000 neurons, in about a second, i.e. a complete run of a GA, with tens of thousands of circuit growths and performance evaluations. Up to 65,000 of these modules, each of which is evolved with a humanly specified function, can be downloaded into a large RAM space, and interconnected according to humanly specified artificial brain architectures. This RAM, containing an artificial brain with up to 75 million neurons, is then updated by the CBM at a rate of 130 billion CA cells per second. Such speeds will enable real time control of robots and hopefully the birth of a new research field that we call ""brain building"". The first such artificial brain, to be built at STARLAB in 2000 and beyond, will be used to control the behaviors of a life sized kitten robot called ""Robokitty"". This kitten robot will need 2D pattern recognizers in the visual section of its artificial brain. This paper presents simulation results on the evolvability and generalization properties of such recognizers.",https://ieeexplore.ieee.org/document/859462/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/CCDC.2008.4597309,Simulation of robot localization based on virtual sensors,IEEE,Conferences,"A flexible simulation frame based on concept of component is presented. An indoor robots localization simulation environment based on virtual sensors RoboSimer is built with OpenGL. The parameters here are easily adjusted and controlled by customs and the simulation module is easy to integrate. It can integrate any sensors, environment and robot shape into the simulation software. The interfaces of simulation software are coincided with the real hardware platform. It provides a convenient condition for the further study on robot localization.",https://ieeexplore.ieee.org/document/4597309/,2008 Chinese Control and Decision Conference,2-4 July 2008,ieeexplore
10.1109/IROS.2018.8593518,Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization,IEEE,Conferences,"Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.",https://ieeexplore.ieee.org/document/8593518/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICHR.2010.5686285,SkyAI: Highly modularized reinforcement learning library,IEEE,Conferences,"This paper introduces a software library of reinforcement learning (RL) methods, named SkyAI. SkyAI is a highly modularized RL library for real/simulated robots to learn behaviors. Our ultimate goal is to develop an artificial intelligence (AI) program with which the robots can learn to behave as their users' wish. In this paper, we describe the concepts, the requirements, and the current implementation of SkyAI. SkyAI provides two conflicting features: high execution-speed enough for real robot systems and high flexibility to design learning systems. We also demonstrate the applications to crawling tasks of both a humanoid robot in simulation and a real spider robot.",https://ieeexplore.ieee.org/document/5686285/,2010 10th IEEE-RAS International Conference on Humanoid Robots,6-8 Dec. 2010,ieeexplore
10.1109/BigComp51126.2021.00051,Smart Energy Management System based on Reconfigurable AI Chip and Electrical Vehicles,IEEE,Conferences,"Almost every larger city in Europe has ambitious smart city projects. This is particularly true for Hamburg, a Hanseatic city in the north of Germany. Hamburg is the smartest city in Germany according to a Federal Association for Information Technology. Although there are no megacities in the European Union (the largest city in the European Union is Berlin with 3.7 million inhabitants), the increasing urbanization is apparent and produces problems to be solved. At the same time rural depopulation creates conjugated problems.One category of these problems is mobility. Mobility can be regarded as the need to move persons and freight. In densely populated cities an increasing amount of transport users have to share a decreasing amount of space with conflicting needs. At the same time in rural areas, a dwindling supply of local public transport makes the mobility of the remaining residents more difficult. The same applies to parcel delivery or the supply of goods. Autonomous systems have great potential to create a sustainable and livable environment. The author has initiated a publicly funded project to investigate technologies of autonomous mobile systems which interact with a smart city. The test area intelligent urban mobility (Testfeld intelligente Quartiersmobilitat) at the campus of Hamburgs University of Applied Sciences is created to do research on connected and autonomous mobile systems like multipurpose robots and other mobility users like pedestrians with a smartphone. A particular focus is on neighborhood mobility. This means that distances of less than 3 kilometers usually have to be covered. The special type of needs in neighborhood mobility has two important aspects that affect development of autonomous mobile systems: It is slow mobility and the transport users are especially vulnerable. The acceptance of the residents of autonomous systems is equally important, as is the protection of privacy when collecting environmental data. They are expected to make decisions on their own in complex environments. The real world usually differs from a simulation or an experimental setup in a laboratory - a problem commonly referred to as Sim-2-Real gap. Active and non-destructive exploration is expected from an autonomous system to solve unexpected problems. Machine learning methods come into play which in turn have their own pitfalls. The author has built a specialized laboratory to investigate machine learning technology applied to autonomous systems. In this laboratory miniature autonomous vehicles are developed. The general idea of this experimental setup allows research on new methodologies for autonomous systems in a very small scale",https://ieeexplore.ieee.org/document/9373129/,2021 IEEE International Conference on Big Data and Smart Computing (BigComp),17-20 Jan. 2021,ieeexplore
10.1109/ICRA40945.2020.9197523,SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference,IEEE,Conferences,"Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&amp;R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.",https://ieeexplore.ieee.org/document/9197523/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA.2018.8460968,Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning,IEEE,Conferences,"We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.",https://ieeexplore.ieee.org/document/8460968/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/IROS45743.2020.9341328,Software Development Framework for Cooperating Robots with High-level Mission Specification,IEEE,Conferences,"In recent years, there has been a growing interest in multiple robots performing a single task through different types of collaboration. There are two software challenges when deploying collaborative robots: how to specify a cooperative mission and how to program each robot to accomplish its mission. In this paper, we propose a novel software development framework to support distributed robot systems, swarm robots, and their hybrid. We extend the service-oriented and model-based (SeMo) framework [1] to improve the robustness, scalability, and flexibility of robot collaboration. To enable a casual user to specify various types of cooperative missions easily, the high-level mission scripting language is extended with new features such as team hierarchy, group service, one-to-many communication. The script program is refined to the robot codes through two intermediate steps, strategy description and task graph generation, in the proposed framework. The viability of the proposed framework is evidenced by two preliminary experiments using real robots and a robot simulator.",https://ieeexplore.ieee.org/document/9341328/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/IROS.1996.570655,Specification and validation of a control architecture for autonomous mobile robots,IEEE,Conferences,"We describe the specification of a software control architecture for autonomous mobile robots. The architecture, designed to provide the robot (in a task-dependent context) with the capacity to react to events but also to intelligently anticipate the future and plan its actions, is based on the decomposition of the robot system into a functional and a decisional level. The article is mainly focused on some aspects of the organisation and of the operation of the system such as execution control, inter-levels communication, reactivity. An important aspect that is developed is the possibility to prove some temporal and logical properties of parts of the system.",https://ieeexplore.ieee.org/document/570655/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/CISIM.2008.21,Strategy Description and Modelling for Multi-Agent Systems,IEEE,Conferences,"The field of robot soccer provides numerous opportunities for the application of AI methods for game strategy development. Robot soccer is a part of standard applications of distributed system control in real time. The software part of a distributed control system is realized by decision making and executive agents. The algorithm of agents' cooperation was proposed with the control agent on a higher level. The algorithms for agents realized in robots are the same. Real-time dynamic simple strategy description and strategy learning possibility based on game observation is important for discovering opponent's strategies and searching for tactical group movements, simulation and synthesis of suitable counter-strategies. For the improvement of game strategy, we are developing an abstract description of the game and propose ways to use this description (e.g. for learning rules and adapting team strategies to every single opponent).",https://ieeexplore.ieee.org/document/4557834/,2008 7th Computer Information Systems and Industrial Management Applications,26-28 June 2008,ieeexplore
10.1109/UKSIM.2008.117,Strategy Description and Modelling for Multi-agent Systems (Invited Paper),IEEE,Conferences,"The field of robot soccer provides numerous opportunities for the application of AI methods for game strategy development. Robot soccer is a part of standard applications of distributed system control in real time. The software part of a distributed control system is realized by decision making and executive agents. The algorithm of agents’ cooperation was proposed with the control agent on a higher level. The algorithms for agents realized in robots are the same. Real-time dynamic simple strategy description and strategy learning possibility based on game observation is important for discovering opponents strategies and searching for tactical group movements, simulation and synthesis of suitable counter-strategies. For the improvement of game strategy, we are developing an abstract description of the game and propose ways to use this description (e.g. for learning rules and adapting team strategies to every single opponent).",https://ieeexplore.ieee.org/document/4489006/,Tenth International Conference on Computer Modeling and Simulation (uksim 2008),1-3 April 2008,ieeexplore
10.1109/SACI.2016.7507375,Superior vision: Always on human-like vision for intelligent devices,IEEE,Conferences,"Summary form only given. We live in a world of intelligent robots, drones and mobile phones/assistants. The technologies behind these products are heralded by a new wave of deep learning applications ported on mobile devices. The robotic and vision technologies behind these products will shift the applications of electronic devices to a more superior level of intelligence that will change our world. From a hardware point of view, these devices will become a hub of learning sensors that will be able to capture and learn from their surrounding environment and their context. On top of the aforementioned deep learning technologies, the most important sense for these devices will be their vision capabilities. To make this sense as close as possible to human vision, will require advanced technology to capture, process, understand and provide analytics in real time to enable their applications make critical “educated: decisions”. “Always on” vision capabilities are envisaged as the paradigm for the next generation of mobile This Keynote will cover in this context the state of the art in the domain of vision with the latest image processing, computer vision and deep learning algorithms implemented on various low-power processing architectures.",https://ieeexplore.ieee.org/document/7507375/,2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI),12-14 May 2016,ieeexplore
10.1109/IIAI-AAI.2014.4,Table of contents,IEEE,Conferences,The following topics are dealt with: data mining; Japanese WordNet synonym misplacement detection; social network; recommender system; sentiment analysis; workshop-based instruction; Japanese public libraries; machine learning methods; collaborative Web presentation support system; SMS4 ultracompact hardware implementation; wireless sensor networks; personalized public transportation recommendation system; adaptive user interface; NIS-Apriori algorithm; GetRNIA software tool; rough set-based rule generation; tree-Ga bump hunting; neural network model; weighted citation network analysis; sound proofing ventilation unit; touch interaction; mutually dependent Markov decision processes; ozone treatment; dynamic query optimization; big data; learner activity recognition; IoT-security approach; nutrition-based vegetable production; farm product cultivation; polynomial time mat learning; C-deterministic regular formal graph system; article abstract key expression extraction; English text comprehension; online social games; knowledge creation; knowledge utilization; online stock trading; customer behavior analysis; project-based collaborative learning; in-field mobile game-based learning activities; e-portfolio system design; self-regulated learning ontological model; mobile augmented reality based scaffolding platform; context-aware mobile Japanese conversation learning system; English writing error classification; image processing; outside-class learning; exercise-centric teaching materials; UML modeling; online historical document reading literacy; MMORPG-based learning environment; computer courses; undergraduate education; energy management system; higher education; decentralised auction-based bandwidth allocation; wireless networked control systems; resource scheduling algorithm; embedded cloud computing; Poisson distribution; Japanese seismic activity; suspect vehicle detection; 3D network traffic visualization; Web information retrieval; agent based disaster evacuation assist system; electroencephalogram; random number generator; multiagent simulations; multicore environment; CPU scheduler; multithreaded processes; reserve-price biddings; real-time traffic signal control; evolutionary computation; robot-assisted rehabilitation system; hybrid automata; Batik motif classification; color-texture-based feature extraction; backpropagation; multimedia storytelling; e-tourism service; Web mining; search engine; simulation-based e-learning mobile application software; library classification training system; WebQuest learning strategy; context-aware ubiquitous English learning; support vector machine; RFID tag ownership transfer protocol; cognitive linguistics; collaborative software engineering learning; write-access reduction method; NVM-DRAM hybrid memory; garbage collection; parallel indexing scheme; lazy-updating snoop cache protocol; distributed storage system; ITS application; software engineering education; ophthalmic multimodal imaging system; injected bug classification; secure live virtual machine migration; flash memory management; genetic programming; heterogeneous databases; time series similarity search; concurrency control program generation; incremental data migration; multidatabase system; software release time decision making; analytic hierarchy process; interactive genetic algorithm; biometric intelligence; talking robots; archaeological ruin analysis; GIS; optical wireless pedestrian-support systems; visual impairment; extreme programming; Japanese e-commerce Web sites; Chinese sign language animation; hearing-impaired people mammography inspection; geographical maps; electroculogram; XML element retrieval technique; image recognition; reinforcement learning; ECU formal verification; gasoline direct injection engines; earthquake disaster simulation; smart devices for autistic children; RoboCup rescue simulation; inductive logic programming; master-slave asynchronous evolutionary hybrid algorithm; VANET routing optimization; and Web image sharing services.,https://ieeexplore.ieee.org/document/6913248/,2014 IIAI 3rd International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2014,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/SNPDWinter52325.2021.00048,Technology-driven Service Innovation in University Libraries,IEEE,Conferences,"Libraries are building a digital environment and preparing for the post-corona era. They attempt to increase operational efficiency and competitiveness by applying new technologies and strive to build a more intelligent and user-friendly environment using big data, the Internet of things (IoT), artificial intelligence (AI), virtual reality (VR), 3D printing, and automated robots. This study aims to present the direction for future university libraries by analyzing technology-based service innovation cases in line with the current era, centering on university libraries.",https://ieeexplore.ieee.org/document/9403519/,"2021 21st ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)",28-30 Jan. 2021,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICISCAE48440.2019.221655,The Construction of Portrait Identification Tracking System Based on Mask R-CNN,IEEE,Conferences,"A portrait identification and tracking system with strong real-time performance, good flexibility and controllable cost is designed and implemented in the paper. Firstly, Mask R-CNN neural network is used to extract the features of the target, and the COCO dataset is used to train and establish the portrait data model. As a result, accuracy of the portrait recognition is improved. Then, a portrait tracking system including monocular camera, data acquisition module, data processing module, steering gear and control system is built. And the ""Raspberry Pi"" control method is used to control the MG955 steering gear group. Finally, the recognition and tracking of characters can be realized through wired, WIFI, Bluetooth and other ways, which improves the universality of the system. The designed system has simple structure, complete functions and can be used for automatic aiming and tracking of other objects. The modular system can also be used for unmanned aerial vehicles, robots and other platforms.",https://ieeexplore.ieee.org/document/9075573/,2019 2nd International Conference on Information Systems and Computer Aided Education (ICISCAE),28-30 Sept. 2019,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/ROBOT.2004.1308800,The artificial ecosystem: a distributed approach to service robotics,IEEE,Conferences,"We propose a multiagent, distributed approach to autonomous mobile robotics which is an alternative to most existing systems in literature: robots are thought of as mobile units within an intelligent environment where they coexist and co-operate with fixed, intelligent devices that are assigned different roles: helping the robot to localize itself, controlling automated doors and elevators, detecting emergency situations, etc. To achieve this, intelligent sensors and actuators (i.e. physical agents) are distributed both onboard the robot and throughout the environment, and they are handled by Real-Time software agents which exchange information on a distributed message board. The paper outlines the benefits of the approach in terms of efficiency and Real-Time responsiveness.",https://ieeexplore.ieee.org/document/1308800/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IRI-05.2005.1506505,The behavior evolving model and application of virtual robots,IEEE,Conferences,"We suggest a model that evolves the behavioral knowledge of a virtual robot. The knowledge is represented in classification rules and a neural network, and is learned by a genetic algorithm. The model consists of a virtual robot with behavior knowledge, an environment that it moves in, and an evolution performer that includes a genetic algorithm. We have also applied our model to an environment where the robots gather food into a nest. When comparing our model with the conventional method on various test cases, our model showed superior overall learning.",https://ieeexplore.ieee.org/document/1506505/,"IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.",15-17 Aug. 2005,ieeexplore
10.1109/IROS.2010.5650765,The design of LEO: A 2D bipedal walking robot for online autonomous Reinforcement Learning,IEEE,Conferences,"Real robots demonstrating online Reinforcement Learning (RL) to learn new tasks are hard to find. The specific properties and limitations of real robots have a large impact on their suitability for RL experiments. In this work, we derive the main hardware and software requirements that a RL robot should fulfill, and present our biped robot LEO that was specifically designed to meet these requirements. We verify its aptitude in autonomous walking experiments using a pre-programmed controller. Although there is room for improvement in the design, the robot was able to walk, fall and stand up without human intervention for 8 hours, during which it made over 43; 000 footsteps.",https://ieeexplore.ieee.org/document/5650765/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IVS.1994.639471,The development of a fully autonomous ground vehicle (FAGV),IEEE,Conferences,"As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",https://ieeexplore.ieee.org/document/639471/,Proceedings of the Intelligent Vehicles '94 Symposium,24-26 Oct. 1994,ieeexplore
10.1109/CEC.2002.1004464,The force model: reducing the complexity by reformulating the problem,IEEE,Conferences,"Most experiments in research on autonomous agents and mobile robots are performed either in simulation or on robots with static physical properties; evolvable hardware is hardly ever used. One of the very rare exceptions is the eyebot on which Lichtensteiger and Eggenberger have evolved simplified insect eyes. Even though substantially improved, the evolutionary models currently applied still lack both scalability and noise-resistance. To tackle these problems, this paper proposes a biologically-inspired force model for this class of real-world applications. The simulation results clearly indicate that this model provides a significant improvement over existing limitations. Furthermore, this paper argues that the force model is of more general utility.",https://ieeexplore.ieee.org/document/1004464/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/IROS40897.2019.8968514,Timepix Radiation Detector for Autonomous Radiation Localization and Mapping by Micro Unmanned Vehicles,IEEE,Conferences,"A system for measuring radiation intensity and for radiation mapping by a micro unmanned robot using the Timepix detector is presented in this paper. Timepix detectors are extremely small, but powerful 14 × 14 mm, 256 × 256 px CMOS hybrid pixel detectors, capable of measuring ionizing alpha, beta, gamma radiation, and heaving ions. The detectors, developed at CERN, produce an image free of any digital noise thanks to per-pixel calibration and signal digitization. Traces of individual ionizing particles passing through the sensors can be resolved in the detector images. Particle type and energy estimates can be extracted automatically using machine learning algorithms. This opens unique possibilities in the task of flexible radiation detection by very small unmanned robotic platforms. The detectors are well suited for the use of mobile robots thanks to their small size, lightweight, and minimal power consumption. This sensor is especially appealing for micro aerial vehicles due to their high maneuverability, which can increase the range and resolution of such novel sensory system. We present a ROS-based readout software and real-time image processing pipeline and review options for 3-D localization of radiation sources using pixel detectors. The provided software supports off-the-shelf FITPix, USB Lite readout electronics with Timepix detectors.",https://ieeexplore.ieee.org/document/8968514/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/ROMAN.2002.1045641,Towards grounded human-robot communication,IEEE,Conferences,"Future robots are expected to communicate with humans using natural language. The naive human user will expect a robot to easily understand what he/she is meaning by instructions concerning robot's tasks. This implies that the robot will need to have a means of grounding, in its own sensors, the natural language terms and constructions used by the human user. This paper presents an approach to solve this problem that is based on the integration of a ""learning server"" in the software architecture of the robot. Such server should be capable of on-line, incremental learning from examples; it should handle multiple problems concurrently and it should have meta-learning capabilities. A learning server already developed by the authors is presented. Complementarily, the dimensionality reduction problem is also addressed, using a Blocked DCT approach. Experimental results are obtained in a scenario in which three concepts (corresponding to natural language expressions) are concurrently learned.",https://ieeexplore.ieee.org/document/1045641/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/IJCNN.2017.7966054,Towards real-time robot simulation on uneven terrain using neural networks,IEEE,Conferences,"Simulation is a valuable tool for robotics research and development, and various simulation packages have been proposed. However, we are aware of no freely-available packages which implement the required fidelity to accurately model earth-moving robots that manipulate the terrain itself. The software which does exist for this is difficult if not impossible to run in real-time while achieving the desired accuracy. This paper proposes a simulation system in which a neural network is trained using data generated in a 3D high-fidelity, non-real-time simulator. The resulting neural network is used to accurately predict the motion of a robot in a 2D simulator, while also taking into consideration a height-field representing a 3D terrain. Using a trained neural network to drive the new simulation provides considerable speedup over the high-fidelity 3D simulation, allowing behaviour to be simulated in real-time while still capturing the physics of the agents and the environment.",https://ieeexplore.ieee.org/document/7966054/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/IJCNN.2011.6033258,Towards the grounding of abstract words: A Neural Network model for cognitive robots,IEEE,Conferences,"In this paper, a model based on Artificial Neural Networks (ANNs) extends the symbol grounding mechanism to abstract words for cognitive robots. The aim of this work is to obtain a semantic representation of abstract concepts through the grounding in sensorimotor experiences for a humanoid robotic platform. Simulation experiments have been developed on a software environment for the iCub robot. Words that express general actions with a sensorimotor component are first taught to the simulated robot. During the training stage the robot first learns to perform a set of basic action primitives through the mechanism of direct grounding. Subsequently, the grounding of action primitives, acquired via direct sensorimotor experience, is transferred to higher-order words via linguistic descriptions. The idea is that by combining words grounded in sensorimotor experience the simulated robot can acquire more abstract concepts. The experiments aim to teach the robot the meaning of abstract words by making it experience sensorimotor actions. The iCub humanoid robot will be used for testing experiments on a real robotic architecture.",https://ieeexplore.ieee.org/document/6033258/,The 2011 International Joint Conference on Neural Networks,31 July-5 Aug. 2011,ieeexplore
10.1109/ROMAN.2017.8172430,"Towards the use of consumer-grade electromyographic armbands for interactive, artistic robotics performances",IEEE,Conferences,"In recent years, gesture-based interfaces have been explored in order to control robots in non-traditional ways. These require the use of systems that are able to track human body movements in 3D space. Deploying Mo-cap or camera systems to perform this tracking tend to be costly, intrusive, or require a clear line of sight, making them ill-adapted for artistic performances. In this paper, we explore the use of consumer-grade armbands (Myo armband) which capture orientation information (via an inertial measurement unit) and muscle activity (via electromyography) to ultimately guide a robotic device during live performances. To compensate for the drop in information quality, our approach rely heavily on machine learning and leverage the multimodality of the sensors. In order to speed-up classification, dimensionality reduction was performed automatically via a method based on Random Forests (RF). Online classification results achieved 88% accuracy over nine movements created by a dancer during a live performance, demonstrating the viability of our approach. The nine movements are then grouped into three semantically-meaningful moods by the dancer for the purpose of an artistic performance achieving 94% accuracy in real-time. We believe that our technique opens the door to aesthetically-pleasing sequences of body motions as gestural interface, instead of traditional static arm poses.",https://ieeexplore.ieee.org/document/8172430/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICACR51161.2020.9265509,Transfer of Inter-Robotic Inductive Classifier,IEEE,Conferences,"In multi-robot deployments, the robots need to share and integrate their own experience and perform transfer learning. Under the assumption that the robots have the same morphology and carry equivalent sensory equipment, the problem of transfer learning can be considered incremental learning. Thus, the transfer learning problem inherits the challenges of incremental learning, such as catastrophic forgetting and concept drift. In catastrophic forgetting, the model abruptly forgets the previously learned knowledge during the learning process. The concept drift arises with different experiences between consecutively sampled models. However, state-of-the-art robotic transfer learning approaches do not address both challenges at once. In this paper, we propose to use an incremental classifier on a transfer learning problem. The feasibility of the proposed approach is demonstrated in a real deployment. The robot consistently merges two classifiers learned on two different tasks into a classifier that performs well on both tasks.",https://ieeexplore.ieee.org/document/9265509/,"2020 4th International Conference on Automation, Control and Robots (ICACR)",11-13 Oct. 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956420,Trust Repair in Human-Swarm Teams+,IEEE,Conferences,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",https://ieeexplore.ieee.org/document/8956420/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ASID50160.2020.9271762,Use of LSTM Regression and Rotation Classification to Improve Camera Pose Localization Estimation,IEEE,Conferences,"More accurately estimating camera pose can be used to greatly improve localization in applications such as augmented reality, autonomous driving, and intelligent robots. Deep learning methods have achieved great progress to improve accuracy but still have limitations with respect to rotation, which results in angle regression errors. In this work, we combine a LSTM module with rotation classification loss to regress the camera pose. The algorithm uses a robust processing pipeline to supervise the pose estimation with dynamic, weighted, multi-losses in order to limit separate Euler angle (yaw, pitch, roll) losses, and common translation-quaternion losses. An empirical test on the 7Scenes benchmark dataset shows better results than when using common absolute pose regression methods.",https://ieeexplore.ieee.org/document/9271762/,"2020 IEEE 14th International Conference on Anti-counterfeiting, Security, and Identification (ASID)",30 Oct.-1 Nov. 2020,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/ICEPDS.2018.8571820,Using Robot and Electric Drive in Fall Prediction,IEEE,Conferences,"The global aging phenomenon has motivated active research in human fall injuries. The fall prevention has hence become a popular topic in health informatics. An effective fall prevention paradigm could save millions of people from injury and avoid considerable casualties. Through comparison studies, detail-oriented simulations, and pragmatic field tests, an effective fall prediction method has been developed by authors. The finding is presented in this paper. Three techniques for fall prediction are discussed in this paper. A comparison technique to mimic the traditional stateless fall prediction techniques, along with an algorithm using artificial neural network, was first implemented in authors' previous paper. Then a robotic scheme was developed to simulate human fall by transplanting a proven fall prediction paradigm for humanoid robots with controlled electric drive systems to human subjects. Due to its simulation nature far from the human fall scenarios in reality, the robotic paradigm has obvious limits in real world applications. It was also used more like a reference framework for our last scheme. Eventually we built the third approach that eliminated the above limitation. The third approach is elaborated in this paper. Our test and simulation have proved its pragmatic superiority over other two approaches, along with vast majority of traditional paradigms.",https://ieeexplore.ieee.org/document/8571820/,2018 X International Conference on Electrical Power Drive Systems (ICEPDS),3-6 Oct. 2018,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/AERO.2015.7119180,Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft,IEEE,Conferences,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.",https://ieeexplore.ieee.org/document/7119180/,2015 IEEE Aerospace Conference,7-14 March 2015,ieeexplore
10.1109/SAMI.2016.7422985,Vehicle navigation by fuzzy cognitive maps using sonar and RFID technologies,IEEE,Conferences,"Emerging concept of the so-called intelligent space (IS) offers means for use of mobile autonomous devices like vehicles or robots in a very broad area without necessity for these devices to own all necessary sensors. From this reason also new navigation methods are developing, which utilize IS means, with the aim to offer maybe not so accurate but first of all cheep and reliable solutions for a wide variety of devices. Our paper deals with the examination of possibility to interconnect sparsely deployed RFID tags with sonars. As signals produced by these two technologies are often affected by uncertainty and incompleteness we use fuzzy logic for their processing as well as control of the entire navigation process. For this purpose a special type of a fuzzy cognitive map was proposed. The paper describes real navigation experiments with a simple vehicle and evaluates them by selected criteria. Based on obtained results their explanations and conclusions for potential future research are sketched.",https://ieeexplore.ieee.org/document/7422985/,2016 IEEE 14th International Symposium on Applied Machine Intelligence and Informatics (SAMI),21-23 Jan. 2016,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/ITST.2017.7972192,Virtual assistants and self-driving cars,IEEE,Conferences,"Self-driving cars are technologically a reality and in the next decade they are expected to reach the highest level of automation. While there is general agreement that an advanced human-autonomous vehicle (HAV) interaction is key to achieve the benefits of self-driving cars, it is less clear what role artificial intelligence (AI) should play in this context. While the scientific community is debating on the role and intersections of AI, autonomous vehicles and related issues, above all ethics, the automotive industry is already presenting AI-based products and services that may influence, in a direction or in another, our technological and societal futures. This paper focuses on virtual assistants, the personification of the car intelligence incorporating, among others, an algorithmic “brain”, a synthetic human “voice” and powerful sensor-based “senses”. Should virtual assistants just assist humans or replace them whenever necessary? Should their scope of action be limited to safety-related driving tasks or to any activity performed in the car or controlled from the car? Although at a very early stage of commercial development, the paper will review the state-of-the-art of in-car virtual assistants underlining their role and functions in the connected and automated driving ecosystem. By drawing from earlier reflections on automation, robots and intelligent agents, it will then identify a series of issues to be addressed by the scientific community, policy-makers and the automotive industry stakeholders.",https://ieeexplore.ieee.org/document/7972192/,2017 15th International Conference on ITS Telecommunications (ITST),29-31 May 2017,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/OCEANS.1995.528724,Virtual world visualization for an autonomous underwater vehicle,IEEE,Conferences,"A critical bottleneck exists in autonomous underwater vehicle (AUV) design and development. It is tremendously difficult to observe, communicate with and test underwater robots, because they operate in a remote and hazardous environment where physical dynamics and sensing modalities are counterintuitive. An underwater virtual world can comprehensively model all necessary functional characteristics of the real world in real time. This virtual world is designed from the perspective of the robot, enabling realistic AUV evaluation and testing in the laboratory. 3D real-time graphics are our window into the virtual world, enabling multiple observers to visualize complex interactions. A networked architecture enables multiple world components to operate collectively in real time, and also permits world-wide observation and collaboration with other scientists interested in the robot and virtual world.",https://ieeexplore.ieee.org/document/528724/,'Challenges of Our Changing Global Environment'. Conference Proceedings. OCEANS '95 MTS/IEEE,9-12 Oct. 1995,ieeexplore
10.1109/i-Society.2016.7854189,Virtualized higher education: Where e-learning trends and new faculty roles converge towards personalization,IEEE,Conferences,"Virtual Higher Education is in sharp focus lately with onslaught of Online Learning Platforms (MOOC, Coursera, Khan Academy, Udacity) offering Free Courses in every discipline. Originally targeted at populations in underdeveloped countries not otherwise able to offer a world-class education, these courses have become popular and mainstream in developed countries being free, online and caters to most professionals to build skills and explore career changes. Current delivery format robs an academic the ability to express their teaching style. The PLErify Application seeks to address the need to support, through a `DIY approach', an Academic's teaching style and retain ownership of materials. PLErify is discussed in the paper relative to the Robots role vis a vis the traditional Professor's role and the prevailing thought of the best ways to energize and modernize current teaching methods.",https://ieeexplore.ieee.org/document/7854189/,2016 International Conference on Information Society (i-Society),10-13 Oct. 2016,ieeexplore
10.1109/AQTR.2006.254650,Vision based algorithm for path planning of a mobile robot by using cellular neural networks,IEEE,Conferences,"The paper presents a new vision based algorithm for mobile robots path planning in an environment with obstacles. Cellular neural networks (CNNs) processing techniques are used here for real time motion planning to reach a fixed target. The CNN methods have been considered a solution for image processing in autonomous mobile robots guidance. The choice of CNNs for the visual processing is based on the possibility of their hardware implementation in large networks on a single VLSI chip (cellular neural networks -universal machine, CNN-UM (Roska and Chua, 1993 and Kim et al., 2002))",https://ieeexplore.ieee.org/document/4022973/,"2006 IEEE International Conference on Automation, Quality and Testing, Robotics",25-28 May 2006,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/ICRA.2019.8794123,Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing,IEEE,Conferences,"Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.",https://ieeexplore.ieee.org/document/8794123/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICSESS52187.2021.9522158,Visual Loop Closure Detection Based on Lightweight Convolutional Neural Network and Product Quantization,IEEE,Conferences,"Mobile robots rely heavily on the creation of the scene map and the positioning in the map in an unknown environment, but no matter what type of map is created, it is inevitably affected by cumulative errors. This presents a huge challenge for loop closure detection technology. Using traditional loop closure detection methods to perform scene recognition is difficult to extract the appearance changes caused by time, weather, or seasonal conditions in the image and deep semantic information, and the speed of extracting image features is slow, which is difficult to meet the real-time performance of robots. Because of the success of deep convolutional neural networks(CNN), it is possible to enrich the information of image features. First of all, this paper uses the pre-trained CNN model SSE-Net to extract the deep visual appearance and semantic features of the image, and obtain the feature description vector. Then, after product quantization(PQ) and encoding, the final pair of candidate frames is quickly searched and matched to obtain the most similar pair of candidate frames and judged as a loop . After the verification of the New collage dataset and the City Center dataset, this algorithm has achieved a good Precision-Recall rate and a faster speed compared with the recently proposed large-scale convolution network VGG16 method and traditional feature extraction methods.",https://ieeexplore.ieee.org/document/9522158/,2021 IEEE 12th International Conference on Software Engineering and Service Science (ICSESS),20-22 Aug. 2021,ieeexplore
10.1109/IECON.2019.8926916,Visual Subterranean Junction Recognition for MAVs based on Convolutional Neural Networks,IEEE,Conferences,"This article proposes a novel visual framework for detecting tunnel crossings/junctions in underground mine areas towards the autonomous navigation of Micro Aerial Vehicles (MAVs). Usually mine environments have complex geometries, including multiple crossings with different tunnels that challenge the autonomous planning of aerial robots. Towards the envisioned scenario of autonomous or semi-autonomous deployment of MAVs with limited Line-of-Sight in subterranean environments, the proposed module acknowledges the existence of junctions by providing crucial information to the autonomy and planning layers of the aerial vehicle. The capability for a junction detection is necessary in the majority of mission scenarios, including unknown area exploration, known area inspection and robot homing missions. The proposed novel method has the ability to feed the image stream from the vehicles on-board forward facing camera in a Convolutional Neural Network (CNN) classification architecture, expressed in four categories: 1) left junction, 2) right junction, 3) left &amp; right junction, and 4) no junction in the local vicinity of the vehicle. The core contribution stems for the incorporation of AlexNet in a transfer learning scheme for detecting multiple branches in a subterranean environment. The validity of the proposed method has been validated through multiple data-sets collected from real underground environments, demonstrating the performance and merits of the proposed module.",https://ieeexplore.ieee.org/document/8926916/,IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society,14-17 Oct. 2019,ieeexplore
10.1109/IROS.1997.655065,Visual navigation in an open environment without map,IEEE,Conferences,We describe how a mobile robot controlled only by visual information can retrieve a particular goal location in an open environment. Our model does not need a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired from neurobiological studies using the recognition of visual patterns called landmarks. The robot merges this visual information and its azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast online learning of a few places located near the goal allows the robot to reach the goal from anywhere in its neighborhood. The system uses only an egocentric representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation tested on our robot in two real indoor environments. We show the limitations of the model and its possible extensions to create autonomous robots only guided by visual information.,https://ieeexplore.ieee.org/document/655065/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/CDS49703.2020.00012,Welding Seam Recognition Robots Based on Edge Computing,IEEE,Conferences,"In order to meet the requirements of the accuracy and real-time performance during the working process of underwater welding robots, a scheme of welding seam recognition robots system based on the edge computing is proposed in this paper. A number of pre-processing methods for capturing welding seam image were designed, including Thresholding, Filtering and Edge Detect. A Convolutional Neural Network(CNN) model for welding seam recognition was also created. In the experiments, the image pre-processing and CNN algorithms were integrated in and deployed to the robots, and the learning and training algorithms of the CNN were deployed to the cloud servers. The image pre-processing methods filtered the interference in underwater operations and achieved the image compression and feature extraction. The cloud servers fulfilled the training and parameter optimization of the CNN, which improved the accuracy of welding seam image recognition.",https://ieeexplore.ieee.org/document/9275963/,2020 International Conference on Computing and Data Science (CDS),1-2 Aug. 2020,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/ICSMC.2011.6083632,[Copyright notice],IEEE,Conferences,The following topics are dealt with: brain-machine interface; machine learning technology; service systems; homeland security systems; virtual reality; agent-based modeling; human centered transportation systems; awareness science and engineering; soft computing; enterprise information systems; social signal processing; infrastructure system; manufacturing systems; pattern recognition; medical mechatronics; minimally invasive surgery; medical robotics; medical technology; intelligent power systems; discrete event systems; Petri nets; biometrics; bioinformatics; computational intelligence; supply chain management; shared control; fault diagnosis; systems engineering; Internet; support vector machines; knowledge acquisition; cloud computing; grey systems; humanoid robots; redundant manipulators; formal methods; granular computing; wireless sensor networks; nonlinear control systems; gesture-based interaction; software engineering; multi-agent systems; cognitive computing; social robotics; natural language processing; conflict resolution; intelligent transportation systems; human-robot interaction; image processing; medical informatics; decision support systems; assistive technology; human-centered design; data mining; and anti-terrorism applications.,https://ieeexplore.ieee.org/document/6083632/,"2011 IEEE International Conference on Systems, Man, and Cybernetics",9-12 Oct. 2011,ieeexplore
10.1109/SISY.2010.5647094,[Front cover],IEEE,Conferences,The following topics are dealt with: computational intelligence; machine learning; genetic algorithms; neural nets; neuro fuzzy control; knowledge based systems; expert systems; intelligent robotics; flexible arm control; perception; recognition; reasoning; human robotic interaction; service robots; surgery robots; machine vision; intelligent mechatronics; sensor data fusion; motion control; intelligent actuators; CAD/CAM/CAE Systems; product modeling; manufacturing process planning; advanced modeling techniques; shape modeling; intelligent manufacturing systems; flexible manufacturing systems; production planning; system simulation; rapid prototyping; concurrent engineering; virtual reality; informatics; digital culture; databases; graphics; digital audio; photography; operating systems; security software engineering; healthcare informatics; teaching informatics; and informatics in education process.,https://ieeexplore.ieee.org/document/5647094/,IEEE 8th International Symposium on Intelligent Systems and Informatics,10-11 Sept. 2010,ieeexplore
10.1109/ICAS.2009.2,[Title page iii],IEEE,Conferences,The following topics are dealt with: real-time chain-structured synchronous dataflow; memory requirement formal determination; linear singular descriptor differential system; execution-optimized paths; greedy strategy; load trend evaluation; self-managed P2P streaming; context-aware ambient assisted living application; self-adaptive distributed model; autonomic systems; wireless sensor networks; topology control; learning based method; self-recovery method; mobile data sharing; heterogeneous QoS resource manager; component-based self-healing; NGN mobility; interactive user activity; .NET Windows service agent technology; agent based Web browser; resource-definition policies; autonomic computing; autonomic system administration; automatic database performance tuning; knowledge management; adaptive reinforcement learning; VoIP services; autonomic RSS: distributed virtual reality simulations; virtual machines resources allocation; multi-lier distributed systems; network I/O extensibility; virtual keyboards; self-configuring smart homes; legged underwater vehicles; particle filters; reusable semantic components; multi-agent systems; fixed-wing unmanned aerial vehicles; fuzzy inference system; robot swarms; mobile robots; optimization architecture; autonomous unmanned helicopter landing system design; heterogeneous multi-database environments; autonomic software license management system; Web server crashes prediction; laser range finder; video quality; wireless networks; ITU-T G.1030; open IMS core; context-aware data mining methodology; supply chain finance cooperative systems; autonomous pervasive environments; distributed generic stress tool; dynamic adaptive systems; multisensory media effects and user preference.,https://ieeexplore.ieee.org/document/4976566/,2009 Fifth International Conference on Autonomic and Autonomous Systems,20-25 April 2009,ieeexplore
10.1109/ICSTCC.2016.7790626,[Title page],IEEE,Conferences,The following topics are dealt with: gain-scheduling control; linear system; PID controllers; optimization; position control; motion control; wastewater treatment; mobile robots; virtual reality; software agents; non-linear hybrid systems; obstacle detection; unmanned aerial vehicles; energy management; image processing; and neural networks.,https://ieeexplore.ieee.org/document/7790626/,"2016 20th International Conference on System Theory, Control and Computing (ICSTCC)",13-15 Oct. 2016,ieeexplore
10.1109/RCAR47638.2019.9043946,libSmart: an Open-Source Tool for Simple Integration of Deep Learning into Intelligent Robotic Systems,IEEE,Conferences,"Intelligent robotic systems can be empowered by advanced deep learning techniques. Robotic operations such as object recognition are well investigated by researchers involved in machine learning. However, these solutions have often led to ad-hoc implementation in experimental settings. Less reported is systematic implementation of deep learning models in industrial robots. The lack of standard implementation platforms has impeded widespread use of deep learning modules in industrial robots. It is of great importance to have development platforms that can coordinate several deep learning modules of a complex system. In this paper, a scalable deep-learning friendly robot task organization system named libSmart is introduced. Similar to ROS, the architecture of the proposed system allows users to plug and play various devices but the proposed architecture is also highly compatible with deep learning modules. Specifically, the deployment of deep learning models is handled using a novel data graph method with distributed computing. In this way, the computationally expensive training and inferencing processes of deep learning models can be handled with isolated accelerating hardware to reduce the overall system latency. Successful implementation of simultaneous object recognition and pose estimation by an industrial robot has been presented as a case study. The proposed system is open source for all users to build their own intelligent systems with customized deep-learning models. (https://github.com/RustIron/libSmart.git).",https://ieeexplore.ieee.org/document/9043946/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/IROS45743.2020.9340956,robo-gym – An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots,IEEE,Conferences,"Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and reduce the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym<sup>1</sup>. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to application on the robot. We showcase the capabilities and the effectiveness of the framework with two real world applications featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally, we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.",https://ieeexplore.ieee.org/document/9340956/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/JIOT.2019.2917066,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,IEEE,Journals,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8715489/,IEEE Internet of Things Journal,Oct. 2019,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2021.3124386,A Multiple Pheromone Communication System for Swarm Intelligence,IEEE,Journals,"Pheromones are chemical substances essential for communication among social insects. In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual pheromone has emerged recently as a powerful real-time method for indirect communication. However, these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviors such as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula>) to support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones simultaneously. The proposed system ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula> uses optical signals to emulate different evaporating chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The color sensors beneath the robots can detect and identify lingering “pheromones” on the screen. Meanwhile, the release of any pheromone from each robot is enabled by monitoring its positional information over time with an overhead camera. No other communication methods apart from virtual pheromones are employed in this system. Two case studies have been carried out which have verified the feasibility and effectiveness of the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel platform is a timely and powerful tool for research into swarm intelligence.",https://ieeexplore.ieee.org/document/9594791/,IEEE Access,2021,ieeexplore
10.1109/TCIAIG.2012.2228483,A Neurally Controlled Computer Game Avatar With Humanlike Behavior,IEEE,Journals,"This paper describes the NeuroBot system, which uses a global workspace architecture, implemented in spiking neurons, to control an avatar within the Unreal Tournament 2004 (UT2004) computer game. This system is designed to display humanlike behavior within UT2004, which provides a good environment for comparing human and embodied AI behavior without the cost and difficulty of full humanoid robots. Using a biologically inspired approach, the architecture is loosely based on theories about the high-level control circuits in the brain, and it is the first neural implementation of a global workspace that has been embodied in a complex dynamic real-time environment. NeuroBot's humanlike behavior was tested by competing in the 2011 BotPrize competition, in which human judges play UT2004 and rate the humanness of other avatars that are controlled by a human or a bot. NeuroBot came a close second, achieving a humanness rating of 36%, while the most human human reached 67%. We also developed a humanness metric that combines a number of statistical measures of an avatar's behavior into a single number. In our experiments with this metric, NeuroBot was rated as 33% human, and the most human human achieved 73%.",https://ieeexplore.ieee.org/document/6357232/,IEEE Transactions on Computational Intelligence and AI in Games,March 2013,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/OJITS.2020.3027146,A Plausibility-Based Fault Detection Method for High-Level Fusion Perception Systems,IEEE,Journals,"Trustworthy environment perception is the fundamental basis for the safe deployment of automated agents such as self-driving vehicles or intelligent robots. The problem remains that such trust is notoriously difficult to guarantee in the presence of systematic faults, e.g., non-traceable errors caused by machine learning functions. One way to tackle this issue without making rather specific assumptions about the perception process is plausibility checking. Similar to the reasoning of human intuition, the final outcome of a complex black-box procedure is verified against given expectations of an object's behavior. In this article, we apply and evaluate collaborative, sensor-generic plausibility checking as a mean to detect empirical perception faults from their statistical fingerprints. Our real use case is next-generation automated driving that uses a roadside sensor infrastructure for perception augmentation, represented here by test scenarios at a German highway and a city intersection. The plausibilization analysis is integrated naturally in the object fusion process, and helps to diagnose known and possibly yet unknown faults in distributed sensing systems.",https://ieeexplore.ieee.org/document/9207739/,IEEE Open Journal of Intelligent Transportation Systems,2020,ieeexplore
10.1109/TSMC.2019.2917034,A Real-Time Robotic Grasping Approach With Oriented Anchor Box,IEEE,Journals,"Grasping is an essential skill for robots to interact with humans and the environment. In this paper, we build a vision-based, robust, and real-time robotic grasping approach with fully convolutional neural network. The main component of our approach is a grasp detection network with oriented anchor boxes as detection priors. Because the orientation of detected grasps is significant, which determines the rotation angle configuration of the gripper, we propose the orientation anchor box mechanism to regress grasp angle based on predefined assumption instead of classification or regression without any priors. With oriented anchor boxes, the grasps can be predicted more accurately and efficiently. Besides, to accelerate the network training and further improve the performance of angle regression, angle matching is proposed during training instead of Jaccard index matching. Fivefold cross-validation results demonstrate that our proposed algorithm achieves an accuracy of 98.8% and 97.8% in image-wise split and object-wise split, respectively, and the speed of our detection algorithm is 67 frames per second (FPS) with GTX 1080Ti, outperforming all the current state-of-the-art grasp detection algorithms on Cornell Dataset both in speed and accuracy. Robotic experiments demonstrate the robustness and generalization ability in unseen objects and real-world environment, with the average success rate of 90.0% and 84.2% of familiar things and unseen things, respectively, on Baxter robot platform.",https://ieeexplore.ieee.org/document/8734882/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",May 2021,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/TASE.2020.3032075,A Virtual Mechanism Approach for Exploiting Functional Redundancy in Finishing Operations,IEEE,Journals,"We propose a new approach to programming by the demonstration of finishing operations. Such operations can be carried out by industrial robots in multiple ways because an industrial robot is typically functionally redundant with respect to a finishing task. In the proposed system, a human expert demonstrates a finishing operation, and the demonstrated motion is recorded in the Cartesian space. The robot’s kinematic model is augmented with a virtual mechanism, which is defined according to the applied finishing tool. This way, the kinematic model is expanded with additional degrees of freedom that can be exploited to compute the optimal joint space motion of the robot without altering the essential aspects of the Cartesian space task execution as demonstrated by the human expert. Finishing operations, such as polishing and grinding, occur in contact with the treated workpiece. Since information about the contact point position is needed to control the robot during the operation, we have developed a novel approach for accurate estimation of contact points using the measured forces and torques. Finally, we applied iterative learning control to refine the demonstrated operations and compensate for inaccurate calibration and different dynamics of the robot and human demonstrator. The proposed method was verified on real robots and real polishing and grinding tasks. <italic>Note to Practitioners</italic>—This work was motivated by the need for automation of finishing operations, such as polishing and grinding, on contemporary industrial robots. Existing approaches are both too complex and too time-consuming to be applied in flexible and small-scale production, which often requires the frequent deployment of new applications. Our approach is based on programming by demonstration and enables the programming of finishing operations also for users who are not specialists in robot programming. Programming by demonstration is especially useful for teaching finishing operations because it enables the transfer of expert knowledge about finishing skills to robots without providing lengthy task descriptions or manual coding. Besides the human demonstration of the desired operation, the proposed approach also requires the availability of the kinematic model for the machine tool applied to carry out the finishing operation. We provide several practical examples of grinding and polishing tools and how to integrate them into our approach. Another feature of the proposed system is that user demonstrations of finishing operations can be transferred between different combinations of robots and machine tools.",https://ieeexplore.ieee.org/document/9246671/,IEEE Transactions on Automation Science and Engineering,Oct. 2021,ieeexplore
10.1109/TMECH.2015.2396114,Adaptive Neural Network Control of a Compact Bionic Handling Arm,IEEE,Journals,"In this paper, autonomous control problem of a class of bionic continuum robots named “Compact Bionic Handling Arm” (CBHA) is addressed. These robots can reproduce biological behaviors of trunks, tentacles, or snakes. The modeling problem associated with continuum robots includes nonlinearities, structured and unstructured uncertainties, and the hyperredundancy. In addition to these problems, the CBHA comprises the hysteresis behavior of its actuators and a memory phenomenon related to its structure made of polyamide materials. These undesirable effects make it difficult to design a control system based on quantitative models of the CBHA. Thus, two subcontrollers are proposed in this paper. One, encapsulated in the other, and both implemented in real time allow controlling of the CBHA's end-effector position. The first subcontroller controls the CBHA's kinematics based on a distal supervised learning scheme. The second subcontroller controls the CBHA's kinetics based on an adaptive neural control. These subcontrollers allow a better assessment of the stability of the control architecture while ensuring the convergence of Cartesian errors. The obtained experimental results using a CBHA robot show an accurate tracking of the CBHA's end-effector position.",https://ieeexplore.ieee.org/document/7057549/,IEEE/ASME Transactions on Mechatronics,Dec. 2015,ieeexplore
10.1109/LRA.2020.2967296,Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation,IEEE,Journals,"On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",https://ieeexplore.ieee.org/document/8962227/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.3004339,AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,IEEE,Journals,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",https://ieeexplore.ieee.org/document/9123492/,IEEE Internet of Things Journal,Sept. 2020,ieeexplore
10.1109/OJCS.2020.3001839,An Instrument for Remote Kissing and Engineering Measurement of Its Communication Effects Including Modified Turing Test,IEEE,Journals,"Various communication systems have been developed to integrate the haptic channel in digital communication. Future directions of such haptic technologies are moving towards realistic virtual reality applications and human-robot social interaction. With the digitisation of touch, robots equipped with touch sensors and actuators can communicate with humans on a more emotional and intimate level, such as sharing a hug or kiss just like humans do. This paper presents the design guideline, implementation and evaluations of a novel haptic kissing machine for smart phones - the Kissenger machine. The key novelties and contributions of the paper are: (i) A novel haptic kissing device for mobile phones, which uses dynamic perpendicular force stimulation to transmit realistic sensations of kissing in order to enhance intimacy and emotional connection of digital communication; (ii) Extensive evaluations of the Kissenger machine, including a lab experiment that compares mediated kissing with Kissenger to real kissing, a unique haptic Turing test that involves the first academic study of human-machine kiss, and a field study of the effects of Kissenger on long distance relationships. The first experiment showed that mediated kissing with Kissenger elicited similar ratings for pleasure, arousal and user experience as real kissing. Experiment 2 confirmed our hypothesis that interrogators have a higher chance of winning the Imitation Game (Turing test) when Kissenger is used during the game. Results from experiment 3 showed that long relationship couples who used Kissenger for a week experienced increased relationship satisfaction and decreased perceived stress.",https://ieeexplore.ieee.org/document/9119758/,IEEE Open Journal of the Computer Society,2020,ieeexplore
10.1109/TASE.2004.840071,Artificial-intelligence approach for biomedical sample characterization using Raman spectroscopy,IEEE,Journals,"An artificial-intelligence approach is proposed to differentiate various biomedical samples via Raman spectroscopy technology to obtain accurate medical diagnosis and decision making. The complete process consists of noise filtering, fluorescence identification, optimization and elimination, spectral normalization, multivariate statistical analysis, and data clustering, as well as the final decision making. Numerous modeling, intelligent control, and system-identification schemes have been employed. By means of fuzzy control, genetic algorithms, and principal component analysis (PCA), as well as system identification, a systematic intelligent-control approach is formulated, which is capable of classifying diversified biomedical samples. Raman spectra are weak signals whose features are sensitive to a variety of noises, which have to be reduced to an acceptable level. Fuzzy logic has been known to interpret uncertainty, imprecision, and vague phenomena. Thus, a fuzzy controller is used for noise filtering. On the other hand, background fluorescence acts as a secondary intensity component within a raw Raman spectrograph, so its spectral baseline should be determined. By removing background fluorescence, intrinsic Raman spectrum can be extracted in consequence. To optimize this detrend process, genetic algorithms have been implemented for baseline-function global optimization by selecting an optimal combination of individual spectroscopic functions. Normalization is performed by standard normal variate (SNV) afterwards to compensate for scattering effects. Normalized intrinsic spectra can be used for sample differentiation, where the PCA approach distinguishes some signatures from different samples in terms of dominant principal components. Eventually, various principal components are accumulated for clustering using scatter plots. The long-term objective of this intelligent-control approach is to create a real-time technique for sample analysis, using a Raman spectrometer directly mounted at the end-effectors of medical robots, which is to enhance the robotic surgery.",https://ieeexplore.ieee.org/document/1381368/,IEEE Transactions on Automation Science and Engineering,Jan. 2005,ieeexplore
10.1109/ACCESS.2019.2925087,Automatic Gauge Detection via Geometric Fitting for Safety Inspection,IEEE,Journals,"For safety considerations in electrical substations, the inspection robots are recently deployed to monitor important devices and instruments with the presence of skilled technicians in the high-voltage environments. The captured images are transmitted to a data station and are usually analyzed manually. Toward automatic analysis, a common task is to detect gauges from captured images. This paper proposes a gauge detection algorithm based on the methodology of geometric fitting. We first use the Sobel filters to extract edges which usually contain the shapes of gauges. Then, we propose to use line fitting under the framework of random sample consensus (RANSAC) to remove straight lines that do not belong to gauges. Finally, the RANSAC ellipse fitting is proposed to find most fitted ellipse from the remaining edge points. The experimental results on a real-world dataset captured by the GuoZi Robotics demonstrate that our algorithm provides more accurate gauge detection results than several existing methods.",https://ieeexplore.ieee.org/document/8746263/,IEEE Access,2019,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/TCDS.2019.2928820,BND*-DDQN: Learn to Steer Autonomously Through Deep Reinforcement Learning,IEEE,Journals,"It is vital for mobile robots to achieve safe autonomous steering in various changing environments. In this paper, a novel end-to-end network architecture is proposed for mobile robots to learn steering autonomously through deep reinforcement learning. Specifically, two sets of feature representations are first extracted from the depth inputs through two different input streams. The acquired features are then merged together to derive both linear and angular actions simultaneously. Moreover, a new action selection strategy is also introduced to achieve motion filtering by taking the consistency in angular velocity into account. Besides, in addition to the extrinsic rewards, the intrinsic bonuses are also adopted during training to improve the exploration capability. Furthermore, it is worth noting the proposed model is readily transferable from the simple virtual training environment to much more complicated real-world scenarios so that no further fine-tuning is required for real deployment. Compared to the existing methods, the proposed method demonstrates significant superiority in terms of average reward, convergence speed, success rate, and generalization capability. In addition, it exhibits outstanding performance in various cluttered real-world environments containing both static and dynamic obstacles. A video of our experiments can be found at https://youtu.be/19jrQGG1oCU.",https://ieeexplore.ieee.org/document/8764461/,IEEE Transactions on Cognitive and Developmental Systems,June 2021,ieeexplore
10.1109/LRA.2021.3062303,Bi-Directional Domain Adaptation for Sim2Real Transfer of Embodied Navigation Agents,IEEE,Journals,"Deep reinforcement learning models are notoriously data hungry, yet real-world data is expensive and time consuming to obtain. The solution that many have turned to is to use simulation for training before deploying the robot in a real environment. Simulation offers the ability to train large numbers of robots in parallel, and offers an abundance of data. However, no simulation is perfect, and robots trained solely in simulation fail to generalize to the real-world, resulting in a “sim-vs-real gap”. How can we overcome the trade-off between the abundance of less accurate, artificial data from simulators and the scarcity of reliable, real-world data? In this letter, we propose Bi-directional Domain Adaptation (BDA), a novel approach to bridge the sim-vs-real gap in both directions- real2sim to bridge the visual domain gap, and sim2real to bridge the dynamics domain gap. We demonstrate the benefits of BDA on the task of PointGoal Navigation. BDA with only 5 k real-world (state, action, next-state) samples matches the performance of a policy fine-tuned with ~ 600 k samples, resulting in a speed-up of ~ 120×.",https://ieeexplore.ieee.org/document/9363564/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/70.88080,CONDOR: an architecture for controlling the Utah-MIT dexterous hand,IEEE,Journals,"The authors describe a fully implemented computational architecture (CONDOR) that controls the Utah-MIT dexterous hand and other complex robots. The architecture derives its power from the highly efficient real-time environment provided for its control processors, coupled with a development host that allows flexible program development. By mapping the memory of a dedicated group of processors into the address space of a host computer, efficient sharing of system resources between them is possible. The software is characterized by a few simple design concepts but provides the facilities out of which more powerful utilities such as a multiprocessor pseudo-terminal emulator, a transparent and fast file server, and a flexible symbolic debugger could be constructed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88080/,IEEE Transactions on Robotics and Automation,Oct. 1989,ieeexplore
10.1109/ACCESS.2018.2845855,Color Transfer Pulse-Coupled Neural Networks for Underwater Robotic Visual Systems,IEEE,Journals,"With rapid developments in cloud computing, artificial intelligence, and robotic systems, ever more complex tasks, such as space and ocean exploration, are being implemented by intelligent robots. Here, we propose an underwater image enhancement scheme for robotic visual systems. The proposed algorithm and its implementation enhances and outputs an image captured by an underwater robot in real time. In this scheme, pulse-coupled neural network (PCNN)-based image enhancement and color transfer algorithms are combined to enhance the underwater image. To avoid color imbalance in the underwater image and enhance details while suppressing noise, color correction is first carried out on the underwater image before converting it into the hue-saturation-intensity domain and enhancing it by PCNN. The enhanced result improves the color and contrast of the source image and enhances the details and edges of darker regions. Experiments are performed on real world data to demonstrate the effectiveness of the proposed scheme.",https://ieeexplore.ieee.org/document/8377996/,IEEE Access,2018,ieeexplore
10.1109/TEVC.2010.2058120,Compact Differential Evolution,IEEE,Journals,"This paper proposes the compact differential evolution (cDE) algorithm. cDE, like other compact evolutionary algorithms, does not process a population of solutions but its statistic description which evolves similarly to all the evolutionary algorithms. In addition, cDE employs the mutation and crossover typical of differential evolution (DE) thus reproducing its search logic. Unlike other compact evolutionary algorithms, in cDE, the survivor selection scheme of DE can be straightforwardly encoded. One important feature of the proposed cDE algorithm is the capability of efficiently performing an optimization process despite a limited memory requirement. This fact makes the cDE algorithm suitable for hardware contexts characterized by small computational power such as micro-controllers and commercial robots. In addition, due to its nature cDE uses an implicit randomization of the offspring generation which corrects and improves the DE search logic. An extensive numerical setup has been implemented in order to prove the viability of cDE and test its performance with respect to other modern compact evolutionary algorithms and state-of-the-art population-based DE algorithms. Test results show that cDE outperforms on a regular basis its corresponding population-based DE variant. Experiments have been repeated for four different mutation schemes. In addition cDE outperforms other modern compact algorithms and displays a competitive performance with respect to state-of-the-art population-based algorithms employing a DE logic. Finally, the cDE is applied to a challenging experimental case study regarding the on-line training of a nonlinear neural-network-based controller for a precise positioning system subject to changes of payload. The main peculiarity of this control application is that the control software is not implemented into a computer connected to the control system but directly on the micro-controller. Both numerical results on the test functions and experimental results on the real-world problem are very promising and allow us to think that cDE and future developments can be an efficient option for optimization in hardware environments characterized by limited memory.",https://ieeexplore.ieee.org/document/5675671/,IEEE Transactions on Evolutionary Computation,Feb. 2011,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/TSMC.2019.2958094,Design and Analysis of a Human–Machine Interaction System for Researching Human’s Dynamic Emotion,IEEE,Journals,"Dynamic emotion is typically used to facilitate human–machine interactions. Conversational data from social media contain a considerable amount of useful information, and such data are the foundation for researching dynamic and artificial emotion. At present, most human–machine interaction systems focus on the complexity and accuracy of the dialog but neglect the emotional characteristics of the speaker. When generating a dialog considering the emotional personality of the interlocutor, controlling, and guiding the dialog to a specified direction are essential. This article presents a system for studying dynamic emotions in human-computer interaction from the perspective of emotional transfer and guidance. Based on the emotional state of the interlocutor and the distribution of emotional transfer, the process of emotional transfer is simulated and sampled, and the sequence of emotional guidance is generated. In this system, two algorithms are proposed. A generative Markov chain Monte Carlo (GEN-MCMC) algorithm is proposed to generate a variety of emotional transfer sequences that fit the talke’s personality dynamically based on the real-world dialog. Further, a guiding MCMC (GUI-MCMC) algorithm-based GEN-MCMC is proposed to generate the emotional guiding sequences. The generated emotional sequences by GEN-MCMC were evaluated in two aspects: 1) consistency and 2) diversity. The experimental results show that the GEN-MCMC algorithm performs better than the general sequence generation algorithm in terms of consistency and diversity in generating emotional states. The GUI-MCMC was able to generate a proper stimulus sequence when given the first and target emotions. An emotional stimulus sequence can simulate the emotional transfer of the interlocutor in the process of dialogue, and give the observer appropriate reference to guide and control the emotions of dialogue. The experimental results show that the proposed system can effectively model the dynamic emotion in emotional transfer and guidance, which can be further used to build chat robots, intelligent assistants, and human–machine interaction systems. The models can also be used for emotional induction and enhance the feel-good or feel-terrible factor in human–machine communication applications, such as medical treatment of mental diseases, interrogation, and psychological attack and defense.",https://ieeexplore.ieee.org/document/8943333/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Oct. 2021,ieeexplore
10.1109/TNNLS.2016.2545298,Embedded Streaming Deep Neural Networks Accelerator With Applications,IEEE,Journals,"Deep convolutional neural networks (DCNNs) have become a very powerful tool in visual perception. DCNNs have applications in autonomous robots, security systems, mobile phones, and automobiles, where high throughput of the feedforward evaluation phase and power efficiency are important. Because of this increased usage, many field-programmable gate array (FPGA)-based accelerators have been proposed. In this paper, we present an optimized streaming method for DCNNs' hardware accelerator on an embedded platform. The streaming method acts as a compiler, transforming a high-level representation of DCNNs into operation codes to execute applications in a hardware accelerator. The proposed method utilizes maximum computational resources available based on a novel-scheduled routing topology that combines data reuse and data concatenation. It is tested with a hardware accelerator implemented on the Xilinx Kintex-7 XC7K325T FPGA. The system fully explores weight-level and node-level parallelizations of DCNNs and achieves a peak performance of 247 G-ops while consuming less than 4 W of power. We test our system with applications on object classification and object detection in real-world scenarios. Our results indicate high-performance efficiency, outperforming all other presented platforms while running these applications.",https://ieeexplore.ieee.org/document/7450197/,IEEE Transactions on Neural Networks and Learning Systems,July 2017,ieeexplore
10.1109/TCDS.2016.2562121,Emergence of Altruistic Behavior Through the Minimization of Prediction Error,IEEE,Journals,"The emergence of altruistic behavior in infants fosters their social development and supports their involvement in our society. Altruistic tendencies, intended to benefit others with no apparent rewards, are also very useful for social robots that are designed to be used in our households. Yet, to make robots capable of learning how to help others as infants do, it is important to understand the mechanisms and motives responsible for the development of altruistic behavior. Further, understanding the mechanisms behind the early development of pro-social behavior would be a great contribution to the field of developmental psychology. To these ends, we hypothesize that infants from 14 months of age help others to minimize the differences between predicted actions and observations, that is, to minimize prediction errors. To evaluate our hypothesis, we created a computational model based on psychological studies and implemented it in real and simulated robots. Our system first acquires its own sensory-motor representation by interacting with its environment. Then, using its experience, the system recognizes and predicts others' actions and uses this prediction to estimate a prediction error. Our experiments demonstrated that our robots could spontaneously generate helping behaviors by being motivated by the minimization of prediction errors.",https://ieeexplore.ieee.org/document/7479539/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/TII.2019.2936167,End-to-End Navigation Strategy With Deep Reinforcement Learning for Mobile Robots,IEEE,Journals,"In this article, we develop a navigation strategy based on deep reinforcement learning (DRL) for mobile robots. Because of the large difference between simulation and reality, most of the trained DRL models cannot be directly migrated into real robots. Moreover, how to explore in a sparsely rewarded environment is also a long-standing problem of DRL. This article proposes an end-to-end navigation planner that translates sparse laser ranging results into movement actions. Using this highly abstract data as input, agents trained by simulation can be extended to the real scene for practical application. For map-less navigation across obstacles and traps, it is difficult to reach the target via random exploration. Curiosity is used to encourage agents to explore the state of an environment that has not been visited and as an additional reward for exploring behavior. The agent relies on the self-supervised model to predict the next state, based on the current state and the executed action. The prediction error is used as a measure of curiosity. The experimental results demonstrate that without any manual design features and previous demonstrations, the proposed method accomplishes map-less navigation in complex environments. Through a reward signal that is enhanced by intrinsic motivation, the agent explores more efficiently, and the learned strategy is more reliable.",https://ieeexplore.ieee.org/document/8807287/,IEEE Transactions on Industrial Informatics,April 2020,ieeexplore
10.1109/LRA.2020.3012951,End-to-End Tactile Feedback Loop: From Soft Sensor Skin Over Deep GRU-Autoencoders to Tactile Stimulation,IEEE,Journals,"Tactile feedback is a key sensory channel that contributes to our ability to perform precise manipulations. In this regard, sensor skin provides robots with the sense of touch making them increasingly capable of dexterous object manipulation. However, in applications like teleoperation, the complex sensory input of an infinite number of different textures must be projected to the human user's skin in a meaningful manner. In addressing this issue, a deep gated recurrent unit-based autoencoder (GRU-AE) that captured the perceptual dimensions of tactile textures in latent space was deployed to implicitly understand unseen textures. The expression of unknown textures in this latent space allowed for the definition of a control law to effectively drive tactile displays and to convey tactile feedback in a psycho-physically meaningful manner. The approach was experimentally verified by evaluating the prediction performance of the GRU-AE on seen and unseen data that were gathered during active tactile exploration of objects commonly encountered in daily living. A user study on a custom-made tactile display was conducted in which real tactile perceptions in response to active tactile object exploration were compared to the emulated tactile feedback using the proposed tactile feedback loop. The results suggest that the deep GRU-AE for tactile display control offers an effective and intuitive method for efficient end-to-end tactile feedback during active tactile texture exploration.",https://ieeexplore.ieee.org/document/9152113/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/ACCESS.2021.3101397,Energy-Efficient Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture Environment,IEEE,Journals,"The current agriculture systems compete to take advantage of industry advanced technologies, including the internet of things (IoT), cloud/fog/edge computing, artificial intelligence, and agricultural robots to monitor, track, analyze and process various functions and services in real-time. Additionally, these technologies can make the agricultural processes smarter and more cost-efficient by using automated systems and eliminating any human interventions, hence enhancing agricultural production to meet future expectations. Although the current agriculture systems that adopt the traditional cloud-based architecture have provided powerful computing infrastructure to distributed IoT sensors. However, the cost of energy consumption associated with transferring heterogeneous data over the multiple network tiers to process, analyze and store the sensor's information in the cloud has created a huge load on information and communication infrastructure. Besides, the energy consumed by cloud data centers has an environmental impact associated with using non-clean fuels, which usually release carbon emissions (CO<sub>2</sub>) to produce electricity. Thus, to tackle these issues, we propose a new integrated edge-fog-cloud architectural paradigm that promises to enhance the energy-efficient of smart agriculture systems and corresponding carbon emissions. This architecture allows data collection from several sensors to process and analyze the agriculture data that require real-time operation (e.g., weather temperature, soil moisture, soil acidity, irrigation, etc.) in several layers (edge, fog, and cloud). Thus, the real-time processing could be held by the edge and fog layers to reduce the load on the cloud layer, which will help to enhance the overall energy consumption and process the agriculture applications/services efficiently. Mathematical modeling is conducted using mixed-integer linear programming (MILP) for a smart agriculture environment, where the proposed architecture is implemented, and results are analyzed and compared to the traditional implementation. According to the results of thousands of agriculture sensors, the proposed architecture outperforms the traditional cloud-based architecture in terms of reducing the overall energy consumption by 36% and the carbon emissions by 43%. In addition to these achievements, the results show that our proposed architecture can reduce network traffic by up to 86%, which can reduce network congestion. Finally, we develop a heuristic algorithm to validate and mimic the presented approach, and it shows comparable results to the MILP model.",https://ieeexplore.ieee.org/document/9502114/,IEEE Access,2021,ieeexplore
10.1109/TNNLS.2018.2830119,Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source Localization,IEEE,Journals,"Inspired by the behavior of humans talking in noisy environments, we propose an embodied embedded cognition approach to improve automatic speech recognition (ASR) systems for robots in challenging environments, such as with ego noise, using binaural sound source localization (SSL). The approach is verified by measuring the impact of SSL with a humanoid robot head on the performance of an ASR system. More specifically, a robot orients itself toward the angle where the signal-to-noise ratio (SNR) of speech is maximized for one microphone before doing an ASR task. First, a spiking neural network inspired by the midbrain auditory system based on our previous work is applied to calculate the sound signal angle. Then, a feedforward neural network is used to handle high levels of ego noise and reverberation in the signal. Finally, the sound signal is fed into an ASR system. For ASR, we use a system developed by our group and compare its performance with and without the support from SSL. We test our SSL and ASR systems on two humanoid platforms with different structural and material properties. With our approach we halve the sentence error rate with respect to the common downmixing of both channels. Surprisingly, the ASR performance is more than two times better when the angle between the humanoid head and the sound source allows sound waves to be reflected most intensely from the pinna to the ear microphone, rather than when sound waves arrive perpendicularly to the membrane.",https://ieeexplore.ieee.org/document/8371531/,IEEE Transactions on Neural Networks and Learning Systems,Jan. 2019,ieeexplore
10.1109/TSMCB.2010.2073702,Experimental Analysis of Mobile-Robot Teleoperation via Shared Impedance Control,IEEE,Journals,"In this paper, Internet-based teleoperation of mobile robots for obstacle avoidance is analyzed. A shared impedance-control scheme is presented, and the results of an experimental study for the evaluation of the effects of different teleoperation parameters are reported. In the experimental study, the effects of time delay, operator training, image-display alternatives (virtual model versus real images), viewpoint, and force-reflection method were studied. For this purpose, several hypotheses were formulated and tested through the experiments using the introduced quantitative and qualitative measures. A fuzzy force-reflection controller is also proposed as an alternative force-reflection technique, and its performance is compared with a conventional proportional-derivative-type force-reflection method. The experimental scheme was implemented using MATLAB XPC Target and Simulink. The results could serve as guidelines in the design of teleoperation systems for obstacle avoidance and could also provide directions for further investigations.",https://ieeexplore.ieee.org/document/5598539/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2011,ieeexplore
10.1109/TOH.2017.2753233,Functional Contour-following via Haptic Perception and Reinforcement Learning,IEEE,Journals,"Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",https://ieeexplore.ieee.org/document/8039205/,IEEE Transactions on Haptics,1 Jan.-March 2018,ieeexplore
10.1109/ACCESS.2020.3043662,Ground-Level Mapping and Navigating for Agriculture Based on IoT and Computer Vision,IEEE,Journals,"Autonomous agricultural systems are a promising solution to bridge the gap between labor shortage for agriculture tasks and the continuing needs for increasing productivity in agriculture. Automated mapping and navigation system will be a cornerstone of most autonomous agricultural system. Accordingly, we propose a ground-level mapping and navigating system based on computer vision technology (Mesh Simultaneous Localization and Mapping algorithm, Mesh-SLAM) and Internet of Things (IoT), to generate a 3D farm map on both the edge side and cloud. The innovation of this system includes three layers as sub-systems that are 1) ground-level robot vehicles' layer for conducting frames collection only with a monocular camera, 2) edge node layer for image feature data edge computing and communication, and 3) cloud layer for general management and deep computing. High efficiency and speed of mapping stage are enabled by making the robot vehicles directly stream continuous frames to their corresponding edge node. Then each edge node, that coordinate a certain range of robots, applies a new Mesh-SLAM frame by frame, whose core is reconstructing the features map by a mesh-based algorithm with scalable units and reduce the feature data size by a filtering algorithm. Additionally, the cloud-computing allows comprehensive arrangement and heavily deep computing. The system is scalable to larger-scale fields and more complex environment by taking advantage of dynamically distributing the computation power to edges. Our evaluation indicates that: 1) this Mesh-SLAM algorithm outperforms in mapping and localization precision, accuracy, and yield prediction error (resolution at centimeter); and 2) The scalability and flexibility of the IoT architecture make the system modularized, easy adding/removing new functional modules or IoT sensors. We conclude the trade-off between cost and performance widely augments the feasibility and practical implementation of this system in real farms.",https://ieeexplore.ieee.org/document/9288741/,IEEE Access,2020,ieeexplore
10.1109/TCDS.2020.2991470,Guest Editorial Special Issue on Multidisciplinary Perspectives on Mechanisms of Language Learning,IEEE,Journals,"Humans excel at learning from other humans [item 1) in the Appendix). Language facilitates such learning and plays a crucial role. On the one hand, it coordinates our interactions and cooperative behavior [item 2) in the Appendix). On the other hand, language and communication allow to directly incorporate novel knowledge gathered from social interaction or from reading [item 3) in the Appendix). It has been a long-standing goal of artificial intelligence to leverage such communicative abilities [item 4) in the Appendix) for robots and smart software agents which would, at first, simplify our interactions with machines through a more human-like way of coordinating between humans and robots. But furthermore, this would allow us to easily teach these machines, increasing their abilities and skills further which would allow them to become real partners and companions.",https://ieeexplore.ieee.org/document/9114350/,IEEE Transactions on Cognitive and Developmental Systems,June 2020,ieeexplore
10.1109/3477.499796,Hidden state and reinforcement learning with instance-based state identification,IEEE,Journals,"Real robots with real sensors are not omniscient. When a robot's next course of action depends on information that is hidden from the sensors because of problems such as occlusion, restricted range, bounded field of view and limited attention, we say the robot suffers from the hidden state problem. State identification techniques use history information to uncover hidden state. Some previous approaches to encoding history include: finite state machines, recurrent neural networks and genetic programming with indexed memory. A chief disadvantage of all these techniques is their long training time. This paper presents instance-based state identification, a new approach to reinforcement learning with state identification that learns with much fewer training steps. Noting that learning with history and learning in continuous spaces both share the property that they begin without knowing the granularity of the state space, the approach applies instance-based (or ""memory-based"") learning to history sequences-instead of recording instances in a continuous geometrical space, we record instances in action-percept-reward sequence space. The first implementation of this approach, called Nearest Sequence Memory, learns with an order of magnitude fewer steps than several previous approaches.",https://ieeexplore.ieee.org/document/499796/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/ACCESS.2021.3063782,Hierarchical Decomposed-Objective Model Predictive Control for Autonomous Casualty Extraction,IEEE,Journals,"In recent years, several robots have been developed and deployed to perform casualty extraction tasks. However, the majority of these robots are overly complex, and require teleoperation via either a skilled operator or a specialised device, and often the operator must be present at the scene to navigate safely around the casualty. Instead, improving the autonomy of such robots can reduce the reliance on expert operators and potentially unstable communication systems, while still extracting the casualty in a safe manner. There are several stages in the casualty extraction procedure, from navigating to the location of the emergency, safely approaching and loading the casualty, to finally navigating back to the medical assistance location. In this paper, we propose a Hierarchical Decomposed-Objective based Model Predictive Control (HiDO-MPC) method for safely approaching and manoeuvring around the casualty. We implement this controller on ResQbot — a proof-of-concept mobile rescue robot we previously developed — capable of safely rescuing an injured person lying on the ground, i.e. performing the casualty extraction procedure. HiDO-MPC achieves the desired casualty extraction behaviour by decomposing the main objective into multiple sub-objectives with a hierarchical structure. At every time step, the controller evaluates this hierarchical decomposed objective and generates the optimal control decision. We have conducted a number of experiments both in simulation and using the real robot to evaluate the proposed method’s performance, and compare it with baseline approaches. The results demonstrate that the proposed control strategy gives significantly better results than baseline approaches in terms of accuracy, robustness, and execution time, when applied to casualty extraction scenarios.",https://ieeexplore.ieee.org/document/9369351/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/TMECH.2015.2490180,Hybrid Approach for Modeling and Solving of Kinematics of a Compact Bionic Handling Assistant Manipulator,IEEE,Journals,"This paper deals with a methodology for real-time solving of a complex kinematics of a class of continuum manipulators, namely the compact bionic handling assistant (CBHA). First, a quantitative approach is used to model kinematically the CBHA inspired from the modeling of parallel rigid manipulators. For this case, the CBHA is modeled as a series of vertebrae, where each vertebra is connected to the next one through a flexible link. The latter named an intervertebra is modeled by three universal-prismatic-spherical and one universal-prismatic joints. The kinematic models of the CBHA are derived from the inverse kinematic equations (IKE) of each intervertebra. A qualitative approach based on neural networks is used to provide approximated solutions of the IKE for real-time implementation. Thus, the combination of the advantages of quantitative and qualitative approaches allows proposing a hybrid methodology for accurate modeling and solving the kinematics of this class of continuum robots. A set of experiments is conducted using a CBHA in order to evaluate the level of efficiency of the proposed hybrid approach.",https://ieeexplore.ieee.org/document/7296659/,IEEE/ASME Transactions on Mechatronics,June 2016,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TIE.2018.2864707,Incremental Updating Multirobot Formation Using Nonlinear Model Predictive Control Method With General Projection Neural Network,IEEE,Journals,"In this paper, an incremental centralized formation system is developed for controlling the multirobot formation with joining robots, and a nonlinear model predictive control (NMPC) method is implemented as the controller. The incremental updating method is used to update the system's state in real time, when there is a new robot joining during the formation process. Then, an NMPC approach is developed to reformulate the formation system into a convex nonlinear minimization problem, which can be further transformed into a quadratic programming (QP) with constraints. Then, a general projection neural network (GPNN) is implemented for solving this QP problem online to get the optimal inputs. In the end, two examples of incremental multirobot formation are demonstrated to verify the effectiveness of this method.",https://ieeexplore.ieee.org/document/8437254/,IEEE Transactions on Industrial Electronics,June 2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/LRA.2018.2870466,Introduction to the Special Issue on AI for Long-Term Autonomy,IEEE,Journals,"The papers in this special section focus on the use of artificial intelligence (AI) for long term autonomy. Autonomous systems have a long history in the fields of AI and robotics. However, only through recent advances in technology has it been possible to create autonomous systems capable of operating in long-term, real-world scenarios. Examples include autonomous robots that operate outdoors on land, in air, water, and space; and indoors in offices, care homes, and factories. Designing, developing, and maintaining intelligent autonomous systems that operate in real-world environments over long periods of time, i.e. weeks, months, or years, poses many challenges. This special issue focuses on such challenges and on ways to overcome them using methods from AI. Long-term autonomy can be viewed as both a challenge and an opportunity. The challenge of long-term autonomy requires system designers to ensure that an autonomous system can continue operating successfully according to its real-world application demands in unstructured and semi-structured environments. This means addressing issues related to hardware and software robustness (e.g., gluing in screws and profiling for memory leaks), as well as ensuring that all modules and functions of the system can deal with the variation in the environment and tasks that is expected to occur over its operating time. ",https://ieeexplore.ieee.org/document/8478420/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2021.3060712,Joint Plant Instance Detection and Leaf Count Estimation for In-Field Plant Phenotyping,IEEE,Journals,"Precision management of agricultural fields as well as plant breeding are central factors for keeping yields high and to provide food, feed, and fiber for our society. A key element in breeding trials but also for targeted management actions is to analyze the growth state of individual plants objectively and at a large scale. In this letter, we address the problem of analyzing crops in real agricultural fields based on camera data recorded with mobile robots and to derive information about the plant development, e.g., to monitor phenotypic traits such as growth stage. We propose a novel single-stage object detection approach that localizes crops and weeds in the field. At the same time, it detects plant-specific leaf keypoints intending to estimate leaf count at a plant level, which is a key trait for classifying the growth stage. We implemented and thoroughly tested our approach on real sugar beet fields. As our experiments show, it performs the required detections and shows superior performance with respect to a state-of-the-art two-stage approach based on Mask R-CNN.",https://ieeexplore.ieee.org/document/9359471/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/ACCESS.2020.2970728,LoPECS: A Low-Power Edge Computing System for Real-Time Autonomous Driving Services,IEEE,Journals,"To simultaneously enable multiple autonomous driving services on affordable embedded systems, we designed and implemented LoPECS, a Low-Power Edge Computing System for real-time autonomous robots and vehicles services. The contributions of this paper are three-fold: first, we developed a Heterogeneity-Aware Runtime Layer to fully utilize vehicle's heterogeneous computing resources to fulfill the real-time requirement of autonomous driving applications; second, we developed a vehicle-edge Coordinator to dynamically offload vehicle tasks to edge cloudlet to further optimize user experience in the way of prolonged battery life; third, we successfully integrated these components into LoPECS system and implemented it on Nvidia Jetson TX1. To the best of our knowledge, this is the first complete edge computing system in a production autonomous vehicle. Our implementation on Nvidia Jetson demonstrated that it could successfully support multiple autonomous driving services with only 11 W of power consumption, and hence proves the effectiveness of the proposed LoPECS system.",https://ieeexplore.ieee.org/document/8977507/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.2972819,Marker-Less Micro Aerial Vehicle Detection and Localization Using Convolutional Neural Networks,IEEE,Journals,"A relative localization system for micro aerial vehicles (MAVs), which is able to work without any markers or other specialized equipment, is presented in this letter. The system utilizes images from an onboard camera to detect nearby MAVs using a convolutional neural network. When compared to traditional computer vision-based relative localization systems, this approach removes the need for specialized markers to be placed on the MAVs, saving weight and space, while also enabling localization of noncooperating robots. The system is designed and implemented to run online, onboard an MAV platform in order to enable relative stabilization of several MAVs in a formation or swarm-like behavior, when operating in a closed feedback loop with the control system of the MAVs. We demonstrate the viability and robustness of the proposed method in real-world experiments. The method was also designed for the purpose of autonomous aerial interception and is a fitting complement to other MAV detection and relative localization methods for this purpose, as is shown in the experiments.",https://ieeexplore.ieee.org/document/8988144/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/TIE.2007.903993,Multimodal Approach to Human-Face Detection and Tracking,IEEE,Journals,"The constructive need for robots to coexist with humans requires human-machine interaction. It is a challenge to operate these robots in such dynamic environments, which requires continuous decision-making and environment-attribute update in real-time. An autonomous robot guide is well suitable in places such as museums, libraries, schools, hospital, etc. This paper addresses a scenario where a robot tracks and follows a human. A neural network is utilized to learn the skin and nonskin colors. The skin-color probability map is utilized for skin classification and morphology-based preprocessing. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification. A face-detection module, based on a 2D color model in the and YUV color space, is selected over the traditional skin-color model in a 3D color space. A modified continuously adaptive mean shift tracking mechanism in a 1D hue, saturation, and value color space is developed and implemented onto the mobile robot. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person's distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. The proposed approach is orientation invariant under varying lighting conditions and invariant to natural transformations such as translation, rotation, and scaling. Such a multimodal solution is effective for face detection and tracking.",https://ieeexplore.ieee.org/document/4392479/,IEEE Transactions on Industrial Electronics,March 2008,ieeexplore
10.1109/56.812,On terrain acquisition by a point robot amidst polyhedral obstacles,IEEE,Journals,"The authors consider the problem of terrain model acquisition by a roving point placed in an unknown terrain populated by stationary polyhedral obstacles in two/three dimensions. The motivation for this problem is that after the terrain model is completely acquired, navigation from a source point to a destination point can be achieved along the collision-free paths. This can be done without the usage of sensors by applying the existing techniques for the find-path problem. In the paper, the point robot autonomous machine (PRAM) is used as a simplified abstract model for real-life roving robots. An algorithm is presented that enables PRAM to autonomously acquire the model of an unexplored obstacle terrain composed of an unknown number of polyhedral obstacles in two/three dimensions. In this method, PRAM undertakes a systematic exploration of the obstacle terrain with its sensor that detects all the edges and vertices visible from the present location, and builds the complete obstacle terrain model.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/812/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TNNLS.2014.2354400,Opportunistic Behavior in Motivated Learning Agents,IEEE,Journals,"This paper focuses on the novel motivated learning (ML) scheme and opportunistic behavior of an intelligent agent. It extends previously developed ML to opportunistic behavior in a multitask situation. Our paper describes the virtual world implementation of autonomous opportunistic agents learning in a dynamically changing environment, creating abstract goals, and taking advantage of arising opportunities to improve their performance. An opportunistic agent achieves better results than an agent based on ML only. It does so by minimizing the average value of all need signals rather than a dominating need. This paper applies to the design of autonomous embodied systems (robots) learning in real-time how to operate in a complex environment.",https://ieeexplore.ieee.org/document/6913540/,IEEE Transactions on Neural Networks and Learning Systems,Aug. 2015,ieeexplore
10.1109/TOH.2020.2975555,Perception of Tactile Directionality via Artificial Fingerpad Deformation and Convolutional Neural Networks,IEEE,Journals,"Humans can perceive tactile directionality with angular perception thresholds of 14-40° via fingerpad skin displacement. Using deformable, artificial tactile sensors, the ability to perceive tactile directionality was developed for a robotic system to aid in object manipulation tasks. Two convolutional neural networks (CNNs) were trained on tactile images created from fingerpad deformation measurements during perturbations to a handheld object. A primary CNN regression model provided a point estimate of tactile directionality over a range of grip forces, perturbation angles, and perturbation speeds. A secondary CNN model provided a variance estimate that was used to determine uncertainty about the point estimate. A 5-fold cross-validation was performed to evaluate model performance. The primary CNN produced tactile directionality point estimates with an error rate of 4.3% for a 20° angular resolution and was benchmarked against an open-source force estimation network. The model was implemented in real-time for interactions with an external agent and the environment with different object shapes and widths. The perception of tactile directionality could be used to enhance the situational awareness of human operators of telerobotic systems and to develop decision-making algorithms for context-appropriate responses by semi-autonomous robots.",https://ieeexplore.ieee.org/document/9007491/,IEEE Transactions on Haptics,Oct.-Dec. 2020,ieeexplore
10.1109/ACCESS.2019.2900475,Pollution Source Localization Based on Multi-UAV Cooperative Communication,IEEE,Journals,"Harmful gas leakage accidents in chemical plants have occurred from time to time. The application of mobile robots to find odor source has become one of the hottest research topics. Compared to traditional robots, unmanned aerial vehicle (UAV) is more flexible and safer. Therefore, using multi-UAV to solve pollution source tracking is a meaningful study. In this paper, an air pollution source tracking algorithm based on artificial potential field and particle swarm optimization is proposed. The particle swarm optimization algorithm combined with artificial potential field method is used to guide the UAVs to track the plume and avoid the collisions among them. At the same time, adaptive inertia weights are used to help improve the convergence and the searchability of particles. We not only evaluated this algorithm in simulation experiments but also designed a multi-UAV pollution source tracking platform for real-world experiments. The experimental results show that the algorithm can accurately find the pollution source in a short time.",https://ieeexplore.ieee.org/document/8665856/,IEEE Access,2019,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/ACCESS.2021.3056149,READ-IoT: Reliable Event and Anomaly Detection Framework for the Internet of Things,IEEE,Journals,"Internet of Things (IoT) enables a myriad of applications by interconnecting software to physical objects. The objects range from wireless sensors to robots and include surveillance cameras. The applications are often critical (e.g. physical intrusion detection, fire fighting) and latency-sensitive. On the one hand, such applications rely on specific protocols (e.g. MQTT, COAP) and the network to communicate with the objects under very tight timeframe. On the other hand, anomalies (e.g. communication noise, sensors' failures, security attacks) are likely to occur in open IoT systems and can result by sending false alerts or the failure to properly detect critical events. To address that, IoT systems have to be equipped with anomaly detection processing in addition to the required event detection capability. This is a key feature that enables reliability and efficiency in IoT. However, anomaly detection systems can be themselves object of failures and attacks, and then can easily fall short to accomplish their mission. This paper introduces a Reliable Event and Anomaly Detection Framework for the Internet of Things (READ-IoT for short). The designed framework integrates events and anomalies detection into a single and common system that centralizes the management of both concepts. To enforce its reliability, the system relies on a reputation-aware provisioning of detection capabilities that takes into account the vulnerability of the deployment hosts. As for validation, READ-IoT was implemented and evaluated using two real life applications, i.e. a fire detection and an unauthorized person detection applications. Several scenarios of anomalies and events were conducted using NSL-KDD public dataset, as well as, generated data to simulate routing attacks. The obtained results and performance measurements show the efficiency of READ-IoT in terms of event detection accuracy and real-time processing.",https://ieeexplore.ieee.org/document/9343860/,IEEE Access,2021,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/ACCESS.2018.2882875,RL and ANN Based Modular Path Planning Controller for Resource-Constrained Robots in the Indoor Complex Dynamic Environment,IEEE,Journals,"Traditional Reinforcement Learning (RL) approaches are designed to work well in static environments. In many real-world scenarios, the environments are complex and dynamic, in which the performance of traditional RL approaches may drastically degrade. One of the factors which results in the dynamicity and complexity of the environment is a change in the position and number of obstacles. This paper presents a path planning approach for autonomous mobile robots in a complex dynamic indoor environment, where the dynamic pattern of obstacles will not drastically affect the performance of RL models. Two independent modules, collision avoidance without considering the goal position and goal-seeking without considering obstacles avoidance, are trained independently using artificial neural networks and RL to obtain their best control policies. Then, a switching function is used to combine the two trained modules for realizing the obstacle avoidance and global path planning in a complex dynamic indoor environment. Furthermore, this control system is designed with a special focus on the computational and memory requirements of resource-constrained robots. The design was tested in a real-world environment on a mini-robot with constrained resources. Along with the static and dynamic obstacles' avoidance, this system has the ability to achieve both static and dynamic targets. This control system can also be used to train a robot in the real world using RL when the robot cannot afford to collide. Robot behavior in the real ground shows a very strong correlation with the simulation results.",https://ieeexplore.ieee.org/document/8543176/,IEEE Access,2018,ieeexplore
10.1109/81.747195,Reaction-diffusion CNN algorithms to generate and control artificial locomotion,IEEE,Journals,"In this paper a physiological-behavioral approach to neural processing is used to realize artificial locomotion in mechatronic devices. The task has been realized by using a particular model of reaction-diffusion cellular neural networks (RD-CNN's) generating autowave fronts as well as Turing patterns. Moreover a programmable hardware cellular neural network structure is presented in order to model, generate, and control in real time some biorobots. The programmable hardware implementation gives the possibility of generating locomotion in real time and also to control the transition among several types of locomotion, with particular attention to hexapodes. The approach proposed allows not only the design of walking robots, but also the ability to build structures able to efficiently solve typical problems in industrial automation, such as online routing of objects moved on conveyor belts.",https://ieeexplore.ieee.org/document/747195/,IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications,Feb. 1999,ieeexplore
10.1109/TASE.2014.2377791,RoboEarth Semantic Mapping: A Cloud Enabled Knowledge-Based Approach,IEEE,Journals,"The vision of the RoboEarth project is to design a knowledge-based system to provide web and cloud services that can transform a simple robot into an intelligent one. In this work, we describe the RoboEarth semantic mapping system. The semantic map is composed of: 1) an ontology to code the concepts and relations in maps and objects and 2) a SLAM map providing the scene geometry and the object locations with respect to the robot. We propose to ground the terminological knowledge in the robot perceptions by means of the SLAM map of objects. RoboEarth boosts mapping by providing: 1) a subdatabase of object models relevant for the task at hand, obtained by semantic reasoning, which improves recognition by reducing computation and the false positive rate; 2) the sharing of semantic maps between robots; and 3) software as a service to externalize in the cloud the more intensive mapping computations, while meeting the mandatory hard real time constraints of the robot. To demonstrate the RoboEarth cloud mapping system, we investigate two action recipes that embody semantic map building in a simple mobile robot. The first recipe enables semantic map building for a novel environment while exploiting available prior information about the environment. The second recipe searches for a novel object, with the efficiency boosted thanks to the reasoning on a semantically annotated map. Our experimental results demonstrate that, by using RoboEarth cloud services, a simple robot can reliably and efficiently build the semantic maps needed to perform its quotidian tasks. In addition, we show the synergetic relation of the SLAM map of objects that grounds the terminological knowledge coded in the ontology.",https://ieeexplore.ieee.org/document/7015601/,IEEE Transactions on Automation Science and Engineering,April 2015,ieeexplore
10.1109/ACCESS.2020.2992701,Robot Formation Control Based on Internet of Things Technology Platform,IEEE,Journals,"The cooperative control technology of robot formation can sense all kinds of external environment in real time. It is a multi-functional control and management system including visual recognition, task management execution and distribution, behavior decision-making and so on. It can easily adapt to all kinds of harsh environment. In order to meet the efficient response requirements of robot formation control, a real-time transmission system of robot cooperative motion control is built based on the Internet of things platform, which collects and feeds back the trajectory of multiple robots. Through particle swarm optimization deep learning algorithm, more accurate identification, prediction and guidance of the robot's next action. Finally, the simulation of robot formation motion is established by MATLAB software, which verifies the feasibility of particle swarm optimization deep learning neural network algorithm under the Internet of things technology. Compared with the traditional robot formation control method, the optimized control method has faster convergence speed, smaller error and more accurate position, which provides method guidance for the accuracy and efficiency of robot formation control technology.",https://ieeexplore.ieee.org/document/9087868/,IEEE Access,2020,ieeexplore
10.1109/TSMCB.2012.2192107,Robust Multiperson Detection and Tracking for Mobile Service and Social Robots,IEEE,Journals,"This paper proposes an efficient system which integrates multiple vision models for robust multiperson detection and tracking for mobile service and social robots in public environments. The core technique is a novel maximum likelihood (ML)-based algorithm which combines the multimodel detections in mean-shift tracking. First, a likelihood probability which integrates detections and similarity to local appearance is defined. Then, an expectation-maximization (EM)-like mean-shift algorithm is derived under the ML framework. In each iteration, the E-step estimates the associations to the detections, and the M-step locates the new position according to the ML criterion. To be robust to the complex crowded scenarios for multiperson tracking, an improved sequential strategy to perform the mean-shift tracking is proposed. Under this strategy, human objects are tracked sequentially according to their priority order. To balance the efficiency and robustness for real-time performance, at each stage, the first two objects from the list of the priority order are tested, and the one with the higher score is selected. The proposed method has been successfully implemented on real-world service and social robots. The vision system integrates stereo-based and histograms-of-oriented-gradients-based human detections, occlusion reasoning, and sequential mean-shift tracking. Various examples to show the advantages and robustness of the proposed system for multiperson tracking from mobile robots are presented. Quantitative evaluations on the performance of multiperson tracking are also performed. Experimental results indicate that significant improvements have been achieved by using the proposed method.",https://ieeexplore.ieee.org/document/6187748/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2012,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/21.61208,Satisficing feedback strategies for local navigation of autonomous mobile robots,IEEE,Journals,"A general approach to the local navigation problem for autonomous mobile robots (AMRs) is presented and its application to omnidirectional and conventionally steered wheelbases is described. The problem of driving an AMR to a goal in an unknown environment is formulated as a dynamic feedback control problem in which local feedback information is used to make steering decisions while the AMR is moving. To obtain a computationally tractable algorithm, a class of satisficing feedback strategies that generate reasonable, collision-free trajectories to the goal using simplified representations of the AMR dynamics and constrains is proposed. Realizations of the feedback strategy are presented and illustrated by simulation under the assumptions of perfect feedback information and zero servo error. Straightforward extensions of the approach to handle uncertainties in real systems are briefly described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/61208/,"IEEE Transactions on Systems, Man, and Cybernetics",Nov.-Dec. 1990,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/LRA.2020.3013848,Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?,IEEE,Journals,"Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCC<sub>Succ</sub> from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.",https://ieeexplore.ieee.org/document/9158349/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/TCAD.2020.3012864,StereoEngine: An FPGA-Based Accelerator for Real-Time High-Quality Stereo Estimation With Binary Neural Network,IEEE,Journals,"Stereo estimation is essential to many applications such as mobile autonomous robots, most of which ask for real-time response, high energy, and storage efficiency. Deep neural networks (DNNs) have shown to yield significant gains in improving accuracy. However, these DNN-based algorithms are challenging to be deployed on energy and resource-constrained devices due to the high computational complexities of DNNs. In this article, we present StereoEngine, a fully pipelined end-to-end stereo vision accelerator that computes accurate dense depth in a real-time and energy-efficient manner. An efficient stereo algorithm is developed and optimized for a high-quality hardware-friendly implementation, that leverages binary neural network (BNN) to learn discriminative binary descriptors to improve the disparity. The design of StereoEngine is a standalone DNN-based stereo vision system where all processing procedures are implemented on a hardware platform. The effectiveness of StereoEngine is evaluated by comprehensive experiments. Compared with software-based implementations on the highend and embedded Nvidia GPUs, StereoEngine achieves up to 3×, 13×, and 50× speedups, as well as up to 211×, 58×, and 73× energy efficiency improvement, respectively. Furthermore, StereoEngine achieves leading accuracy when compared to state-of-the-art hardware implementations on the challenging KITTI dataset.",https://ieeexplore.ieee.org/document/9211569/,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,Nov. 2020,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2019.2939195,Toward a Clustering-Based Approach for Self-Adjusting Impact Factors in Robotic Control Model,IEEE,Journals,"In mobile robotic control models, control parameters are always generated by sensors' information and a set of Impact Factors (IFs, such as the P-value in the PID model). The IFs take forms of fixed coefficients in control models and need to be pre-defined at design-time. However, when operating in an open environment, IFs of the control model are expected to be adjusted automatically at run-time in order to adapt to the environment changes and improve the operation of robotics. This paper presents a clustering-based approach to continuously updating the IFs in robot control model. The proposed approach utilizes the density-based clustering method to classify environmental changes based on the effects of these changes on robots. In each cluster, the regression method is designed to learn the relationship between IFs and environment changes, and therefore generate corresponding IF adjustment model. Such approach can decrease the mutual interference of environmental changes and enhance the rationality of robotic actions. The paper presents the self-adjusting framework and designs corresponding IFs update algorithms. This paper develops robotics path-following scenario and object-following scenario in open environment and conducts experiments to evaluate the effectiveness of the proposed approach. The results show that the proposed approach has faster response to environmental changes than DQN and MPC approaches, along with a lower deviation of robot's actions.",https://ieeexplore.ieee.org/document/8822939/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2020.3046730,Tracking In-Cabin Astronauts Using Deep Learning and Head Motion Clues,IEEE,Journals,"A person-following robot is under development for astronaut assistance on the Chinese Space Station. Real-time astronaut detection and tracking are the most important prerequisites for in-cabin flying assistant robots so that they can follow a specific astronaut and offer him/her assistance. In the limited space in the space station cabin, astronauts stand close to each other when working collaboratively; thus, large regions of their bodies tend to overlap in the image. In addition, because astronauts wear the same clothes most of the time, it is difficult to distinguish an individual astronaut using human body features. In this paper, we distinguish the astronauts by tracking their heads in the image. A deep learning model trained using big data is proposed for effective head detection. In addition, a motion model based on spatial clues is combined with the head detection results to track astronauts in the scene. A complete pipeline of the algorithm has been implemented and run efficiently on the Tegra X2 embedded AI microprocessor. A set of experiments were carried out and successfully validated the effectiveness of the proposed tracking algorithm. This algorithm is a step toward the implementation of robot assistants, especially in resource-limited environments.",https://ieeexplore.ieee.org/document/9305234/,IEEE Access,2021,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/JSEN.2020.3024094,k-Nearest Neighbor Classification for Pattern Recognition of a Reference Source Light for Machine Vision System,IEEE,Journals,"The design of machine vision applications allows automatic inspection, measuring systems, and robot guidance. Typical applications of industrial robots are based on no-contact sensors to give the robot information about the environment. Robot's machine vision requires photosensors or video cameras to make intelligent decisions about its localization. Video cameras used as image-capturing equipment are too costly in comparison with optical scanning systems (OSS). The OSS system provides spatial coordinates measurements that can be exploited to solve a wide variety of structural problems in real-time. Localization and guidance using machine learning (ML) techniques offer advantages due to signals captured can be transformed and be reduced for processing, storage, and displaying. The use of algorithms of ML enhances the performance of the optical system based on localization and guidance. Feature extraction represents an important part of ML techniques to transform the original raw data onto a low-dimensional subspace and holding relevant information. This work presents an improvement of an optical system based on <i>k</i>-nearest neighbor ( <i>k</i>-NN) technique to solve the object detection and localization problem. The utility of this improvement allows the optical system can discriminate between the reference source and the optical noise or interference. The OSS system presented in this article has been implemented in structural health monitoring to measure the angular position even under “lighting and weather conditions”. The feature extraction techniques used in this article were linear predictive coding (LPC), quartiles ( <i>Q</i><sub>iquartile</sub>), and autocorrelation coefficients (ACC). The results of using <i>k</i>-NN and autocorrelation coefficients and quartiles predicted more than 98% of correct classification by using a reference source light as a class 1 and a light bulb as an optical noise and called class 2.",https://ieeexplore.ieee.org/document/9195874/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/AIID51893.2021.9456574,3D scene geometry estimation method of substation inspection robot based on lightweight neural network,IEEE,Conferences,"Understanding 3D scene geometry from video is a basic subject of visual perception. It includes many classic computer vision tasks, such as depth recovery, traffic estimation, visual odometer. Recent work has proved that deep learning can be applied to scene understanding problems. But they all have some inherent limitations. For example, they need stereo cameras as additional devices for data acquisition, or can't explicitly deal with non-rigid and occlusion. The environment in the substation is complex, and there are many devices. In the working process of inspection robot, the target is very easy to be blocked, and it is difficult to deploy directly by traditional methods. In addition, the real-time performance of neural network is very important for electric inspection robot. In this paper, 3D scene geometry estimation method of substation inspection robot is proposed, which consists of two main parts: GeoNet module and pruning module. Experiments show that the proposed method can be effectively applied to electric inspection robot.",https://ieeexplore.ieee.org/document/9456574/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/WCICA.2016.7578819,3D vision based fast badminton localization with prediction and error elimination for badminton robot,IEEE,Conferences,"In this paper, the problem of fast badminton localization problem is investigated for a class of badminton robots. More precisely, a manifold-learning based localization method is implemented for the improvement of hitting accuracy and effectiveness. Based on the localization results, a novel badminton trajectory prediction algorithm is designed based on 3D Vision in the real world. Furthermore, clock-synchronization combined with motion compensation methods are also proposed to better localization error elimination. In the end, the validity and usefulness of our proposed algorithm is demonstrated by numerical experiments.",https://ieeexplore.ieee.org/document/7578819/,2016 12th World Congress on Intelligent Control and Automation (WCICA),12-15 June 2016,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CNNA.1998.685360,A CNN stereo vision hardware system for autonomous robot navigation,IEEE,Conferences,"The high parallel analogue processing rate makes the cellular neural networks paradigm really useful in such a problems where real-time replies to external stimuli are required. The development of an effective system for autonomous robot navigation can find a valid support from this research. Moreover, the growth of new CNN algorithms can afford the necessary feedback to the hardware developers to improve their realisations. In this paper some measurements of a stereo-vision algorithm on a CNN hardware implementation (the 720DPCNN system) are given.",https://ieeexplore.ieee.org/document/685360/,1998 Fifth IEEE International Workshop on Cellular Neural Networks and their Applications. Proceedings (Cat. No.98TH8359),14-17 April 1998,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/RTCSA.2018.00012,A Case Study of Cyber-Physical System Design: Autonomous Pick-and-Place Robot,IEEE,Conferences,"Although modern robots in warehousing systems can perform adequately in a goods-to-person model using hand-designed algorithms that are specialized to a particular environment, developing a robotic system that is capable of handling new products at an inexpensive cost remains a challenge. A conspicuous example of this challenge is seen in Amazon's use of autonomous robots to fetch customers' orders in their massive warehouses. To encourage advance in this technology, Amazon organized the competition, Amazon Picking Challenge that asked participants to develop their own hardware and software for the general task of picking a designated set of products from inventory shelves and then placing them at a target location (called a pick-and-place task). Current technology for pick-and-place tasks is still insufficient to meet the demand for low-cost automation. Handling awkward or oddly shaped object must still depend on hand-programming or specialized robotic systems, making manufacturing automation less flexible and expensive. In this paper, we shall present the design and implementation of a software system that is a step in advancing the technology toward full automation at reasonable costs. Our system integrates a set of state-of-the-art techniques in computer vision, deep-learning, trajectory optimization, visual servoing to create a library of skills that can be composed to perform a variety of robotic tasks. We demonstrate the capability of our system for performing autonomous pick-and-place tasks with an implementation using Hoppy, an industrial robotic arm in an environment similar to the Amazon Picking Challenge.",https://ieeexplore.ieee.org/document/8607230/,2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA),28-31 Aug. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICICSP54369.2021.9611881,A Multi-agent Reinforcement Learning Routing Protocol in Mobile Robot Network,IEEE,Conferences,"Robots are now essential in unreachable, repeated, and dangerous real-world applications where they take place of human beings. One of the important capabilities of a multi-robot system is that it should be able to form an autonomous robot network to transmit information. However, due to the limited communication capability of a single robot, the highly variable environment where robots work, and the mobility of the robots, it is difficult for them to exchange information with each other in need. In this article, we propose a novel robot network routing protocol based on multi-agent reinforcement learning called MAQR. The robot nodes can deliver packets cooperatively. The mobility factor, buffer status, and packet delay of neighbor nodes are taken into consideration. We design a reliability model for a robot agent to make reliable routing decisions. We also design an adaptive exploration-exploitation method to balance the convergence speed, solution space as well as network fluctuation. The routing algorithm has been implemented and evaluated in simulation. Results show that MAQR can provide less packet delay, less average queue length and higher delivery ratio than other Q-learning based routing protocol.",https://ieeexplore.ieee.org/document/9611881/,2021 4th International Conference on Information Communication and Signal Processing (ICICSP),24-26 Sept. 2021,ieeexplore
10.1109/CSICC52343.2021.9420614,A New Approach for Mapping of Soccer Robot Agents Position to Real Filed Based on Multi-Core Fuzzy Clustering,IEEE,Conferences,"Mapping the position of soccer robot agents to a real field, is one of the essential issues in the practical implementation of scientific contributions in this context. The lack of a proper assignment affects the scientific implementation of many subjects, such as routing, obstacle avoidance, and robot guidance. For this reason, the use of a clustering method is proposed in this article. Upon the entrance of a new agent, its position is mapped to the real field based on the clustering algorithm. After this mapping, the system begins to work according to the position of the agents, which is defined as the position of the centers of the clusters, as well as the rules defined in the knowledge-base. Considering the unknown and dynamic environment of the robot, some objects inherit common traits from multiple clusters. One reasonable solution for considering the cluster overlaps is to assign a set of membership degrees to each of them. Multiple membership degree assignments result from the fuzzy nature of the clusters. Due to the reduction of segmentations and the shrinkage of the search space, fuzzy clustering generally faces less computational overhead, while the identification and handling of vague, noisy, and outlier data also become much easier in them. The approach of the proposed method is based on the feasibility ideas and uses multi-core learning to identify clusters with complex data structures. The feasibility score of each data represents the percentages of the properties that data inherits from the clusters. Automatically adjusting the weights of the cores in an optimization framework, the proposed method avoids the damage caused by problems such as adopting inefficient cores, or irrelevant features.",https://ieeexplore.ieee.org/document/9420614/,"2021 26th International Computer Conference, Computer Society of Iran (CSICC)",3-4 March 2021,ieeexplore
10.1109/ISIC.2007.4450948,A New Color Based Optical Flow Algorithm for Environment Mapping Using a Mobile Robot,IEEE,Conferences,"Environment mapping from a video sequence is considered to be one of the most important problems in computer vision because of its application in surveillance, virtual reality, autonomous navigation, multimedia communications, medical prognosis, etc. In this paper, we have presented an optical flow based method for environment mapping. It uses a new color based optical flow computation technique. The camera, which is mounted on a mobile robot, is kept perpendicular to the direction of motion, and the captured set of images is used to compute the dense depth map. We have used a Kalman filter to denoise the depth map.",https://ieeexplore.ieee.org/document/4450948/,2007 IEEE 22nd International Symposium on Intelligent Control,1-3 Oct. 2007,ieeexplore
10.1109/FUZZ48607.2020.9177557,A Novel Self-Organizing PID Approach for Controlling Mobile Robot Locomotion,IEEE,Conferences,"A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID) control system is proposed in this paper. The proposed system consists of a pair of control and reference models, both of which are implemented by a first-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. The SOF-PID controller self-organizes and self-updates the structures and meta-parameters of both the control and reference models during the control process ""on the fly"". This gives the SOF-PID control system the capability of quickly adapting to entirely new operating environments without a full re-training. Moreover, the SOF-PID control system is free from user- and problem-specific parameters and is entirely data-driven. Simulations and real-world experiments with mobile robots demonstrate the effectiveness and validity of the proposed SOF-PID control system.",https://ieeexplore.ieee.org/document/9177557/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/RAMECH.2011.6070484,A Q-learning based Cartesian model reference compliance controller implementation for a humanoid robot arm,IEEE,Conferences,This paper presents the implementation (real time and simulation) of a model-free Q-learning based discrete model reference compliance controller for a humanoid robot arm. The Reinforcement learning (RL) scheme uses a recently developed Q-learning scheme to develop an optimal policy on-line. The RL Cartesian (x and y) tracking controller with model reference compliance was implemented using two links (shoulder flexion and elbow flexion joints) of the right arm of the humanoid Bristol-Elumotion-Robotic-Torso II (BERT II) torso.,https://ieeexplore.ieee.org/document/6070484/,"2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM)",17-19 Sept. 2011,ieeexplore
10.1109/IJCNN.2003.1224077,A RAM-based neural network for collision avoidance in a mobile robot,IEEE,Conferences,"A RAM-based neural network is being developed for a mobile robot controlled by a simple microprocessor system. Conventional neural networks often require a powerful and sophisticated computer system. Training a multi-layer neural network requires repeated presentation of training data, which often results in very long learning time. The goal for this paper is to demonstrate that RAM-based neural networks are a suitable choice for embedded applications with few computational resources. This functionality is demonstrated in a simple robot powered by an 8051 microcontroller with 512 bytes of RAM. The RAM-based neural network allows the robot to detect and avoid obstacles in real time.",https://ieeexplore.ieee.org/document/1224077/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2006.340185,A Study of real-time EMG-driven Arm Wrestling Robot,IEEE,Conferences,"An EMG-driven arm wrestling robot (AWR) is being developed in our laboratories for the purposes of studying neuromuscular control of arm movements. The AWR arm have 2-DOF, integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera, is used to estimate tension developed by individual muscles based on recorded electromyograms (EMGs). The surface electromyographic signal form the upper limb is sampled from a real player in same conditions. By using the method of wavelet packet transformation (WPT) and auto regressive model (AR), the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments. The purpose of this paper is to describe the design objectives, fundamental components and implementation of our real-time, EMG-driven AWR arm.",https://ieeexplore.ieee.org/document/4142107/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICRA.2012.6225245,A depth space approach to human-robot collision avoidance,IEEE,Conferences,"In this paper a real-time collision avoidance approach is presented for safe human-robot coexistence. The main contribution is a fast method to evaluate distances between the robot and possibly moving obstacles (including humans), based on the concept of depth space. The distances are used to generate repulsive vectors that are used to control the robot while executing a generic motion task. The repulsive vectors can also take advantage of an estimation of the obstacle velocity. In order to preserve the execution of a Cartesian task with a redundant manipulator, a simple collision avoidance algorithm has been implemented where different reaction behaviors are set up for the end-effector and for other control points along the robot structure. The complete collision avoidance framework, from perception of the environment to joint-level robot control, is presented for a 7-dof KUKA Light-Weight-Robot IV using the Microsoft Kinect sensor. Experimental results are reported for dynamic environments with obstacles and a human.",https://ieeexplore.ieee.org/document/6225245/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ROBIO.2007.4522431,A fast robot feedback decision algorithm,IEEE,Conferences,"Intelligence decision is an important subject for robotic intelligence system. This paper presents an experimental research work about robotic intelligence decision, where a fast information reduction with feedback features is proposed to solve robot intelligent decision and judgement issue. We have investigated the properties satisfied by the robotic information processing and decision process: if an attribute is the only discerning of multiple information objects, this attribute can be taken as the first core attribute, and can be reused in an iterative information reduction process to get another core attribute; furthermore, a feedback method can be used to enhance this iterative processing capability in real-time robots cooperative systems. Out feedback control method is somewhat dynamical and iterative process, and the investigated properties are utilized to design the feedback control laws. We have set up the relative experimental platform, and the experimental results show that our fast robot feedback decision algorithm is efficient and effective, which can be used in multiple robots collaborative missions.",https://ieeexplore.ieee.org/document/4522431/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICAL.2010.5585308,A framework for coordination and navigation of multi-robot systems,IEEE,Conferences,"In this paper, a novel framework is proposed to incorporate task assignment, path planning, and tracking control of a multi-robot system. The dynamic task assignment of multi-robots is achieved using a self-organizing map based feature. The real-time collision-free robot path is generated from a neuro-dynamics network through sensor measurement and responding immediately to dynamic elements in the environment including the robot, the target, and obstacles. The tracking control is accomplished by a neuro-dynamics and back-stepping based model. This type of control is able to generate smooth, bounded acceleration control signals for a non-holonomic mobile robot to track the reference path generated by the path planner. Experiments under various situations demonstrated the effectiveness of this integrated system.",https://ieeexplore.ieee.org/document/5585308/,2010 IEEE International Conference on Automation and Logistics,16-20 Aug. 2010,ieeexplore
10.1109/SSCI.2016.7849899,A fuzzy-based machine learning model for robot prediction of link quality,IEEE,Conferences,"With foresight into the state of the wireless channel, a robot can make various optimization decisions with regards to routing packets, planning mobility paths, or switching between diverse radios. However, the process of predicting link quality (LQ) is nontrivial due to the streaming and dynamic nature of radio wave propagation, which is complicated by robot mobility. Due to robot movement, the wireless propagation environment can change considerably in terms of distance, obstacles, noise, and interference. Therefore, LQ must be learned and regularly updated while the robot is online. However, the existing fuzzy-based models for assessing LQ are non-adaptable due to the absence of any learning mechanism. To address this issue, we introduce a fuzzy-based prediction model designed for the efficient online and incremental learning of LQ. The unique approach uses fuzzy logic to infer LQ based on the collective output from a series of offset classifiers and their posterior probabilities. In essence, the proposed model leverages machine learning for extracting the underlying functional relationship between the input and output variables, but deeper inferences are made from the output of the learning algorithms using fuzzy logic. Wireless link data from a real-world robot network was used to compare the model with the traditional linear regression approach. The results show statistically significant improvements in three out of the six real-world indoor and outdoor environments where the robot operated. Additionally, the novel approach offers a number of other benefits, including the flexibility to use fuzzy logic for model tuning, as well as the ability to make implementation efficiencies in terms of parallelization and the conservation of labeling resources.",https://ieeexplore.ieee.org/document/7849899/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICCE-Asia.2016.7804752,A hardware architecture of face detection for human-robot interaction and its implementation,IEEE,Conferences,"This paper presents hardware architecture with low-complexity face detection (FD) and parallel processing of local binary pattern (LBP) generation and adaptive boosting (AdaBoost) algorithm using Haar features for the intelligent service robot system. We designed a fully pipelined architecture implemented with the design techniques, such as variable image scaling and parallel processing multiple classifiers without integral image generation, on the FPGA platform. The proposed architecture enables a real-time FD processing for a VGA video at 30 frames per second.",https://ieeexplore.ieee.org/document/7804752/,2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),26-28 Oct. 2016,ieeexplore
10.1109/SKIMA.2016.7916262,"A hybrid real-time EMG intelligent rehabilitation robot motions control based on Kalman Filter, support vector machines and particle swarm optimization",IEEE,Conferences,"Intelligent Control of agent autonomous rehabilitation robot is a very complex problem, especially for stroke patients' treatments and dealing with real-time EMG sensors readings of muscles activity states and transfer between real-time Human motions to interface with rehabilitation robot agent or assisteddevice. The field of Artificial Intelligence and neural networks plays a critical role in modern intelligent control interfaces for robot devices. This paper presents a novel hybrid intelligent robot control that acts as human-robot interaction, where it depends on real-time EMG sensor patients data and extracted features along with estimated knee joint angles from Extended Kalman Filter method are used for training the intelligent controller using support vector machines trained with Adatron Learning algorithm for handling huge data values of sensors readings. Moreover, the proposed platform for rehabilitation robot agent is tested in the framework of the NAO Humanoid Robot agent along with Neurosolutions Toolkit and Matlab code. The average overall accuracy of the proposed intelligent motion SVM-EKF controller shows average high performance that approaches average 96% of knee motions classifications and also good performance for comparing Extended Kalman filter knee joint angles estimations and real EMG human knee joint angles in the framework of Human Walk Gait cycle. Also, the basic enhancement of proposing PSO optimization technique for robot knee motion is discussed for future improvements. The overall algorithm, methodology and experiments are presented in this paper along with future work.",https://ieeexplore.ieee.org/document/7916262/,"2016 10th International Conference on Software, Knowledge, Information Management & Applications (SKIMA)",15-17 Dec. 2016,ieeexplore
10.1109/ICCAE.2010.5451340,A low cost microcontroller implementation of neural network based hurdle avoidance controller for a car-like robot,IEEE,Conferences,This paper describes the implementation of a neural network based hurdle avoidance controller for a car like robot using a low cost single chip 89C52 microcontroller. The neural network is the multilayer feed-forward network with back propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that up-to twenty neurons in hidden layer can be deployed with the proposed technique using a single 89C52 microcontroller. The vehicle is tested in various environments containing obstacles and is found to avoid obstacles in its path successfully.,https://ieeexplore.ieee.org/document/5451340/,2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE),26-28 Feb. 2010,ieeexplore
10.1109/ROBOT.2001.933206,A method for obstacle avoidance and shooting action of the robot soccer,IEEE,Conferences,"A fuzzy-obstacle-avoidance-path algorithm for obstacle avoidance and a procedure for the shooting action of a soccer robot based on this algorithm are proposed. This algorithm contains a fuzzy system that is used to estimate the rotational velocity of the soccer robot. To demonstrate the effectiveness and applicability of the proposed method, two simulations are presented and a real-time implementation is developed.",https://ieeexplore.ieee.org/document/933206/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/IROS.1997.649083,A mobile robot for service use: behaviour simulation system and intelligent control,IEEE,Conferences,"The structure of hardware and software of AI control system of a mobile robot for service use are described. Hardware of the mobile robot described include an autonomous wheel vehicle and a five degree of freedom manipulator. The software of the AI control system is based on soft computing including fuzzy control rules, fuzzy neural network and genetic algorithms. The intelligent control of cooperative motion between the autonomous vehicle and manipulator realises flexible operations such as navigation of a mobile robot in presence of static and dynamic obstacles, processes of opening door in rooms and pushing buttons of an elevator. New hierarchical structure of the AI control system includes direct human-robot communication line based on natural language and cognitive graphics, and a generator of virtual reality for simulation of artificial life conditions for the mobile service robot. Simulation and experimental results of navigation and technical operations with the manipulator mobile service robot used in office building are described.",https://ieeexplore.ieee.org/document/649083/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICIPS.1997.669208,A neural network approach to the elimination of road shadow for outdoor mobile robot,IEEE,Conferences,"A new method of road tracking oriented environmental noise elimination is presented for implementing navigation and control of land autonomous vehicles (ALV). The concept of vision based environmental noise is firstly introduced for the purpose of road and/or obstacle edge detection. Then, a representation of pyramid is proposed for vision processing. Furthermore, a fuzzy neural network is designed and implemented to recognize the environmental noises such as shadow and water prints on the road. With structure optimization by genetic algorithm and special training by classified samples, we use the network to guide our THMR-III (Tsinghua University Mobile Robot, Model 3) in the outdoor real world. Experiments have shown good properties for the ALV's ""perception-action"" behaviors, including obstacle avoidance, road following, wandering, etc. Although the work is still going on, we can see from the present results the better quality, adaptability and robustness of the above approach.",https://ieeexplore.ieee.org/document/669208/,1997 IEEE International Conference on Intelligent Processing Systems (Cat. No.97TH8335),28-31 Oct. 1997,ieeexplore
10.1109/IACC.1995.465839,A neural network system that controls and plans paths for a robot,IEEE,Conferences,"Proposes to solve the problems of direct/inverse kinematics and control of trajectories by multilevel perceptrons. The authors' solution admits a parallel implementation in real time. It does not need either to solve kinematic equations or robot trajectories, because it learns gradually by examples adaptively. The control system consists of different networks each of which specialises in solving a particular problem. This structure enables a modular approach to the problem accelerating convergence. The system obtains an acceptable trajectory and gives a parallel solution that could be used in real-time applications.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/465839/,Proceedings of IEEE/IAS International Conference on Industrial Automation and Control,5-7 Jan. 1995,ieeexplore
10.1109/ICSMC.1995.538227,A neural network-based robot safety system,IEEE,Conferences,"This paper presents a new approach for real-time robot safety system based on artificial neural networks. This approach includes a neural network detection unit and a neural network decision unit, implemented at an intermediate and high level of sensory processing, respectively. Both the detection and decision units have been implemented and tested by simulation, both separately and as an integrated unit. The response time of the integrated system measured on the 90 MHz, P5 microprocessor is less than 11 ms, and the correctness of safety decisions is 97%.",https://ieeexplore.ieee.org/document/538227/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1049/cp:19990285,A neural vision based controller for a robot footballer,IET,Conferences,"Robot football is growing in popularity both as a research topic and as a sporting event. The football setting provides rich interaction possibilities and a ready source of competition in an environment containing both predictable and non-deterministic elements. Successful players must be able to react quickly in real time, exhibit multiple competences and choose between several possibly conflicting goals. Opportunities exist to explore reflexive behaviour, strategic behaviour and even communication and social behaviour in team events. At the same time, artificial neural networks are increasingly being used in robot controllers to explore new biologically-inspired ideas relating to perception, memory and motor control. The research described in this paper attempts to combine these two areas of study to produce a framework for a neurally based and visually guided football-playing controller. A controller architecture is proposed in which a small set of high-level features in the robot's environment are extracted from raw image data by using a feedforward neural network. These feature signals, collectively termed the ""feature bus"", are then available for use by other controller modules. The feature bus signals are sufficiently general and high-level to be used with many different controller strategies, and their low dimensionality compared to the raw visual input makes the implementation of learning controllers more feasible.",https://ieeexplore.ieee.org/document/791354/,"Image Processing And Its Applications, 1999. Seventh International Conference on (Conf. Publ. No. 465)",13-15 July 1999,ieeexplore
10.1109/SBRN.1998.730998,A neural-network based approach for recognition of pose and motion gestures on a mobile robot,IEEE,Conferences,"Since a variety of changes in both robotic hardware and software suggests that service robots will soon become possible, to find ""natural"" ways of communication between human and robots is of fundamental importance for the robotic field. The paper describes a gesture-based interface for human-robot interaction, which enables people to instruct robots through easy-to-perform arm gestures. Such gestures might be static pose gestures, which involve only a specific configuration of the person's arm, or they might be dynamic motion gestures, that is, they involve motion (such as waving). Gestures are recognized in real-time at approximate frame rate, using neural networks. A fast, color-based tracking algorithm enables the robot to track and follow a person reliably through office environments with drastically changing lighting conditions. Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned, and the robot picks up trash which it then delivers to the nearest trash-bin.",https://ieeexplore.ieee.org/document/730998/,Proceedings 5th Brazilian Symposium on Neural Networks (Cat. No.98EX209),9-11 Dec. 1998,ieeexplore
10.1109/IJCNN.2015.7280750,A neurocomputational model implemented on humanoid robot for learning action selection,IEEE,Conferences,"Computational modeling of neural circuits enhances our comprehension of brain functions. In addition to the simulation of the models which helps to anticipate cognitive processes, embodiment of these models is essential. Such embodiment would provide the setting to explain neural functioning ongoing in real environments under oncoming sensory information besides giving opportunity of implementation of intelligent systems. Even studies pursued in neuroscience seem far from achieving all these aims in intelligent systems, the pre-results using cognitive models are faster than animal experiments in leading further the understanding of cognitive processes and designing related experiments. In this study, a computational model of basal ganglia, thalamus and cortex for action selection is extended with the point neuron approach to obtain a more realistic method to investigate the model in real time task on humanoid robot platform, Darwin-Op. The spiking neural network model of cortex consists of channels for each action to be elected and plastic alI-to-alI connections from the sensory stimuli to the basal ganglia structures which are modulated with reward. In the task, the sensory inputs, namely colors, are presented to the humanoid robot and it is expected that these sensory inputs would be associated with the predefined actions by modulating the connections. Furthermore, the rearrangement of these associations with reward is performed after learning is accomplished. In this way, the embodiment of computational-model provided more information on the evolution of connections through reward based learning in the action selection circuit.",https://ieeexplore.ieee.org/document/7280750/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/WINCOM50532.2020.9272477,A new middleware for managing heterogeneous robot in ubiquitous environments,IEEE,Conferences,"Heterogeneity is one of the main issues for the deployment of the Industry 4.0. This is due to the diversity in the available robots and the IIoT devices. These equipments use different programming languages and communication protocols. To make the integration of such equipments easy, we propose TalkRoBots, a middleware that allows heterogeneous robots and IIoT devices to communicate together and exchange data in a transparent way. The middleware was experimented in a real scenario with different robots that demonstrate its efficiency.",https://ieeexplore.ieee.org/document/9272477/,2020 8th International Conference on Wireless Networks and Mobile Communications (WINCOM),27-29 Oct. 2020,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/ICMLC.2011.6016883,A novel intelligent control system design for a humanoid robot,IEEE,Conferences,"This paper presents the design of an intelligent control system for a humanoid robot. A novel fuzzy cerebellar model articulation controller (FCMAC) is proposed; this controller incorporates the fuzzy system inference rule with a CMAC fast learning ability. This FCMAC is a generalization network; in some special cases it can be reduced to a fuzzy neural network or a CMAC. This FCMAC is used as the main controller for the trajectory tracking control of the robot. In this robotic system, an inertial navigation system (INS) including gyroscopes and accelerometers is used to measure the robot's attitude and acceleration for modifying the dynamic attitude of the robot. Moreover, a zero moment point (ZMP) compensator is used to on-line adjust the gait trajectories to improve the walking stability. The control system is implemented based on system on a programmable chip (SoPC) technology. Thus, this intelligent control system can achieve real-time on-line closed-loop feedback control of the humanoid robot. Experimental results show that the developed system can achieve favorable control performance for a high-order nonlinear humanoid robot.",https://ieeexplore.ieee.org/document/6016883/,2011 International Conference on Machine Learning and Cybernetics,10-13 July 2011,ieeexplore
10.1109/PEAM.2011.6135058,A novel on-line training solution using a Radial Basis Function Network to modify the inverse kinematic approximation of a robot-vision system,IEEE,Conferences,"This paper describes a new practical approach for approximating the inverse kinematics of a manipulator using an RBFN (Radial Basis Function Network). This neural network with its inherent learning ability can be an effective alternative solution for the inverse kinematics problem where traditional methods are impractical because the manipulator geometry cannot be easily determined, e.g. in a robot-vision system. However, sometimes a well-trained network cannot work effectively in the operational phase because the initial network training occurs in an environment that is not exactly the same as the environment where the system is actually deployed. In this paper, an on-line retraining solution using the Delta rule is presented for systems whose characteristics change due to environmental variations. Moreover, a “free interference rule” is also suggested to avoid learning interference where the training effect of a current training point may upset some of the weights which were trained with previous points. To verify the performance of the proposed approach, a practical experiment has been performed using a Mitsubishi PA10-6CE manipulator observed by a webcam. All application programmes, such as robot servo control, neural network, and image processing tool, were written in C/C++ and run in a real robotic system. The experimental results prove that the proposed approach is effective.",https://ieeexplore.ieee.org/document/6135058/,2011 IEEE Power Engineering and Automation Conference,8-9 Sept. 2011,ieeexplore
10.1109/ICSMC.1999.812484,A paradigm for intelligent motion planning of robot manipulators,IEEE,Conferences,"A paradigm for intelligent motion planning of robot manipulators is presented, and its implementation by some unconventional (AI, soft computing, computational intelligence) techniques is outlined. The article focuses on those aspects that lead, from an intelligent/unconventional point of view, to a unified framework for real-time motion planning, singularities prevention, and/or pseudoinverse robustness.",https://ieeexplore.ieee.org/document/812484/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2014.7090487,A portable stand-alone bi-hemispherical neuronal network model of the cerebellum for adaptive robot control,IEEE,Conferences,"Development of computational models of the brain is relevant not only for deepening our understanding of the biological system but also for potential applications to various engineering problems. In this paper the implementation of a bi-hemispherical neuronal network model of the cerebellum (biCNN) in a stand-alone, portable real time (RT) device is presented. The biCNN is tested during a control engineering application, namely, control of a highly unstable two-wheel balancing robot. The RT device considered is the National Instruments myRIO-1900, which provides flexibility and portability to the biCNN. Execution times obtained with the RT device are compared with a personal computer implementation as reference. The results demonstrate the suitability of the RT implementation of the biCNN for robot control, and provide a successful bridge between the cerebellar research and engineering.",https://ieeexplore.ieee.org/document/7090487/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/ICCAS.2015.7364829,A precise position control of robot manipulator with eight joints,IEEE,Conferences,"We describe a new approach to the design and real-time implementation of an adaptive controller for robotic manipulator based on digital signal processors in this paper. The Texas Instruments DSPs(TMS320C80) chips are used in implementing real-time adaptive control algorithms to provide enhanced motion control performance for dual-arm robotic manipulators. In the proposed scheme, adaptation laws are derived from model reference adaptive control principle based on the improved direct Lyapunov method. The proposed adaptive controller consists of an adaptive feed-forward and feedback controller and time-varying auxiliary controller elements. The proposed control scheme is simple in structure, fast in computation, and suitable for real-time control. Moreover, this scheme does not require any accurate dynamic modeling, nor values of manipulator parameters and payload. Performance of the proposed adaptive controller is illustrated by simulation and experimental results for robot manipulator consisting of dual arm with four degrees of freedom at the joint space and cartesian space.",https://ieeexplore.ieee.org/document/7364829/,"2015 15th International Conference on Control, Automation and Systems (ICCAS)",13-16 Oct. 2015,ieeexplore
10.1109/IROS.1998.727453,A real-time library for the design of hybrid robot control architectures,IEEE,Conferences,"Describes a real-time library providing facilities useful in the design of robot control architectures. The library supports structured creation of reactive and deliberative modules, dynamic modification of relevant real-time parameters, generation of timing fault handlers, measurement and monitoring of execution times. This support enables adaptation of the rate of computation of real-time modules to the rate of change of the external world, and hence better tuning of robot behavior to the world uncertainty and dynamics. The real-time library has been put to work by designing a hybrid control architecture for a robot performing a kitting task. In the prototype experiment described in the paper, a Puma 560 robot manipulator is fed with parts by a small mobile robot. The control architecture governing Puma operations dynamically allocates computational resources to reactive and deliberative modules, according to the task level priorities.",https://ieeexplore.ieee.org/document/727453/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ICAMechS.2013.6681701,A real-time walking robot control system based on Linux RTAI,IEEE,Conferences,"This study developed a real-time control system for a walking robot. The control system for the walking robot should have a real-time operating system, a small size, and extendable IO cards. The PC104 computer is selected due to its small size, reliability and availability of many IO cards. The Linux RTAI is selected because it is an open-source, efficient and hard real-time operating system. The Turbo PMAC PC104 card is used to control motor drivers because its small size, multi-axis synchronization and powerful control functions. Compared with CAN or EtherCAT bus control scheme, this system can easily support motor drivers from different companies. The software is reusable to different robots due to its independence on communication bus protocols and motor drivers. The motor control experiments are provided to show the satisfactory real-time control performance.",https://ieeexplore.ieee.org/document/6681701/,Proceedings of the 2013 International Conference on Advanced Mechatronic Systems,25-27 Sept. 2013,ieeexplore
10.1109/TENCON.2000.888756,A review of real-time software engineering methodologies for developing a wall-climbing robot control firmware,IEEE,Conferences,"Designing and developing software for autonomous robot control system is a challenging task. Issues related to real-time control, embedded system and artificial intelligence are involved in the software development process. This type of software must be developed with proper software methodology or well-defined development process in order to increase the productivity and quality of the software design and software products. This paper presents a review of two real-time software development methodologies and compares their suitability for developing real-time control software for a wall-climbing robot under development at Universiti Teknologi Malaysia (UTM).",https://ieeexplore.ieee.org/document/888756/,2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119),24-27 Sept. 2000,ieeexplore
10.1049/cp.2012.0975,A robot dance system based on real-time beat prediction,IET,Conferences,"In this paper, we present a robot with a system of tracking beats and downbeats from musical audio in real time as well as automatically synthesizing dance motions synchronized to the extracted musical events. And a real-time beat prediction approach improved by an off-line analysis is described, which has positive effects on the estimations of beat and downbeat. We also make an attempt to solve the problem of enabling a robot to understand the played music and accomplish dance compositions intelligently itself. Consequently, the experimental results are quite encouraging and show that our implemented robot, to some extent, has the ability of dancing in time to the music.",https://ieeexplore.ieee.org/document/6492582/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
,A robust control of mobile robot based on sonar sensors,IEEE,Conferences,"This paper describes the design and real implementation of wall following and fuzzy perception concept with a non-holonomic mobile robot named KHAN-Robo. The main focus of this paper is obtaining a fuzzy perception of the environment in the design of each reactive behavior and solving the problem of behavior combination to implement a fuzzy behavior based control architecture. It should be remarked that, the proposed technique of the nonholonomic constraints are considered in the design of each behavior. Furthermore, in order to improve the capabilities of the intelligent control system and its practical applicability, teleoperation and planned behaviors, together with their combination with reactive ones, have been considered. Experimental results, of an application to control the KHAN-Robo autonomous vehicle, demonstrate the robustness of the proposed method.",https://ieeexplore.ieee.org/document/6106329/,"2011 11th International Conference on Control, Automation and Systems",26-29 Oct. 2011,ieeexplore
10.1109/MFI-2003.2003.1232590,A robust real time position and force (hybrid) control of a robot manipulator in presence of uncertainties,IEEE,Conferences,"We examine the living intelligent biological systems and model the computational system components. We consider the situation of a kind of ""blind-tracking"" with constant force/torque by a human hand. The problem involves hand kinematics, hand motor control, and an adaptive judgment method from the position and force/torque reflection of the uncertain hyper plane. In this study, these control levels were designed using neural networks and fuzzy logic technologies. The control levels are coordinated amongst themselves forming the distributed artificial intelligent (DAI) system. The conclusive characteristic of the proposed controller was a one-step-ahead feedback control. This DAI-based control systems was implemented in the RX-90 industrial robot. Certainly these types of control system will help an industry to be autonomous and increase the productivity as well.",https://ieeexplore.ieee.org/document/1232590/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/WCICA.2000.863460,A study on a new robot simulation and monitoring system based on PC,IEEE,Conferences,"A new robot simulation and monitoring system has been developed. Running on Pentium II PCs with Windows 95 operation system and being developed with OpenGL, this system has the capacity of real-time simulating the motion of an industrial robot through 3D animation with ray tracing. Connected with the robot controller via network, users can monitor the behavior of the robot dynamically or even directly control the action of the robot if necessary. By comparing with the traditional off-line programming system, the framework and the functions of this system and the hardware and software platform of the system are described. The principle of 3D-motion simulation and both the geometry modeling and kinematics modeling are discussed in more detail. Finally, the paper summarizes the characteristics of the system and discusses the extension prospect of the system.",https://ieeexplore.ieee.org/document/863460/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/IJCNN.2004.1379924,A virtual exploring mobile robot for left ventricle contour tracking,IEEE,Conferences,"In this paper we describe a totally new and original approach for combining global and local information in medical image processing. We implemented a virtual mobile robot and trained it using fuzzy neural networks to recognize segments of the myocardium while he navigates autonomously around the left ventricle (LV) of the heart. On its journey around the heart, the virtual exploring robot applies appropriate local edge detection to delineate fully automatically the borders of the myocardium. This may sound unconventional but it has proven effective enough to be integrated in a clinical analytical software tool.",https://ieeexplore.ieee.org/document/1379924/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/IROS.1998.724594,A virtual target approach for resolving the limit cycle problem in navigation of a fuzzy behaviour-based mobile robot,IEEE,Conferences,"A virtual target approach is proposed for resolving the limit cycle problem in navigation of a behaviour-based mobile robot. Starting from the onset point of a possible limit cycle path, the real target is switched to a virtual location and the robot is navigated according to the virtual target set up temporarily and the real environment information sensed, until a switching back condition is reached. The condition for switching back to the real target is established using a specific change in the obstacle information sensed. The algorithm is described together with some particular considerations in implementation. Efficiency and effectiveness of the proposed approach are verified through simulation and experiments conducted with a Nomad 200 robot incorporating a fuzzy, behaviour-based controller.",https://ieeexplore.ieee.org/document/724594/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/IROS.2004.1389844,Acquisition of human-robot joint attention through real-time natural interaction,IEEE,Conferences,"Joint attention, a process to attend to the object that the other attends to is supposed to be important for human-robot communication as well as for human-human communication. We propose an architecture for acquiring joint attention within a certain time period for realizing natural human-robot interaction. The architecture has two featured modules: a self-organizing map that makes the leaning time shorter and an automatic visual attention selector that let the agent communicate with a human synchronously. We implemented the proposed architecture in a real robot agent and found that 30 minutes was enough for acquiring joint attention with two objects. We can conclude from preliminary experiments that even if the gaze preference of the robot is different from that of the human caregiver, it can acquire joint attention.",https://ieeexplore.ieee.org/document/1389844/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/DEVLRN.2002.1011736,Action chaining by a developmental robot with a value system,IEEE,Conferences,"A developmental cognitive learning architecture with a value system is proposed for an artificial agent to learn composite behaviors upon the acquisition of basic ones. This work is motivated by researches on classical conditioning in animal learning areas. Compared to former works, the proposed architecture enables an agent to conduct learning in unknown environments through online realtime experiences. All possible perceptions and actions, including even the actual number of classes, are not available until the programming is finished and the robot starts to learn in the real world. Experiments with our SAIL (Self-organizing Autonomous Incremental Learner) robot are reported to show how a trainer instructed (or shaped) the behaviors of the agent through verbal commands.",https://ieeexplore.ieee.org/document/1011736/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/FUZZ-IEEE.2014.6891705,Active interaction control of a rehabilitation robot based on motion recognition and adaptive impedance control,IEEE,Conferences,"Although electromyography (EMG) signals and interaction force have been widely used in patient cooperative or interactive training, the conventional EMG based control usually breaks the process into a patient-driven phase and a separate passive phase, which is not desirable. In this research, an active interaction controller based on motion recognition and adaptive impedance control is proposed and implemented on a six-DOFs parallel robot for lower limb rehabilitation. The root mean square (RMS) features of EMG signals integrating with the support vector machine (SVM) classifier were used to online predict the lower limb intention in advance and to trigger the robot assistance. The impedance control strategy was adopted to directly influence the robot assistance velocity and allow the exercise to follow a physiological trajectory. Moreover, an adaptive scheme learned the muscle activity level in real time and adapted the robot impedance in accordance with patient's voluntary participation efforts. Experimental results on several healthy subjects demonstrated that the lower limb motion intention can be precisely predicted in advance, and the robot assistance mode was also adjustable based on human-robot interaction and muscle activity level of subjects. Comparing with the conventional EMG-triggered assistance methods, such a strategy can increase patient's motivation because the subject's movement intention, active efforts as well as the muscle activity level changes can be directly reflected in the trajectory pattern and the robot assistance speeds.",https://ieeexplore.ieee.org/document/6891705/,2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),6-11 July 2014,ieeexplore
10.1109/ICRoM.2014.6990997,Actor-critic neural network reinforcement learning for walking control of a 5-link bipedal robot,IEEE,Conferences,"Today, researches on adaptive control have focused on bio-inspired learning techniques to deal with real-life applications. Reinforcement Learning (RL) is one of these major techniques, which has been widely used in robot control tasks recently. On the other hand, artificial neural networks are an accurate approximation tool in nonlinear robotic dynamic control tasks. In this paper, our main goal was to combine the advantages of the artificial neural networks and the RL to reduce the learning time length and enhance the control accuracy. Therefore, we have implemented one of the promising RL approaches, actor-critic RL to control the actuation torques of a planar five-link bipedal robot and retain the passive torso in the vertical position. Our control agent consists of two three-layered neural network units, known as the critic and the actor for learning prediction and learning control tasks. These units are synchronized by the temporal difference error, which implements the eligibility trace vector to assign credit or blame for the error. Moreover, since the neural networks are implemented in both of the actor and the critic sections, we have added a learning database to reduce the probability of inaccurate approximation of the nonlinear functions. Results of our presented control method reveal its perfect performance in stable walking control of the bipedal robot.",https://ieeexplore.ieee.org/document/6990997/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/M2VIP.2017.8211476,Actuation planning and modeling of a soft swallowing robot,IEEE,Conferences,"The paper presents a new methodology to solve the actuation and modelling problems of a soft-bodied swallowing robot (SR), developed for human swallow evaluation. To solve the actuation problem, a central pattern generator (CPG) based novel actuation scheme is developed and implemented to generate peristalsis in the robot. Machine learning based technique is used to determine the governing dynamics of the robot because presently the robot does not have any differential equation to describe its actuation principle or its physics. To profile and sense the peristaltic waveform, a flat version of the robot containing pneumatic chambers for actuation has been proposed to approximate the deformation of the original SR and the CPG actuation scheme is used to command the flat SR so that the pneumatic chambers can be inflated. The logic of actuation is motivated from the swallowing phenomenon in humans, have been implemented in real time. An optical motion detection system (Vicon) is used to track the displacement of the air chambers of the robot and hence, to generate time-series data for determining the governing differential equations of the robot by using l<sub>1</sub> regularised machine learning technique. It is also concluded that the proposed method provides a promising new modelling technique for determining the governing dynamics of the robot where conventional modelling approaches are not applicable.",https://ieeexplore.ieee.org/document/8211476/,2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),21-23 Nov. 2017,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ICIT.1996.601644,Adaptive robust robot control using BP-SMENs,IEEE,Conferences,"This paper presents the development of a new adaptive recurrent neural network for the control of a nonlinear system represented by a two-link SCARA type planar robot manipulator. The standard backpropagation algorithm is used to adjust the weights of the networks. The proposed control system consists of an inverse neural model of robot (INNM), an INNM-based neural controller, a robust controller, a conventional PI controller, and a second order linear filter. To evaluate the performance of the proposed control scheme and neural network, a simulated SCARA type robot was studied and the results showed how well the proposed controller can minimise the error between an actual and desired end-effector trajectory. From simulation examples, the robot trajectory tracking showed superior performance that is very attractive for real-time implementation and application in complex industrial tasks. For comparison, the standard computed torque method is employed for controlling the robot.",https://ieeexplore.ieee.org/document/601644/,Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96),2-6 Dec. 1996,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/TAI.1994.346494,Advanced fuzzy control of a trailer type mobile robot-stability analysis and model-based fuzzy control,IEEE,Conferences,"In a previous paper (see ""A Robust Stabilization Problem of Fuzzy Controller Systems and Its Applications to Backing up Control of a Truck-Trailer"", IEEE Trans. on Fuzzy Systems, Vo1.2, no.2, p.119-34, 1994), we designed a control system for backing up a computer simulated trailer type mobile robot, which is non-linear and unstable, by applying a robust stabilization technique for fuzzy systems. Furthermore, we have shown that the designed fuzzy controller smoothly achieves backing up control of the computer simulated trailer type mobile robot from all initial positions. We control a real trailer type mobile robot by applying the design method proposed previously. The experimental results show that the designed fuzzy controller effectively realize backing up control of the real trailer type mobile robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/346494/,Proceedings Sixth International Conference on Tools with Artificial Intelligence. TAI 94,6-9 Nov. 1994,ieeexplore
10.1109/ICRA40945.2020.9196582,Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video,IEEE,Conferences,"Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.",https://ieeexplore.ieee.org/document/9196582/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA48506.2021.9562117,Agile Robot Navigation through Hallucinated Learning and Sober Deployment,IEEE,Conferences,"Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination—a feature we call ""sober deployment""—and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",https://ieeexplore.ieee.org/document/9562117/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISCSIC.2017.28,An Adaptive 2D Tracking Approach for Person Following Robot,IEEE,Conferences,"In this paper, we present a 2D appearance vision based tracking approach for human following robot. Generally, existing methods have high cost of computing and requirements of hardware which makes the difficulty of employing the function on service robot. Hence, minimizing the cost of tracking with slight loss of precision can benefit this area. We focus on approach based on 2D image data which reduce tracking into two dimensions and can minimize the cost of computation. Our approach presents a corporate strategy which utilizes central consensus of correspondence for 2D feature points pairwise to track and employ a semi-supervised learning detector to update appearance change. To overcome difficulties from environment change, we set an enhancing process for feature points and background segmentation through depth information. We carefully evaluate our approach with common challenges of visual tracking in static view and deploy a dynamic view a real-world following task. The experiment results illustrate that our tracking approach works against common risks at 2D appearance tracking and properly follows the user obtaining 25 fps performance on mobile platform.",https://ieeexplore.ieee.org/document/8294176/,2017 International Symposium on Computer Science and Intelligent Controls (ISCSIC),20-22 Oct. 2017,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/WCICA.2006.1713761,An Embedded Platform for Intelligent Mobile Robot,IEEE,Conferences,"To overcome the limitations of the special architectures adopted by traditional industrial robots, an embedded intelligent robot platform based on Windows CE.NET is established by customizing the operating system. On this intelligent robot platform, all major necessary sensors are included, and abundant control interfaces and driver modules are available, such as movement control interface, USB camera driver, laser driver, etc. Besides, various testing software and application modules for intelligent robot are designed, such as multi-sensor data fusion, path planning, speech recognition, wireless network communication and graphic human-robot interface. The platform is modularized, extensible, transplantable and customizable. Compared to the previous robot platform, it also has many advantages such as more compact hardware, lower-power consumption, better real-time performance and higher reliability",https://ieeexplore.ieee.org/document/1713761/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/ROBIO.2006.340133,An Extension of the Distance-Propagating Dynamic System for Robot Path Planning to Safe Obstacle Clearance,IEEE,Conferences,"In this paper we extend our previously presented efficient distance-propagating dynamic system for real-time robot path planning in dynamic environments to the case where safety margins around obstacles are included. Inclusion of safety margins approximately triples the number of arithmetic operations, however, the distance-propagating dynamic system is still very computationally efficient. The algorithm uses a grid representation of the environment, which need not be regular, and is applicable to dynamic environments where both targets and obstacles are permitted to move. No prior knowledge of target or obstacle movement is assumed. Safety margins around obstacles are implemented as ""soft"" margins defined by local penalty functions around obstacles which represent the extra distance the robot is willing to travel in order to avoid passing through this margin. The path through which the robot travels minimizes the sum of the current known distance to a target and the cumulative local penalty functions along the path. The effectiveness of the algorithm is demonstrated through a number of simulations.",https://ieeexplore.ieee.org/document/4142070/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ROMAN.2018.8525668,An Ontology-based Home Care Service Robot for Persons with Dementia,IEEE,Conferences,"In this paper, we introduce an ontology-based home care service robot that can provide personalized care for people who are in the early stage of dementia. The hardware and software framework encompassed in the proposed service robot was developed to carry out care services in their daily life at home. Specifically, to generate adaptive task plans in diverse caring situation, context reasoner and ontological model of dementia are included. Ontology includes various concepts that are related with the knowledge of caring dementia patient: dementia, dementia symptom, environment of around patient, and situation during patient's daily life. To evaluate if the proposed service robot could provide appropriate care service or not, experimental care scenario for helping a person with dementia take medicine was tried in the lab environment. Although tasks of the robot required for the experiment are rather simple, we have demonstrated that the robot could provide a personalized service that may be beneficial to dementia patient, family members and caregivers. In the future, we will add more care knowledge in the ontology and further develop a variety of care services. Additionally, we are going to test the care service robot in a real environment with actual dementia patient.",https://ieeexplore.ieee.org/document/8525668/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ROMAN.2012.6343892,An active audition framework for auditory-driven HRI: Application to interactive robot dancing,IEEE,Conferences,"In this paper we propose a general active audition framework for auditory-driven Human-Robot Interaction (HRI). The proposed framework simultaneously processes speech and music on-the-fly, integrates perceptual models for robot audition, and supports verbal and non-verbal interactive communication by means of (pro)active behaviors. To ensure a reliable interaction, on top of the framework a behavior decision mechanism based on active audition policies the robot's actions according to the reliability of the acoustic signals for auditory processing. To validate the framework's application to general auditory-driven HRI, we propose the implementation of an interactive robot dancing system. This system integrates three preprocessing robot audition modules: sound source localization, sound source separation, and ego noise suppression; two modules for auditory perception: live audio beat tracking and automatic speech recognition; and multi-modal behaviors for verbal and non-verbal interaction: music-driven dancing and speech-driven dialoguing. To fully assess the system, we set up experimental and interactive real-world scenarios with highly dynamic acoustic conditions, and defined a set of evaluation criteria. The experimental tests revealed accurate and robust beat tracking and speech recognition, and convincing dance beat-synchrony. The interactive sessions confirmed the fundamental role of the behavior decision mechanism for actively maintaining a robust and natural human-robot interaction.",https://ieeexplore.ieee.org/document/6343892/,2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,9-13 Sept. 2012,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICARCV.2002.1235010,An autonomous mobile robot with fuzzy obstacle avoidance behaviors and a visual landmark recognition system,IEEE,Conferences,"Multi-sensor fusion has been a hot topic in the field of robotics. Inspired by the modern philosophy's spirit, the behavior-based systems interact with the real world directly. In this study, a fully autonomous mobile robot is developed that extracts all its knowledge from physical sensors and expresses all its goals and desires as physical action to affect its environment. The control software implements behavior-based artificial intelligence, where the coordination between various sensors are realized by layers of several simple and primitive behaviors similar to those observed in animals. In the developed mobile robot, each module itself generates behaviors. Behaviors corresponding to different sensors have different priorities, where the vision system has the lowest priority, and the ultrasonic sensors and bumper sensors have higher priority. The effectiveness of the developed system is demonstrated by experimental studies.",https://ieeexplore.ieee.org/document/1235010/,"7th International Conference on Control, Automation, Robotics and Vision, 2002. ICARCV 2002.",2-5 Dec. 2002,ieeexplore
10.1109/ICSMC.2009.5346800,An embedded interval type-2 neuro-fuzzy controller for mobile robot navigation,IEEE,Conferences,"This paper describes intelligent navigation using an embedded interval type-2 neuro-fuzzy controller. Weightless neural network (WNNs) strategy is used because fast learning, easy hardware implementation and well suited to microcontroller-based-real-time systems. The WNNs utilizes previous sensor data and analyzes the situation of the current environment and classifies geometric feature such as U-shape, corridor and left or right corner. The behavior of mobile robot is implemented by means of interval type-2 fuzzy control rules can be generated directly from the WNNs classifier. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show, using that technique the source code is efficient. The mobile robot can recognize the current environment and to be able successfully avoid obstacle in real time and achieve smother motion compare than logic function and fuzzy type-1 controller.",https://ieeexplore.ieee.org/document/5346800/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/CIRA.1997.613874,An evolutionary method for active learning of mobile robot path planning,IEEE,Conferences,"Several evolutionary algorithms have been proposed for robot path planning. Most existing methods for evolutionary path planning require a number of generations for finding a satisfactory trajectory and thus are not efficient enough for real-time applications. In this paper we present a new method for evolutionary path planning which can be used online in real-time. We use an evolutionary algorithm as a means for active learning of a route map for the path planner. Given a source-destination pair, the path planner searches the map for a best matching route. If an acceptable match is not found, the planner uses another evolutionary algorithm to generate online a path for the source-destination pair. The overall system is an incremental learning planner that gradually expands its own knowledge suitable for path planning in real-time. Simulations have been performed in the domain of robotic soccer to demonstrate the effectiveness of the presented method.",https://ieeexplore.ieee.org/document/613874/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/CNNA.2010.5430339,An on-line test setup of CNN based real-time mobile robot navigation application,IEEE,Conferences,"In this demo, we introduced a mobile robot navigation test setup that is accessible via internet. This test setup has a Lego Mindstorms NXT differential drive mobile robot which is controlled by a computer with Bluetooth connection. The control computer, which is called Host Computer in Fig. 1, runs MATLAB to operate the system. The navigation of mobile robot is based on an algorithm which uses a Relaxation Oscillator Cellular Neural/Nonlinear Network to execute wave computing. This network is also simulated by the Host Computer. The significant property of this demo is that any Client Computer can establish a remote desktop connection with the Host Computer and use the test setup remotely. By this means, any comparative tests on this setup can be handled remotely by independent researchers.",https://ieeexplore.ieee.org/document/5430339/,2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010),3-5 Feb. 2010,ieeexplore
10.1109/ROBOT.1992.220085,An optimal scheduling of pick place operations of a robot-vision-tracking system by using back-propagation and Hamming networks,IEEE,Conferences,"The authors present a neural network approach to solve the dynamic scheduling problem for pick-place operations of a robot-vision-tracking system. An optimal scheduling problem is formulated to minimize robot processing time without constraint violations. This is a real-time optimization problem which must be repeated for each group of objects. A scheme which uses neural networks to learn the mapping from object pattern space to optimal order space offline and to recall online what has been learned is presented. The idea was implemented in a real system to solve a problem in large commercial dishwashing operations. Experimental results have been shown that with four different objects, time savings of up to 21% are possible over first-come, first-served schemes currently used in industry.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220085/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.23919/IConAC.2019.8895095,Ant Colony Optimization Algorithm for Industrial Robot Programming in a Digital Twin,IEEE,Conferences,"Advanced manufacturing that is adaptable to constantly changing product designs often requires dynamic changes on the factory floor to enable manufacture. The integration of robotic manufacture with machine learning approaches offers the possibility to enable such dynamic changes on the factory floor. While ensuring safety and the possibility of losses of components and waste of material are against their usage. Furthermore, developments in design of virtual environments makes it possible to perform simulations in a virtual environment, to enable human-in-the-loop production of parts correctly the first time like never before. Such powerful simulation and control software provides the means to design a digital twin of manufacturing environment in which trials are completed at almost at no cost. In this paper, ant colony optimization is used to program an industrial robot to avoid obstacles and find its way to pick and place objects during an assembly task in an environment containing obstacles that must be avoided. The optimization is completed in a digital twin environment first and movements transferred to the real robot after human inspection. It is shown that the proposed methodology can find the optimal solution, in addition to avoiding collisions, for an assembly task with minimum human intervention.",https://ieeexplore.ieee.org/document/8895095/,2019 25th International Conference on Automation and Computing (ICAC),5-7 Sept. 2019,ieeexplore
10.1109/AICI.2009.305,Application of RBF Neural Network in Trajectory Planning of Robot,IEEE,Conferences,"Trajectory planning of robot is to control the robot in order to accurately follow the target track. And the target trajectory is always high-order and nonlinear. But RBF neural network can be achieved from the input to the output of arbitrary nonlinear mapping, through network learning and training to achieve the nonlinear function. This paper establishes a RBF neural network model firstly, and carries on the simulation through software MATLAB. The result confirms that the RBF neural network can keep the control of the robot's nonlinear trajectory planning in real time.",https://ieeexplore.ieee.org/document/5375883/,2009 International Conference on Artificial Intelligence and Computational Intelligence,7-8 Nov. 2009,ieeexplore
10.1109/IJCNN.1990.137866,Application of neural networks on robot grippers,IEEE,Conferences,"A new-generation general-purpose robot gripper system which applies an artificial neural network to guide a three-finger gripper has been designed. The simulation of the core part of the whole system, i.e. optimally placing three fingers for a stable grasp using the Hopfield net, has been conducted. The results obtained show that this scheme behaves in a promising fashion. The actual computation time is usually within several seconds if implemented in an analog neural net, making the real application attractive",https://ieeexplore.ieee.org/document/5726824/,1990 IJCNN International Joint Conference on Neural Networks,17-21 June 1990,ieeexplore
10.1109/CDC.1999.833361,Application of reinforcement learning control to a nonlinear dexterous robot,IEEE,Conferences,"In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration were studied in detail. We attempt to increase feasibility for practical applications, implementation, learning efficiency, and performance. Reinforcement learning is then applied for control of a nonlinear dexterous robot. This control problem dictates that the learning is performed online, based on binary and real valued reinforcement signal from a critic network, without knowing the system model nonlinearity. The learning algorithm consists of an action and critic networks that learn to keep the multifinger hand of the dexterous robot within desired limits.",https://ieeexplore.ieee.org/document/833361/,Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304),7-10 Dec. 1999,ieeexplore
10.1109/IJCNN.2004.1380179,Applying KIV dynamic neural network model for real time navigation by mobile robot EMMA,IEEE,Conferences,"We use a biologically inspired dynamic neural network model to accomplish goal-oriented navigation by a mobile robot in a real environment with obstacles. This model is the KIV model of the brain. Real time navigation is a challenging task, especially when there is no a priori information about the environment. Our robot EMMA is designed to be autonomous using various sensory inputs, which are integrated to achieve an efficient navigation task. This paper focuses on the design, implementation, and evaluation of the performance of EMMA and gives a proof-of-principle in a real environment.",https://ieeexplore.ieee.org/document/1380179/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/ICONIP.1999.845675,Artificial neural networks for autonomous robot control: reflective navigation and adaptive sensor calibration,IEEE,Conferences,"The authors present the application of artificial neural networks to the control of a mobile autonomous robot, which is acting in a totally unknown and-most importantly-dynamically changing environment. In particular, the employment of interacting 'simple', i.e. hand-designed, neural networks for navigation purposes is investigated as well as a variation of self-organizing maps for adaptive sensor calibration. We take a pragmatic point of view as the minimal condition imposed on the developed algorithms: that they do well on a real system acting in a real environment. Hence, the design of all of the implemented neural networks is clearly motivated by their applicability. In this context, special considerations are dedicated to ensure robustness, real-time capability and memory resourcefulness. In order to practically demonstrate the obtained results, the mini-robot Khepera is utilized as an experimentational platform, which is (due to its small size), a versatile tool for scientific investigation.",https://ieeexplore.ieee.org/document/845675/,ICONIP'99. ANZIIS'99 & ANNES'99 & ACNN'99. 6th International Conference on Neural Information Processing. Proceedings (Cat. No.99EX378),16-20 Nov. 1999,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/SIU.2015.7130068,Audio-visual human tracking for active robot perception,IEEE,Conferences,"In this paper, a multimodal system is designed in the form of an active audio-vision in order to improve the perceptual capability of a robot in a noisy environment. The system running in real-time consists of 1) audition modality, 2) a complementary vision modality and 3) motion modality incorporating intelligent behaviors based on the data obtained from both modalities. The tasks of audition and vision are to detect, localize and track a speaker independently. The aim of motion modality is to enable a robot to have intelligent and human-like behaviors by using localization results from the sensor fusion. The system is implemented on a mobile robot platform in a real-time environment and the speaker tracking performance of the fusion is confirmed to be improved compared to each of sensory modalities.",https://ieeexplore.ieee.org/document/7130068/,2015 23nd Signal Processing and Communications Applications Conference (SIU),16-19 May 2015,ieeexplore
10.1109/AIVR46125.2019.00061,Augmented Reality for Human-Robot Cooperation in Aircraft Assembly,IEEE,Conferences,"Augmented Reality (AR) is often discussed as one of the enabling technologies in Industrie 4.0. In this paper, we describe a practical application, where Augmented Reality glasses are used not only for assembly assistance, but also as a means of communication to enable the orchestration of a hybrid team consisting of a human worker and two mobile robotic systems. The task of the hybrid team is to rivet so-called stringers onto an aircraft hull. While the two robots do the physically demanding, unergonomic and possibly hazardous tasks (squeezing and sealing rivets), the human takes over those responsibilities that need experience, multi-sensory sensitiveness and specialist knowledge. We describe the working scenario, the overall architecture and give design and implementation details on the AR application.",https://ieeexplore.ieee.org/document/8942239/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/IJCNN.2003.1223997,Automatic language acquisition by an autonomous robot,IEEE,Conferences,"There is no such thing as a disembodied mind. We posit that cognitive development can only occur through interaction with the physical world. To this end, we are developing a robotic platform for the purpose of studying cognition. We suggest that the central component of cognition is a memory which is primarily associative, one where learning occurs as the correlation of events from diverse inputs. We also posit that human-like cognition requires a well-integrated sensory-motor system, to provide these diverse inputs. As implemented in our robot, this system includes binaural hearing, stereo vision, tactile sense, and basic proprioceptive control. On top of these abilities, we are implementing and studying various models of processing, learning and decision making. Our goal is to produce a robot that will learn to carry out simple tasks in response to natural language requests. The robot's understanding of language will be learned concurrently with its other cognitive abilities. We have already developed a robust system and conducted a number or experiments on the way to this goal, some details of which appear in this paper. This is a first progress report of what we believe will be a long term project with significant implications.",https://ieeexplore.ieee.org/document/1223997/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IROS.2003.1250752,Autonomous behavior control architecture of entertainment humanoid robot SDR-4X,IEEE,Conferences,"In this paper we describe the autonomous behavior control architecture of SDR-4X, which serves to integrate multi-modal recognition and motion control technologies. We overview the entire software architecture of SDR-4X, which is composed of perception, short and long term memory, behavior control, and motion control parts. Regarding autonomous behavior control, we further focus on issues such as spontaneous behavior generation using a homeostasis regulation mechanism, and a behavior control/selection mechanism with tree-structured situated behavior modules. In the autonomous behavior control architecture, we achieve three basic requirements, which are the concurrent evaluation of the situation of each behavior module, concurrent execution of multiple behavior modules, and preemption (behavior interruption/resume capability). Using the autonomous behavior control architecture described, we demonstrate that SDR-4X can spontaneously and passively interact with a human.",https://ieeexplore.ieee.org/document/1250752/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/SYSOSE.2008.4724191,Autonomous navigation based on a Q-learning algorithm for a robot in a real environment,IEEE,Conferences,"This paper explores autonomous navigation and obstacle avoidance techniques based on Q-learning for a mobile robot in a real environment. The implemented algorithm focuses on simplicity and efficiency. The learning process takes place in both simulation and real world allowing the combination of a longer learning time in the simulator with a more accurate knowledge from the real world. After learning is completed in simulation and in the real world, the robot was able to navigate without hitting obstacles and able to generate control law for complex situations such as corners and small objects.",https://ieeexplore.ieee.org/document/4724191/,2008 IEEE International Conference on System of Systems Engineering,2-4 June 2008,ieeexplore
10.1109/ISIC.2002.1157759,Autonomous robot navigation based on fuzzy sensor fusion and reinforcement learning,IEEE,Conferences,"This paper presents the design and implementation of an autonomous robot navigation system for intelligent target collection in dynamic environments. A feature-based multi-stage fuzzy logic (MSFL) sensor fusion system is developed for target recognition, which is capable of mapping noisy sensor inputs into reliable decisions. The robot exploration and path planning are based on a grid map oriented reinforcement path learning system (GMRPL), which allows for long-term predictions and path adaptation via dynamic interactions with physical environments. In our implementation, the MSFL and GMRPL are integrated into a subsumption architecture for intelligent target-collecting applications. The subsumption architecture is a layered reactive agent structure that enables the robot to implement higher-layer functions including path learning and target recognition regardless of lower-layer functions such as obstacle detection and avoidance. Real-world application using a Khepera robot shows the robustness and flexibility of the developed system in dealing with robotic behavior such as target collecting in an ever-changing physical environment.",https://ieeexplore.ieee.org/document/1157759/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/CEC.2002.1004426,Autonomous robot navigation via intrinsic evolution,IEEE,Conferences,"This paper presents the design and implementation of an evolvable hardware based autonomous robot navigation system using intrinsic evolution. Distinguished from the traditional evolutionary approaches based on software simulation, an evolvable robot controller at the hardware gate-level that is capable of adapting dynamic changes in the environments is implemented. In our approach, the concept of Boolean function is used to construct the evolvable controller implemented on an FPGA-based robot turret, and evolutionary computing is applied as a learning tool to guide the artificial evolution at the hardware level. The effectiveness of the proposed evolvable autonomous robotic system is confirmed with the physical real-time implementation of robot navigation behaviors on light source following and obstacle avoidance using a robot with traction fault.",https://ieeexplore.ieee.org/document/1004426/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/IROS40897.2019.8967694,Benchmarking and Workload Analysis of Robot Dynamics Algorithms,IEEE,Conferences,"Rigid body dynamics calculations are needed for many tasks in robotics, including online control. While there currently exist several competing software implementations that are sufficient for use in traditional control approaches, emerging sophisticated motion control techniques such as nonlinear model predictive control demand orders of magnitude more frequent dynamics calculations. Current software solutions are not fast enough to meet that demand for complex robots. The goal of this work is to examine the performance of current dynamics software libraries in detail. In this paper, we (i) survey current state-of-the-art software implementations of the key rigid body dynamics algorithms (RBDL, Pinocchio, Rigid-BodyDynamics.jl, and RobCoGen), (ii) establish a methodology for benchmarking these algorithms, and (iii) characterize their performance through real measurements taken on a modern hardware platform. With this analysis, we aim to provide direction for future improvements that will need to be made to enable emerging techniques for real-time robot motion control. To this end, we are also releasing our suite of benchmarks to enable others to help contribute to this important task.",https://ieeexplore.ieee.org/document/8967694/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICMLC.2008.4620720,Bi-criteria joint torque minimization of redundant robot arms using LVI-based primal-dual neural network,IEEE,Conferences,"To diminish the discontinuity and divergence of infinity norm torque minimization scheme, a bi-criteria weighting scheme is proposed for online redundancy resolution of redundant robot arms. Such a scheme can easily be reformulated into a quadratic program (QP) subject to equality, inequality and bound constraints. To solve this QP problem online, a primal-dual dynamical-system solver is further presented based on linear variational inequalities (LVI). Compared to previous research work, the adopted QP-solver has simple piecewise-linear dynamics, and does not entail real-time matrix inversion. Computer simulations are performed based on a PUMA560 manipulator to verify the performance and effectiveness of the proposed torque-optimization method.",https://ieeexplore.ieee.org/document/4620720/,2008 International Conference on Machine Learning and Cybernetics,12-15 July 2008,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/BIOROB.2018.8487202,Bioinspired Adaptive Spiking Neural Network to Control NAO Robot in a Pavlovian Conditioning Task,IEEE,Conferences,"The cerebellum has a central role in fine motor control and in various neural processes, as in associative paradigms. In this work, a bioinspired adaptive model, developed by means of a spiking neural network made of thousands of artificial neurons, has been leveraged to control a humanoid NAO robot in real-time. The learning properties of the system have been challenged in a classic cerebellum-driven paradigm, the Pavlovian timing association between two provided stimuli, here implemented as a laser-avoidance task. The neurophysiological principles used to develop the model, succeeded in driving an adaptive motor control protocol with acquisition and extinction phases. The spiking neural network model showed learning behaviors similar to the ones experimentally measured with human subjects in the same conditioning task. The model processed in real-time external inputs, encoded as spikes, and the generated spiking activity of its output neurons was decoded, in order to trigger the proper response with a correct timing. Three long-term plasticity rules have been embedded for different connections and with different time-scales. The plasticities shaped the firing activity of the output layer neurons of the network. In the Pavlovian protocol, the neurorobot successfully learned the correct timing association, generating appropriate responses. Therefore, the spiking cerebellar model was able to reproduce in the robotic platform how biological systems acquire and extinguish associative responses, dealing with noise and uncertainties of a real-world environment.",https://ieeexplore.ieee.org/document/8487202/,2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob),26-29 Aug. 2018,ieeexplore
10.1109/IJCNN.2000.859467,Biologically inspired neural controllers for motor control in a quadruped robot,IEEE,Conferences,"This paper presents biologically inspired neural controllers for generating motor patterns in a quadruped robot. Sets of artificial neural networks are presented which provide 1) pattern generation and gait control, allowing continuous passage from walking to trotting to galloping, 2) control of sitting and lying down behaviors, and 3) control of scratching. The neural controllers consist of sets of oscillators composed of leaky-integrator neurons, which control pairs of flexor-extensor muscles attached to each joint. The networks receive sensory feedback proportional to the contraction of simulated muscles and to joint flexion. Similarly to what is observed in cats, locomotion can be initiated by either applying tonic (i.e. non-oscillating) input to the locomotion network or by sensory feedback from extending the legs. The networks are implemented in a quadruped robot. It is shown that computation can be carried out in real time and that the networks can generate the above mentioned motor behaviors.",https://ieeexplore.ieee.org/document/859467/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/INES.2018.8523877,Body State Recognition for a Quadruped Mobile Robot,IEEE,Conferences,"The body states must be tracked by the onboard software on the robot to make good decisions. A human can pick up this machine or if the robot encounters anomalies (e.g. fall over) during locomotion, the state changes must be identified to execute the necessary responses. The authors of this paper developed a machine learning model which can recognize four states (normal, pick-up, fall over, poked) of a Sony AIBO robot. A deep neural network classifier with these predictors achieved 98% accuracy on unseen data and actual test runs on the robot proved the practical use with real-time execution speed. These properties made the proposed method a good candidate for adaption to other legged robots.",https://ieeexplore.ieee.org/document/8523877/,2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES),21-23 June 2018,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/IROS.2006.281655,Brush Footprint Acquisition and Preliminary Analysis for Chinese Calligraphy using a Robot Drawing Platform,IEEE,Conferences,"A robot drawing platform supporting four degrees of freedom (x, y, z and z-rotation) of a brush-pen motion for studying Chinese painting and calligraphy has been operational in our laboratory. This paper describes the real-time capturing and data analysis of the brush footprint using the new hardware and software capabilities in the platform. They include a transparent drawing plate and an underneath camera system, together with projective rectification and video segmentation algorithms. Preliminary result of the footprint analysis and nonparametric modeling, and their applications to well-known Chinese calligraphy are demonstrated",https://ieeexplore.ieee.org/document/4059247/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/ISCAS.2004.1329695,CNN wave based computation for robot navigation planning,IEEE,Conferences,"In this work a methodology for real-time robot navigation in a complex, dynamically changing environment, based on wave computation and implemented by cellular neural networks (CNNs) is introduced. The keypoint of the approach is to consider the environment in which the robot moves as an excitable medium. Obstacles and targets represent the source of autowave generation. The wavefronts propagating in the CNN medium provide to the robot all the information to achieve an adaptive motion avoiding the obstacles and directed to the target. In particular the paradigm of reaction-diffusion (RD) equations are used to implement a CNN-based wave computation for navigation control. Experimental results validating the approach are shown.",https://ieeexplore.ieee.org/document/1329695/,2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512),23-26 May 2004,ieeexplore
10.23919/ACC.1989.4790240,CONDOR: A Coarse-grained Parallel Architecture for Robot Control,IEEE,Conferences,"This paper presents an overview of the CONDOR, a real-time development environment designed for robotics research applications. The architecture is based on standard hardware components consisting of upto eight microprocessors interconnected through a shared memory bus, and is coupled with a powerful software environment based on message passing that enables the development of control programs for complicated robots. The hardware is extremely easy to set up since it uses standard components. Besides program libraries tuned for real-time control, the software utilities include a multi-processor pseudo-terminal emulator, a file-server and a flexible symbolic debugger that greatly enhance programmer productivity.",https://ieeexplore.ieee.org/document/4790240/,1989 American Control Conference,21-23 June 1989,ieeexplore
10.1109/IROS40897.2019.8967592,Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography,IEEE,Conferences,"Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",https://ieeexplore.ieee.org/document/8967592/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBIO.2017.8324803,Classification-lock tracking approach applied on person following robot,IEEE,Conferences,"The task of following a person in the real complex environment by camera still keeps at risk even the visual tracking technologies have been well studied in the last decade. Currently, most approaches only utilize single-shot initialization in the first frame and update their tracking models according to the result of the last frame. However, it leads to an uncorrected target selection once the inner appearance changes, i.e., a feature-rich object is moved out of the human. In this paper, we reveal a classification-lock tracking framework and apply our approach on a mobile platform. A pairwise cluster tracker is used to locate the person. A positive &amp; negative classifier is utilized to verify the tracker's result and update tracking model. In addition, a pre-trained CPU optimized neural network is employed to lock the tracking result to only be human. In the experiment, we deploy the common challenges of visual tracking both on the static scene and a real-following task. Furthermore, our approach is compared with other state-of-art approaches on common datasets. Results prove the tracking quality of our approach in both the static and the dynamic scenes. Our approach achieves the best average score on the common dataset.",https://ieeexplore.ieee.org/document/8324803/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICCE46568.2020.9042997,Cliff-sensor-based Low-level Obstacle Detection for a Wheeled Robot in an Indoor Environment,IEEE,Conferences,"A ramp and uneven ground formed by a low-level obstacle - whose height is too low from the ground - often stalls a robot's navigation in an indoor environment. Few-centimeter differences between a low-level obstacle and a low-level non-obstacle are very difficult to be precisely measured in a constant distance at a mobile robot. In this paper, a wheeled mobile robot thus makes physical contact onto a low-level object, in order to measure such subtle differences. We use one or more cliff sensors typically in place for a mobile robot in order to avoid a drop-off. A wheeled robot climbs over a low-level object, classifies an obstacle vs. a non-obstacle using a cliff sensor's timeseries data, and rapidly backs up before getting stuck onto an obstacle. While adopting a simplified deep-learning architecture, we suggest a rapid and accurate obstacle detection technique in real-time. We implemented our technique on an embedded robot platform of LG Hom-Bot. The supplementary video on the physical robot experiment can be accessed at https://youtu.be/yK57S857_II.",https://ieeexplore.ieee.org/document/9042997/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/INDIN.2011.6034840,Cognitive decision unit applied to autonomous biped robot NAO,IEEE,Conferences,"The novel approach to use meta-psychology - the theoretic foundation of psychoanalysis - as archetype for a decision making framework for autonomous agents was realized in simulations recently. In addition, multiple studies showed the capability of a robot to sense and interact in its environment. This work fills the gap between sensing, environmental interaction and decision making by grounding these topics with an agents internal needs using the concepts of meta-psychology. The bodies of typical agents are equipped with internal systems which can generate bodily needs - for example the urgent need for food. As proof-of-concept we implemented this concept on a simulated agent as well as on a physical real humanoid biped robot to additionally proof the concept within a fully controlled simulated environment. The use of the common humanoid robot platform NAO, which has 25 degrees of freedom and biped locomotion, enforced us to deal with complex situations and disturbed sensor readings. NAO provides various internal sensors like engine temperature or battery level as well as external sensors like sonar or cameras. An implemented visual marker detecting system allowed us to detect objects in the surrounding environmental, representing food or energy sources. We show, how it is possible to use the psychoanalytically inspired framework ARS to control a real world application, the robot NAO.",https://ieeexplore.ieee.org/document/6034840/,2011 9th IEEE International Conference on Industrial Informatics,26-29 July 2011,ieeexplore
10.1109/CARE.2013.6733739,Cognitive learning enabled real time object search robot,IEEE,Conferences,"Object Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Most works are focused on a specific application, such as tracking human, car, or pre-learned objects. All these require database and considerable amount of training time to detect the current object and to track it. In this paper we propose a method to track objects where a pre-stored database is not a requirement. The proposed method uses a combination of Scale Invariant Feature Transform (SIFT) based feature extraction, Kalman filter and Cognitive learning. The algorithm has the ability to make its own database of the objects in the due course of time by interacting with the user through text based communication. This algorithm is deployed on a search robot which does the operation of searching an object in real time upon a command from the user. The search operation of robot is made more flexible using Bluetooth wireless communication protocol.",https://ieeexplore.ieee.org/document/6733739/,"2013 International Conference on Control, Automation, Robotics and Embedded Systems (CARE)",16-18 Dec. 2013,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICTAI.2019.00023,Collision-Free Path Finding for Dynamic Gaming and Real Time Robot Navigation,IEEE,Conferences,"Collision-free path finding is crucial for multi-agent traversing environments like gaming systems. An efficient and accurate technique is proposed for avoiding collisions with potential obstacles in virtual and real time environments. Potential field is a coherent technique but it eventuates with various problems like static map usage and pre-calculated potential field map of the environment. It is unsuitable for dynamically changing or unknown environments. Agents can get stuck inside a local minima incompetent in escaping without a workaround implementation. This paper presents efficient and accurate solutions to find collision free path using potential field for dynamic gaming and real time robot navigation. A surfing game in two testing environments with a Gamecar and a physical robot called Robocar is created with dynamic and solid obstacles. Sensor like proximity, line and ultrasonic are used along with the camera as different agents for path finding. The proposed intelligent agent (IA) technique is compared with other path planing algorithms and games in terms of time complexity, cost metrics, decision making complexity, action repertoire, interagent communication, reactivity and temporally continuous. It traverses for 135 meters(m) in 55.8 seconds(s) covering 20 goals and 419.3 m in 8.7 minutes while avoiding 10 local minimas successfully. Proposed technique shows comparable results to path finding with techniques using neural networks and A* algorithm. Experimental results prove the efficiency with run time overload, time complexity and resource consumption of the proposed technique.",https://ieeexplore.ieee.org/document/8995276/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/HUMANOIDS.2017.8246935,Combining deep learning for visuomotor coordination with object identification to realize a high-level interface for robot object-picking,IEEE,Conferences,"We present a proof of concept to show how a deep network for end-to-end visuomotor learning to grasp is coupled with an attention focus mechanism for state-of-the-art object detection with convolutional neural networks. The cognitively motivated integration of both methods in a single robotic system allows us to realize a high-level interface to use the visuomotor network in environments with several objects, which otherwise would only be usable in environments with a single object. The resulting system is deployed on a humanoid robot, and we perform several real-world grasping experiments that demonstrate the feasibility of our approach.",https://ieeexplore.ieee.org/document/8246935/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.23919/ICCAS47443.2019.8971680,Comparison of Object Recognition Approaches using Traditional Machine Vision and Modern Deep Learning Techniques for Mobile Robot,IEEE,Conferences,"In this paper, we consider the problem of object recognition for a mobile robot in an indoor environment using two different vision approaches. Our first approach uses HOG descriptor with SVM classifier as traditional machine vision model while the second approach uses Tiny-YOLOv3 as modern deep learning model. The purpose of this study is to gain intuitive insight of both approaches for understanding the principles behind these techniques through their practical implementation in real world. We train both approaches with our own dataset for doors. The proposed work is assessed through the real-world implementation of both approaches using mobile robot with Zed camera in real world indoor environment and the robustness has been evaluated by comparing and analyzing the experimental results of both models on same dataset.",https://ieeexplore.ieee.org/document/8971680/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
10.1109/IROS.2006.282163,Conceptual Design and Implementation of Arm Wrestling Robot,IEEE,Conferences,"In this paper, we develop a novel robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is intended to play arm wrestling game with real human on a table for entertainment. The designing scenario of the prototype model's hardware is performed. Elbow/wrist force sensors, as a crucial device in the force sensing system, are described in details. Software is developed for device driven and interface. The surface electromyographic (EMG) signals from the upper limb are sampled when a real player competes with the force testing system. By using the method of wavelet packet transformation (WPT), the high-frequency noises can be eliminated effectively and the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments",https://ieeexplore.ieee.org/document/4059139/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/SAUPEC/RobMech/PRASA48453.2020.9041114,Context-Aware Action with a Small Mobile Robot,IEEE,Conferences,"Simultaneous advances in mobile GPU computing and real-time object recognition now enable machines to make decisions and take actions based on the detection of objects of interest in the environment. An implementation of a mobile robot system that combines autonomous exploration and mapping capabilities with a real-time object recognition method based on a deep neural network running on a mobile GPU, is described. The system is able to detect objects of interest and then take real-time actions to interact with the objects, in this case, by moving to acquire inspection-style images of the object, from multiple angles. The robot system is small, self-contained and runs on battery power. The system shows the potential for the development of robotic systems with context awareness, permitting advanced autonomy.",https://ieeexplore.ieee.org/document/9041114/,2020 International SAUPEC/RobMech/PRASA Conference,29-31 Jan. 2020,ieeexplore
10.1109/ICEEE.2011.6106626,Continuous-time neural control for a 2 DOF vertical robot manipulator,IEEE,Conferences,"This paper presents a continuous-time neural control scheme for identification and control of a two degrees of freedom (DOF) direct drive vertical robot manipulator model, on which effects due to friction and gravitational forces are both considered. A recurrent high-order neural network (RHONN) structure is proposed in order to identify the plant model to then, based on this neural structure, derive a neural controller using the backstepping design methodology. The trajectory tracking performance of the neural controller is illustrated via simulations results, which suggest the validity of the proposed approach for its implementation in real-time.",https://ieeexplore.ieee.org/document/6106626/,"2011 8th International Conference on Electrical Engineering, Computing Science and Automatic Control",26-28 Oct. 2011,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ICNC.2008.718,Corridor-Scene Classification for Mobile Robot Using Spiking Neurons,IEEE,Conferences,"The ability of cognition and recognition for complex environment is very important for a real autonomous robot. A corridor-scene-classifier based on spiking neural networks (SNN) for mobile robot is designed to help the mobile robot to locate correctly. In the SNN classifier, the integrate-and-fire model (IAF) spiking neuron model is used and there is lateral inhibiting in the output layer. The winner-take-all rule is used to modify the connecting weights between the hidden layer and the outputting layer. The experimental results show that the corridor-scene-classifier is effective and it also has strong robustness.",https://ieeexplore.ieee.org/document/4667262/,2008 Fourth International Conference on Natural Computation,18-20 Oct. 2008,ieeexplore
10.1109/IROS.2018.8593374,Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan,IEEE,Conferences,"The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.",https://ieeexplore.ieee.org/document/8593374/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICRA.2019.8794187,Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation,IEEE,Conferences,"The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.",https://ieeexplore.ieee.org/document/8794187/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IJCNN.2018.8489239,Deep Learning-based Cooperative Trail Following for Multi-Robot System,IEEE,Conferences,"Following trails in the wild is an essential capability of out-door autonomous mobile robots. Recently, deep learning-based approaches have made great advancements in this field. However, the existing research only focuses on the trail following with a single robot. In contrast, many robotic tasks in the reality, such as search and patrolling, are conducted by a group of robots. While these robots are grouped to move in the wild, they can cooperate to significantly promote the trail following accuracy, for example, by sharing images of different view angles or real-time decision fusion. This paper proposes such an approach named DL-Cooper that enables multi-robot vision-based trail following based on deep learning algorithms. It allows each robot to make a decision respectively with deep neural network and then fusion the decisions on the collective level with the support of back-end cloud computing infrastructure. It also takes Quality of Service (QoS) assurance, a very essential property of robotic software, into consideration. By limiting the condition to fusion decisions, the time latency can be minimally sacrificed. Experiments on the real-world dataset show that our approach has significantly improved the accuracy of the single-robot system.",https://ieeexplore.ieee.org/document/8489239/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICARSC52212.2021.9429811,Deep Reinforcement Multi-Directional Kick-Learning of a Simulated Robot with Toes,IEEE,Conferences,"This paper describes a thorough analysis of using PPO to learn kick behaviors with simulated NAO robots in the simspark environment. The analysis includes an investigation of the influence of PPO hyperparameters, network size, training setups and performance in real games. We believe to improve the state of the art mainly in four points: first, the kicks are learned with a toed version of the NAO robot, second, we improve the reliability with respect to kickable area and avoidance of falls, third, the kick can be parameterized with desired distance and direction as input to the deep network and fourth, the approach allows to integrate the learned behavior seamlessly into soccer games. The result is a significant improvement of the general level of play.",https://ieeexplore.ieee.org/document/9429811/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/BDAI52447.2021.9515251,Design and Simulation of Tracked Mobile Robot Path Planning,IEEE,Conferences,"Aiming at the problem of autonomous navigation of robots in unknown environments, the robot operating system ROS is used as a development platform, and an autonomous navigation system is designed based on open source function packages such as Gmapping and Navigation, so that robots equipped with this system can learn map information in unknown environments. And based on the map to achieve positioning, path planning, obstacle avoidance and other functions. The 3D physical simulation software Gazebo simulates the environment and loads the designed URDF robot model to simulate and verify the autonomous navigation system. The results show that the autonomous navigation system can enable the robot to achieve accurate mapping, positioning, real-time obstacle avoidance and path planning in an unknown environment.",https://ieeexplore.ieee.org/document/9515251/,2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI),2-4 July 2021,ieeexplore
10.1109/AINL-ISMW-FRUCT.2015.7382967,Design and implementation Raspberry Pi-based omni-wheel mobile robot,IEEE,Conferences,Nowadays simultaneous localization and mapping (SLAM) algorithms are being tested at least in two phases: software simulation and real hardware platform testing. This paper describes hardware design and control software for small size omni-directional wheels robot implemented for indoor testing SLAM algorithms.,https://ieeexplore.ieee.org/document/7382967/,"2015 Artificial Intelligence and Natural Language and Information Extraction, Social Media and Web Search FRUCT Conference (AINL-ISMW FRUCT)",9-14 Nov. 2015,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/ICMA.2017.8015890,Design and implementation of self-tuning control method for the underwater spherical robot,IEEE,Conferences,"Considering the complicated disturbance in underwater circumstance, usually it is difficult to solve the control problem when the robot changes its motion state or it is subject to ocean currents, its performance deteriorates since the fixed set of parameters is no longer valid for the new conditions. Thus, in this paper, an auto-tune PID (Proportional + Integral + Derivative)-like controller based on Neural Networks is applied to our amphibious spherical underwater robot, which has a great advantage on processing online for the robot due to their nonlinear dynamics. The Neural Networks (NN) plays the role of automatically estimating the suitable set of PID gains that achieves stability of the system. The NN adjusts online the controller gains that attain the smaller position tracking error. The performance of the NN-based controller is investigated in ADAMS and MATLAB cooperative simulation. The velocity of the spherical robot can be controlled to precisely track desired trajectory in body-fixed coordinate system. Additionally, real time experiments on our underwater spherical robot are conducted to show the effectiveness of the algorithm.",https://ieeexplore.ieee.org/document/8015890/,2017 IEEE International Conference on Mechatronics and Automation (ICMA),6-9 Aug. 2017,ieeexplore
10.1109/AEMCSE51986.2021.00262,Design of Motion Control System of Handling Robot,IEEE,Conferences,"Handling robots are very important for improving productivity, reducing work intensity, improving the surrounding environment, and ensuring work safety. Based on the kinematics analysis of a two-degree-of-freedom manipulator based on a slider mechanism, this paper uses an open motion controller as a development platform to carry out hardware design and software development to realize the flexible control of the handling robot, with simple structure and real-time control, open structure, standard programming and rich man-machine interface, etc. which can be widely used in material destacking and palletizing handling.",https://ieeexplore.ieee.org/document/9513197/,"2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)",26-28 March 2021,ieeexplore
10.1109/AIEA53260.2021.00013,Design of a Real-time Robot Control System oriented for Human-Robot Cooperation,IEEE,Conferences,"An open real-time control system based on the EtherCAT fieldbus communication technology is proposed to fulfill the high real-time requirement of the human-robot cooperation controller in this paper. An open source real-time kernel of Xenomai is employed as the real-time software platform of the robot control system. Based on this, four-layer interfaces architecture are accomplished, which are human-machine cooperation control layer, motion control layer, robot axis control layer and hardware abstraction layer, through the corresponding four real-time tasks to meet the demand of human-robot cooperation operations. In addition, the scheduling task is developed to manage the 4 real-time tasks. The dual buffer communication mechanisms and priority-based scheduling strategy between layers was exploited to synchronize these real-time tasks. The underlying hardware abstract interface and the human-robot collaborative control algorithm interface are opened in the control system as the quadric exploitation interfaces to meet the need of developing application tasks in real-time space. Experiment results which are conducted on a self-developed 6-DOF collaborative robot show that the proposed control system is effective in real-time control applications of human-robot cooperative control at the control cycle of 5 milliseconds.",https://ieeexplore.ieee.org/document/9525600/,2021 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA),14-16 May 2021,ieeexplore
10.1109/CNNA.2000.876849,Design of a dedicated CNN chip for autonomous robot navigation,IEEE,Conferences,"Obstacle avoidance is the main issue in autonomous robotics. It requires a three-dimensional effective environment sensing in real time. Among the others, the stereo vision approach to environmental information extraction seems to be very appealing, even if it leads an extremely high computational cost. However, a high performance implementation of this algorithm on a cellular neural network is able to overcome these difficulties. In the paper, the design of a CNN chip well suited for this algorithm is presented. This chip, performing a real time processing of the stereo vision data, will improve the cruising speed of a robotic platform.",https://ieeexplore.ieee.org/document/876849/,Proceedings of the 2000 6th IEEE International Workshop on Cellular Neural Networks and their Applications (CNNA 2000) (Cat. No.00TH8509),25-25 May 2000,ieeexplore
10.1109/CMCE.2010.5609659,Design of mobile robot system with remote control based on CAN-bus,IEEE,Conferences,"In order to realizing remote control and information collection quickly and reliably, the mobile robot with remote control is designed. In the paper, according to analysis of the overall structure, hardware circuit of the robot system is designed. Because the CAN2.0 standard only makes physical layer protocol and data link layer protocol, application layer protocol is ruled according to robot control system. In the last part of this paper, the software of master/slave computer is introduced in detail. The experiment shows that running performance of robot control system is balanced, efficient and has satisfied the practical demand.",https://ieeexplore.ieee.org/document/5609659/,"2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering",24-26 Aug. 2010,ieeexplore
10.1109/ICSMC.1998.726514,"Designing, making, and using a mobile robot",IEEE,Conferences,"Describes the building and control of a mobile robot which is capable of navigating in a well defined workspace by means of generating an optimal trajectory. The basic control architecture of the mobile robot is implemented with a combination of an MC68HC11 microcontroller and a personal computer. The kinematics of the proposed differential impulse is analyzed which allow us to select the appropriate steering DC motors and speed measurement requirements of the system. The motor control is performed by a PWM scheme and PI controllers. A path planning stage finds the optimal trajectory, taking a graphical description of the workspace and using potential fields and dynamic programming to solve the optimization problem and avoid the obstacles. Clearly there are two specific problems: building a complete device that will allow having an electric powered robot and the use of these resources to obtain controlled and collision-free movement in a real workspace.",https://ieeexplore.ieee.org/document/726514/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICoSTA48221.2020.1570615971,Detecting Features of Middle Size Soccer Field using Omnidirectional Camera for Robot Soccer ERSOW,IEEE,Conferences,"ERSOW (EEPIS Robot Soccer on Wheeled) is robot soccer developed by Politeknik Elektronika Negeri Surabaya that is designed and implemented on a Middle Size League division by following the rules of RoboCup, an international robot competition. One of the most famous division is a soccer robot, that is divided into two divisions: (1) SSL (Small Size League) and (2) MSL (Middle Size League). There are many research fields related to soccer robot which must be developed in robot ERSOW such as Artificial Intelligence (AI), Computer Vision, Embedded System, Mechanic Systems, and Hardware. This paper focuses on computer vision research for robot ERSOW, especially detecting features of the middle size soccer field, so that specific features of the field like X-junction, T-junction and L-junction can be detected to help robot positioning task where the result is represented into x and y in real-world coordinate. By knowing the position of the features, the robot position can be calculated. The localization system at robot ERSOW uses odometry, which has a large percentage of data errors. Therefore, we attempt to extract the feature of X-junction that is done to find its x and y coordinates and then the obtained coordinate can be used as a reference for correcting odometry data by AI.",https://ieeexplore.ieee.org/document/9079260/,2020 International Conference on Smart Technology and Applications (ICoSTA),20-20 Feb. 2020,ieeexplore
10.1109/ICCSPN46366.2019.9150190,Developing A Framework for A Tactile Internet Enabled Robot Assisted Real-Time Interactive Medical System,IEEE,Conferences,"In this paper we outline a high-level framework and architecture for a robotic assisted real time interactive medical system for use in developing countries to help cure the acute shortage of qualified skill medical personnel in the health sector in of an internet of skills domain. We explore the application of new and innovative advancements in technological areas such as AI, 5G mobile networks, the tactile internet networks, robotics and haptic technology to aid in the digital transfer of medical expertise over a wide geographical area. We describe and propose technical specifications of such systems and review existing literature and current technologies in these areas. We interrogate the potential benefits and challenges facing the deployment of these technologies.",https://ieeexplore.ieee.org/document/9150190/,"2019 International Conference on Communications, Signal Processing and Networks (ICCSPN)",29-31 May 2019,ieeexplore
10.1109/MHS.2000.903293,Developing Khepera robot applications in a Webots environment,IEEE,Conferences,"Khepera is a high performance mini-robot. Its compact power allows an efficient experimentation using a real robot and applying the basic simulation tools. Webots is a high quality Khepera simulator used in the fields of autonomous systems, intelligent robotics, evolutionary robotics, machine learning, computer vision, and artificial intelligence. The simulation program can be transferred to the real robots easily. The aim of this article is to support the development of Khepera applications in the Webots environment. Starting from the introduction of Khepera robot and its development methodologies, the paper presents and analyses an application example of Khepera robot in the Webots environment. Finally, current applications and future research directions are presented.",https://ieeexplore.ieee.org/document/903293/,MHS2000. Proceedings of 2000 International Symposium on Micromechatronics and Human Science (Cat. No.00TH8530),22-25 Oct. 2000,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/FarEastCon.2018.8602651,Development of a Transport Robot for Automated Warehouses,IEEE,Conferences,"Industrial robots and manipulators are widely used as transport-loading devices in automated production. It is possible to combine equipment into coordinated production complexes of various sizes with the help of robots and they will not be bound by rigid planning and the number of installed units. Transport robots have proven themselves as flexible automated means of realizing intra-shop and interoperation material connections. More and more companies are developing technologies for vehicles through which they can communicate with each other and use real-time data from production infrastructure facilities. Electric vehicles and unmanned vehicles have become a new technological trend. In this regard, the paper deals with a prototype of an innovative transport robot, created for automated warehouses. It is proposed to use a computer vision system with image recognition based on the embedded software for the transport robot positioning inside the production facilities. The algorithm of deep machine learning was adapted to solve this problem. Using this algorithm, the prototype tests were performed successfully.",https://ieeexplore.ieee.org/document/8602651/,2018 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon),3-4 Oct. 2018,ieeexplore
10.1109/IJCNN48605.2020.9207522,Discrete-Time Lyapunov based Kinematic Control of Robot Manipulator using Actor-Critic Framework,IEEE,Conferences,"Stability and optimality are the two foremost re-quirements for robotic systems that are deployed in critical operations and are to work for long hours or under limited energy resources. To address these, in this work we present a novel Lyapunov stability based discrete-time optimal kinematic control of a robot manipulator using actor-critic (AC) framework. The robot is actuated using optimal joint-space velocity control input to track a time-varying end-effector trajectory in its task space. In comparison to the existing near-optimal kinematic control solutions for robot manipulator under AC framework, proposed controller exhibits guaranteed analytical stability. We derive a novel critic weight update law based on Lyapunov stability, thus ensuring that the weights are updated along the negative gradient of Lyapunov function. This eventually ensures closed-loop system stability and convergence to the optimal control in discrete-time. Extensive simulations are performed on a 3D model of 6-DoF Universal Robot (UR) 10 in Gazebo, followed by implementation on real UR 10 robot manipulator to show the efficacy of the proposed scheme.",https://ieeexplore.ieee.org/document/9207522/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1049/cp.2012.1127,Distributed parallel processing of mobile robot PF-SLAM,IET,Conferences,"Real-time property is a fundamental requirement for a practical robot system. For this purpose, this article proposes an implementation architecture of robot SLAM by adopting two parallel threads processing. Since the dominant factor which determines the computational complexity is the employed particle number, two distributed threads with different particle set size are executed simultaneously. Conventional PF-SLAM algorithm occupies one of threads, and the other thread which hires more particles is activated whenever robot has significant motion changes. Advantages of this presented idea are validated by experiment carried on Pioneer robot.",https://ieeexplore.ieee.org/document/6492734/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/SCCC.2001.972633,Domain-dependent option policies in autonomous robot learning,IEEE,Conferences,"In control-related applications such as robotics, determination of optimal solutions is made very difficult for many reasons. Among these stands the difficulty in finding out an appropriate model of the domain, as defined by the control agent (robot), environment where it acts and their interaction. Reinforcement learning is a theory which defines a collection of algorithms for determination of control actions under model-free assumptions, which allows control agents to learn optimal actions in an autonomous way. In reinforcement learning, a cost functional to be optimised is determined in advance. The agent then learns how to perform this optimisation via trial and error on its environment. A trial corresponds to execution of actions chosen by the agent, and the error is the immediate result (a real-valued reinforcement) of this action. In the work reported, we consider trials by a learning robotic agent which are not based on low level actions, but instead on sequences of actions (options or macro-operators). We analysed the performance both in terms of learning speed and quality of learned control-for options that correspond to mappings from states to action policies (O/sub /spl Pi// options). Experimental results show that careful (domain-dependent) selection of options (via methods such as discretised potential fields) produce much faster learning for option-based robots when compared to their action-based counterparts. Of critical importance, however, is the option mapping in regions of the state space where the options are not assumed to be necessary: as performance of reinforcement learning algorithms is strongly dependent on sufficient exploration of the state space, even in such regions a careful, ad-hoc selection of actions is of foremost importance.",https://ieeexplore.ieee.org/document/972633/,SCCC 2001. 21st International Conference of the Chilean Computer Science Society,9-9 Nov. 2001,ieeexplore
10.1109/SNPD.2008.97,Early-Life Cycle Reuse Approach for Component-Based Software of Autonomous Mobile Robot System,IEEE,Conferences,"Applying software reuse to many embedded realtime systems, such as autonomous mobile robot system poses significant challenges to industrial software processes due to the resource-constrained and realtime requirements of the systems. An approach for early life-cycle systematic reuse for component-based software engineering (ELCRA) of autonomous mobile robot software is developed. The approach allows reuse at the early stage of software development process by integrating analysis patterns, component model, and component-oriented programming framework. The results of applying the approach in developing software for real robots show that the strategies and processes proposed in the approach can fulfill requirements for self-contained, platform-independent and real-time predictable mobile robot.",https://ieeexplore.ieee.org/document/4617381/,"2008 Ninth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing",6-8 Aug. 2008,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/ICRA.2019.8793748,Effect of Mechanical Resistance on Cognitive Conflict in Physical Human-Robot Collaboration,IEEE,Conferences,"Physical Human-Robot Collaboration (pHRC) is about the interaction between one or more human operator(s) and one or more robot(s) in direct contact and voluntarily exchanging forces to accomplish a common task. In any pHRC, the intuitiveness of the interaction has always been a priority, so that the operator can comfortably and safely interact with the robot. So far, the intuitiveness has always been described in a qualitative way. In this paper, we suggest an objective way to evaluate intuitiveness, known as prediction error negativity (PEN) using electroencephalogram (EEG). PEN is defined as a negative deflection in event related potential (ERP) due to cognitive conflict, as a consequence of a mismatch between perception and reality. Experimental results showed that the forces exchanged between robot and human during pHRC modulate the amplitude of PEN, representing different levels of cognitive conflict. We also found that PEN amplitude significantly decreases (p &lt;; 0.05) when a mechanical resistance is being applied smoothly and more time in advance before an invisible obstacle, when compared to a scenario in which the resistance is applied abruptly before the obstacle. These results indicate that an earlier and smoother resistance reduces the conflict level. Consequently, this suggests that smoother changes in resistance make the interaction more intuitive.",https://ieeexplore.ieee.org/document/8793748/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ROMAN.2009.5326159,Efficient parsing of spoken inputs for human-robot interaction,IEEE,Conferences,"The use of deep parsers in spoken dialogue systems is usually subject to strong performance requirements. This is particularly the case in human-robot interaction, where the computing resources are limited and must be shared by many components in parallel. A real-time dialogue system must be capable of responding quickly to any given utterance, even in the presence of noisy, ambiguous or distorted input. The parser must therefore ensure that the number of analyses remains bounded at every processing step. The paper presents a practical approach to addressing this issue in the context of deep parsers designed for spoken dialogue. The approach is based on a word lattice parser combined with a statistical model for parse selection. Each word lattice is parsed incrementally, word by word, and a discriminative model is applied at each incremental step to prune the set of resulting partial analyses. The model incorporates a wide range of linguistic and contextual features and can be trained with a simple perceptron. The approach is fully implemented as part of a spoken dialogue system for human-robot interaction. Evaluation results on a Wizard-of-Oz test suite demonstrate significant improvements in parsing time.",https://ieeexplore.ieee.org/document/5326159/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICE2T.2017.8215992,Elevator button and floor number recognition through hybrid image classification approach for navigation of service robot in buildings,IEEE,Conferences,"To successfully move a robot into the building, the elevator button and elevator floor number detection and recognition can play an important role. It can help a robot move in the building, just as it also can help a visually impaired person who wants to move another floor in the building. Due to vision-based approach, the difference in lighting condition and the complex background are the main obstacles in this research. A hybrid image classification model is presented in this research to overcome all these difficulties. This hybrid model is the combination of histogram of oriented gradients and bag of words models, which later reduces the dimension of image features by using the feature selection algorithm. An artificial neural network has been implemented to get the experimental result by training and testing. In order to get training performance, 1000 training image samples have been used and additional 1000 image samples also been used to get the testing performance. The experimental results of this research indicate that this proposed framework is important for real-time implementation to implement the elevator button and elevator floor number recognition framework.",https://ieeexplore.ieee.org/document/8215992/,2017 International Conference on Engineering Technology and Technopreneurship (ICE2T),18-20 Sept. 2017,ieeexplore
10.1109/ICIEV.2018.8641023,Embedded System based Bangla Intelligent Social Virtual Robot with Sentiment Analysis,IEEE,Conferences,"Bangla is the mother tongue of millions of people all over the world. Despite being a very popular language, any social virtual robot that can intelligently communicate in Bangla is a fairytale till now. One of the main reason of this is lack of rich text corpus and previous research on Bangla language. The proposed Bangla Intelligent Social Virtual Robot can communicate in Bangla intelligently and can express its reflective emotion virtually with the help of machine learning algorithms and sentiment analysis. In this paper, we discuss the approached system, design methodology and implementation details of first ever Bangla virtual embedded robot followed by the methodology of building a rich Bangla text corpus. The proposed embedded virtual robot turns out better performer when compared with only known Bangla intelligent chatbot named `Golpo' and the embedded system performance efficiency has been upgraded with the help CPU over-clocking technique.",https://ieeexplore.ieee.org/document/8641023/,"2018 Joint 7th International Conference on Informatics, Electronics & Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",25-29 June 2018,ieeexplore
10.1109/SII.2019.8700376,Emotion Recognition from Speech for an Interactive Robot Agent,IEEE,Conferences,"Speech is one of the fundamental approaches for human to human interaction. Given this, it should be the main approach for robot human interaction as well. Towards this, the research presented here focuses on emotion recognition from human speech to aid the interaction between humans and robots. There are various steps involved in developing emotion recognition system for an interactive robot agent. The first step is to choose a suitable dataset that is Berlin database for training and testing the models developed. The second important step is extraction and choice of suitable features related to emotions. The third step is to make an appropriate classification scheme. The performance of each classifier is analyzed and acomparison among multiple frameworks of emotion recognition is made. In response to the findings in these preliminary studies, a prototype application was developed to allow the recognition of emotions from speech in real-time for future use on an interactive robot. On a preliminary test set, the application achieved performance levels between 81% and 92%. The approach offers the integration of speech collection hardware, emotion recognition software, mobile devices and robotic systems to aid assist human-robot interaction.",https://ieeexplore.ieee.org/document/8700376/,2019 IEEE/SICE International Symposium on System Integration (SII),14-16 Jan. 2019,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/ICRA48506.2021.9562114,Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and Gamification,IEEE,Conferences,"Robot grasping and manipulation planning in unstructured and dynamic environments is heavily dependent on the attributes of manipulated objects. Although deep learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Moreover, training such models requires large datasets that are generally expensive to obtain. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation aspects of robot perception. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand an initial attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in a proof-of-concept application for enhancing object recognition in autonomous robot grasping and a model for estimating the response time is proposed. The obtained results demonstrate that given enough players, the framework can offer near real-time labeling of novel objects, based purely on visual information and human experience.",https://ieeexplore.ieee.org/document/9562114/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICCAE.2009.52,Environmental Recognition Using RAM-Network Based Type-2 Fuzzy Neural for Navigation of Mobile Robot,IEEE,Conferences,"Reactive autonomous mobile robot navigating in real time environment is one of the most important requirements. Most of the systems have some common drawbacks such as, large computation, expensive equipment, hard implementation, and the complexity of the system. The work presented in this paper deals with a type-2 fuzzy-neural controller using RAM-based network to make navigation decisions. The proposed architecture can be implemented easily with low cost range sensor and low cost microprocessor. To minimize the execution time, we used a look-up table and that output stored into the robot RAM memory and becomes the current controller that drives the robot. This functionality is demonstrated on a mobile robot using a simple, 8 bit microcontroller with 512 bytes of RAM. The experiment results show that source code is efficient, works well, and the robot was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/4804536/,2009 International Conference on Computer and Automation Engineering,8-10 March 2009,ieeexplore
10.1109/ICRA40945.2020.9197510,Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing,IEEE,Conferences,"This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.",https://ieeexplore.ieee.org/document/9197510/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/WCICA.2000.863468,Estimated force emulation for space robot using neural networks,IEEE,Conferences,"This paper introduces the telerobotic system estimated force emulation using neural networks. A delay-compensating 3D stereo-graphic simulator is implemented in SGI ONYX/4 RE/sup 2/. The estimated force emulation can protect the real robot in time from being damaged in collision. The neural network is used to learn the mapping between the contact force error and the accommodated position command to the controller of the space robot. Finally, the controller can feel the emulated force with a two-hand 6-DOF master arm using the force feedback interface.",https://ieeexplore.ieee.org/document/863468/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ROMAN.2007.4415203,Evolving Personality of a Genetic Robot in Ubiquitous Environment,IEEE,Conferences,"This paper discusses the personality of genetic robot and its evolving algorithm within the purview of the broader ubiquitous robot framework. Ubiquitous robot systems blends mobile robot technology (Mobot) with distributed sensor systems (Embot) and overseeing software intelligence (Sobot), for various integrated services. The Sobot is a critical question since it performs the dual purpose of overseeing intelligence as well as user interface. The Sobot is hence modelled as an artificial creature with autonomously driven behavior. The artificial creature has its own genome and in which each chromosome consists of many genes that contribute to defining its personality. This paper proposes evolving the personality of an artificial creature. A genome population is evolved such that it customized the genome satisfying a set of personality traits desired by the user. Evaluation procedure for each genome of the population is carried out in a virtual environment. Effectiveness of this scheme is demonstrated by using an artificial creature, Rity in the virtual 3D world created in a PC.",https://ieeexplore.ieee.org/document/4415203/,RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,26-29 Aug. 2007,ieeexplore
10.1109/INDIN.2017.8104924,Experiences in integrating Internet of Things and cloud services with the robot operating system,IEEE,Conferences,"New Internet of Things open source technologies, middlewares, and programming languages, make the quick integration of devices, systems and cloud services easier than never before. With their utilization, complex tasks such as object detection, tracking and tracing, can be easily realized, even by embedded devices in a fraction of time. The interplay of highly heterogeneous IoT devices and open source software, has been utilized in this work as a learning tool, in order to train developers and enhance their IoT skills. By designing, implementing, testing and deploying a rapid prototype, new knowledge is acquired, assessment of technologies and concepts is carried out, and the end-result, although developed in a constraint timeframe, is technologically promising, cost-effective and feature-rich. This work sheds some light on the prototype implemented and discusses the developer experiences and benefits of this IoT integration hands-on approach.",https://ieeexplore.ieee.org/document/8104924/,2017 IEEE 15th International Conference on Industrial Informatics (INDIN),24-26 July 2017,ieeexplore
10.1109/ICITA.2005.135,Experiences with simulated robot soccer as a teaching tool,IEEE,Conferences,"The development of assignments for undergraduate teaching typically requires a compromise between what is achievable by an average student and what engages the interest of a more advanced member of the class. Selecting a suitable compromise is particularly problematic for undergraduate artificial intelligence (AI) courses which typically attempt to cover a very broad range of topics, without delving too deeply into the details. Ideally, a single problem would be selected whose solution could be approached with more than one technique covered in the course, enabling students to carry out a comparative analysis of performance. Robot soccer simulation has provided an interesting platform for artificial intelligence research and is increasingly being used as a teaching apparatus. There are a number of limitations with existing simulation methodologies for this purpose. Current robot soccer simulators are aimed at research groups where accuracy is paramount and all facets of the real system must be emulated. However, many of the intricacies of a real robot soccer player are inappropriate for a teaching environment, as they detract from desired learning outcomes. Consequently, there is a need for a simulation that employs a simplified set of game rules and dynamics. This paper describes the design and implementation of such a framework and presents experiences gained from its use as a third year practical.",https://ieeexplore.ieee.org/document/1488833/,Third International Conference on Information Technology and Applications (ICITA'05),4-7 July 2005,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/ICRA48506.2021.9561040,Extendable Navigation Network based Reinforcement Learning for Indoor Robot Exploration,IEEE,Conferences,This paper presents a navigation network based deep reinforcement learning framework for autonomous indoor robot exploration. The presented method features a pattern cognitive non-myopic exploration strategy that can better reflect universal preferences for structure. We propose the Extendable Navigation Network (ENN) to encode the partially observed high-dimensional indoor Euclidean space to a sparse graph representation. The robot’s motion is generated by a learned Q-network whose input is the ENN. The proposed framework is applied to a robot equipped with a 2D LIDAR sensor in the GAZEBO simulation where floor plans of real buildings are implemented. The experiments demonstrate the efficiency of the framework in terms of exploration time.,https://ieeexplore.ieee.org/document/9561040/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/FPT.2009.5377635,FPGA implementation of mixed integer quadratic programming solver for mobile robot control,IEEE,Conferences,"We propose a high-speed mixed integer quadratic programming (MIQP) solver on an FPGA. The MIQP solver can be applied to various optimizing applications including real-time robot control. In order to rapidly solve the MIQP problem, we implement reusing a first solution (first point), pipeline architecture, and multi-core architecture on the single FPGA. By making use of them, we confirmed that 79.5% of the cycle times are reduced, compared with straightforward sequential processing. The operating frequency is 67 MHz, although a core 2 duo PC requires 3.16 GHz in processing the same size problem. The power consumption of the MIQP solver is 4.2 W.",https://ieeexplore.ieee.org/document/5377635/,2009 International Conference on Field-Programmable Technology,9-11 Dec. 2009,ieeexplore
10.1109/RCAR52367.2021.9517650,FT-MSTC*: An Efficient Fault Tolerance Algorithm for Multi-robot Coverage Path Planning,IEEE,Conferences,"Fault tolerance is very important for multi-robot systems, especially for those operated in remote environments. The ability to tolerate failures, allows robots effectively to continue performing tasks without the need for immediate human intervention. In this paper, we present a new efficient fault tolerance algorithm for multi-robot coverage path planning (mCPP). The entire coverage path is considered as a topological task loop. The ideal mCPP problem is handled by partitioning this task loop and assign each partition to individual robot. When a faulty robot is detected, we use an optimization method to minimize the overall maximum coverage cost while considering both the tasks accomplished before robot failures and the remaining tasks. We perform various experiments for regular grid maps and real field terrains. We compare our algorithm against other coverage path planning algorithms and our algorithm outperforms existing spiral-STC-based methods in terms of the overall maximum coverage cost.",https://ieeexplore.ieee.org/document/9517650/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ICMLC.2006.258689,Facial Tracking for an Emotion-Diagnosis Robot to Support E-Learning,IEEE,Conferences,"There have been a lot of researches on the detection/estimation of human emotions from facial expressions. However, most of them have extracted facial features for some specific emotions from the still pictures of artificial actions or performances. This paper describes facial tracking for e-learning support robot which can estimate a emotion of e-learning user from his/her facial expression in real-time; (1) the criteria of the facial expression to classify the eight emotions was obtained by the time sequential subjective evaluation on the emotions as well as the time sequential analysis of a facial expression by image processing. (2) The coincidence ratio between the discriminated emotions based upon the criteria of emotion diagnosis and the time sequential subjective evaluation on emotions for ten e-learning subjects was 69%. (3) Then, the possibility of the real time emotion diagnosis robot to support e-learning was confirmed by the facial image processing at the 15 frame/sec. rate as well as the simple emotion diagnosis algorithm based upon the Mahalonobis distance",https://ieeexplore.ieee.org/document/4028735/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/ICSMC.1997.633250,Facial interaction between animated 3D face robot and human beings,IEEE,Conferences,"We study the realization of a realistic human-like response of an animated 3D face robot in communicative interaction with human beings. The face robot can produce human-like facial expressions and recognize human facial expressions using facial image data obtained by a CCD camera mounted inside the left eyeball. We developed the real time machine recognition of facial expressions by using a layered neural network and achieved a high correct recognition ratio of 85% with respect to 6 typical facial expressions of 15 subjects in 55 ms. We also developed a new small-size actuator for display of facial expressions on the face robot, giving the same speed in dynamic facial expressions as in human even in the case of a high-speed expression of ""surprise"". For facial interactive communication between the face robot and human beings, we integrated these two technologies to produce the facial expression in respond to the recognition result of the human facial expression in real time. This implies a high technological potential for the animated face robot to undertake interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/633250/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/UR49135.2020.9144836,Fall detection based on CNN models implemented on a mobile robot,IEEE,Conferences,"Fall accidents are serious events that need to be addressed. Generally, elderly people could suffer these accidents that may lead injures or even death. The use of Convolutional Neural Networks (CNN) has achieved the state of the art for fall detection, but it requires a high computational cost. In this work, we propose an efficient CNN architecture with a reduced number of parameters, which is applied to fall detection in a service with a mobile robot, equipped with a resource-constrained hardware (Nvidia Jetson TX2 platform). Also, different pre-trained CNN models are compared to measure their performances in real scenarios, in addition with other functions like following people and navigation. Furthermore, fall detection is carried out by extraction of temporal features obtained with an Optical Flow extraction from two consecutive RGB images. The proposed network is confirmed by our results to be faster and more suitable for running on resource-constrained Hardware. Our model achieves 88.55% of accuracy using the proposed architecture and it works at 23.16 FPS on GPU and 10.23 FPS on CPU.",https://ieeexplore.ieee.org/document/9144836/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ISPACS.2018.8923369,Fast Recognition and Control of Walking Mode for Humanoid Robot Based on Pressure Sensors and Nearest Neighbor Search,IEEE,Conferences,"In this paper, we propose a nearest-neighbor multi-reference learning system for control of humanoid-robot movements, using real-time data from pressure sensors embedded in the robot feet, which is processed with parallelized pipeline architecture for high-speed recognition of actual surface conditions. A first nearest-neighbor (1-NN) classifier is used to recognize the most similar reference pattern in terms of the smallest Euclidean distance. Our proposed architecture achieves a classification time of about 2.4μ s with a total power consumption of 8.53mW at 100 MHz operating frequency when implemented on a low-cost FPGA (Cyclone-V GX-Series). The analysis results are further useful for a next-generation-ASIC-based AI-chip design for a robust real-time robot-learning system.",https://ieeexplore.ieee.org/document/8923369/,2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS),27-30 Nov. 2018,ieeexplore
10.1109/ROBOT.1996.506991,Fast connectionist learning for trailer backing using a real robot,IEEE,Conferences,This paper presents the application of a connectionist control-learning system to an autonomous mini-robot. The system's design is severely constrained by the computing power and memory available on board the mini-robot and the on-board training time is greatly limited by the short life of the battery. The system is capable of rapid unsupervised learning of output responses in temporal domains through the use of eligibility traces and data sharing within topologically defined neighborhoods.,https://ieeexplore.ieee.org/document/506991/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/SSCI.2017.8280891,Fault diagnosis in robot swarms: An adaptive online behaviour characterisation approach,IEEE,Conferences,"The need for an active approach to fault tolerance in swarm robotics systems is well established. This will necessarily include an approach to fault diagnosis if robot swarms are to retain long-term autonomy. This paper proposes a novel method for fault diagnosis, based around behavioural feature vectors, that incorporates real-time learning and memory. Initial results are encouraging, and show that an unsupervised learning approach is able to diagnose common electro-mechanical fault types, and arrive at an appropriate recovery option in the majority of the cases tested.",https://ieeexplore.ieee.org/document/8280891/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/RCAR.2018.8621723,Fault-Tolerant and Self-Adaptive Market-Based Coordination Using Hoplites Framework for Multi-Robot Patrolling Tasks,IEEE,Conferences,"An autonomous robot team can be employed for continuous coverage of a dynamic environment. In this paper, we propose a novel approach for creating multi-robot patrolling policies, which is fault-tolerant and self-adaptive. A dynamic priority queue and time-out replanning mechanism are maintained by each robot to schedule the tasks fault-tolerantly in the context of the market-based method. Hoplites framework is adapted by introducing a self-adaptive threshold adjustment and sharing mechanism to provide a high-level coordination. This work is demonstrated by a multi-robot patrolling task implemented on Robot Operating System (ROS). A flexible tool, Stage, is leveraged to provide the simulated environment. The experimental results validate the effectiveness and availability.",https://ieeexplore.ieee.org/document/8621723/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ICARSC52212.2021.9429801,Few-Shot Visual Grounding for Natural Human-Robot Interaction,IEEE,Conferences,"Natural Human-Robot Interaction (HRI) is one of the key components for service robots to be able to work in human-centric environments. In such dynamic environments, the robot needs to understand the intention of the user to accomplish a task successfully. Towards addressing this point, we propose a software architecture that segments a target object from a crowded scene, indicated verbally by a human user. At the core of our system, we employ a multi-modal deep neural network for visual grounding. Unlike most grounding methods that tackle the challenge using pre-trained object detectors via a two-stepped process, we develop a single stage zero-shot model that is able to provide predictions in unseen data. We evaluate the performance of the proposed model on real RGB-D data collected from public scene datasets. Experimental results showed that the proposed model performs well in terms of accuracy and speed, while showcasing robustness to variation in the natural language input.",https://ieeexplore.ieee.org/document/9429801/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/MMAR.2019.8864671,Fusion of Gesture and Speech for Increased Accuracy in Human Robot Interaction,IEEE,Conferences,"An approach for decision-level fusion for gesture and speech based human-robot interaction (HRI) is proposed. A rule-based method is compared with several machine learning approaches. Gestures and speech signals are initially classified using hidden Markov models, reaching accuracies of 89.6% and 84% respectively. The rule-based approach reached 91.6% while SVM, which was the best of all evaluated machine learning algorithms, reached an accuracy of 98.2% on the test data. A complete framework is deployed in real time humanoid robot (NAO) which proves the efficacy of the system.",https://ieeexplore.ieee.org/document/8864671/,2019 24th International Conference on Methods and Models in Automation and Robotics (MMAR),26-29 Aug. 2019,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/AIM.2009.5229761,Fuzzy and Neural controllers for acute obstacle avoidance in mobile robot navigation,IEEE,Conferences,"Robot navigation is the technique to guide the mobile robot move towards the desired goal where dynamic and unknown environment is involved. The environment is distinguished by variable terrain and also certain objects which are known as obstacles that may block the movement of the robot in reaching the desired destination. Fuzzy Logic (FL) and Artificial Neural Network (ANN) are used to assist autonomous mobile robot move, learn the environment and reach the desired goal. This research study is focused on exploring the four combinations of training algorithms composed of FL and ANN that avoid acute obstacles in the environment. Path Remembering algorithm proposed in this paper will assist the mobile robot to come out from acute obstacles. Virtual wall building method also is proposed in order to prevent the mobile robot reentering the same acute obstacle once it has been turned away from the wall. MATLAB simulation is developed to verify and validate the algorithms before they are implemented in real time on Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed the flexibility and robustness of the controllers designed in avoiding acute obstacles and a comparison of all the four combinations of algorithms is done to find the best combination of algorithms to perform the required navigation to avoid acute obstacles.",https://ieeexplore.ieee.org/document/5229761/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/FUZZY.1997.619465,Fuzzy behaviors combination to control a nonholonomic mobile robot using virtual perception memory,IEEE,Conferences,This paper presents the implementation of the combination of fuzzy reactive navigation behaviors using virtual perception memory. Robot control actions are generated by different fuzzy behavior components which cooperate to determine the motion of the vehicle. This approach differs from other methods in the use of a virtual perception memory to make a robot controller more robust with respect to temporary loss of sensorial information. Experimental results of an application to a real robot demonstrate the robustness of the proposed method.,https://ieeexplore.ieee.org/document/619465/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ISMA.2009.5164850,Fuzzy motion-based control for a bi-steerable mobile robot navigation,IEEE,Conferences,"This paper presents an implementation of a Fuzzy Motion Controller (FMC) to endow the mobile robot Robucar with capability to achieve the action behavior allowing smooth motion generation with intelligence in real-time. The robot state space (velocity and distances) is modeled in discrete intervals leading to linguistic variables. The fuzzy motion control rules are derived and used in a fuzzy inference mechanism to give the final control command to the robot actuators. Simulation and experimental results show FMC capabilities in generating smooth motions, illustrating then its adaptivity and intelligence.",https://ieeexplore.ieee.org/document/5164850/,2009 6th International Symposium on Mechatronics and its Applications,23-26 March 2009,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/ICMA.2007.4303585,Genetic Programming in Robot Exploration,IEEE,Conferences,"Exploration using mobile robots is an active research area. In general, an optimal robot exploration strategy is difficult to obtain. In this paper an investigation is conducted using genetic programming (GP) to solve this problem. GP is a form of artificial intelligence capable of automatically creating and developing computer programs to solve problems using the theory of evolution. However, like many other learning algorithms, GP is a computationally expensive and time-consuming process. This characteristic can impede its application where learning time is limited, such as in real-time robotic control applications. Therefore, this paper further investigates the possibility of developing a time-efficient GP algorithm to reduce evolution time. This is done by directly incorporating the amount of time evolved solutions take to form into the fitness function, in order to encourage time efficient problem solving. Experimental results have shown that while the time efficient aspect of the proposed GP algorithm is not conclusive, the robot exploration using GP produces promising outcomes.",https://ieeexplore.ieee.org/document/4303585/,2007 International Conference on Mechatronics and Automation,5-8 Aug. 2007,ieeexplore
10.1109/ICRA40945.2020.9196608,Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-to-end Robot Learning Scheme,IEEE,Conferences,"Traditional robotic control suits require profound task-specific knowledge for designing, building and testing control software. The rise of Deep Learning has enabled end-to-end solutions to be learned entirely from data, requiring minimal knowledge about the application area. We design a learning scheme to train end-to-end linear dynamical systems (LDS)s by gradient descent in imitation learning robotic domains. We introduce a new regularization loss component together with a learning algorithm that improves the stability of the learned autonomous system, by forcing the eigenvalues of the internal state updates of an LDS to be negative reals. We evaluate our approach on a series of real-life and simulated robotic experiments, in comparison to linear and nonlinear Recurrent Neural Network (RNN) architectures. Our results show that our stabilizing method significantly improves test performance of LDS, enabling such linear models to match the performance of contemporary nonlinear RNN architectures. A video of the obstacle avoidance performance of our method on a mobile robot, in unseen environments, compared to other methods can be viewed at https://youtu.be/mhEsCoNao5E.",https://ieeexplore.ieee.org/document/9196608/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROMAN.2009.5326235,Gestural teleoperation of a mobile robot based on visual recognition of sign language static handshapes,IEEE,Conferences,"This paper presents results achieved in the frames of a national research project (titled ldquoDIANOEMArdquo), where visual analysis and sign recognition techniques have been explored on Greek Sign Language (GSL) data. Besides GSL modelling, the aim was to develop a pilot application for teleoperating a mobile robot using natural hand signs. A small vocabulary of hand signs has been designed to enable desktopbased teleoperation at a high-level of supervisory telerobotic control. Real-time visual recognition of the hand images is performed by training a multi-layer perceptron (MLP) neural network. Various shape descriptors of the segmented hand posture images have been explored as inputs to the MLP network. These include Fourier shape descriptors on the contour of the segmented hand sign images, moments, compactness, eccentricity, and histogram of the curvature. We have examined which of these shape descriptors are best suited for real-time recognition of hand signs, in relation to the number and choice of hand postures, in order to achieve maximum recognition performance. The hand-sign recognizer has been integrated in a graphical user interface, and has been implemented with success on a pilot application for real-time desktop-based gestural teleoperation of a mobile robot vehicle.",https://ieeexplore.ieee.org/document/5326235/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/ISIC.1992.225127,Hierarchical architecture for multi-sensor robot cell operation,IEEE,Conferences,"The authors describe a hierarchical architecture designed to carry out experiments in multisensor integration and sensor-based control in robotics. The hierarchical model is composed of three major levels: a high-level information processing and planning structure at the top, a logic-branching control structure at the intermediate level, and a real-time continuous sensory feedback loop at the bottom level. The two lower control structures are addressed. The principal submodules of the intermediate structure are described, with particular emphasis on communication issues and on the available software mechanisms for configuration and online maintenance of the robot cell. The architecture of the real-time continuous control structure that composes the bottom level is also described. The application of the adaptive self-tuning scheme in controlling position and force, specified in task-space coordinates, is discussed. Practical issues and experimental results are summarized.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/225127/,Proceedings of the 1992 IEEE International Symposium on Intelligent Control,11-13 Aug. 1992,ieeexplore
10.1109/ICSMC.1996.565422,High speed neural control for robot navigation,IEEE,Conferences,"This paper addresses the real time control of the Khepera mobile robot navigation in a maze with reflector walls. Boolean neural networks such as RAM and GSN models are applied to drive the vehicle, following a light source, while avoiding obstacles. Both neural networks are implemented with simple logic and arithmetic functions (NOT, AND, OR, Addition, and Comparison), aiming to improve the system speed. The results obtained are compared with two other control strategies: multilayer perceptron and fuzzy logic.",https://ieeexplore.ieee.org/document/565422/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA48506.2021.9561034,High-Speed Robot Navigation using Predicted Occupancy Maps,IEEE,Conferences,"Safe and high-speed navigation is a key enabling capability for real world deployment of robotic systems. A significant limitation of existing approaches is the computational bottleneck associated with explicit mapping and the limited field of view (FOV) of existing sensor technologies. In this paper, we study algorithmic approaches that allow the robot to predict spaces extending beyond the sensor horizon for robust planning at high speeds. We accomplish this using a generative neural network trained from real-world data without requiring human annotated labels. Further, we extend our existing control algorithms to support leveraging the predicted spaces to improve collision-free planning and navigation at high speeds. Our experiments are conducted on a physical robot based on the MIT race car using an RGBD sensor where were able to demonstrate improved performance at 4 m/s compared to a controller not operating on predicted regions of the map.",https://ieeexplore.ieee.org/document/9561034/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore
10.1109/YAC53711.2021.9486647,Human-Robot Interaction System Design for Manipulator Control Using Reinforcement Learning,IEEE,Conferences,"In this article, a novel human-robot interaction (HRI) system is presented and applied in the robotic arm coordinated operation control task. The presented HRI system includes two parts, the impedance model controller and the robotic arm controller, which allows the operator to manipulate the robotic arm to accomplish the given task with minimal human effort. First, the model-based reinforcement learning (RL) method is applied in the impedance model for operator adaptation. The impedance model controller can transform human input into the specific signal for the manipulator. Second, a novel adaptive manipulator controller is designed. In contrast to existing controllers, a velocity-free filter is implemented in our controller, which is developed to replace the manipulator actuator's speed signal. The effectiveness of the presented HRI system is verified by the simulation based on real manipulator parameters.",https://ieeexplore.ieee.org/document/9486647/,2021 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC),28-30 May 2021,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/EPIA.2005.341221,Hybrid State Machines with Timed Synchronization for Multi-Robot System Specification,IEEE,Conferences,"In multi-robot systems, the need for precise modeling or specification of agent behaviors arises due to the high complexity of the robot agent interactions and the dynamics of the environment. Since the behavior of agents usually can be understood as driven by external events and internal states, it is obvious to model multiagent systems by state transition diagrams. The corresponding formalisms come equipped with a formal semantics which is advantageous. In this paper, a combination of UML statecharts and hybrid automata is proposed, allowing formal system specification on different levels on abstraction on the one hand, and expressing real-time system behavior with continuous variables on the other hand. One important aspect of multi-robot systems is the need of coordination and hence synchronization of behavior. For both, statecharts and hybrid automata, it is assumed that synchronization takes zero time. This is sometimes unrealistic. Therefore, a new notation and implementation of synchronization is proposed here, which overcomes this problem. The proposed method is illustrated with a case study from the robotic soccer domain",https://ieeexplore.ieee.org/document/4145962/,2005 portuguese conference on artificial intelligence,5-8 Dec. 2005,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/iFuzzy.2013.6825409,Implementation of human following mission by using fuzzy head motion control and Q-learning wheel motion control for home service robot,IEEE,Conferences,"This paper mainly implements human following function for home service robot, May, developed in our laboratory. In order to follow the operator accurately, visual tracking is composed by Tracing-Learning-Detection (TLD) and Kinect skeleton, where TLD plays the role as re-detecting the situation that operator is occluded or disappeared, and Kinect skeleton is adopted to track all other situations while TLD is learning how to enlarge operator image patterns in order to enhance recognition rates. For the sake of improving tracking capability, fuzzy head motion control is added in the visual tracking system to compensate the constraints that the mobile platform of May cannot react rapidly. Every instant movement of the operator can be captured by fuzzy head motion control in real time. Q-learning is applied to discover the pose switching of the mobile platform such that May possesses more robust following ability. By Q-learning, states setting are based on three dimensional position, actions are created by the pose of four wheel independent steering and four wheel independent driven (4WIS4WID) platform, and rewards are established on state transitions. Finally, both the experimental results in the laboratory and competition consequents of Follow Me Mission in robot@home league at RoboCup Japan Open 2013 Tokyo demonstrate that our robot May can fluently switch its poses to follow operator by utilizing the proposed schemes.",https://ieeexplore.ieee.org/document/6825409/,2013 International Conference on Fuzzy Theory and Its Applications (iFUZZY),6-8 Dec. 2013,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/INES.1997.632397,Implementation of neural network sliding-mode controller for DD robot,IEEE,Conferences,"The experimental development of a trajectory tracking neural network controller based on the theory of continuous sliding-mode controllers is shown in the paper. The neural network control law was verified on a real direct drive 3 DOF PUMA mechanism. The new neural network sliding-mode controller was successfully tested for trajectory tracking sudden changes in the manipulator dynamics (load). The comparision between the neural network sliding mode controller, a computer torque method controller and a continuous sliding mode controller with PI-estimator for sudden load changes on the real robot mechanism is shown.",https://ieeexplore.ieee.org/document/632397/,Proceedings of IEEE International Conference on Intelligent Engineering Systems,17-17 Sept. 1997,ieeexplore
10.1109/I2CT.2014.7092212,Implementation of synthetic brain concept in humanoid robot,IEEE,Conferences,"This paper is elaborate the model of humanoid robot interacts with human being and perform various operation as per the command given by the human being. A humanoid robot having Synthetic brain can able to do Interaction, communication, Object detection, information acquisition about any object, response to voice command, chatting logically with human beings. Object detection will be done by this robot for that purpose there is use image processing concept (HAAR Technique), And to make the system intelligent that is whenever system interact, communicate, chat with human it gives proper response, question / answers there is integrates artificial intelligence and DFA / NFA automata and Prolog language concept for answering logically over the complex and relevant strings or data.",https://ieeexplore.ieee.org/document/7092212/,International Conference for Convergence for Technology-2014,6-8 April 2014,ieeexplore
10.1109/COGINF.2011.6016164,Improved mobile robot's Corridor-Scene Classifier based on probabilistic Spiking Neuron Model,IEEE,Conferences,"The ability of cognition and recognition for complex environment is very important for a real autonomous robot. A improved Corridor-Scene-Classifier based on probabilistic Spiking Neuron Model(pSNM) for mobile robot is designed. In the SNN classifier, the model pSNM is used. As network's training, Thorpe's learning rule is used. The experimental results show that the improved Classifier is more effective and it also has stronger robustness than the previous classifier based on Integrated-and-Fire (IAF) spiking neuron model for the structural corridor-scene. It also has better robustness than the traditional kernel-pca and the BP Corridor-Scene-classifier.",https://ieeexplore.ieee.org/document/6016164/,IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11),18-20 Aug. 2011,ieeexplore
10.1109/ELECSYM.2018.8615506,Improving Field and Ball Detector for Humanoid Robot Soccer EROS Platform,IEEE,Conferences,"Humanoid robot soccer perceives environment mostly through cameras. The performance decrement in our humanoid soccer platform (EROS) is primarily due to the visual perception that is less robust to the RoboCup new rule which specifically reducing color coding in the field. Notable works favorably employ simple color segmentation, image morphology, and blob detector due to simplicity in the implementation and run in real-time for most embedded hardware, while some employ a more advanced supervised learning running in sophisticated hardware to boost detection accuracy. In this paper, a visual perception system consisting of field and ball detection is developed in our platform EROS to address the RoboCup new rule. Color segmentation and image morphology are stacked with a more advanced supervised learning cascade classifier. In this way, the favorable color segmentation and image morphology help to reduce the number of object candidates while the cascade classifier helps to boost the accuracy of detection. Experiments show encouraging result for detecting field and ball position. Our approach has successfully been implemented in practice and achieves remarkably result in Indonesian humanoid robot soccer competition.",https://ieeexplore.ieee.org/document/8615506/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/CASE48305.2020.9216902,Industrial Robot Grasping with Deep Learning using a Programmable Logic Controller (PLC),IEEE,Conferences,"Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95% with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world's largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",https://ieeexplore.ieee.org/document/9216902/,2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),20-21 Aug. 2020,ieeexplore
10.1109/ROBOT.1992.219999,Integrated planning and execution control of autonomous robot actions,IEEE,Conferences,"The authors describe an implemented integrated system allowing a mobile robot to plan its actions, taking into account temporal constraints, and to control their execution in real time. The general architecture has three levels, and the approach is related to hierarchical planning: the plan produced by the temporal planner is further refined at the control level, which in turn supervises its execution by a functional level. The framework of the French Mars Rover project VAP is used as an illustration of the various aspects discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/219999/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/CIRA.1997.613877,Intelligence computing for direct human-robot communication using natural language and cognitive graphics,IEEE,Conferences,"A direct human-robot communication system based on natural language (NL) and cognitive graphics (CG) as a part of a new hierarchical structure of an AI control system of a mobile robot for service use (MRSU) is developed. The software of the simulation system for direct human-robot communication and MRSU behavior based on NL and CG is described. The NL and CG are used for description and representation of possible external worlds in the robot artificial life. This system allows us to evaluate the control algorithms of real time robot behavior and to reduce difficulties connected with such troubles as robot collisions with real objects and robot hardware damage. The mathematical background of direct NL human-robot communication and robot behavior simulation system is knowledge engineering based on spatio-temporal and action logics, default reasoning, cognitive graphics and soft computing. The main concepts, structure, conceptual model of the simulation system for description of the artificial life of the MRSU are discussed. A simulation example and real experimental results are described.",https://ieeexplore.ieee.org/document/613877/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/ARIS50834.2020.9205772,Intelligent Robot for Worker Safety Surveillance: Deep Learning Perception and Visual Navigation,IEEE,Conferences,"The fatal injury rate for the construction industry is higher than the average for all industries. Recently, researchers have shown an increased interest in occupational safety in the construction industry. However, all the current methods using conventional machine learning with stationary cameras suffer from some severe limitations, perceptual aliasing (e.g., different places/objects can appear identical), occlusion (e.g., place/object appearance changes between visits), seasonal / illumination changes, significant viewpoint changes, etc. This paper proposes a perception module using end-to-end deep-learning and visual SLAM (Simultaneous Localization and Mapping) for an effective and efficient object recognition and navigation using a differential-drive mobile robot. Various deep-learning frameworks and visual navigation strategies with evaluation metrics are implemented and validated for the selection of the best model. The deep-learning model's predictions are evaluated via the metrics (model speed, accuracy, complexity, precision, recall, P-R curve, F1 score). The YOLOv3 shows the best trade-off among all algorithms, 57.9% mean average precision (mAP), in real-world settings, and can process 45 frames per second (FPS) on NVIDIA Jetson TX2 which makes it suitable for real-time detection, as well as a right candidate for deploying the neural network on a mobile robot. The evaluation metrics used for the comparison of laser SLAM are Root Mean Square Error (RMSE). The Google Cartographer SLAM shows the lowest RMSE and acceptable processing time. The experimental results demonstrate that the perception module can meet the requirements of head protection criteria in Occupational Safety and Health Administration (OSHA) standards for construction. To be more precise, this module can effectively detect construction worker's non-hardhat-use in different construction site conditions and can facilitate improved safety inspection and supervision.",https://ieeexplore.ieee.org/document/9205772/,2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),19-21 Aug. 2020,ieeexplore
10.1109/ICNN.1988.23981,Intelligent control of the Intelledex 605T robot manipulator,IEEE,Conferences,"The authors present the results of the experiments which indicate how controlled robotic motion might be achieved through pattern-based paradigms, implemented for real-time operation on the Intelledex 605T robot manipulator with artificial neural nets (ANN). Previous attempts at pattern-based control have often failed, primarily because of the need for storage of an enormous number of training-set patterns and the long times required for pattern processing. It is demonstrated that these problems can be overcome through use of artificial neural networks implemented by parallel distributed processing. The feedforward Rumelhart net is investigated for the constrained robot manipulator. The robot arm, with two degrees of freedom, must move its end effector toward an observed target in the presence of disturbances. Such a control action need not be programmed in detail. Presented with a small number of training situations, the ANN can generalize and perform in many different situations. Preliminary results obtained using an Intelledex 605T and an IBM PC/AT are described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/23981/,IEEE 1988 International Conference on Neural Networks,24-27 July 1988,ieeexplore
10.1109/IROS.2005.1545188,Interactive evolution of human-robot communication in real world,IEEE,Conferences,"This paper describes how to implement interactive evolutionary computation (IEC) into a human-robot communication system. IEC is an evolutionary computation (EC) in which the fitness function is performed by human assessors. We used IEC to configure the human-robot communication system. We have already simulated IEC's application. In this paper, we implemented IEC into a real robot. Since this experiment leads considerable burdens on both the robot and experimental subjects, we propose the human-machine hybrid evaluation (HMHE) to increase the diversity within the genetic pool without increasing the number of interactions. We used a communication robot, WAMOEBA-3 (Waseda artificial mind on emotion base), which is appropriate for this experiment. In the experiment, human assessors interacted with WAMOEBA-3 in various ways. The fitness values increased gradually, and assessors felt the robot learnt the motions they desired. Therefore, it was confirmed that the IEC is most suitable as the communication learning system.",https://ieeexplore.ieee.org/document/1545188/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/HUMANOIDS.2012.6651596,Interactive symbol generation of task planning for daily assistive robot,IEEE,Conferences,"For the development of both hardware and software, task plannings become more and more important for robots to perform various tasks. Applying task planning to robotic system for working in real environments has difficulties. Estimating required symbols before planning is difficult because real environments are partially observable. In this paper, we proposed a method for task planning in partially observable environments with unknown objects. To construct conditional plans used in these environments, we extend the description of actions to multi-effect actions, and to deal with unknown objects, robots get new symbols generated by human interaction on demand. Additionally we show experiments of Willow Garage's PR2 executing the task in the real environment with unknown objects.",https://ieeexplore.ieee.org/document/6651596/,2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012),29 Nov.-1 Dec. 2012,ieeexplore
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/AIMSEC.2011.6009874,Kinematics simulation of upper limb rehabilitant robot based on virtual reality techniques,IEEE,Conferences,"The wearable exoskeletal robot for upper extremity rehabilitation is taken as the research object. According to D-H method, an accurate three-dimensional mechanism model for the robot system is established by SolidWorks software. The virtual set was generated in Simulink/VRML to carry out dynamic simulation. The variable parameters were set based on robotic practical joint range movement. The simulation of all joints and terminal trajectory and space motion area provided theoretical basis for position control, remote control and trajectory planning, realizing the rehabilitation robot visualizations and system interaction.",https://ieeexplore.ieee.org/document/6009874/,"2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)",8-10 Aug. 2011,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/ROBIO.2007.4522258,Layered omnidirectional walking controller for the humanoid soccer robot,IEEE,Conferences,"This paper proposes the layered omnidirectional walking controller for the humanoid soccer robot. The gait of the robot can be parameterized using the destination posititon and the desired direction while reaching the destination. Its implementation in our RoboCup simulation team - SEU-3D is detailed in this paper. Our approach generates smooth robot trajectories without stop before changing direction or turning, and is fast enough to meet the real-time requirements. The proposed approach has been tested in the RoboCup soccer 3D server platform. The results showed that omnidirectional walking has advantages in dynamic environments.",https://ieeexplore.ieee.org/document/4522258/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICTC49870.2020.9289214,Learning Control Policy with Previous Experiences from Robot Simulator,IEEE,Conferences,"Advances in deep reinforcement learning enabled cost-efficient training of control policy of physical robot actions from robot simulators. Learning control policy in a simulated environment is cost-efficient over learning in a real environment. Reward engineering is one of the key components to train efficient control policy. For tasks with long horizons such as navigation and manipulation, a sparse reward is providing limited information. The robot simulator for a physical engine of physical robot manipulation has made it easy for researchers in the field of deep reinforcement learning to simulate complicated robot manipulation environments. In this paper, A robot manipulation simulator and a deep RL framework are utilized for implement a training control policy by utilizing previous experiences. For implementation, Recent innovation Hindsight Experience Replay (HER) algorithms with previous experiences to calculate dense rewards from a sparse reward is leveraged . Proposed implementation showed an approach to investigate the reward engineering method to formulate dense reward in robot manipulator tasks.",https://ieeexplore.ieee.org/document/9289214/,2020 International Conference on Information and Communication Technology Convergence (ICTC),21-23 Oct. 2020,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2017.8324818,Learning complex assembly skills from kinect based human robot interaction,IEEE,Conferences,"Acquiring complex assembly skills is still a challenging task for robot programming. Because of the sensory and body structure differences, the human knowledge has to be demonstrated, recorded, converted and finally learned by the robot, in an inexplicit and indirect way. During this process, “how to demonstrate”, “how to convert” and “how to learn” are the key problems. In this paper, Kinect sensor is utilized to provide the behavior information of the human demonstrator. Through natural human robot interaction, body skeleton and joint 3D coordinates are provided in real-time, which can fully describe the human intension and task related skills. To overcome the structural and individual differences, a Cartesian level unified mapping method is proposed to convert the human motion and match the specified robot. The recorded data set are modeled using Gaussian mixture model(GMM) and Gaussian mixture regression(GMR), which can extract redundancies across multiple demonstrations and build robust models to regenerate the dynamics of the recorded movements. The proposed methodologies are implemented in the imNEU humanoid robot platform. Experimental results verify the effectiveness.",https://ieeexplore.ieee.org/document/8324818/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICNN.1994.374669,Learning dynamic balance of a biped walking robot,IEEE,Conferences,"This paper discusses the application of CMAC (cerebellar model arithmetic computer) neural networks to the problem of biped walking with dynamic balance. The project goal is to develop biped control strategies based on a hierarchy of simple gait oscillators, PID controllers and neural network learning, but requiring no detailed dynamic models. The focus of this report is on real-time control studies using a ten axis biped robot with joint position, foot force and body acceleration sensors. While efficient walking has not yet been achieved, the experimental biped has learned the closed chain kinematics necessary to shift body weight from side-to-side while maintaining good foot contact and has learned the dynamic balance required in order to lift a foot off the floor for a desired length of time, during which the foot can be moved to a new location relative to the body. Using these skills, the biped is able to link short steps without falling.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/374669/,Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94),28 June-2 July 1994,ieeexplore
10.1109/IJCNN.1993.716991,Learning goal-directed navigation as attractor dynamics for a sensory motor system. (An experiment by the mobile robot YAMABICO),IEEE,Conferences,"This paper describes experimental results based on the authors' prior-proposed scheme: learning of sensory-based, goal-directed behavior. The scheme was implemented on the mobile robot ""YAMABICO"" and learning of a set of goal-directed navigations were conducted. The experiment assumed that the robot receives no global information such as position nor prior environment model. Instead, the robot was trained to learn adequate maneuvering in the adopted workspace by building a correct mapping between a spatio-temporal sequence of sensory inputs and maneuvering outputs on a neural structure. The experimental results showed that sufficient training generated rigid dynamical structure of a fixed point and limit cycling in the sensory-based state space, which realized robust navigations of homing and cyclic routing even against certain changes of environment as well as miscellaneous noises in the real world.",https://ieeexplore.ieee.org/document/716991/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ROBIO.2009.5420526,Learning-based action planning for real-time robot telecontrol with binocular vision in enhanced reality environment,IEEE,Conferences,"Action planning is one of the pivot issues in robot telecontrol, in which the action instructions are often given by the controller from remote site with the help of vision systems. In this paper, we present a learning-based strategy for action planning in robot telecontrol, in which the parameters of sophisticated actions of the remote robot equipped with a binocular vision system could be pre-scheduled with a virtual robot at the control terminal. The remote robot will then be 'taught' with the scheduled action plan with a series of parameter sets obtained form try-outs with the virtual robot and object in the enhanced environment, thus implementing dedicated actions assigned correctly. The action planning process is implemented within a enhanced reality environment, in which both the virtual and the real robot will be displayed simultaneously for the purpose of being deeply immersed. Experiment results demonstrate that the proposed method is capable of promoting the action precision of the remote robot, and effective and valid to designated applications, where action precision plays a critical role.",https://ieeexplore.ieee.org/document/5420526/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.23919/ChiCC.2018.8483251,Local Gaussian Processes for Identifying Complex Mobile robot System,IEEE,Conferences,"Nonparametric Gaussian processes regression (GPR) is an important tool in machine learning, can be applied in identifying nonlinear models from experimental data, especially, the prediction of mean and variance present the useful advantage. However, when dealing with the large number of training data for the prediction of a complex dynamics system, GPR is not suitable to implement in real-time learning systems. To reduce the computation effort, local learning algorithm is introduced to improve the global Gaussian processes (GP) model in this paper. In this paper, a convenient and effective method for building local model network is proposed and then local GP for weighted regression is performed. The proposed local GPR method is implemented on a simulated example of online identification and prediction fast for a complex dynamic system of wheeled mobile robot.",https://ieeexplore.ieee.org/document/8483251/,2018 37th Chinese Control Conference (CCC),25-27 July 2018,ieeexplore
10.1109/ICCSE.2014.6926425,MKL-SVM-based human detection for autonomous navigation of a robot,IEEE,Conferences,"This paper presents a classifier trained by a multiple kernel-learning support vector machine (MKL-SVM) to detect a human in sequential images from a video stream. The developed method consists of two aspects: multiple features consisting of HOG features and HOF features suitable for moving objects, and combined nonlinear kernels for SVM. For the purpose of real time application in autonomous navigation, the SimpleMKL algorithm is implemented into the proposed MKL-SVM classifier. It is able to converge rapidly with comparable efficiency through a weighted 2-norm regularization formulation with an additional constraint on the weights. The classifier is compared with the state-of-the-art linear SVM using a dataset called TUD-Brussels, which is available on line. The results show that the proposed classifier outperforms the Linear SVM with respect to accuracy.",https://ieeexplore.ieee.org/document/6926425/,2014 9th International Conference on Computer Science & Education,22-24 Aug. 2014,ieeexplore
10.1109/WACV.2009.5403083,ML-fusion based multi-model human detection and tracking for robust human-robot interfaces,IEEE,Conferences,"A novel stereo vision system for real-time human detection and tracking on a mobile service robot is presented in this paper. The system integrates the individually enhanced stereo-based human detection, HOG-based human detection, color-based tracking, and motion estimation for the robust detection and tracking of humans with large appearance and scale variations in real-world environments. A new framework of maximum likelihood based multi-model fusion is proposed to fuse these four human detection and tracking models according to the detection-track associations in 3D space, which is robust to the possible missed detections, false detections, and duplicated responses from the individual models. Multi-person tracking is implemented in a sequential near-to-far way, which well alleviates the difficulties caused by human-over-human occlusions. Extensive experimental results demonstrate the robustness of the proposed system under real-world scenarios with large variations in lighting conditions, cluttered backgrounds, human clothes and postures, and complex occlusion situations. Significant improvements in human detection and tracking have been achieved. The system has been deployed on six robot butlers to serve drinks, and showed encouraging performance in open ceremony events.",https://ieeexplore.ieee.org/document/5403083/,2009 Workshop on Applications of Computer Vision (WACV),7-8 Dec. 2009,ieeexplore
10.1109/MFI-2003.2003.1232635,Map generation based on the interaction between robot body and its surrounding environment,IEEE,Conferences,"This paper presents a method for map generation based on the interaction between a robot body and its surrounding environment. While a robot moves in the environment, the robot interacts with its surrounding environment. If the effect of the environment on the robot changes, such interactions also change. By observing the robot's body, our method detects such change of the interaction and generates a description representing the type of change and the location where such change is observed. In the current implementation, we assume that there are two types of the change in the interaction. The real robot experiments are conducted in order to show the validity of our method.",https://ieeexplore.ieee.org/document/1232635/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/ICCCI50826.2021.9402304,Maze Solving with humanoid robot NAO using Real-Time object detection,IEEE,Conferences,"In a future that is not too distant from today, humanoids are surely going to be an integral part of both our professional and private lives, assisting us with various tasks. Unlike normal robots that we may encounter in our everyday lives, humanoids are designed in specific manners to give them more human-like capabilities that enable them to perform complex tasks such as climbing a flight of stairs. In this paper, we present a Maze-Solving Algorithm which is a software developed specifically for the humanoid robot, NAO, and gives it the capability to enter and exit a maze autonomously. NAO is a next-gen humanoid bot developed by SoftBank Robotics using the power of AI. The bot is equipped with numerous sensors and cameras. Though various quantitative approaches were considered and experimented with, we stuck onto the one which had the least average time complexity of all after a thorough comparative study. We suggest an approach where the humanoid can detect and localize objects from a distance and take programmable decisions based on them. AI constantly tries to give robots human-thinking capabilities to make their decision-making skills similar to those of humans, if not better than them. This algorithm was developed taking into consideration how a human intellect would react rationally if he is stuck in a maze. The methodology used revolves primarily around the combined use of SONAR(Sound navigation ranging) and tactical sensors, and cameras equipped within the bot. The output values from this hardware were then evaluated to judge the distance from a wall and the reactions from the bot were calculated by the suggested algorithm accordingly.",https://ieeexplore.ieee.org/document/9402304/,2021 International Conference on Computer Communication and Informatics (ICCCI),27-29 Jan. 2021,ieeexplore
10.1109/SSCI.2016.7850169,Memetic robot control evolution and adaption to reality,IEEE,Conferences,"Inspired by animals' ability to learn and adapt to changes in their environment during life, hybrid evolutionary algorithms have been developed and successfully applied in a number of research areas. This paper explores the effects of learning combined with a genetic algorithm to evolve control system parameters for a four-legged robot. Here, learning corresponds to the application of a local search algorithm on individuals during evolution. Two types of learning were implemented and tested, i.e. Baldwinian and Lamarckian learning. On the direct results from evolution in simulation, Lamarckian learning showed promising results, with a significant increase in final fitness compared with the results from evolution without learning. Further experiments with learning on the real robot demonstrated an efficient adaptation of the robot gait to the real world environment, and increased the performance to the level measured in simulation. This paper demonstrates that Lamarckian evolution is effective in improving the performance of robot controller evolution, and that the same learning process on the physical robot efficiently reduces the negative impact of the simulation-reality gap.",https://ieeexplore.ieee.org/document/7850169/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/AIMS.2014.35,Mobile Robot Performance in Robotics Challenges: Analyzing a Simulated Indoor Scenario and Its Translation to Real-World,IEEE,Conferences,"This paper discusses the pros and cons of using 3D simulators for testing the autonomous behavior of mobile robots in indoor environments. Major contribution of the paper is the discussion about which problems that can be faced using the simulator and those that cannot. We present the integration and calibration of a real non-commercial robot in a simulator, the characterization of the errors in sensing, navigation, and manipulation, and how these errors would impact in the real performance of the robot. The experimental support of the claims made in the paper has been developed using the gazebo simulator. RoCKIn competition rulebook defined the indoor restrictions.",https://ieeexplore.ieee.org/document/7102451/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/SISY.2009.5291131,Mobile robot control using self-learning neural network,IEEE,Conferences,"The paper describes the concept of the navigation system for a mobile robot. The system is using a navigation algorithm based on self-learning neural network, necessary to form a movement plan for a robot. The algorithm is adapted and implemented to navigate real platform of a mobile robot equipped by two independent wheel drives, encoders and a set of short-range sonars. Navigation algorithm is placed into a PC, which is connected to mobile robot by wireless and wired links. Experiments have shown ability of collision-free navigation of mobile robot in real time.",https://ieeexplore.ieee.org/document/5291131/,2009 7th International Symposium on Intelligent Systems and Informatics,25-26 Sept. 2009,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ISIC.1998.713694,Mobile robot localization using the Hough transform and neural networks,IEEE,Conferences,"For an autonomous mobile robot to navigate in an unknown environment it is essential to know the location of the robot on a real-time basis. Finding position and orientation of a mobile robot in a world coordinate system is a problem in localization. Dead-reckoning is commonly used for localization, but position and orientation errors from dead-reckoning tend to accumulate over time. The objective of the paper is to develop a feature-based localization method that uses the Hough transform to detect wall-like features in the environment based on sonar range data. Although the Hough transform is an effective method for detecting lines and curves from noisy data it has the drawback of being sensitive to discretization resolution. Results of line detection using various discretization resolutions and using a winner-take-all neural network are presented and discussed. The results indicate that the Hough transform method is able to reliably recognize wall-like features from noisy sonar data, but the accuracy of detected features is dependent heavily on the choice of resolution of parameter discretization.",https://ieeexplore.ieee.org/document/713694/,Proceedings of the 1998 IEEE International Symposium on Intelligent Control (ISIC) held jointly with IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA) Intell,17-17 Sept. 1998,ieeexplore
10.1109/AMC.2006.1631674,Mobile robot navigation in an unknown environment,IEEE,Conferences,"This paper discusses application of an intelligent system in order to navigate in real-time a small size, four wheeled, indoor mobile robot accurately using ultra-light (160 gr), inexpensive laser range finder without prior information of the environment. A recurrent neural network is used to find the best path to the target of the robot. An accurate grid-based map is generated using a laser range finder scene and location found by a modified dead reckoning system. Finally a motion control method is presented. These approaches are implemented and tested in Resquake mobile robot",https://ieeexplore.ieee.org/document/1631674/,"9th IEEE International Workshop on Advanced Motion Control, 2006.",27-29 March 2006,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ROMAN.2005.1513775,Modularity and integration in the design of a socially interactive robot,IEEE,Conferences,"Designing robots that are capable of interacting with humans in real life settings is a challenging task. One key issue is the integration of multiple modalities (e.g., mobility, physical structure, navigation, vision, audition, dialogue, reasoning) into a coherent framework. Taking the AAAI mobile robot challenge (making a robot attend the national conference on artificial intelligence) as the experimental context, we are currently addressing hardware, software and computation integration issues involved in designing a robot capable of sophisticated interaction with humans. This paper reports on our design solutions and the current status of the work, along with the potential impacts this design on human-robot interaction research.",https://ieeexplore.ieee.org/document/1513775/,"ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",13-15 Aug. 2005,ieeexplore
10.1109/ROMAN.2009.5326151,"Motion capture and classification for real-time interaction with a bipedal robot using on-body, fully wireless, motion capture specknets",IEEE,Conferences,"This paper presents, to the best of our knowledge, the first instance of real-time human-robot interaction using motion capture (mocap) data obtained from fully wireless, on-body sensor networks. During the learning phase, data for motion such as waving of the hands, standing on a leg, performing sit-ups and squats is captured from a human strapped with the orient motion capture specks. Key features are extracted from the captured motion data using unsupervised learning algorithms. During subsequent interactions with the robot, the motion of the operator, speckled with orients, is classified and the robot selects to play the closest motion. This approach is particularly useful in situations where the robot operates a well defined vocabulary of motion, and the advantages are the real-time interaction and the rapidity (in a matter of minutes) in programming new behaviour compared to a heuristics-based approach. This paper compares the performances of three unsupervised learning algorithms: c-means, k-means and expectation maximisation (EM) for the four motion scenarios. Nine best candidates for the three learning algorithms for each of the four motion scenarios were selected in the Webots robot simulator and then transferred to the real robot. Metrics were defined for each motion scenario and their performances compared for the three learning algorithms. In all the cases the motions were able to be imitated; c-means was the best, followed closely by the k-means algorithms, and the reasons have been analysed.",https://ieeexplore.ieee.org/document/5326151/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/ROBOT.1990.125999,Motion planning for a whole-sensitive robot arm manipulator,IEEE,Conferences,"A sensor-based motion planning system for a robot arm manipulator must include these four basic components: sensor hardware; real-time signal/sensory data processing hardware/software a local step planning subsystem that works at the basic sample rate of the arm; and a subsystem for global planning. The objective of this work is to develop the fourth component, a real-time implementable algorithm that realizes the upper, global level of planning. Based on the current collection of local normals, the algorithm generates preferable directions of motion around obstacles, in order to guarantee reaching the target position if it is reachable. Experimental results from testing the developed system are also discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/125999/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/ICAR.2013.6766513,Move and the robot will learn: Vision-based autonomous learning of object models,IEEE,Conferences,"As robots are increasingly deployed in complex real-world domains, visual object recognition continues to be an open problem. Existing algorithms for learning and recognizing objects are predominantly computationally expensive, and require considerable training or domain knowledge. Our algorithm enables robots to use motion cues to identify and focus on a set of interesting objects, automatically extracting appearance-based and contextual cues from a small number of images to efficiently learn representative models of these objects. Learned models exploit complementary strengths of: (a) relative spatial arrangement of gradient features; (b) graph-based models of neighborhoods of gradient features; (c) parts-based models of image segments; (d) color distributions; and (e) mixture models of local context. The learned models are used in conjunction with an energy minimization algorithm and a generative model of information fusion for reliable and efficient recognition in novel scenes. The algorithm is evaluated on mobile robots in indoor and outdoor domains, and on images from benchmark datasets.",https://ieeexplore.ieee.org/document/6766513/,2013 16th International Conference on Advanced Robotics (ICAR),25-29 Nov. 2013,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/FUZZ.2002.1005041,Multi-axis fuzzy control and performance analysis for an industrial robot,IEEE,Conferences,"Robot control systems can be considered as complex systems, the design of the controller involving the determination of the dynamic model for the system. Fuzzy logic provides functional capability without the use of a system model or the characteristics associated with capturing the approximate, varying values found in real world systems. Development of a multi-axis fuzzy logic control system was implemented on an industrial robot, replacing the existing control and hardware systems with a new developmental system. During robot control no adaptation of the rule base or membership functions was carried out online; only system gain was modified in relation to link speed and joint error within predetermined design parameters. The fuzzy control system had to manage the effects of frictional and gravitational forces whilst compensating for the varying inertia components when each linkage is moving. Testing based on ISO 9283 for path accuracy and repeatability verified that real time control of three axes was achievable with values of 938 /spl mu/m and 864 /spl mu/m recorded for accuracy and repeatability, respectively.",https://ieeexplore.ieee.org/document/1005041/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/IROS.2001.977153,Multi-robot path planning for dynamic environments: a case study,IEEE,Conferences,"Most multi-robot navigation planning methods make assumptions about the kind of navigation problems they are to solve and the capabilities of the robots they are to control. In this paper, we propose to select problem-adequate navigation planning methods based on empirical investigations, that is, the robots should learn by experimentation to use the best planning methods. To support this development strategy we provide software tools that enable the robots to automatically learn predictive models for the performance of different navigation planning methods in a given application domain. We show, in the context of robot soccer, that the hybrid planning method which selects planning methods based on a learned predictive model outperforms the individual planning methods. The results are validated in extensive experiments using a realistic and accurate robot simulator that has learned the dynamic model of the real robots.",https://ieeexplore.ieee.org/document/977153/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/FUZZY.1997.616431,Multilayered fuzzy behavior fusion for reactive control of an autonomous mobile robot,IEEE,Conferences,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, however, may benefit from qualitative rules as well if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine. A control function is broken down into multiple agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. Using this system, a fuzzy behavior-based reactive control system has been implemented on an autonomous mobile robot MARGE, with great success.",https://ieeexplore.ieee.org/document/616431/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/ISKE.2010.5680764,Multilevel fuzzy navigation control scheme applied to a monitoring mobile robot,IEEE,Conferences,"The design, construction and real time performance of a mobile monitoring system based on a Khepera mobile robot are presented. The functions performed by the system are: (a) line following, (b) obstacle avoidance, (c) identification of test points along the path, (d) recognition of the mark (bar code) located at each test point and, (e) measuring of a physical parameter. For the navigation, an innovative multilevel fuzzy control scheme is implemented in which the fuzzy sensor fusion, related to the perception of the environment, reduces the complexity of the navigation function. Other distinctive characteristics are the identification of test points by means of a Kohonen's neural network and the processing of a one-dimensional video signal for recognition of landmarks located at each test point.",https://ieeexplore.ieee.org/document/5680764/,2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering,15-16 Nov. 2010,ieeexplore
10.1109/ROMAN.1995.531939,Multimedia sensing system for robot,IEEE,Conferences,"The purpose of this study is to realize a multimedia sensing system for robot. Using both image and sound processing, the system makes a robot track the person who is speaking. The sound direction is calculated from the phase difference between the sounds arriving at the right and left microphones (ears) of the robot. Then by detecting the synchronization between the sound and image changes, the system identifies the speaker. Furthermore, by introducing a multi-level synchronization checking and context analysis, the action pattern of the robot can be regulated to make the robot perform in a complicated environment with plural speakers. All the processes are performed in real-time. The proposed system is implemented in the information assistant robot ""Hadaly"".",https://ieeexplore.ieee.org/document/531939/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/CEC.2007.4424774,Multiple sensors data integration using MFAM for mobile robot navigation,IEEE,Conferences,"The mobile robot navigation with complex environment needs more input space to match the environmental data into robot outputs in order to perform realistic task. At the same time, the number of rules at the rule base needs to be optimized to reduce the computing time and to provide the possibilities for real time operation. In this paper, the optimization of fuzzy rules using a modified fuzzy associative memory (MFAM) is designed and implemented. MFAM provides good flexibility to use multiple input space and reduction of rule base for robot navigation. This paper presents the MFAM model to generate the rule base for robot navigation. The behavior rules obtained from MFAM model are tested using simulation and real world experiments, and the results are discussed in the paper and compared with the existing methods.",https://ieeexplore.ieee.org/document/4424774/,2007 IEEE Congress on Evolutionary Computation,25-28 Sept. 2007,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICMLC.2016.7872960,Muscle-gesture robot hand control based on sEMG signals with wavelet transform features and neural network classifier,IEEE,Conferences,"In this paper, we propose a muscle gesture-computer interface (MGCI) system for a five-fingered robotic hand control employing a commercial wearable MYO gesture armband. Eight channels of surface EMG (sEMG) signals were acquired and segmented. Then four levels of Daubechies 5 Wavelet family were performed to analyze the EMG signal. Totally 72 features were extracted from the EMG raw data for 16 hand motions recognition utilizing artificial Neural Networks. The average of best overall classification rate during off-line training is 87.8%. Consequently, real-time hand gesture recognition was implemented to evaluate the performance of the proposed system and the average recognition accuracy was 89.38%. Finally, it was applied to control a five-fingered robot hand.",https://ieeexplore.ieee.org/document/7872960/,2016 International Conference on Machine Learning and Cybernetics (ICMLC),10-13 July 2016,ieeexplore
10.1109/IECON.2000.972604,NN controller of the constrained robot under unknown constraint,IEEE,Conferences,"In this paper, the problems faced in the constrained force control is studied (uncertainties in dynamic model and the unknown constraints). A neural network (NN) controller is proposed based on the derived dynamic model of robot in the task space. The feed-forward neural network is used to adaptively compensate for the uncertainties in the robot dynamics. Training signals are proposed for the feed-forward neural network controller. The NN weights are tuned online, with no off-line learning phase required. An online estimation algorithm is developed to estimate the local shape of the constraint surface by using measured data on the force and position of the end-effector. The suggested controller is simple in structure and can be implemented easily. Real-time experiments are conducted using the five-bar robot to demonstrate the effectiveness of the proposed controller.",https://ieeexplore.ieee.org/document/972604/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/ICMA52036.2021.9512587,Natural Residual Reinforcement Learning for Bicycle Robot Control,IEEE,Conferences,"This work focuses on motion control of the bicycle robot by using the proposed NRRL algorithm. Unlike the traditional RL algorithm, decomposing the main tasks into subtasks manually and introducing qualitative prior knowledge to the agent have been applied in the NRRL algorithm. Simulation results show that better performance and better sample efficiency of the proposed NRRL algorithm have been achieved in terms of balance control and path tracking of bicycle robot. It's believed that the NRRL algorithm is available on the real physical bicycle robot, and the deployment of the algorithm will be realized soon, as the real physical bicycle robot has been constructed currently.",https://ieeexplore.ieee.org/document/9512587/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/CIMCA.2008.133,Neural Dynamic Control of a Nonholonomic Mobile Robot Incorporating the Actuator Dynamics,IEEE,Conferences,"In this paper, a trajectory tracking control for a nonholonomic mobile robot by the integration of a kinematic controller and neural dynamic controller is investigated, where the wheel actuator (e.g., dc motor) dynamics is integrated with mobile robot dynamics and kinematics so that the actuator input voltages are the control inputs. The proposed neural dynamic controller (PNDC), based on the sliding mode theory, is applied to compensate the mobile robot dynamics, bounded unknown disturbances, and influence of payload. This controller is obtained by modeling the Radial Basis Functions Neural Networks (RBFNNs) of the centripetal and Coriolis matrix through of the inertia matrix of the mobile robot dynamics. Thus, PNDC is constituted of static RBFNNs only, what makes possible the reduction of the size of the RBFNNs, of the computational load and the implementation in real time. Stability analysis and numerical simulations are provided to show the effectiveness of the PNDC.",https://ieeexplore.ieee.org/document/5172687/,2008 International Conference on Computational Intelligence for Modelling Control & Automation,10-12 Dec. 2008,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/IROS.1991.174585,Neural network approach to path planning for two dimensional robot motion,IEEE,Conferences,"A method for robot obstacle avoidance and path planning is proposed. The algorithm is based on a camera image feedback loop utilizing a neural network for image processing. The method can successfully generate collision-free paths in a 2D robot workspace containing randomly-placed polygonal obstacles. The control algorithm is simple and robust and has low computational requirements. Controller simulation implemented on a personal computer can generate collision-free robot paths in real time, requiring approximately 1 sec. per robot move.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174585/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ROBOT.1995.525344,Neural network based iterative learning controller for robot manipulators,IEEE,Conferences,"An efficient neural network based learning control scheme is proposed to solve the trajectory tracking controI problem of robot manipulators. The proposed approach has four distinctive characteristics: 1) good tracking performance can be achieved during the first learning trial; 2) learning algorithm for adjusting neural network weights is independent of the manipulator dynamic model, thus displays strong robustness to torque disturbances and model parameter uncertainty; 3) no acceleration measurement or estimation is needed; and 4) real-time implementation with a higher sampling rate is readily possible. Simulation results on a 3 degree-of-freedom manipulator are presented to show its validity.",https://ieeexplore.ieee.org/document/525344/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/HUMANOIDS.2018.8625038,NimbRo-OP2X: Adult-Sized Open-Source 3D Printed Humanoid Robot,IEEE,Conferences,"Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreál, Canada, where it won all possible awards in the Humanoid AdultSize class.",https://ieeexplore.ieee.org/document/8625038/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/IROS.2003.1250614,Non-learning artificial neural network approach to motion planning for the Pioneer robot,IEEE,Conferences,This paper describes the implementation of a biologically-inspired non-learning artificial neural network for robot motion planning on the Pioneer 2DX robot. This motion planner fits within the Saphira operating system. The deliberative ANN motion planner is able to respond to changing situations in real time and complements the reactive behaviours.,https://ieeexplore.ieee.org/document/1250614/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/ICIEAM.2019.8742984,Objects Geometry Comparative Analysis Method for Industrial Robot Vision System,IEEE,Conferences,"At present, in computer vision systems, neural networks are used to process information received by the system from cameras. The recognition of all objects on the image is an extremely resource-intensive task, the solution of which consumes most of the computing power. For that reason, systems based on neural networks cannot be fully utilized for real-time systems due to limited computing resources. To build real-time computer vision systems, the authors suggested using the contour comparison method. The method allows to supervise the geometry of objects, conduct presorting and screen out defective parts, thereby the pressure on neural networks will reduce. The method is implemented in the Java. The created software performs image processing and objects search on it, that are the most similar to the template. The results of the experiment showed that the desired object is correctly determined on a noisy image and the proposed method can be used to solve the problem of pattern recognition in technical vision systems.",https://ieeexplore.ieee.org/document/8742984/,"2019 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)",25-29 March 2019,ieeexplore
10.1109/IECON.2006.347441,Obstacle avoidance algorithm based on biological patterns for anthropomorphic robot manipulator,IEEE,Conferences,"This study addresses the problem of collision-free controlling of 3-DOF (degree of freedom) anthropomorphic manipulators with given a priori unrestricted trajectory. The robot constraints resulting from the physical robot's actuators are also taken into account during the robot movement. Obstacle avoidance algorithm is based on penalty function, which is minimized when collision is predicted. Mathematical construction of penalty function and minimization process allows modeling of variety behaviors of robot elusion moves. Implementation of artificial neural network (ANN) inside the control process gives the additional flexibility needed to remember most important robot behaviors based on biological pattern of human arm moves. Thanks to the fast collisions' detection, the presented algorithm appears to be applicable to the industrial real-time implementations. Numerical simulations of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented",https://ieeexplore.ieee.org/document/4152937/,IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,6-10 Nov. 2006,ieeexplore
10.1109/ICRA48506.2021.9561790,Occupancy Map Inpainting for Online Robot Navigation,IEEE,Conferences,"In this work, we focus on mobile robot navigation in indoor environments where occlusions and field-of-view limitations hinder onboard sensing capabilities. We show that the footprint of a camera mounted on a robot can be drastically improved using learning-based approaches. Specifically, we consider the task of building an occupancy map for autonomous navigation of a robot equipped with a depth camera. In our approach, a local occupancy map is first computed using measurements from the camera directly. Afterwards, an inpainting network adds further information, the occupancy probabilities of unseen grid cells, to the map. A novel aspect of our approach is that rather than direct supervision from ground truth, we combine the information from a second camera with a better field-of-view for supervision. The training focuses on predicting extensions of the sensed data. To test the effectiveness of our approach, we use a robot setup with a single camera placed at 0.5m above the ground. We compare the navigation performance using raw maps from only this camera’s input (baseline) versus using inpainted maps augmented with our network. Our method outperforms the baseline approach even in completely new environments not included in the training set and can yield 21% shorter paths than the baseline approach. A real-time implementation of our method on a mobile robot is also tested in home and office environments.",https://ieeexplore.ieee.org/document/9561790/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2013.6630740,Off-line path integral reinforcement learning using stochastic robot dynamics approximated by sparse pseudo-input Gaussian processes: Application to humanoid robot motor learning in the real environment,IEEE,Conferences,"We develop fast reinforcement learning (RL) framework using the approximated dynamics of a humanoid robot. Although RL is a useful non-linear optimizer, applying it to real robotic systems is usually difficult due to the large number of iterations required to acquire suitable policies. In this study, we approximate the dynamics using data from a real robot with sparse pseudo-input Gaussian processes (SPGPs). By using SPGPs, we estimated the probability distribution considering both the input vector and output signal variances. In real environments, since the observations from robotic sensors include large noise, SPGPs can suitably approximate the stochastic dynamics of a real humanoid robot. We use the approximated dynamics to improve the performance of a movement task in a path integral RL framework, which updates a policy from the sampled trajectories of the state and action vectors and the cost. We implemented our proposed method on a real humanoid robot and tested on a via-point reaching task. The robot achieved successful performance with fewer number of interactions with the real environment by using the proposed method than a conventional approach which dose not use the simulated dynamics.",https://ieeexplore.ieee.org/document/6630740/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/ICAS.2006.40,On the conception of an autonomous and modular robot based on an Event Driven OSEK System with deterministic real-time behavior,IEEE,Conferences,"In this paper, we are interested in the design of an autonomous and modular self-reconfigurable robot having self-assembly capability and deterministic behavior. The ability of a modular robot to meet its mission strongly depends on the artificial intelligence software and on the underlying hardware and software architecture. The artificial intelligence software of a robot is mapped into several elementary tasks with different real-time constraints. We propose in this paper a real-time analysis taking into account kernel overheads for the validation of the real-time behavior of an artificial intelligence software. We study the OSEK operating system that requires few hardware resources and is cost effective. The overheads are due to the context switching mechanism which activates, terminates, and reschedules tasks, and to the periodic timer used to create the time base which is necessary for the periodic tasks model. We show how to take into account those overheads in the feasibility conditions. We compare the theoretical worst case response time obtained with kernel overheads to the response time obtained on a task set, on a real robot, based on the event driven OSEK implementation. We show that the kernel overheads cannot be neglected and that the theoretical results are valid and can be used to ensure a deterministic behavior of the robot",https://ieeexplore.ieee.org/document/1690225/,International Conference on Autonomic and Autonomous Systems (ICAS'06),19-21 July 2006,ieeexplore
10.1109/MWSCAS.1991.251981,On the fast robot dynamic parameters learning,IEEE,Conferences,"A computationally efficient solution to the problem of identifying the dynamic parameters of a robot manipulator is presented. The identification procedure is based on a simplified form of the dynamics. The approach has three important characteristics. First, being based on the Lagrangian representation, the equations are linear in the dynamic parameters, which makes possible the application of linear identification techniques. Second, the dynamic parameters are easily recognized, extracted, and grouped. Third, the equations are amenable to the implementation of parallel processing schemes. For the identification a recursive least squares algorithm is used. The algorithm is distributed over a network of transputers. Real-time results have been produced to demonstrate the speedup and efficiency of the proposed technique. A case study is given for the first three links of the Stanford Arm positioning system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/251981/,[1991] Proceedings of the 34th Midwest Symposium on Circuits and Systems,14-17 May 1992,ieeexplore
10.1109/ROMAN.2007.4415153,Online Affect Detection and Adaptation in Robot Assisted Rehabilitation for Children with Autism,IEEE,Conferences,"This paper presents a novel affect-sensitive human-robot interaction framework for rehabilitation of children with autism spectrum disorder (ASD) where the robot can detect the affective cues of the children implicitly and response to them appropriately. Psychophysiological analysis is performed that uses subjective reports of the affective states from a clinical observer. Comprehensive physiological indices are investigated that may correlate with the affective states of children with ASD. A robot uses a support vector machines based affect model to detect the affective cues. A reinforcement learning based adaptation mechanism is employed to allow the robot to adjust its behaviors autonomously as a function of the predicted children's affective state. Four adolescents diagnosed with high-functioning autism participated in the experiments. This is the first time, to our knowledge, that the affective states of children with ASD have been detected via physiology-based affective modeling technique in real-time. This is also the first time that impact of affect-sensitive interaction between a robot and children with ASD in closed loop has been demonstrated experimentally.",https://ieeexplore.ieee.org/document/4415153/,RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,26-29 Aug. 2007,ieeexplore
10.1109/ICMA.2019.8816298,Online Learning of the Inverse Dynamics with Parallel Drifting Gaussian Processes: Implementation of an Approach for Feedforward Control of a Parallel Kinematic Industrial Robot,IEEE,Conferences,"The present paper deals with an online approach to learn the inverse dynamics of any robot. This is realized by the use of Gaussian Processes drifting parallel along the system data. An extension by a database enables the efficient use of data points from the past. The central component of this work is the implementation of such a method in a controller in order to achieve the actual goal: the feedforward control of an industrial robot by means of machine learning. This is done by splitting the procedure into two threads running parallel so that the prediction is decoupled from the computing-intensive training of the models. Experiments show that the method reduces the tracking errors more clearly than an elaborately identified rigid body model including friction. For a defined trajectory, the squared areas of the tracking errors of all axes are reduced by more than 54% compared to motion without pre-control. In addition, a highly dynamic pick-and-place experiment is used to investigate the possible changes in system dynamics. Compared to an offline trained model, the approximation error of the proposed online approach is smaller for the remaining time of the experiment after an initial phase. Furthermore, this error is smaller throughout the experiment for online learning with parallel drifting Gaussian Processes than when using a single one.",https://ieeexplore.ieee.org/document/8816298/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA.2012.6224998,Online audio beat tracking for a dancing robot in the presence of ego-motion noise in a real environment,IEEE,Conferences,"This paper presents the design and implementation of a real-time real-world beat tracking system which runs on a dancing robot. The main problem of such a robot is that, while it is moving, ego noise is generated due to its motors, and this directly degrades the quality of the audio signal features used for beat tracking. Therefore, we propose to incorporate ego noise reduction as a pre-processing stage prior to our tempo induction and beat tracking system. The beat tracking algorithm is based on an online strategy of competing agents sequentially processing a continuous musical input, while considering parallel hypotheses regarding tempo and beats. This system is applied to a humanoid robot processing the audio from its embedded microphones on-the-fly, while performing simplistic dancing motions. A detailed and multi-criteria based evaluation of the system across different music genres and varying stationary/non-stationary noise conditions is presented. It shows improved performance and noise robustness, outperforming our conventional beat tracker (i.e., without ego noise suppression) by 15.2 points in tempo estimation and 15.0 points in beat-times prediction.",https://ieeexplore.ieee.org/document/6224998/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ICSMC.1998.726546,Online learning neural network controller for pneumatic robot position control,IEEE,Conferences,"This paper presents the implementation of online learning neural network controller in the pneumatic robot position servo control. The advantages of this design include: the ability to compensate for nonlinearities, and it is insensitive to system parameter time-varying. The traditional PID controller is replaced by neural network controller trained online to learn the inverse model of the pneumatic manipulator by backpropagation of the performance error. The simulation studies and experimental results on the PID controller, online learning neural network controller and off-line training neural network controller, are presented and discussed.",https://ieeexplore.ieee.org/document/726546/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICMA.2012.6285128,Online learning of COM trajectory for humanoid robot locomotion,IEEE,Conferences,"Center Of Mass (COM) trajectory is an essential factor for stable and natural robot locomotion. Unlike previous research in which COM trajectory either restricted by ZMP trajectory or directly predefined by simple function such as sinusoid, this research aims to establish the COM trajectory by online autonomous learning under the objective of locomotion stability and naturalness, which is expressed as a self-consistent measure in this paper. It provides an alternative that may avoid or weaken the mismatch between theoretical planning and practical implementation. The experimental results on a real humanoid robot PKU-HR4 show its effectiveness and promising future.",https://ieeexplore.ieee.org/document/6285128/,2012 IEEE International Conference on Mechatronics and Automation,5-8 Aug. 2012,ieeexplore
10.1109/INDIN.2006.275808,"Ontology for Cognitics, Closed-Loop Agility Constraint, and Case Study - a Mobile Robot with Industrial-Grade Components",IEEE,Conferences,"The paper refers to intelligent industrial automation. The objective is to present key elements and methods for best practice, as well as some results obtained. The first part presents an ontology for automated cognition (cognitics), where, based on information and time, the main cognitive concepts, including those of complexity, knowledge, expertise, learning, intelligence abstraction, and concretization are rigorously defined, along with corresponding metrics and specific units. Among important conclusions at this point are the fact that reality is much too complex to be approached better than through much simplified models, in very restricted contexts. Another conclusion is the necessity to be focused on goal. Extensions are made here for group behavior. The second part briefly presents a basic law governing the choice of overall control architecture: achievable performance level of control system in terms of agility, relative to process dynamics, dictates the type of approaches which is suitable, in a spectrum which ranges from simple threshold-based switching, to classical closed-loop calculus (PID, state space multivariable systems, etc.), up to ""impossible"" cases where additional controllers must be considered, leading to cascaded, hierarchical control structures. For complex cases such as latter ones, new tools and methodologies must be designed, as is typical in O<sup>3</sup>NEIDA initiative, at least for software components. Finally, a large part of the paper presents a case study, a mobile robot, i.e. an embedded autonomous system with distributed, networked control, featuring industry-grade components, designed with the main goal of robust functionality. The case illustrates several of the concepts introduced earlier in the paper.",https://ieeexplore.ieee.org/document/4053562/,2006 4th IEEE International Conference on Industrial Informatics,16-18 Aug. 2006,ieeexplore
10.1109/UR49135.2020.9144838,Outdoor Robot Navigation System using Game-Based DQN and Augmented Reality,IEEE,Conferences,"This paper presents a deep reinforcement learning based robot outdoor navigation method using visual information. The deep q network (DQN) maps the visual data to robot action in a goal location reaching task. An advantage of the proposed method is that the implemented DQN is trained in the first-person shooter (FPS) game-based simulated environment provided by ViZDoom. The FPS simulated environment reduces the differences between the training and the real environments resulting in a good performance of trained DQNs. In our implementation a marker-based augmented reality algorithm with a simple object detection method is used to train the DQN. The proposed outdoor navigation system is tested in the simulation and real robot implementation, with no additional training. Experimental results showed that the navigation system trained inside the game-based simulation can guide the real robot in outdoor goal directed navigation tasks.",https://ieeexplore.ieee.org/document/9144838/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ROBOT.1991.131722,Parallel robot motion planning,IEEE,Conferences,"A fast, parallel method for computing configuration space maps is presented. The method is made possible by recognizing that one can compute a family of primitive maps which can be combined by superposition based on the distribution of real obstacles. This motion planner has been implemented for the first three degrees-of-freedom of a Puma robot in *Lisp on a Connection Machine with 8 K processors. A six degree-of-freedom version of the algorithm which performs a sequential search of the six-dimensional configuration space, building three-dimensional cross sections in parallel, has also been implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131722/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.1109/URAI.2012.6463006,Path planning through maze routing for a mobile robot with nonholonomic constraints,IEEE,Conferences,"A comprehensive technique to plan path for a mobile robot with nonholonomic constraints through maze routing technique has been presented. Our robot uses a stereo vision based approach to detect the obstacles by creating dense 3D point clouds from the stereo images. ROS packages have been implemented on the robot for specific tasks of providing: i) Linear and angular velocity commands, ii) Calibration and rectification of the stereo images for generating point clouds, iii) Simulating the URDF (Unified Robot Description Format) module in real time, with respect to the real robot and iv) For visualizing the sensor data. For efficient path planning a hybrid technique using Lee's algorithm, modified by Hadlock and Soukup's algorithm has been implemented. Different path planning results have been shown using the maze routing algorithms. Preliminary results shows that Lee's algorithm is more time consuming in comparison with other algorithms. A hybrid of Lee's with Soukup's algorithm is more efficient but unpredictable for minimal path. A hybrid of Lee's with Hadlock's algorithm is the most efficient and least time consuming.",https://ieeexplore.ieee.org/document/6463006/,2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),26-28 Nov. 2012,ieeexplore
10.1109/ICCEAI52939.2021.00074,Pedestrian Recognition System for Smart Security Robot using Pedestrian Re-identification Algorithm,IEEE,Conferences,"The security system is an important guarantee for the safety of citizens' lives and property. In recent years, security robots have been more and more widely used in security systems. At present, domestic security robots generally lack of pedestrian recognition ability under complex circumstances. Therefore, this paper designs and implements pedestrian recognition system for smart security robots using improved pedestrian re-identification algorithm. Experiment result shows that the system has success rate of 90 % and response speed compliance rate of 94.4% under real circumstances, which is much better than traditional system.",https://ieeexplore.ieee.org/document/9544430/,2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI),27-29 Aug. 2021,ieeexplore
10.1109/ICSMC.1999.816641,"Perception, reasoning and learning of multiple agent systems for robot soccer",IEEE,Conferences,"Presents a supervisory control strategy for coordination of soccer playing mobile robots. Within the framework of a hierarchical control structure, three layered components of supervisor, coordinator, and executor emulate the basic three concepts of human intelligence, perception, reasoning, and learning. A small size discrete event system model is derived and implemented in the supervisor and coordinator for state-action reasoning and coordination of multiple robotic agents for a successful soccer game. Experimental results of real soccer games are given to demonstrate the feasibility and effectiveness of the developed supervisory control strategy in terms of structural simplicity and computational speed for real-time control.",https://ieeexplore.ieee.org/document/816641/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/ICSMC.1996.571370,Perception-action method for mobile robot plan and control based on driving experience,IEEE,Conferences,"A method of navigation and control for mobile robot is introduced. It combines task planning and path tracking together with the principle of ""perception-action"" under the guidance of ""goal planning"". First, we discuss the behavior of the mobile robot in an outdoor real world for the purpose of setting up a mixed layered architecture with ""perception-action"" and ""goal planning"". Then a simple but effective approach of sensor based navigation and control is described for the implementation of the architecture. Finally, we give some improvements based on the human-driving experience concerning path tracking and control for the mobile robot moving on outdoor semistructured roads. The experiments carried out on our THMR-III (Tsinghua Mobile Robot III) mobile robot navigating in the real world showed the method described was effective and robust.",https://ieeexplore.ieee.org/document/571370/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA.2011.5979792,Physical human robot interaction in imitation learning,IEEE,Conferences,"This video presents our recent research on the integration of physical human-robot interaction (pHRI) into imitation learning. First, a marker control approach for real time human motion imitation is shown. Secondly, physical coaching in addition to observational learning is applied for the incremental learning of motion primitives. Last, we extend imitation learning to learning pHRI which includes the establishment of intended physical contacts. The proposed methods were implemented and tested using the IRT humanoid robot and DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5979792/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/ICRA.2014.6907470,Posture control of a three-segmented tracked robot with torque minimization during step climbing,IEEE,Conferences,"In this paper, we present a posture control scheme for step climbing by an in-house developed three-segmented tracked robot, miniUGV. The posture control scheme results in minimum torque at the actuated joints of the segments. Non-linear optimization is carried out offline for progressively decreasing distance of the robot from the step with torque minimization as objective function and force balance, motor torque limits, slippage avoidance and interference avoidance constraints. The resulting angles of the joints are fitted to a third degree polynomial as a function of the robot distance from the step and the step height. It is shown that a single set of polynomial functions is sufficient for climbing steps of all permissible heights and angles of attack of the front segment. The methodology has been verified through simulation followed by implementation on the real robot. As a consequence of this optimization we find that the average current reduced by more than thirty percent, reducing power consumption and confirming the efficacy of the optimization framework.",https://ieeexplore.ieee.org/document/6907470/,2014 IEEE International Conference on Robotics and Automation (ICRA),31 May-7 June 2014,ieeexplore
10.1109/IJCNN.2014.6889830,Predictive Hebbian association of time-delayed inputs with actions in a developmental robot platform,IEEE,Conferences,"The work described here explores a neural network architecture that can be embedded directly in the realtime sensorimotor coordination loop of a developmental robot platform. We take inspiration from the way children are able to learn while interacting with a teacher, in particular the use of prediction of the teacher actions to improve own learning. The architecture is based on two neural networks that operate online, and in parallel, one for learning and one for prediction. A Hebbian learning rule is used to associate the high-dimensional afferent sensor input at different time-delays with the current efferent motor commands corresponding to the teacher demonstration. The predictions of future motor commands are used to limit the growth of the neural network weights, and to enable the robot to smoothly continue movements the teacher has begun. Results on a simulated iCub robot learning object interaction tasks are presented, including an analysis of the sensitivity to changes in the task setup. We also outline the first implementation on the real iCub platform.",https://ieeexplore.ieee.org/document/6889830/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/IMTC.1999.776982,Problems and solutions in acquisition and interpretation of sensorial data on a mobile robot,IEEE,Conferences,"We discuss some guidelines to cope with problems that arise when using cheap and simple sensors on mobile, autonomous, robotic agents. In particular we focus on the perceptual aliasing problem and on the possibility to perform active sensor data acquisition. We present a robotic architecture that we have implemented on a real robot following the proposed guidelines. The obtained mobile robot satisfies the design specifications, navigating autonomously in an unstructured environment.",https://ieeexplore.ieee.org/document/776982/,IMTC/99. Proceedings of the 16th IEEE Instrumentation and Measurement Technology Conference (Cat. No.99CH36309),24-26 May 1999,ieeexplore
10.1109/ICEC.1996.542714,Propagating learned behaviors from a virtual agent to a physical robot in reinforcement learning,IEEE,Conferences,"For a physical robot to acquire behaviors, it is important for it to learn in the physical environment. Since reinforcement learning requires large computation costs as well as a lot of time in the physical environment, most research has performed learning by simulation. However, this does not work well in the real world. Realizing reinforcement learning of a physical robot in a physical environment requires both an adaptation for the diversity of possible situations and a high-speed learning method that can learn from fewer trials. This paper describes cooperative reinforcement learning based on propagating the learned behaviors of a virtual agent to a physical robot in order to accelerate learning in a physical environment. The method consists of two parts: (1) preparation learning in a virtual environment to accelerate initial learning, which accounts for most of the learning cost; and, (2) refinement learning in a physical environment by using the virtual learning results as an initial behavior set of a physical robot. Experimental results are given for a ball-pushing task with the physical robot and a virtual agent.",https://ieeexplore.ieee.org/document/542714/,Proceedings of IEEE International Conference on Evolutionary Computation,20-22 May 1996,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ICRoM.2015.7367861,ReMoRo; A mobile robot platform based on distributed I/O modules for research and education,IEEE,Conferences,"We present our recent work on the electrical and hardware design of the mobile robot platform ReMoRo that is based on distributed input/output modules. We have designed three generation of this platform with different specifications, which it help us to design more compatible and applied mobile robot. Nevertheless, the goal of this project was to develop a low-cost and robust but extensible modular robot platform for research and educational purposes. In this paper we describe a new affordable robot structure that enables large-scale innovative, new curriculum, multi robot research and multi-robotics outreach to computer and artificial intelligent students. We introduce the ReMoRo platform, which offers a balance between capabilities, accessibility, cost and an opendesign. All of electrical devices like sensors module, motor drivers and device communication manager are designed based on ARM Cortex M3 microcontrollers that runs under Real-Time Operating System (freeRTOS) for manages each modules internal scheduling and activation control in communication bus. With a range of different sensors, cylindrical manipulator and omnidirectional locomotion system, RoMeRo can interact with environment in multiple ways, handle common objects and therefore be used in various service robot scenarios like warehouse robots or multi agent mobile robots. We demonstrate the usability of our concept by quantifying the object-handling task and also briefly describe the software design based on ROS framework for educational usage.",https://ieeexplore.ieee.org/document/7367861/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/ISIE.2005.1529114,Real time implementation of a selective attention model for the intelligent robot with autonomous mental development,IEEE,Conferences,"We propose a biologically motivated selective attention model to find an object based on context free search for an intelligent robot with an autonomous mental development (AMD) mechanism. For real-time operation of the selective attention model in the robot system, we have considered a way to reduce the computational load of the selective attention model, which uses a simplified symmetry operation with retina-topic sampling and look-up table in the localized candidate attention region. As a result, our model can perform within 270 ms at Pentium-4 2.8Ghz, and obtain a plausible human-like visual scan path in order to pay attention to an object preferentially. Then, we implemented an intelligent mobile robot with selective attention for an AMD mechanism.",https://ieeexplore.ieee.org/document/1529114/,"Proceedings of the IEEE International Symposium on Industrial Electronics, 2005. ISIE 2005.",20-23 June 2005,ieeexplore
10.1109/WCICA.2000.863455,Real time tracking in robot teleoperation system,IEEE,Conferences,"The robot teleoperation system based on stereo vision was developed by the State Key Lab of Intelligent Technology and System of Tsinghua University. The paper presents the design frame of the whole system, and describes in detail some of the key design and implementation problems. Finally, the paper analyses the difficulty of applying this technology to virtual reality and augmented reality systems, and some suggestions are provided. The success of this system can contribute to further research on augmented reality.",https://ieeexplore.ieee.org/document/863455/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ICMLC.2006.259112,Real-Time Implementation of a PD+DFNNS Controller for Compliance Robot,IEEE,Conferences,"This paper presents the compliance control of a robot manipulator under a constrained environment. The controller design proposed herein is based on the intelligence adaptive control scheme. In this design, the DFNNs (dynamic fuzzy neural networks) and PD feedback controllers control the position and the contact force of robot end-effector. The DFNNs controller is employed to compensate for environmental variations such as payload mass and disturbance torque during the operation process; PD feedback controllers control the position and the contact force of end-effector. Applying these controllers allows us to adapt the manipulator to the unknown surface of the surrounding environment and to have close contact with the curved surface",https://ieeexplore.ieee.org/document/4028106/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/DEVLRN.2005.1490961,Real-Time Multi-View Face Tracking for Human-Robot Interaction,IEEE,Conferences,"For face tracking in a video sequence, various face tracking algorithms have been proposed. However, most of them have difficulty in finding the initial position and size of a face automatically. In this paper, we present a fast and robust method for fully automatic multi-view face detection and tracking. Using a small number of critical rectangle features selected and trained by the Adaboost learning algorithm, we can detect the initial position, size and view of a face correctly. Once a face is reliably detected, we can extract face and upper body color distribution from the detected facial regions and upper body regions for building robust color modeling respectively. Simultaneously, each color modeling is performed by using k-means clustering and multiple Gaussian models. Then, fast and efficient multi-view face tracking is executed by using several critical features. Our proposed algorithm is robust to rotation, partial occlusions, and scale changes in front of dynamic, unstructured background. In addition, our proposed method is computationally efficient. Therefore, it can be executed in real-time",https://ieeexplore.ieee.org/document/1490961/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/IROS45743.2020.9341473,Real-World Human-Robot Collaborative Reinforcement Learning,IEEE,Conferences,"The intuitive collaboration of humans and intelligent robots (embodied AI) in the real-world is an essential objective for many desirable applications of robotics. Whilst there is much research regarding explicit communication, we focus on how humans and robots interact implicitly, on motor adaptation level. We present a real-world setup of a human-robot collaborative maze game, designed to be non-trivial and only solvable through collaboration, by limiting the actions to rotations of two orthogonal axes, and assigning each axes to one player. This results in neither the human nor the agent being able to solve the game on their own. We use deep reinforcement learning for the control of the robotic agent, and achieve results within 30 minutes of real-world play, without any type of pre-training. We then use this setup to perform systematic experiments on human/agent behaviour and adaptation when co-learning a policy for the collaborative game. We present results on how co-policy learning occurs over time between the human and the robotic agent resulting in each participant's agent serving as a representation of how they would play the game. This allows us to relate a person's success when playing with different agents than their own, by comparing the policy of the agent with that of their own agent.",https://ieeexplore.ieee.org/document/9341473/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SYSOSE.2015.7151922,Real-time FPGA decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper presents a field programmable gate array (FPGA) implementation for a decentralized inverse optimal neural controller for unknown nonlinear systems, in presence of external disturbances and parameter uncertainties. This controller is based on two techniques: first, an identifier using a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the neural identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/7151922/,2015 10th System of Systems Engineering Conference (SoSE),17-20 May 2015,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/CCA.2007.4389266,Real-time Obstacle Avoidance Strategy for Mobile Robot Based On Improved Coordinating Potential Field with Genetic Algorithm,IEEE,Conferences,"To overcome the problems during navigation of mobile robots in dynamic environment using the traditional artificial potential field (APF) method, a novel improved method called coordinating potential field (CPF) is proposed. The local potential field is constructed by using local subgoals, which obtained by updating dynamic windows. The questions of local minima, oscillation between multiple obstacles and real-time dynamic obstacle avoidance are solved. At last multi-objective parameter optimization is implemented by using adaptive genetic algorithm. Simulation results indicate that this strategy is practicable and effective.",https://ieeexplore.ieee.org/document/4389266/,2007 IEEE International Conference on Control Applications,1-3 Oct. 2007,ieeexplore
10.1109/CCA.1994.381367,Real-time control of a robot using neural networks,IEEE,Conferences,"The real-time computation of the robot kinematics is very important. The basic transformations are the direct kinematic transformation (DKT) and the inverse kinematic transformation (IKT). The DKT can be computed in a straightforward way using the Denavit-Hartenberg notation. No such general method yet exists for the IKT, although this transformation is of major interest for control purposes. In this paper a neural network is presented that maps the IKT independent of the type of robot. After training, the network achieves very good accuracy and may easily be implemented in real-time. The performance of the algorithm is tested an the RTX robot, a SCARA-type robot with six degrees of freedom. This robot is controlled by a distributed control system. A host computer realizes the continuous path control and a network of 5 slave-transputers is used to compute the local controls and to drive the DC servomotors.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/381367/,1994 Proceedings of IEEE International Conference on Control and Applications,24-26 Aug. 1994,ieeexplore
10.1109/IJCNN.2013.6706785,Real-time decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper deals with a decentralized inverse optimal neural controller for MIMO discrete-time unknown nonlinear systems, in a presence of external disturbances and parameter uncertainties. It uses two techniques: first, an identifier based on a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the real identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/6706785/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/CCA.2009.5280998,Real-time decentralized neural backstepping controller for a robot manipulator,IEEE,Conferences,This paper deals with adaptive trajectory tracking for discrete-time MIMO nonlinear systems. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The HONN learning is performed online by an Extended Kalman Filter (EKF) algorithm. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.,https://ieeexplore.ieee.org/document/5280998/,"2009 IEEE Control Applications, (CCA) & Intelligent Control, (ISIC)",8-10 July 2009,ieeexplore
10.1109/IROS.2009.5354338,Real-time decentralized neural block controller for a robot manipulator,IEEE,Conferences,"This paper presents a discrete-time decentralized control scheme for identification and trajectory tracking of a two degrees of freedom (DOF) robot manipulator. A recurrent high order neural network (RHONN) structure is used to identify the plant model and based on this model, a discrete-time control law is derived, which combines discrete-time block control and sliding modes techniques. The neural network learning is performed online by Kalman filtering. A controller is designed for each joint, using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.",https://ieeexplore.ieee.org/document/5354338/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/ISIC.2010.5612924,Real-time five DOF robot control using a decentralized neural backstepping scheme,IEEE,Conferences,This paper presents a discrete-time decentralized control scheme for trajectory tracking of a five degrees of freedom (DOF) redundant robot. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The neural network learning is performed on-line by Kalman filtering. The controllers are designed for each joint using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The applicability of the proposed scheme is illustrated via real-time implementation.,https://ieeexplore.ieee.org/document/5612924/,2010 IEEE International Symposium on Intelligent Control,8-10 Sept. 2010,ieeexplore
10.1109/ICAR.1997.620222,Real-time navigation of a mobile robot using Kohonen's topology conserving neural network,IEEE,Conferences,"This paper proposes a real-time sensor based navigation method using Kohonen's topology conserving network for navigation of a mobile robot in any uncertain environment. The sensory information including target location with respect to current location of the mobile robot, have been discretely conserved using a two dimensional Kohonen lattice. Reinforcement learning based on a stochastic real valued technique have been implemented to compute the action space for this Kohonen lattice. The proposed scheme learns the input and output weight space of the Kohonen lattice which is generalized to any workspace. The effectiveness of the proposed scheme has been established by simulation where the complete domain of the input-space is quantized based on experience on sensory data encountered in real-time. The input-output mapping conserved by the Kohonen lattice during simulation was used to guide a mobile robot in a real-time environment. Successful navigation of the mobile robot without further training confirms the robustness of the proposed scheme.",https://ieeexplore.ieee.org/document/620222/,1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97,7-9 July 1997,ieeexplore
10.1109/ROBOT.2001.932598,Real-time robot learning,IEEE,Conferences,"This paper presents the design, implementation and testing of a real-time system using computer vision and machine learning techniques to demonstrate learning behavior in a miniature mobile robot. The miniature robot, through environmental sensing, learns to navigate a maze choosing the optimum route. Several reinforcement learning based algorithms, such as the Q-learning, Q(/spl lambda/)-learning, fast online Q(/spl lambda/)-learning and DYNA structure, are considered. Experimental results based on simulation and an integrated real-time system are presented for varying density of obstacles in a 15/spl times/15 maze.",https://ieeexplore.ieee.org/document/932598/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICACEH51803.2020.9366217,Realization of Human and Fish Robot Interaction with Artificial Intelligence Using Hand Gesture,IEEE,Conferences,This study mimicked a real fish movement in the aquarium which was controlled by hand signals. The main idea to develop an aquarium robotic fish with hand gestures. Control actions include directions and stop and go of the fish. The inputs are given by human hands known as bio-mimetic ornamental. We implemented control algorithms to recognize hand gestures. The experimental results showed the effective control of robot fish with hand gestures.,https://ieeexplore.ieee.org/document/9366217/,"2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH)",25-27 Dec. 2020,ieeexplore
10.1109/GTSD50082.2020.9303087,Receptionist and Security Robot Using Face Recognition with Standardized Data Collecting Method,IEEE,Conferences,"Face recognition has become the front runner for deep learning applications in the real world and this paper focuses on its implementation in a human-robot interaction and security system. For this specific project, it is inherent that restraints are created to allow the system to produce greater performance within the requirements of a receptionist and security robot. A k-nearest neighbors classifier is applied to further enhance the accuracy of face recognition. By sequencing images from videos, we create large datasets to train our own classifier in various conditions to increase its accuracy and lower false-positive rates in poor lighting environments. With the goal of creating a service robot, we have standardized our method of data collection for new inputs that will assist the recognition process in variable conditions of operation. The resulting product is a system that can accurately predict known and unknown faces with Asian features.",https://ieeexplore.ieee.org/document/9303087/,2020 5th International Conference on Green Technology and Sustainable Development (GTSD),27-28 Nov. 2020,ieeexplore
10.1109/ICCCT.2010.5640434,Recognizing &amp; interpreting Indian Sign Language gesture for Human Robot Interaction,IEEE,Conferences,"This paper describes a novel approach towards recognizing of Indian Sign Language (ISL) gestures for Humanoid Robot Interaction (HRI). An extensive approach is being introduced for classification of ISL gesture which imparts an elegant way of interaction between humanoid robot HOAP-2 and human being. ISL gestures are being considered as a communicating agent for humanoid robot which is being used in this context explicitly. It involves different image processing techniques followed by a generic algorithm for feature extraction process. The classification technique deals with the Euclidean distance metric. The concrete HRI system has been established for initiation based learning mechanism. The Real time robotics simulation software, WEBOTS has been adopted to simulate the classified ISL gestures on HOAP-2 robot. The JAVA based software has been developed to deal with the entire HRI process.",https://ieeexplore.ieee.org/document/5640434/,2010 International Conference on Computer and Communication Technology (ICCCT),17-19 Sept. 2010,ieeexplore
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/BioRob49111.2020.9224392,Reinforcement Learning Assist-as-needed Control for Robot Assisted Gait Training,IEEE,Conferences,"The primary goal of an assist-as-needed (AAN) controller is to maximize subjects' active participation during motor training tasks while allowing moderate tracking errors to encourage human learning of a target movement. Impedance control is typically employed by AAN controllers to create a compliant force-field around the desired motion trajectory. To accommodate different individuals with varying motor abilities, most of the existing AAN controllers require extensive manual tuning of the control parameters, resulting in a tedious and time-consuming process. In this paper, we propose a reinforcement learning AAN controller that can autonomously reshape the force-field in real-time based on subjects' training performances. The use of action-dependent heuristic dynamic programming enables a model-free implementation of the proposed controller. To experimentally validate the controller, a group of healthy individuals participated in a gait training session wherein they were asked to learn a modified gait pattern with the help of a powered ankle-foot orthosis. Results indicated the potential of the proposed control strategy for robot-assisted gait training.",https://ieeexplore.ieee.org/document/9224392/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/AI4I46381.2019.00027,Reinforcement Learning of a Robot Cell Control Logic using a Software-in-the-Loop Simulation as Environment,IEEE,Conferences,"This paper introduces a method for automatic robot programming of industrial robots using reinforcement learning on a Software-in-the-loop simulation. The focus of the the paper is on the higher levels of a hierarchical robot programming problem. While the lower levels the skills are stored as domain specific program code, the combination of the skills into a robot control program to solve a specific task is automated. The reinforcement learning learning approach allows the shopfloor workers and technicians just to define the end result of the manufacturing process through a reward function. The programming and process optimization is done within the learning procedure. The Software-in-the-loop simulation with the robot control software makes it possible to to interpret the real program code and generate the exact motion. The exact motion of the robot is needed in order to find not just an optimal but also a collision-free policy.",https://ieeexplore.ieee.org/document/9027783/,2019 Second International Conference on Artificial Intelligence for Industries (AI4I),25-27 Sept. 2019,ieeexplore
10.1109/CIRA.2007.382878,Reinforcement Learning with a Supervisor for a Mobile Robot in a Real-world Environment,IEEE,Conferences,"This paper describes two experiments with supervised reinforcement learning (RL) on a real, mobile robot. Two types of experiments were preformed. One tests the robot's reliability in implementing a navigation task it has been taught by a supervisor. The other, in which new obstacles are placed along the previously learned path to the goal, measures the robot's robustness to changes in environment. Supervision consisted of human-guided, remote-controlled runs through a navigation task during the initial stages of reinforcement learning. The RL algorithms deployed enabled the robot to learn a path to a goal yet retain the ability to explore different solutions when confronted with a new obstacle. Experimental analysis was based on measurements of average time to reach the goal, the number of failed states encountered during an episode, and how closely the RL learner matched the supervisor's actions.",https://ieeexplore.ieee.org/document/4269878/,2007 International Symposium on Computational Intelligence in Robotics and Automation,20-23 June 2007,ieeexplore
10.1109/ICSMC.2012.6377767,Reinforcement learning-based tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal adaptive control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6377767/,"2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",14-17 Oct. 2012,ieeexplore
10.1109/CYBER.2012.6392582,Reinforecement learning-based optimal tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6392582/,"2012 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 May 2012,ieeexplore
10.1109/WCICA.2000.863464,Related value set algorithm for robot to distinguish image,IEEE,Conferences,"The image recognition from image database is different from robot vision in real world because the robot concerned is movable. The size of the image that captured by the robot varies with the distance between robot's camera and the real picture, or object. We analyzed the process of how human remembers and identifies an image. We derived eight properties of the key feature in an image. We then developed a related value set algorithm. With the algorithm, we defined a set to represent the key features of an image. The elements of the set are represented with the related value. The key features retrieved from an image with the algorithm satisfied the eight properties, thus the algorithm can be used for robot to distinguish images or object. The key features can also be used in image knowledge representation.",https://ieeexplore.ieee.org/document/863464/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/RCAR47638.2019.9044114,Research on omnidirectional mobile robot motion control based on integration of traction and steering wheel,IEEE,Conferences,"In order to solve the automatic transportation of heavy materials under the limited working space of production workshops and warehouses, two sets of heavy-duty omnidirectional mobile robot motion control systems with steering wheel drive units were designed. The steering wheel combination drive unit of the “walking + steering” set is used to build the mobile robot chassis, and the mechatronics servo system and mathematical model of multi-motor coordinated motion are constructed. The communication between the controller and the steering wheel combination drive unit is established through the CAN bus. The specific implementation is to capture and analyze the control signal through the controller to obtain the desired motion mode, to obtain the motion of each set of steering wheel unit through the mathematical model, and to realize the desired motion through the synthesis of each set of steering wheel unit motion. It has been verified by experiments that the two sets of steering wheel unit-driven mobile robot control system realizes the zero turning radius, 360-degree omnidirectional movement of the robot and rotation during the movement. It can be used for flexible work in tight spaces.",https://ieeexplore.ieee.org/document/9044114/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/WCICA.2004.1343675,Research on remote controlled robot motion control system based on agent theory,IEEE,Conferences,"This paper introduces remote controlled robot motion control system based on agent theory. Task planning and reactive behavior control are discussed and implemented. This paper describes design of manager agent and motion control agent in detail. Agent theory are implemented in the robot control system to realize distributed intelligence based on M/A/R(Man/Agent/Robot) architecture. Thereby autonomy, reliability and real-time operation are improved.",https://ieeexplore.ieee.org/document/1343675/,Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788),15-19 June 2004,ieeexplore
10.1109/ICRA.2019.8794127,Residual Reinforcement Learning for Robot Control,IEEE,Conferences,"Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",https://ieeexplore.ieee.org/document/8794127/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICRA.2015.7139395,RoboSherlock: Unstructured information processing for robot perception,IEEE,Conferences,"We present RoboSherlock, an open source software framework for implementing perception systems for robots performing human-scale everyday manipulation tasks. In RoboSherlock, perception and interpretation of realistic scenes is formulated as an unstructured information management (UIM) problem. The application of the UIM principle supports the implementation of perception systems that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate the potential of the proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of RoboSherlock.",https://ieeexplore.ieee.org/document/7139395/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/SAIS53221.2021.9483964,Robot First Aid: Autonomous Vehicles Could Help in Emergencies,IEEE,Conferences,"Safety is of critical importance in designing autonomous vehicles (AVs) that will be able to perform effectively in complex, mixed-traffic, real-world urban environments. Some prior research has looked at how to proactively avoid accidents with safe distancing and driver monitoring, but currently little research has explored strategies to recover afterwards from emergencies, from crime to natural disasters. The current short paper reports on our ongoing work using a speculative prototyping approach to explore this expansive design space, in the context of how a robot inside an AV could be deployed to support first aid. As a result, we present some proposals for how to detect emergencies, and examine and help victims, as well as lessons learned in prototyping. Thereby, our aim is to stimulate discussion and ideation that-by considering the prevalence of Murphy's law in our complex world, and the various technical, ethical, and practical concerns raised-could potentially lead to useful safety innovations.",https://ieeexplore.ieee.org/document/9483964/,2021 Swedish Artificial Intelligence Society Workshop (SAIS),14-15 June 2021,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/∼cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICNSC48988.2020.9238090,Robot Navigation with Map-Based Deep Reinforcement Learning,IEEE,Conferences,"This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",https://ieeexplore.ieee.org/document/9238090/,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",30 Oct.-2 Nov. 2020,ieeexplore
10.1109/IJCNN.2010.5596709,Robot guiding with obstacle avoidance algorithm for uncertain enviroments based on DTCNN,IEEE,Conferences,"This paper introduces two applications of Discrete Time Cellular Non-Linear Networks (DTCNN) in a robot guiding avoiding obstacles algorithm and prove the feasibility of both applications: a high data rate one, using a CMOS camera, and small data rate one, using ultrasonic sensors. The key value of DTCNNs is the locally connections and the parallelism in processing. These characteristics permit a hardware implementation, in our case over a Field Programmable Gate Arraw (FPGA) and a real time template based algorithm processing. A camera and an ultrasonic sensor are used as avoiding obstacles system, requiring both implementations, different inputs informations: the first one complex environment information and the later for basic situations information where impulsive response is required. Both input can have an enhanced behaviour within DTCNN structure.",https://ieeexplore.ieee.org/document/5596709/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/MECHATRONIKA.2014.7018286,Robot imitation of human arm via Artificial Neural Network,IEEE,Conferences,"In this study, a robot arm that can imitate human arm is designed and presented. The potentiometers are located to the joints of the human arm in order to detect movements of human gestures, and data were collected by this way. The collected data named as “movement of human arm” are classified by the help of Artificial Neural Network (ANN). The robot performs its movements according to the classified movements of the human. Real robot and real data are used in this study. Obtained results show that the learning application of imitating human action via the robot was successfully implemented. With this application, the platforms of robot arm in an industrial environment can be controlled more easily; on the other hand, robotic automation systems which have the capability of making a standard movements of a human can become more resistant to the errors.",https://ieeexplore.ieee.org/document/7018286/,Proceedings of the 16th International Conference on Mechatronics - Mechatronika 2014,3-5 Dec. 2014,ieeexplore
10.1109/ROBOT.2000.845355,Robot improv: using drama to create believable agents,IEEE,Conferences,"Believable agents usually depend upon explicit, model-based simulations of human emotions. This work appeals instead to the sensibilities of dramatic acting to create agents that are believable. The chosen task is that of comedy improvisation as it provides a solid demonstration of the agents' believability in the context of a high-level deliberative goal. Furthermore, this work employs physical robots as the actors, employing the real-time sensor values from the robots as inputs into the acting process. This paper describes the dramatic approach to acting that we used and describes the Java-based implementation on two Nomad Scout robots. Actual, improvised scripts created by the robots are included and analyzed.",https://ieeexplore.ieee.org/document/845355/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ASAMA.1999.805407,Robot media communication: an interactive real-world guide agent,IEEE,Conferences,"Describes a guide system and the software architecture for an autonomous, interactive robot based on a multi-agent system. A robot navigation system has been developed allowing the robot to guide people through halls in various types of exhibitions. Our approach uses an infrared location system in the hallway ceilings, making the environment part of a sensor-distributed robot system. The real-world guide agent is composed of a guide agent on a hand-held mobile computer and a robot agent on an autonomous mobile robot. The guide agent plays the role of ""robot media"" in order to integrate information in the information space of the mobile computer and the physical space of the exhibits in order to guide visitors through the physical space. This research aims to develop a cooperative adaptive system using two-way communication among spaces, media and human beings to construct transparent knowledge boundaries between the real space and the virtual space. The virtual space is generated from computer data using shared space technology and it creates a distributed intelligence in order to manage the communication and control the guide in a laboratory. We have experimented with and verified this software architecture using a prototype autonomous mobile robot equipped with a compass.",https://ieeexplore.ieee.org/document/805407/,"Proceedings. First and Third International Symposium on Agent Systems Applications, and Mobile Agents",6-6 Oct. 1999,ieeexplore
10.1109/ICSMC.2008.4811760,Robot navigation using KFLANN place field,IEEE,Conferences,"This paper presents an implementation of place cells for a robot navigation using the K-iterations fast learning artificial neural networks (KFLANN) clustering algorithm. The KFLANN possesses several desirable properties suitable for place cell robot navigation tasks. The technique proposed is able to autonomously adjust the resolution of cells according to the complexity of the environment. This is achieved through two parameters known as the tolerance and the vigilance of the network. In addition, a navigation system consisting of a topological map building and a place cell path planning strategy is presented. A physical implementation of the system was developed on an autonomous platform and actual results were obtained. The experimental results obtained indicate that the system was able to navigate successfully through the experimental space and also tolerate unexpected discrepancies arising from motor and sensor errors present in a real environment. Furthermore, despite abrupt changes in an environment due to the deliberate introduction of obstacles, the system was still able to cope without changes to the program. The experiment was also extended to include a kidnapped robot scenario and the results were favorable, indicating a positive use of allothetic cue recognition capabilities.",https://ieeexplore.ieee.org/document/4811760/,"2008 IEEE International Conference on Systems, Man and Cybernetics",12-15 Oct. 2008,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/SMC.2016.7844958,Robot position control in pipes using Q Learning,IEEE,Conferences,"In the most critical hydro crisis in Brazil, 37 percent of the whole amount of treated water is wasted before reaching consumers. A robot with a position control to travel inside a pipe is an important step in the pursuit of an autonomous solution to detect and correct pipes failures. This paper shows a Q Learning controller algorithm implemented using a microcontroller in a mechanical body of a commercial pipe inspection robot. Using only the measurements of a gyroscope, and controlling the wheels' motors on the left and right sides, the controller learned the best set of movements to ride inside a 300mm sewer pipe, in the tested conditions. Real tests in a 300mm pipe were performed using the developed algorithm and it was compared to a random movement and to a straight forward movement.",https://ieeexplore.ieee.org/document/7844958/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1145/1957656.1957814,Robot self-initiative and personalization by learning through repeated interactions,IEEE,Conferences,"We have developed a robotic system that interacts with the user, and through repeated interactions, adapts to the user so that the system becomes semi-autonomous and acts proactively. In this work we show how to design a system to meet a user's preferences, show how robot pro-activity can be learned and provide an integrated system using verbal instructions. All these behaviors are implemented in a real platform that achieves all these behaviors and is evaluated in terms of user acceptability and efficiency of interaction.",https://ieeexplore.ieee.org/document/6281377/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/RO-MAN47096.2020.9223566,Robust Real-Time Hand Gestural Recognition for Non-Verbal Communication with Tabletop Robot Haru,IEEE,Conferences,"In this paper, we present our work in close-distance non-verbal communication with tabletop robot Haru through hand gestural interaction. We implemented a novel hand gestural understanding system by training a machine-learning architecture for real-time hand gesture recognition with the Leap Motion. The proposed system is activated based on the velocity of a user's palm and index finger movement, and subsequently labels the detected movement segments under an early classification scheme. Our system is able to combine multiple gesture labels for recognition of consecutive gestures without clear movement boundaries. System evaluation is conducted on data simulating real human-robot interaction conditions, taking into account relevant performance variables such as movement style, timing and posture. Our results show robustness in hand gesture classification performance under variant conditions. We furthermore examine system behavior under sequential data input, paving the way towards seamless and natural real-time close-distance hand-gestural communication in the future.",https://ieeexplore.ieee.org/document/9223566/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CCDC.2019.8832613,Robust Zhang Neural Network for Tracking Control of Parallel Robot Manipulators With Unknown Parameters,IEEE,Conferences,"Under the situation of parameter uncertainty, the tracking control of parallel robot manipulators is a challenging problem in robotic research. Unlike conventional Zhang neural network (ZNN) relying on the assumption that the robot parameter information is fully and accurately known, this paper proposes a robust Zhang neural network (RZNN) for tracking control problems solving of parallel robot manipulators in the absence of parameter information. The proposed RZNN features the full utilization of effector feedback information, and shows a robust tracking performance even with unknown robot parameter information. Then, the continuous-time model of the RZNN is discretized via Euler forward formula (EFF) for numerical implementation. Finally, comprehensive simulative experiments including robustness test verify the effectiveness of the RZNN model for the real-time tracking control of parallel robot manipulators with unknown parameters.",https://ieeexplore.ieee.org/document/8832613/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/HUMANOIDS.2014.7041487,Robust fall detection with an assistive humanoid robot,IEEE,Conferences,"Summary form only given. In this video we introduce a robot assistant that monitors a person in a household environment to promptly detect fall events. In contrast to the use of a fixed sensor, the humanoid robot will track and keep the moving person in the scene while performing daily activities. For this purpose, we extended the humanoid Nao<sup>1</sup> with a depth sensor<sup>2</sup> attached to its head. The tracking framework implemented with OpenNI<sup>3</sup> segments and tracks the person's position and body posture. We use a learning neural framework for processing the extracted body features and detecting abnormal behaviors, e.g. a fall event [1]. The neural architecture consists of a hierarchy of self-organizing neural networks for attenuating noise caused by tracking errors and detecting fall events from video stream in real time. The tracking application, the neural framework, and the humanoid actuators communicate over Robot Operating System (ROS)<sup>4</sup>. We use communication over the ROS network implemented with publisher-subscriber nodes. When a fall event is detected, Nao will approach the person and ask whether assistance is needed. In any case, Nao will take a picture of the scene that can be sent to the caregiver or a relative for further human evaluation and agile intervention. The combination of this sensor technology with our neural network approach allows to tailor the robust detection of falls independently from the background surroundings and in the presence of noise (tracking errors and occlusions) introduced by a real-world scenario. The video shows experiments run in a home-like environment.",https://ieeexplore.ieee.org/document/7041487/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/ICIAS.2012.6306173,SCARA robot control using neural networks,IEEE,Conferences,"A SCARA industrial robot model is identified based on a 4-axis structure using Lagrangian mechanics, also the dynamic model for the electromechanical actuator and motion transmission systems is identified. A conventional PD controller is implemented and compared to neural networks control system to achieve precise position control of SCARA manipulator. The performance of the modeled system is simulated using several desired tracking motion for each joint. Neural networks control method has shown a remarkable improvement of tracking capabilities for the SCARA robot over conventional PD controller. The proposed neural network controller has the potential to accurately control real-time manipulator applications.",https://ieeexplore.ieee.org/document/6306173/,2012 4th International Conference on Intelligent and Advanced Systems (ICIAS2012),12-14 June 2012,ieeexplore
10.1109/ICRA48506.2021.9561020,SQRP: Sensing Quality-aware Robot Programming System for Non-expert Programmers,IEEE,Conferences,"Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot’s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",https://ieeexplore.ieee.org/document/9561020/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICSMC.2001.969840,STNS-R: a learning method for seamless transplantation from a virtual agent to a physical robot,IEEE,Conferences,"In this paper, we are concerned with the problem of how a physical robot can get an appropriate internal representation to its task and environment. Learning from experience is effective for the problem, but it is very time-consuming to learn a representation from the beginning in a real environment. On the other hand, the representation learned only in a simulated environment has the risk of not serving the purpose in a real environment because of the uncertainty in sensors, actuators, and the environment. In, order to have the best of both worlds, it is effective to transplant the learned state representation of a virtual agent to a physical robot. For this purpose., we improved our developed incremental learning architecture for use in the real environment and developed a new architecture, called STNS-R. In this architecture, inappropriate negative instances caused by uncertainties are found on the basis of the distribution of instances and removed in order to correct the distorted shapes of the states. The effectiveness of STNS-R is shown in the experimental results.",https://ieeexplore.ieee.org/document/969840/,"2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236)",7-10 Oct. 2001,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/CIMCA.2005.1631415,Self-Organization of Spiking Neural Network Generating Autonomous Behavior in a Real Mobile Robot,IEEE,Conferences,"In this paper, we study the relation between neural dynamics and robot behavior to develop self-organization algorithm of spiking neural network applicable to autonomous robot. We first formulated a spiking neural network model whose inputs and outputs were analog. We then implemented it into a miniature mobile robot Khepera. In order to see whether or not a solution(s) for the given task exists with the spiking neural network, the robot was evolved with the genetic algorithm (GA) in an environment. The robot acquired the obstacle avoidance and navigation task successfully, exhibiting the presence of the solution. Then, a self-organization algorithm based on the use-dependent synaptic potentiation and depotentiation was formulated and implemented into the robot. In the environment, the robot gradually organized the network and the obstacle avoidance behavior was formed. The time needed for the training was much less than with genetic evolution, approximately one fifth (1/5)",https://ieeexplore.ieee.org/document/1631415/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ISSCAA.2008.4776238,Self-motion planning of redundant robot manipulators based on quadratic program and shown via PA10 example,IEEE,Conferences,"In this paper, a criterion is proposed in the form of a quadratic function for the purpose of self-motion planning of redundant robot arms. The proposed self-motion scheme with joint physical limits considered could be formulated as a quadratic programming (QP) problem subject to equality, (inequality) and bound constraints. A primal-dual neural network based on linear variational inequalities (LVI) is developed as the real-time solver for the resultant quadratic-program. The so-called LVI-based primal-dual neural network has a simple piecewise-linear dynamics and a global exponential convergence to optimal solutions of QP problems. Computer-simulations performed based on PA10 robot arm substantiate the efficacy of the proposed QP-based neural self-motion-planning scheme.",https://ieeexplore.ieee.org/document/4776238/,2008 2nd International Symposium on Systems and Control in Aerospace and Astronautics,10-12 Dec. 2008,ieeexplore
10.1109/ICSMC.1997.625763,Self-organized learning and its implementation of robot movements,IEEE,Conferences,The self-organizing map algorithm using an artificial neural network originally developed by Kohonen and extended and modified later provides a distributed and autonomous learning procedure in engineering modeling of the human sensory-motor mapping mechanism. Its extension and adaptation to a control problem of a robot manipulator has been intensively discussed in past years. In this article the application of the self-organizing map algorithm to the generation of a visuo-motor map is focused on. A task-oriented inverse kinematic solution to a redundant manipulator is formed and real-time implementation of the map on a mechanical manipulator is performed.,https://ieeexplore.ieee.org/document/625763/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ROBOT.2006.1642213,Self-organizing approach for robot's behavior imitation,IEEE,Conferences,"In this paper, an approach for behavior imitation using visual information was introduced. The imitation process is done by a self organizing neural network module. From several demonstrations of task operation, a vision system captures movement of the demonstrator mobile robot and associated objects in an operation field. Then, the movement features are extracted to present to an imitation engine. Finally, skill or decision policy from teacher's demonstration is extracted and embedded into a self organizing neural network without explicit external supervisory signals. A simple action selection algorithm for choosing action from learned network is proposed. The algorithm was implemented and tested on a simulated robot and a real mobile robot to imitate two simple robot soccer behaviors: approaching the target and obstacle avoidance. Furthermore, the concept of similarity measure is introduced to evaluate imitation performance from the demonstrator",https://ieeexplore.ieee.org/document/1642213/,"Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.",15-19 May 2006,ieeexplore
10.1109/ROBOT.1996.506506,Semantic learning by an autonomous mobile robot,IEEE,Conferences,Describes the design and implementation of a learning system for control of an autonomous mobile robot. The robot learns reactive behaviors that allow it to retreat from potential collisions and to explore its environment by seeking out nearby objects. No external teaching input is required. Results from experiments with a real robot are presented. The learned reactive behaviors become the basis for the acquisition of more complex behaviors. Sensory/motor states are classified and then associated with lexical items to form a simple command language which is then used to direct the robot.,https://ieeexplore.ieee.org/document/506506/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/IROS.2017.8206048,Sensor fusion for robot control through deep reinforcement learning,IEEE,Conferences,"Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information generated by multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",https://ieeexplore.ieee.org/document/8206048/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/CCDC.2008.4597309,Simulation of robot localization based on virtual sensors,IEEE,Conferences,"A flexible simulation frame based on concept of component is presented. An indoor robots localization simulation environment based on virtual sensors RoboSimer is built with OpenGL. The parameters here are easily adjusted and controlled by customs and the simulation module is easy to integrate. It can integrate any sensors, environment and robot shape into the simulation software. The interfaces of simulation software are coincided with the real hardware platform. It provides a convenient condition for the further study on robot localization.",https://ieeexplore.ieee.org/document/4597309/,2008 Chinese Control and Decision Conference,2-4 July 2008,ieeexplore
10.1109/ICAR.2015.7251437,Simultaneous human-robot adaptation for effective skill transfer,IEEE,Conferences,"In this paper, we propose and implement a human-in-the loop robot skill synthesis framework that involves simultaneous adaptation of the human and the robot. In this framework, the human demonstrator learns to control the robot in real-time to make it perform a given task. At the same time, the robot learns from the human guided control creating a non-trivial coupled dynamical system. The research question we address is how this system can be tuned to facilitate faster skill transfer or improve the performance level of the transferred skill. In the current paper we report our initial work for the latter. At the beginning of the skill transfer session, the human demonstrator controls the robot exclusively as in teleoperation. As the task performance improves the robot takes increasingly more share in control, eventually reaching full autonomy. The proposed framework is implemented and shown to work on a physical cart-pole setup. To assess whether simultaneous learning has advantage over the standard sequential learning (where the robot learns from the human observation but does not interfere with the control) experiments with two groups of subjects were performed. The results indicate that the final autonomous controller obtained via simultaneous learning has a higher performance measured as the average deviation from the upright posture of the pole.",https://ieeexplore.ieee.org/document/7251437/,2015 International Conference on Advanced Robotics (ICAR),27-31 July 2015,ieeexplore
10.1109/SaCoNeT.2018.8585616,Smart Navigation of Mobile Robot Using Neural Network Controller,IEEE,Conferences,"The field of autonomous navigation of mobile robot is advancing so fast especially with the development of machine learning algorithms. This study aims to introduce a neural network controller that controls the trajectory and the obstacle avoidance of a non-holonomic mobile robot.We train the robot in environment containing multiple obstacles with different places. This paper includes both a kinematic and a dynamic study of a mobile robot. Different training schemes have been studied that tackle the learning objectives differently. The trained controller is producing the Pulse Width Modulation (PWM) signals that could be implemented in a microprocessor and validated by simulations. Unlike some other recent approaches, this work was validated by a 3D simulation which is similar to the real model.",https://ieeexplore.ieee.org/document/8585616/,2018 International Conference on Smart Communications in Network Technologies (SaCoNeT),27-31 Oct. 2018,ieeexplore
10.1109/ROBOT.2004.1308781,Software approach for the autonomous inspection robot MAKRO,IEEE,Conferences,"The sewer inspection robot MAKRO is an autonomous multi-segment robot with worm-like shape driven by wheels. It is currently under development in the project MAKRO-PLUS. The robot has to navigate autonomously within sewer systems. Its first tasks is to take water probes, analyze them onboard, and measure positions of manholes and pipes to detect pollution loaded sewage and to improve current maps of sewer systems. One of the challenging problems is the control software, which should enable the robot to navigate in the sewer system and perform the inspection tasks autonomously, while always taking care of its own safety. Tests in our test environment and in a real sewer system show promising results. This paper focuses on the software approach. To manage the complexity a layered architecture has been chosen, each layer defining a different level of abstraction. After determining the abstraction levels, we use different methods for implementation. For the highest abstraction level a standard AI-planning algorithm is used. For the next level, finite state automata has been chosen. For ""simple"" task implementation we use a modular C++ based method (MCA2), which is also used on the lowest software level.",https://ieeexplore.ieee.org/document/1308781/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/ICCE46568.2020.9042995,Stroke Signs Detection System by SNS Agency Robot,IEEE,Conferences,"This paper proposes a system which implements the Cincinnati Prehospital Stroke Scale (CPSS), the widely used screening method for the initial symptoms of a stroke, in a communication robot. AI on cloud analyses an acquired video through a conversation with the robot in real time and automatically determines the abnormalities. The judgement result is informed to his/her families by SNS. This study implemented two of the three CPSS scales such as “Arms” and “Speech”, we confirmed that the system enables to acquire, analyze and notify the information in real time.",https://ieeexplore.ieee.org/document/9042995/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IJCNN.2008.4634389,Supporting mixed initiative human-robot interaction: A script-based cognitive architecture approach,IEEE,Conferences,"As complex indoor-robot systems are developed and deployed into the real-world, the demand for human-robot interaction is increasing. Mixed-initiative human-robot interaction is a good method to coordinate actions of a human and a robot in a complementary fashion. In order to support such interactions, we employ scripts that are rich, flexible, and extensible for a robotpsilas interactions in a variety of situations. Scripts are amenable for expressing knowledge in an applicable form, especially describing a sequence of actions in organizing tasks. In this paper, we propose a script-based cognitive architecture for collaboration, which is based on three-level cognitive models. It incorporates dynamic Bayesian network (DBN) to automatically govern action sequences in the scripts and detect userpsilas intention or goal. Starting from an understanding of user initiatives, our intelligent task manager suggests the most relevant initiatives for an efficient collaboration. DBN has been evaluated in real indoor task scenarios for its efficacy in interaction reduction, error minimization, and task satisfaction.",https://ieeexplore.ieee.org/document/4634389/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ISIC.1991.187403,Symbolic feature-based representation and planning for an agent based robot controller,IEEE,Conferences,"A prototype system has been developed to input 3-D computer-aided-design (CAD) data to automatically generate and implement robot trajectories for such application as waterjet cutting, surface finishing and polishing. The system can drive various robot configurations and handle contingencies such as collisions and singularities. The system provides a framework for integration of high-level reasoning, real-time path and trajectory planning, and various levels of feedback based on contingency detection algorithms or sensor data. Although initial CAD data have been in the form of IGES geometric entities, a higher-level CAD description based on manufacturing features which incorporates both geometric and process information is being developed. This feature-based CAD representation provides a direct interface between the CAD design data and the planning system for robot control. An agent actor paradigm is proposed as the representation for software/hardware system specifications and associated software and hardware modules.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/187403/,Proceedings of the 1991 IEEE International Symposium on Intelligent Control,13-15 Aug. 1991,ieeexplore
10.1109/ICSICT.2018.8565654,System Simulation for Robot Control Based on AI Approach,IEEE,Conferences,"In this paper, we focus on real robot development and control for different surface conditions using an AI based approach. The core components of our existing robot are pressure sensor, servomotor and software-driven microcontroller. We performed robot system simulation for various ground surface conditions to control the robot with respect to pressure-sensing data that incorporates the two-way interactions between robot and ground. We have used an artificial neural network (ANN) approach for pressure-sensor-data analysis. The analysis result shows that above 25 hidden neurons and an increasing number of training cycles will deliver better performance in terms of mean square error (mse), learning time and improved nearest surface-pattern recognition. The analysis results are useful for next generation AI-chip development for real-time robot control and movement.",https://ieeexplore.ieee.org/document/8565654/,2018 14th IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT),31 Oct.-3 Nov. 2018,ieeexplore
10.1109/ICMA52036.2021.9512666,Target Detection and Tracking of Ground Mobile Robot Based on Improved Single Shot Multibox Detector Network,IEEE,Conferences,"To solve the problems of slow labeling speed of the traditional labellmg data set establishment method, and slow running speed of target classification and detection algorithm based on Single Shot Multibox Detector(SSD) deep learning network, this paper proposes a fast data set labeling algorithm and a fast SSD network for target real-time detection and tracking research. First, a data set is established quickly by using TLD target detection and tracking algorithms, cropping and mirroring methods are used to strengthen the data set. Then, SSD backbone network is improved based on depth-wise separable convolution to establish a fast SSD network. Finally, the ground mobile robot in RoboMasters(RM) competition is used as the detection and tracking target indoors and outdoors, as well as with other different scenarios with shield to test the real-time performance, accuracy and effectiveness of the algorithm. The results show that compared with traditional SSD network research, in terms of the analysis and processing system deployed on low-performance hardware, the improved fast SSD network can better meet the real-time requirements of target detection and tracking.",https://ieeexplore.ieee.org/document/9512666/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/IROS.1999.812762,Task-model based human robot cooperation using vision,IEEE,Conferences,"In order to assist a human, the robot must recognize human motion in real time by vision, and must plan and execute the needed assistance motion based on the task purpose and the context. In this research, we tried to solve such problems. We defined the abstract task model, analyzed the human demonstration by using events and an event stack, and automatically generated the task models needed in the assistance by the robot. The robot planned and executed the appropriate assistance motions based on the task: models according to the human motions in the cooperation with the human. We implemented a 3D object recognition system and a human grasp recognition system by using trinocular stereo color cameras and a real time range finder. The effectiveness of these methods was tested through an experiment in which the human and the robotic hand assembled toy parts in cooperation.",https://ieeexplore.ieee.org/document/812762/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/PADSW.2000.884672,Teleoperation system for real world robots-adaptive robot navigation based on sensor fusion,IEEE,Conferences,"The authors propose a teleoperation system with an autonomous robot which is able to solve tasks even without a large load for the operator and the system. Most teleoperation systems require skilled operators and expensive interfaces to solve tasks because they assume that the operator controls a robot completely. For these problems, we propose a teleoperation system which consists of an operation system and an autonomous robot. The operation system has a man-machine interface and allows a user to specify the working space and the tasks to be done. The autonomous robot follows the instruction from the operation system to solve the specific tasks. The paper focuses on navigation problems of the autonomous robot as an essential part of the proposed system. Namely, the autonomous robot should keep on the instructed paths in the real world to achieve a goal of the tasks. Our approach is based on a sensor fusion method based on two learning schemes: self-organizing map (SOM) and reinforcement learning. These learning schemes allow the system to be able to solve the tasks in an unreliable environment such as outdoors. Computational simulations reveal the effectiveness and robustness of the proposed method in the navigation problem.",https://ieeexplore.ieee.org/document/884672/,Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops,4-7 July 2000,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/IROS.2010.5650765,The design of LEO: A 2D bipedal walking robot for online autonomous Reinforcement Learning,IEEE,Conferences,"Real robots demonstrating online Reinforcement Learning (RL) to learn new tasks are hard to find. The specific properties and limitations of real robots have a large impact on their suitability for RL experiments. In this work, we derive the main hardware and software requirements that a RL robot should fulfill, and present our biped robot LEO that was specifically designed to meet these requirements. We verify its aptitude in autonomous walking experiments using a pre-programmed controller. Although there is room for improvement in the design, the robot was able to walk, fall and stand up without human intervention for 8 hours, during which it made over 43; 000 footsteps.",https://ieeexplore.ieee.org/document/5650765/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IJCNN.2008.4633777,"The development of a hybrid, distributed architecture for multiagent systems and its application in robot soccer",IEEE,Conferences,"Several issues still need to be unraveled in the development of multiagent systems equipped with global vision, as in robot soccer leagues. Here, we underscore three of them (1) real-time constraints on recognition of scene objects; (2) acquisition of environment knowledge; and (3) distribution and allocation of control competencies shared between the repertoire of the agentpsilas reactive behavior, and the central control entitypsilas strategic and deliberative behavior. The objective of this article is to describe the implementation of a distributed and hybrid reactive-deliberative control architecture for a multiagent system, equipped with global vision camera and agent local sensor and cameras. This multiple agent system was developed for application in robot soccer. We present the digital image processing techniques applied, as well as the proposed control architecture aimed at satisfying the constraints of this kind of application.",https://ieeexplore.ieee.org/document/4633777/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/BEC.2010.5631008,Timed Automata based provably correct robot control,IEEE,Conferences,"This paper presents a feasibility study on the usage of Uppaal Timed Automata (UPTA) for deliberative level robotic control. The study is based on the Scrub Nurse Robot case-study. Our experience confirms that UPTA model based control enables the control loop to be defined and maintained during the robot operation autonomously with minimum human intervention. Specifically, in our robot architecture the control model is constructed automatically using unsupervised learning. Correctness of the model is verified on-the-fly against safety, reachability, and performance requirements. Finally, it is demonstrated that UPTA model based robot control, action planning and model updates have natural implementation based on existing model execution and conformance testing tool Uppaal Tron.",https://ieeexplore.ieee.org/document/5631008/,2010 12th Biennial Baltic Electronics Conference,4-6 Oct. 2010,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/RO-MAN50785.2021.9515348,Towards Out-of-Sight Predictive Tracking for Long-Term Indoor Navigation of Non-Holonomic Person Following Robot<sup>*</sup>,IEEE,Conferences,"The ability to predict the movements of the target person allows a person following robot (PFR) to coexist with the person while still complying with the social norms. In human-robot collaboration, this is an essential requisite for long-term time-dependent navigation and not losing sight of the person during momentary occlusions that may arise from a crowd due to static or dynamic obstacles, other human beings, or intersections in the local surrounding. The PFR must not only traverse to the previously unknown goal position but also relocate the target person after the miss, and resume following. In this paper, we try to solve this as a coupled motion-planning and control problem by formulating a model predictive control (MPC) controller with non-linear constraints for a wheeled differential-drive robot. And, using a human motion prediction strategy based on the recorded pose and trajectory information of both the moving target person and the PFR, add additional constraints to the same MPC, to recompute the optimal controls to the wheels. We make comparisons with RNNs like LSTM and Early Relocation for learning the best-predicted reference path.MPC is best suited for complex constrained problems because it allows the PFR to periodically update the tracking information, as well as to adapt to the moving person’s stride. We show the results using a simulated indoor environment and lay the foundation for its implementation on a real robot. Our proposed method offers a robust person following behaviour without the explicit need for policy learning or offline computation, allowing us to design a generalized framework.",https://ieeexplore.ieee.org/document/9515348/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/DEVLRN.2005.1490968,Towards Robot Soccer Team Behaviours Through Approximate Simulation,IEEE,Conferences,"Robot soccer is now recognized as one of the most popular and efficient testbeds for intelligent robotics. It involves many challenges for computation, mechanics, control, software engineering, machine learning, and other fields. The international RoboCup initiative supports research into robot soccer and provides an excellent environment to investigate machine learning for robotics in simulation and the real world",https://ieeexplore.ieee.org/document/1490968/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/AIVR.2018.00060,Towards a Music Visualization on Robot (MVR) Prototype,IEEE,Conferences,"This paper presents a Music Visualization on Robot (MVR) prototype system which automatically links the flashlight, color and emotion of a robot through music. The MVR system is divided into three portions. Firstly, the system calculates the waiting time for a flashlight by beat tracking. Secondly, the system calculates the emotion correlated with music mood. Thirdly, the system links the color with emotion. To illustrate the prototype on a robot, the prototype implementation is based on a programmable robot called Zenbo because Zenbo has 8 LED light colors on 2 wheels and 24 face emotions to support various compositions.",https://ieeexplore.ieee.org/document/8613679/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROMAN.2002.1045641,Towards grounded human-robot communication,IEEE,Conferences,"Future robots are expected to communicate with humans using natural language. The naive human user will expect a robot to easily understand what he/she is meaning by instructions concerning robot's tasks. This implies that the robot will need to have a means of grounding, in its own sensors, the natural language terms and constructions used by the human user. This paper presents an approach to solve this problem that is based on the integration of a ""learning server"" in the software architecture of the robot. Such server should be capable of on-line, incremental learning from examples; it should handle multiple problems concurrently and it should have meta-learning capabilities. A learning server already developed by the authors is presented. Complementarily, the dimensionality reduction problem is also addressed, using a Blocked DCT approach. Experimental results are obtained in a scenario in which three concepts (corresponding to natural language expressions) are concurrently learned.",https://ieeexplore.ieee.org/document/1045641/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/IJCNN.2017.7966054,Towards real-time robot simulation on uneven terrain using neural networks,IEEE,Conferences,"Simulation is a valuable tool for robotics research and development, and various simulation packages have been proposed. However, we are aware of no freely-available packages which implement the required fidelity to accurately model earth-moving robots that manipulate the terrain itself. The software which does exist for this is difficult if not impossible to run in real-time while achieving the desired accuracy. This paper proposes a simulation system in which a neural network is trained using data generated in a 3D high-fidelity, non-real-time simulator. The resulting neural network is used to accurately predict the motion of a robot in a 2D simulator, while also taking into consideration a height-field representing a 3D terrain. Using a trained neural network to drive the new simulation provides considerable speedup over the high-fidelity 3D simulation, allowing behaviour to be simulated in real-time while still capturing the physics of the agents and the environment.",https://ieeexplore.ieee.org/document/7966054/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/SIPROCESS.2016.7888345,Towards robust ego-centric hand gesture analysis for robot control,IEEE,Conferences,"Wearable device with an ego-centric camera would be the next generation device for human-computer interaction such as robot control. Hand gesture is a natural way of ego-centric human-computer interaction. In this paper, we present an ego-centric multi-stage hand gesture analysis pipeline for robot control which works robustly in the unconstrained environment with varying luminance. In particular, we first propose an adaptive color and contour based hand segmentation method to segment hand region from the ego-centric viewpoint. We then propose a convex U-shaped curve detection algorithm to precisely detect positions of fingertips. And parallelly, we utilize the convolutional neural networks to recognize hand gestures. Based on these techniques, we combine most information of hand to control the robot and develop a hand gesture analysis system on an iPhone and a robot arm platform to validate its effectiveness. Experimental result demonstrates that our method works perfectly on controlling the robot arm by hand gesture in real time.",https://ieeexplore.ieee.org/document/7888345/,2016 IEEE International Conference on Signal and Image Processing (ICSIP),13-15 Aug. 2016,ieeexplore
10.1109/IJCNN.2008.4633874,Tracking a moving object with mobile robot based on vision,IEEE,Conferences,"The paper proposes a real-time tracking algorithm for a moving object with mobile robot based on vision using adaptive color matching and Kalman filter. The adaptive color matching can limit the region containing moving object on vision image plane. It can adjust color matching threshold to reduce the influence of lighting variations in the scene. Kalman filter is used as our prediction module to calculate motion vectors of moving object in the robot coordinate system. A view window containing the position of moving object estimated by Kalman filter is determined on image plane to reduce the image processing area. Color matching threshold can adjust itself adaptively in view window, which is used as an updating module. Experimental results show that the algorithm can adapt to lighting variations and has good tracking precision. It can also be implemented in real time.",https://ieeexplore.ieee.org/document/4633874/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ICCICT.2012.6398104,Tracking of a target person using face recognition by surveillance robot,IEEE,Conferences,"In this paper we designed an experimental setup in order to have human-robot interaction i.e. first we are going to detect the face and after that we recognise the detected face. Afterwards we get the persons upper body torso color as a key feature. As we extracted the color feature we can compute the moments and also evaluate the motion parameters so that the surveillance robot can track the person accordingly. We also had introduced Speech module in order to have a interaction between the remote and base station. Surveillance robot must track the targeted person in a robust manner in indoor and outdoor environment in different light and dynamic varying conditions. In our proposed setup we use PCA which is going to recognise the person in a real time environment and should communicate to the person via speech module deployed in the surveillance robot, as face recognition works on real time environment we are getting average recognition rate of 98%. Experiment demonstration validates the efficient performance of the approach.",https://ieeexplore.ieee.org/document/6398104/,"2012 International Conference on Communication, Information & Computing Technology (ICCICT)",19-20 Oct. 2012,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ROBOT.2010.5509160,Transfer of skills between human operators through haptic training with robot coordination,IEEE,Conferences,"In this paper, we discuss a coordinated haptic training architecture useful for transferring expertise in teleoperation-based manipulation between two human users. The objective is to construct a reality-based haptic interaction system for knowledge transfer by linking an expert's skill with robotic movement in real time. The benefits from this approach include 1) a representation of an expert's knowledge into a more compact and general form by learning from a minimized set of training samples, and 2) an increase in the capability of a novice user by coupling learned skills absorbed by a robotic system with haptic feedback. In order to evaluate our ideas and present the effectiveness of our paradigm, human handwriting is selected as our experiment of interest. For the learning algorithms, artificial neural network (ANN) and support vector machine (SVM) are utilized and their performances are compared. For the evaluation of the performance of the output of the learning modules, a modified Longest Common Subsequence (LCSS) algorithm is implemented. Results show that one or two experts' samples are sufficient for the generation of haptic training knowledge, which can successfully recreate manipulation motion with a robotic system and transfer haptic forces to an untrained user with a haptic device. Also in the case of handwriting comparison, the similarity measures result in up to an 88% match even with a minimized set of training samples.",https://ieeexplore.ieee.org/document/5509160/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ROBOT.1998.680515,Unsupervised learning to recognize environments from behavior sequences in a mobile robot,IEEE,Conferences,"We describe the development of a mobile robot which does unsupervised learning for recognizing environments from behavior sequences. Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may not be obtained in real environments. Furthermore unsupervised-learning is necessary for recognition in unknown environments without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in enclosures. Then the sequences of behaviors executed in each enclosure are transformed into input vectors for a self-organizing network. Learning without a teacher is done, and the robot becomes able to identify enclosures. Moreover we developed a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",https://ieeexplore.ieee.org/document/680515/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICEPDS.2018.8571820,Using Robot and Electric Drive in Fall Prediction,IEEE,Conferences,"The global aging phenomenon has motivated active research in human fall injuries. The fall prevention has hence become a popular topic in health informatics. An effective fall prevention paradigm could save millions of people from injury and avoid considerable casualties. Through comparison studies, detail-oriented simulations, and pragmatic field tests, an effective fall prediction method has been developed by authors. The finding is presented in this paper. Three techniques for fall prediction are discussed in this paper. A comparison technique to mimic the traditional stateless fall prediction techniques, along with an algorithm using artificial neural network, was first implemented in authors' previous paper. Then a robotic scheme was developed to simulate human fall by transplanting a proven fall prediction paradigm for humanoid robots with controlled electric drive systems to human subjects. Due to its simulation nature far from the human fall scenarios in reality, the robotic paradigm has obvious limits in real world applications. It was also used more like a reference framework for our last scheme. Eventually we built the third approach that eliminated the above limitation. The third approach is elaborated in this paper. Our test and simulation have proved its pragmatic superiority over other two approaches, along with vast majority of traditional paradigms.",https://ieeexplore.ieee.org/document/8571820/,2018 X International Conference on Electrical Power Drive Systems (ICEPDS),3-6 Oct. 2018,ieeexplore
10.1109/SPW50608.2020.00045,Using Taint Analysis and Reinforcement Learning (TARL) to Repair Autonomous Robot Software,IEEE,Conferences,"It is important to be able to establish formal performance bounds for autonomous systems. However, formal verification techniques require a model of the environment in which the system operates; a challenge for autonomous systems, especially those expected to operate over longer timescales. This paper describes work in progress to automate the monitor and repair of ROS-based autonomous robot software written for an apriori partially known and possibly incorrect environment model. A taint analysis method is used to automatically extract the dataflow sequence from input topic to publish topic, and instrument that code. A unique reinforcement learning approximation of MDP utility is calculated, an empirical and non-invasive characterization of the inherent objectives of the software designers. By comparing design (a-priori) utility with deploy (deployed system) utility, we show, using a small but real ROS example, that it's possible to monitor a performance criterion and relate violations of the criterion to parts of the software. The software is then patched using automated software repair techniques and evaluated against the original off-line utility.",https://ieeexplore.ieee.org/document/9283859/,2020 IEEE Security and Privacy Workshops (SPW),21-21 May 2020,ieeexplore
10.1109/HNICEM.2018.8666242,Utilization of Fuzzy Logic Control in a Waste Robot,IEEE,Conferences,"This research aimed to design and develop an autonomous robot to feasibly address waste disposal issues in common indoor places. The researchers explored opportunities to improve path planning using Fuzzy Logic Control (FLC). The researchers utilized a Microcontroller Unit (MCU) to control input proximity, sound, and infrared sensors, and output geared Direct Current (DC) motors through machine learning and electromechanical interface. The researchers simulated an adaptive algorithm using Mamdani-type FLC model, implemented using C programming language, then downloaded as machine code to a real prototype. Based on significant test results, the waste robot accurately detected human interference, a feature that would be pivotal in overcoming individual indifferences on waste management.",https://ieeexplore.ieee.org/document/8666242/,"2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)",29 Nov.-2 Dec. 2018,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/AQTR.2006.254650,Vision based algorithm for path planning of a mobile robot by using cellular neural networks,IEEE,Conferences,"The paper presents a new vision based algorithm for mobile robots path planning in an environment with obstacles. Cellular neural networks (CNNs) processing techniques are used here for real time motion planning to reach a fixed target. The CNN methods have been considered a solution for image processing in autonomous mobile robots guidance. The choice of CNNs for the visual processing is based on the possibility of their hardware implementation in large networks on a single VLSI chip (cellular neural networks -universal machine, CNN-UM (Roska and Chua, 1993 and Kim et al., 2002))",https://ieeexplore.ieee.org/document/4022973/,"2006 IEEE International Conference on Automation, Quality and Testing, Robotics",25-28 May 2006,ieeexplore
10.1109/ICMLC.2018.8526952,Vision-Based Line-Following Control of a Two-Wheel Self-Balancing Robot,IEEE,Conferences,"This paper presents a vision-based two-wheel self-balancing (TWSB) robot to follow a black line using visual feedback. We use MATLAB software to connect to the URL of IP camera and use image processing toolbox to process the image from the IP camera. After image processing, this paper sets 10 coordinates to detect if the black line is straight or the black line is in different kind of situation. This paper considers the black line including straight line, curve line, intersection and inconsecutive line. Thus, a cascade intelligent motion control system is proposed to control the balancing and moment of the vision-based TWSB robot with tracking the position and direction commands from MATLAB software. Finally, it shows that the vision-based TWSB robot can trace the black line on the map very well from the real-time experimental results.",https://ieeexplore.ieee.org/document/8526952/,2018 International Conference on Machine Learning and Cybernetics (ICMLC),15-18 July 2018,ieeexplore
10.1109/ICOVET50258.2020.9230275,Vision-Based Robot Hand Using Open Source Software,IEEE,Conferences,"The robot hand can plan grasp movements based on the position of the target object and the motion of the robot hand. The position of the target object is recognized from the image captured by a camera mounted on the robot arm, and the motion of the robot hand is estimated from the inertial measurement unit (IMU). We also adopt a variety of mechanisms to determine the target object among the objects detected in the camera scene. Experiments are conducted to verify the validity of control system. The experiments proved that the developed system can support the user to grasp the target object.",https://ieeexplore.ieee.org/document/9230275/,2020 4th International Conference on Vocational Education and Training (ICOVET),19-19 Sept. 2020,ieeexplore
10.1109/FSKD.2017.8393254,Visual control system design of wheeled inverted pendulum robot based on Beaglebone Black,IEEE,Conferences,"The wheeled inverted pendulum robot has broad prospects of applications in real life. It can use two coaxial wheels to achieve the body self-balancing, forward moving and turning. But the general wheeled inverted pendulum robot seldom has vision function to perceive enviromental change. In order to realize the robust visual control, a wheeled inverted-pendulum vision robot with attitude sensors, photoelectric encoders, ultrasonic sensors and so on is designed based on Beaglebone Black board. The moving object is separated in the space domain by obtaining the image sequence which is sent by a robot-mounted camera, and the modeling, identification and tracking of target sequence are implemented in the time domain. The balance PD, speed PI and steering PD controllers are designed to realize the dynamic balance, forward and steering function of the robot. To satisfy the functional requirements of the visual tracking system, an improved tracking-learning-detection algorithm based on kernelized correlation filtering is used, and a tracking anomaly based on spatial context is detected to determine the tracking state and reduce the error rate. Experimental results show that the robot reaches the requirement of design and achieves better visual control effectiveness.",https://ieeexplore.ieee.org/document/8393254/,"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)",29-31 July 2017,ieeexplore
10.1109/ICRoM.2014.6990935,Visual servoing control of robot manipulator with Jacobian matrix estimation,IEEE,Conferences,"Visual servoing system is a system to control a robot by visual feedback. This paper presents a visual servoing control that drives the end-effector of a real robot manipulator from any arbitrary start position to the desired positions. The control law is obtained using inverse Jacobian matrix. Since there is not access to the model of the robot, artificial neural networks are used to estimate of inverse Jacobian matrix. There are many challenges in practical implementation such as: how to calculate Jacobian matrix, determining the intelligent structure for estimation of Jacobian matrix, recognition coordinate of each joint with image processing and changes in illumination. We proposed appropriate solutions to solve the mentioned challenges. The experimental results in the real robot show that the control system can move the end-effector to target positions from any arbitrary start position with good accuracy.",https://ieeexplore.ieee.org/document/6990935/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/ICMLA.2006.53,Web Robot Learning Powered by Bluetooth Communication System,IEEE,Conferences,"This paper presents a web robot web-robot learning powered by Bluetooth communication system. The web-robot system is used as the virtual robot laboratory integrating a number of disciplines in engineering. This virtual laboratory is a valuable teaching tool for engineering education used at any time and from any location through Internet. The mobile robot was controlled with robot server named as control center. The server can be connected to mobile robot via Bluetooth adapter. The mobile robot system focuses on vision sensing. Real time image processing techniques are realized by the web robot system. This system can also realize monitoring, tele-controlling, parameter adjusting and reprogramming through Internet exclusively with a standard Web browser without the need of any additional software",https://ieeexplore.ieee.org/document/4041484/,2006 5th International Conference on Machine Learning and Applications (ICMLA'06),14-16 Dec. 2006,ieeexplore
10.1109/ICMLA.2007.19,Web-based maze robot learning using fuzzy motion control system,IEEE,Conferences,"In this study, a Web based maze robot system has been designed and implemented for solving different maze algorithms with the help of machine learning approaches. The robot system has a map-based heuristic maze solving algorithm. The algorithm used for solving the maze is based on map creation and produces a control signal for robot direction. Robot motions were controlled by a fuzzy motion control system running on a chip. The control algorithm can be easily changed with the help of an algorithm via web interface controlled by the control center. The control center program powered by MATLAB functions and special libraries (image and control) in DELPHI manage all robotic activities. These activities are: command interpreter, image capturing, processing and serving, machine learning techniques, Web serving, database management, communication with robot, and compiling microcontroller programs. The results have shown that the proposed, designed and implemented system provides amazing new features to the applicants doing their real-time programming exercises on Web.",https://ieeexplore.ieee.org/document/4457243/,Sixth International Conference on Machine Learning and Applications (ICMLA 2007),13-15 Dec. 2007,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/CBS.2018.8612261,sEMG-Based Torque Estimation Using Time-Delay ANN for Control of an Upper-Limb Rehabilitation Robot,IEEE,Conferences,"Robotic-assisted rehabilitation of the upper limb following neurological injury can achieve best possible functional recovery when patients are engaged in the therapy. However, implementation of active training is still difficult as it's challenging to detect human motion intention online and impose corresponding robot control. This paper introduces a novel upper-limb rehabilitation robot, and proposes a sEMG-driven (sEMG: surface Electromyography) torque estimation model based on artificial neural networks (ANN). The robot has three DOFs, of which the first two DOFs adopt a planar parallel structure, and the wrist module has an exoskeleton form. In this study, we design an impedance controller and an admittance controller for the first two DOFs and the wrist module, respectively. Specifically, for the first two DOFs, the assistance/resistance force at the end-effector was controlled according to its motions and desired interaction impedance; for the wrist module, an sEMG armband was used to collect 8 channels of sEMG signals from the forearm muscles, and a time-delay ANN model was developed to estimate the wrist pronation/supination torque, based on which the wrist rotation was controlled according to the human motion intention. To overcome the overfitting problem, besides the experimental samples of wrist rotation, both resting and co-contraction samples were collected for training. Finally, combining with the design of a virtual reality game and force fields, the proposed methods were implemented and tested experimentally on the upper-limb rehabilitation robot.",https://ieeexplore.ieee.org/document/8612261/,2018 IEEE International Conference on Cyborg and Bionic Systems (CBS),25-27 Oct. 2018,ieeexplore
10.1109/TSMCC.2004.840063,"""Sticky Hands"": learning and generalization for cooperative physical interactions with a humanoid robot",IEEE,Journals,"""Sticky Hands"" is a physical game for two people involving gentle contact with the hands. The aim is to develop relaxed and elegant motion together, achieve physical sensitivity-improving reactions, and experience an interaction at an intimate yet comfortable level for spiritual development and physical relaxation. We developed a control system for a humanoid robot allowing it to play Sticky Hands with a human partner. We present a real implementation including a physical system, robot control, and a motion learning algorithm based on a generalizable intelligent system capable itself of generalizing observed trajectories' translation, orientation, scale and velocity to new data, operating with scalable speed and storage efficiency bounds, and coping with contact trajectories that evolve over time. Our robot control is capable of physical cooperation in a force domain, using minimal sensor input. We analyze robot-human interaction and relate characteristics of our motion learning algorithm with recorded motion profiles. We discuss our results in the context of realistic motion generation and present a theoretical discussion of stylistic and affective motion generation based on, and motivating cross-disciplinary research in computer graphics, human motion production and motion perception.",https://ieeexplore.ieee.org/document/1522534/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",Nov. 2005,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/ACCESS.2020.3042439,A Fuzzy Ensemble Method With Deep Learning for Multi-Robot System,IEEE,Journals,"In a multi-robot system, situation assessment evaluates the current situation quantitatively to help decision-makers make the best decision. Conventional situation assessment methods ignore the initiative of each robot, so it often encounters bottlenecks. Collaborative intelligence shows better performance than a single global decision. To address this problem, this work introduces a deep learning-based fuzzy adaptive method (DLFA) to achieve the real-time situation assessment for a multi-robot system. The proposed method employs the shortest path faster algorithm to achieve information sharing between agents. The shortest path faster algorithm ensures that the agent distributes its state information to its teammates in the fastest way. Each agent gets the information from teammates and treats their state as the observation of the scene. Deep neural network maps current observations into a local situation assessment result by combining a large number of nonlinear processing layers. Finally, each local assessment result is regarded as a brick to construct the final situation assessment via a fuzzy ensemble method. Experimental results show that the proposed method outperforms competitors.",https://ieeexplore.ieee.org/document/9279196/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2021.3091642,A Human-Robot Interaction System Calculating Visual Focus of Human’s Attention Level,IEEE,Journals,"Attention is the mental awareness of human on a particular object or a piece of information. The level of attention indicates how intense the focus is on an object or an instance. In this study, several types of human attention level have been observed. After introducing image segmentation and detection technique for facial features, eyeball movement and gaze estimation were measured. Eye movement were assessed using the video data, and a total of 10197 data instances were manually labelled for the attention level. Then Artificial Neural Network (ANN) and Recurrent Neural Network-Long Short Term Memory (LSTM) based Deep learning (DL) architectures have been proposed for analysing the data. Next, the trained DL model has been implanted into a robotic system that is capable of detecting various features; ultimately leading to the calculation of visual attention for reading, browsing, and writing purposes. This system is capable of checking the attention level of the participants and also can detect if participants are present or not. Based on a certain level of visual focus of attention (VFOA), this system interacts with the person, generates awareness and establishes verbal or visual communication with that person. The proposed ML techniques have achieved almost 99.24% validation accuracy and 99.43% test accuracy. It is also shown in the comparative study that, since the dataset volumes are limited, ANN is more suitable for attention level calculation than RNN-LSTM. We hope that the implemented robotic structure manifests the real-world implication of the proposed method.",https://ieeexplore.ieee.org/document/9462086/,IEEE Access,2021,ieeexplore
10.1109/TAMD.2011.2164404,A Multiple Context Brain for Experiments With Robot Consciousness,IEEE,Journals,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",https://ieeexplore.ieee.org/document/5986693/,IEEE Transactions on Autonomous Mental Development,Dec. 2011,ieeexplore
10.1109/TSMC.2013.2297398,A Multiple-Feature and Multiple-Kernel Scene Segmentation Algorithm for Humanoid Robot,IEEE,Journals,"This paper presents a multiple-feature and multiple-kernel support vector machine (MFMK-SVM) methodology to achieve a more reliable and robust segmentation performance for humanoid robot. The pixel wise intensity, gradient, and C1 SMF features are extracted via the local homogeneity model and Gabor filter, which would be used as inputs of MFMK-SVM model. It may provide multiple features of the samples for easier implementation and efficient computation of MFMK-SVM model. A new clustering method, which is called feature validity-interval type-2 fuzzy C-means (FV-IT2FCM) clustering algorithm, is proposed by integrating a type-2 fuzzy criterion in the clustering optimization process to improve the robustness and reliability of clustering results by the iterative optimization. Furthermore, the clustering validity is employed to select the training samples for the learning of the MFMKSVM model. The MFMK-SVM scene segmentation method is able to fully take advantage of the multiple features of scene image and the ability of multiple kernels. Experiments on the BSDS dataset and real natural socene images demonstrate the superior performance of our proposed method.",https://ieeexplore.ieee.org/document/6717184/,IEEE Transactions on Cybernetics,Nov. 2014,ieeexplore
10.1109/TSMC.2019.2956321,A Novel Approach to Image-Sequence-Based Mobile Robot Place Recognition,IEEE,Journals,"Visual place recognition is a challenging problem in simultaneous localization and mapping (SLAM) due to a large variability of the scene appearance. A place is usually described by a single-frame image in conventional place recognition algorithms. However, it is unlikely to completely describe the place appearance using a single frame image. Moreover, it is more sensitive to the change of environments. In this article, a novel image-sequence-based framework for place detection and recognition is proposed. Rather than a single frame image, a place is represented by an image sequence in this article. Position invariant robust feature (PIRF) descriptors are extracted from images and processed by the incremental bag-of-words (BoWs) for feature extraction. The robot automatically partitions the sequentially acquired images into different image sequences according to the change of the environmental appearance. Then, the echo state network (ESN) is applied to model each image sequence. The resultant states of the ESN are used as features of the corresponding image sequence for place recognition. The proposed method is evaluated on two public datasets. Experimental comparisons with the FAB-MAP 2.0 and SeqSLAM are conducted. Finally, a real-world experiment on place recognition with a mobile robot is performed to further verify the proposed method.",https://ieeexplore.ieee.org/document/8931657/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Sept. 2021,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/JSEN.2020.3042665,A Searching Space Constrained Partial to Full Registration Approach With Applications in Airport Trolley Deployment Robot,IEEE,Journals,"For airports with high passenger and luggage flows, a large number of staff members have to be hired to deploy the scattered passenger luggage trolleys. To release humans from the repetitive and laborious job, we develop an autonomous trolley deployment robot to detect, transport and collect the scattered idle trolleys to recycling points. This paper will firstly illustrate the entire collection pipeline of the deployment robot system and then address the key challenge: partial to full point set registration. With the perception framework, the robot can detect the idle trolleys and acquire the pose of the trolleys on the ground, and then capture the trolley from behind, along the same direction for subsequent grasping and manipulation. With RGB-D camera and a segmentation Convolutional Neural Network, the robot can generate a partial surface point cloud of the detected trolley. The resulting point cloud, data and a pre-scanned full trolley point cloud, model, are matched by an implicit pose. To tackle the low accuracy and long computation time issues, a novel searching space-constrained point set registration algorithm is proposed to register the two overlapping point sets. Based on Branch-and-Bound (BnB) mechanism, the error between data and model is iteratively optimized. The constraint of searching space speeds up the global searching of the optimal pose, by pruning the candidate spaces which is impossible to contain the optimal result. To evaluate the performance, an airport trolley segmentation dataset and a point cloud dataset for registration are constructed. Experimental results on the datasets and synthetic dataset show that our method achieves higher accuracy and success rate than the previous methods. The experiments demonstrated in video clips validate the developed system works in real-world applications.",https://ieeexplore.ieee.org/document/9281085/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/JPROC.2018.2840045,A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm,IEEE,Journals,"In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare.",https://ieeexplore.ieee.org/document/8500162/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/TITB.2004.840062,A tele-operated mobile ultrasound scanner using a light-weight robot,IEEE,Journals,"This paper presents a new tele-operated robotic chain for real-time ultrasound image acquisition and medical diagnosis. This system has been developed in the frame of the Mobile Tele-Echography Using an Ultralight Robot European Project. A light-weight six degrees-of-freedom serial robot, with a remote center of motion, has been specially designed for this application. It holds and moves a real probe on a distant patient according to the expert gesture and permits an image acquisition using a standard ultrasound device. The combination of mechanical structure choice for the robot and dedicated control law, particularly nearby the singular configuration allows a good path following and a robotized gesture accuracy. The choice of compression techniques for image transmission enables a compromise between flow and quality. These combined approaches, for robotics and image processing, enable the medical specialist to better control the remote ultrasound probe holder system and to receive stable and good quality ultrasound images to make a diagnosis via any type of communication link from terrestrial to satellite. Clinical tests have been performed since April 2003. They used both satellite or Integrated Services Digital Network lines with a theoretical bandwidth of 384 Kb/s. They showed the tele-echography system helped to identify 66% of lesions and 83% of symptomatic pathologies.",https://ieeexplore.ieee.org/document/1402447/,IEEE Transactions on Information Technology in Biomedicine,March 2005,ieeexplore
10.1109/TNSRE.2020.3038175,AI Therapist Realizing Expert Verbal Cues for Effective Robot-Assisted Gait Training,IEEE,Journals,"Repetitive and specific verbal cues by a therapist are essential in aiding a patient's motivation and improving the motor learning process. The verbal cues comprise various expressions, sentences, volumes, and timings, depending on the therapist's proficiency. This paper proposes an AI therapist (AI-T) that implements the verbal cues of professional therapists having extensive experience with robot-assisted gait training using the SUBAR for stroke patients. The AI-T was developed using a neuro-fuzzy system, a machine learning technique leveraging the benefits of fuzzy logic and artificial neural networks. The AI-T was trained with the professional therapist's verbal cue data, as well as clinical and robotic data collected from robot-assisted gait training with real stroke patients. Ten clinical data and 16 robotic data are input variables, and six verbal cues are output variables. Fifty-eight stroke patients wore the SUBAR, a gait training robot, and participated in the robot-assisted gait training. A total of 9059 verbal cue data, 580 clinical data of stroke patients, and 144 944 robotic data were collected from 693 training sessions. Test results show that the trained AI-T can implement six types of verbal cues with 93.7% accuracy for the 1812 verbal cue data of the professional therapist. Currently, the trained AI-T is deployed in the SUBAR and provides six verbal cues to stroke patients in robot-assisted gait training.",https://ieeexplore.ieee.org/document/9260225/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1109/TCST.2012.2191969,Adaptive PD Controller Modeled via Support Vector Regression for a Biped Robot,IEEE,Journals,"The real-time balance control of an eight link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, an intelligent computing control technique is used. This technique is based on support vector regression (SVR). The method uses the ZMP error and its variation as inputs, and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR is trained based on simulation data and their performance is verified with a real biped robot. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that is acquired and adapted to the robot's size. Some experiments are presented, and the results show that the implemented gait combined with the SVR controller can be used to control this biped robot. The SVR controller performs the control in 0.2 ms.",https://ieeexplore.ieee.org/document/6180212/,IEEE Transactions on Control Systems Technology,May 2013,ieeexplore
10.1109/JIOT.2020.2979413,Adversarial Learning-Enabled Automatic WiFi Indoor Radio Map Construction and Adaptation With Mobile Robot,IEEE,Journals,"Location-based service (LBS) has become an indispensable part of our daily lives. Realizing accurate LBS in indoor environments is still a challenging task. WiFi fingerprinting-based indoor positioning system (IPS) has achieved encouraging results recently, but the time and labor overhead of constructing a dense WiFi radio map remains the key bottleneck that hinders it for real-world large-scale implementation. In this article, we propose WiGAN an automatic fine-grained indoor ratio map construction and the adaptation scheme empowered by the Gaussian process regression conditioned least-squares generative adversarial networks (GPR-GANs) with a mobile robot. First, we develop a mobile robotic platform that constructs the spatial map and radio map simultaneously in the easily accessed free space. GPR-GAN first establishes a Gaussian process regression (GPR) model using the real received signal strength (RSS) measurements collected by our robotic platform via LiDAR SLAM in the free space. Then, the outputs of the GPR are adopted as the input of GAN's generator. The learning objective of GAN is to synthesize realistic RSS data in a constrained space where it has not been covered and model the irregular RSS distributions in complex indoor environments. Real-world experiments were conducted in a real-world indoor environment, which confirms the feasibility, high accuracy, and superiority of WiGAN over existing solutions in terms of both RSS estimation accuracy and localization accuracy.",https://ieeexplore.ieee.org/document/9031749/,IEEE Internet of Things Journal,Aug. 2020,ieeexplore
10.1109/21.3461,An approach to an expert robot welding system,IEEE,Journals,"Adaptive control and sensory processing techniques in robotic arc welding are discussed. The gas metal arc welding and gas tungsten arc welding processes are considered, along with a literature review of aspects of welding automation. Topics covered include process modeling, detection and measurement of process features, real-time control, and implementation considerations. An approach for an adaptive welding system is presented. The proposed architecture fits within the scope of an ambitious project to develop an expert welding robot. Different levels of automation are discussed, from the decision level to the closed-loop control of process variables and torch trajectory.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/3461/,"IEEE Transactions on Systems, Man, and Cybernetics",March-April 1988,ieeexplore
10.1109/ACCESS.2021.3079427,Autonomous Endoscope Robot Positioning Using Instrument Segmentation With Virtual Reality Visualization,IEEE,Journals,"This paper presents a method for endoscope's autonomous positioning by a robotic endoscope holder for minimally invasive surgery. The method improves human-robot cooperation in robot-assisted surgery by allowing the endoscope holder to acknowledge the surgeon's view projection and navigate the camera without manual control. The real-time prediction of next desired camera location is estimated using segmented instrument's tip locations from endoscope video and surgeon's attention focus given by tracked virtual reality headset. To tackle the issue of real-time surgical instrument segmentation for more precise instrument tip localization, we propose the YOLOv3 and ResNet Combined Neural Network. The method showed an 86.6% IoU across MICCAI'17 Endovis datasets with 30 frames per second processing speed. The proposed pipeline was implemented in ROS on Ubuntu with visualization running under Windows operating system in Unity3D. The simulation demonstrates the robotic arm, endoscope, and surgical environment visualized in 3D in the virtual reality headset to provide a stable view of the endoscope and improve the surgeon's perception of the operating environment.",https://ieeexplore.ieee.org/document/9429186/,IEEE Access,2021,ieeexplore
10.1109/TSMCA.2003.811766,Autonomous fuzzy parking control of a car-like mobile robot,IEEE,Journals,"This paper is devoted to design and implement a car-like mobile robot (CLMR) that possesses autonomous garage-parking and parallel-parking capability by using real-time image processing. For fuzzy garage-parking control (FGPC) and fuzzy parallel-parking control (FPPC), feasible reference trajectories are provided for the fuzzy logic controller to maneuver the steering angle of the CLMR. We propose two FGPC methods and two FPPC methods to back-drive or head-in the CLMR to the garage and the parking lot, respectively. Simulation results illustrate the effectiveness of the developed schemes. The overall experimental setup of the parking system developed in this paper is composed of a host computer, a communication module, a CLMR, and a vision system. Finally, the image-based real-time implementation experiments of the CLMR demonstrate the feasibility and effectiveness of the proposed schemes.",https://ieeexplore.ieee.org/document/1235979/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/ACCESS.2021.3093340,Ball Motion Control in the Table Tennis Robot System Using Time-Series Deep Reinforcement Learning,IEEE,Journals,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball’s accurate motion control, which depends on various factors such as the incoming ball’s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball’s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball’s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable “target landing location” and the “over-net height” which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70%.",https://ieeexplore.ieee.org/document/9467347/,IEEE Access,2021,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TSMCB.2009.2018138,Cerebellar-Inspired Adaptive Control of a Robot Eye Actuated by Pneumatic Artificial Muscles,IEEE,Journals,"In this paper, a model of cerebellar function is implemented and evaluated in the control of a robot eye actuated by pneumatic artificial muscles. The investigated control problem is stabilization of the visual image in response to disturbances. This is analogous to the vestibuloocular reflex (VOR) in humans. The cerebellar model is structurally based on the adaptive filter, and the learning rule is computationally analogous to least-mean squares, where parameter adaptation at the parallel fiber/Purkinje cell synapse is driven by the correlation of the sensory error signal (carried by the climbing fiber) and the motor command signal. Convergence of the algorithm is first analyzed in simulation on a model of the robot and then tested online in both one and two degrees of freedom. The results show that this model of neural function successfully works on a real-world problem, providing empirical evidence for validating: 1) the generic cerebellar learning algorithm; 2) the function of the cerebellum in the VOR; and 3) the signal transmission between functional neural components of the VOR.",https://ieeexplore.ieee.org/document/4814555/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Dec. 2009,ieeexplore
10.1109/TSMCB.2006.874131,Control Architecture for Human–Robot Integration: Application to a Robotic Wheelchair,IEEE,Journals,"Completely autonomous performance of a mobile robot within noncontrolled and dynamic environments is not possible yet due to different reasons including environment uncertainty, sensor/software robustness, limited robotic abilities, etc. But in assistant applications in which a human is always present, she/he can make up for the lack of robot autonomy by helping it when needed. In this paper, the authors propose human-robot integration as a mechanism to augment/improve the robot autonomy in daily scenarios. Through the human-robot-integration concept, the authors take a further step in the typical human-robot relation, since they consider her/him as a constituent part of the human-robot system, which takes full advantage of the sum of their abilities. In order to materialize this human integration into the system, they present a control architecture, called architecture for human-robot integration, which enables her/him from a high decisional level, i.e., deliberating a plan, to a physical low level, i.e., opening a door. The presented control architecture has been implemented to test the human-robot integration on a real robotic application. In particular, several real experiences have been conducted on a robotic wheelchair aimed to provide mobility to elderly people",https://ieeexplore.ieee.org/document/1703648/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2006,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3033550,Developing a Lightweight Rock-Paper-Scissors Framework for Human-Robot Collaborative Gaming,IEEE,Journals,"We present a novel implementation of a Rock-Paper-Scissors (RPS) game interaction with a social robot. The framework is tailored to be computationally lightweight, as well as entertaining and visually appealing through collaboration with designers and animators. The fundamental gesture recognition pipeline employs a Leap motion device and two separate machine learning architectures to evaluate kinematic hand data on-the-fly. The first architecture is used to recognize and segment human motion activity in order to initialize the RPS play, and the second architecture is used to classify hand gestures into rock, paper or scissors. The employed tabletop robot interacts in the RPS play through unique animated gestural movements and vocalizations designed by animators which communicate the robot's choices as well as cognitive reflection on winning, losing and draw states. Performance of both learning architectures is carefully evaluated with respect to accuracy, reliability and run time performance under different feature and classifier types. Moreover, we assess our system during an interactive RPS play between robot and human. Experimental results show that the proposed system is robust to user variations and play style in real environment conditions. As such, it offers a powerful application for the subsequent exploration of social human-machine interaction.",https://ieeexplore.ieee.org/document/9239276/,IEEE Access,2020,ieeexplore
10.1109/3516.537045,Development and integration of generic components for a teachable vision-based mobile robot,IEEE,Journals,"This paper presents a mobile robotic system for human assistance in navigation-the robot navigates by receiving visual instructions from a human being and is able to replicate them autonomously. We describe three generic components defined as the HOST, the VISION, and the CONTROL components as well as their integration in our teachable mobile robot. These components are connected to each other via a transputer serial link, namely they are loosely coupled, they work in parallel and are asynchronous with each other. Each component is described with a peculiar feature of extensibility. Especially in the VISION component, there are two major features. The first one is a correlator which each vision board possesses. The correlator does block-matching between the template and the grabbed images in real-time. The other is the PIM library which manages the visual tasks over limited parallel visual resources of the mobile robot. These features of our design enable the system to be real-time and allow for efficient and extensible software development. In order to show the feasibility of our system design, we present a preliminary experiment of the route teaching on our mobile robot.",https://ieeexplore.ieee.org/document/537045/,IEEE/ASME Transactions on Mechatronics,Sept. 1996,ieeexplore
10.1109/TMECH.2013.2294180,Development of a Laser-Range-Finder-Based Human Tracking and Control Algorithm for a Marathoner Service Robot,IEEE,Journals,"This paper presents a human detection algorithm and an obstacle avoidance algorithm for a marathoner service robot (MSR) that provides a service to a marathoner while training. To be used as a MSR, the mobile robot should have the abilities to follow a running human and avoid dynamically moving obstacles in an unstructured outdoor environment. To detect a human by a laser range finder (LRF), we defined features of the human body in LRF data and employed a support vector data description method. In order to avoid moving obstacles while tracking a running person, we defined a weighted radius for each obstacle using the relative velocity between the robot and an obstacle. For smoothly bypassing obstacles without collision, a dynamic obstacle avoidance algorithm for the MSR is implemented, which directly employed a real-time position vector between the robot and the shortest path around the obstacle. We verified the feasibility of these proposed algorithms through experimentation in different outdoor environments.",https://ieeexplore.ieee.org/document/6690173/,IEEE/ASME Transactions on Mechatronics,Dec. 2014,ieeexplore
10.1109/TNNLS.2018.2830119,Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source Localization,IEEE,Journals,"Inspired by the behavior of humans talking in noisy environments, we propose an embodied embedded cognition approach to improve automatic speech recognition (ASR) systems for robots in challenging environments, such as with ego noise, using binaural sound source localization (SSL). The approach is verified by measuring the impact of SSL with a humanoid robot head on the performance of an ASR system. More specifically, a robot orients itself toward the angle where the signal-to-noise ratio (SNR) of speech is maximized for one microphone before doing an ASR task. First, a spiking neural network inspired by the midbrain auditory system based on our previous work is applied to calculate the sound signal angle. Then, a feedforward neural network is used to handle high levels of ego noise and reverberation in the signal. Finally, the sound signal is fed into an ASR system. For ASR, we use a system developed by our group and compare its performance with and without the support from SSL. We test our SSL and ASR systems on two humanoid platforms with different structural and material properties. With our approach we halve the sentence error rate with respect to the common downmixing of both channels. Surprisingly, the ASR performance is more than two times better when the angle between the humanoid head and the sound source allows sound waves to be reflected most intensely from the pinna to the ear microphone, rather than when sound waves arrive perpendicularly to the membrane.",https://ieeexplore.ieee.org/document/8371531/,IEEE Transactions on Neural Networks and Learning Systems,Jan. 2019,ieeexplore
10.1109/70.650165,Environment prediction for a mobile robot in a dynamic environment,IEEE,Journals,"The problem of navigating a mobile robot among moving obstacles is usually solved on the condition of knowing the velocity of obstacles. However, it is difficult to provide such information to a robot in real time. In this paper, we present an environment predictor that provides an estimate of future environment configuration by fusing multisensor data in real time. The predictor is implemented by an artificial neural network (ANN) trained using a relative-error-backpropagation (REBP) algorithm. The REBP algorithm enables the ANN to provide output data with a minimum relative error, which is better than conventional backpropagation (BP) algorithms in this prediction application. The mobile robot can, therefore, respond to anticipated changes in the environment. The performance is verified by prediction simulation and navigation experiments.",https://ieeexplore.ieee.org/document/650165/,IEEE Transactions on Robotics and Automation,Dec. 1997,ieeexplore
10.1109/TSMCB.2010.2073702,Experimental Analysis of Mobile-Robot Teleoperation via Shared Impedance Control,IEEE,Journals,"In this paper, Internet-based teleoperation of mobile robots for obstacle avoidance is analyzed. A shared impedance-control scheme is presented, and the results of an experimental study for the evaluation of the effects of different teleoperation parameters are reported. In the experimental study, the effects of time delay, operator training, image-display alternatives (virtual model versus real images), viewpoint, and force-reflection method were studied. For this purpose, several hypotheses were formulated and tested through the experiments using the introduced quantitative and qualitative measures. A fuzzy force-reflection controller is also proposed as an alternative force-reflection technique, and its performance is compared with a conventional proportional-derivative-type force-reflection method. The experimental scheme was implemented using MATLAB XPC Target and Simulink. The results could serve as guidelines in the design of teleoperation systems for obstacle avoidance and could also provide directions for further investigations.",https://ieeexplore.ieee.org/document/5598539/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2011,ieeexplore
10.1109/LRA.2020.2979656,Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion,IEEE,Journals,"Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",https://ieeexplore.ieee.org/document/9028178/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TOH.2020.3029043,Human-Inspired Haptic Perception and Control in Robot-Assisted Milling Surgery,IEEE,Journals,"Bone milling is one of the most widely used and high-risk procedures in various types of surgeries, and it is important to be noted that the experienced surgeon can perform such an operation safely. The objective of this article is to enhance the safety of the robot-assisted milling operation with the inspiration of human haptic perception. The emergence, coding and perception of the human haptic are introduced. Following this, a single axis accelerometer that measures the vibration of the surgical power tool is mounted in the robot arm, and the recorded acceleration signal is encoded as parallel stream of binary data. The data are subsequently inputted to the Hopfield network so as to identify the milling state. Inspired by human inference procedure, the fuzzy logic controller is introduced to control the robot to track the desired state when performing bone milling operations. A real-time implementation of the proposed method on a digital signal processing is also described. The experimental results in milling porcine spines prove that the robot accurately discriminates different milling states even when the additive noise is serious, and the safe motion control of the robot is also realized.",https://ieeexplore.ieee.org/document/9220848/,IEEE Transactions on Haptics,1 April-June 2021,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TMECH.2013.2245337,Image-Based Visual Servoing of a 7-DOF Robot Manipulator Using an Adaptive Distributed Fuzzy PD Controller,IEEE,Journals,"This paper is concerned with the design and implementation of a distributed proportional-derivative (PD) controller of a 7-degrees of freedom (DOF) robot manipulator using the Takagi-Sugeno (T-S) fuzzy framework. Existing machine learning approaches to visual servoing involve system identification of image and kinematic Jacobians. In contrast, the proposed approach actuates a control signal primarily as a function of the error and derivative of the error in the desired visual feature space. This approach leads to a significant reduction in the computational burden as compared to model-based approaches, as well as existing learning approaches to model inverse kinematics. The simplicity of the controller structure will make it attractive in industrial implementations where PD/PID type schemes are in common use. While the initial values of PD gain are learned with the help of model-based controller, an online adaptation scheme has been proposed that is capable of compensating for local uncertainties associated with the system and its environment. Rigorous experiments have been performed to show that visual servoing tasks such as reaching a static target and tracking of a moving target can be achieved using the proposed distributed PD controller. It is shown that the proposed adaptive scheme can dynamically tune the controller parameters during visual servoing, so as to improve its initial performance based on parameters obtained while mimicking the model-based controller. The proposed control scheme is applied and assessed in real-time experiments using an uncalibrated eye-in-hand robotic system with a 7-DOF PowerCube robot manipulator.",https://ieeexplore.ieee.org/document/6471828/,IEEE/ASME Transactions on Mechatronics,April 2014,ieeexplore
10.1109/ACCESS.2021.3057808,Intuitive Robot Teleoperation Through Multi-Sensor Informed Mixed Reality Visual Aids,IEEE,Journals,"Mobile robotic systems have evolved to include sensors capable of truthfully describing robot status and operating environment as accurately and reliably as never before. This possibility is challenged by effective sensor data exploitation, because of the cognitive load an operator is exposed to, due to the large amount of data and time-dependency constraints. This paper addresses this challenge in remote-vehicle teleoperation by proposing an intuitive way to present sensor data to users by means of using mixed reality and visual aids within the user interface. We propose a method for organizing information presentation and a set of visual aids to facilitate visual communication of data in teleoperation control panels. The resulting sensor-information presentation appears coherent and intuitive, making it easier for an operator to catch and comprehend information meaning. This increases situational awareness and speeds up decision-making. Our method is implemented on a real mobile robotic system operating outdoor equipped with on-board internal and external sensors, GPS, and a reconstructed 3D graphical model provided by an assistant drone. Experimentation verified feasibility while intuitive and comprehensive visual communication was confirmed through an assessment, which encourages further developments.",https://ieeexplore.ieee.org/document/9349454/,IEEE Access,2021,ieeexplore
10.1109/3468.952717,Learning and communication via imitation: an autonomous robot perspective,IEEE,Journals,"This paper proposes a neural network architecture designed to exhibit learning and communication capabilities via imitation. Our architecture allows a ""protoimitation"" behavior using the ""perception ambiguity"" inherent in real environments. In the perspective of turn-taking and gestural communication between two agents, new experiments on movement synchronization in an interaction game are presented. Synchronization is obtained as a global attractor depending on the coupling between agents' dynamics. We also discuss the unsupervised context of the imitation process and present new experiments in which the same architecture is able to learn perception-action associations without any explicit reinforcement. The learning is based on the ability to detect novelty or irregularities in the communication rhythm.",https://ieeexplore.ieee.org/document/952717/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",Sept. 2001,ieeexplore
10.1109/TASE.2017.2783342,MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration,IEEE,Journals,"Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to task efficiently. The biggest bottleneck here is the tedious programming, which also has high prerequisites for most practitioners in manufacturing. This situation motivates the development of a PBD system that can understand the assembly skills performed by the human experts in the demonstration and accordingly generate the program for robot's execution of the taught task. In this paper, we present a skill decoding system to parse the observational raw demonstration into symbolic sequences, which is the crucial bridge to enable the automatic programming. The system achieves high performance in recognition and is tailored for the PBD in assembly tasks by considering both advantages and disadvantages in the background of assembly, such as controllable environment and limited computational resources. It is particularly useful for assembly tasks with modularized actions based on a set of standard parts. At the perspective of industrial application, the PBD upon the proposed system is a promising solution to improve the flexibility of manufacture, which is expected to be true in midterm but an important step toward this goal.",https://ieeexplore.ieee.org/document/8263146/,IEEE Transactions on Automation Science and Engineering,Oct. 2018,ieeexplore
10.1109/TCYB.2017.2718037,Multiobjective Evolution of Biped Robot Gaits Using Advanced Continuous Ant-Colony Optimized Recurrent Neural Networks,IEEE,Journals,"This paper proposes the optimization of a fully connected recurrent neural network (FCRNN) using advanced multiobjective continuous ant colony optimization (AMO-CACO) for the multiobjective gait generation of a biped robot (the NAO). The FCRNN functions as a central pattern generator and is optimized to generate angles of the hip roll and pitch, the knee pitch, and the ankle pitch and roll. The performance of the FCRNN-generated gait is evaluated according to the walking speed, trajectory straightness, oscillations of the body in the pitch and yaw directions, and walking posture, subject to the basic constraints that the robot cannot fall down and must walk forward. This paper formulates this gait generation task as a constrained multiobjective optimization problem and solves this problem through an AMO-CACO-based evolutionary learning approach. The AMO-CACO finds Pareto optimal solutions through ant-path selection and sampling operations by introducing an accumulated rank for the solutions in each single-objective function into solution sorting to improve learning performance. Simulations are conducted to verify the AMO-CACO-based FCRNN gait generation performance through comparisons with different multiobjective optimization algorithms. Selected software-designed Pareto optimal FCRNNs are then applied to control the gait of a real NAO robot.",https://ieeexplore.ieee.org/document/7964700/,IEEE Transactions on Cybernetics,June 2018,ieeexplore
10.1109/TIE.2005.847576,Obstacle avoidance of a mobile robot using hybrid learning approach,IEEE,Journals,"in this paper, a hybrid learning approach for obstacle avoidance of a mobile robot is presented. the key features of the approach are, firstly, innate hardwired behaviors which are used to bootstrap learning in the mobile robot system. a neuro-fuzzy controller is developed from a pre-wired or innate controller based on supervised learning in a simulation environment. the fuzzy inference system has been constructed based on the generalized dynamic fuzzy neural networks learning algorithm of Wu and Er, whereby structure and parameters identification are carried out automatically and simultaneously. Secondly, the neuro-fuzzy controller is capable of re-adapting in a new environment. After carrying out the learning phase on a simulated robot, the controller is implemented on a real robot. A reinforcement learning method based on the fuzzy actor-critic learning algorithm is employed so that the system can re-adapt to a new environment without human intervention. In this phase, the structure of the fuzzy inference system and the parameters of the antecedent parts of fuzzy rules are frozen, and reinforcement learning is applied to further tune the parameters in the consequent parts of the fuzzy rules. Through the hybrid learning approach, an efficient and compact neuro-fuzzy system is generated for obstacle avoidance of a mobile robot in the real world.",https://ieeexplore.ieee.org/document/1435700/,IEEE Transactions on Industrial Electronics,June 2005,ieeexplore
10.1109/56.812,On terrain acquisition by a point robot amidst polyhedral obstacles,IEEE,Journals,"The authors consider the problem of terrain model acquisition by a roving point placed in an unknown terrain populated by stationary polyhedral obstacles in two/three dimensions. The motivation for this problem is that after the terrain model is completely acquired, navigation from a source point to a destination point can be achieved along the collision-free paths. This can be done without the usage of sensors by applying the existing techniques for the find-path problem. In the paper, the point robot autonomous machine (PRAM) is used as a simplified abstract model for real-life roving robots. An algorithm is presented that enables PRAM to autonomously acquire the model of an unexplored obstacle terrain composed of an unknown number of polyhedral obstacles in two/three dimensions. In this method, PRAM undertakes a systematic exploration of the obstacle terrain with its sensor that detects all the edges and vertices visible from the present location, and builds the complete obstacle terrain model.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/812/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/ACCESS.2020.3048877,"Online Measuring of Robot Positions Using Inertial Measurement Units, Sensor Fusion and Artificial Intelligence",IEEE,Journals,"This research introduces a new method to estimate the position of a robot's Tool Center Point (TCP) using Inertial Measurement Units (IMUs), sensor fusion and Artificial Neural Networks (ANNs). The objective is to make an accurate estimate of TCP navigation, using the signals from an IMU as resources of a neural network capable of predicting the position. Considering that the IMU sensors suffer noise in the measurements and the noise progresses over time, this proposal employs a technique that eliminates the filtering step, and the process is done internally by the network. The work employs a non-parametric approach to reset the reference dynamically, minimize noise from sensors, and converge positioning to a nominal result. This method offers a solution for fast, cheap, and efficient robot calibration. The work does not want to replace current techniques but to introduce a new design to the literature. The concept does not require sophisticated mechanical parts and the production line to be idle during the calibration process, and the results show that the developed technique can accurately predict the TCP position with millimeter errors and in real-time. The study also implemented the concept with other neural networks, for which it used a smaller set of data in an attempt to reduce training time. The research used the Multilayer Perceptron and XGBRegressor networks to test the approach introduced with others algorithms. Different applications that need real-time positioning can benefit from the proposal.",https://ieeexplore.ieee.org/document/9312193/,IEEE Access,2021,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/TCSI.2004.827654,Reaction-diffusion navigation robot control: from chemical to VLSI analogic processors,IEEE,Journals,"We introduce a new methodology and experimental implementations for real-time wave-based robot navigation in a complex, dynamically changing environment. The main idea behind the approach is to consider the robot arena as an excitable medium, in which moving objects-obstacles and the target-are represented by sites of autowave generation: the target generates attractive waves, while the obstacles repulsive ones. The moving robot detects traveling and colliding wave fronts and uses the information about dynamics of the autowaves to adapt its direction of collision-free motion toward the target. This approach allows us to achieve a highly adaptive robot behavior and thus an optimal path along which the robot reaches the target while avoiding obstacles. At the computational and experimental levels, we adopt principles of computation in reaction-diffusion (RD) nonlinear active media. Nonlinear media where autowaves are used for information processing purposes can therefore be considered as RD computing devices. In this paper, we design and experiment with three types of RD processors: experimental and computational Belousov-Zhabotinsky chemical processor, computational CNN processor, and experimental RD-CNN very large-scale integration chip-the complex analog and logic computing engine (CACE1k). We demonstrate how to experimentally implement robot navigation using space-time snapshots of active chemical medium and how to overcome low-speed limitation of this ""wetware"" implementation in CNN-based silicon processors.",https://ieeexplore.ieee.org/document/1296805/,IEEE Transactions on Circuits and Systems I: Regular Papers,May 2004,ieeexplore
10.1109/TCYB.2013.2275291,Real-Time Multiple Human Perception With Color-Depth Cameras on a Mobile Robot,IEEE,Journals,"The ability to perceive humans is an essential requirement for safe and efficient human-robot interaction. In real-world applications, the need for a robot to interact in real time with multiple humans in a dynamic, 3-D environment presents a significant challenge. The recent availability of commercial color-depth cameras allow for the creation of a system that makes use of the depth dimension, thus enabling a robot to observe its environment and perceive in the 3-D space. Here we present a system for 3-D multiple human perception in real time from a moving robot equipped with a color-depth camera and a consumer-grade computer. Our approach reduces computation time to achieve real-time performance through a unique combination of new ideas and established techniques. We remove the ground and ceiling planes from the 3-D point cloud input to separate candidate point clusters. We introduce the novel information concept, depth of interest, which we use to identify candidates for detection, and that avoids the computationally expensive scanning-window methods of other approaches. We utilize a cascade of detectors to distinguish humans from objects, in which we make intelligent reuse of intermediary features in successive detectors to improve computation. Because of the high computational cost of some methods, we represent our candidate tracking algorithm with a decision directed acyclic graph, which allows us to use the most computationally intense techniques only where necessary. We detail the successful implementation of our novel approach on a mobile robot and examine its performance in scenarios with real-world challenges, including occlusion, robot motion, nonupright humans, humans leaving and reentering the field of view (i.e., the reidentification challenge), human-object and human-human interaction. We conclude with the observation that the incorporation of the depth information, together with the use of modern techniques in new ways, we are able to create an accurate system for real-time 3-D perception of humans by a mobile robot.",https://ieeexplore.ieee.org/document/6583249/,IEEE Transactions on Cybernetics,Oct. 2013,ieeexplore
10.1109/LRA.2021.3102318,Real-Time Obstacle Avoidance Using Dual-Type Proximity Sensor for Safe Human-Robot Interaction,IEEE,Journals,"This letter introduces a dual-type proximity sensor and a control strategy for a robot manipulator to realize safe human-robot interactions (HRI) by using the sensor. Safety is an essential condition for HRI in practical scenarios. To achieve this condition, information about the relationship between an external objects and the robot is required. To obtain this information, we employ a dual-type proximity sensor, which consists of capacitive and inductive transducers and can detect the distance between a robot and external objects. Further, we propose a real-time trajectory planning method to deal with obstacles by using admittance control and distance measurements. To update the motion of the manipulator according to our control strategy, a Weight-Prioritized solution based on a QP (quadratic programming) formalism was applied. Further, the problem of self-sensing is solved via machine learning using a training dataset consisting of data corresponding to random joint positions. The proposed method was implemented on a collaborate robot (UR10). Experiments were conducted considering realistic human-robot interactions, and safety improvement was validated.",https://ieeexplore.ieee.org/document/9508896/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/70.265922,Real-time vision-based robot localization,IEEE,Journals,"This paper describes an algorithm for determining robot location from visual landmarks. This algorithm determines both the correspondence between observed landmarks (in this case vertical edges in the environment) and a stored map, and computes the location of the robot using those correspondences. The primary advantages of this algorithm are its use of a single geometric tolerance to describe observation error, its ability to recognize ambiguous sets of correspondences, its ability to compute bounds on the error in localization, and fast execution. The algorithm has been implemented and tested on a mobile robot system. In several hundred trials it has never failed, and computes location accurate to within a centimeter in less than 0.5 s.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/265922/,IEEE Transactions on Robotics and Automation,Dec. 1993,ieeexplore
10.1109/ACCESS.2020.3018026,Reinforcement Learning for Position Control Problem of a Mobile Robot,IEEE,Journals,"Due to the increase in complexity in autonomous vehicles, most of the existing control systems are proving to be inadequate. Reinforcement Learning is gaining traction as it is posed to overcome these difficulties in a natural way. This approach allows an agent that interacts with the environment to get rewards for appropriate actions, learning to improve its performance continuously. The article describes the design and development of an algorithm to control the position of a wheeled mobile robot using Reinforcement Learning. One main advantage of this approach concerning traditional control algorithms is that the learning process is carried out automatically with a recursive procedure forward in time. Moreover, given the fidelity of the model for the particular implementation described in this work, the whole learning process can be carried out in simulation. This fact avoids damages to the actual robot during the learning stage. It shows that the position control of the robot (or similar specific tasks) can be done without the need to know the dynamic model of the system explicitly. Its main drawback is that the learning stage can take a long time to finish and that it depends on the complexity of the task and the availability of adequate hardware resources. This work provides a comparison between the proposed approach and traditional existing control laws in simulation and real environments. The article also discusses the main effects of using different controlled variables in the performance of the developed control law.",https://ieeexplore.ieee.org/document/9171241/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2020.2992701,Robot Formation Control Based on Internet of Things Technology Platform,IEEE,Journals,"The cooperative control technology of robot formation can sense all kinds of external environment in real time. It is a multi-functional control and management system including visual recognition, task management execution and distribution, behavior decision-making and so on. It can easily adapt to all kinds of harsh environment. In order to meet the efficient response requirements of robot formation control, a real-time transmission system of robot cooperative motion control is built based on the Internet of things platform, which collects and feeds back the trajectory of multiple robots. Through particle swarm optimization deep learning algorithm, more accurate identification, prediction and guidance of the robot's next action. Finally, the simulation of robot formation motion is established by MATLAB software, which verifies the feasibility of particle swarm optimization deep learning neural network algorithm under the Internet of things technology. Compared with the traditional robot formation control method, the optimized control method has faster convergence speed, smaller error and more accurate position, which provides method guidance for the accuracy and efficiency of robot formation control technology.",https://ieeexplore.ieee.org/document/9087868/,IEEE Access,2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TNN.2009.2032183,SVR Versus Neural-Fuzzy Network Controllers for the Sagittal Balance of a Biped Robot,IEEE,Journals,"The real-time balance control of an eight-link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, two alternative intelligent computing control techniques were compared: one based on support vector regression (SVR) and another based on a first-order Takagi-Sugeno-Kang (TSK)-type neural-fuzzy (NF) network. Both methods use the ZMP error and its variation as inputs and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR and the NF were trained based on simulation data and their performance was verified with a real biped robot. Two performance indexes are proposed to evaluate and compare the online performance of the two control methods. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that was acquired and adapted to the robot's size. Some experiments are presented and the results show that the implemented gait combined either with the SVR controller or with the TSK NF network controller can be used to control this biped robot. The SVR and the NF controllers exhibit similar stability, but the SVR controller runs about 50 times faster.",https://ieeexplore.ieee.org/document/5276806/,IEEE Transactions on Neural Networks,Dec. 2009,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2021.3080517,Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning,IEEE,Journals,"Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.",https://ieeexplore.ieee.org/document/9431107/,IEEE Access,2021,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/LRA.2019.2961598,When Your Robot Breaks: Active Learning During Plant Failure,IEEE,Journals,"Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.",https://ieeexplore.ieee.org/document/8938725/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.2986685,WiFi-Based Indoor Robot Positioning Using Deep Fuzzy Forests,IEEE,Journals,"Addressing the positioning problem of a mobile robot remains challenging to date despite many years of research. Indoor robot positioning strategies developed in the literature either rely on sophisticated computer vision techniques to handle visual inputs or require strong domain knowledge for nonvisual sensors. Although some systems have been deployed, the former may be lacking due to the intrinsic limitation of cameras (such as calibration, data association, system initialization, etc.) and the latter usually only works under certain environment layouts and additional equipment. To cope with those issues, we design a lightweight indoor robot positioning system which operates on cost-effective WiFi-based received signal strength (RSS) and could be readily pluggable into any existing WiFi network infrastructures. Moreover, a novel deep fuzzy forest is proposed to inherit the merits of decision trees and deep neural networks within an end-to-end trainable architecture. Real-world indoor localization experiments are conducted and results demonstrate the superiority of the proposed method over the existing approaches.",https://ieeexplore.ieee.org/document/9060874/,IEEE Internet of Things Journal,Nov. 2020,ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/IJCNN48605.2020.9207496,"""I’m Sorry Dave, I’m Afraid I Can’t Do That"" Deep Q-Learning from Forbidden Actions",IEEE,Conferences,"The use of Reinforcement Learning (RL) is still restricted to simulation or to enhance human-operated systems through recommendations. Real-world environments (e.g. industrial robots or power grids) are generally designed with safety constraints in mind implemented in the shape of valid actions masks or contingency controllers. For example, the range of motion and the angles of the motors of a robot can be limited to physical boundaries. Violating constraints thus results in rejected actions or entering in a safe mode driven by an external controller, making RL agents incapable of learning from their mistakes. In this paper, we propose a simple modification of a state-of-the-art deep RL algorithm (DQN), enabling learning from forbidden actions. To do so, the standard Q-learning update is enhanced with an extra safety loss inspired by structured classification. We empirically show that it reduces the number of hit constraints during the learning phase and accelerates convergence to near-optimal policies compared to using standard DQN. Experiments are done on a Visual Grid World Environment and the TextWorld domain.",https://ieeexplore.ieee.org/document/9207496/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ISSCC.2019.8662455,2.5 A 40×40 Four-Neighbor Time-Based In-Memory Computing Graph ASIC Chip Featuring Wavefront Expansion and 2D Gradient Control,IEEE,Conferences,"Single-source shortest path (SSP) problems have a rich history of algorithm development [1-3]. SSP has many applications including AI decision making, robot navigation, VLSI signal routing, autonomous vehicles and many other classes of problems that can be mapped onto graphs. Conventional algorithms rely on sequentially traversing the search space, which is inherently limited by traditional computer architecture. In graphs which become very large, this slow processing time can become a bottleneck in real world applications. We propose a time-based ASIC to address this issue. Our design leverages a dedicated hardware implementation to solve these problems in linear time complexity with superior energy efficiency. A $40\times40$ four-neighbor grid implements a wavefront (WF) expansion with a first-in lockout mechanism to enable traceback. Outside the array, a programmable resistive ladder provides bias voltages to the edge cells, which enables pulse shaping reminiscent of the A* algorithm [3].",https://ieeexplore.ieee.org/document/8662455/,2019 IEEE International Solid- State Circuits Conference - (ISSCC),17-21 Feb. 2019,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/AIID51893.2021.9456574,3D scene geometry estimation method of substation inspection robot based on lightweight neural network,IEEE,Conferences,"Understanding 3D scene geometry from video is a basic subject of visual perception. It includes many classic computer vision tasks, such as depth recovery, traffic estimation, visual odometer. Recent work has proved that deep learning can be applied to scene understanding problems. But they all have some inherent limitations. For example, they need stereo cameras as additional devices for data acquisition, or can't explicitly deal with non-rigid and occlusion. The environment in the substation is complex, and there are many devices. In the working process of inspection robot, the target is very easy to be blocked, and it is difficult to deploy directly by traditional methods. In addition, the real-time performance of neural network is very important for electric inspection robot. In this paper, 3D scene geometry estimation method of substation inspection robot is proposed, which consists of two main parts: GeoNet module and pruning module. Experiments show that the proposed method can be effectively applied to electric inspection robot.",https://ieeexplore.ieee.org/document/9456574/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ICTAI.2015.60,A 3D Frontier-Based Exploration Tool for MAVs,IEEE,Conferences,"This paper presents a 3D frontier-based exploration tool named 3D-FBET. Our tool runs onboard the MAV equipped with a 3D sensor. The 3D map of the environment explored is constructed incrementally from two consecutive point clouds obtained. Considering the computation and memory limitations of MAVs, the OctoMap is utilized to represent 3D models. A novel approach is designed to extract the 3D frontiers from the OctoMap. Different from existing extraction method, only state-changed space in the 3D map is processed in each iteration. We implement our approach on top of the well-known robot operating system (ROS) and demonstrate the effectiveness of our tool in real scenarios.",https://ieeexplore.ieee.org/document/7372156/,2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2015,ieeexplore
10.1109/CIG.2011.6032006,A Bayesian model for RTS units control applied to StarCraft,IEEE,Conferences,"In real-time strategy games (RTS), the player must reason about high-level strategy and planning while having effective tactics and even individual units micro-management. Enabling an artificial agent to deal with such a task entails breaking down the complexity of this environment. For that, we propose to control units locally in the Bayesian sensory motor robot fashion, with higher level orders integrated as perceptions. As complete inference encompassing global strategy down to individual unit needs is intractable, we embrace incompleteness through a hierarchical model able to deal with uncertainty. We developed and applied our approach on a StarCraft<sup>1</sup> AI.",https://ieeexplore.ieee.org/document/6032006/,2011 IEEE Conference on Computational Intelligence and Games (CIG'11),31 Aug.-3 Sept. 2011,ieeexplore
10.1109/IROS40897.2019.8968233,A Behavior Tree Cognitive Assistant System for Emergency Medical Services,IEEE,Conferences,"This paper presents a cognitive assistant system for emergency medical services (EMS) that can serve as a rescue robot or virtual assistant, helping with improving situational awareness of the first responders through automated collection and analysis of data from the incident scene and providing suggestions to them. The proposed system relies on a Behavior Tree (BT) framework that combines the knowledge of EMS protocol guidelines with speech recognition, natural language processing, and machine learning methods to (i) extract critical information from responders' conversations and verbalized observations, (ii) infer the incident context, and (iii) decide on safe and effective response interventions to perform. We use a data-set of 8302 real EMS call records from an urban, high volume regional ambulance agency in the U.S. to evaluate the responsiveness and cognitive ability of the system and assess the safety of the suggestions provided to the responders. The experimental results show that the developed cognitive assistant achieves an average top-3 accuracy of 89% in selecting the correct EMS protocols and an average F1-score of 71% in suggesting the protocol specific interventions while providing transparency and evidence for the suggestions.",https://ieeexplore.ieee.org/document/8968233/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/SICE.2008.4655167,A CMAC-Q-Learning based Dyna agent,IEEE,Conferences,"In the this paper, a CMAC-Q-learning based Dyna agent is presented to relieve the problem of learning speed in reinforcement learning, in order to achieve the goals of shortening training process and increasing the learning, speed. We combine CMAC, Q-learning, and prioritized sweeping techniques to construct the Dyna agent in which a Q-learning is trained for policy learning; meanwhile, model approximators, called CMAC-model and CMAC-R-model, are in charge of approximating the environment model. The approximated model provides the Q-learning with virtual interaction experience to further update the policy within the time gap when there is no interplay between the agent and the real environment. The Dyna agent switches seamlessly between the real environment and the virtual environment model for the objective of policy learning. A simulation for controlling a differential-drive mobile robot has been conducted to demonstrate that the proposed method can preliminarily achieve the design goal.",https://ieeexplore.ieee.org/document/4655167/,2008 SICE Annual Conference,20-22 Aug. 2008,ieeexplore
10.1109/CNNA.1998.685360,A CNN stereo vision hardware system for autonomous robot navigation,IEEE,Conferences,"The high parallel analogue processing rate makes the cellular neural networks paradigm really useful in such a problems where real-time replies to external stimuli are required. The development of an effective system for autonomous robot navigation can find a valid support from this research. Moreover, the growth of new CNN algorithms can afford the necessary feedback to the hardware developers to improve their realisations. In this paper some measurements of a stereo-vision algorithm on a CNN hardware implementation (the 720DPCNN system) are given.",https://ieeexplore.ieee.org/document/685360/,1998 Fifth IEEE International Workshop on Cellular Neural Networks and their Applications. Proceedings (Cat. No.98TH8359),14-17 April 1998,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/FDL53530.2021.9568376,A Container-based Design Methodology for Robotic Applications on Kubernetes Edge-Cloud architectures,IEEE,Conferences,"Programming modern Robots' missions and behavior has become a very challenging task. The always increasing level of autonomy of such platforms requires the integration of multi-domain software applications to implement artificial intelligence, cognition, and human-robot/robot-robot interaction applications. In addition, to satisfy both functional and nonfunctional requirements such as reliability and energy efficiency, robotic SW applications have to be properly developed to take advantage of heterogeneous (Edge-Fog-Cloud) architectures. In this context, containerization and orchestration are becoming a standard practice as they allow for better information flow among different network levels as well as increased modularity in the use of software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de-facto development standards (i.e., robotic operating system - ROS - compliancy for robotic applications) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The design methodology allows for (i) integration and verification of multi-domain components since early in the design flow, (ii) task-to-container mapping techniques to guarantee minimum overhead in terms of performance and memory footprint, and (iii) multi-domain verification of functional and non-functional constraints before deployment. We present the results obtained in a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. The source code of the mobile robot is publicly available on GitHub.",https://ieeexplore.ieee.org/document/9568376/,2021 Forum on specification & Design Languages (FDL),8-10 Sept. 2021,ieeexplore
10.1109/ACSOS-C51401.2020.00067,A Deep Domain-Specific Model Framework for Self-Reproducing Robotic Control Systems,IEEE,Conferences,"As robots play more critical roles in diverse and complex scenarios in the real world, monomorphic robots are limited to repeating and rather simple tasks. How to achieve a robust, flexible, and scalable multi-robot system becomes essential research. Model-driven software development (MDSD) provides a sturdy methodology for robotic programming using multilevel domain-specific languages (DSLs). These DSLs lay a solid foundation for the design, integration, and extensibility of robotic applications. In this paper, we propose a deep domain-specific model framework for the self-reproducing robotic control system to escort reliable, versatile tasks of heterogeneous robots.",https://ieeexplore.ieee.org/document/9196470/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C),17-21 Aug. 2020,ieeexplore
10.1109/SNPD.2013.12,A Fast Genetic SLAM Approach for Mobile Robots,IEEE,Conferences,"This paper presents a new SLAM (simultaneous localization and mapping) method using genetic algorithm (GA) for mobile robots. A laser range finder (LRF) is installed on a mobile robot for collecting point-distance information about the surroundings. From the LRF points, several important ones are extracted for describing the main features of the surroundings. A new form of chromosomes for representing the changes of feature LRF points that are caused by the robot's movement is designed. The matching of current LRF features and the robot's possible movement is done by a fast genetic algorithm. A restart mechanism that re-initializes all chromosomes for increasing the diversity of solutions is developed and works with the matching process. Some constrains are developed for filtering out irrational chromosomes after the operation of crossover and mutation. With these mechanisms and constrains, our proposed method generates feasible solutions in several hundreds of GA iterations. Experiments are conducted on a real mobile robot. The experimental results show that our proposed method is efficient and effective for SLAM.",https://ieeexplore.ieee.org/document/6598520/,"2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",1-3 July 2013,ieeexplore
10.1109/IJCNN48605.2020.9207308,A Few-shot Dynamic Obstacle Avoidance Strategy in Unknown Environments,IEEE,Conferences,"Obstacle avoidance is one of the basic capabilities of intelligent mobile robots. With the diversification of the application environment, mobile robots are required to avoid obstacles with higher generality. Benefit from the development of mobile platform and deep learning algorithm in recent years, we conceive a few-shot dynamic obstacle avoidance strategy to meet this higher generality demand. Under this metric-based meta-learning method, mobile robots can quickly adapt to unknown environments by learning from several samples. In order to verify its effectiveness, we use this strategy to train a model and deploy it to the mobile robot and run multiple obstacle avoidance recognition tests in the real-world environment. The results of experiments performed on the mobile robot platform illustrates a good performance and verifies our proposed strategy. In addition to analyzing the experimental results, the advantages, disadvantages as well as application potential of the proposed strategy as a decision aid are also discussed.",https://ieeexplore.ieee.org/document/9207308/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/UR49135.2020.9144789,A Markerless Deep Learning-based 6 Degrees of Freedom Pose Estimation for Mobile Robots using RGB Data,IEEE,Conferences,"Augmented Reality has been subject to various integration efforts within industries due to its ability to enhance human machine interaction and understanding. Neural networks have achieved remarkable results in areas of computer vision, which bear great potential to assist and facilitate an enhanced Augmented Reality experience. However, most neural networks are computationally intensive and demand huge processing power, thus are not suitable for deployment on Augmented Reality devices. In this work, we propose a method to deploy state of the art neural networks for real time 3D object localization on augmented reality devices. As a result, we provide a more automated method of calibrating the AR devices with mobile robotic systems. To accelerate the calibration process and enhance user experience, we focus on fast 2D detection approaches which are extracting the 3D pose of the object fast and accurately by using only 2D input. The results are implemented into an Augmented Reality application for intuitive robot control and sensor data visualization. For the 6D annotation of 2D images, we developed an annotation tool, which is, to our knowledge, the first open source tool to be available. We achieve feasible results which are generally applicable to any AR device, thus making this work promising for further research in combining high demanding neural networks with Internet of Things devices.",https://ieeexplore.ieee.org/document/9144789/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ICRA40945.2020.9196677,A Mobile Manipulation System for One-Shot Teaching of Complex Tasks in Homes,IEEE,Conferences,"We describe a mobile manipulation hardware and software system capable of autonomously performing complex human-level tasks in real homes, after being taught the task with a single demonstration from a person in virtual reality. This is enabled by a highly capable mobile manipulation robot, whole-body task space hybrid position/force control, teaching of parameterized primitives linked to a robust learned dense visual embeddings representation of the scene, and a task graph of the taught behaviors. We demonstrate the robustness of the approach by presenting results for performing a variety of tasks, under different environmental conditions, in multiple real homes. Our approach achieves 85% overall success rate on three tasks that consist of an average of 45 behaviors each. The video is available at: https://youtu.be/HSyAGMGikLk.",https://ieeexplore.ieee.org/document/9196677/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/SNPD.2012.115,A Model-Based Approach to Constructing Safe Soft Real-Time Programs for Non-Real-Time Environments,IEEE,Conferences,"The primary goal of this work is to provide an easy and systematic way of developing safe soft real-time systems. To achieve this goal, we propose a method of generating real-time programs from formally verified models written as systems of timed automata. The models are verified using UPPAAL model checker prior to be processed by our code generators. A characteristic of our code generator is that the generated code runs in a non-real-time environment, i.e., a runtime environment without inherent real-time schedulers. To realize this, the code generator weaves timing checking code fragments within the generated programs. The generated code explicitly checks the real-time clock of its runtime to obey the timing constraints specified in the model. In this paper, we describe how to generate Java/C programs from UPPAAL timed automata and show the benefits of our method using a robot controller case study.",https://ieeexplore.ieee.org/document/6299291/,"2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",8-10 Aug. 2012,ieeexplore
10.1109/RoSE52553.2021.00011,A Modeling Tool for Reconfigurable Skills in ROS,IEEE,Conferences,"Known attempts to build autonomous robots rely on complex control architectures, often implemented with the Robot Operating System platform (ROS). The implementation of adaptable architectures is very often ad hoc, quickly gets cumbersome and expensive. Reusable solutions that support complex, runtime reasoning for robot adaptation have been seen in the adoption of ontologies. While the usage of ontologies significantly increases system reuse and maintainability, it requires additional effort from the application developers to translate requirements into formal rules that can be used by an ontological reasoner. In this paper, we present a design tool that facilitates the specification of reconfigurable robot skills. Based on the specified skills, we generate corresponding runtime models for self-adaptation that can be directly deployed to a running robot that uses a reasoning approach based on ontologies. We demonstrate the applicability of the tool in a real robot performing a patrolling mission at a university campus.",https://ieeexplore.ieee.org/document/9474550/,2021 IEEE/ACM 3rd International Workshop on Robotics Software Engineering (RoSE),2-2 June 2021,ieeexplore
10.1109/ICICSP54369.2021.9611881,A Multi-agent Reinforcement Learning Routing Protocol in Mobile Robot Network,IEEE,Conferences,"Robots are now essential in unreachable, repeated, and dangerous real-world applications where they take place of human beings. One of the important capabilities of a multi-robot system is that it should be able to form an autonomous robot network to transmit information. However, due to the limited communication capability of a single robot, the highly variable environment where robots work, and the mobility of the robots, it is difficult for them to exchange information with each other in need. In this article, we propose a novel robot network routing protocol based on multi-agent reinforcement learning called MAQR. The robot nodes can deliver packets cooperatively. The mobility factor, buffer status, and packet delay of neighbor nodes are taken into consideration. We design a reliability model for a robot agent to make reliable routing decisions. We also design an adaptive exploration-exploitation method to balance the convergence speed, solution space as well as network fluctuation. The routing algorithm has been implemented and evaluated in simulation. Results show that MAQR can provide less packet delay, less average queue length and higher delivery ratio than other Q-learning based routing protocol.",https://ieeexplore.ieee.org/document/9611881/,2021 4th International Conference on Information Communication and Signal Processing (ICICSP),24-26 Sept. 2021,ieeexplore
10.1109/SMC.2019.8914519,A Multimodal Perception System for Detection of Human Operators in Robotic Work Cells,IEEE,Conferences,"Workspace monitoring is a critical hw/sw component of modern industrial work cells or in service robotics scenarios, where human operators share their workspace with robots. Reliability of human detection is a major requirement not only for safety purposes but also to avoid unnecessary robot stops or slowdowns in case of false positives. The present paper introduces a novel multimodal perception system for human tracking in shared workspaces based on the fusion of depth and thermal images. A machine learning approach is pursued to achieve reliable detection performance in multi-robot collaborative systems. Robust experimental results are finally demonstrated on a real robotic work cell.",https://ieeexplore.ieee.org/document/8914519/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/CSICC52343.2021.9420614,A New Approach for Mapping of Soccer Robot Agents Position to Real Filed Based on Multi-Core Fuzzy Clustering,IEEE,Conferences,"Mapping the position of soccer robot agents to a real field, is one of the essential issues in the practical implementation of scientific contributions in this context. The lack of a proper assignment affects the scientific implementation of many subjects, such as routing, obstacle avoidance, and robot guidance. For this reason, the use of a clustering method is proposed in this article. Upon the entrance of a new agent, its position is mapped to the real field based on the clustering algorithm. After this mapping, the system begins to work according to the position of the agents, which is defined as the position of the centers of the clusters, as well as the rules defined in the knowledge-base. Considering the unknown and dynamic environment of the robot, some objects inherit common traits from multiple clusters. One reasonable solution for considering the cluster overlaps is to assign a set of membership degrees to each of them. Multiple membership degree assignments result from the fuzzy nature of the clusters. Due to the reduction of segmentations and the shrinkage of the search space, fuzzy clustering generally faces less computational overhead, while the identification and handling of vague, noisy, and outlier data also become much easier in them. The approach of the proposed method is based on the feasibility ideas and uses multi-core learning to identify clusters with complex data structures. The feasibility score of each data represents the percentages of the properties that data inherits from the clusters. Automatically adjusting the weights of the cores in an optimization framework, the proposed method avoids the damage caused by problems such as adopting inefficient cores, or irrelevant features.",https://ieeexplore.ieee.org/document/9420614/,"2021 26th International Computer Conference, Computer Society of Iran (CSICC)",3-4 March 2021,ieeexplore
10.1109/ISIC.2007.4450948,A New Color Based Optical Flow Algorithm for Environment Mapping Using a Mobile Robot,IEEE,Conferences,"Environment mapping from a video sequence is considered to be one of the most important problems in computer vision because of its application in surveillance, virtual reality, autonomous navigation, multimedia communications, medical prognosis, etc. In this paper, we have presented an optical flow based method for environment mapping. It uses a new color based optical flow computation technique. The camera, which is mounted on a mobile robot, is kept perpendicular to the direction of motion, and the captured set of images is used to compute the dense depth map. We have used a Kalman filter to denoise the depth map.",https://ieeexplore.ieee.org/document/4450948/,2007 IEEE 22nd International Symposium on Intelligent Control,1-3 Oct. 2007,ieeexplore
10.1109/RAMECH.2011.6070484,A Q-learning based Cartesian model reference compliance controller implementation for a humanoid robot arm,IEEE,Conferences,This paper presents the implementation (real time and simulation) of a model-free Q-learning based discrete model reference compliance controller for a humanoid robot arm. The Reinforcement learning (RL) scheme uses a recently developed Q-learning scheme to develop an optimal policy on-line. The RL Cartesian (x and y) tracking controller with model reference compliance was implemented using two links (shoulder flexion and elbow flexion joints) of the right arm of the humanoid Bristol-Elumotion-Robotic-Torso II (BERT II) torso.,https://ieeexplore.ieee.org/document/6070484/,"2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM)",17-19 Sept. 2011,ieeexplore
10.1109/IJCNN.2003.1224077,A RAM-based neural network for collision avoidance in a mobile robot,IEEE,Conferences,"A RAM-based neural network is being developed for a mobile robot controlled by a simple microprocessor system. Conventional neural networks often require a powerful and sophisticated computer system. Training a multi-layer neural network requires repeated presentation of training data, which often results in very long learning time. The goal for this paper is to demonstrate that RAM-based neural networks are a suitable choice for embedded applications with few computational resources. This functionality is demonstrated in a simple robot powered by an 8051 microcontroller with 512 bytes of RAM. The RAM-based neural network allows the robot to detect and avoid obstacles in real time.",https://ieeexplore.ieee.org/document/1224077/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/NAECON.2018.8556769,A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams,IEEE,Conferences,"This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.",https://ieeexplore.ieee.org/document/8556769/,NAECON 2018 - IEEE National Aerospace and Electronics Conference,23-26 July 2018,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561722,A Scavenger Hunt for Service Robots,IEEE,Conferences,"Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",https://ieeexplore.ieee.org/document/9561722/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2018.8593714,A Software Framework for Planning Under Partial Observability,IEEE,Conferences,"Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.",https://ieeexplore.ieee.org/document/8593714/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.23919/ChiCC.2019.8865929,A Speech Interaction System Based on Cloud Service under ROS,IEEE,Conferences,"With the recent development of technologies such as artificial intelligence and cloud computing, intelligent service robots are more and more widely used, and current users are paying more attention to the speech interaction function of robots. In this paper, we design a cloud-based intelligent speech interaction system under ROS to enhance the human-robot interaction experience, and carry out related tests on the laptop. The system we designed runs stably and smoothly, and has high real-time performance, which can satisfy user's requirements.",https://ieeexplore.ieee.org/document/8865929/,2019 Chinese Control Conference (CCC),27-30 July 2019,ieeexplore
10.1109/ROBIO.2006.340185,A Study of real-time EMG-driven Arm Wrestling Robot,IEEE,Conferences,"An EMG-driven arm wrestling robot (AWR) is being developed in our laboratories for the purposes of studying neuromuscular control of arm movements. The AWR arm have 2-DOF, integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera, is used to estimate tension developed by individual muscles based on recorded electromyograms (EMGs). The surface electromyographic signal form the upper limb is sampled from a real player in same conditions. By using the method of wavelet packet transformation (WPT) and auto regressive model (AR), the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments. The purpose of this paper is to describe the design objectives, fundamental components and implementation of our real-time, EMG-driven AWR arm.",https://ieeexplore.ieee.org/document/4142107/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ECAI.2017.8166446,A control approach for a robotic ground walking platform,IEEE,Conferences,"This study presents a control approach for a Ground Walking Platform (GWP). The control approach was developed to be a part of a future lower limb rehabilitation robot that aims to simulate the walking on different terrains (e.g. walking, on plane ground, on stairs, or on a hill). In addition the system aims to simulate for the user not only classic hard ground walking trajectories, but also to simulate different values of stiffens of as well. This may involve walking on solid ground, muddy land, sand and water too. The objective of this paper is to present a dynamic control study of a GWP system allowing us to predict the relationship between the walker's foot and a virtual environment. More specifically, his involves defining the equations describing the relation between the contact forces (foot/platform) and the position of the foot.",https://ieeexplore.ieee.org/document/8166446/,"2017 9th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",29 June-1 July 2017,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICRA.2012.6225245,A depth space approach to human-robot collision avoidance,IEEE,Conferences,"In this paper a real-time collision avoidance approach is presented for safe human-robot coexistence. The main contribution is a fast method to evaluate distances between the robot and possibly moving obstacles (including humans), based on the concept of depth space. The distances are used to generate repulsive vectors that are used to control the robot while executing a generic motion task. The repulsive vectors can also take advantage of an estimation of the obstacle velocity. In order to preserve the execution of a Cartesian task with a redundant manipulator, a simple collision avoidance algorithm has been implemented where different reaction behaviors are set up for the end-effector and for other control points along the robot structure. The complete collision avoidance framework, from perception of the environment to joint-level robot control, is presented for a 7-dof KUKA Light-Weight-Robot IV using the Microsoft Kinect sensor. Experimental results are reported for dynamic environments with obstacles and a human.",https://ieeexplore.ieee.org/document/6225245/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ISIC.2003.1253933,A dynamically sized Radial Basis Function neural network for joint control of a PUMA 500 manipulator,IEEE,Conferences,"We present the design and analysis of a neural control structure for joint control of a PUMA 500 robot manipulator. We lay out the design considerations and steps to build an experimental electronic control system to control the shoulder joint of the manipulator. We review the use of neural networks for on-line learning closed-loop control applications. The 'curse of dimensionality', a problem encountered when using Radial Basis Function (RBF) neural networks, is addressed and a neuron-node resource-allocating algorithm is investigated to overcome this problem. An on-line learning neural-control structure, employing this resource-allocating algorithm, is proposed, implemented and successfully tested to improve the position accuracy of the robot manipulator. All the implementations are executed on a 16-bit microcontroller in real-time, developed using integer arithmetic in the programming language C. The program listings are available upon email request.",https://ieeexplore.ieee.org/document/1253933/,Proceedings of the 2003 IEEE International Symposium on Intelligent Control,8-8 Oct. 2003,ieeexplore
10.1109/ROBIO.2007.4522431,A fast robot feedback decision algorithm,IEEE,Conferences,"Intelligence decision is an important subject for robotic intelligence system. This paper presents an experimental research work about robotic intelligence decision, where a fast information reduction with feedback features is proposed to solve robot intelligent decision and judgement issue. We have investigated the properties satisfied by the robotic information processing and decision process: if an attribute is the only discerning of multiple information objects, this attribute can be taken as the first core attribute, and can be reused in an iterative information reduction process to get another core attribute; furthermore, a feedback method can be used to enhance this iterative processing capability in real-time robots cooperative systems. Out feedback control method is somewhat dynamical and iterative process, and the investigated properties are utilized to design the feedback control laws. We have set up the relative experimental platform, and the experimental results show that our fast robot feedback decision algorithm is efficient and effective, which can be used in multiple robots collaborative missions.",https://ieeexplore.ieee.org/document/4522431/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICAL.2010.5585308,A framework for coordination and navigation of multi-robot systems,IEEE,Conferences,"In this paper, a novel framework is proposed to incorporate task assignment, path planning, and tracking control of a multi-robot system. The dynamic task assignment of multi-robots is achieved using a self-organizing map based feature. The real-time collision-free robot path is generated from a neuro-dynamics network through sensor measurement and responding immediately to dynamic elements in the environment including the robot, the target, and obstacles. The tracking control is accomplished by a neuro-dynamics and back-stepping based model. This type of control is able to generate smooth, bounded acceleration control signals for a non-holonomic mobile robot to track the reference path generated by the path planner. Experiments under various situations demonstrated the effectiveness of this integrated system.",https://ieeexplore.ieee.org/document/5585308/,2010 IEEE International Conference on Automation and Logistics,16-20 Aug. 2010,ieeexplore
10.1109/SSCI.2016.7849899,A fuzzy-based machine learning model for robot prediction of link quality,IEEE,Conferences,"With foresight into the state of the wireless channel, a robot can make various optimization decisions with regards to routing packets, planning mobility paths, or switching between diverse radios. However, the process of predicting link quality (LQ) is nontrivial due to the streaming and dynamic nature of radio wave propagation, which is complicated by robot mobility. Due to robot movement, the wireless propagation environment can change considerably in terms of distance, obstacles, noise, and interference. Therefore, LQ must be learned and regularly updated while the robot is online. However, the existing fuzzy-based models for assessing LQ are non-adaptable due to the absence of any learning mechanism. To address this issue, we introduce a fuzzy-based prediction model designed for the efficient online and incremental learning of LQ. The unique approach uses fuzzy logic to infer LQ based on the collective output from a series of offset classifiers and their posterior probabilities. In essence, the proposed model leverages machine learning for extracting the underlying functional relationship between the input and output variables, but deeper inferences are made from the output of the learning algorithms using fuzzy logic. Wireless link data from a real-world robot network was used to compare the model with the traditional linear regression approach. The results show statistically significant improvements in three out of the six real-world indoor and outdoor environments where the robot operated. Additionally, the novel approach offers a number of other benefits, including the flexibility to use fuzzy logic for model tuning, as well as the ability to make implementation efficiencies in terms of parallelization and the conservation of labeling resources.",https://ieeexplore.ieee.org/document/7849899/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICARSC.2018.8374189,A generic visual perception domain randomisation framework for Gazebo,IEEE,Conferences,"The impressive results of applying deep neural networks in tasks such as object recognition, language translation, and solving digital games are largely attributed to the availability of massive amounts of high quality labelled data. However, despite numerous promising steps in incorporating these techniques in robotic tasks, the cost of gathering data with a real robot has halted the proliferation of deep learning in robotics. In this work, a plugin for the Gazebo simulator is presented, which allows rapid generation of synthetic data. By introducing variations in simulator-specific or irrelevant aspects of a task, one can train a model which exhibits some degree of robustness against those aspects, and ultimately narrow the reality gap between simulated and real-world data. To show a use-case of the developed software, we build a new dataset for detection and localisation of three object classes: box, cylinder and sphere. Our results in the object detection and localisation task demonstrate that with small datasets generated only in simulation, one can achieve comparable performance to that achieved when training on real-world images.",https://ieeexplore.ieee.org/document/8374189/,2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),25-27 April 2018,ieeexplore
10.1109/INDIN.2013.6622897,A genetic algorithm for optimizing vector-based paths of industrial manipulators,IEEE,Conferences,"Nowadays there is a vast amount of IT tools specialized in vector graphics. The data generated by those tools could be used to describe the path of industrial manipulators as a set of vectors. The main problem is that the sequence/direction of those vectors is not meant to be executed by a robot and attempting to do it, would result in inefficient cycle times of the robot. Therefore it is necessary to generate an execution plan that minimizes the cost of carrying out the vector-based path. The number of possible execution actions has a factorial growth and it is unfeasible to evaluate each of them. This paper proposes the use of a genetic algorithm to optimize this task. The main contribution of this work is a chromosome encoding structure and modifications to the Partially Mapped Crossover operator in order to comply with the constraints of this optimization problem. The algorithm was implemented and tested in a real industrial manipulator.",https://ieeexplore.ieee.org/document/6622897/,2013 11th IEEE International Conference on Industrial Informatics (INDIN),29-31 July 2013,ieeexplore
10.1109/ICCE-Asia.2016.7804752,A hardware architecture of face detection for human-robot interaction and its implementation,IEEE,Conferences,"This paper presents hardware architecture with low-complexity face detection (FD) and parallel processing of local binary pattern (LBP) generation and adaptive boosting (AdaBoost) algorithm using Haar features for the intelligent service robot system. We designed a fully pipelined architecture implemented with the design techniques, such as variable image scaling and parallel processing multiple classifiers without integral image generation, on the FPGA platform. The proposed architecture enables a real-time FD processing for a VGA video at 30 frames per second.",https://ieeexplore.ieee.org/document/7804752/,2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),26-28 Oct. 2016,ieeexplore
10.1109/ECBS.2003.1194801,A hybrid architecture for visualization and decision making in battlespace environments,IEEE,Conferences,"This article presents a hybrid software/hardware architecture for commander's decision support in tactical operations. The architecture builds on the symbolic, object-oriented visualization software called Advanced Tactical Architecture for Combat Knowledge System (ATACKS). The extension discussed here is the design of a real-time robot agent layer that interacts wirelessly with ATACKS. This layer enacts decisions made by software agents (wargamers), continuously relays the execution states back to ATACKS, and updates its actions as advocated by replanning algorithms. The software layer is briefly described followed by the specification of the real-time requirements for the robotic architecture. The design and implementation are given with a small example that illustrates the hybrid system's operation.",https://ieeexplore.ieee.org/document/1194801/,"10th IEEE International Conference and Workshop on the Engineering of Computer-Based Systems, 2003. Proceedings.",7-10 April 2003,ieeexplore
10.1109/SKIMA.2016.7916262,"A hybrid real-time EMG intelligent rehabilitation robot motions control based on Kalman Filter, support vector machines and particle swarm optimization",IEEE,Conferences,"Intelligent Control of agent autonomous rehabilitation robot is a very complex problem, especially for stroke patients' treatments and dealing with real-time EMG sensors readings of muscles activity states and transfer between real-time Human motions to interface with rehabilitation robot agent or assisteddevice. The field of Artificial Intelligence and neural networks plays a critical role in modern intelligent control interfaces for robot devices. This paper presents a novel hybrid intelligent robot control that acts as human-robot interaction, where it depends on real-time EMG sensor patients data and extracted features along with estimated knee joint angles from Extended Kalman Filter method are used for training the intelligent controller using support vector machines trained with Adatron Learning algorithm for handling huge data values of sensors readings. Moreover, the proposed platform for rehabilitation robot agent is tested in the framework of the NAO Humanoid Robot agent along with Neurosolutions Toolkit and Matlab code. The average overall accuracy of the proposed intelligent motion SVM-EKF controller shows average high performance that approaches average 96% of knee motions classifications and also good performance for comparing Extended Kalman filter knee joint angles estimations and real EMG human knee joint angles in the framework of Human Walk Gait cycle. Also, the basic enhancement of proposing PSO optimization technique for robot knee motion is discussed for future improvements. The overall algorithm, methodology and experiments are presented in this paper along with future work.",https://ieeexplore.ieee.org/document/7916262/,"2016 10th International Conference on Software, Knowledge, Information Management & Applications (SKIMA)",15-17 Dec. 2016,ieeexplore
10.1109/FUZZY.1992.258618,A learning method of fuzzy inference rules by descent method,IEEE,Conferences,"The authors propose a learning method for fuzzy inference rules by a descent method. From input-output data gathered from specialists, the inference rules expressing the input-output relation of the data are obtained automatically. The membership functions in the antecedent part and the real number in the consequent part of the inference rules are tuned by means of the descent method. The learning speed and the generalization capability of this method are higher than those of a conventional backpropagation type neural network. This method has the capability to express the knowledge acquired from input-output data in the form of fuzzy inference rules. Some numerical examples are described to show these advantages over the conventional neural network. An application of the method to a mobile robot that avoids a moving obstacle and its computer simulation are reported.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/258618/,[1992 Proceedings] IEEE International Conference on Fuzzy Systems,8-12 March 1992,ieeexplore
10.1109/IROS.2013.6696771,A learning-based approach to robust binaural sound localization,IEEE,Conferences,"Sound source localization is an important feature designed and implemented on robots and intelligent systems. Like other artificial audition tasks, it is constrained to multiple problems, notably sound reflections and noises. This paper presents a sound source azimuth estimation approach in reverberant environments. It exploits binaural signals in a humanoid robotic context. Interaural Time and Level Differences (ITD and ILD) are extracted on multiple frequency bands and combined with a neural network-based learning scheme. A cue filtering process is used to reduce the reverberations effects. The system has been evaluated with simulation and real data, in multiple aspects covering realistic robot operating conditions, and was proven satisfying and effective as will be shown and discussed in the paper.",https://ieeexplore.ieee.org/document/6696771/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICCAE.2010.5451340,A low cost microcontroller implementation of neural network based hurdle avoidance controller for a car-like robot,IEEE,Conferences,This paper describes the implementation of a neural network based hurdle avoidance controller for a car like robot using a low cost single chip 89C52 microcontroller. The neural network is the multilayer feed-forward network with back propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that up-to twenty neurons in hidden layer can be deployed with the proposed technique using a single 89C52 microcontroller. The vehicle is tested in various environments containing obstacles and is found to avoid obstacles in its path successfully.,https://ieeexplore.ieee.org/document/5451340/,2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE),26-28 Feb. 2010,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/IROS.1996.571054,A method for expecting the features of objects and enabling real-time vision processing,IEEE,Conferences,"This paper presents a mathematical analysis of image processing, algorithms designed according to the results of this analysis, and their implementation. We prove that the search of objects features can be accelerated without loss of precision by using an inhomogeneous density of the sensitive cells the parameters space is composed of. In other words, the visual analysis should be concentrated in the region of the features space around the expected object position. The improvement relative to an uniform cell density is quantified using a cost function corresponding to time and precision optimisation. We show that a Kohonen neural network can be used for efficient image processing, and simulate this strategy. We introduce a simpler algorithm for the case that the object positions are Gauss-distributed around the expected position. This algorithm has been implemented it on a robot guided by a vision system. The robot learned to process images efficiently during the manoeuvres and after that was able to track objects moving in a fast and unpredictable manner.",https://ieeexplore.ieee.org/document/571054/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/ROBOT.2001.933206,A method for obstacle avoidance and shooting action of the robot soccer,IEEE,Conferences,"A fuzzy-obstacle-avoidance-path algorithm for obstacle avoidance and a procedure for the shooting action of a soccer robot based on this algorithm are proposed. This algorithm contains a fuzzy system that is used to estimate the rotational velocity of the soccer robot. To demonstrate the effectiveness and applicability of the proposed method, two simulations are presented and a real-time implementation is developed.",https://ieeexplore.ieee.org/document/933206/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/IROS.1997.649083,A mobile robot for service use: behaviour simulation system and intelligent control,IEEE,Conferences,"The structure of hardware and software of AI control system of a mobile robot for service use are described. Hardware of the mobile robot described include an autonomous wheel vehicle and a five degree of freedom manipulator. The software of the AI control system is based on soft computing including fuzzy control rules, fuzzy neural network and genetic algorithms. The intelligent control of cooperative motion between the autonomous vehicle and manipulator realises flexible operations such as navigation of a mobile robot in presence of static and dynamic obstacles, processes of opening door in rooms and pushing buttons of an elevator. New hierarchical structure of the AI control system includes direct human-robot communication line based on natural language and cognitive graphics, and a generator of virtual reality for simulation of artificial life conditions for the mobile service robot. Simulation and experimental results of navigation and technical operations with the manipulator mobile service robot used in office building are described.",https://ieeexplore.ieee.org/document/649083/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/RAMECH.2004.1438939,A model-based humanoid perception system for real-time human motion imitation,IEEE,Conferences,"This paper presents real-time human motion analysis based on hierarchical tracking and inverse kinematics. Our goal is to implement a mechanism of human-machine interaction that permits a robot to learn from human gestures, and, as a first stage, we have developed a computer-vision based human upperbody motion analysis system. This application requires developing a real-time human motion capturing system that works without special devices or markers. Since such a system is unstable and can only acquire, partial information because of self-occlusions, we have introduced a pose estimation method based on inverse kinematics. This system can estimate upper-body human postures with limited perceptual cues such as position of head and hands. The method has been tested using a HOAP-I humanoid robot.",https://ieeexplore.ieee.org/document/1438939/,"IEEE Conference on Robotics, Automation and Mechatronics, 2004.",1-3 Dec. 2004,ieeexplore
,A multi-agent framework for coordination of intelligent assistive technologies,IEEE,Conferences,"Intelligent care for the future is the IntelliCare project's main priority. This paper describes the design of a generic multi-agent framework for coordination of intelligent assistive technologies. The paper overviews technologies and software systems suitable for context awareness and housekeeping tasks, especially for performing a multi-robot cleaning-task activity. It also describes conducted work in the design of a multi-agent platform for coordination of intelligent assistive technologies. Instead of using traditional robot odometry estimation methods, we have tested an independent indoor localization system for real-time localization. We conducted an experiment in two steps: first, creating and testing interaction interfaces with and between robotic systems, and secondly, wrapping all in a multi-agent system, defining a vacuuming-cleaning ontology. With the pose data from an indoor localization system, is it possible to compare with real robot positions. From this, we can make some platform assumptions regarding heterogeneous robot cooperation, by thinking further i.e. sharing workspace with humans.",https://ieeexplore.ieee.org/document/5556631/,5th Iberian Conference on Information Systems and Technologies,16-19 June 2010,ieeexplore
10.1109/ICIPS.1997.669208,A neural network approach to the elimination of road shadow for outdoor mobile robot,IEEE,Conferences,"A new method of road tracking oriented environmental noise elimination is presented for implementing navigation and control of land autonomous vehicles (ALV). The concept of vision based environmental noise is firstly introduced for the purpose of road and/or obstacle edge detection. Then, a representation of pyramid is proposed for vision processing. Furthermore, a fuzzy neural network is designed and implemented to recognize the environmental noises such as shadow and water prints on the road. With structure optimization by genetic algorithm and special training by classified samples, we use the network to guide our THMR-III (Tsinghua University Mobile Robot, Model 3) in the outdoor real world. Experiments have shown good properties for the ALV's ""perception-action"" behaviors, including obstacle avoidance, road following, wandering, etc. Although the work is still going on, we can see from the present results the better quality, adaptability and robustness of the above approach.",https://ieeexplore.ieee.org/document/669208/,1997 IEEE International Conference on Intelligent Processing Systems (Cat. No.97TH8335),28-31 Oct. 1997,ieeexplore
10.23919/ECC.2001.7076440,A neural network implementation of real-time fuzzy predictive control,IEEE,Conferences,"Fuzzy predictive controllers have been applied to several applications with good control performance. However, this methodology often leads to nonconvex optimization problems, which are difficult to solve for fast processes, i.e. processes with small sampling times. This paper proposes a new methodology to apply a fuzzy predictive controller in real-time by using a neural network architecture, which receives data from the process and computes the control actions. Thus, the neural network is learned off-line, and its final structure guarantees that control actions are computed very rapidly. An internal model control structure is used to cope with model-plant mismatches and disturbances. The proposed methodology is tested in a realistic simulation of an experimental robot manipulator, where force and position are both controlled. The proposed scheme reveals very good control performance.",https://ieeexplore.ieee.org/document/7076440/,2001 European Control Conference (ECC),4-7 Sept. 2001,ieeexplore
10.1109/IACC.1995.465839,A neural network system that controls and plans paths for a robot,IEEE,Conferences,"Proposes to solve the problems of direct/inverse kinematics and control of trajectories by multilevel perceptrons. The authors' solution admits a parallel implementation in real time. It does not need either to solve kinematic equations or robot trajectories, because it learns gradually by examples adaptively. The control system consists of different networks each of which specialises in solving a particular problem. This structure enables a modular approach to the problem accelerating convergence. The system obtains an acceptable trajectory and gives a parallel solution that could be used in real-time applications.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/465839/,Proceedings of IEEE/IAS International Conference on Industrial Automation and Control,5-7 Jan. 1995,ieeexplore
10.1109/ICSMC.1995.538227,A neural network-based robot safety system,IEEE,Conferences,"This paper presents a new approach for real-time robot safety system based on artificial neural networks. This approach includes a neural network detection unit and a neural network decision unit, implemented at an intermediate and high level of sensory processing, respectively. Both the detection and decision units have been implemented and tested by simulation, both separately and as an integrated unit. The response time of the integrated system measured on the 90 MHz, P5 microprocessor is less than 11 ms, and the correctness of safety decisions is 97%.",https://ieeexplore.ieee.org/document/538227/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1049/cp:19990285,A neural vision based controller for a robot footballer,IET,Conferences,"Robot football is growing in popularity both as a research topic and as a sporting event. The football setting provides rich interaction possibilities and a ready source of competition in an environment containing both predictable and non-deterministic elements. Successful players must be able to react quickly in real time, exhibit multiple competences and choose between several possibly conflicting goals. Opportunities exist to explore reflexive behaviour, strategic behaviour and even communication and social behaviour in team events. At the same time, artificial neural networks are increasingly being used in robot controllers to explore new biologically-inspired ideas relating to perception, memory and motor control. The research described in this paper attempts to combine these two areas of study to produce a framework for a neurally based and visually guided football-playing controller. A controller architecture is proposed in which a small set of high-level features in the robot's environment are extracted from raw image data by using a feedforward neural network. These feature signals, collectively termed the ""feature bus"", are then available for use by other controller modules. The feature bus signals are sufficiently general and high-level to be used with many different controller strategies, and their low dimensionality compared to the raw visual input makes the implementation of learning controllers more feasible.",https://ieeexplore.ieee.org/document/791354/,"Image Processing And Its Applications, 1999. Seventh International Conference on (Conf. Publ. No. 465)",13-15 July 1999,ieeexplore
10.1109/SBRN.1998.730998,A neural-network based approach for recognition of pose and motion gestures on a mobile robot,IEEE,Conferences,"Since a variety of changes in both robotic hardware and software suggests that service robots will soon become possible, to find ""natural"" ways of communication between human and robots is of fundamental importance for the robotic field. The paper describes a gesture-based interface for human-robot interaction, which enables people to instruct robots through easy-to-perform arm gestures. Such gestures might be static pose gestures, which involve only a specific configuration of the person's arm, or they might be dynamic motion gestures, that is, they involve motion (such as waving). Gestures are recognized in real-time at approximate frame rate, using neural networks. A fast, color-based tracking algorithm enables the robot to track and follow a person reliably through office environments with drastically changing lighting conditions. Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned, and the robot picks up trash which it then delivers to the nearest trash-bin.",https://ieeexplore.ieee.org/document/730998/,Proceedings 5th Brazilian Symposium on Neural Networks (Cat. No.98EX209),9-11 Dec. 1998,ieeexplore
10.1109/IJCNN.2015.7280750,A neurocomputational model implemented on humanoid robot for learning action selection,IEEE,Conferences,"Computational modeling of neural circuits enhances our comprehension of brain functions. In addition to the simulation of the models which helps to anticipate cognitive processes, embodiment of these models is essential. Such embodiment would provide the setting to explain neural functioning ongoing in real environments under oncoming sensory information besides giving opportunity of implementation of intelligent systems. Even studies pursued in neuroscience seem far from achieving all these aims in intelligent systems, the pre-results using cognitive models are faster than animal experiments in leading further the understanding of cognitive processes and designing related experiments. In this study, a computational model of basal ganglia, thalamus and cortex for action selection is extended with the point neuron approach to obtain a more realistic method to investigate the model in real time task on humanoid robot platform, Darwin-Op. The spiking neural network model of cortex consists of channels for each action to be elected and plastic alI-to-alI connections from the sensory stimuli to the basal ganglia structures which are modulated with reward. In the task, the sensory inputs, namely colors, are presented to the humanoid robot and it is expected that these sensory inputs would be associated with the predefined actions by modulating the connections. Furthermore, the rearrangement of these associations with reward is performed after learning is accomplished. In this way, the embodiment of computational-model provided more information on the evolution of connections through reward based learning in the action selection circuit.",https://ieeexplore.ieee.org/document/7280750/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ICRoM.2015.7367862,A new adaptive neural network based observer for robotic manipulators,IEEE,Conferences,"In this paper, a new neural network based observer is proposed for a class of nonlinear systems. The proposed observer can applied to estimate nonlinear systems with a high nonlinearity without any prior knowledge about system. This features help the proposed neuro-observer for real implementation and to use it in practice. The Lyapunov's direct method employed to show the stability and estimating performance of the proposed scheme. Simulation results on a two DOF robot manipulator are presented to show the efficiency of the proposed neural network based observer.",https://ieeexplore.ieee.org/document/7367862/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/HAPTICS.2014.6775492,A novel haptic interface and control algorithm for robotic rehabilitation of stoke patients,IEEE,Conferences,"Rehabilitation robots are gradually becoming popular for stroke rehabilitation to improve motor recovery. By using a robot, the patient may perform the training more frequently on their own, but they must be motivated to do so. Therefore, this project develops a set of rehabilitation training programs with different haptic modalities on Compact Rehabilitation Robot (CR2) - a robot used to train upper and lower limbs reaching movement. The paper present the developed haptic interface, Haptic Sense with five configurable haptic modalities that include sensations of weight, wall, spring, sponge and visual amplification. A combination of several haptic modalities was implemented into virtual reality games, Water Drop - a progressive training game with up to nine levels of difficulties that requires user to move the cup to collect the water drops.",https://ieeexplore.ieee.org/document/6775492/,2014 IEEE Haptics Symposium (HAPTICS),23-26 Feb. 2014,ieeexplore
10.1109/ICMLC.2011.6016883,A novel intelligent control system design for a humanoid robot,IEEE,Conferences,"This paper presents the design of an intelligent control system for a humanoid robot. A novel fuzzy cerebellar model articulation controller (FCMAC) is proposed; this controller incorporates the fuzzy system inference rule with a CMAC fast learning ability. This FCMAC is a generalization network; in some special cases it can be reduced to a fuzzy neural network or a CMAC. This FCMAC is used as the main controller for the trajectory tracking control of the robot. In this robotic system, an inertial navigation system (INS) including gyroscopes and accelerometers is used to measure the robot's attitude and acceleration for modifying the dynamic attitude of the robot. Moreover, a zero moment point (ZMP) compensator is used to on-line adjust the gait trajectories to improve the walking stability. The control system is implemented based on system on a programmable chip (SoPC) technology. Thus, this intelligent control system can achieve real-time on-line closed-loop feedback control of the humanoid robot. Experimental results show that the developed system can achieve favorable control performance for a high-order nonlinear humanoid robot.",https://ieeexplore.ieee.org/document/6016883/,2011 International Conference on Machine Learning and Cybernetics,10-13 July 2011,ieeexplore
10.1049/cp:19940180,A novel neural adaptive controller for robots,IET,Conferences,"Existing industrial robotic manipulators have proven to be limited in many applications, e.g. both their payload capability and manipulation speeds are limited. This paper presents a novel neural adaptive controller-intelligent gain scheduling-(IGS) for robotic manipulators. It advances the idea of mapping the nonlinear relationship between robot working conditions (e.g. payload, speed, etc.) and its controller gains. This scheme is simple, inexpensive, and especially, attractive for its possible implementation in real-time. Simulation has shown promising results.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/327097/,1994 International Conference on Control - Control '94.,21-24 March 1994,ieeexplore
10.1109/PEAM.2011.6135058,A novel on-line training solution using a Radial Basis Function Network to modify the inverse kinematic approximation of a robot-vision system,IEEE,Conferences,"This paper describes a new practical approach for approximating the inverse kinematics of a manipulator using an RBFN (Radial Basis Function Network). This neural network with its inherent learning ability can be an effective alternative solution for the inverse kinematics problem where traditional methods are impractical because the manipulator geometry cannot be easily determined, e.g. in a robot-vision system. However, sometimes a well-trained network cannot work effectively in the operational phase because the initial network training occurs in an environment that is not exactly the same as the environment where the system is actually deployed. In this paper, an on-line retraining solution using the Delta rule is presented for systems whose characteristics change due to environmental variations. Moreover, a “free interference rule” is also suggested to avoid learning interference where the training effect of a current training point may upset some of the weights which were trained with previous points. To verify the performance of the proposed approach, a practical experiment has been performed using a Mitsubishi PA10-6CE manipulator observed by a webcam. All application programmes, such as robot servo control, neural network, and image processing tool, were written in C/C++ and run in a real robotic system. The experimental results prove that the proposed approach is effective.",https://ieeexplore.ieee.org/document/6135058/,2011 IEEE Power Engineering and Automation Conference,8-9 Sept. 2011,ieeexplore
10.1109/ICSMC.1999.812484,A paradigm for intelligent motion planning of robot manipulators,IEEE,Conferences,"A paradigm for intelligent motion planning of robot manipulators is presented, and its implementation by some unconventional (AI, soft computing, computational intelligence) techniques is outlined. The article focuses on those aspects that lead, from an intelligent/unconventional point of view, to a unified framework for real-time motion planning, singularities prevention, and/or pseudoinverse robustness.",https://ieeexplore.ieee.org/document/812484/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/IJCNN.2003.1223697,A performance comparison of TRACA - an incremental on-line learning algorithm,IEEE,Conferences,"TRACA (Temporal Reinforcement-learning and Classification Architecture) is a learning system intended for robot-navigation tasks. One problem in this area is input-generalisation. Input generalisation requires learning a small set of internal states which represent useful abstractions of the much larger set of actual states. As such, the input-generalisation problem is fundamentally similar to the classical problems of classification, concept learning and discrimination. The priorities when evaluating a system for on-line robot learning include a small number of trials, predictive accuracy and minimal parameter tuning. Other requirements are the ability to learn without predefined classes (i.e. classes must be learned during training) and an efficient and adaptable representation. This paper evaluates the performance of TRACA, a new learning algorithm, on a number of common classification tasks. The same set of parameters is used to obtain all TRACA's results, which are then compared to the results obtained by other well-known algorithms. On most tasks, TRACA's predictive accuracy is within a few percent of the best performing systems compared. Furthermore, TRACA's result is often achieved with less training experience. In a final experiment TRACA is trialled on a robot navigation task that requires discrimination of a number of discrete locations.",https://ieeexplore.ieee.org/document/1223697/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2014.7090487,A portable stand-alone bi-hemispherical neuronal network model of the cerebellum for adaptive robot control,IEEE,Conferences,"Development of computational models of the brain is relevant not only for deepening our understanding of the biological system but also for potential applications to various engineering problems. In this paper the implementation of a bi-hemispherical neuronal network model of the cerebellum (biCNN) in a stand-alone, portable real time (RT) device is presented. The biCNN is tested during a control engineering application, namely, control of a highly unstable two-wheel balancing robot. The RT device considered is the National Instruments myRIO-1900, which provides flexibility and portability to the biCNN. Execution times obtained with the RT device are compared with a personal computer implementation as reference. The results demonstrate the suitability of the RT implementation of the biCNN for robot control, and provide a successful bridge between the cerebellar research and engineering.",https://ieeexplore.ieee.org/document/7090487/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/ICCAS.2015.7364829,A precise position control of robot manipulator with eight joints,IEEE,Conferences,"We describe a new approach to the design and real-time implementation of an adaptive controller for robotic manipulator based on digital signal processors in this paper. The Texas Instruments DSPs(TMS320C80) chips are used in implementing real-time adaptive control algorithms to provide enhanced motion control performance for dual-arm robotic manipulators. In the proposed scheme, adaptation laws are derived from model reference adaptive control principle based on the improved direct Lyapunov method. The proposed adaptive controller consists of an adaptive feed-forward and feedback controller and time-varying auxiliary controller elements. The proposed control scheme is simple in structure, fast in computation, and suitable for real-time control. Moreover, this scheme does not require any accurate dynamic modeling, nor values of manipulator parameters and payload. Performance of the proposed adaptive controller is illustrated by simulation and experimental results for robot manipulator consisting of dual arm with four degrees of freedom at the joint space and cartesian space.",https://ieeexplore.ieee.org/document/7364829/,"2015 15th International Conference on Control, Automation and Systems (ICCAS)",13-16 Oct. 2015,ieeexplore
10.1109/IROS.1998.727453,A real-time library for the design of hybrid robot control architectures,IEEE,Conferences,"Describes a real-time library providing facilities useful in the design of robot control architectures. The library supports structured creation of reactive and deliberative modules, dynamic modification of relevant real-time parameters, generation of timing fault handlers, measurement and monitoring of execution times. This support enables adaptation of the rate of computation of real-time modules to the rate of change of the external world, and hence better tuning of robot behavior to the world uncertainty and dynamics. The real-time library has been put to work by designing a hybrid control architecture for a robot performing a kitting task. In the prototype experiment described in the paper, a Puma 560 robot manipulator is fed with parts by a small mobile robot. The control architecture governing Puma operations dynamically allocates computational resources to reactive and deliberative modules, according to the task level priorities.",https://ieeexplore.ieee.org/document/727453/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ICAMechS.2013.6681701,A real-time walking robot control system based on Linux RTAI,IEEE,Conferences,"This study developed a real-time control system for a walking robot. The control system for the walking robot should have a real-time operating system, a small size, and extendable IO cards. The PC104 computer is selected due to its small size, reliability and availability of many IO cards. The Linux RTAI is selected because it is an open-source, efficient and hard real-time operating system. The Turbo PMAC PC104 card is used to control motor drivers because its small size, multi-axis synchronization and powerful control functions. Compared with CAN or EtherCAT bus control scheme, this system can easily support motor drivers from different companies. The software is reusable to different robots due to its independence on communication bus protocols and motor drivers. The motor control experiments are provided to show the satisfactory real-time control performance.",https://ieeexplore.ieee.org/document/6681701/,Proceedings of the 2013 International Conference on Advanced Mechatronic Systems,25-27 Sept. 2013,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/TENCON.2000.888756,A review of real-time software engineering methodologies for developing a wall-climbing robot control firmware,IEEE,Conferences,"Designing and developing software for autonomous robot control system is a challenging task. Issues related to real-time control, embedded system and artificial intelligence are involved in the software development process. This type of software must be developed with proper software methodology or well-defined development process in order to increase the productivity and quality of the software design and software products. This paper presents a review of two real-time software development methodologies and compares their suitability for developing real-time control software for a wall-climbing robot under development at Universiti Teknologi Malaysia (UTM).",https://ieeexplore.ieee.org/document/888756/,2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119),24-27 Sept. 2000,ieeexplore
10.1049/cp.2012.0975,A robot dance system based on real-time beat prediction,IET,Conferences,"In this paper, we present a robot with a system of tracking beats and downbeats from musical audio in real time as well as automatically synthesizing dance motions synchronized to the extracted musical events. And a real-time beat prediction approach improved by an off-line analysis is described, which has positive effects on the estimations of beat and downbeat. We also make an attempt to solve the problem of enabling a robot to understand the played music and accomplish dance compositions intelligently itself. Consequently, the experimental results are quite encouraging and show that our implemented robot, to some extent, has the ability of dancing in time to the music.",https://ieeexplore.ieee.org/document/6492582/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/MFI-2003.2003.1232590,A robust real time position and force (hybrid) control of a robot manipulator in presence of uncertainties,IEEE,Conferences,"We examine the living intelligent biological systems and model the computational system components. We consider the situation of a kind of ""blind-tracking"" with constant force/torque by a human hand. The problem involves hand kinematics, hand motor control, and an adaptive judgment method from the position and force/torque reflection of the uncertain hyper plane. In this study, these control levels were designed using neural networks and fuzzy logic technologies. The control levels are coordinated amongst themselves forming the distributed artificial intelligent (DAI) system. The conclusive characteristic of the proposed controller was a one-step-ahead feedback control. This DAI-based control systems was implemented in the RX-90 industrial robot. Certainly these types of control system will help an industry to be autonomous and increase the productivity as well.",https://ieeexplore.ieee.org/document/1232590/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/EMWRTS.1994.336860,A software architecture for telerobotics,IEEE,Conferences,"Describes a currently developed software architecture for telerobotics, based on a high-level and interpreted language, PILOT (Programming and Interpreted Language Of actions for Telerobotics), allowing one to plan the actions of a robot. Such a language allows the operator to modify a mission during its execution. A software architecture is developed for this language, and is composed of four modules which manage different aspects of plan execution.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/336860/,Proceedings Sixth Euromicro Workshop on Real-Time Systems,15-17 June 1994,ieeexplore
10.1109/WCICA.2000.863460,A study on a new robot simulation and monitoring system based on PC,IEEE,Conferences,"A new robot simulation and monitoring system has been developed. Running on Pentium II PCs with Windows 95 operation system and being developed with OpenGL, this system has the capacity of real-time simulating the motion of an industrial robot through 3D animation with ray tracing. Connected with the robot controller via network, users can monitor the behavior of the robot dynamically or even directly control the action of the robot if necessary. By comparing with the traditional off-line programming system, the framework and the functions of this system and the hardware and software platform of the system are described. The principle of 3D-motion simulation and both the geometry modeling and kinematics modeling are discussed in more detail. Finally, the paper summarizes the characteristics of the system and discusses the extension prospect of the system.",https://ieeexplore.ieee.org/document/863460/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/IJCNN.2004.1379924,A virtual exploring mobile robot for left ventricle contour tracking,IEEE,Conferences,"In this paper we describe a totally new and original approach for combining global and local information in medical image processing. We implemented a virtual mobile robot and trained it using fuzzy neural networks to recognize segments of the myocardium while he navigates autonomously around the left ventricle (LV) of the heart. On its journey around the heart, the virtual exploring robot applies appropriate local edge detection to delineate fully automatically the borders of the myocardium. This may sound unconventional but it has proven effective enough to be integrated in a clinical analytical software tool.",https://ieeexplore.ieee.org/document/1379924/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/IROS.1998.724594,A virtual target approach for resolving the limit cycle problem in navigation of a fuzzy behaviour-based mobile robot,IEEE,Conferences,"A virtual target approach is proposed for resolving the limit cycle problem in navigation of a behaviour-based mobile robot. Starting from the onset point of a possible limit cycle path, the real target is switched to a virtual location and the robot is navigated according to the virtual target set up temporarily and the real environment information sensed, until a switching back condition is reached. The condition for switching back to the real target is established using a specific change in the obstacle information sensed. The algorithm is described together with some particular considerations in implementation. Efficiency and effectiveness of the proposed approach are verified through simulation and experiments conducted with a Nomad 200 robot incorporating a fuzzy, behaviour-based controller.",https://ieeexplore.ieee.org/document/724594/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/FUZZ48607.2020.9177654,AI-FML Agent for Robotic Game of Go and AIoT Real-World Co-Learning Applications,IEEE,Conferences,"In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world.",https://ieeexplore.ieee.org/document/9177654/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/ROBIO.2009.5420410,AMF: A novel reactive approach for motion planning of mobile robots in unknown dynamic environments,IEEE,Conferences,"This paper presents a new approach based on Artificial Potential Fields (APF) which provides real-time and very effective methodology for practical motion planners in unknown dynamic environments. The Maxwell's equations are exploited to define Artificial Magnetoquasistatic Fields (AMF) as an extension of APF, which provides a predictive, intelligent, and natural behavior in contrast with other approaches. The essential aim of the AMF is dealing with moving obstacles, as well as static ones. The main idea is to consider an electrical current in the direction of each moving obstacle which induces magnetic field around it. These moving obstacles could be arbitrary in shape, size, and number. Neither the motion-trajectory of the moving obstacles nor the model of their motion is known. The only available information is their instantaneous velocity at each time step. In this method, the magnetoquasistatic approximation is used to obtain the electric and magnetic fields around robot. Next, using Lorentz equation, the necessary force can be calculated which should be applied to robot to avoid the collision with obstacles. A path planner based on this approach has been implemented and tested by various scenarios containing both static and moving obstacles. Simulations and experimental results illustrate the efficacy of the proposed method.",https://ieeexplore.ieee.org/document/5420410/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/ISCAS.2019.8702353,AR-C3D: Action Recognition Accelerator for Human-Computer Interaction on FPGA,IEEE,Conferences,"In recent years, action recognition has been widely explored and attains significant performance improvement. In this paper, we propose a real-time action recognition specified convolutional 3D (AR-C3D) neural network for human-computer interaction. The CNN structure is optimized to decrease the complexity. Furthermore, Winograd algorithm is adopted to accelerate computation. It achieves 89.9% accuracy in the application which refers to the robot classifies the video captured by itself and would either imitate human's action or give verbal feedback. The Artix-7 FPGA implementation result outperforms previous work in terms of resource utilization and no external storage is consumed. One video can be processed in 6.6ms, and the power consumption is only 2.7W.",https://ieeexplore.ieee.org/document/8702353/,2019 IEEE International Symposium on Circuits and Systems (ISCAS),26-29 May 2019,ieeexplore
10.1109/SIBGRAPI.2001.963057,ARENA and WOXBOT: first steps towards virtual world simulations,IEEE,Conferences,"This paper reports new results of a project to build virtual worlds aimed at the graphic simulation of an arena where small mobile robots can perform requested tasks while behaving according to their own motivation and reasoning. Each robot is an intelligent agent that perceives the virtual environment via a simulated vision system and reacts to translating or rotating its body by driving its own wheels. The conception and specification of the robots and the environment are developed to create an open distributed object architecture that could serve as a testbed freely available and ready to use for testing theories in some computational areas such as evolutionary computation, artificial life, pattern recognition, artificial intelligence, cognitive neurosciences and distributed object architectures.",https://ieeexplore.ieee.org/document/963057/,Proceedings XIV Brazilian Symposium on Computer Graphics and Image Processing,15-18 Oct. 2001,ieeexplore
10.1109/WRCSARA53879.2021.9612673,ATFVO: An Attentive Tensor-compressed LSTM Model with Optical Flow Features for Monocular Visual Odometry,IEEE,Conferences,"This paper proposes a new framework called ATFVO which can be deployed on the edge device to resolve monocular visual odometry problem. The vast majority of visual odometry algorithms using deep learning are equivalent to or beyond the traditional visual odometry algorithms in performance, however they do not consider the computing capability of edge equipment. In this paper, convolution neural network (CNN) and attentive tensor-compressed compression LSTM (A-T-LSTM) are used, with optical flow feature as input and a 6-DoF absolute-scale pose as output. The framework is fused with the spatio-temporal feature and deal with the overfitting problem of over-parameterized LSTM with high-dimensional inputs, and utilizes attention mechanism to get poses from the sequence output of T-LSTM. The poses are estimated from the original RGB images sequence without depending on any prior knowledge. The experimental outcomes at the KITTI dataset display that, in compared with the performance of the most advanced methods, the single T-LSTM model is 141× smaller than the original LSTM model, and the entire model is nearly one-seventh of DeepVO with a speed 23× faster than Flowdometry. The proposed VO is deployed to the robot based on raspberry pi, which can achieve real-time inference and navigate a cruise.",https://ieeexplore.ieee.org/document/9612673/,2021 WRC Symposium on Advanced Robotics and Automation (WRC SARA),11-11 Sept. 2021,ieeexplore
10.1109/IEEECONF49454.2021.9382693,Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player,IEEE,Conferences,"This paper presents a sensor-level mapless collision avoidance algorithm for use in mobile robots that map raw sensor data to linear and angular velocities and navigate in an unknown environment without a map. An efficient training strategy is proposed to allow a robot to learn from both human experience data and self-exploratory data. A game format simulation framework is designed to allow the human player to tele-operate the mobile robot to a goal and human action is also scored using the reward function. Both human player data and self-playing data are sampled using prioritized experience replay algorithm. The proposed algorithm and training strategy have been evaluated in two different experimental configurations: Environment 1, a simulated cluttered environment, and Environment 2, a simulated corridor environment, to investigate the performance. It was demonstrated that the proposed method achieved the same level of reward using only 16% of the training steps required by the standard Deep Deterministic Policy Gradient (DDPG) method in Environment 1 and 20% of that in Environment 2. In the evaluation of 20 random missions, the proposed method achieved no collision in less than 2 h and 2.5 h of training time in the two Gazebo environments respectively. The method also generated smoother trajectories than DDPG. The proposed method has also been implemented on a real robot in the real-world environment for performance evaluation. We can confirm that the trained model with the simulation software can be directly applied into the real-world scenario without further fine-tuning, further demonstrating its higher robustness than DDPG. The video and code are available: https://youtu.be/BmwxevgsdGc https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance.",https://ieeexplore.ieee.org/document/9382693/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ICTAI.2019.00249,Accurate and Robust RGB-D Dense Mapping with Inertial Fusion and Deformation-Graph Optimization,IEEE,Conferences,"RGB-D dense mapping has become more and more popular, however, when encountering rapid movement or shake, the robustness and accuracy of most RGB-D dense mapping methods are degraded and the generated maps are overlapped or distorted, due to the drift of pose estimation. In this paper, we present a novel RGB-D dense mapping method, which can obtain accurate, robust and global consistency map even in the above complex conditions. Firstly, the improved ORBSLAM method, which tightly-couples RGB-D information and inertial information to estimate the current pose of robot, is firstly introduced for accurate pose estimation rather than traditional frame-to-frame method in most RGB-D dense mapping methods. Besides, the TSDF (Truncated Signed Distance Function) method is used to effectively fuse depth frame into a global model, and to keep the global consistency of the generated map. Furthermore, since the drift error is inevitable, a deformation graph is constructed to minimize the consistent error in global model, to further improve the mapping performance. The performance of the proposed RGB-D dense mapping method was validated by extensive localization and mapping experiments on public datasets and real scene datasets, and it showed strongly accuracy and robustness over other state-of-the-art methods. What's more, the proposed method can achieve real-time performance implemented on GPU.",https://ieeexplore.ieee.org/document/8995400/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/IROS.2004.1389844,Acquisition of human-robot joint attention through real-time natural interaction,IEEE,Conferences,"Joint attention, a process to attend to the object that the other attends to is supposed to be important for human-robot communication as well as for human-human communication. We propose an architecture for acquiring joint attention within a certain time period for realizing natural human-robot interaction. The architecture has two featured modules: a self-organizing map that makes the leaning time shorter and an automatic visual attention selector that let the agent communicate with a human synchronously. We implemented the proposed architecture in a real robot agent and found that 30 minutes was enough for acquiring joint attention with two objects. We can conclude from preliminary experiments that even if the gaze preference of the robot is different from that of the human caregiver, it can acquire joint attention.",https://ieeexplore.ieee.org/document/1389844/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/DEVLRN.2002.1011736,Action chaining by a developmental robot with a value system,IEEE,Conferences,"A developmental cognitive learning architecture with a value system is proposed for an artificial agent to learn composite behaviors upon the acquisition of basic ones. This work is motivated by researches on classical conditioning in animal learning areas. Compared to former works, the proposed architecture enables an agent to conduct learning in unknown environments through online realtime experiences. All possible perceptions and actions, including even the actual number of classes, are not available until the programming is finished and the robot starts to learn in the real world. Experiments with our SAIL (Self-organizing Autonomous Incremental Learner) robot are reported to show how a trainer instructed (or shaped) the behaviors of the agent through verbal commands.",https://ieeexplore.ieee.org/document/1011736/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/ISCIS.2009.5291811,Active humanoid vision and object classification,IEEE,Conferences,"In this paper we study object learning and recognition on a humanoid robot with foveated vision. The developed approach is view-based and can learn viewpoint-independent representations for object recognition. The training data is collected statistically and in an interactive way where a human instructor freely shows the object from a number of different viewpoints. The proposed system was fully implemented and runs in real-time, which is essential for meaningful interaction with a humanoid robot.",https://ieeexplore.ieee.org/document/5291811/,2009 24th International Symposium on Computer and Information Sciences,14-16 Sept. 2009,ieeexplore
10.1109/FUZZ-IEEE.2014.6891705,Active interaction control of a rehabilitation robot based on motion recognition and adaptive impedance control,IEEE,Conferences,"Although electromyography (EMG) signals and interaction force have been widely used in patient cooperative or interactive training, the conventional EMG based control usually breaks the process into a patient-driven phase and a separate passive phase, which is not desirable. In this research, an active interaction controller based on motion recognition and adaptive impedance control is proposed and implemented on a six-DOFs parallel robot for lower limb rehabilitation. The root mean square (RMS) features of EMG signals integrating with the support vector machine (SVM) classifier were used to online predict the lower limb intention in advance and to trigger the robot assistance. The impedance control strategy was adopted to directly influence the robot assistance velocity and allow the exercise to follow a physiological trajectory. Moreover, an adaptive scheme learned the muscle activity level in real time and adapted the robot impedance in accordance with patient's voluntary participation efforts. Experimental results on several healthy subjects demonstrated that the lower limb motion intention can be precisely predicted in advance, and the robot assistance mode was also adjustable based on human-robot interaction and muscle activity level of subjects. Comparing with the conventional EMG-triggered assistance methods, such a strategy can increase patient's motivation because the subject's movement intention, active efforts as well as the muscle activity level changes can be directly reflected in the trajectory pattern and the robot assistance speeds.",https://ieeexplore.ieee.org/document/6891705/,2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),6-11 July 2014,ieeexplore
10.1109/FPA.1994.636089,"Active perception, navigation, homing, and grasping: an autonomous perspective",IEEE,Conferences,"Perception is needed for action, not for the pure sake of the construction of abstract representations, although it does not exclude the role of internal representations for mediating complex behaviours. We think that, for the purpose of building autonomous robots, active perception requires specific recipes for three related aspects: the design of the physical sensory system, the modality and type of information extracted, and the structure and functioning of the control system. We outline a set of solutions for these three aspects and describe their implementation on a real mobile robot through a set of three different experiments using a combination of neural networks and genetic algorithms. The results show that active perception is a useful feature that is exploited by autonomous agents. The experiments shout that the combination of genetic algorithms and neural networks is a feasible and fruitful technique for the development of active perception in autonomous agents.",https://ieeexplore.ieee.org/document/636089/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/ROBOT.2009.5152428,Active-learning assisted self-reconfigurable activity recognition in a dynamic environment,IEEE,Conferences,"It is desirable to know a resident's on-going activities before a robot or a smart system can provide attentive services to meet real human needs. This work addresses the problem of learning and recognizing human daily activities in a dynamic environment. Most currently available approaches learn offline activity models and recognize activities of interest on a real time basis. However, the activity models become outdated when human behaviors or device deployment have changed. It is a tedious and error-prone job to recollect data for retraining the activity models. In such a case, it is important to adapt the learnt activity models to the changes without much human supervision. In this work, we present a self-reconfigurable approach for activity recognition which reconfigures previously learnt activity models and infers multiple activities under a dynamic environment meanwhile pursuing minimal human efforts in relabeling training data by utilizing active-learning assistance.",https://ieeexplore.ieee.org/document/5152428/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ICRoM.2014.6990997,Actor-critic neural network reinforcement learning for walking control of a 5-link bipedal robot,IEEE,Conferences,"Today, researches on adaptive control have focused on bio-inspired learning techniques to deal with real-life applications. Reinforcement Learning (RL) is one of these major techniques, which has been widely used in robot control tasks recently. On the other hand, artificial neural networks are an accurate approximation tool in nonlinear robotic dynamic control tasks. In this paper, our main goal was to combine the advantages of the artificial neural networks and the RL to reduce the learning time length and enhance the control accuracy. Therefore, we have implemented one of the promising RL approaches, actor-critic RL to control the actuation torques of a planar five-link bipedal robot and retain the passive torso in the vertical position. Our control agent consists of two three-layered neural network units, known as the critic and the actor for learning prediction and learning control tasks. These units are synchronized by the temporal difference error, which implements the eligibility trace vector to assign credit or blame for the error. Moreover, since the neural networks are implemented in both of the actor and the critic sections, we have added a learning database to reduce the probability of inaccurate approximation of the nonlinear functions. Results of our presented control method reveal its perfect performance in stable walking control of the bipedal robot.",https://ieeexplore.ieee.org/document/6990997/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/M2VIP.2017.8211476,Actuation planning and modeling of a soft swallowing robot,IEEE,Conferences,"The paper presents a new methodology to solve the actuation and modelling problems of a soft-bodied swallowing robot (SR), developed for human swallow evaluation. To solve the actuation problem, a central pattern generator (CPG) based novel actuation scheme is developed and implemented to generate peristalsis in the robot. Machine learning based technique is used to determine the governing dynamics of the robot because presently the robot does not have any differential equation to describe its actuation principle or its physics. To profile and sense the peristaltic waveform, a flat version of the robot containing pneumatic chambers for actuation has been proposed to approximate the deformation of the original SR and the CPG actuation scheme is used to command the flat SR so that the pneumatic chambers can be inflated. The logic of actuation is motivated from the swallowing phenomenon in humans, have been implemented in real time. An optical motion detection system (Vicon) is used to track the displacement of the air chambers of the robot and hence, to generate time-series data for determining the governing differential equations of the robot by using l<sub>1</sub> regularised machine learning technique. It is also concluded that the proposed method provides a promising new modelling technique for determining the governing dynamics of the robot where conventional modelling approaches are not applicable.",https://ieeexplore.ieee.org/document/8211476/,2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),21-23 Nov. 2017,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/IROS.2013.6696494,Adaptive collision-limitation behavior for an assistive manipulator,IEEE,Conferences,"An approach for adaptive shared control of an assistive manipulator is presented. A set of distributed collision and proximity sensors is used to aid in limiting collisions during direct control by the disabled user. Artificial neural networks adapt the use of the proximity sensors online, which limits movements in the direction of an obstacle before a collision occurs. The system learns by associating the different proximity sensors to the collision sensors where collisions are detected. This enables the user and the robot to adapt simultaneously and in real-time, with the objective of converging on a usage of the proximity sensors that increases performance for a given user, robot implementation and task-set. The system was tested in a controlled setting with a simulated 5 DOF assistive manipulator and showed promising reductions in the mean time on simplified manipulation tasks. It extends earlier work by showing that the approach can be applied to full multi-link manipulators.",https://ieeexplore.ieee.org/document/6696494/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ICIT.1996.601644,Adaptive robust robot control using BP-SMENs,IEEE,Conferences,"This paper presents the development of a new adaptive recurrent neural network for the control of a nonlinear system represented by a two-link SCARA type planar robot manipulator. The standard backpropagation algorithm is used to adjust the weights of the networks. The proposed control system consists of an inverse neural model of robot (INNM), an INNM-based neural controller, a robust controller, a conventional PI controller, and a second order linear filter. To evaluate the performance of the proposed control scheme and neural network, a simulated SCARA type robot was studied and the results showed how well the proposed controller can minimise the error between an actual and desired end-effector trajectory. From simulation examples, the robot trajectory tracking showed superior performance that is very attractive for real-time implementation and application in complex industrial tasks. For comparison, the standard computed torque method is employed for controlling the robot.",https://ieeexplore.ieee.org/document/601644/,Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96),2-6 Dec. 1996,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/ROMAN.2002.1045593,Advanced autonomous action elements in combination control of remote operation and autonomous control,IEEE,Conferences,"This paper examines the combination control in which remote operation is combined with autonomous behaviors with the aim to realize the remote operation of mobile robot which moves in human-coexisting environment. We consider the distance and direction to an obstacle and the speed of motion of the mobile robot for revolution, following, and slowdown, which we have proposed as the autonomous action element in combination control. Fuzzy reasoning and vector components are used. From the experiment by three subject persons, almost the same result has been obtained. When the distance and direction to an obstacle and the speed of motion of the mobile robot are considered, there doesn't seem to be a great difference in following, but mileage becomes shorter in revolution and transit time is reduced in slowdown.",https://ieeexplore.ieee.org/document/1045593/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/ETFA.1999.815411,Advanced control techniques based in artificial intelligence for robotics manipulators,IEEE,Conferences,"The performance quality in nonlinear model based control of mechanical manipulators is conditioned to the reliability of the mathematical model and precision in the knowledge of all the involved parameters. Control methods based on artificial intelligence techniques (learning algorithms, system identification and neural networks) can be applied to improve its performance. A neural control scheme is proposed, consisting basically of a neural network for learning the robot inverse dynamics and online generating the control signal. Also an online supervision based on optimisation techniques is designed and implemented for such neural control. Simulation results are provided to evaluate the alternative variations to the proposed central scheme.",https://ieeexplore.ieee.org/document/815411/,1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467),18-21 Oct. 1999,ieeexplore
10.1109/TAI.1994.346494,Advanced fuzzy control of a trailer type mobile robot-stability analysis and model-based fuzzy control,IEEE,Conferences,"In a previous paper (see ""A Robust Stabilization Problem of Fuzzy Controller Systems and Its Applications to Backing up Control of a Truck-Trailer"", IEEE Trans. on Fuzzy Systems, Vo1.2, no.2, p.119-34, 1994), we designed a control system for backing up a computer simulated trailer type mobile robot, which is non-linear and unstable, by applying a robust stabilization technique for fuzzy systems. Furthermore, we have shown that the designed fuzzy controller smoothly achieves backing up control of the computer simulated trailer type mobile robot from all initial positions. We control a real trailer type mobile robot by applying the design method proposed previously. The experimental results show that the designed fuzzy controller effectively realize backing up control of the real trailer type mobile robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/346494/,Proceedings Sixth International Conference on Tools with Artificial Intelligence. TAI 94,6-9 Nov. 1994,ieeexplore
10.1109/ICPR.2010.843,Aesthetic Image Classification for Autonomous Agents,IEEE,Conferences,"Computational aesthetics is the study of applying machine learning techniques to identify aesthetically pleasing imagery. Prior work used online datasets scraped from large user communities like Flikr to get labeled data. However, online imagery represents results late in the media generation process, as the photographer has already framed the shot and then picked the best results to upload. Thus, this technique can only identify quality imagery once it has been taken. In contrast, automatically creating pleasing imagery requires understanding the imagery present earlier in the process. This paper applies computational aesthetics techniques to a novel dataset from earlier in that process in order to understand how the problem changes when an autonomous agent, like a robot or a real-time camera aid, creates pleasing imagery instead of simply identifying it.",https://ieeexplore.ieee.org/document/5597531/,2010 20th International Conference on Pattern Recognition,23-26 Aug. 2010,ieeexplore
10.1109/ICRA48506.2021.9562117,Agile Robot Navigation through Hallucinated Learning and Sober Deployment,IEEE,Conferences,"Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination—a feature we call ""sober deployment""—and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",https://ieeexplore.ieee.org/document/9562117/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISCSIC.2017.28,An Adaptive 2D Tracking Approach for Person Following Robot,IEEE,Conferences,"In this paper, we present a 2D appearance vision based tracking approach for human following robot. Generally, existing methods have high cost of computing and requirements of hardware which makes the difficulty of employing the function on service robot. Hence, minimizing the cost of tracking with slight loss of precision can benefit this area. We focus on approach based on 2D image data which reduce tracking into two dimensions and can minimize the cost of computation. Our approach presents a corporate strategy which utilizes central consensus of correspondence for 2D feature points pairwise to track and employ a semi-supervised learning detector to update appearance change. To overcome difficulties from environment change, we set an enhancing process for feature points and background segmentation through depth information. We carefully evaluate our approach with common challenges of visual tracking in static view and deploy a dynamic view a real-world following task. The experiment results illustrate that our tracking approach works against common risks at 2D appearance tracking and properly follows the user obtaining 25 fps performance on mobile platform.",https://ieeexplore.ieee.org/document/8294176/,2017 International Symposium on Computer Science and Intelligent Controls (ISCSIC),20-22 Oct. 2017,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/WCICA.2006.1713761,An Embedded Platform for Intelligent Mobile Robot,IEEE,Conferences,"To overcome the limitations of the special architectures adopted by traditional industrial robots, an embedded intelligent robot platform based on Windows CE.NET is established by customizing the operating system. On this intelligent robot platform, all major necessary sensors are included, and abundant control interfaces and driver modules are available, such as movement control interface, USB camera driver, laser driver, etc. Besides, various testing software and application modules for intelligent robot are designed, such as multi-sensor data fusion, path planning, speech recognition, wireless network communication and graphic human-robot interface. The platform is modularized, extensible, transplantable and customizable. Compared to the previous robot platform, it also has many advantages such as more compact hardware, lower-power consumption, better real-time performance and higher reliability",https://ieeexplore.ieee.org/document/1713761/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/ISCAS.2019.8702113,An Energy Efficient System for Touch Modality Classification in Electronic Skin Applications,IEEE,Conferences,"Electronic-skin aiming to mimic human skin is becoming a reality and systems able to process data close to the sensors are required to reduce latency and power consumption. This paper presents the design and implementation of an energy efficient smart system for tactile sensing based on a RISC-V parallel ultra-low power platform (PULP). The PULP processor, called Mr. Wolf, performs the on-board classification of different touch modalities. This demonstrates the promising use of on-board classification for emerging robot and prosthetic applications. Experimental results demonstrate the effectiveness of the platform on improving the energy efficiency of the online classification. In our experiments, Mr. Wolf runs 3.6 times faster than an ARM Cortex M4F (STM32F40), consuming only 28 mW. The proposed platform achieves 15× better energy efficiency, than the classification done on the STM32F40, consuming only 81mJ per classification.",https://ieeexplore.ieee.org/document/8702113/,2019 IEEE International Symposium on Circuits and Systems (ISCAS),26-29 May 2019,ieeexplore
10.1109/ICTAI.2015.111,An Environment Visual Awareness Approach in Cognitive Model ABGP,IEEE,Conferences,"ABGP is a special cognitive model, which consists of awareness, beliefs, goals and plans. As most agent architectures, ABGP agents obtain knowledge from the natural scenes only through single preestablished rules as well, don't directly capture the natural scenes information like human visual. Inspired by the biological visual cortex (V1) and the higher brain areas perceiving visual features, we propose a novel deep network model convolutional generative stochastic model (CGSM) used to visual feature representation, and firstly introduce it into the awareness module of the cognitive model ABGP to construct a state-of-the-art cognitive model ABGP-CGSM. For the novel cognitive model ABGP-CGSM, we construct a rat-robot maze search simulation platform to show the validity recognizing natural scenes. According to the simulation results on the noise and noiseless natural scenes, the rat-robot implemented by ABGP-CGSM has an excellent success rate when passing through the maze. The simulation shows that the ABGP-CGSM model proposed in our work can directly enhance the capability of communication between agent and natural scenes, improve the ability to cognize the real world as human being and conduct the agent to plan independently its path in terms of the visual information from the natural scenes.",https://ieeexplore.ieee.org/document/7372207/,2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2015,ieeexplore
10.1109/COASE.2018.8560532,An EtherCAT-Based Real-Time Control System Architecture for Humanoid Robots,IEEE,Conferences,"The design of humanoid robots naturally requires the simultaneous control of a high number of joints. Moreover, the performance of the overall robot is strongly determined by the low-level control system as all high-level software e.g. for locomotion planning and control is built on top of it. In order to achieve high update rates and high bandwidth for the joint control, an advanced real-time control system architecture is required. However, outdated communication protocols with associated limits in the achievable update rates are still used in nowadays humanoid robots. Moreover, the performance of the low-level control systems is not analyzed in detail or the systems rely on specialized hardware, which lacks reliability and persistence. We present a reliable and high-performance control system architecture for humanoid robots based on the ETHERCAT technology. To the authors' knowledge this is the only system, which operates at control rates beyond 2 khz and input/output latencies below 1 ms. Our control architecture includes a learning-based feedforward control strategy to improve joint tracking performance. The improved joint control method and the communication system are evaluated on our humanoid robot LOLA. Our software framework is available online to allow other researchers to benefit from our experiences.",https://ieeexplore.ieee.org/document/8560532/,2018 IEEE 14th International Conference on Automation Science and Engineering (CASE),20-24 Aug. 2018,ieeexplore
10.1109/ROBIO.2006.340133,An Extension of the Distance-Propagating Dynamic System for Robot Path Planning to Safe Obstacle Clearance,IEEE,Conferences,"In this paper we extend our previously presented efficient distance-propagating dynamic system for real-time robot path planning in dynamic environments to the case where safety margins around obstacles are included. Inclusion of safety margins approximately triples the number of arithmetic operations, however, the distance-propagating dynamic system is still very computationally efficient. The algorithm uses a grid representation of the environment, which need not be regular, and is applicable to dynamic environments where both targets and obstacles are permitted to move. No prior knowledge of target or obstacle movement is assumed. Safety margins around obstacles are implemented as ""soft"" margins defined by local penalty functions around obstacles which represent the extra distance the robot is willing to travel in order to avoid passing through this margin. The path through which the robot travels minimizes the sum of the current known distance to a target and the cumulative local penalty functions along the path. The effectiveness of the algorithm is demonstrated through a number of simulations.",https://ieeexplore.ieee.org/document/4142070/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/WCICA.2006.1713159,An Improved Q-learning Algorithm Based on Exploration Region Expansion Strategy,IEEE,Conferences,"In order to find a good solution to one of the key problems in Q-learning algorithm - keeping the balance between exploration and exploitation, an improved Q-learning algorithm based on exploration region expansion strategy is proposed on the base of Metropolis criterion-based Q-learning. With this strategy, the exploration blindness in the entire environment is eliminated, and the learning efficiency is increased. Meanwhile, other feasible path is sought where agent encounters obstacles, which makes the implementation of the algorithm on real robot easy. An automatic termination condition is also put forward, therefore, the redundant learning after finding optimal path is avoided, and the time of learning is reduced. The validity of the algorithm is proved by simulation experiments",https://ieeexplore.ieee.org/document/1713159/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/KCIC.2018.8628468,An Incremental Episodic Memory Framework for Topological Map Building,IEEE,Conferences,"In this paper, an episodic memory learning framework is proposed for categorizing and encoding sensory information that acquired from a robot for environment adaptation and sensorimotor map building. The proposed learning model termed as Incremental Episodic Memory Adaptive Resonance Theory (In-EMART), consists two layers of ART networks which used to detect novel event encountered by the robot and learn the spatio-temporal relationship by creating neurons incrementally. A set of connected episodes forms a sensorimotor map that can be used for path planning and goal navigation autonomously. The experimental results for a mobile robot show that: (i) In-EMART can learn sensory data in real time which is important for robot implementation; (ii) the model solves the perceptual aliasing issue by recalling the connected episode neurons; (iii) compared with previous works, the proposed method further generates a sensorimotor map for connecting episodes together to navigate from one place to another continuously.",https://ieeexplore.ieee.org/document/8628468/,2018 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC),29-30 Oct. 2018,ieeexplore
10.1109/ROBOT.2010.5509310,An Inertia-Based Surface Identification System,IEEE,Conferences,"In many robotics applications, knowing the material properties around a robot is often critical for the robot's successful performance. For example, in mobility, knowledge about the ground surface may determine the success of a robot's gait. In manipulation, the physical properties of an object may dictate the results of a grasping strategy. Thus, a reliable surface identification system would be invaluable for these applications. This paper presents an Inertia-Based Surface Identification System (ISIS) based on accelerometer sensor data. Using this system, a robot actively “knocks” on a surface with an accelerometer-equipped device (e.g., hand or leg), collects the accelerometer data in real-time, and then analyzes and extracts three critical physical properties, the hardness, the elasticity, and the stiffness, of the surface. A lookup table and k-nearest neighbors techniques are used to classify the surface material based on a database of previously known materials. This technique is low-cost and efficient in computation. It has been implemented on the modular and self-reconfigurable SuperBot and has achieved high accuracy (95% and 85%) in several identification experiments with real-world material.",https://ieeexplore.ieee.org/document/5509310/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/CCDC49329.2020.9164059,An Integration-Enhanced Noise-Resistant RNN Model with Superior Performance Illustrated via Time-Varying Sylvester Equation Solving,IEEE,Conferences,"The Sylvester equation plays a fundamental role in the control system, e.g, which can be applied to inverse-kinematic motion control problem in robot manipulators through a certain conversion. Considering the incompatibility of most existing Sylvester equation solving schemes on noise and the inevitability of noise in real life, by defining a new matrix-valued error function, an integration-enhanced noise-resistant recurrent neural network (IENRRNN) is generalize to the time-varying Sylvester equation solving in this paper. The convergence of the IENRRNN model under both the model implementation error and differential error of coefficient matrices are investigated. What's more, from both convergence speed and convergence quality, effects of three activation functions on the computational errors achieved by the IENRRNN are evaluated. The influences of different design parameters on them are also discussed. Finally, with MATLAB, the effectiveness of the IENRRNN model for online solving the considered equation and its superiority compared to the traditional zeroing neural network (ZNN) model are demonstrated by simulative results.",https://ieeexplore.ieee.org/document/9164059/,2020 Chinese Control And Decision Conference (CCDC),22-24 Aug. 2020,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/ROMAN.2018.8525668,An Ontology-based Home Care Service Robot for Persons with Dementia,IEEE,Conferences,"In this paper, we introduce an ontology-based home care service robot that can provide personalized care for people who are in the early stage of dementia. The hardware and software framework encompassed in the proposed service robot was developed to carry out care services in their daily life at home. Specifically, to generate adaptive task plans in diverse caring situation, context reasoner and ontological model of dementia are included. Ontology includes various concepts that are related with the knowledge of caring dementia patient: dementia, dementia symptom, environment of around patient, and situation during patient's daily life. To evaluate if the proposed service robot could provide appropriate care service or not, experimental care scenario for helping a person with dementia take medicine was tried in the lab environment. Although tasks of the robot required for the experiment are rather simple, we have demonstrated that the robot could provide a personalized service that may be beneficial to dementia patient, family members and caregivers. In the future, we will add more care knowledge in the ontology and further develop a variety of care services. Additionally, we are going to test the care service robot in a real environment with actual dementia patient.",https://ieeexplore.ieee.org/document/8525668/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ROMAN.2012.6343892,An active audition framework for auditory-driven HRI: Application to interactive robot dancing,IEEE,Conferences,"In this paper we propose a general active audition framework for auditory-driven Human-Robot Interaction (HRI). The proposed framework simultaneously processes speech and music on-the-fly, integrates perceptual models for robot audition, and supports verbal and non-verbal interactive communication by means of (pro)active behaviors. To ensure a reliable interaction, on top of the framework a behavior decision mechanism based on active audition policies the robot's actions according to the reliability of the acoustic signals for auditory processing. To validate the framework's application to general auditory-driven HRI, we propose the implementation of an interactive robot dancing system. This system integrates three preprocessing robot audition modules: sound source localization, sound source separation, and ego noise suppression; two modules for auditory perception: live audio beat tracking and automatic speech recognition; and multi-modal behaviors for verbal and non-verbal interaction: music-driven dancing and speech-driven dialoguing. To fully assess the system, we set up experimental and interactive real-world scenarios with highly dynamic acoustic conditions, and defined a set of evaluation criteria. The experimental tests revealed accurate and robust beat tracking and speech recognition, and convincing dance beat-synchrony. The interactive sessions confirmed the fundamental role of the behavior decision mechanism for actively maintaining a robust and natural human-robot interaction.",https://ieeexplore.ieee.org/document/6343892/,2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,9-13 Sept. 2012,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/INMIC.2004.1492904,An adaptive clustering method for model-free reinforcement learning,IEEE,Conferences,Machine learning for real world applications is a complex task due to the huge state and action sets they deal with and the a priori unknown dynamics of the environment involved. Reinforcement learning offers very efficient model-free methods which are often combined with approximation architectures to overcome these problems. We present a Q-learning implementation that uses a new adaptive clustering method to approximate state and actions sets. Experimental results for an obstacle avoidance behavior with the mobile robot Khepera are given.,https://ieeexplore.ieee.org/document/1492904/,"8th International Multitopic Conference, 2004. Proceedings of INMIC 2004.",24-26 Dec. 2004,ieeexplore
10.1109/CCECE.1993.332425,An adaptive control scheme for robots with unknown dynamics,IEEE,Conferences,"In this paper, a stable adaptive control scheme for robot manipulators with unknown dynamics is proposed. It consists of an off-line least-mean-square (LMS) type identifier to identify structured system dynamics and an online dynamic compensator to compensating for dynamic uncertainties. Taking advantage of the unique structure of the robot regressor dynamics, the former uses an LMS type algorithm to identify, using a set of trial data, the structured dynamic parameters of the robot while the latter uses an online stable parameter updating mechanism determined using Lyapunov theory to compensate for both unknown and uncertain dynamics. The off-line identified parameters we used as initial values for the online dynamic parameter estimation. Since both identifier and compensator are implemented using the regressor dynamics, the recursive formula, for the computation of robot regressor dynamics previously proposed can be used to achieve high computational efficiency in real-time implementations. An illustrative simulation example is included to show the proposed adaptive control algorithm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/332425/,Proceedings of Canadian Conference on Electrical and Computer Engineering,14-17 Sept. 1993,ieeexplore
10.1109/ETFA46521.2020.9212163,An adaptive robotic grasping with a 2-finger gripper based on deep learning network,IEEE,Conferences,"In this paper, an adaptive and versatile robotic grasping system is presented that is able to manipulate manufactured objects in production factories with a 2-finger gripper. A pick and place scenario based on deep learning framework is implemented and is achieved based on the following main steps: detection of the manufactured objects in the global scene observed by a first RGB-D camera using a first deep learning network, estimation of the object pose using 2D bounding box coordinates and depth information, motion of the arm above the object in an approach pose using Kinematics and Dynamics Library (KDL), recognition of the object's face using a second deep learning network and information coming from a second RGB-D camera setup on the arm wrist, decision on the optimal grasping mode (opening or closing the fingers), execution of the grasping action. The developed system is validated practically by experiments in real world settings using a mobile manipulator platform consisting of 6 DoF robot arm with a 2-finger gripper setup on a mobile robot equipped by two RGB-D cameras.",https://ieeexplore.ieee.org/document/9212163/,2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),8-11 Sept. 2020,ieeexplore
10.1109/WCICA.2000.859945,An agent team for RoboCup simulator league,IEEE,Conferences,"RoboCup is an attempt to promote AI and robotics research by providing a common task, soccer playing, for evaluation of various theories, algorithms and agent architectures. RoboCup consists of both the real robot league and the simulator league, where the soccer server is a standard software platform. A wide range of key issues on AI research emerges when designing simulator teams, such as the agent architecture, multi-agent teamwork, machine learning, etc. These issues are what we concerned most when developing our simulator team. Our team participated the first RoboCup tournament in China, and won the second place in the competition.",https://ieeexplore.ieee.org/document/859945/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/INDIN.2005.1560420,An analogue recurrent neural network for trajectory learning and other industrial applications,IEEE,Conferences,"A real-time analogue recurrent neural network (RNN) can extract and learn the unknown dynamics (and features) of a typical control system such as a robot manipulator. The task at hand is a tracking problem in the presence of disturbances. With reference to the tasks assigned to an industrial robot, one important issue is to determine the motion of the joints and the effector of the robot. In order to model robot dynamics we use a neural network that can be implemented in hardware. The synaptic weights are modelled as variable gain cells that can be implemented with a few MOS transistors. The network output signals portray the periodicity and other characteristics of the input signal in unsupervised mode. For the specific purpose of demonstrating the trajectory learning capabilities, a periodic signal with varying characteristics is used. The developed architecture, however, allows for more general learning tasks typical in applications of identification and control. The periodicity of the input signal ensures convergence of the output to a limit cycle. Online versions of the synaptic update can be formulated using simple CMOS circuits. Because the architecture depends on the network generating a stable limit cycle, and consequently a periodic solution which is robust over an interval of parameter uncertainties, we currently place the restriction of a periodic format for the input signals. The simulated network contains interconnected recurrent neurons with continuous-time dynamics. The system emulates random-direction descent of the error as a multidimensional extension to the stochastic approximation. To achieve unsupervised learning in recurrent dynamical systems we propose a synapse circuit which has a very simple structure and is suitable for implementation in VLSI.",https://ieeexplore.ieee.org/document/1560420/,"INDIN '05. 2005 3rd IEEE International Conference on Industrial Informatics, 2005.",10-12 Aug. 2005,ieeexplore
10.1109/ICPHYS.2018.8390779,An approach for implementing key performance indicators of a discrete manufacturing simulator based on the ISO 22400 standard,IEEE,Conferences,"Performance measurement tools and techniques have become very significant in today's industries for increasing the efficiency of their processes in order to face the competitive market. The first step towards performance measurement is the real-time monitoring and gathering of the data from the manufacturing system. Applying these performance measurement techniques on real-world industry in a way that is more general and efficient is the next challenge. This paper presents a methodology for implementing the key performance indicators defined in the ISO 22400 standard-Automation systems and integration, Key performance indicators (KPIs) for manufacturing operations management. The proposed methodology is implemented on a multi robot line simulator for measuring its performance at runtime. The approach implements a knowledge-based system within an ontology model which describes the environment, the system and the KPIs. In fact, the KPIs semantic descriptions are based on the data models presented in the Key Performance Indicators Markup Language (KPIML), which is an XML implementation of models developed by the Manufacturing Enterprise Solutions Association (MESA) international organization.",https://ieeexplore.ieee.org/document/8390779/,2018 IEEE Industrial Cyber-Physical Systems (ICPS),15-18 May 2018,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICARCV.2002.1235010,An autonomous mobile robot with fuzzy obstacle avoidance behaviors and a visual landmark recognition system,IEEE,Conferences,"Multi-sensor fusion has been a hot topic in the field of robotics. Inspired by the modern philosophy's spirit, the behavior-based systems interact with the real world directly. In this study, a fully autonomous mobile robot is developed that extracts all its knowledge from physical sensors and expresses all its goals and desires as physical action to affect its environment. The control software implements behavior-based artificial intelligence, where the coordination between various sensors are realized by layers of several simple and primitive behaviors similar to those observed in animals. In the developed mobile robot, each module itself generates behaviors. Behaviors corresponding to different sensors have different priorities, where the vision system has the lowest priority, and the ultrasonic sensors and bumper sensors have higher priority. The effectiveness of the developed system is demonstrated by experimental studies.",https://ieeexplore.ieee.org/document/1235010/,"7th International Conference on Control, Automation, Robotics and Vision, 2002. ICARCV 2002.",2-5 Dec. 2002,ieeexplore
10.1109/INDIN.2017.8104950,An autopilot system based on ROS distributed architecture and deep learning,IEEE,Conferences,"An autopilot system includes several modules, and the software architecture has a variety of programs. As we all know, it is necessary that there exists one brand with a compatible sensor system till now, owing to complexity and variety of sensors before. In this paper, we apply (Robot Operating System) ROS-based distributed architecture. Deep learning methods also adopted by perception modules. Experimental results demonstrate that the system can reduce the dependence on the hardware effectively, and the sensor involved is convenient to achieve well the expected functionalities. The system adapts well to some specific driving scenes, relatively fixed and simple driving environment, such as the inner factories, bus lines, parks, highways, etc. This paper presents the case study of autopilot system based on ROS and deep learning, especially convolution neural network (CNN), from the perspective of system implementation. And we also introduce the algorithm and realization process including the core module of perception, decision, control and system management emphatically.",https://ieeexplore.ieee.org/document/8104950/,2017 IEEE 15th International Conference on Industrial Informatics (INDIN),24-26 July 2017,ieeexplore
10.1109/ICSMC.2009.5346800,An embedded interval type-2 neuro-fuzzy controller for mobile robot navigation,IEEE,Conferences,"This paper describes intelligent navigation using an embedded interval type-2 neuro-fuzzy controller. Weightless neural network (WNNs) strategy is used because fast learning, easy hardware implementation and well suited to microcontroller-based-real-time systems. The WNNs utilizes previous sensor data and analyzes the situation of the current environment and classifies geometric feature such as U-shape, corridor and left or right corner. The behavior of mobile robot is implemented by means of interval type-2 fuzzy control rules can be generated directly from the WNNs classifier. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show, using that technique the source code is efficient. The mobile robot can recognize the current environment and to be able successfully avoid obstacle in real time and achieve smother motion compare than logic function and fuzzy type-1 controller.",https://ieeexplore.ieee.org/document/5346800/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/CIRA.1997.613874,An evolutionary method for active learning of mobile robot path planning,IEEE,Conferences,"Several evolutionary algorithms have been proposed for robot path planning. Most existing methods for evolutionary path planning require a number of generations for finding a satisfactory trajectory and thus are not efficient enough for real-time applications. In this paper we present a new method for evolutionary path planning which can be used online in real-time. We use an evolutionary algorithm as a means for active learning of a route map for the path planner. Given a source-destination pair, the path planner searches the map for a best matching route. If an acceptable match is not found, the planner uses another evolutionary algorithm to generate online a path for the source-destination pair. The overall system is an incremental learning planner that gradually expands its own knowledge suitable for path planning in real-time. Simulations have been performed in the domain of robotic soccer to demonstrate the effectiveness of the presented method.",https://ieeexplore.ieee.org/document/613874/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/ICSMC.2002.1175718,An evolutionary visual landmark recognition system,IEEE,Conferences,A vision-based landmark recognition system by using the evolutionary principle for robot navigation tasks is implemented in this study. The research is aimed at using the GA to do pattern matching. The basic idea is to use genetic algorithms to find the best matching between nodes of the two patterns. The evaluation function can be defined in terms of total differences in magnitudes of nodes between the desired pattern and the real pattern. A search method based on genetic algorithms for pattern recognition in digital images is implemented as the vision layer for a behavior based mobile robot. The vision layer can recognize artificial landmarks by searching all the pro-defined patterns using the GA. Then it generates the desired behavior corresponding to various landmarks. The results of the algorithm is promising and has a high accuracy in classifying the input patterns. The effectiveness of the developed system is demonstrated by simulation and experimental studies.,https://ieeexplore.ieee.org/document/1175718/,"IEEE International Conference on Systems, Man and Cybernetics",6-9 Oct. 2002,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
10.1109/ICAICA52286.2021.9497930,An improved semantic segmentation and fusion method for semantic SLAM,IEEE,Conferences,"Perception of the environment is an important part of robot intelligence. In order to better interact with the environment, the robot should not only know the shape of objects but also their semantics. In order to meet diversified needs, robot products are becoming more and more miniaturized, and related technologies have become research hotspots in the field. In response to this situation, this paper focuses on speed optimization based on the existing semantic map construction method to make it suitable for operation in embedded systems. This paper makes improvements to semantic segmentation and uses TensorRT to build a fast inference engine to accelerate target detection and speed up its inference speed on embedded devices. This paper uses Bayesian fusion method to fuse the semantic information of different locations to build an accurate map. Finally, in order to evaluate the real-time performance and effectiveness of this method, a test on the ADE20K data set was carried out, and the experimental results were analyzed to prove the effectiveness of the optimization of this algorithm.",https://ieeexplore.ieee.org/document/9497930/,2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA),28-30 June 2021,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/URTC.2016.8284091,An indoor positioning system facilitated by computer vision,IEEE,Conferences,"The purpose of this paper is to present our work on a novel method which allows for previously unattainable accuracy in indoor positioning. Global positioning has changed the way in which we interact with our specific locations on a real time basis, as can be seen most prominently in mapping applications. However, global positioning is severely limited indoors where location is equally important, and further, requires greater accuracy. While there have been attempts to implement indoor positioning, these methods are severely lacking, prompting us to take a completely new approach. We use low cost webcams and a series of algorithms to detect people in a video frame, and then identify and position them. Accuracy for identification is upwards of 95% and positioning accuracy is within a half-meter for the majority of the frame of view, all while running in real time on mobile CPUs. Such a system can be implemented on large scales to allow for exciting new applications; indoor directions in malls and public transportation hubs, new forms of human-robot interactions and consumer habit analysis in stores are all now possible.",https://ieeexplore.ieee.org/document/8284091/,2016 IEEE MIT Undergraduate Research Technology Conference (URTC),4-6 Nov. 2016,ieeexplore
10.1109/IJCNN.2010.5596513,An insect brain computational model inspired by Drosophila melanogaster: Simulation results,IEEE,Conferences,"Since many years insects have been considered as a source of inspiration for robotic architectures. From this point of view the fly Drosophila melanogaster is more than likely a protagonist, because of the genetic techniques that allow neurobiologists to make deep studies and hypotheses about the brain of this fly. In this work a computational model of the Drosophila has been tested and implemented on a robot simulator. Moreover, the normal capabilities of the fly have been extended in order to have an useful robot-oriented model. Results about a possible application in a real-life scenario of the whole model of the Drosophila brain are reported.",https://ieeexplore.ieee.org/document/5596513/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/ICMA.2013.6618173,An intelligent object manipulation framework for industrial tasks,IEEE,Conferences,"This paper presents an intelligent object manipulation framework for industrial tasks, which integrates a sensor-rich multi-fingered robot hand, an industrial robot manipulator, a conveyor belt and employs machine learning algorithms. The framework software architecture is implemented using a Windows 7 operating system with RTX real-time extension for synchronous handling of peripheral devices. The framework uses Scale Invariant Feature Transform (SIFT) image processing algorithm, Support Vector Machine (SVM) machine learning algorithm and 3D point cloud techniques for intelligent object recognition based on RGB camera and laser rangefinder information from the robot hand end effector. The objective is automated manipulation of objects with different shapes and poses with minimum programming effort applied by a user.",https://ieeexplore.ieee.org/document/6618173/,2013 IEEE International Conference on Mechatronics and Automation,4-7 Aug. 2013,ieeexplore
10.1109/CNNA.2010.5430339,An on-line test setup of CNN based real-time mobile robot navigation application,IEEE,Conferences,"In this demo, we introduced a mobile robot navigation test setup that is accessible via internet. This test setup has a Lego Mindstorms NXT differential drive mobile robot which is controlled by a computer with Bluetooth connection. The control computer, which is called Host Computer in Fig. 1, runs MATLAB to operate the system. The navigation of mobile robot is based on an algorithm which uses a Relaxation Oscillator Cellular Neural/Nonlinear Network to execute wave computing. This network is also simulated by the Host Computer. The significant property of this demo is that any Client Computer can establish a remote desktop connection with the Host Computer and use the test setup remotely. By this means, any comparative tests on this setup can be handled remotely by independent researchers.",https://ieeexplore.ieee.org/document/5430339/,2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010),3-5 Feb. 2010,ieeexplore
10.1109/IJCNN.2010.5596696,An open-source real-time system for remote robotic control using Neuroblastoma cultures,IEEE,Conferences,"This paper introduces an open-source real-time system that controls remotelly a robot using Human Neuroblastoma cultures and basic Braitenberg principles. Multielectrode Arrays Setups have been designed for direct culturing neural cells over silicon or glass substrates, providing the capability to stimulate and record simultaneously populations of neural cells. The main objective of this research is to modulate the natural physiologic responses of human neural cells by tetanic stimulation of the culture. If the system is able to modify the selective responses of some cells with a external pattern stimuli provided by a robot over different time scales, the neuroblastoma-cultured structure could be trained to process pre-programmed spatio-temporal patterns, controlling in this way the robotic behaviour.",https://ieeexplore.ieee.org/document/5596696/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/ROBOT.1992.220085,An optimal scheduling of pick place operations of a robot-vision-tracking system by using back-propagation and Hamming networks,IEEE,Conferences,"The authors present a neural network approach to solve the dynamic scheduling problem for pick-place operations of a robot-vision-tracking system. An optimal scheduling problem is formulated to minimize robot processing time without constraint violations. This is a real-time optimization problem which must be repeated for each group of objects. A scheme which uses neural networks to learn the mapping from object pattern space to optimal order space offline and to recall online what has been learned is presented. The idea was implemented in a real system to solve a problem in large commercial dishwashing operations. Experimental results have been shown that with four different objects, time savings of up to 21% are possible over first-come, first-served schemes currently used in industry.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220085/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ROBOT.1991.131636,Analogue computation of collision-free paths,IEEE,Conferences,"A method for robot path planning that uses a 2D scalar electric potential subject to Neumann boundary conditions is presented. Obstacles are modeled as nonconducting solids in a conducting medium. The starting point is modeled as a current source and the goal as an equal and opposite current sink. It is shown that this formulation is considerably more powerful than the recent potential-field algorithm of C.I. Connolly et al. (1990), particularly when navigating long, narrow corridors. Feasible paths for navigation are current streamlines, as demonstrated by the results of software simulations in a 2D Euclidean plane. One of the principal advantages of the method is that it can be implemented with parallel analog hardware in the form of a resistive grid. With analog VLSI chips, it will be possible to plan paths for realistic environments in real time.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131636/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.23919/IConAC.2019.8895095,Ant Colony Optimization Algorithm for Industrial Robot Programming in a Digital Twin,IEEE,Conferences,"Advanced manufacturing that is adaptable to constantly changing product designs often requires dynamic changes on the factory floor to enable manufacture. The integration of robotic manufacture with machine learning approaches offers the possibility to enable such dynamic changes on the factory floor. While ensuring safety and the possibility of losses of components and waste of material are against their usage. Furthermore, developments in design of virtual environments makes it possible to perform simulations in a virtual environment, to enable human-in-the-loop production of parts correctly the first time like never before. Such powerful simulation and control software provides the means to design a digital twin of manufacturing environment in which trials are completed at almost at no cost. In this paper, ant colony optimization is used to program an industrial robot to avoid obstacles and find its way to pick and place objects during an assembly task in an environment containing obstacles that must be avoided. The optimization is completed in a digital twin environment first and movements transferred to the real robot after human inspection. It is shown that the proposed methodology can find the optimal solution, in addition to avoiding collisions, for an assembly task with minimum human intervention.",https://ieeexplore.ieee.org/document/8895095/,2019 25th International Conference on Automation and Computing (ICAC),5-7 Sept. 2019,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/CIMCA.2005.1631615,Application of Competitive Clustering to Acquisition of Human Manipulation Skills,IEEE,Conferences,"The work carried out to explore the feasibility of reconstructing human constrained motion manipulation skills is reported. This is achieved by tracing and learning the manipulation performed by a human operator in a haptic rendered virtual environment. The peg-in-hole insertion problem is used as a case study. In the developed system, position and contact force and torque as well as orientation data generated in the haptic rendered virtual environment combined with a priori knowledge about the task are used to identify and learn the skills in the newly demonstrated task. The data obtained from the virtual environment is classified into different cluster sets using a competitive fuzzy clustering algorithm called competitive agglomeration (CA). The CA algorithm starts with an over specified number of clusters which compete for feature points in the training procedure. Clusters with small cardinalities lose the competition and gradually vanish. The optimal number of clusters that win the competition is eventually determined. The clusters in the optimum cluster set are tuned using locally weighted regression (LWR) to produce prediction models for robot trajectory performing the physical assembly based on the force/position information received from the rig. A background on the work and its significance is provided. The approach developed is explained and the results obtained so far are presented",https://ieeexplore.ieee.org/document/1631615/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/AICI.2009.305,Application of RBF Neural Network in Trajectory Planning of Robot,IEEE,Conferences,"Trajectory planning of robot is to control the robot in order to accurately follow the target track. And the target trajectory is always high-order and nonlinear. But RBF neural network can be achieved from the input to the output of arbitrary nonlinear mapping, through network learning and training to achieve the nonlinear function. This paper establishes a RBF neural network model firstly, and carries on the simulation through software MATLAB. The result confirms that the RBF neural network can keep the control of the robot's nonlinear trajectory planning in real time.",https://ieeexplore.ieee.org/document/5375883/,2009 International Conference on Artificial Intelligence and Computational Intelligence,7-8 Nov. 2009,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/CYBER53097.2021.9588269,Application of YOLO Object Detection Network In Weld Surface Defect Detection,IEEE,Conferences,"As industrial production becomes more modern and intelligent today, the inspection of product quality of the workshop is becoming more and more accustomed to replacing the old manual visual inspection methods with automated inspection systems. In the welding field, automated welding robots are not only used in traditional large-scale automobile assembly lines. In more general welding work, welding robots also plays an important role. The inspection of the welding quality of the welding robot is mainly to detect the four main types of weld defects. Compared to traditional defect classification based on support vector machines and defect detection based on template matching, this paper uses a welding surface defect detection system designed based on deep learning methods. By working with workshop welding experts, a large-scale image of nearly 5000 pictures is built. Large-scale weld defect datasets, while using the real-time and accuracy of the YOLO series of deep learning object detection frameworks, the weld defects detection model reaches 75.5% mean average precision(mAP) in constructed weld defect data set. In addition, the construction cost of the detection model and the deployment time of the detection system are greatly reduced. During the field test of the system in the workshop, among a batch of welding workpieces provided by the factory, the detection accuracy of weld defects reached 71%, which initially met the requirements of the workshop for an automated defect detection system.",https://ieeexplore.ieee.org/document/9588269/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/IJCNN.1990.137866,Application of neural networks on robot grippers,IEEE,Conferences,"A new-generation general-purpose robot gripper system which applies an artificial neural network to guide a three-finger gripper has been designed. The simulation of the core part of the whole system, i.e. optimally placing three fingers for a stable grasp using the Hopfield net, has been conducted. The results obtained show that this scheme behaves in a promising fashion. The actual computation time is usually within several seconds if implemented in an analog neural net, making the real application attractive",https://ieeexplore.ieee.org/document/5726824/,1990 IJCNN International Joint Conference on Neural Networks,17-21 June 1990,ieeexplore
10.1109/CDC.1999.833361,Application of reinforcement learning control to a nonlinear dexterous robot,IEEE,Conferences,"In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration were studied in detail. We attempt to increase feasibility for practical applications, implementation, learning efficiency, and performance. Reinforcement learning is then applied for control of a nonlinear dexterous robot. This control problem dictates that the learning is performed online, based on binary and real valued reinforcement signal from a critic network, without knowing the system model nonlinearity. The learning algorithm consists of an action and critic networks that learn to keep the multifinger hand of the dexterous robot within desired limits.",https://ieeexplore.ieee.org/document/833361/,Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304),7-10 Dec. 1999,ieeexplore
10.1109/IJCNN.2004.1380179,Applying KIV dynamic neural network model for real time navigation by mobile robot EMMA,IEEE,Conferences,"We use a biologically inspired dynamic neural network model to accomplish goal-oriented navigation by a mobile robot in a real environment with obstacles. This model is the KIV model of the brain. Real time navigation is a challenging task, especially when there is no a priori information about the environment. Our robot EMMA is designed to be autonomous using various sensory inputs, which are integrated to achieve an efficient navigation task. This paper focuses on the design, implementation, and evaluation of the performance of EMMA and gives a proof-of-principle in a real environment.",https://ieeexplore.ieee.org/document/1380179/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/SNPD.2007.118,Applying Multiple Classifier Systems to SoftMan's Perception System,IEEE,Conferences,"SoftMan, the virtual robot in network environment, is a kind of software Artificial Life living in computer networks. It has a humanoid structure, and simulating human, its perception system should be able to recognize perceptive objects. Enlightened by human's perception system and the ""disassemble-integration"" method in analyzing large systems, a cooperative classification model in SoftMan's perception system is proposed. In the model, different humanoid senses are simulated by multiple classifier systems (MCS). Consequently, SoftMan can perform multi-sense cooperative classification on its perceptive objects. A simulated experiment validates the basic feasibility of the model.",https://ieeexplore.ieee.org/document/4287524/,"Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)",30 July-1 Aug. 2007,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/HUMANOIDS.2012.6651500,Applying statistical generalization to determine search direction for reinforcement learning of movement primitives,IEEE,Conferences,"In this paper we present a new methodology for robot learning that combines ideas from statistical generalization and reinforcement learning. First we apply statistical generalization to compute an approximation for the optimal control policy as defined by training movements that solve the given task in a number of specific situations. This way we obtain a manifold of movements, which dimensionality is usually much smaller than the dimensionality of a full space of movement primitives. Next we refine the policy by means of reinforcement learning on the approximating manifold, which results in a learning problem constrained to the low dimensional manifold. We show that in some situations, learning on the low dimensional manifold can be implemented as an error learning algorithm. We apply golden section search to refine the control policy. Furthermore, we propose a reinforcement learning algorithm with an extended parameter set, which combines learning in constrained domain with learning in full space of parametric movement primitives, which makes it possible to explore actions outside of the initial approximating manifold. The proposed approach was tested for learning of pouring action both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/6651500/,2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012),29 Nov.-1 Dec. 2012,ieeexplore
10.1109/IJCNN.2015.7280807,Applying the canonical distributed Embodied Evolution algorithm in a collective indoor navigation task,IEEE,Conferences,"The automatic design of control systems for multi-robot teams that operate in real time is not affordable with traditional evolutionary algorithms mainly due to the huge computational requirements they imply. Embodied Evolution (EE) is an evolutionary paradigm that aims to address this problem through the embodiment of the individuals that make up the population in the physical robots. The interest for this type of evolutionary approach has been increasing steadily, leading to different algorithms and variations adapted to solve very specific practical cases. In a previous work, the authors started the implementation of a standard canonical EE algorithm that captures the more general principles of this paradigm and that can be applied to any distributed optimization problem. This canonical algorithm has been characterized already over a set of theoretical fitness landscapes corresponding to representative examples of the basic casuistry found in collective tasks. The current paper goes one step ahead in this research line, and the canonical algorithm is applied here in a collective navigation task in which a fleet of Micro Aerial Vehicles (MAVs) has to gather red rocks in an indoor scenario. The objective is to confirm that the characterization conclusions are generalizable to a practical case and to show that the canonical algorithm can be configured to operate as a specific algorithm easily.",https://ieeexplore.ieee.org/document/7280807/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ROBOT.1986.1087518,Architecture and early experience with planning for the ALV,IEEE,Conferences,"This paper describes the software architecture and the initial algorithms that have proved to be effective for a real time robot planning system. The architecture is designed to incorporate planning technology from research on artificial intelligence while at the same time supporting the high performance decision making needed to control a fast-moving autonomous vehicle. The symbolic representation of the vehicle's plan is a key element in this architecture. Our initial algorithms use an especially efficient version of dynamic programming to find the best routes. The route is then translated into a symbolic plan. Replanning happens at several levels with the cost of replanning proportionate to the scope of the changes. This software is currently running in an environment which simulates the vehicle and perception systems, but it will be transferred to the DARPA Autonomous Land Vehicle built by Martin Marietta Denver Aerospace [Lowrie 86].",https://ieeexplore.ieee.org/document/1087518/,Proceedings. 1986 IEEE International Conference on Robotics and Automation,7-10 April 1986,ieeexplore
10.1109/ICONIP.1999.845675,Artificial neural networks for autonomous robot control: reflective navigation and adaptive sensor calibration,IEEE,Conferences,"The authors present the application of artificial neural networks to the control of a mobile autonomous robot, which is acting in a totally unknown and-most importantly-dynamically changing environment. In particular, the employment of interacting 'simple', i.e. hand-designed, neural networks for navigation purposes is investigated as well as a variation of self-organizing maps for adaptive sensor calibration. We take a pragmatic point of view as the minimal condition imposed on the developed algorithms: that they do well on a real system acting in a real environment. Hence, the design of all of the implemented neural networks is clearly motivated by their applicability. In this context, special considerations are dedicated to ensure robustness, real-time capability and memory resourcefulness. In order to practically demonstrate the obtained results, the mini-robot Khepera is utilized as an experimentational platform, which is (due to its small size), a versatile tool for scientific investigation.",https://ieeexplore.ieee.org/document/845675/,ICONIP'99. ANZIIS'99 & ANNES'99 & ACNN'99. 6th International Conference on Neural Information Processing. Proceedings (Cat. No.99EX378),16-20 Nov. 1999,ieeexplore
10.1109/SIBCON50419.2021.9438884,Assessment of Map Construction in vSLAM,IEEE,Conferences,"Vision-based Simultaneous Localization and Mapping (vSLAM) is a challenging task in modern computer vision. vSLAM is particularly important as mobile robotics application. It allows to localize the robot and build the map of unknown environment in 3D in real-time. During research and development of new methods, it needs extensive evaluation on trajectory and map quality compared to known methods. In this work we focus on map quality estimation. We develop the simulated ground-truth data in photo-realistic environment and introduce new metrics in order to estimate map quality. We evaluate neural network based vSLAM methods with our framework in order to show that it fits map quality estimation more than standard approaches. Open-source implementation of our map metrics is available at https://github.com/CnnDepth/slam_comparison.",https://ieeexplore.ieee.org/document/9438884/,2021 International Siberian Conference on Control and Communications (SIBCON),13-15 May 2021,ieeexplore
10.1109/IJCNN.2011.6033367,Attention driven computational model of the auditory midbrain for sound localization in reverberant environments,IEEE,Conferences,"In this paper, an auditory attention driven computational model of the auditory midbrain is proposed based on a spiking neural network [17] in order to localize attended sound sources in reverberant environments. Both bottom-up attention driven by sensors and top-down attention driven by the cortex are modeled at the level of an auditory midbrain nucleus - the inferior colliculus (IC). Improvements of the model in [17] is made to increase biological plausibility. First, inter-neuron inhibitions are modeled among the IC neurons which have the same characteristic frequency but different spatial response. This is designed to mimic the precedence effect [15] to produce localization results in reverberate environments. Secondly, descending projections from the auditory cortex (AC) to the IC are model to simulate the top-down attention so that focused sound sources can be better sensed in noise or multiple sound source situations. Our model is implemented on a mobile robot with a manikin head equipped with binaural microphones and tested in a real environment. The results shows that our attention driven model can give more accurate localization results than prior models.",https://ieeexplore.ieee.org/document/6033367/,The 2011 International Joint Conference on Neural Networks,31 July-5 Aug. 2011,ieeexplore
10.1109/RIOS.2015.7270741,Attitude control and trajectory tracking of an autonomous miniature aerial vehicle,IEEE,Conferences,"This paper introduces a Miniature Aerial Vehicle (MAV) which is Autonomous in outdoor environment. Main contributions of this research are both new trajectory tracking and attitude control scheme in real flight mode. This MAV is based on a traditional quadrotor. For stabilization of the quadrotor's attitude a PID controller is utilized. The proposed controller is designed such that to be able to attenuate effect of external wind disturbance and guarantee stability in this condition. For autonomous trajectory tracking, it is necessary to have a fixed altitude. Also an ARM cortex M4 microcontroller performs processing activities. Then, a trajectory is determined by a GPS in Mission Planner software for the outdoor environment. For real time communication between robot and ground station, HMTR module is used. Flight data is saved in Memory SD card and converts to MATLAB code for real time implementation. Experimental results of the proposed controller on the Autonomous Quadrotor in real conditions show the effectiveness of our approach.",https://ieeexplore.ieee.org/document/7270741/,2015 AI & Robotics (IRANOPEN),12-12 April 2015,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/SIU.2015.7130068,Audio-visual human tracking for active robot perception,IEEE,Conferences,"In this paper, a multimodal system is designed in the form of an active audio-vision in order to improve the perceptual capability of a robot in a noisy environment. The system running in real-time consists of 1) audition modality, 2) a complementary vision modality and 3) motion modality incorporating intelligent behaviors based on the data obtained from both modalities. The tasks of audition and vision are to detect, localize and track a speaker independently. The aim of motion modality is to enable a robot to have intelligent and human-like behaviors by using localization results from the sensor fusion. The system is implemented on a mobile robot platform in a real-time environment and the speaker tracking performance of the fusion is confirmed to be improved compared to each of sensory modalities.",https://ieeexplore.ieee.org/document/7130068/,2015 23nd Signal Processing and Communications Applications Conference (SIU),16-19 May 2015,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/IJCNN.2003.1223997,Automatic language acquisition by an autonomous robot,IEEE,Conferences,"There is no such thing as a disembodied mind. We posit that cognitive development can only occur through interaction with the physical world. To this end, we are developing a robotic platform for the purpose of studying cognition. We suggest that the central component of cognition is a memory which is primarily associative, one where learning occurs as the correlation of events from diverse inputs. We also posit that human-like cognition requires a well-integrated sensory-motor system, to provide these diverse inputs. As implemented in our robot, this system includes binaural hearing, stereo vision, tactile sense, and basic proprioceptive control. On top of these abilities, we are implementing and studying various models of processing, learning and decision making. Our goal is to produce a robot that will learn to carry out simple tasks in response to natural language requests. The robot's understanding of language will be learned concurrently with its other cognitive abilities. We have already developed a robust system and conducted a number or experiments on the way to this goal, some details of which appear in this paper. This is a first progress report of what we believe will be a long term project with significant implications.",https://ieeexplore.ieee.org/document/1223997/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/IROS45743.2020.9341657,Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs,IEEE,Conferences,"We consider an autonomous exploration problem in which a range-sensing mobile robot is tasked with accurately mapping the landmarks in an a priori unknown environment efficiently in real-time; it must choose sensing actions that both curb localization uncertainty and achieve information gain. For this problem, belief space planning methods that forward- simulate robot sensing and estimation may often fail in real-time implementation, scaling poorly with increasing size of the state, belief and action spaces. We propose a novel approach that uses graph neural networks (GNNs) in conjunction with deep reinforcement learning (DRL), enabling decision-making over graphs containing exploration information to predict a robot's optimal sensing action in belief space. The policy, which is trained in different random environments without human intervention, offers a real-time, scalable decision-making process whose high-performance exploratory sensing actions yield accurate maps and high rates of information gain.",https://ieeexplore.ieee.org/document/9341657/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/FIE.2006.322654,Autonomous Robots as a Generic Teaching Tool,IEEE,Conferences,"An undergraduate bioengineering laboratory course using small autonomous robots has been developed to demonstrate control theory, learning, and behavior. The lab consists of several modules that demonstrate concepts in classical control theory, fuzzy logic, neural network control, and genetic algorithms. The autonomous agents are easy-to-build, inexpensive kit robots. Each robot functions independently in a real-world environment. Students program and retrieve data wirelessly using handheld computers. The hands-on nature of the lab modules engages students in ways that lectures, readings and software simulations cannot. By interacting with these robots, students directly experience the effects of unexpected environmental factors on designs and deviations from software simulations. The robots are easily adapted for use in many different aspects of two-year college and K-12 STEM education. Students are motivated to understand engineering, math and science principles in order to control the robots. Examples of use of the robots and modules by a local community college are presented",https://ieeexplore.ieee.org/document/4117154/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/AERO47225.2020.9172808,Autonomous UAV Navigation for Active Perception of Targets in Uncertain and Cluttered Environments,IEEE,Conferences,"The use of Small Unmanned Aerial Vehicles (sUAVs) has grown exponentially owing to an increasing number of autonomous capabilities. Automated functions include the return to home at critical energy levels, collision avoidance, take-off and landing, and target tracking. However, sUAVs applications in real-world and time-critical scenarios, such as Search and Rescue (SAR) is still limited. In SAR applications, the overarching aim of autonomous sUAV navigation is the quick localisation, identification and quantification of victims to prioritise emergency response in affected zones. Traditionally, sUAV pilots are exposed to prolonged use of visual systems to interact with the environment, which causes fatigue and sensory overloads. Nevertheless, the search for victims onboard a sUAV is challenging because of noise in the data, low image resolution, illumination conditions, and partial (or full) occlusion between the victims and surrounding structures. This paper presents an autonomous Sequential Decision Process (SDP) for sUAV navigation that incorporates target detection uncertainty from vision-based cameras. The SDP is modelled as a Partially Observable Markov Decision Process (POMDP) and solved online using the Adaptive Belief Tree (ABT) algorithm. In particular, a detailed model of target detection uncertainty from deep learning-based models is shown. The presented formulation is tested under Software in the Loop (SITL) through Gazebo, Robot Operating System (ROS), and PX4 firmware. A Hardware in the Loop (HITL) implementation is also presented using an Intel Myriad Vision Processing Unit (VPU) device and ROS. Tests are conducted in a simulated SAR GPS-denied scenario, aimed to find a person at different levels of location and pose uncertainty.",https://ieeexplore.ieee.org/document/9172808/,2020 IEEE Aerospace Conference,7-14 March 2020,ieeexplore
10.1109/SIMPAR.2016.7862403,Autonomous exploration by expected information gain from probabilistic occupancy grid mapping,IEEE,Conferences,"Occupancy grid maps are spatial representations of environments, where the space of interest is decomposed into a number of cells that are considered either occupied or free. This paper focuses on exploring occupancy grid maps by predicting the uncertainty of the map. Based on recent improvements in computing occupancy probability, this paper presents a novel approach for selecting robot poses designed to maximize expected map information gain represented by the change in entropy. This result is simplified with several approximations to develop an algorithm suitable for real-time implementation. The predicted information gain proposed in this paper governs an effective autonomous exploration strategy when applied in conjunction with an existing motion planner to avoid obstacles, which is illustrated by numerical examples.",https://ieeexplore.ieee.org/document/7862403/,"2016 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)",13-16 Dec. 2016,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/SYSOSE.2008.4724191,Autonomous navigation based on a Q-learning algorithm for a robot in a real environment,IEEE,Conferences,"This paper explores autonomous navigation and obstacle avoidance techniques based on Q-learning for a mobile robot in a real environment. The implemented algorithm focuses on simplicity and efficiency. The learning process takes place in both simulation and real world allowing the combination of a longer learning time in the simulator with a more accurate knowledge from the real world. After learning is completed in simulation and in the real world, the robot was able to navigate without hitting obstacles and able to generate control law for complex situations such as corners and small objects.",https://ieeexplore.ieee.org/document/4724191/,2008 IEEE International Conference on System of Systems Engineering,2-4 June 2008,ieeexplore
10.1109/IJCNN.2013.6706877,Autonomous reinforcement of behavioral sequences in neural dynamics,IEEE,Conferences,"We introduce a dynamic neural algorithm called Dynamic Neural (DN) SARSA(λ) for learning a behavioral sequence from delayed reward. DN-SARSA(λ) combines Dynamic Field Theory models of behavioral sequence representation, classical reinforcement learning, and a computational neuroscience model of working memory, called Item and Order working memory, which serves as an eligibility trace. DN-SARSA(λ) is implemented on both a simulated and real robot that must learn a specific rewarding sequence of elementary behaviors from exploration. Results show DN-SARSA(λ) performs on the level of the discrete SARSA(λ), validating the feasibility of general reinforcement learning without compromising neural dynamics.",https://ieeexplore.ieee.org/document/6706877/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/ISIC.2002.1157759,Autonomous robot navigation based on fuzzy sensor fusion and reinforcement learning,IEEE,Conferences,"This paper presents the design and implementation of an autonomous robot navigation system for intelligent target collection in dynamic environments. A feature-based multi-stage fuzzy logic (MSFL) sensor fusion system is developed for target recognition, which is capable of mapping noisy sensor inputs into reliable decisions. The robot exploration and path planning are based on a grid map oriented reinforcement path learning system (GMRPL), which allows for long-term predictions and path adaptation via dynamic interactions with physical environments. In our implementation, the MSFL and GMRPL are integrated into a subsumption architecture for intelligent target-collecting applications. The subsumption architecture is a layered reactive agent structure that enables the robot to implement higher-layer functions including path learning and target recognition regardless of lower-layer functions such as obstacle detection and avoidance. Real-world application using a Khepera robot shows the robustness and flexibility of the developed system in dealing with robotic behavior such as target collecting in an ever-changing physical environment.",https://ieeexplore.ieee.org/document/1157759/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/CEC.2002.1004426,Autonomous robot navigation via intrinsic evolution,IEEE,Conferences,"This paper presents the design and implementation of an evolvable hardware based autonomous robot navigation system using intrinsic evolution. Distinguished from the traditional evolutionary approaches based on software simulation, an evolvable robot controller at the hardware gate-level that is capable of adapting dynamic changes in the environments is implemented. In our approach, the concept of Boolean function is used to construct the evolvable controller implemented on an FPGA-based robot turret, and evolutionary computing is applied as a learning tool to guide the artificial evolution at the hardware level. The effectiveness of the proposed evolvable autonomous robotic system is confirmed with the physical real-time implementation of robot navigation behaviors on light source following and obstacle avoidance using a robot with traction fault.",https://ieeexplore.ieee.org/document/1004426/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/IST.2012.6295593,Autonomous robotic ground penetrating radar surveys of ice sheets; Using machine learning to identify hidden crevasses,IEEE,Conferences,"This paper presents methods to continue development of a completely autonomous robotic system employing ground penetrating radar imaging of the glacier sub-surface. We use well established machine learning algorithms and appropriate un-biased processing, particularly those which are also suitable for real-time image analysis and detection. We tested and evaluated three processing schemes in conjunction with a Support Vector Machine (SVM) trained on 15 examples of Antarctic GPR imagery, collected by our robot and a Pisten Bully tractor in 2010 in the shear zone near McMurdo Station. Using a modified cross validation technique, we correctly classified all examples with a radial basis kernel SVM trained and evaluated on down-sampled and texture-mapped GPR images of crevasses, compared to 60% classification rate using raw data. We also test the most successful processing scheme on a larger dataset, comprised of 94 GPR images of crevasse crossings recorded in the same deployment. Our experiments demonstrate the promise and reliability of real-time object detection and classification with robotic GPR imaging surveys.",https://ieeexplore.ieee.org/document/6295593/,2012 IEEE International Conference on Imaging Systems and Techniques Proceedings,16-17 July 2012,ieeexplore
10.1109/ICRA.2013.6631235,Autonomous robotic valve turning: A hierarchical learning approach,IEEE,Conferences,"Autonomous valve turning is an extremely challenging task for an Autonomous Underwater Vehicle (AUV). To resolve this challenge, this paper proposes a set of different computational techniques integrated in a three-layer hierarchical scheme. Each layer realizes specific subtasks to improve the persistent autonomy of the system. In the first layer, the robot acquires the motor skills of approaching and grasping the valve by kinesthetic teaching. A Reactive Fuzzy Decision Maker (RFDM) is devised in the second layer which reacts to the relative movement between the valve and the AUV, and alters the robot's movement accordingly. Apprenticeship learning method, implemented in the third layer, performs tuning of the RFDM based on expert knowledge. Although the long-term goal is to perform the valve turning task on a real AUV, as a first step the proposed approach is tested in a laboratory environment.",https://ieeexplore.ieee.org/document/6631235/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/IROS.2017.8202143,Autonomous skill-centric testing using deep learning,IEEE,Conferences,Software testing is an important tool to ensure software quality. This is a hard task in robotics due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and/or simulation-based testing to overcome these problems. We propose model-free skill-centric testing in which a robot autonomously executes skills in the real world and compares it to previous experiences. The skills are selected by maximising the expected information gain on the distribution of erroneous software functions. We use deep learning to model the sensor data observed during previous successful skill executions and to detect irregularities. Sensor data is connected to function call profiles such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or task-specific models.,https://ieeexplore.ieee.org/document/8202143/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/IEMBS.2008.4649235,BMI cyberworkstation: Enabling dynamic data-driven brain-machine interface research through cyberinfrastructure,IEEE,Conferences,"Dynamic data-driven brain-machine interfaces (DDDBMI) have great potential to advance the understanding of neural systems and improve the design of brain-inspired rehabilitative systems. This paper presents a novel cyberinfrastructure that couples in vivo neurophysiology experimentation with massive computational resources to provide seamless and efficient support of DDDBMI research. Closed-loop experiments can be conducted with in vivo data acquisition, reliable network transfer, parallel model computation, and real-time robot control. Behavioral experiments with live animals are supported with real-time guarantees. Offline studies can be performed with various configurations for extensive analysis and training. A Web-based portal is also provided to allow users to conveniently interact with the cyberinfrastructure, conducting both experimentation and analysis. New motor control models are developed based on this approach, which include recursive least square based (RLS) and reinforcement learning based (RLBMI) algorithms. The results from an online RLBMI experiment shows that the cyberinfrastructure can successfully support DDDBMI experiments and meet the desired real-time requirements.",https://ieeexplore.ieee.org/document/4649235/,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,20-25 Aug. 2008,ieeexplore
10.1109/ICMLC.2012.6359467,BMP: A self-balancing mobile platform,IEEE,Conferences,"The development of two wheels self-balancing robot has gained more and more attention over the past years. It is suitable for working in outdoor environment especially where the ground is not flat. This paper describes our works on building a self-Balancing Mobile Platform named BMP. We build the dynamic model to find the relation between the robot posture and output voltages applying on the motors. An accelerometer and gyroscope are used to estimate the posture through Kalman filter algorithm. Then a multi-segment PID controller changes the motor voltage according to the platform motion mode and posture. The experiments are carried out in simulation, then on the real platform. The results of the experiments show that BMP works effectively and robustly.",https://ieeexplore.ieee.org/document/6359467/,2012 International Conference on Machine Learning and Cybernetics,15-17 July 2012,ieeexplore
10.1109/IES53407.2021.9594013,Ball Position Transformation with Artificial Intelligence Based on Tensorflow Libraries,IEEE,Conferences,Research on wheeled soccer robots has been carried out by several researchers. This is due to the existence of national and international competitions. Previous research was to create a ball position transformation system with a modified method of neural network architecture. This research was developed by building an intelligent transformation system with the Tensorflow library. This transformation system aims to be able to directly measure the distance of objects in real terms without first changing the environmental image from an omni field to a flat plane with conventional camera calibration techniques. This process can replace manual calibration with a variety of field size changes The system can transform with mean error 0.0000026 on epoch 10000 using “conda-tensorflowneural network” libraries. It can transform the position of the ball from the omni space to the cartesian space. This system was implemented on wheeled soccer robot as keeper.,https://ieeexplore.ieee.org/document/9594013/,2021 International Electronics Symposium (IES),29-30 Sept. 2021,ieeexplore
10.1109/ICDL-EpiRob48136.2020.9278071,Bayesian Optimization for Developmental Robotics with Meta-Learning by Parameters Bounds Reduction,IEEE,Conferences,"In robotics, methods and softwares usually require optimizations of hyperparameters in order to be efficient for specific tasks, for instance industrial bin-picking from homogeneous heaps of different objects. We present a developmental framework based on long-term memory and reasoning modules (Bayesian Optimisation, visual similarity and parameters bounds reduction) allowing a robot to use meta-learning mechanism increasing the efficiency of such continuous and constrained parameters optimizations. The new optimization, viewed as a learning for the robot, can take advantage of past experiences (stored in the episodic and procedural memories) to shrink the search space by using reduced parameters bounds computed from the best optimizations realized by the robot with similar tasks of the new one (e.g. bin-picking from an homogenous heap of a similar object, based on visual similarity of objects stored in the semantic memory). As example, we have confronted the system to the constrained optimizations of 9 continuous hyperparameters for a professional software (Kamido) in industrial robotic arm bin-picking tasks, a step that is needed each time to handle correctly new object. We used a simulator to create bin-picking tasks for 8 different objects (7 in simulation and one with real setup, without and with meta-learning with experiences coming from other similar objects) achieving goods results despite a very small optimization budget, with a better performance reached when meta-learning is used (84.3 % vs 78.9 % of success overall, with a small budget of 30 iterations for each optimization) for every object tested (p-value=0.036).",https://ieeexplore.ieee.org/document/9278071/,2020 Joint IEEE 10th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),26-30 Oct. 2020,ieeexplore
10.1109/FUZZY.2000.838648,Behavior based decision control in autonomous vehicles: a fuzzy approach using Khepera,IEEE,Conferences,"A fuzzy behavior based decision control architecture is introduced. Each behavior is composed by several fuzzy actions-a concept that constitutes the behavior building block, allowing the implementation of a single aspect of the desired competence. A fuzzy action itself is composed by action (fuzzy controller) and activity (fuzzy predicate) producing modules. The behavior performance is also dependent on the (simulated) available energy. The arbitration process is present at the levels of action and behavior. This architecture is tested on the Khepera robot, both in simulation and in reality. The results of the performed experiments are presented, encouraging the architecture use in long range autonomous vehicles.",https://ieeexplore.ieee.org/document/838648/,Ninth IEEE International Conference on Fuzzy Systems. FUZZ- IEEE 2000 (Cat. No.00CH37063),7-10 May 2000,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/EMWRTS.1996.557846,Behaviour-oriented commands: from distributed knowledge representation to real-time implementation,IEEE,Conferences,"This paper presents a general methodology to model and implement real time control of complex systems with high reactivity. It is based on an original concept called ""behaviour oriented commands"" (BOCs). This methodology has been applied successfully in our mobile robot. BOCs incorporate mechanisms to model the set of rules (knowledge) which describes the restrictions and actions to achieve a goal. Basic rules are well encapsulated by entities called ""behaviours"", while global co-operating rules are explicited by the association link managed by the BOC's control unit. The model is easily translated into a real time implementation. This fusion between knowledge and real time is the main contribution of our work to the RT area.",https://ieeexplore.ieee.org/document/557846/,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,12-14 June 1996,ieeexplore
10.1109/ICRA40945.2020.9197470,"Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance",IEEE,Conferences,"We contribute a study benchmarking the performance of multiple motion-based learning from demonstration approaches. Given the number and diversity of existing methods, it is critical that comprehensive empirical studies be performed comparing the relative strengths of these techniques. In particular, we evaluate four approaches based on properties an end user may desire for real-world tasks. To perform this evaluation, we collected data from nine participants, across four manipulation tasks. The resulting demonstrations were used to train 180 task models and evaluated on 720 task reproductions on a physical robot. Our results detail how i) complexity of the task, ii) the expertise of the human demonstrator, and iii) the starting configuration of the robot affect task performance. The collected dataset of demonstrations, robot executions, and evaluations are publicly available. Research insights and guidelines are also provided to guide future research and deployment choices about these approaches.",https://ieeexplore.ieee.org/document/9197470/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/IROS40897.2019.8967694,Benchmarking and Workload Analysis of Robot Dynamics Algorithms,IEEE,Conferences,"Rigid body dynamics calculations are needed for many tasks in robotics, including online control. While there currently exist several competing software implementations that are sufficient for use in traditional control approaches, emerging sophisticated motion control techniques such as nonlinear model predictive control demand orders of magnitude more frequent dynamics calculations. Current software solutions are not fast enough to meet that demand for complex robots. The goal of this work is to examine the performance of current dynamics software libraries in detail. In this paper, we (i) survey current state-of-the-art software implementations of the key rigid body dynamics algorithms (RBDL, Pinocchio, Rigid-BodyDynamics.jl, and RobCoGen), (ii) establish a methodology for benchmarking these algorithms, and (iii) characterize their performance through real measurements taken on a modern hardware platform. With this analysis, we aim to provide direction for future improvements that will need to be made to enable emerging techniques for real-time robot motion control. To this end, we are also releasing our suite of benchmarks to enable others to help contribute to this important task.",https://ieeexplore.ieee.org/document/8967694/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICMLC.2008.4620720,Bi-criteria joint torque minimization of redundant robot arms using LVI-based primal-dual neural network,IEEE,Conferences,"To diminish the discontinuity and divergence of infinity norm torque minimization scheme, a bi-criteria weighting scheme is proposed for online redundancy resolution of redundant robot arms. Such a scheme can easily be reformulated into a quadratic program (QP) subject to equality, inequality and bound constraints. To solve this QP problem online, a primal-dual dynamical-system solver is further presented based on linear variational inequalities (LVI). Compared to previous research work, the adopted QP-solver has simple piecewise-linear dynamics, and does not entail real-time matrix inversion. Computer simulations are performed based on a PUMA560 manipulator to verify the performance and effectiveness of the proposed torque-optimization method.",https://ieeexplore.ieee.org/document/4620720/,2008 International Conference on Machine Learning and Cybernetics,12-15 July 2008,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/BIOROB.2018.8487202,Bioinspired Adaptive Spiking Neural Network to Control NAO Robot in a Pavlovian Conditioning Task,IEEE,Conferences,"The cerebellum has a central role in fine motor control and in various neural processes, as in associative paradigms. In this work, a bioinspired adaptive model, developed by means of a spiking neural network made of thousands of artificial neurons, has been leveraged to control a humanoid NAO robot in real-time. The learning properties of the system have been challenged in a classic cerebellum-driven paradigm, the Pavlovian timing association between two provided stimuli, here implemented as a laser-avoidance task. The neurophysiological principles used to develop the model, succeeded in driving an adaptive motor control protocol with acquisition and extinction phases. The spiking neural network model showed learning behaviors similar to the ones experimentally measured with human subjects in the same conditioning task. The model processed in real-time external inputs, encoded as spikes, and the generated spiking activity of its output neurons was decoded, in order to trigger the proper response with a correct timing. Three long-term plasticity rules have been embedded for different connections and with different time-scales. The plasticities shaped the firing activity of the output layer neurons of the network. In the Pavlovian protocol, the neurorobot successfully learned the correct timing association, generating appropriate responses. Therefore, the spiking cerebellar model was able to reproduce in the robotic platform how biological systems acquire and extinguish associative responses, dealing with noise and uncertainties of a real-world environment.",https://ieeexplore.ieee.org/document/8487202/,2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob),26-29 Aug. 2018,ieeexplore
10.1109/IJCNN.2000.859467,Biologically inspired neural controllers for motor control in a quadruped robot,IEEE,Conferences,"This paper presents biologically inspired neural controllers for generating motor patterns in a quadruped robot. Sets of artificial neural networks are presented which provide 1) pattern generation and gait control, allowing continuous passage from walking to trotting to galloping, 2) control of sitting and lying down behaviors, and 3) control of scratching. The neural controllers consist of sets of oscillators composed of leaky-integrator neurons, which control pairs of flexor-extensor muscles attached to each joint. The networks receive sensory feedback proportional to the contraction of simulated muscles and to joint flexion. Similarly to what is observed in cats, locomotion can be initiated by either applying tonic (i.e. non-oscillating) input to the locomotion network or by sensory feedback from extending the legs. The networks are implemented in a quadruped robot. It is shown that computation can be carried out in real time and that the networks can generate the above mentioned motor behaviors.",https://ieeexplore.ieee.org/document/859467/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/INES.2018.8523877,Body State Recognition for a Quadruped Mobile Robot,IEEE,Conferences,"The body states must be tracked by the onboard software on the robot to make good decisions. A human can pick up this machine or if the robot encounters anomalies (e.g. fall over) during locomotion, the state changes must be identified to execute the necessary responses. The authors of this paper developed a machine learning model which can recognize four states (normal, pick-up, fall over, poked) of a Sony AIBO robot. A deep neural network classifier with these predictors achieved 98% accuracy on unseen data and actual test runs on the robot proved the practical use with real-time execution speed. These properties made the proposed method a good candidate for adaption to other legged robots.",https://ieeexplore.ieee.org/document/8523877/,2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES),21-23 June 2018,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/IROS.2006.281655,Brush Footprint Acquisition and Preliminary Analysis for Chinese Calligraphy using a Robot Drawing Platform,IEEE,Conferences,"A robot drawing platform supporting four degrees of freedom (x, y, z and z-rotation) of a brush-pen motion for studying Chinese painting and calligraphy has been operational in our laboratory. This paper describes the real-time capturing and data analysis of the brush footprint using the new hardware and software capabilities in the platform. They include a transparent drawing plate and an underneath camera system, together with projective rectification and video segmentation algorithms. Preliminary result of the footprint analysis and nonparametric modeling, and their applications to well-known Chinese calligraphy are demonstrated",https://ieeexplore.ieee.org/document/4059247/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/CRV52889.2021.00009,Building Facades to Normal Maps: Adversarial Learning from Single View Images,IEEE,Conferences,"Surface normal estimation is an essential component of several computer and robot vision pipelines. While this problem has been extensively studied, most approaches are geared towards indoor scenes and often rely on multiple modalities (depth, multiple views) for accurate estimation of normal maps. Outdoor scenes pose a greater challenge as they exhibit significant lighting variation, often contain occluders, and structures like building facades are often ridden with numerous windows and protrusions. Conventional supervised learning schemes excel in indoor scenes, but do not exhibit competitive performance when trained and deployed in outdoor environments. Furthermore, they involve complex network architectures and require many more trainable parameters. To tackle these challenges, we present an adversarial learning scheme that regularizes the output normal maps from a neural network to appear more realistic, by using a small number of precisely annotated examples. Our method presents a lightweight and simpler architecture, while improving performance by at least 1.5x across most metrics. We evaluate our approaches against the state-of-the-art on normal map estimation, on a synthetic and a real outdoor dataset, and observe significant performance enhancements.",https://ieeexplore.ieee.org/document/9469450/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.1109/IJCNN.2005.1555934,Building a cheaper artificial brain,IEEE,Conferences,"This paper presents a methodology for building artificial brains that is much cheaper than the first author's earlier attempt. What initially cost $500,000, now costs about $3000. The much cheaper approach uses a Celoxica(.com) programmable board containing a Xilinx Virtex II FPGA chip with 3 million programmable logic gates, to evolve neural networks at electronic speeds. The genetic algorithm (GA) and the neural network model are programmed using a high level language called Handel-C, whose code is (silicon) compiled into the chip. The elite circuit is downloaded from the board into the memory of a PC. This process occurs up to several 10,000 s of times, once for each neural net circuit module having a unique function. Special software in the PC is used to specify the connections between the modules, according to the designs of human BAs (brain architects). The PC is then used to execute the neural signaling of the artificial brain (A-brain) in real time, defined to be 25 Hz per neuron. At this speed, the PC can handle several 10,000 s of modules. We would use our A-brain to control the behaviors of a small, four wheeled radio controlled robot with a CCD camera and gripper. The robot's task is to detect and collect unexploded cluster bomblets and deposit them in some central place. The total price of the PC, Celoxica board, and robot is less than $3000, making it affordable to virtually any research group interested in building artificial brains.",https://ieeexplore.ieee.org/document/1555934/,"Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.",31 July-4 Aug. 2005,ieeexplore
10.1109/IJCNN.2012.6252637,Building block of a programmable neuromorphic substrate: A digital neurosynaptic core,IEEE,Conferences,"The grand challenge of neuromorphic computation is to develop a flexible brain-inspired architecture capable of a wide array of real-time applications, while striving towards the ultra-low power consumption and compact size of biological neural systems. Toward this end, we fabricated a building block of a modular neuromorphic architecture, a neurosynaptic core. Our implementation consists of 256 integrate-and-fire neurons and a 1,024×256 SRAM crossbar memory for synapses that fits in 4.2mm<sup>2</sup> using a 45nm SOI process and consumes just 45pJ per spike. The core is fully configurable in terms of neuron parameters, axon types, and synapse states and its fully digital implementation achieves one-to-one correspondence with software simulation models. One-to-one correspondence allows us to introduce an abstract neural programming model for our chip, a contract guaranteeing that any application developed in software functions identically in hardware. This contract allows us to rapidly test and map applications from control, machine vision, and classification. To demonstrate, we present four test cases (i) a robot driving in a virtual environment, (ii) the classic game of pong, (iii) visual digit recognition and (iv) an autoassociative memory.",https://ieeexplore.ieee.org/document/6252637/,The 2012 International Joint Conference on Neural Networks (IJCNN),10-15 June 2012,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/ISCAS.2004.1329695,CNN wave based computation for robot navigation planning,IEEE,Conferences,"In this work a methodology for real-time robot navigation in a complex, dynamically changing environment, based on wave computation and implemented by cellular neural networks (CNNs) is introduced. The keypoint of the approach is to consider the environment in which the robot moves as an excitable medium. Obstacles and targets represent the source of autowave generation. The wavefronts propagating in the CNN medium provide to the robot all the information to achieve an adaptive motion avoiding the obstacles and directed to the target. In particular the paradigm of reaction-diffusion (RD) equations are used to implement a CNN-based wave computation for navigation control. Experimental results validating the approach are shown.",https://ieeexplore.ieee.org/document/1329695/,2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512),23-26 May 2004,ieeexplore
10.1109/ROBOT.1990.126097,CSL: a cost-sensitive learning system for sensing and grasping objects,IEEE,Conferences,"The goal of the research reported is to build a learning robot which can survive in an unknown environment for a long time. Such a robot must learn which sensors to use, where to use them, and how to generate an inexpensive and reliable robot control procedure to accomplish its task. This is beyond machine learning methods because they usually ignore robot execution costs and are ill-prepared to handle failures. A cost-sensitive, noise-tolerant and inductive robot learning system, CSL, that represents the first steps toward achieving this goal is described, emphasizing the cost and noise issues in learning. CSL has been implemented in a real-world robot for sensing objects and selecting their grasping procedures.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126097/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/ICCE-Berlin50680.2020.9352201,Camera-LIDAR Object Detection and Distance Estimation with Application in Collision Avoidance System,IEEE,Conferences,"Nowadays we are aware of accelerated development of automotive software. Numerous of ADAS (Advanced Driver Assistance Systems) systems are being developed these days. One such system is the forward CAS (Collision Avoidance System). In order to implement such a system, this paper presents one solution for detecting an object located directly in front of the vehicle and estimating its distance. The solution is based on the use of camera and LIDAR (Light Detection and Ranging) sensor fusion. The camera was used for object detection and classification, while 3D data obtained from LIDAR sensor were used for distance estimation. In order to map the 3D data from the LIDAR to the 2D image space, a spatial calibration was used. The solution was developed as a prototype using the ROS (Robot Operating System) based Autoware open source platform. This platform is essentially a framework intended for the development and testing of automotive software. ROS as the framework on which the Autoware platform is based, provides a library for the Python and C++ programming languages, intended for creating new applications. For the reason that this is a prototype project, and it is popular for application in machine learning, we decided to use the Python programming language. The solution was tested inside the CARLA simulator, where the estimation of the obstacle distance obtained at the output of our algorithm was compared with the ground truth values obtained from the simulator itself. Measurements were performed under different weather conditions, where this algorithm showed satisfactory results, with real-time processing.",https://ieeexplore.ieee.org/document/9352201/,2020 IEEE 10th International Conference on Consumer Electronics (ICCE-Berlin),9-11 Nov. 2020,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/IJCNN52387.2021.9533738,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,IEEE,Conferences,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",https://ieeexplore.ieee.org/document/9533738/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/IROS45743.2020.9341134,Catch the Ball: Accurate High-Speed Motions for Mobile Manipulators via Inverse Dynamics Learning,IEEE,Conferences,"Mobile manipulators consist of a mobile platform equipped with one or more robot arms and are of interest for a wide array of challenging tasks because of their extended workspace and dexterity. Typically, mobile manipulators are deployed in slow-motion collaborative robot scenarios. In this paper, we consider scenarios where accurate high-speed motions are required. We introduce a framework for this regime of tasks including two main components: (i) a bi-level motion optimization algorithm for real-time trajectory generation, which relies on Sequential Quadratic Programming (SQP) and Quadratic Programming (QP), respectively; and (ii) a learning-based controller optimized for precise tracking of high-speed motions via a learned inverse dynamics model. We evaluate our framework with a mobile manipulator platform through numerous high-speed ball catching experiments, where we show a success rate of 85.33%. To the best of our knowledge, this success rate exceeds the reported performance of existing related systems [1], [2] and sets a new state of the art.",https://ieeexplore.ieee.org/document/9341134/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/CIFEr.2019.8759121,Chatbot Application on Cryptocurrency,IEEE,Conferences,"Many chatbots have been developed that provide a multitude of services through a wide range of methods. A chatbot is a brand-new conversational agent in the highspeed changing technology world. With the advance of Artificial Intelligence and machine learning, chatbots are becoming more and more popular. A chatbot is the extension of human interface mediums such as the phone and social platforms. Similarly, Cryptocurrency is a new extension of digital or virtual currency designed to work as a medium of exchange. In the current digital exchanging world, investors and interested parties are eager to know more information about, and the capabilities of, this new type of currency. One of the potential paths to retrieve the info automatically and quickly is through a chatbot. We explored the open source python library, Chatterbot, to apply Itchat API (a WeChat interface) with the aim of building a robot chatting application, I&amp;C Chat, on the topic of cryptocurrency. First, we collected question and answer pairs datasets from Quora websites. Furthermore, we also created API calls to query the real time quote for the top 25 cryptocurrencies. Then we used the collected data to train our chatbot and implemented a logic adapter to receive the price quote of cryptocurrencies based on the incoming question. The Itchat API method will return the best matched answer to the asking party automatically. The response time of different questions has been investigated. The results imply that this application is quite useful, feasible and beneficial to the digital currency world.",https://ieeexplore.ieee.org/document/8759121/,2019 IEEE Conference on Computational Intelligence for Financial Engineering & Economics (CIFEr),4-5 May 2019,ieeexplore
10.1109/ICRA48506.2021.9561926,Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs,IEEE,Conferences,"Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 °/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",https://ieeexplore.ieee.org/document/9561926/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICCE46568.2020.9042997,Cliff-sensor-based Low-level Obstacle Detection for a Wheeled Robot in an Indoor Environment,IEEE,Conferences,"A ramp and uneven ground formed by a low-level obstacle - whose height is too low from the ground - often stalls a robot's navigation in an indoor environment. Few-centimeter differences between a low-level obstacle and a low-level non-obstacle are very difficult to be precisely measured in a constant distance at a mobile robot. In this paper, a wheeled mobile robot thus makes physical contact onto a low-level object, in order to measure such subtle differences. We use one or more cliff sensors typically in place for a mobile robot in order to avoid a drop-off. A wheeled robot climbs over a low-level object, classifies an obstacle vs. a non-obstacle using a cliff sensor's timeseries data, and rapidly backs up before getting stuck onto an obstacle. While adopting a simplified deep-learning architecture, we suggest a rapid and accurate obstacle detection technique in real-time. We implemented our technique on an embedded robot platform of LG Hom-Bot. The supplementary video on the physical robot experiment can be accessed at https://youtu.be/yK57S857_II.",https://ieeexplore.ieee.org/document/9042997/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IEEE.ICCC.2017.20,Cognitive Acoustic Analytics Service for Internet of Things,IEEE,Conferences,"The rapid development of the Internet of Things (IoT) has brought great changes for non-contact and non-destructive sensing and diagnosis. For every inanimate object can tell us something by the sound it makes, acoustic sensor demonstrates great advantages comparing to conventional electronic and mechanic sensors in such cases: overcoming environmental obstacles, mapping to existing use cases of detecting problems with human ears, low cost for deployment, etc. It could be widely applied to various domains, such as predictive maintenance of machinery, robot sensory, elderly and baby care in smart home, etc. Whether we can use the acoustic sensor data to understand what is happening and to predict what will happen relies heavily on the analytics capabilities we apply to the acoustic data, which has to overcome the obstacles of noise, disturbance and errors, and has to meet the requirement of real-time processing of high volume signals with large number of sensors. In this paper, we propose a scalable cognitive acoustics analytics service for IoT that provides the user an incremental learning approach to evolve their analytics capability on non-intuitive and unstructured acoustic data through the combination of acoustic signal processing and machine learning technology. It first performs acoustic signal processing and denoising, enables acoustic signal based abnormal detection based on sound intensity, spectral centroid, etc. Then based on the accumulated abnormal data, a supervised learning method is performed as baseline and a neural network based classifier is used to recognize acoustic events in different scenarios with various volume of sample data and requirement of accuracy. In addition, acoustic sensor arrays processing is supported for localization of moving acoustic source in more complex scenario. In this paper, we designed a hybrid computing structure. Finally, we conduct experiments on acoustic event recognition for machinery diagnosis, and show that the proposed system can achieve high accuracy.",https://ieeexplore.ieee.org/document/8029228/,2017 IEEE International Conference on Cognitive Computing (ICCC),25-30 June 2017,ieeexplore
10.1109/INDIN.2011.6034840,Cognitive decision unit applied to autonomous biped robot NAO,IEEE,Conferences,"The novel approach to use meta-psychology - the theoretic foundation of psychoanalysis - as archetype for a decision making framework for autonomous agents was realized in simulations recently. In addition, multiple studies showed the capability of a robot to sense and interact in its environment. This work fills the gap between sensing, environmental interaction and decision making by grounding these topics with an agents internal needs using the concepts of meta-psychology. The bodies of typical agents are equipped with internal systems which can generate bodily needs - for example the urgent need for food. As proof-of-concept we implemented this concept on a simulated agent as well as on a physical real humanoid biped robot to additionally proof the concept within a fully controlled simulated environment. The use of the common humanoid robot platform NAO, which has 25 degrees of freedom and biped locomotion, enforced us to deal with complex situations and disturbed sensor readings. NAO provides various internal sensors like engine temperature or battery level as well as external sensors like sonar or cameras. An implemented visual marker detecting system allowed us to detect objects in the surrounding environmental, representing food or energy sources. We show, how it is possible to use the psychoanalytically inspired framework ARS to control a real world application, the robot NAO.",https://ieeexplore.ieee.org/document/6034840/,2011 9th IEEE International Conference on Industrial Informatics,26-29 July 2011,ieeexplore
10.1109/CARE.2013.6733739,Cognitive learning enabled real time object search robot,IEEE,Conferences,"Object Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Most works are focused on a specific application, such as tracking human, car, or pre-learned objects. All these require database and considerable amount of training time to detect the current object and to track it. In this paper we propose a method to track objects where a pre-stored database is not a requirement. The proposed method uses a combination of Scale Invariant Feature Transform (SIFT) based feature extraction, Kalman filter and Cognitive learning. The algorithm has the ability to make its own database of the objects in the due course of time by interacting with the user through text based communication. This algorithm is deployed on a search robot which does the operation of searching an object in real time upon a command from the user. The search operation of robot is made more flexible using Bluetooth wireless communication protocol.",https://ieeexplore.ieee.org/document/6733739/,"2013 International Conference on Control, Automation, Robotics and Embedded Systems (CARE)",16-18 Dec. 2013,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICTAI.2019.00023,Collision-Free Path Finding for Dynamic Gaming and Real Time Robot Navigation,IEEE,Conferences,"Collision-free path finding is crucial for multi-agent traversing environments like gaming systems. An efficient and accurate technique is proposed for avoiding collisions with potential obstacles in virtual and real time environments. Potential field is a coherent technique but it eventuates with various problems like static map usage and pre-calculated potential field map of the environment. It is unsuitable for dynamically changing or unknown environments. Agents can get stuck inside a local minima incompetent in escaping without a workaround implementation. This paper presents efficient and accurate solutions to find collision free path using potential field for dynamic gaming and real time robot navigation. A surfing game in two testing environments with a Gamecar and a physical robot called Robocar is created with dynamic and solid obstacles. Sensor like proximity, line and ultrasonic are used along with the camera as different agents for path finding. The proposed intelligent agent (IA) technique is compared with other path planing algorithms and games in terms of time complexity, cost metrics, decision making complexity, action repertoire, interagent communication, reactivity and temporally continuous. It traverses for 135 meters(m) in 55.8 seconds(s) covering 20 goals and 419.3 m in 8.7 minutes while avoiding 10 local minimas successfully. Proposed technique shows comparable results to path finding with techniques using neural networks and A* algorithm. Experimental results prove the efficiency with run time overload, time complexity and resource consumption of the proposed technique.",https://ieeexplore.ieee.org/document/8995276/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/IDAP.2017.8090332,Color based moving object tracking with an active camera using motion information,IEEE,Conferences,"In this study, a real-time system design, which can track (RGB) targets in dynamic environments with an active camera, was implemented. Object tracking applications are quite important for military, surveillance system and operational robot applications and getting more important day by day. This design allows us tracking an object using fewer cameras. The design consists of three main parts that are object detection, mapping, tracking the object. When the camera catches the object, first it detects the shape of the object and creates bounding box, according to bounding box information, the algorithm calculates the centroid of the object. Object coordinates are determined using centroid of the object then tracking process works by activating motors via Arduino-MATLAB communication. The motors placed on a platform called pan-tilt platform. The platform can turn 270 and 180 degrees on×and y-axis respectively.",https://ieeexplore.ieee.org/document/8090332/,2017 International Artificial Intelligence and Data Processing Symposium (IDAP),16-17 Sept. 2017,ieeexplore
10.1109/HUMANOIDS.2017.8246935,Combining deep learning for visuomotor coordination with object identification to realize a high-level interface for robot object-picking,IEEE,Conferences,"We present a proof of concept to show how a deep network for end-to-end visuomotor learning to grasp is coupled with an attention focus mechanism for state-of-the-art object detection with convolutional neural networks. The cognitively motivated integration of both methods in a single robotic system allows us to realize a high-level interface to use the visuomotor network in environments with several objects, which otherwise would only be usable in environments with a single object. The resulting system is deployed on a humanoid robot, and we perform several real-world grasping experiments that demonstrate the feasibility of our approach.",https://ieeexplore.ieee.org/document/8246935/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/IROS.1996.571056,Combining probabilistic map and dialog for robust life-long office navigation,IEEE,Conferences,A design of mobile robot for robust life-long navigation in office environment is proposed and evaluated. The key idea is combining probabilistic map and dialog with humans for reducing the location uncertainty. Bayesian inference with the map represented by probabilistic automata is used in order to reduce the number of queries and to evaluate the success rate of planned paths. We experimentally implemented the design using a simple Bayesian network with continuous nodes and demonstrated its effectiveness in a real environment.,https://ieeexplore.ieee.org/document/571056/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.23919/ICCAS47443.2019.8971680,Comparison of Object Recognition Approaches using Traditional Machine Vision and Modern Deep Learning Techniques for Mobile Robot,IEEE,Conferences,"In this paper, we consider the problem of object recognition for a mobile robot in an indoor environment using two different vision approaches. Our first approach uses HOG descriptor with SVM classifier as traditional machine vision model while the second approach uses Tiny-YOLOv3 as modern deep learning model. The purpose of this study is to gain intuitive insight of both approaches for understanding the principles behind these techniques through their practical implementation in real world. We train both approaches with our own dataset for doors. The proposed work is assessed through the real-world implementation of both approaches using mobile robot with Zed camera in real world indoor environment and the robustness has been evaluated by comparing and analyzing the experimental results of both models on same dataset.",https://ieeexplore.ieee.org/document/8971680/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
10.1109/IROS.2006.282163,Conceptual Design and Implementation of Arm Wrestling Robot,IEEE,Conferences,"In this paper, we develop a novel robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is intended to play arm wrestling game with real human on a table for entertainment. The designing scenario of the prototype model's hardware is performed. Elbow/wrist force sensors, as a crucial device in the force sensing system, are described in details. Software is developed for device driven and interface. The surface electromyographic (EMG) signals from the upper limb are sampled when a real player competes with the force testing system. By using the method of wavelet packet transformation (WPT), the high-frequency noises can be eliminated effectively and the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments",https://ieeexplore.ieee.org/document/4059139/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/IROS.2009.5354270,Consideration on robotic giant-swing motion generated by reinforcement learning,IEEE,Conferences,"This study attempts to make a compact humanoid robot acquire a giant-swing motion without any robotic models by using reinforcement learning; only the interaction with environment is available. Generally, it is widely said that this type of learning method is not appropriated to obtain dynamic motions because Markov property is not necessarily guaranteed during the dynamic task. However, in this study, we try to avoid this problem by embedding the dynamic information in the robotic state space; the applicability of the proposed method is considered using both the real robot and dynamic simulator. This paper, in particular, discusses how the robot with 5-DOF, in which the Q-Learning algorithm is implemented, acquires a giant-swing motion. Further, we describe the reward effects on the Q-Learning. Finally, this paper demonstrates that the application of the Q-Learning enable the robot to perform a very attractive giant-swing motion.",https://ieeexplore.ieee.org/document/5354270/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223341,Context Dependent Trajectory Generation using Sequence-to-Sequence Models for Robotic Toilet Cleaning,IEEE,Conferences,"A robust, easy-to-deploy robot for service tasks in a real environment is difficult to construct. Record-and-playback (R&amp;P) is a method used to teach motor-skills to robots for performing service tasks. However, R&amp;P methods do not scale to challenging tasks where even slight changes in the environment, such as localization errors, would either require trajectory modification or a new demonstration. In this paper, we propose a Sequence-to-Sequence (Seq2Seq) based neural network model to generate robot trajectories in configuration space given a context variable based on real-world measurements in Cartesian space. We use the offset between a target pose and the actual pose after localization as the context variable. The model is trained using a few expert demonstrations collected using teleoperation. We apply our proposed method to the task of toilet cleaning where the robot has to clean the surface of a toilet bowl using a compliant end-effector in a constrained toilet setting. In the experiments, the model is given a novel offset context and it generates a modified robot trajectory for that context. We demonstrate that our proposed model is able to generate trajectories for unseen setups and the executed trajectory results in cleaning of the toilet bowl.",https://ieeexplore.ieee.org/document/9223341/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/SAUPEC/RobMech/PRASA48453.2020.9041114,Context-Aware Action with a Small Mobile Robot,IEEE,Conferences,"Simultaneous advances in mobile GPU computing and real-time object recognition now enable machines to make decisions and take actions based on the detection of objects of interest in the environment. An implementation of a mobile robot system that combines autonomous exploration and mapping capabilities with a real-time object recognition method based on a deep neural network running on a mobile GPU, is described. The system is able to detect objects of interest and then take real-time actions to interact with the objects, in this case, by moving to acquire inspection-style images of the object, from multiple angles. The robot system is small, self-contained and runs on battery power. The system shows the potential for the development of robotic systems with context awareness, permitting advanced autonomy.",https://ieeexplore.ieee.org/document/9041114/,2020 International SAUPEC/RobMech/PRASA Conference,29-31 Jan. 2020,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICEEE.2011.6106626,Continuous-time neural control for a 2 DOF vertical robot manipulator,IEEE,Conferences,"This paper presents a continuous-time neural control scheme for identification and control of a two degrees of freedom (DOF) direct drive vertical robot manipulator model, on which effects due to friction and gravitational forces are both considered. A recurrent high-order neural network (RHONN) structure is proposed in order to identify the plant model to then, based on this neural structure, derive a neural controller using the backstepping design methodology. The trajectory tracking performance of the neural controller is illustrated via simulations results, which suggest the validity of the proposed approach for its implementation in real-time.",https://ieeexplore.ieee.org/document/6106626/,"2011 8th International Conference on Electrical Engineering, Computing Science and Automatic Control",26-28 Oct. 2011,ieeexplore
10.1109/WHC.2011.5945522,Control of a desktop mobile haptic interface,IEEE,Conferences,"Most haptic devices share two main limits: they are grounded and they have limited workspace. A possible solution is to create haptic interfaces by combining mobile robots and standard grounded force-feedback devices, the so called Mobile Haptic Interfaces (MHIs). However, MHIs are characterized by dynamical limitations due to performance of the employed devices. This paper focuses on basic design issues and presents a novel (prototype) Mobile Haptics Platform that employs the coordination of numerically controlled wheel torques to render forces to a user handle placed on the top of the device. The interface, consisting in a small omni-directional robot, is link-less, fully portable and it has been designed to support home-rehabilitation exercises. In the present paper we shall review relevant choices concerning the functional aspects and the control design. In particular a specific embedded sensor fusion was implemented to allow the device to move on a desk without drifting. The sensor fusion algorithm has been optimized to provide users with a quality force feedback while ensuring accurate position tracking. The two requirements are in contrast each other and a specific variant of the Extended Kalman Filter (EKF) was required to allow the device working.",https://ieeexplore.ieee.org/document/5945522/,2011 IEEE World Haptics Conference,21-24 June 2011,ieeexplore
10.1109/IROS.2012.6385803,Control of contact forces: The role of tactile feedback for contact localization,IEEE,Conferences,"This paper investigates the role of precise estimation of contact points in force control. This analysis is motivated by scenarios in which robots make contacts, either voluntarily or accidentally, with different parts of their body. Control paradigms that are usually implemented in robots with no tactile system, make the hypothesis that contacts occur at the end-effectors only. In this paper we try to investigate what happens when this assumption is not verified. First we consider a simple feedforward force control law, and then we extend it by introducing a proportional feedback term. For both controllers we find the error in the resulting contact force, that is induced by a hypothetic error in the estimation of the contact point. We show that, depending on the geometry of the contact, incorrect estimation of contact points can induce undesired joint accelerations. We validate the presented analysis with tests on a simulated robot arm. Moreover we consider a complex real world scenario, where most of the assumptions that we make in our analytical derivation do not hold. Through tests on the iCub humanoid robot we see how errors in contact localization affect the performance of a parallel force/position controller. In order to estimate contact points and contact forces on the forearm of the iCub we do not use any model of the environment, but we exploit its 6-axis force/torque sensor and its sensorized skin.",https://ieeexplore.ieee.org/document/6385803/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROBOT.1998.677351,Cooperative behavior acquisition in multi-mobile robots environment by reinforcement learning based on state vector estimation,IEEE,Conferences,"This paper proposes a method that acquires robots' behaviors based on the estimation of the state vectors. In order to acquire the cooperative behaviors in multi-robot environments, each learning robot estimates the local predictive model between the learner and the other objects separately. Based on the local predictive models, the robots learn the desired behaviors using reinforcement learning. The proposed method is applied to a soccer playing situation, where a rolling ball and other moving robots are well modeled and the learner's behaviors are successfully acquired by the method. Computer simulations and real experiments are shown and a discussion is given.",https://ieeexplore.ieee.org/document/677351/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/IVS.2000.898390,Coordination strategies for the goal-keeper of a RoboCup mid-size team,IEEE,Conferences,"In robot soccer, as well as in real soccer and in every team effort, coordination between members of a team is a key issue. We describe the coordination strategies that were designed to achieve effective cooperation between a robot goal-keeper and the rest of the ART (Azzurra Robot Team) team that participates in the RoboCup F-2000 (midsize) competitions.",https://ieeexplore.ieee.org/document/898390/,Proceedings of the IEEE Intelligent Vehicles Symposium 2000 (Cat. No.00TH8511),5-5 Oct. 2000,ieeexplore
10.1109/ICNC.2008.718,Corridor-Scene Classification for Mobile Robot Using Spiking Neurons,IEEE,Conferences,"The ability of cognition and recognition for complex environment is very important for a real autonomous robot. A corridor-scene-classifier based on spiking neural networks (SNN) for mobile robot is designed to help the mobile robot to locate correctly. In the SNN classifier, the integrate-and-fire model (IAF) spiking neuron model is used and there is lateral inhibiting in the output layer. The winner-take-all rule is used to modify the connecting weights between the hidden layer and the outputting layer. The experimental results show that the corridor-scene-classifier is effective and it also has strong robustness.",https://ieeexplore.ieee.org/document/4667262/,2008 Fourth International Conference on Natural Computation,18-20 Oct. 2008,ieeexplore
10.1109/IROS.2018.8593374,Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan,IEEE,Conferences,"The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.",https://ieeexplore.ieee.org/document/8593374/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBIO49542.2019.8961433,CyberEarth: a Virtual Simulation Platform for Robotics and Cyber-Physical Systems,IEEE,Conferences,"The increasing sophisticated robot and intelligent system applications require universal visualization platforms which can guarantee the security and efficiency of task process execution in the situation of user-programming and using different kinds of automated equipment. In this paper, we present a universal visualization framework to build up program-driven simulation software of complex robots and intelligent systems by integrating several open-source technical modules, including Ubuntu Linux operation-system, QT Creator IDE environment, ROS robot operation system, OSG(OpenSceneGraph) 3D scene, osgEarth GIS(Geographic Information System)-based 3D scene, and also Python based user-programing robotic script language. Many complex visualization simulation systems of complex tasks in wide area and dynamic scenarios are realized by using this framework. Based on this framework, we built a virtual simulation platform CyberEarth for robotics and Cyber-Physical systems. The typical robotic simulation task, which is a visual coverage task for Multi-Agent/UAV, is also introduced to demonstration the universality of this platform.",https://ieeexplore.ieee.org/document/8961433/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/ROMAN.2018.8525717,Data-driven development of Virtual Sign Language Communication Agents,IEEE,Conferences,"Engaging deaf and hearing people in common discussions requires interfaces to help them understand each other, such as robot agents that translate spoken language into Sign Language (SL) expressions and vice-versa. However, the recognition and generation of signed sentences is a complex task of high dimensionality that cannot be solved in sufficient quality yet. Thus, it is necessary to develop new technologies of improved performances. The sequence to sequence neural network model, traditionally used for machine translation, is adapted to the above two tasks by treating a SL sequence as a multi-dimensional sentence. We defined an encoding of the SL annotations and conducted experiments on the network structure to define a most accurate translation model. This study proves the network trainable and possibly applicable in real-life with an extended dataset, which shall be tested for deployment in virtual translation assistants in the following.",https://ieeexplore.ieee.org/document/8525717/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ICRA48506.2021.9561066,Decentralized Connectivity Maintenance with Time Delays using Control Barrier Functions,IEEE,Conferences,"Connectivity maintenance is crucial for the real world deployment of multi-robot systems, as it ultimately allows the robots to communicate, coordinate and perform tasks in a collaborative way. A connectivity maintenance controller must keep the multi-robot system connected independently from the system’s mission and in the presence of undesired real world effects such as communication delays, model errors, and computational time delays, among others. In this paper we present the implementation, on a real robotic setup, of a connectivity maintenance control strategy based on Control Barrier Functions. During experimentation, we found that the presence of communication delays has a significant impact on the performance of the controlled system, with respect to the ideal case. We propose a heuristic to counteract the effects of communication delays, and we verify its efficacy both in simulation and with physical robot experiments.",https://ieeexplore.ieee.org/document/9561066/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2016.7487617,Decentralized multi-agent exploration with online-learning of Gaussian processes,IEEE,Conferences,"Exploration is a crucial problem in safety of life applications, such as search and rescue missions. Gaussian processes constitute an interesting underlying data model that leverages the spatial correlations of the process to be explored to reduce the required sampling of data. Furthermore, multi-agent approaches offer well known advantages for exploration. Previous decentralized multi-agent exploration algorithms that use Gaussian processes as underlying data model, have only been validated through simulations. However, the implementation of an exploration algorithm brings difficulties that were not tackle yet. In this work, we propose an exploration algorithm that deals with the following challenges: (i) which information to transmit to achieve multi-agent coordination; (ii) how to implement a light-weight collision avoidance; (iii) how to learn the data's model without prior information. We validate our algorithm with two experiments employing real robots. First, we explore the magnetic field intensity with a ground-based robot. Second, two quadcopters equipped with an ultrasound sensor explore a terrain profile. We show that our algorithm outperforms a meander and a random trajectory, as well as we are able to learn the data's model online while exploring.",https://ieeexplore.ieee.org/document/7487617/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS40897.2019.8967874,Deep Dive into Faces: Pose &amp; Illumination Invariant Multi-Face Emotion Recognition System,IEEE,Conferences,"One of the advancements in humanization of robots is its ability to recognize human emotions. Facial expression plays a key role in identifying human emotions relative to other cues. In this research, an intelligent network capable of real-time emotion recognition from multiple faces using deep learning technique is presented. The proposed network is based on Convolution Neural Network (CNN) in which three blocks of Convolution layers for feature extraction and two blocks of Dense layers for classification are used. The novelty of this method lies in recognizing emotions from multiple faces simultaneously in real time and its invariance to head pose, illumination and age factor. Most of reported work in literature for multiple faces is for frontal face without illumination variation. The proposed emotion recognition system is deployed on Raspberry Pi3 B+ for human robot interaction applications and achieved an average accuracy of 95.8% in real time.",https://ieeexplore.ieee.org/document/8967874/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRoM48714.2019.9071857,Deep Learning Approach For Object Tracking Of RoboEye,IEEE,Conferences,"RoboEye is a spherical 3RRR parallel robot which has been developed for its high precision. It can provide high speeds, so can be used for fast tracking tasks. To this end, in this paper proper deep learning approaches are combined with classical control methods. Deep learning algorithms are employed to detect an object of interest among various ones in a monocular image, and then obtain an estimatation of the distance to the camera. So, simultaneous depth estimation, and object detection with a monocular camera for real time implementation is proposed here. For fast calculations, also to overcome manufacturing uncertainties, inverse kinematic equations are computed by a multi-layer perceptron (MLP) network based on real data. Finally, a classical PID controller can perform a fast tracking of the object.",https://ieeexplore.ieee.org/document/9071857/,2019 7th International Conference on Robotics and Mechatronics (ICRoM),20-21 Nov. 2019,ieeexplore
10.1109/UR52253.2021.9494704,Deep Learning based Food Instance Segmentation using Synthetic Data,IEEE,Conferences,"In the process of intelligently segmenting foods in images using deep neural networks for diet management, data collection and labeling for network training are very important but labor-intensive tasks. In order to solve the difficulties of data collection and annotations, this paper proposes a food segmentation method applicable to real-world through synthetic data. To perform food segmentation on healthcare robot systems, such as meal assistance robot arm, we generate synthetic data using the open-source 3D graphics software Blender placing multiple objects on meal plate and train Mask R-CNN for instance segmentation. Also, we build a data collection system and verify our segmentation model on real-world food data. As a result, on our real-world dataset, the model trained only synthetic data is available to segment food instances that are not trained with 52.2% mask AP@all, and improve performance by +6.4%p after fine-tuning comparing to the model trained from scratch. In addition, we also confirm the possibility and performance improvement on the public dataset for fair analysis.",https://ieeexplore.ieee.org/document/9494704/,2021 18th International Conference on Ubiquitous Robots (UR),12-14 July 2021,ieeexplore
10.1109/ICRA.2019.8794187,Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation,IEEE,Conferences,"The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.",https://ieeexplore.ieee.org/document/8794187/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CASE48305.2020.9216881,Deep Learning for Early Damage Detection of Tailing Pipes Joints with a Robotic Device,IEEE,Conferences,"In the mining industry, it is usual to employ several kilometers of pipes to carry tailing from the plant to a dam. Only in the Salobo Mine, a copper operation in the Amazon forest from Vale S.A., there are more than three and a half kilometers of tailing pipes. Since the material passing through the tailing pipe causes an abrasion effect that could lead to failures, regular inspections are needed. However, given the risky environment to perform manual inspections, a teleoperated or autonomous robot is a crucial tool to keep track of the pipe health. In this work, we propose a deep-learning methodology to process the data stream of images from the robot, aiming to detect early failures directly on the onboard computer of the device in real-time. Multiple architectures of deep-learning image classification were evaluated to detect the anomalies. We validated the early damage detection accuracy and pinpointed the approximate location of the anomalies using the Class Activation Mapping of the networks. Then, we tested the runtime for the network architectures that obtained the best results on different hardware to analyze the need for a GPU onboard in the robot. Moreover, we also trained a Single Shot object Detector to find the boundaries of the pipe joints, which means that the anomaly classification is performed only when a joint is detected. Our results show that it is possible to build an automatic anomaly detection system in the software of the robot.",https://ieeexplore.ieee.org/document/9216881/,2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),20-21 Aug. 2020,ieeexplore
10.1109/R10-HTC.2018.8629836,Deep Learning-Based Eye Gaze Controlled Robotic Car,IEEE,Conferences,"In recent years Eye gaze tracking (EGT) has emerged as an attractive alternative to conventional communication modes. Gaze estimation can be effectively used in human-computer interaction, assistive devices for motor-disabled persons, autonomous robot control systems, safe car driving, diagnosis of diseases and even in human sentiment assessment. Implementation in any of these areas however mostly depends on the efficiency of detection algorithm along with usability and robustness of detection process. In this context we have proposed a Convolutional Neural Network (CNN) architecture to estimate the eye gaze direction from detected eyes which outperforms all other state of the art results for Eye-Chimera dataset. The overall accuracies are 90.21% and 99.19% for Eye-Chimera and HPEG datasets respectively. This paper also introduces a new dataset EGDC for which proposed algorithm finds 86.93% accuracy. We have developed a real-time eye gaze controlled robotic car as a prototype for possible implementations of our algorithm.",https://ieeexplore.ieee.org/document/8629836/,2018 IEEE Region 10 Humanitarian Technology Conference (R10-HTC),6-8 Dec. 2018,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IJCNN.2018.8489239,Deep Learning-based Cooperative Trail Following for Multi-Robot System,IEEE,Conferences,"Following trails in the wild is an essential capability of out-door autonomous mobile robots. Recently, deep learning-based approaches have made great advancements in this field. However, the existing research only focuses on the trail following with a single robot. In contrast, many robotic tasks in the reality, such as search and patrolling, are conducted by a group of robots. While these robots are grouped to move in the wild, they can cooperate to significantly promote the trail following accuracy, for example, by sharing images of different view angles or real-time decision fusion. This paper proposes such an approach named DL-Cooper that enables multi-robot vision-based trail following based on deep learning algorithms. It allows each robot to make a decision respectively with deep neural network and then fusion the decisions on the collective level with the support of back-end cloud computing infrastructure. It also takes Quality of Service (QoS) assurance, a very essential property of robotic software, into consideration. By limiting the condition to fusion decisions, the time latency can be minimally sacrificed. Experiments on the real-world dataset show that our approach has significantly improved the accuracy of the single-robot system.",https://ieeexplore.ieee.org/document/8489239/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/IJCNN48605.2020.9207332,Deep Reinforcement Learning Control of Hand-Eye Coordination with a Software Retina,IEEE,Conferences,"Deep Reinforcement Learning (DRL) has gained much attention for solving robotic hand-eye coordination tasks from raw pixel values. Despite promising results, training agents using images is hardware intensive often requiring millions of training steps to converge incurring long training times and increased risk of wear and tear on the robot. To speed up training, images are often cropped and downscaled resulting in a smaller field of view and loss of valuable high-frequency data. In this paper, we propose training the vision system using supervised learning prior to training robotic actuation using Deep Deterministic Policy Gradient (DDPG). The vision system uses a software retina, based on the mammalian retino-cortical transform, to preprocess full-size images to compress image data while preserving the full field of view and high-frequency visual information around the fixation point prior to processing by a Deep Convolutional Neural Network (DCNN) to extract visual state information. Using the vision system to preprocess the environment improves the agent's sample complexity and network update speed leading to significantly faster training with reduced image data loss. Our method is used to train a DRL system to control a real Baxter robot's arm, processing full-size images captured by an in-wrist camera to locate an object on a table and centre the camera over it by actuating the robot arm.",https://ieeexplore.ieee.org/document/9207332/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/IV48863.2021.9575616,Deep Reinforcement Learning based control algorithms: Training and validation using the ROS Framework in CARLA Simulator for Self-Driving applications,IEEE,Conferences,"This paper presents a Deep Reinforcement Learning (DRL) framework adapted and trained for Autonomous Vehicles (AVs) purposes. To do that, we propose a novel software architecture for training and validating DRL based control algorithms that exploits the concepts of standard communication in robotics using the Robot Operating System (ROS), the Docker approach to provide the system with portability, isolation and flexibility, and CARLA (CAR Learning to Act) as our hyper-realistic open-source simulation platform. First, the algorithm is introduced in the context of Self-Driving and DRL tasks. Second, we highlight the steps to merge the proposed algorithm with ROS, Docker and the CARLA simulator, as well as how the training stage is carried out to generate our own model, specifically designed for the AV paradigm. Finally, regarding our proposed validation architecture, the paper compares the trained model with other state-of-the-art traditional control approaches, demonstrating the full strength of our DL based control algorithm, as a preliminary stage before implementing it in our real-world autonomous electric car.",https://ieeexplore.ieee.org/document/9575616/,2021 IEEE Intelligent Vehicles Symposium (IV),11-17 July 2021,ieeexplore
10.23919/ICCAS50221.2020.9268370,Deep Reinforcement Learning-based ROS-Controlled RC Car for Autonomous Path Exploration in the Unknown Environment,IEEE,Conferences,"Nowadays, Deep reinforcement learning has become the front runner to solve problems in the field of robot navigation and avoidance. This paper presents a LiDAR-equipped RC car trained in the GAZEBO environment using the deep reinforcement learning method. This paper uses reshaped LiDAR data as the data input of the neural architecture of the training network. This paper also presents a unique way to convert the LiDAR data into a 2D grid map for the input of training neural architecture. It also presents the test result from the training network in different GAZEBO environment. It also shows the development of hardware and software systems of embedded RC car. The hardware system includes-Jetson AGX Xavier, teensyduino and Hokuyo LiDAR; the software system includes-ROS and Arduino C. Finally, this paper presents the test result in the real world using the model generated from training simulation.",https://ieeexplore.ieee.org/document/9268370/,"2020 20th International Conference on Control, Automation and Systems (ICCAS)",13-16 Oct. 2020,ieeexplore
10.1109/ICARSC52212.2021.9429811,Deep Reinforcement Multi-Directional Kick-Learning of a Simulated Robot with Toes,IEEE,Conferences,"This paper describes a thorough analysis of using PPO to learn kick behaviors with simulated NAO robots in the simspark environment. The analysis includes an investigation of the influence of PPO hyperparameters, network size, training setups and performance in real games. We believe to improve the state of the art mainly in four points: first, the kicks are learned with a toed version of the NAO robot, second, we improve the reliability with respect to kickable area and avoidance of falls, third, the kick can be parameterized with desired distance and direction as input to the deep network and fourth, the approach allows to integrate the learned behavior seamlessly into soccer games. The result is a significant improvement of the general level of play.",https://ieeexplore.ieee.org/document/9429811/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/ICUAS.2019.8797770,Deep learning based semantic situation awareness system for multirotor aerial robots using LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots, based on 2D LIDAR measurements, targeting the understanding of the environment and assuming to have a precise robot localization as an input of our algorithm. Our proposed situation awareness system calculates a semantic map of the objects of the environment as a list of circles represented by their radius, and the position and the velocity of their center in world coordinates. Our proposed algorithm includes three main parts. First, the LIDAR measurements are preprocessed and an object segmentation clusters the candidate objects present in the environment. Secondly, a Convolutional Neural Network (CNN) that has been designed and trained using an artificially generated dataset, computes the radius and the position of the center of individual circles in sensor coordinates. Finally, an indirect-EKF provides the estimate of the semantic map in world coordinates, including the velocity of the center of the circles in world coordinates.We have quantitative and qualitative evaluated the performance of our proposed situation awareness system by means of Software-In-The-Loop simulations using VRep with one and multiple static and moving cylindrical objects in the scene, obtaining results that support our proposed algorithm. In addition, we have demonstrated that our proposed algorithm is capable of handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) and moving (i.e. a person) objects.",https://ieeexplore.ieee.org/document/8797770/,2019 International Conference on Unmanned Aircraft Systems (ICUAS),11-14 June 2019,ieeexplore
10.1109/ASCC.2017.8287420,Deep learning for picking point detection in dense cluster,IEEE,Conferences,"This paper considers the problem of picking objects in cluster. This requires the robot to reliably detect the picking point for the known or unseen objects under the environment with occlusion, disorder and a variety of objects. We present a novel pipeline to detect picking point based on deep convolutional neural network (CNN). A two-dimensional picking configuration is proposed, thus an extensive data augmentation strategy is enabled and a labeled dataset is established quickly and easily. At last, we demonstrate the implementation of our method on a real robot and show that our method can accurately detect picking point of unseen objects and achieve a pick success of 91% in cluster bin-picking scenario.",https://ieeexplore.ieee.org/document/8287420/,2017 11th Asian Control Conference (ASCC),17-20 Dec. 2017,ieeexplore
10.1109/IROS.2017.8206046,Deep predictive policy training using reinforcement learning,IEEE,Conferences,"Skilled robot task learning is best implemented by predictive action policies due to the inherent latency of sensorimotor processes. However, training such predictive policies is challenging as it involves finding a trajectory of motor activations for the full duration of the action. We propose a data-efficient deep predictive policy training (DPPT) framework with a deep neural network policy architecture which maps an image observation to a sequence of motor activations. The architecture consists of three sub-networks referred to as the perception, policy and behavior super-layers. The perception and behavior super-layers force an abstraction of visual and motor data trained with synthetic and simulated training samples, respectively. The policy super-layer is a small subnetwork with fewer parameters that maps data in-between the abstracted manifolds. It is trained for each task using methods for policy search reinforcement learning. We demonstrate the suitability of the proposed architecture and learning framework by training predictive policies for skilled object grasping and ball throwing on a PR2 robot. The effectiveness of the method is illustrated by the fact that these tasks are trained using only about 180 real robot attempts with qualitative terminal rewards.",https://ieeexplore.ieee.org/document/8206046/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/RCAR49640.2020.9303294,Deep-Learning Based Robotic Manipulation of Flexible PCBs,IEEE,Conferences,"In the past 10 years, due to the fast development of 3C industries such as mobile phones and computers, people have higher requirements for the automatic soldering technology of flexible PCBs. However, the deformation and the small size of flexible PCBs open up significant challenges to robotic soldering. This paper proposes a deep-learning based manipulation scheme for automatic soldering of flexible PCBs. The proposed controller can enable the robot to automatically contact the flexible PCB first, then actively control the flexible PCB to the desired position with the visual feedback, and finally, the soldering machine will solder the flexible PCBs smoothly. First, the approach of deep learning is used to detect the position of the solder pad (feature). Then, the vision-based controller drives the robot to manipulate the solder pad to the desired position, such that the soldering machine can work to solder two pieces of flexible PCBs together. The use of a deep learning approach can explore the human's experience to improve the accuracy of detection and hence deals with the issues of clustered environment, change of illumination, and different initial position, etc. The proposed detection approach and control scheme is implemented in a soldering robot for flexible PCBs and the results validate the performance of the proposed methods.",https://ieeexplore.ieee.org/document/9303294/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/CVPR.2019.00346,DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion,IEEE,Conferences,"A key technical challenge in performing 6D object pose estimation from RGB-D image is to fully leverage the two complementary data sources. Prior works either extract information from the RGB image and depth separately or use costly post-processing steps, limiting their performances in highly cluttered scenes and real-time applications. In this work, we present DenseFusion, a generic framework for estimating 6D pose of a set of known objects from RGB-D images. DenseFusion is a heterogeneous architecture that processes the two data sources individually and uses a novel dense fusion network to extract pixel-wise dense feature embedding, from which the pose is estimated. Furthermore, we integrate an end-to-end iterative pose refinement procedure that further improves the pose estimation while achieving near real-time inference. Our experiments show that our method outperforms state-of-the-art approaches in two datasets, YCB-Video and LineMOD. We also deploy our proposed method to a real robot to grasp and manipulate objects based on the estimated pose.",https://ieeexplore.ieee.org/document/8953386/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/ICRA.2013.6631325,Deploying artificial landmarks to foster data association in simultaneous localization and mapping,IEEE,Conferences,"Data association is an essential problem in simultaneous localization and mapping. It is hard to solve correctly, especially in ambiguous environments. We consider a scenario where the robot can ease the data association problem by deploying a limited number of uniquely identifiable artificial landmarks along its path and use them afterwards as fixed anchors. Obviously, the choice of the positions where the robot should drop these markers is crucial as poor choices might prevent the robot from establishing accurate data associations. In this paper, we present a novel approach for learning when to drop the landmarks so as to optimize the data association performance. We use Monte Carlo reinforcement learning for computing an optimal policy and apply a statistical convergence test to decide if the policy is converged and the learning process can be stopped. Extensive experiments also carried out with a real robot demonstrate that the data association performance using landmarks deployed according to our learned policies is significantly higher compared to other strategies.",https://ieeexplore.ieee.org/document/6631325/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/FPL.2005.1515790,Design and FPGA implementation of an embedded real-time biologically plausible spiking neural network processor,IEEE,Conferences,"The implementation of a large scale, leaky-integrate-and-fire neural network processor using the Xilinx Virtex-II family of field programmable gate array (FPGA) is presented. The processor has been designed to model biologically plausible networks of spiking neurons in real-time to assist with the control of a mobile robot. The real-time constraint has led to a re-evaluation of some of the established architectural and algorithmic features of previous spiking neural network based hardware. The design was coded and simulated using Handel-C hardware description language (HDL) and the DK3 design suite from Celoxica. The processor has been physically implemented and tested on a RC200 development board, also from Celoxica.",https://ieeexplore.ieee.org/document/1515790/,"International Conference on Field Programmable Logic and Applications, 2005.",24-26 Aug. 2005,ieeexplore
10.1109/BDAI52447.2021.9515251,Design and Simulation of Tracked Mobile Robot Path Planning,IEEE,Conferences,"Aiming at the problem of autonomous navigation of robots in unknown environments, the robot operating system ROS is used as a development platform, and an autonomous navigation system is designed based on open source function packages such as Gmapping and Navigation, so that robots equipped with this system can learn map information in unknown environments. And based on the map to achieve positioning, path planning, obstacle avoidance and other functions. The 3D physical simulation software Gazebo simulates the environment and loads the designed URDF robot model to simulate and verify the autonomous navigation system. The results show that the autonomous navigation system can enable the robot to achieve accurate mapping, positioning, real-time obstacle avoidance and path planning in an unknown environment.",https://ieeexplore.ieee.org/document/9515251/,2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI),2-4 July 2021,ieeexplore
10.1109/AINL-ISMW-FRUCT.2015.7382967,Design and implementation Raspberry Pi-based omni-wheel mobile robot,IEEE,Conferences,Nowadays simultaneous localization and mapping (SLAM) algorithms are being tested at least in two phases: software simulation and real hardware platform testing. This paper describes hardware design and control software for small size omni-directional wheels robot implemented for indoor testing SLAM algorithms.,https://ieeexplore.ieee.org/document/7382967/,"2015 Artificial Intelligence and Natural Language and Information Extraction, Social Media and Web Search FRUCT Conference (AINL-ISMW FRUCT)",9-14 Nov. 2015,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/ITAIC.2019.8785457,Design and implementation of a cooperative dual body vehicle,IEEE,Conferences,"In order to reduce the over-dependence of low-cost underwater vehicles on cables, and considering that it is difficult to transmit radio signals underwater, proposeding a design scheme of vehicle combining unmanned ship with underwater vehicles on the basis of the ROS platform (robot operating system).The work shows that under the condition of reasonable utilization of ROS compatibility, advantages of USV (unmanned surface vessel) and ROV (remote operating vehicle) can be complemented greatly. The USV shares part of the functions of the underwater working module, while providing auxiliary means for inertial navigation devices, it maintains better endurance and maneuverability. ROV which focuses on underwater operation has practical functions and low volume, thus saving production costs. This system has navigation performance, intelligent level, remote control ability and expansion ability, which can provide reference for the design of some low cost underwater vehicles in a way.",https://ieeexplore.ieee.org/document/8785457/,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),24-26 May 2019,ieeexplore
10.1109/ICMLC.2009.5212155,Design and implementation of a visual servo system,IEEE,Conferences,"Robot visual servo system has an important status in robotic research and application, also has a decisive influence on robot intelligence. According to robotic kinematics and dynamics, the method of visual servo controller based on position is adopted in this paper. Binocular camera stereo vision technology and a kind of real-time control card Q8 based on MATLAB are used in motion control. The paper describes the control structure, hardware, software, designs a visual servo system platform and implements the real-time mission that track, capture or access moving targets on the platform.",https://ieeexplore.ieee.org/document/5212155/,2009 International Conference on Machine Learning and Cybernetics,12-15 July 2009,ieeexplore
10.1109/ICMA.2017.8015890,Design and implementation of self-tuning control method for the underwater spherical robot,IEEE,Conferences,"Considering the complicated disturbance in underwater circumstance, usually it is difficult to solve the control problem when the robot changes its motion state or it is subject to ocean currents, its performance deteriorates since the fixed set of parameters is no longer valid for the new conditions. Thus, in this paper, an auto-tune PID (Proportional + Integral + Derivative)-like controller based on Neural Networks is applied to our amphibious spherical underwater robot, which has a great advantage on processing online for the robot due to their nonlinear dynamics. The Neural Networks (NN) plays the role of automatically estimating the suitable set of PID gains that achieves stability of the system. The NN adjusts online the controller gains that attain the smaller position tracking error. The performance of the NN-based controller is investigated in ADAMS and MATLAB cooperative simulation. The velocity of the spherical robot can be controlled to precisely track desired trajectory in body-fixed coordinate system. Additionally, real time experiments on our underwater spherical robot are conducted to show the effectiveness of the algorithm.",https://ieeexplore.ieee.org/document/8015890/,2017 IEEE International Conference on Mechatronics and Automation (ICMA),6-9 Aug. 2017,ieeexplore
10.1109/AEMCSE51986.2021.00262,Design of Motion Control System of Handling Robot,IEEE,Conferences,"Handling robots are very important for improving productivity, reducing work intensity, improving the surrounding environment, and ensuring work safety. Based on the kinematics analysis of a two-degree-of-freedom manipulator based on a slider mechanism, this paper uses an open motion controller as a development platform to carry out hardware design and software development to realize the flexible control of the handling robot, with simple structure and real-time control, open structure, standard programming and rich man-machine interface, etc. which can be widely used in material destacking and palletizing handling.",https://ieeexplore.ieee.org/document/9513197/,"2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)",26-28 March 2021,ieeexplore
10.1109/AIEA53260.2021.00013,Design of a Real-time Robot Control System oriented for Human-Robot Cooperation,IEEE,Conferences,"An open real-time control system based on the EtherCAT fieldbus communication technology is proposed to fulfill the high real-time requirement of the human-robot cooperation controller in this paper. An open source real-time kernel of Xenomai is employed as the real-time software platform of the robot control system. Based on this, four-layer interfaces architecture are accomplished, which are human-machine cooperation control layer, motion control layer, robot axis control layer and hardware abstraction layer, through the corresponding four real-time tasks to meet the demand of human-robot cooperation operations. In addition, the scheduling task is developed to manage the 4 real-time tasks. The dual buffer communication mechanisms and priority-based scheduling strategy between layers was exploited to synchronize these real-time tasks. The underlying hardware abstract interface and the human-robot collaborative control algorithm interface are opened in the control system as the quadric exploitation interfaces to meet the need of developing application tasks in real-time space. Experiment results which are conducted on a self-developed 6-DOF collaborative robot show that the proposed control system is effective in real-time control applications of human-robot cooperative control at the control cycle of 5 milliseconds.",https://ieeexplore.ieee.org/document/9525600/,2021 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA),14-16 May 2021,ieeexplore
10.1109/SECON.2008.4494306,Design of an integrated environment for operation and control of robotic arms (non-reviewed),IEEE,Conferences,"As more advanced control algorithms are becoming available for the control of robotic arms, traditional fixed controller boards and associated code generators are becoming less convenient way to test such control algorithms in real-time. The process of using such boards is complex, time consuming, and inflexible. In this work, an integrated hardware-software environment was developed and presented where researchers can simply use any Matlab/Simulink basic function block and/or toolbox, such as fuzzy logic or neural network, to design, implement, and test different controller algorithms in realtime for robotic arm operations. The hardware includes a computer, the dSPACE-ds1103 digital processing board, an amplifier board, and the Zebra-ZERO robotics arm as a test-bed. Also, Matlab GUI, m-file, Matlab/Simulink blocks, and dSPACE interface functions are combined together to form the software environment. Control algorithms can be designed in the Matlab/Simulink then converted to c-code and download to the dSPACE processing board. The Matlab m-file are used to code the arm inverse kinematics model and the path planning to calculate the joint angles then send them to the dSPACE processing board using the dSPACE interface functions. Finally, the dSPACE processing board generates physical signal to control the robot arm in real-time. The proposed hardware-software components are developed and integrated together, and several control algorithms can be tested on it. The development steps and some of the realtime testing results conducted on the hardware are explained next in this extended abstract. Typically, controllers are designed to run on dedicated hardware and researchers need different hardware to test different control strategies. This can be costly and time consuming where one has to develop different control environment for every control strategy to be tested. In this work, an integrated hardware-software environment was developed for implementation and testing of different control algorithms in real-time. The integrated system is composed of a computer, a power supply, the DS1103 dSPACE controller board, an amplifier, and the Zebra- Zero force robotics arm. The computer is used to send commands to the DS1103 dSPACE controller board.Inside the DS1103 dSPACE controller board, a Texas instruments DSP micro-controller performs the necessary calculation to determine the PWM signal to be generated and sent to the amplifier. The amplifier then generates the control signals that are applied to dc-motors that drive the links. The motor encoders provide feedback position signals as output. To develop the software environment, the Matlab programming environment (m-file), Matlab's graphical user interface, Simulink, and the toolbox are all employed. A user graphical interface (GUI) was designed for user convenience. The robot can be moved to the ready position then, the forward or inverse kinematical model is chosen according to the type of input data. The links begin to move when the Move button is pressed. The user can also select different movement speed for each link. Finally, when link movement has ceased, the joint trajectories are displayed on the GUI. Trajectory planning files for position, velocity and acceleration references are also developed and implemented in the environment. Two types of trajectories are made available according to different requirements; second order polynomial and third-order polynomial trajectory. The second order polynomial trajectory is recommended for links with large angular position difference. For purpose of testing and verification, the Zebra-Zero robotics arm was used. The Lagrangian mechanics is used to develop the dynamic equations for the Zebra-Zero robotic arm. Some of the arm parameters are calculated while others are determined experimentally, e.g., the link inertias and masses. A Simulink model of the robotic arm dynamic was developed. To test the environment a control algorithm was also designed then automatically converted to C programming language and downloaded to the DS1103 dSPACE controller board. The user enters commands using the Matlab GUI. Based on input, positions or final location and orientation, the forward or inverse kinematical model is selected. In this work a PID control algorithm was designed and tested on the Zebra- Zero robotics arm. To verify the controller performance, Matlab toolbox was used to simulate the Zebra-Zero robotic arm dynamics model. The results were very comparable with the actual Zebra-Zero robotic arm hardware performance.",https://ieeexplore.ieee.org/document/4494306/,IEEE SoutheastCon 2008,3-6 April 2008,ieeexplore
10.1109/TENCON.2016.7848000,Design of hardware circuit based on a neural network model for rapid detection of center of gravity position,IEEE,Conferences,"This paper proposes a rapid detection method for the center of gravity based on a neural network model. It is suitable for the rapid response requirement such as attitude control of a gait robot or real time torque control of a running car. The proposed method detects the center of gravity position on a straight line by using only the hardware circuit composing of common electronic devices instead of software, microprocessor and AD converter. The circuit employs some neural based comparators without the learning function to simplify the circuit structure. The detection circuit using some parallel processing neural comparators rapidly detects the center of gravity position on a straight line. In this paper, the circuit is designed and fabricated with electronic devices, and the circuit experiment shows the performance of the position detection.",https://ieeexplore.ieee.org/document/7848000/,2016 IEEE Region 10 Conference (TENCON),22-25 Nov. 2016,ieeexplore
10.1109/CMCE.2010.5609659,Design of mobile robot system with remote control based on CAN-bus,IEEE,Conferences,"In order to realizing remote control and information collection quickly and reliably, the mobile robot with remote control is designed. In the paper, according to analysis of the overall structure, hardware circuit of the robot system is designed. Because the CAN2.0 standard only makes physical layer protocol and data link layer protocol, application layer protocol is ruled according to robot control system. In the last part of this paper, the software of master/slave computer is introduced in detail. The experiment shows that running performance of robot control system is balanced, efficient and has satisfied the practical demand.",https://ieeexplore.ieee.org/document/5609659/,"2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering",24-26 Aug. 2010,ieeexplore
10.1109/IROS.1999.813052,Designing rhythmic motions using neural oscillators,IEEE,Conferences,"Neural oscillators offer simple and robust solutions to problems such as locomotion and dynamic manipulation. However, the parameters of these systems are notoriously difficult to tune. This paper presents an analysis technique which alleviates the difficulty of tuning. The method is based on describing function analysis, and can predict the steady state motion of the system, analyze stability, and be used to determine robustness to system changes. The method is illustrated using a number of design examples including an implementation of juggling on a real robot.",https://ieeexplore.ieee.org/document/813052/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/ICSMC.1998.726514,"Designing, making, and using a mobile robot",IEEE,Conferences,"Describes the building and control of a mobile robot which is capable of navigating in a well defined workspace by means of generating an optimal trajectory. The basic control architecture of the mobile robot is implemented with a combination of an MC68HC11 microcontroller and a personal computer. The kinematics of the proposed differential impulse is analyzed which allow us to select the appropriate steering DC motors and speed measurement requirements of the system. The motor control is performed by a PWM scheme and PI controllers. A path planning stage finds the optimal trajectory, taking a graphical description of the workspace and using potential fields and dynamic programming to solve the optimization problem and avoid the obstacles. Clearly there are two specific problems: building a complete device that will allow having an electric powered robot and the use of these resources to obtain controlled and collision-free movement in a real workspace.",https://ieeexplore.ieee.org/document/726514/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICoSTA48221.2020.1570615971,Detecting Features of Middle Size Soccer Field using Omnidirectional Camera for Robot Soccer ERSOW,IEEE,Conferences,"ERSOW (EEPIS Robot Soccer on Wheeled) is robot soccer developed by Politeknik Elektronika Negeri Surabaya that is designed and implemented on a Middle Size League division by following the rules of RoboCup, an international robot competition. One of the most famous division is a soccer robot, that is divided into two divisions: (1) SSL (Small Size League) and (2) MSL (Middle Size League). There are many research fields related to soccer robot which must be developed in robot ERSOW such as Artificial Intelligence (AI), Computer Vision, Embedded System, Mechanic Systems, and Hardware. This paper focuses on computer vision research for robot ERSOW, especially detecting features of the middle size soccer field, so that specific features of the field like X-junction, T-junction and L-junction can be detected to help robot positioning task where the result is represented into x and y in real-world coordinate. By knowing the position of the features, the robot position can be calculated. The localization system at robot ERSOW uses odometry, which has a large percentage of data errors. Therefore, we attempt to extract the feature of X-junction that is done to find its x and y coordinates and then the obtained coordinate can be used as a reference for correcting odometry data by AI.",https://ieeexplore.ieee.org/document/9079260/,2020 International Conference on Smart Technology and Applications (ICoSTA),20-20 Feb. 2020,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/IROS.2018.8594335,Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline,IEEE,Conferences,"In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.",https://ieeexplore.ieee.org/document/8594335/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/MHS.2000.903293,Developing Khepera robot applications in a Webots environment,IEEE,Conferences,"Khepera is a high performance mini-robot. Its compact power allows an efficient experimentation using a real robot and applying the basic simulation tools. Webots is a high quality Khepera simulator used in the fields of autonomous systems, intelligent robotics, evolutionary robotics, machine learning, computer vision, and artificial intelligence. The simulation program can be transferred to the real robots easily. The aim of this article is to support the development of Khepera applications in the Webots environment. Starting from the introduction of Khepera robot and its development methodologies, the paper presents and analyses an application example of Khepera robot in the Webots environment. Finally, current applications and future research directions are presented.",https://ieeexplore.ieee.org/document/903293/,MHS2000. Proceedings of 2000 International Symposium on Micromechatronics and Human Science (Cat. No.00TH8530),22-25 Oct. 2000,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ROBOT.2004.1307521,Development and deployment of a line of sight virtual sensor for heterogeneous teams,IEEE,Conferences,"For a team of cooperating robots, geometry plays a vital role in operation. Knowledge of line of sight to local obstacles and adjacent teammates is critical in both the movement and planning stages to avoid collisions, maintain formation and localize the team. However, determining if other robots are within the line of sight of one another is difficult with existing sensor platforms - especially as the scale of the robot is reduced. We describe a method of exploiting collective team information to generate a virtual sensor that provides line of sight determination, greater range and resolution and the ability to generalize local sensing. We develop this sensor and apply it to the control of a tightly coupled, resource-limited robot team called Millibots.",https://ieeexplore.ieee.org/document/1307521/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/FarEastCon.2019.8934756,Development of a Software and Hardware Anthropomorphic Robotic Appliance Interacting with a Student by Means of Electroencephalographic Signals for Teachers,IEEE,Conferences,"This article describes a method to control the educational process using a software and hardware appliance - a humanoid robot - to help teachers. The baseline data to analyze a student's condition are represented by electroencephalographic signals recorded online. Analysis of electroencephalographic signals included several stages, such as removal of artifacts caused by, for instance, oculomotor activity; distinction between brain activity patterns; preprocessing of data of the distinguished brain activity patterns; data analysis to determine the level of attention concentration, presence/absence of unwanted (not corresponding with the requirements of the current assignment) motor activity, etc. Electroencephalographic signals are analyzed using artificial neural networks. The signals obtained in laboratory conditions at rest, at real and imaginary motor activity of hands and legs separately were used to train artificial neural networks. Study results demonstrate satisfactory results of assessing condition of students in the educational process.",https://ieeexplore.ieee.org/document/8934756/,2019 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon),1-4 Oct. 2019,ieeexplore
10.1109/FarEastCon.2018.8602651,Development of a Transport Robot for Automated Warehouses,IEEE,Conferences,"Industrial robots and manipulators are widely used as transport-loading devices in automated production. It is possible to combine equipment into coordinated production complexes of various sizes with the help of robots and they will not be bound by rigid planning and the number of installed units. Transport robots have proven themselves as flexible automated means of realizing intra-shop and interoperation material connections. More and more companies are developing technologies for vehicles through which they can communicate with each other and use real-time data from production infrastructure facilities. Electric vehicles and unmanned vehicles have become a new technological trend. In this regard, the paper deals with a prototype of an innovative transport robot, created for automated warehouses. It is proposed to use a computer vision system with image recognition based on the embedded software for the transport robot positioning inside the production facilities. The algorithm of deep machine learning was adapted to solve this problem. Using this algorithm, the prototype tests were performed successfully.",https://ieeexplore.ieee.org/document/8602651/,2018 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon),3-4 Oct. 2018,ieeexplore
10.1109/ICSSE.2011.5961891,Development of simulator for kid-sized humanoid soccer in RoboCup,IEEE,Conferences,"The robot soccer game system is a challenge for real-time control, which can be moderately abstracted from the standpoint of AI (Artificial Intelligence) and multi-agent systems. This simulator is developed for RoboCup Soccer Humanoid League. A humanoid robot belongs to highly intelligent system. The intelligent technologies of the humanoid robots include mechanism design, vision system, and algorithms in software programming. Therefore, its competitions can encourage creativity and technical development. To facilitate the strategy testing of these humanoid robot soccer competitions, a strategy simulator for kid-sized humanoid soccer in RoboCup is proposed. In this simulator, strategies compiled to DLL files may be explicitly loaded at run-time.",https://ieeexplore.ieee.org/document/5961891/,Proceedings 2011 International Conference on System Science and Engineering,8-10 June 2011,ieeexplore
10.1109/DEVLRN.2018.8761037,Developmental Bayesian Optimization of Black-Box with Visual Similarity-Based Transfer Learning,IEEE,Conferences,"We present a developmental framework based on a long-term memory and reasoning mechanisms (Vision Similarity and Bayesian Optimisation). This architecture allows a robot to optimize autonomously hyper-parameters that need to be tuned from any action and/or vision module, treated as a black-box. The learning can take advantage of past experiences (stored in the episodic and procedural memories) in order to warm-start the exploration using a set of hyper-parameters previously optimized from objects similar to the new unknown one (stored in a semantic memory). As example, the system has been used to optimized 9 continuous hyper-parameters of a professional software (Kamido) both in simulation and with a real robot (industrial robotic arm Fanuc) with a total of 13 different objects. The robot is able to find a good object-specific optimization in 68 (simulation) or 40 (real) trials. In simulation, we demonstrate the benefit of the transfer learning based on visual similarity, as opposed to an amnesic learning (i.e. learning from scratch all the time). Moreover, with the real robot, we show that the method consistently outperforms the manual optimization from an expert with less than 2 hours of training time to achieve more than 88% of success.",https://ieeexplore.ieee.org/document/8761037/,2018 Joint IEEE 8th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),17-20 Sept. 2018,ieeexplore
10.1109/ICRA48506.2021.9562061,Dexterous Manoeuvre through Touch in a Cluttered Scene,IEEE,Conferences,"Manipulation in a densely cluttered environment creates complex challenges in perception to close the control loop, many of which are due to the sophisticated physical interaction between the environment and the manipulator. Drawing from biological sensory-motor control, to handle the task in such a scenario, tactile sensing can be used to provide an additional dimension of the rich contact information from the interaction for decision making and action selection to manoeuvre towards a target. In this paper, a new tactile-based motion planning and control framework based on bioinspiration is proposed and developed for a robot manipulator to manoeuvre in a cluttered environment. An iterative two-stage machine learning approach is used in this framework: an autoencoder is used to extract important cues from tactile sensory readings while a reinforcement learning technique is used to generate optimal motion sequence to efficiently reach the given target. The framework is implemented on a KUKA LBR iiwa robot mounted with a SynTouch BioTac tactile sensor and tested with real-life experiments. The results show that the system is able to move the end-effector through the cluttered environment to reach the target effectively.",https://ieeexplore.ieee.org/document/9562061/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/CCTA41146.2020.9206279,Direct Force Feedback using Gaussian Process based Model Predictive Control,IEEE,Conferences,"Many robotic applications require control of the applied forces or moments. Model predictive control allows for the direct or indirect control of forces, while taking constraints into account. However, challenges arise when the robot environment that affects the force is highly variable, uncertain and difficult to model. Learning supported model predictive control makes it possible to combine the advantages of optimal control, such as the explicit consideration of constraints, with the advantages of machine learning, such as adaptive data-based modeling. In this paper Gaussian processes are used to model the contact forces that are applied in model predictive force control. The Gaussian process learns the static output mapping describing the interaction of the robot with the environment. It is shown that stability guarantees can be derived in a similar way as in classical predictive control. A proof-of-concept experimental implementation of a direct hybrid position force controller for a lightweight robot shows real-time feasibility.",https://ieeexplore.ieee.org/document/9206279/,2020 IEEE Conference on Control Technology and Applications (CCTA),24-26 Aug. 2020,ieeexplore
10.1109/IJCNN48605.2020.9207522,Discrete-Time Lyapunov based Kinematic Control of Robot Manipulator using Actor-Critic Framework,IEEE,Conferences,"Stability and optimality are the two foremost re-quirements for robotic systems that are deployed in critical operations and are to work for long hours or under limited energy resources. To address these, in this work we present a novel Lyapunov stability based discrete-time optimal kinematic control of a robot manipulator using actor-critic (AC) framework. The robot is actuated using optimal joint-space velocity control input to track a time-varying end-effector trajectory in its task space. In comparison to the existing near-optimal kinematic control solutions for robot manipulator under AC framework, proposed controller exhibits guaranteed analytical stability. We derive a novel critic weight update law based on Lyapunov stability, thus ensuring that the weights are updated along the negative gradient of Lyapunov function. This eventually ensures closed-loop system stability and convergence to the optimal control in discrete-time. Extensive simulations are performed on a 3D model of 6-DoF Universal Robot (UR) 10 in Gazebo, followed by implementation on real UR 10 robot manipulator to show the efficacy of the proposed scheme.",https://ieeexplore.ieee.org/document/9207522/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/Agro-Geoinformatics.2017.8047016,Disease detection on the leaves of the tomato plants by using deep learning,IEEE,Conferences,"The aim of this work is to detect diseases that occur on plants in tomato fields or in their greenhouses. For this purpose, deep learning was used to detect the various diseases on the leaves of tomato plants. In the study, it was aimed that the deep learning algorithm should be run in real time on the robot. So the robot will be able to detect the diseases of the plants while wandering manually or autonomously on the field or in the greenhouse. Likewise, diseases can also be detected from close-up photographs taken from plants by sensors built in fabricated greenhouses. The examined diseases in this study cause physical changes in the leaves of the tomato plant. These changes on the leaves can be seen with RGB cameras. In the previous studies, standard feature extraction methods on plant leaf images to detect diseases have been used. In this study, deep learning methods were used to detect diseases. Deep learning architecture selection was the key issue for the implementation. So that, two different deep learning network architectures were tested first AlexNet and then SqueezeNet. For both of these deep learning networks training and validation were done on the Nvidia Jetson TX1. Tomato leaf images from the PlantVillage dataset has been used for the training. Ten different classes including healthy images are used. Trained networks are also tested on the images from the internet.",https://ieeexplore.ieee.org/document/8047016/,2017 6th International Conference on Agro-Geoinformatics,7-10 Aug. 2017,ieeexplore
10.1109/NCA.2013.21,Distributed and Dynamic Map-less Self-reconfiguration for Microrobot Networks,IEEE,Conferences,"MEMS micro robots are low-power and low memory capacity devices that can sense and act. One of the most challenges in MEMS micro robot applications is the self-reconfiguration, especially when the efficiency and the scalability of the algorithm are required. In the literature, if we want a self-reconfiguration of micro robots to a target shape consisting of P positions, each micro robot should have a memory capacity of P positions. Therefore, if P equals to millions, each node should have a memory capacity of millions of positions. Therefore, this is not scalable. In this paper, nodes do not record any position, we present a self-reconfiguration method where a set of micro robots are unaware of their current position and do not have the map of the target shape. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to O(1). An algorithm of self-reconfiguration to optimize the communication is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots) of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6623641/,2013 IEEE 12th International Symposium on Network Computing and Applications,22-24 Aug. 2013,ieeexplore
10.1049/cp.2012.1127,Distributed parallel processing of mobile robot PF-SLAM,IET,Conferences,"Real-time property is a fundamental requirement for a practical robot system. For this purpose, this article proposes an implementation architecture of robot SLAM by adopting two parallel threads processing. Since the dominant factor which determines the computational complexity is the employed particle number, two distributed threads with different particle set size are executed simultaneously. Conventional PF-SLAM algorithm occupies one of threads, and the other thread which hires more particles is activated whenever robot has significant motion changes. Advantages of this presented idea are validated by experiment carried on Pioneer robot.",https://ieeexplore.ieee.org/document/6492734/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/SCCC.2001.972633,Domain-dependent option policies in autonomous robot learning,IEEE,Conferences,"In control-related applications such as robotics, determination of optimal solutions is made very difficult for many reasons. Among these stands the difficulty in finding out an appropriate model of the domain, as defined by the control agent (robot), environment where it acts and their interaction. Reinforcement learning is a theory which defines a collection of algorithms for determination of control actions under model-free assumptions, which allows control agents to learn optimal actions in an autonomous way. In reinforcement learning, a cost functional to be optimised is determined in advance. The agent then learns how to perform this optimisation via trial and error on its environment. A trial corresponds to execution of actions chosen by the agent, and the error is the immediate result (a real-valued reinforcement) of this action. In the work reported, we consider trials by a learning robotic agent which are not based on low level actions, but instead on sequences of actions (options or macro-operators). We analysed the performance both in terms of learning speed and quality of learned control-for options that correspond to mappings from states to action policies (O/sub /spl Pi// options). Experimental results show that careful (domain-dependent) selection of options (via methods such as discretised potential fields) produce much faster learning for option-based robots when compared to their action-based counterparts. Of critical importance, however, is the option mapping in regions of the state space where the options are not assumed to be necessary: as performance of reinforcement learning algorithms is strongly dependent on sufficient exploration of the state space, even in such regions a careful, ad-hoc selection of actions is of foremost importance.",https://ieeexplore.ieee.org/document/972633/,SCCC 2001. 21st International Conference of the Chilean Computer Science Society,9-9 Nov. 2001,ieeexplore
10.1109/RoboSoft51838.2021.9479353,DroneTrap: Drone Catching in Midair by Soft Robotic Hand with Color-Based Force Detection and Hand Gesture Recognition,IEEE,Conferences,"The paper proposes a novel concept of docking drones to make this process as safe and fast as possible. The idea behind the project is that a robot with a soft gripper grasps the drone in midair. The human operator navigates the robotic arm with the ML-based gesture recognition interface. The 3-finger robot hand with soft fingers is equipped with touch sensors, making it possible to achieve safe drone catching and avoid inadvertent damage to the drone's propellers and motors. Additionally, the soft hand is featured with a unique color-based force estimation technology based on a computer vision (CV) system. Moreover, the visual color-changing system makes it easier for the human operator to interpret the applied forces.Without any additional programming, the operator has full real-time control of robot's motion and task execution by wearing a mocap glove with gesture recognition, which was developed and applied for the high-level control of DroneTrap.The experimental results revealed that the developed color-based force estimation can be applied for rigid object capturing with high precision (95.3%). The proposed technology can potentially revolutionize the landing and deployment of drones for parcel delivery on uneven ground, structure maintenance and inspection, risque operations, and etc.",https://ieeexplore.ieee.org/document/9479353/,2021 IEEE 4th International Conference on Soft Robotics (RoboSoft),12-16 April 2021,ieeexplore
10.1109/ICAR46387.2019.8981552,Dynamic Movement Primitives: Volumetric Obstacle Avoidance,IEEE,Conferences,"Dynamic Movement Primitives (DMPs) are a framework for learning a trajectory from a demonstration. The trajectory can be learned efficiently after only one demonstration, and it is immediate to adapt it to new goal positions and time duration. Moreover, the trajectory is also robust against perturbations. However, obstacle avoidance for DMPs is still an open problem. In this work, we propose an extension of DMPs to support volumetric obstacle avoidance based on the use of superquadric potentials. We show the advantages of this approach when obstacles have known shape, and we extend it to unknown objects using minimal enclosing ellipsoids. A simulation and experiments with a real robot validate the framework, and we make freely available our implementation.",https://ieeexplore.ieee.org/document/8981552/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/DEVLRN.2008.4640818,Dynamic field theory of sequential action: A model and its implementation on an embodied agent,IEEE,Conferences,"How sequences of actions are learned, remembered, and generated is a core problem of cognition. Despite considerable theoretical work on serial order, it typically remains unexamined how physical agents may direct sequential actions at the environment within which they are embedded. Situated physical agents face a key problem - the need to accommodate variable amounts of time it takes to terminate each individual action within the sequence. Here we examine how Dynamic Field Theory (DFT), a neuronally grounded dynamical systems approach to embodied cognition, may address sequence learning and sequence generation. To demonstrate that the proposed DFT solution works with real and potentially noisy sensory systems as well as with real physical action systems, we implement the approach on a simple autonomous robot. We demonstrate how the robot acquires sequences from experiencing the associated sensory information and how the robot generates sequences based on visual information from its environment using low-level visual features.",https://ieeexplore.ieee.org/document/4640818/,2008 7th IEEE International Conference on Development and Learning,9-12 Aug. 2008,ieeexplore
10.1109/ICSMC.1995.537949,Dynamic path planning,IEEE,Conferences,"Path planning is dynamic when the path is continually recomputed as more information becomes available. A computational framework for dynamic path planning is proposed which has the ability to provide navigational directions during the computation of the plan. Path planning is performed using a potential field approach. We use a specific type of potential function-a harmonic function-which has no local minima. The implementation is parallel and consists of a collection of communicating processes, across a network of SPARC &amp; SGI workstations using a message passing software package called PVM. The computation of the plan is performed independently of the execution of the plan. A hierarchical coarse-to-fine procedure is used to guarantee a correct control strategy at the expense of accuracy. We have successfully navigated a Nomad robot around our lab space with no a priori map in real-time. The result of the described approach is a parallel implementation which permits dynamic path planning using available processor resources.",https://ieeexplore.ieee.org/document/537949/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1109/MWSCAS.2018.8624056,EMG-based hand gesture control system for robotics,IEEE,Conferences,"In this paper, a Electromyogram (EMG) based hand gesture control system is developed. A wearable human machine interface (HMI) device is designed for an in-home assistance service robot. An EMG-based control system utilizes MyoWave muscle sensor to acquire and amplify EMG signal. A microcontroller system is used to an artificial neural network (ANN) to classify the EMG signal. Based on different hand movements, commands are sent through WiFi to control the motor in a service robot. The on-board Camera system mounted the robot can capture video real-time. In addition, a web server is implemented to provide live video feedback for robot navigation and user instructions.",https://ieeexplore.ieee.org/document/8624056/,2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS),5-8 Aug. 2018,ieeexplore
10.1109/IROS45743.2020.9341406,EU Long-term Dataset with Multiple Sensors for Autonomous Driving,IEEE,Conferences,"The field of autonomous driving has grown tremendously over the past few years, along with the rapid progress in sensor technology. One of the major purposes of using sensors is to provide environment perception for vehicle understanding, learning and reasoning, and ultimately interacting with the environment. In this paper, we first introduce a multisensor platform allowing vehicle to perceive its surroundings and locate itself in a more efficient and accurate way. The platform integrates eleven heterogeneous sensors including various cameras and lidars, a radar, an IMU (Inertial Measurement Unit), and a GPS-RTK (Global Positioning System / Real-Time Kinematic), while exploits a ROS (Robot Operating System) based software to process the sensory data. Then, we present a new dataset (https://epan-utbm.github.io/utbm_robocar_dataset/) for autonomous driving captured many new research challenges (e.g. highly dynamic environment), and especially for long-term autonomy (e.g. creating and maintaining maps), collected with our instrumented vehicle, publicly available to the community.",https://ieeexplore.ieee.org/document/9341406/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SNPD.2008.97,Early-Life Cycle Reuse Approach for Component-Based Software of Autonomous Mobile Robot System,IEEE,Conferences,"Applying software reuse to many embedded realtime systems, such as autonomous mobile robot system poses significant challenges to industrial software processes due to the resource-constrained and realtime requirements of the systems. An approach for early life-cycle systematic reuse for component-based software engineering (ELCRA) of autonomous mobile robot software is developed. The approach allows reuse at the early stage of software development process by integrating analysis patterns, component model, and component-oriented programming framework. The results of applying the approach in developing software for real robots show that the strategies and processes proposed in the approach can fulfill requirements for self-contained, platform-independent and real-time predictable mobile robot.",https://ieeexplore.ieee.org/document/4617381/,"2008 Ninth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing",6-8 Aug. 2008,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/ICRA.2019.8793748,Effect of Mechanical Resistance on Cognitive Conflict in Physical Human-Robot Collaboration,IEEE,Conferences,"Physical Human-Robot Collaboration (pHRC) is about the interaction between one or more human operator(s) and one or more robot(s) in direct contact and voluntarily exchanging forces to accomplish a common task. In any pHRC, the intuitiveness of the interaction has always been a priority, so that the operator can comfortably and safely interact with the robot. So far, the intuitiveness has always been described in a qualitative way. In this paper, we suggest an objective way to evaluate intuitiveness, known as prediction error negativity (PEN) using electroencephalogram (EEG). PEN is defined as a negative deflection in event related potential (ERP) due to cognitive conflict, as a consequence of a mismatch between perception and reality. Experimental results showed that the forces exchanged between robot and human during pHRC modulate the amplitude of PEN, representing different levels of cognitive conflict. We also found that PEN amplitude significantly decreases (p &lt;; 0.05) when a mechanical resistance is being applied smoothly and more time in advance before an invisible obstacle, when compared to a scenario in which the resistance is applied abruptly before the obstacle. These results indicate that an earlier and smoother resistance reduces the conflict level. Consequently, this suggests that smoother changes in resistance make the interaction more intuitive.",https://ieeexplore.ieee.org/document/8793748/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ROMAN.2011.6005223,Effect of human guidance and state space size on Interactive Reinforcement Learning,IEEE,Conferences,"The Interactive Reinforcement Learning algorithm enables a human user to train a robot by providing rewards in response to past actions and anticipatory guidance to guide the selection of future actions. Past work with software agents has shown that incorporating user guidance into the policy learning process through Interactive Reinforcement Learning significantly improves the policy learning time by reducing the number of states the agent explores. We present the first study of Interactive Reinforcement Learning in real-world robotic systems. We report on four experiments that study the effects that teacher guidance and state space size have on policy learning performance. We discuss modifications made to apply Interactive Reinforcement Learning to a real-world system and show that guidance significantly reduces the learning rate, and that its positive effects increase with state space size.",https://ieeexplore.ieee.org/document/6005223/,2011 RO-MAN,31 July-3 Aug. 2011,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/OCEANS.2014.7003085,Efficient multi-AUV cooperation using semantic knowledge representation for underwater archaeology missions,IEEE,Conferences,"Advances in the fields of communication technology and software, electrical and mechanical engineering enable the replacement of a single robot by cooperative robotic team in highly demanding applications, such as search and rescue. A robotic team could perform better than a single robot, if certain challenges, such as action planning, coordination, and decision making, are successfully tackled. One key factor for the successful performance of a robotic team is the multi-robot task allocation. Specifically, the challenge is to define which robot executes which task, considering an efficient solution for the successful completion of the complex mission. The task allocation could be even more challenging when real-world communication constraints and uncertainties are presented, such as limited bandwidth, high latency and high packet loss. In the current study, we attempt to resolve the issue of a cooperative robotic team under communication constraints. To reach this goal, the use of a distributed world model for multi-robot task allocation is proposed. This ontology based distributed world model is capable of successfully handling to a great extent the aforementioned communications limitations, thus allowing successful mission execution even under harsh communication conditions. An efficient centralised task allocation mechanism, using k-means clustering, is described, and its performance is compared to a greedy centralised task allocation method. Experimental simulation results indicate that the efficient method performs better on average than the greedy one, without extra time requirements.",https://ieeexplore.ieee.org/document/7003085/,2014 Oceans - St. John's,14-19 Sept. 2014,ieeexplore
10.1109/ROMAN.2009.5326159,Efficient parsing of spoken inputs for human-robot interaction,IEEE,Conferences,"The use of deep parsers in spoken dialogue systems is usually subject to strong performance requirements. This is particularly the case in human-robot interaction, where the computing resources are limited and must be shared by many components in parallel. A real-time dialogue system must be capable of responding quickly to any given utterance, even in the presence of noisy, ambiguous or distorted input. The parser must therefore ensure that the number of analyses remains bounded at every processing step. The paper presents a practical approach to addressing this issue in the context of deep parsers designed for spoken dialogue. The approach is based on a word lattice parser combined with a statistical model for parse selection. Each word lattice is parsed incrementally, word by word, and a discriminative model is applied at each incremental step to prune the set of resulting partial analyses. The model incorporates a wide range of linguistic and contextual features and can be trained with a simple perceptron. The approach is fully implemented as part of a spoken dialogue system for human-robot interaction. Evaluation results on a Wizard-of-Oz test suite demonstrate significant improvements in parsing time.",https://ieeexplore.ieee.org/document/5326159/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICE2T.2017.8215992,Elevator button and floor number recognition through hybrid image classification approach for navigation of service robot in buildings,IEEE,Conferences,"To successfully move a robot into the building, the elevator button and elevator floor number detection and recognition can play an important role. It can help a robot move in the building, just as it also can help a visually impaired person who wants to move another floor in the building. Due to vision-based approach, the difference in lighting condition and the complex background are the main obstacles in this research. A hybrid image classification model is presented in this research to overcome all these difficulties. This hybrid model is the combination of histogram of oriented gradients and bag of words models, which later reduces the dimension of image features by using the feature selection algorithm. An artificial neural network has been implemented to get the experimental result by training and testing. In order to get training performance, 1000 training image samples have been used and additional 1000 image samples also been used to get the testing performance. The experimental results of this research indicate that this proposed framework is important for real-time implementation to implement the elevator button and elevator floor number recognition framework.",https://ieeexplore.ieee.org/document/8215992/,2017 International Conference on Engineering Technology and Technopreneurship (ICE2T),18-20 Sept. 2017,ieeexplore
10.1109/IHMSC.2013.225,Embedded Motion Controller Design Based on RTEX Network,IEEE,Conferences,"Adopting embedded framework and network communication mode, a kind of multi-axis embedded motion controller hardware platform design for the Panasonic A5N drive is proposed, which is Based on the modular control core (ARM + FPGA) and can adapt to the new real-time network RTEX. The processes of controller's functional design, hardware design and software design are explained in detail. Up to now, the motion controller's hardware platform have been completed and verified by communication experiments, position and velocity control experiments, and the results of which show that the controller have good scalability, reliability, flexibility and openness and could well meet the needs of the multi-axis robot's motion control.",https://ieeexplore.ieee.org/document/6642753/,2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics,26-27 Aug. 2013,ieeexplore
10.1109/ICIEV.2018.8641023,Embedded System based Bangla Intelligent Social Virtual Robot with Sentiment Analysis,IEEE,Conferences,"Bangla is the mother tongue of millions of people all over the world. Despite being a very popular language, any social virtual robot that can intelligently communicate in Bangla is a fairytale till now. One of the main reason of this is lack of rich text corpus and previous research on Bangla language. The proposed Bangla Intelligent Social Virtual Robot can communicate in Bangla intelligently and can express its reflective emotion virtually with the help of machine learning algorithms and sentiment analysis. In this paper, we discuss the approached system, design methodology and implementation details of first ever Bangla virtual embedded robot followed by the methodology of building a rich Bangla text corpus. The proposed embedded virtual robot turns out better performer when compared with only known Bangla intelligent chatbot named `Golpo' and the embedded system performance efficiency has been upgraded with the help CPU over-clocking technique.",https://ieeexplore.ieee.org/document/8641023/,"2018 Joint 7th International Conference on Informatics, Electronics & Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",25-29 June 2018,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/SII.2019.8700376,Emotion Recognition from Speech for an Interactive Robot Agent,IEEE,Conferences,"Speech is one of the fundamental approaches for human to human interaction. Given this, it should be the main approach for robot human interaction as well. Towards this, the research presented here focuses on emotion recognition from human speech to aid the interaction between humans and robots. There are various steps involved in developing emotion recognition system for an interactive robot agent. The first step is to choose a suitable dataset that is Berlin database for training and testing the models developed. The second important step is extraction and choice of suitable features related to emotions. The third step is to make an appropriate classification scheme. The performance of each classifier is analyzed and acomparison among multiple frameworks of emotion recognition is made. In response to the findings in these preliminary studies, a prototype application was developed to allow the recognition of emotions from speech in real-time for future use on an interactive robot. On a preliminary test set, the application achieved performance levels between 81% and 92%. The approach offers the integration of speech collection hardware, emotion recognition software, mobile devices and robotic systems to aid assist human-robot interaction.",https://ieeexplore.ieee.org/document/8700376/,2019 IEEE/SICE International Symposium on System Integration (SII),14-16 Jan. 2019,ieeexplore
10.1109/RO-MAN46459.2019.8956327,End-User Programming of Low-and High-Level Actions for Robotic Task Planning,IEEE,Conferences,"Programming robots for general purpose applications is extremely challenging due to the great diversity of end-user tasks ranging from manufacturing environments to personal homes. Recent work has focused on enabling end-users to program robots using Programming by Demonstration. However, teaching robots new actions from scratch that can be reused for unseen tasks remains a difficult challenge and is generally left up to robotic experts. We propose iRoPro, an interactive Robot Programming framework that allows end-users to teach robots new actions from scratch and reuse them with a task planner. In this work we provide a system implementation on a two-armed Baxter robot that (i) allows simultaneous teaching of low-and high-level actions by demonstration, (ii) includes a user interface for action creation with condition inference and modification, and (iii) allows creating and solving previously unseen problems using a task planner for the robot to execute in real-time. We evaluate the generalisation power of the system on six benchmark tasks and show how taught actions can be easily reused for complex tasks. We further demonstrate its usability with a user study (N=21), where users completed eight tasks to teach the robot new actions that are reused with a task planner. The study demonstrates that users with any programming level and educational background can easily learn and use the system.",https://ieeexplore.ieee.org/document/8956327/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/SEAMS51251.2021.00015,Enhancing Human-in-the-Loop Adaptive Systems through Digital Twins and VR Interfaces,IEEE,Conferences,"Self-adaptation approaches usually rely on closed-loop controllers that avoid human intervention from adaptation. While such fully automated approaches have proven successful in many application domains, there are situations where human involvement in the adaptation process is beneficial or even necessary. For such “human-in-the-loop” adaptive systems, two major challenges, namely transparency and controllability, have to be addressed to include the human in the self-adaptation loop. Transparency means that relevant context information about the adaptive systems and its context is represented based on a digital twin enabling the human an immersive and realistic view. Concerning controllability, the decision-making and adaptation operations should be managed in a natural and interactive way. As existing human-in-the-loop adaptation approaches do not fully cover these aspects, we investigate alternative human-in-the-loop strategies by using a combination of digital twins and virtual reality (VR) interfaces. Based on the concept of the digital twin, we represent a self-adaptive system and its respective context in a virtual environment. With the help of a VR interface, we support an immersive and realistic human involvement in the self-adaptation loop by mirroring the physical entities of the real world to the VR interface. For integrating the human in the decision-making and adaptation process, we have implemented and analyzed two different human-in-the-loop strategies in VR: a procedural control where the human can control the decision making-process and adaptations through VR interactions (human-controlled) and a declarative control where the human specifies the goal state and the configuration is delegated to an AI planner (mixed-initiative). We illustrate and evaluate our approach based on an autonomic robot system that is accessible and controlled through a VR interface.",https://ieeexplore.ieee.org/document/9462035/,2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS),18-24 May 2021,ieeexplore
10.1109/ICRA48506.2021.9562114,Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and Gamification,IEEE,Conferences,"Robot grasping and manipulation planning in unstructured and dynamic environments is heavily dependent on the attributes of manipulated objects. Although deep learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Moreover, training such models requires large datasets that are generally expensive to obtain. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation aspects of robot perception. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand an initial attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in a proof-of-concept application for enhancing object recognition in autonomous robot grasping and a model for estimating the response time is proposed. The obtained results demonstrate that given enough players, the framework can offer near real-time labeling of novel objects, based purely on visual information and human experience.",https://ieeexplore.ieee.org/document/9562114/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISIC.2001.971506,Enhancing control architectures using CORBA,IEEE,Conferences,"The nature of applied research in intelligent robot controllers makes having a versatile software architecture a real need for exploring alternative designs in robotic minds construction. The paper presents an experiment in the adaptation of a multi-robot cooperation architecture to a CORBA-based schema. The paper demonstrates not only the feasibility but the convenience of using, state-of-the-art, modular software technologies for the construction of advanced intelligent controllers.",https://ieeexplore.ieee.org/document/971506/,Proceeding of the 2001 IEEE International Symposium on Intelligent Control (ISIC '01) (Cat. No.01CH37206),5-7 Sept. 2001,ieeexplore
10.1109/SECON.2010.5453897,Enhancing student learning in artificial intelligence using robotics,IEEE,Conferences,"Artificial intelligence (AI) techniques may be applied to a variety of real-world problems. At Embry-Riddle Aeronautical University, CS 455: Artificial Intelligence was offered during the Spring 2008 semester in which students from all disciplines were invited to attend. Robot kits are incorporated into the course as a pedagogical tool to motivate and encourage learning by applying theoretically abstract algorithms to concrete real-world problems. This paper discusses the approach to incorporating robotics in the AI classroom. A set of commercial off-the-shelf robot kits are discussed and analyzed with respect to the students' work during the semester. Finally, recommendations for improvements on teaching AI to a multi-disciplinary audience with the help of robot kits will be discussed.",https://ieeexplore.ieee.org/document/5453897/,Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon),18-21 March 2010,ieeexplore
10.1109/ICCAE.2009.52,Environmental Recognition Using RAM-Network Based Type-2 Fuzzy Neural for Navigation of Mobile Robot,IEEE,Conferences,"Reactive autonomous mobile robot navigating in real time environment is one of the most important requirements. Most of the systems have some common drawbacks such as, large computation, expensive equipment, hard implementation, and the complexity of the system. The work presented in this paper deals with a type-2 fuzzy-neural controller using RAM-based network to make navigation decisions. The proposed architecture can be implemented easily with low cost range sensor and low cost microprocessor. To minimize the execution time, we used a look-up table and that output stored into the robot RAM memory and becomes the current controller that drives the robot. This functionality is demonstrated on a mobile robot using a simple, 8 bit microcontroller with 512 bytes of RAM. The experiment results show that source code is efficient, works well, and the robot was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/4804536/,2009 International Conference on Computer and Automation Engineering,8-10 March 2009,ieeexplore
10.1109/ICRA40945.2020.9197510,Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing,IEEE,Conferences,"This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.",https://ieeexplore.ieee.org/document/9197510/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/WCICA.2000.863468,Estimated force emulation for space robot using neural networks,IEEE,Conferences,"This paper introduces the telerobotic system estimated force emulation using neural networks. A delay-compensating 3D stereo-graphic simulator is implemented in SGI ONYX/4 RE/sup 2/. The estimated force emulation can protect the real robot in time from being damaged in collision. The neural network is used to learn the mapping between the contact force error and the accommodated position command to the controller of the space robot. Finally, the controller can feel the emulated force with a two-hand 6-DOF master arm using the force feedback interface.",https://ieeexplore.ieee.org/document/863468/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ROMAN.2007.4415203,Evolving Personality of a Genetic Robot in Ubiquitous Environment,IEEE,Conferences,"This paper discusses the personality of genetic robot and its evolving algorithm within the purview of the broader ubiquitous robot framework. Ubiquitous robot systems blends mobile robot technology (Mobot) with distributed sensor systems (Embot) and overseeing software intelligence (Sobot), for various integrated services. The Sobot is a critical question since it performs the dual purpose of overseeing intelligence as well as user interface. The Sobot is hence modelled as an artificial creature with autonomously driven behavior. The artificial creature has its own genome and in which each chromosome consists of many genes that contribute to defining its personality. This paper proposes evolving the personality of an artificial creature. A genome population is evolved such that it customized the genome satisfying a set of personality traits desired by the user. Evaluation procedure for each genome of the population is carried out in a virtual environment. Effectiveness of this scheme is demonstrated by using an artificial creature, Rity in the virtual 3D world created in a PC.",https://ieeexplore.ieee.org/document/4415203/,RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,26-29 Aug. 2007,ieeexplore
10.1109/ICITA.2005.135,Experiences with simulated robot soccer as a teaching tool,IEEE,Conferences,"The development of assignments for undergraduate teaching typically requires a compromise between what is achievable by an average student and what engages the interest of a more advanced member of the class. Selecting a suitable compromise is particularly problematic for undergraduate artificial intelligence (AI) courses which typically attempt to cover a very broad range of topics, without delving too deeply into the details. Ideally, a single problem would be selected whose solution could be approached with more than one technique covered in the course, enabling students to carry out a comparative analysis of performance. Robot soccer simulation has provided an interesting platform for artificial intelligence research and is increasingly being used as a teaching apparatus. There are a number of limitations with existing simulation methodologies for this purpose. Current robot soccer simulators are aimed at research groups where accuracy is paramount and all facets of the real system must be emulated. However, many of the intricacies of a real robot soccer player are inappropriate for a teaching environment, as they detract from desired learning outcomes. Consequently, there is a need for a simulation that employs a simplified set of game rules and dynamics. This paper describes the design and implementation of such a framework and presents experiences gained from its use as a third year practical.",https://ieeexplore.ieee.org/document/1488833/,Third International Conference on Information Technology and Applications (ICITA'05),4-7 July 2005,ieeexplore
10.1109/RIOS.2016.7529488,Experimental stability study of an Octorotor using an intelligent controller,IEEE,Conferences,"In this paper, the attitude stabilization problem of an Octorotor with coaxial motors is studied. To this end, the new method of intelligent adaptive control is presented. The designed controller which includes fuzzy and PID controllers, is completed by resistant adaptive function of approximate external disturbance and changing in the dynamic model. In fact, the regulation factor of PID controller is done by the fuzzy logic system. At first, the Fuzzy-PID and PID controllers are simulated in MATLAB/Simulink. Then, the Fuzzy-PID controller is implemented on the Octorotor with coaxial motors as online auto-tuning. Also, LabVIEW software has been used for tests and the performance analysis of the controllers. All of this experimental operation is done in indoor environment in the presence of wind as disturbance in the hovering operation. All of these operations are real-time and telemetry wireless is done by network connection between the robot and ground station in the LABVIEW software. Finally, the controller efficiency and results are studied.",https://ieeexplore.ieee.org/document/7529488/,2016 Artificial Intelligence and Robotics (IRANOPEN),9-9 April 2016,ieeexplore
10.1109/ICRA.2019.8793829,Exploiting Trademark Databases for Robotic Object Fetching,IEEE,Conferences,"Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.",https://ieeexplore.ieee.org/document/8793829/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIM.2019.8868536,Exploiting the ACCuracy-ACCeleration tradeoff: VINS-assisted real-time object detection on moving systems,IEEE,Conferences,"In recent years, Convolutional Neural Networks (CNNs) have repeatedly shown state-of-the-art performance for their accuracy in the task of object detection, but their heavy computational costs impede their ability for real-time detection when the supporting system is moving, particularly when it is accelerating. At the same time, recent progress on visual inertial systems takes great advantage of movement information to robustly estimate the robot state and its surrounding. This paper proposes to exploit the advantages of inertial odometry research for the purpose of real-time object detection system on mobile robots. We combine a CNN detector with VINS-Mono, a moving visual odometry system, and show reliable improvement in the detection process, especially when the robot accelerates or decelerates. Our system is ready-to-use in that it has very low deployment cost and requires no calibration. The resulting system allows for simultaneous robot state estimation and object detection, as well as object tracking. Lastly, this architecture proves to be flexible because not restrained to a specific object type or detector.",https://ieeexplore.ieee.org/document/8868536/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/ICVRIS.2018.00078,Exploration of Computer Emotion Decision Based on Artificial Intelligence,IEEE,Conferences,"To carry out the discussion of computer emotion decision based on artificial intelligence, first of all, based on the psychological experiment paradigm of children's game task, and the test process of the artificial emotion generating engine was completed on the emotional spontaneous transfer and the stimulus transfer model. Secondly, the reasoning method and analytic hierarchy process (AHP) were introduced into the multi system, and a kind of multi emotion decision model based on the emotion reasoning was constructed. The hierarchical structure method was used to solve the complex decision problem of the humanoid robot in the intelligent home environment. Then, based on the emotion energy theory, a mood state regulation algorithm based on the combination of HMM-based spontaneous transfer and stimulus transfer was established. In addition, on this basis, the design and implementation of humanoid robot associative memory model was realized. Finally, the theory and algorithm were integrated into the interactive platform of human-computer expression, and the validity of the model was analysed and verified. The results showed that, on this robot platform, the process of human-computer interaction and cooperation which integrated emotion evaluation, emotional decision, associative memory and emotion regulation was realized. As a result, the computer emotion decision based on artificial intelligence can be well applied in many fields.",https://ieeexplore.ieee.org/document/8531405/,2018 International Conference on Virtual Reality and Intelligent Systems (ICVRIS),10-11 Aug. 2018,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/IJCNN.2019.8852425,Exploring Deep Models for Comprehension of Deictic Gesture-Word Combinations in Cognitive Robotics,IEEE,Conferences,"In the early stages of infant development, gestures and speech are integrated during language acquisition. Such a natural combination is therefore a desirable, yet challenging, goal for fluid human-robot interaction. To achieve this, we propose a multimodal deep learning architecture, for comprehension of complementary gesture-word combinations, implemented on an iCub humanoid robot. This enables human-assisted language learning, with interactions like pointing at a cup and labelling it with a vocal utterance. We evaluate various depths of the Mask Regional Convolutional Neural Network (for object and wrist detection) and the Residual Network (for gesture classification). Validation is carried out with two deictic gestures across ten real-world objects on frames recorded directly from the iCub's cameras. Results further strengthen the potential of gesture-word combinations for robot language acquisition.",https://ieeexplore.ieee.org/document/8852425/,2019 International Joint Conference on Neural Networks (IJCNN),14-19 July 2019,ieeexplore
10.1109/ICORR.2019.8779424,Exploring the Impact of Machine-Learned Predictions on Feedback from an Artificial Limb,IEEE,Conferences,"Learning to get by without an arm or hand can be very challenging, and existing prostheses do not yet fill the needs of individuals with amputations. One promising solution is to improve the feedback from the device to the user. Towards this end, we present a simple machine learning interface to supplement the control of a robotic limb with feedback to the user about what the limb will be experiencing in the near future. A real-time prediction learner was implemented to predict impact-related electrical load experienced by a robot limb; the learning system's predictions were then communicated to the device's user to aid in their interactions with a workspace. We tested this system with five able-bodied subjects. Each subject manipulated the robot arm while receiving different forms of vibrotactile feedback regarding the arm's contact with its workspace. Our trials showed that using machine-learned predictions as a basis for feedback led to a statistically significant improvement in task performance when compared to purely reactive feedback from the device. Our study therefore contributes initial evidence that prediction learning and machine intelligence can benefit not just control, but also feedback from an artificial limb. We expect that a greater level of acceptance and ownership can be achieved if the prosthesis itself takes an active role in transmitting learned knowledge about its state and its situation of use.",https://ieeexplore.ieee.org/document/8779424/,2019 IEEE 16th International Conference on Rehabilitation Robotics (ICORR),24-28 June 2019,ieeexplore
10.1109/ICRA48506.2021.9561040,Extendable Navigation Network based Reinforcement Learning for Indoor Robot Exploration,IEEE,Conferences,This paper presents a navigation network based deep reinforcement learning framework for autonomous indoor robot exploration. The presented method features a pattern cognitive non-myopic exploration strategy that can better reflect universal preferences for structure. We propose the Extendable Navigation Network (ENN) to encode the partially observed high-dimensional indoor Euclidean space to a sparse graph representation. The robot’s motion is generated by a learned Q-network whose input is the ENN. The proposed framework is applied to a robot equipped with a 2D LIDAR sensor in the GAZEBO simulation where floor plans of real buildings are implemented. The experiments demonstrate the efficiency of the framework in terms of exploration time.,https://ieeexplore.ieee.org/document/9561040/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/FPT.2009.5377635,FPGA implementation of mixed integer quadratic programming solver for mobile robot control,IEEE,Conferences,"We propose a high-speed mixed integer quadratic programming (MIQP) solver on an FPGA. The MIQP solver can be applied to various optimizing applications including real-time robot control. In order to rapidly solve the MIQP problem, we implement reusing a first solution (first point), pipeline architecture, and multi-core architecture on the single FPGA. By making use of them, we confirmed that 79.5% of the cycle times are reduced, compared with straightforward sequential processing. The operating frequency is 67 MHz, although a core 2 duo PC requires 3.16 GHz in processing the same size problem. The power consumption of the MIQP solver is 4.2 W.",https://ieeexplore.ieee.org/document/5377635/,2009 International Conference on Field-Programmable Technology,9-11 Dec. 2009,ieeexplore
10.1109/RCAR52367.2021.9517666,FPGA-based Deep Learning Acceleration for Visual Grasping Control of Manipulator,IEEE,Conferences,"The vision-based robotic arm control system is an important solution for intelligent production, and the robotic arm visual grasping system based on deep learning is an important branch. Aiming at the requirements of fast visual recognition speed, low power consumption and high precision of mobile visual grasping robot, a deep learning target detection scheme based on FPGA hardware acceleration is proposed. Use Vivado and Petalinux development kit to build the software and hardware system, then deploy YOLOv3 model in the system. Experiments show that the solution meets the demand of robotic arm visual grasping, and the real-time performance is better. The recognition speed is 18 times that of the CPU, the power consumption is 1/13 of the GPU, and the cost is lower.",https://ieeexplore.ieee.org/document/9517666/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/RCAR52367.2021.9517650,FT-MSTC*: An Efficient Fault Tolerance Algorithm for Multi-robot Coverage Path Planning,IEEE,Conferences,"Fault tolerance is very important for multi-robot systems, especially for those operated in remote environments. The ability to tolerate failures, allows robots effectively to continue performing tasks without the need for immediate human intervention. In this paper, we present a new efficient fault tolerance algorithm for multi-robot coverage path planning (mCPP). The entire coverage path is considered as a topological task loop. The ideal mCPP problem is handled by partitioning this task loop and assign each partition to individual robot. When a faulty robot is detected, we use an optimization method to minimize the overall maximum coverage cost while considering both the tasks accomplished before robot failures and the remaining tasks. We perform various experiments for regular grid maps and real field terrains. We compare our algorithm against other coverage path planning algorithms and our algorithm outperforms existing spiral-STC-based methods in terms of the overall maximum coverage cost.",https://ieeexplore.ieee.org/document/9517650/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ICMLC.2006.258689,Facial Tracking for an Emotion-Diagnosis Robot to Support E-Learning,IEEE,Conferences,"There have been a lot of researches on the detection/estimation of human emotions from facial expressions. However, most of them have extracted facial features for some specific emotions from the still pictures of artificial actions or performances. This paper describes facial tracking for e-learning support robot which can estimate a emotion of e-learning user from his/her facial expression in real-time; (1) the criteria of the facial expression to classify the eight emotions was obtained by the time sequential subjective evaluation on the emotions as well as the time sequential analysis of a facial expression by image processing. (2) The coincidence ratio between the discriminated emotions based upon the criteria of emotion diagnosis and the time sequential subjective evaluation on emotions for ten e-learning subjects was 69%. (3) Then, the possibility of the real time emotion diagnosis robot to support e-learning was confirmed by the facial image processing at the 15 frame/sec. rate as well as the simple emotion diagnosis algorithm based upon the Mahalonobis distance",https://ieeexplore.ieee.org/document/4028735/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/ICSMC.1997.633250,Facial interaction between animated 3D face robot and human beings,IEEE,Conferences,"We study the realization of a realistic human-like response of an animated 3D face robot in communicative interaction with human beings. The face robot can produce human-like facial expressions and recognize human facial expressions using facial image data obtained by a CCD camera mounted inside the left eyeball. We developed the real time machine recognition of facial expressions by using a layered neural network and achieved a high correct recognition ratio of 85% with respect to 6 typical facial expressions of 15 subjects in 55 ms. We also developed a new small-size actuator for display of facial expressions on the face robot, giving the same speed in dynamic facial expressions as in human even in the case of a high-speed expression of ""surprise"". For facial interactive communication between the face robot and human beings, we integrated these two technologies to produce the facial expression in respond to the recognition result of the human facial expression in real time. This implies a high technological potential for the animated face robot to undertake interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/633250/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/UR49135.2020.9144836,Fall detection based on CNN models implemented on a mobile robot,IEEE,Conferences,"Fall accidents are serious events that need to be addressed. Generally, elderly people could suffer these accidents that may lead injures or even death. The use of Convolutional Neural Networks (CNN) has achieved the state of the art for fall detection, but it requires a high computational cost. In this work, we propose an efficient CNN architecture with a reduced number of parameters, which is applied to fall detection in a service with a mobile robot, equipped with a resource-constrained hardware (Nvidia Jetson TX2 platform). Also, different pre-trained CNN models are compared to measure their performances in real scenarios, in addition with other functions like following people and navigation. Furthermore, fall detection is carried out by extraction of temporal features obtained with an Optical Flow extraction from two consecutive RGB images. The proposed network is confirmed by our results to be faster and more suitable for running on resource-constrained Hardware. Our model achieves 88.55% of accuracy using the proposed architecture and it works at 23.16 FPS on GPU and 10.23 FPS on CPU.",https://ieeexplore.ieee.org/document/9144836/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ICRA40945.2020.9197159,Fast Adaptation of Deep Reinforcement Learning-Based Navigation Skills to Human Preference,IEEE,Conferences,"Deep reinforcement learning (RL) is being actively studied for robot navigation due to its promise of superior performance and robustness. However, most existing deep RL navigation agents are trained using fixed parameters, such as maximum velocities and weightings of reward components. Since the optimal choice of parameters depends on the use-case, it can be difficult to deploy such existing methods in a variety of real-world service scenarios. In this paper, we propose a novel deep RL navigation method that can adapt its policy to a wide range of parameters and reward functions without expensive retraining. Additionally, we explore a Bayesian deep learning method to optimize these parameters that requires only a small amount of preference data. We empirically show that our method can learn diverse navigation skills and quickly adapt its policy to a given performance metric or to human preference. We also demonstrate our method in real-world scenarios.",https://ieeexplore.ieee.org/document/9197159/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ISPACS.2018.8923369,Fast Recognition and Control of Walking Mode for Humanoid Robot Based on Pressure Sensors and Nearest Neighbor Search,IEEE,Conferences,"In this paper, we propose a nearest-neighbor multi-reference learning system for control of humanoid-robot movements, using real-time data from pressure sensors embedded in the robot feet, which is processed with parallelized pipeline architecture for high-speed recognition of actual surface conditions. A first nearest-neighbor (1-NN) classifier is used to recognize the most similar reference pattern in terms of the smallest Euclidean distance. Our proposed architecture achieves a classification time of about 2.4μ s with a total power consumption of 8.53mW at 100 MHz operating frequency when implemented on a low-cost FPGA (Cyclone-V GX-Series). The analysis results are further useful for a next-generation-ASIC-based AI-chip design for a robust real-time robot-learning system.",https://ieeexplore.ieee.org/document/8923369/,2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS),27-30 Nov. 2018,ieeexplore
10.1109/IROS40897.2019.8967966,Fast and Safe Policy Adaptation via Alignment-based Transfer,IEEE,Conferences,"Applying deep reinforcement learning to physical systems, as opposed to learning in simulation, presents additional challenges in terms of sample efficiency and safety. Collecting large amounts of hardware demonstration data is time-consuming and the exploratory behavior of reinforcement learning algorithms may lead the system into dangerous states, especially during the early stages of training. To address these challenges, we apply transfer learning to reuse a previously learned policy instead of learning from scratch. In this paper, we propose a method where given a source policy, policy adaptation is performed via transfer learning to produce a target policy suitable for real-world deployment. For policy adaptation, alignment-based transfer learning is applied to trajectories generated by the source policy and their corresponding safe target trajectories. We apply this method to manipulators and show that the proposed method is applicable to both inter-task and inter-robot transfer whilst considering safety. We also show that the resulting target policy is robust and can be further improved with reinforcement learning.",https://ieeexplore.ieee.org/document/8967966/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBOT.1996.506991,Fast connectionist learning for trailer backing using a real robot,IEEE,Conferences,This paper presents the application of a connectionist control-learning system to an autonomous mini-robot. The system's design is severely constrained by the computing power and memory available on board the mini-robot and the on-board training time is greatly limited by the short life of the battery. The system is capable of rapid unsupervised learning of output responses in temporal domains through the use of eligibility traces and data sharing within topologically defined neighborhoods.,https://ieeexplore.ieee.org/document/506991/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/IROS.2004.1389583,"Fast, reliable, adaptive, bimodal people tracking for indoor environments",IEEE,Conferences,"We present a real-time system for a mobile robot that can reliably detect and track people in uncontrolled indoor environments. The system uses a combination of leg detection based on distance information from a laser range sensor and visual face detection based on an analogical algorithm implemented on specialized hardware (the CNN universal machine). Results from tests in a variety of environments with different lighting conditions, a different number of appearing and disappearing people, and different obstacles are reported to demonstrate that the system can find and subsequently track several, possibly people simultaneously in indoor environments. Applications of the system include in particular service robots for social events.",https://ieeexplore.ieee.org/document/1389583/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/WiSPNET51692.2021.9419438,Faster Training of Edge-attention Aided 6D Pose Estimation Model using Transfer Learning and Small Customized Dataset,IEEE,Conferences,"Computer Vision is the field of machine learning that deals with computers gaining knowledge from digital images/videos and performing tasks that human vision is capable of doing. It is widely used in the field of robotics for designing guidance systems where objects in the robot's field of view are identified and located. This research work is an application-specific project enabling a half-humanoid to find the 6D pose and bounding boxes of its hand and other objects within its field of view. We add an edge prediction head to the NOCS (Normalised Object Coordinate Space) model, which predicts the edges of each object from the predicted instance maps. An additional edge-agreement-loss found from the predicted edges is added to the total loss. This increases the attention to the edges and improves the accuracy of prediction of the instance masks. This edge-attention aided model is initialized with pre-trained weights of CAMERA and REAL dataset using transfer learning. The backbone layers of the model are frozen and the head layers alone are trained using a synthetic dataset (HAND dataset) we created using a software called blender. The model gives promising results when tested with objects kept in varying lighting conditions and at different distances from the camera. The use of transfer learning in models as large as the NOCS model allows us to train the model for a new class by only training the top few layers with a significantly small dataset.",https://ieeexplore.ieee.org/document/9419438/,"2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",25-27 March 2021,ieeexplore
10.1109/CIRA.2005.1554338,Faster learning in embodied systems through characteristic attitudes,IEEE,Conferences,"Classical reinforcement learning is a general learning paradigm with wide applicability in many problem domains. Where embodied agents are concerned, however, it is unable to take advantage of the structured, regular nature of the physical world to maximise learning efficiency. Here, using a model of a three joint robot arm, we show initial learning accelerated by an order of magnitude using simple constraints to produce characteristic attitudes, implemented as part of the learning algorithm. We point out possible parallels with constraints on the movement of natural organisms owing to their detailed mechanical structure. The work forms part of our EMBER framework for reinforcement learning in embodied agents introduced and developed in 2004.",https://ieeexplore.ieee.org/document/1554338/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/SSCI.2017.8280891,Fault diagnosis in robot swarms: An adaptive online behaviour characterisation approach,IEEE,Conferences,"The need for an active approach to fault tolerance in swarm robotics systems is well established. This will necessarily include an approach to fault diagnosis if robot swarms are to retain long-term autonomy. This paper proposes a novel method for fault diagnosis, based around behavioural feature vectors, that incorporates real-time learning and memory. Initial results are encouraging, and show that an unsupervised learning approach is able to diagnose common electro-mechanical fault types, and arrive at an appropriate recovery option in the majority of the cases tested.",https://ieeexplore.ieee.org/document/8280891/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/CYBER53097.2021.9588329,Fault-Aware Robust Control via Adversarial Reinforcement Learning,IEEE,Conferences,"Robots have limited adaptation ability compared to humans and animals in the case of damage. However, robot damages are prevalent in realworld applications, especially for robots deployed in extreme environments. The fragility of robots greatly limits their widespread application. We propose an adversarial reinforcement learning framework, which significantly increases robot robustness over joint damage cases in both manipulation tasks and locomotion tasks. The agent is trained iteratively under the joint damage cases where it has poor performance. We validate our algorithm on a three-fingered robot hand and a quadruped robot. Our algorithm can be trained only in simulation and directly deployed on a real robot without any fine-tuning. It also demonstrates exceeding success rates over arbitrary joint damage cases.",https://ieeexplore.ieee.org/document/9588329/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/RCAR.2018.8621723,Fault-Tolerant and Self-Adaptive Market-Based Coordination Using Hoplites Framework for Multi-Robot Patrolling Tasks,IEEE,Conferences,"An autonomous robot team can be employed for continuous coverage of a dynamic environment. In this paper, we propose a novel approach for creating multi-robot patrolling policies, which is fault-tolerant and self-adaptive. A dynamic priority queue and time-out replanning mechanism are maintained by each robot to schedule the tasks fault-tolerantly in the context of the market-based method. Hoplites framework is adapted by introducing a self-adaptive threshold adjustment and sharing mechanism to provide a high-level coordination. This work is demonstrated by a multi-robot patrolling task implemented on Robot Operating System (ROS). A flexible tool, Stage, is leveraged to provide the simulated environment. The experimental results validate the effectiveness and availability.",https://ieeexplore.ieee.org/document/8621723/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ICARSC52212.2021.9429801,Few-Shot Visual Grounding for Natural Human-Robot Interaction,IEEE,Conferences,"Natural Human-Robot Interaction (HRI) is one of the key components for service robots to be able to work in human-centric environments. In such dynamic environments, the robot needs to understand the intention of the user to accomplish a task successfully. Towards addressing this point, we propose a software architecture that segments a target object from a crowded scene, indicated verbally by a human user. At the core of our system, we employ a multi-modal deep neural network for visual grounding. Unlike most grounding methods that tackle the challenge using pre-trained object detectors via a two-stepped process, we develop a single stage zero-shot model that is able to provide predictions in unseen data. We evaluate the performance of the proposed model on real RGB-D data collected from public scene datasets. Experimental results showed that the proposed model performs well in terms of accuracy and speed, while showcasing robustness to variation in the natural language input.",https://ieeexplore.ieee.org/document/9429801/,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),28-29 April 2021,ieeexplore
10.1109/ROBOT.1993.292135,Fixed computation real-time sonar fusion for local navigation,IEEE,Conferences,"A system is described for the spatial and temporal fusion of multiple sonars into a dynamic model which serves as a basis for local navigation. In order to guarantee that the robot's actions remain in synchrony with the changing state of the world, there is a continuous mapping from sonar readings to local model to navigation plan and, finally, to actuator commands. Because of this tight coupling of sensing and action, the responsiveness of the system is limited by the computational power of the processor and the required fidelity of the fused model. To address this tradeoff, the system is implemented using the GAPPS/REX circuit-based language. Analysis of the resulting fixed sized circuits allows computation tradeoffs to be made between the system fidelity and the responsiveness required by the operating environment. A description is presented of the sensor fusion and navigation algorithms, as well as the results of the system controlling MITRE's mobile robot Uncle Bob.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292135/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/HUMANOIDS.2014.7041373,Footstep planning on uneven terrain with mixed-integer convex optimization,IEEE,Conferences,"We present a new method for planning footstep placements for a robot walking on uneven terrain with obstacles, using a mixed-integer quadratically-constrained quadratic program (MIQCQP). Our approach is unique in that it handles obstacle avoidance, kinematic reachability, and rotation of footstep placements, which typically have required non-convex constraints, in a single mixed-integer optimization that can be efficiently solved to its global optimum. Reachability is enforced through a convex inner approximation of the reachable space for the robot's feet. Rotation of the footsteps is handled by a piecewise linear approximation of sine and cosine, designed to ensure that the approximation never overestimates the robot's reachability. Obstacle avoidance is ensured by decomposing the environment into convex regions of obstacle-free configuration space and assigning each footstep to one such safe region. We demonstrate this technique in simple 2D and 3D environments and with real environments sensed by a humanoid robot. We also discuss computational performance of the algorithm, which is currently capable of planning short sequences of a few steps in under one second or longer sequences of 10-30 footsteps in tens of seconds to minutes on common laptop computer hardware. Our implementation is available within the Drake MATLAB toolbox [1].",https://ieeexplore.ieee.org/document/7041373/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/IECON.2000.973216,Force control in robotic assembly under extreme uncertainty using ANN,IEEE,Conferences,"Robotic assembly operations can be performed by specifying an exact model of the operation. However, the uncertainties involved during assembly make it difficult to conceive such a model In these cases, the use of a connectionist model may be advantageous. In this paper, the design of a robotic cell based on the adaptive resonance theory artificial neural network and a PC host-slave architecture that overcame these uncertainties is presented. Different sources of uncertainty under real conditions are identified and their contribution in a typical assembly operation evaluated. The robotic system is implemented using a PUMA 761 industrial robot with six degrees of freedom (DOF) and a force/torque (F/T) sensor attached to its wrist which conveys force information to the neural network controller (NNC). Results during assembly operations are presented which validate the approach. Furthermore, the method is generic and can be implemented onto other manipulators.",https://ieeexplore.ieee.org/document/973216/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/AiDAS47888.2019.8970881,"Framework Of Malay Intelligent Autonomous Helper (Min@H): Text, Speech And Knowledge Dimension Towards Artificial Wisdom For Future Military Training System",IEEE,Conferences,"Industrial Revolution 4.0 is expected to improve the way of military training system. Most of the assistant systems use English for their Human Machine Interaction (HMI) such `SARA' a virtual socially aware robot assistant which exclude Malay socio-emotional aspects. This scenario opens a suggestion, to internalize socio-emotional aspects based on Malay culture, custom and beliefs to military autonomous training systems (i.e. MIN@H) that can improve the `collaborative' skills between Malaysian military personnel and the systems. Therefore, to increase the wisdom of the systems, they must have feature to capture information for their human users or helping human users to learn new knowledge and ensure the interaction is comfortable and engaging. For that reason, the systems must understand Malay language and be able to interpret emotion and expression behavior according to the Malay culture and custom, furthermore, the systems able to differentiate the level of user's understanding and build a good rapport or feeling of harmony that makes communication possible or easy between the systems and users. This concept of the systems is referred as Malay Artificial Wisdom System (AWS). There are three fundamental aspects to achieve the AWS. First, to computationally model the conversational strategies and rapport between the system and human users based-on user's understanding and system's articulation. Second, to computationally model, recognize and synthesize the emotion and expression behavior according to the Malay culture, custom and beliefs. Third, the AWS can do analytical reasoning and responding in relation to falsehood analysis and users' understanding level. Knowledge discovery and inference technique as well as HMI that cater the inputs and output of the MIN@H will be developed to accomplish the AWS concept. This program could embrace military training system in Malaysia to enhance military personnel skills and experts in various areas.",https://ieeexplore.ieee.org/document/8970881/,2019 1st International Conference on Artificial Intelligence and Data Sciences (AiDAS),19-19 Sept. 2019,ieeexplore
10.1109/IROS40897.2019.8967568,From Pixels to Buildings: End-to-end Probabilistic Deep Networks for Large-scale Semantic Mapping,IEEE,Conferences,"We introduce TopoNets, end-to-end probabilistic deep networks for modeling semantic maps with structure reflecting the topology of large-scale environments. TopoNets build a unified deep network spanning multiple levels of abstraction and spatial scales, from pixels representing geometry of local places to high-level descriptions of semantics of buildings. To this end, TopoNets leverage complex spatial relations expressed in terms of arbitrary, dynamic graphs. We demonstrate how TopoNets can be used to perform end-to-end semantic mapping from partial sensory observations and noisy topological relations discovered by a robot exploring large-scale office spaces. Thanks to their probabilistic nature and generative properties, TopoNets extend the problem of semantic mapping beyond classification. We show that TopoNets successfully perform uncertain reasoning about yet unexplored space and detect novel and incongruent environment configurations unknown to the robot. Our implementation of TopoNets achieves real-time, tractable and exact inference, which makes these new deep models a promising, practical solution to mobile robot spatial understanding at scale.",https://ieeexplore.ieee.org/document/8967568/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/DEVLRN.2005.1490934,From Unknown Sensors and Actuators to Visually Guided Movement,IEEE,Conferences,"This paper describes a developmental system implemented on a real robot that learns a model of its own sensory and actuator apparatuses. There is no innate knowledge regarding the modality or representation of the sensoric input and the actuators, and the system relies on generic properties of the robot's world such as piecewise smooth effects of movement on sensory changes. The robot develops the model of its sensorimotor system by first performing random movements to create an informational map of the sensors. Using this map the robot then learns what effects the different possible actions have on the sensors. After this developmental process the robot can perform simple motion tracking",https://ieeexplore.ieee.org/document/1490934/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/ISSE.2015.7248059,Fully integrated artificial intelligence solution for real time route tracking,IEEE,Conferences,"In this paper the authors propose a solution in which an intelligent algorithm - genetic algorithm in our case - is used to generate commands for a robot in real time, so that the robot can determine the optimal moves considering several aspects: route tracking and low power consumption. Genetic algorithms are intelligent solutions for multi-criteria optimization and using them to find solutions to the optimization problems containing constrictions. However, they were designed as algorithms running on computer and therefore cannot ensure rapid generation of the solutions. On the other hand, the problem of determining the optimal response to command a robot requires real time response. The paper presents a method for hardware implementation and integration in a FPGA circuit of a genetic algorithm, in order to accelerate the convergence and to generate solutions in real time.",https://ieeexplore.ieee.org/document/7248059/,2015 38th International Spring Seminar on Electronics Technology (ISSE),6-10 May 2015,ieeexplore
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/MMAR.2019.8864671,Fusion of Gesture and Speech for Increased Accuracy in Human Robot Interaction,IEEE,Conferences,"An approach for decision-level fusion for gesture and speech based human-robot interaction (HRI) is proposed. A rule-based method is compared with several machine learning approaches. Gestures and speech signals are initially classified using hidden Markov models, reaching accuracies of 89.6% and 84% respectively. The rule-based approach reached 91.6% while SVM, which was the best of all evaluated machine learning algorithms, reached an accuracy of 98.2% on the test data. A complete framework is deployed in real time humanoid robot (NAO) which proves the efficacy of the system.",https://ieeexplore.ieee.org/document/8864671/,2019 24th International Conference on Methods and Models in Automation and Robotics (MMAR),26-29 Aug. 2019,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/AIM.2009.5229761,Fuzzy and Neural controllers for acute obstacle avoidance in mobile robot navigation,IEEE,Conferences,"Robot navigation is the technique to guide the mobile robot move towards the desired goal where dynamic and unknown environment is involved. The environment is distinguished by variable terrain and also certain objects which are known as obstacles that may block the movement of the robot in reaching the desired destination. Fuzzy Logic (FL) and Artificial Neural Network (ANN) are used to assist autonomous mobile robot move, learn the environment and reach the desired goal. This research study is focused on exploring the four combinations of training algorithms composed of FL and ANN that avoid acute obstacles in the environment. Path Remembering algorithm proposed in this paper will assist the mobile robot to come out from acute obstacles. Virtual wall building method also is proposed in order to prevent the mobile robot reentering the same acute obstacle once it has been turned away from the wall. MATLAB simulation is developed to verify and validate the algorithms before they are implemented in real time on Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed the flexibility and robustness of the controllers designed in avoiding acute obstacles and a comparison of all the four combinations of algorithms is done to find the best combination of algorithms to perform the required navigation to avoid acute obstacles.",https://ieeexplore.ieee.org/document/5229761/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/FUZZY.1997.619465,Fuzzy behaviors combination to control a nonholonomic mobile robot using virtual perception memory,IEEE,Conferences,This paper presents the implementation of the combination of fuzzy reactive navigation behaviors using virtual perception memory. Robot control actions are generated by different fuzzy behavior components which cooperate to determine the motion of the vehicle. This approach differs from other methods in the use of a virtual perception memory to make a robot controller more robust with respect to temporary loss of sensorial information. Experimental results of an application to a real robot demonstrate the robustness of the proposed method.,https://ieeexplore.ieee.org/document/619465/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ISMA.2009.5164850,Fuzzy motion-based control for a bi-steerable mobile robot navigation,IEEE,Conferences,"This paper presents an implementation of a Fuzzy Motion Controller (FMC) to endow the mobile robot Robucar with capability to achieve the action behavior allowing smooth motion generation with intelligence in real-time. The robot state space (velocity and distances) is modeled in discrete intervals leading to linguistic variables. The fuzzy motion control rules are derived and used in a fuzzy inference mechanism to give the final control command to the robot actuators. Simulation and experimental results show FMC capabilities in generating smooth motions, illustrating then its adaptivity and intelligence.",https://ieeexplore.ieee.org/document/5164850/,2009 6th International Symposium on Mechatronics and its Applications,23-26 March 2009,ieeexplore
10.1109/ISIC.1994.367848,Fuzzy neural network implementation of self tuning PID control systems,IEEE,Conferences,"The fuzzy cognitive map (FCM) is a powerful universal method for representation of knowledge in various domains. The fuzzy inference engine can be implemented in the form of a network of FCMs. FCM implementation of the inference engine provides a suitable mechanism for expert control systems and information engineers to embed acquired human expertise, which is often imprecise, vague, or incomplete. The exploitation of an online learning algorithm empowers the fuzzy inference engine with the ability to modify its incomplete or possibly inconsistent knowledge base resulting in continuous improvement of the embedded knowledge. The fact that learning is an inherent feature of neural networks has inspired several researchers with the idea of using neural networks to implement fuzzy inference engines capable of learning. This paper presents a method for neural network FCM implementation of the fuzzy inference engine using the fuzzy columnar neural network architecture (FCNA). In this method the available human expertise is mapped first into an initial set of weights for the neurons. A new learning algorithm is then used to enhance the embedded knowledge in the neural network as a result of real time experience. The fuzzy inference engine (the neural network FCM) is used in computer simulations to control the speed of an underwater autonomous mobile robot. Results and computer simulation experiments are presented along with an evaluation of the new approach.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/367848/,Proceedings of 1994 9th IEEE International Symposium on Intelligent Control,16-18 Aug. 1994,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
10.1109/ROBIO.2017.8324476,Generalized framework for the parallel semantic segmentation of multiple objects and posterior manipulation,IEEE,Conferences,"The end-to-end approach presented in this paper deals with the recognition, detection, segmentation and grasping of objects, assuming no prior knowledge of the environment nor objects. The proposed pipeline is as follows: 1) Usage of a trained Convolutional Neural Net (CNN) that recognizes up to 80 different classes of objects in real time and generates bounding boxes around them. 2) An algorithm to derive in parallel the pointclouds of said regions of interest (ROI). 3) Eight different segmentation methods to remove background data and noise from the pointclouds and obtain a precise result of the semantically segmented objects. 4) Registration of the object's pointclouds over time to generate the best possible model. 5) Utilization of an algorithm to detect an array of grasping positions and orientations based mainly on the geometry of the object's model. 6) Implementation of the system on the humanoid robot MyBot, developed in the RIT Lab at KAIST. 7) An algorithm to find the bounding box of the object's model in 3D to then create a collision object and add it to the octomap. The collision checking between robot's hand and the object is removed to allow grasping using the MoveIt libraries. 8) Selection of the best grasping pose for a certain object, plus execution of the grasping movement. 9) Retrieval of the object and moving it to a desired final position.",https://ieeexplore.ieee.org/document/8324476/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/IROS.1994.407570,Generation of optimal configuration for a redundant manipulator with a trained neural network,IEEE,Conferences,"Redundant manipulators have more degrees of freedom than what is absolutely necessary for performing a task. The extra degrees of freedom can be used for avoiding obstacles or to optimize certain performance indices like manipulability or task compatibility. Maximizing manipulability keeps the manipulator away from singularities and provides more velocity transmission ratios in all directions. Optimizing task compatibility improves the force/velocity transmission ratios in the specified directions. However, the real time implementation of various optimizing algorithms is difficult because of the need of large computing time. In the present work, robot configurations for an optimum performance index are computed throughout the workspace. These configurations are then used to train a layered feed forward neural network (FFNN). During operation of the robot, the trained neural net outputs optimal configurations in real-time. The neural net captures the gross behaviour of the training data rather than memorizing the individual data, as in a lookup table. Thus its output is smooth and ideally suited for control purposes. We have simulated this approach on a 3-DOF redundant planar manipulator and the results are discussed in this paper.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407570/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ROBOT.2001.933128,Generation of optimal trajectory for real system of an underactuated manipulator,IEEE,Conferences,"Trajectory of an underactuated manipulator is usually generated according to both kinematics and dynamics of the manipulator, different to that of conventional manipulator. The real trajectory by a real system may differ greatly from the trajectory generated from the dynamics model because there always exist errors in the dynamic model, and the feedback control is less effective in an underactuated manipulator. A method for generation of optimal trajectory for the real system of an underactuated manipulator with nonholonomic constraints is proposed. By using this method, the dynamics model of a real system can be improved by learning, and an optimal trajectory is generated according to the model improved sequentially. The effectiveness of the method is confirmed by experiment with a golf swinging robot. The implementation and experimental results obtained of the control method are described.",https://ieeexplore.ieee.org/document/933128/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICMA.2007.4303585,Genetic Programming in Robot Exploration,IEEE,Conferences,"Exploration using mobile robots is an active research area. In general, an optimal robot exploration strategy is difficult to obtain. In this paper an investigation is conducted using genetic programming (GP) to solve this problem. GP is a form of artificial intelligence capable of automatically creating and developing computer programs to solve problems using the theory of evolution. However, like many other learning algorithms, GP is a computationally expensive and time-consuming process. This characteristic can impede its application where learning time is limited, such as in real-time robotic control applications. Therefore, this paper further investigates the possibility of developing a time-efficient GP algorithm to reduce evolution time. This is done by directly incorporating the amount of time evolved solutions take to form into the fitness function, in order to encourage time efficient problem solving. Experimental results have shown that while the time efficient aspect of the proposed GP algorithm is not conclusive, the robot exploration using GP produces promising outcomes.",https://ieeexplore.ieee.org/document/4303585/,2007 International Conference on Mechatronics and Automation,5-8 Aug. 2007,ieeexplore
10.1109/ICRA40945.2020.9196608,Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-to-end Robot Learning Scheme,IEEE,Conferences,"Traditional robotic control suits require profound task-specific knowledge for designing, building and testing control software. The rise of Deep Learning has enabled end-to-end solutions to be learned entirely from data, requiring minimal knowledge about the application area. We design a learning scheme to train end-to-end linear dynamical systems (LDS)s by gradient descent in imitation learning robotic domains. We introduce a new regularization loss component together with a learning algorithm that improves the stability of the learned autonomous system, by forcing the eigenvalues of the internal state updates of an LDS to be negative reals. We evaluate our approach on a series of real-life and simulated robotic experiments, in comparison to linear and nonlinear Recurrent Neural Network (RNN) architectures. Our results show that our stabilizing method significantly improves test performance of LDS, enabling such linear models to match the performance of contemporary nonlinear RNN architectures. A video of the obstacle avoidance performance of our method on a mobile robot, in unseen environments, compared to other methods can be viewed at https://youtu.be/mhEsCoNao5E.",https://ieeexplore.ieee.org/document/9196608/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROMAN.2009.5326235,Gestural teleoperation of a mobile robot based on visual recognition of sign language static handshapes,IEEE,Conferences,"This paper presents results achieved in the frames of a national research project (titled ldquoDIANOEMArdquo), where visual analysis and sign recognition techniques have been explored on Greek Sign Language (GSL) data. Besides GSL modelling, the aim was to develop a pilot application for teleoperating a mobile robot using natural hand signs. A small vocabulary of hand signs has been designed to enable desktopbased teleoperation at a high-level of supervisory telerobotic control. Real-time visual recognition of the hand images is performed by training a multi-layer perceptron (MLP) neural network. Various shape descriptors of the segmented hand posture images have been explored as inputs to the MLP network. These include Fourier shape descriptors on the contour of the segmented hand sign images, moments, compactness, eccentricity, and histogram of the curvature. We have examined which of these shape descriptors are best suited for real-time recognition of hand signs, in relation to the number and choice of hand postures, in order to achieve maximum recognition performance. The hand-sign recognizer has been integrated in a graphical user interface, and has been implemented with success on a pilot application for real-time desktop-based gestural teleoperation of a mobile robot vehicle.",https://ieeexplore.ieee.org/document/5326235/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/IRIS.2016.8066077,Gesture based robotic arm control for meal time care using a wearable sensory jacket,IEEE,Conferences,"This work presents the development of a wireless, low cost, wearable sensor jacket for the purpose of controlling a robot arm by mimicking the motion and behaviour of a humans arm. The intended use of our system is to provide remote daily nursing care by using our system from a distant place such as a nursing home or hospital, to control a stationed robotic arm placed in an elderly or patient's home. The final system is comprised of a wearable jacket which is embedded with IMU and flex sensors to detect and track the wearers arm movements and behaviour. The system is capable of detecting up to 5 degrees of freedom of the human arm and replicate these motions using a 6 DOF robot arm. The usability, accuracy and precision of our jacket system is evaluated through a user study and the results demonstrated that our system was more accurate and easier to use for operators than a conventional robotic arm joystick controller. In a water bottle transfer task our developed wearable jacket system demonstrated an average error distance of 29.36mm from the target point, while the results using the conventional joystick demonstrated an average error distance of 37.48mm. Furthermore subjects using our system were able to complete the transfer task in an average time of 44.1s per trial which was more efficient than the joystick method in which subjects averaged 55.55s per trial. Finally, we report a feasibility study with the jacket and a subject to demonstrate the capability of this system of giving a patient water to drink. The feasibility experiment showed an 86.66% success rate in giving a patient water via video stream teleoperation control.",https://ieeexplore.ieee.org/document/8066077/,2016 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS),17-20 Dec. 2016,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/SII46433.2020.9025951,Gym-Ignition: Reproducible Robotic Simulations for Reinforcement Learning,IEEE,Conferences,"This paper presents Gym-Ignition, a new framework to create reproducible robotic environments for reinforcement learning research. It interfaces with the new generation of Gazebo, part of the Ignition Robotics suite, which provides three main improvements for reinforcement learning applications compared to the alternatives: 1) the modular architecture enables using the simulator as a C++ library, simplifying the interconnection with external software; 2) multiple physics and rendering engines are supported as plugins, simplifying their selection during the execution; 3) the new distributed simulation capability allows simulating complex scenarios while sharing the load on multiple workers and machines. The core of Gym-Ignition is a component that contains the Ignition Gazebo simulator and exposes a simple interface for its configuration and execution. We provide a Python package that allows developers to create robotic environments simulated in Ignition Gazebo. Environments expose the common OpenAI Gym interface, making them compatible out-of-the-box with third-party frameworks containing reinforcement learning algorithms. Simulations can be executed in both headless and GUI mode, the physics engine can run in accelerated mode, and instances can be parallelized. Furthermore, the Gym-Ignition software architecture provides abstraction of the Robot and the Task, making environments agnostic on the specific runtime. This abstraction allows their execution also in a real-time setting on actual robotic platforms, even if driven by different middlewares.",https://ieeexplore.ieee.org/document/9025951/,2020 IEEE/SICE International Symposium on System Integration (SII),12-15 Jan. 2020,ieeexplore
10.1109/IROS.2018.8594070,HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System,IEEE,Conferences,"This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.",https://ieeexplore.ieee.org/document/8594070/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ITSC.2014.6958165,HOG based multi-object detection for urban navigation,IEEE,Conferences,"A necessary condition to perform a fully autonomous driving system in urban environment is to detect object types in real scenes. Visual object recognition is a key solution, but multi-object detection still remain unsolved. In this paper, we present a fast and efficient multi-object detection system built to recognize, at the same time, pedestrians cars and bicycles. For each target type, we construct a holistic detector in a cascade manner, using a dense overlapping grid based on histograms of oriented gradients (HOG). The selection of HOG features is obtained through a learning process using AdaBoost algorithm. Experiments have been conducted on the car-like robot Robucar, where the single detectors are combined and implemented on its embedded computer, which is endowed with a modular software platform. Results are promising as the system can process up to 20 fps with VGA images.",https://ieeexplore.ieee.org/document/6958165/,17th International IEEE Conference on Intelligent Transportation Systems (ITSC),8-11 Oct. 2014,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/ISVLSI.2016.101,Hardware Design Automation of Convolutional Neural Networks,IEEE,Conferences,"Convolutional Neural Networks (CNNs) are a variation of feed-forward Neural Networks inspired by the biological process in the visual cortex of animals. The interest in this supervised learning algorithm has rapidly grown in many fields like image and video recognition and natural language processing. Nowadays they have become the state of the art in various applications like mobile robot vision, video surveillance and Big Data analytics. The specific computation pattern of CNNs results to be highly suitable for hardware acceleration, in fact different types of accelerators have been proposed based on GPU, Field Programmable Gate Array (FPGA) and ASIC. In particular, in the embedded systems context, due to real time and power consumption challenges, it is crucial to find the right tradeoff between performance, energy efficiency, fast development round and cost. This work proposes a framework meant as a tool for the user to accelerate and simplify the design and the implementation of CNNs on FPGAs by leveraging High Level Synthesis, still providing a certain level of customization of the hardware design.",https://ieeexplore.ieee.org/document/7560201/,2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),11-13 July 2016,ieeexplore
10.1109/ICAEE.2017.8255341,Hardware and software implementation of real time electrooculogram (EOG) acquisition system to control computer cursor with eyeball movement,IEEE,Conferences,"Human computer interface (HCI) is an emerging technology of neuroscience and artificial intelligence. Development of HCI system using bio signal e.g. Electrooculogram (EOG), Electromyogram (EMG), Electroencephalogram (EEG), Functional near-infrared spectroscopy (fNIRS) etc. are attracted more and more attention of researchers all over the world in recent years because through this it is possible to get acquainted with advanced technologies of artificial intelligence. This paper presents the design and implementation of a fully functional Electrooculogram (EOG) based human computer interface. In this work we have designed and implemented necessary hardware and software for EOG signal acquisition along with controlling hardware such as wheelchair, robotic arm, mobile robot etc., and move computer mouse cursor simultaneously using EOG signal. This interface has three portion: EOG signal acquisition and amplification, analog to digital conversion, and real time hardware and mouse cursor movement. Eye movement is detected by measuring potential difference between cornea and retina using five Ag-Agcl disposable electrodes. Frequency range of EOG signal is considered as 0.3 to 15Hz, so this frequency range is taken using an active high and low pass filter so that accurate EOG signal can be achieved. The analog output of the EOG signal from filter is converted into digital signal by using an Arduino. Arduino serialize the EOG data for calibration and provides a threshold reference point which is used for controlling Hardware. The Classification module e.g. Support Vector machine (SVM) and Linear Discriminant Analysis (LDA) classify live data with respect to the horizontal and vertical data. This works as a binary classifier and choose optimal hyper-plane between two variables. According to each update on the eye position, cursor automatically accelerated in particular direction. PyMouse module in python is used for this task. Eye gesture based Hardware like robot, wheelchair etc. control and mouse cursor movement are the principle outcome of this research work.",https://ieeexplore.ieee.org/document/8255341/,2017 4th International Conference on Advances in Electrical Engineering (ICAEE),28-30 Sept. 2017,ieeexplore
10.1109/ROBOT.1993.292013,Hidden Markov model approach to skill learning and its application in telerobotics,IEEE,Conferences,"The problem of how human skill can be represented as a parametric model using a hidden Markov (HMM), and how an HMM-based skill model can be used to learn human skill, is discussed. The HMM is feasible for characterizing two stochastic processes, measurable action and immeasurable mental states that are involved in the skill learning. Based on the most likely performance criterion, the best action sequence can be selected from previously measured action data by modeling the skill as an HMM. This selection process can be updated in real-time by feeding new action data and modifying HMM parameters. The implementation of the proposed method in a teleoperation-controlled space robot is discussed. The results demonstrate the feasibility of the method.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292013/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/SMC.2018.00176,Hierarchical Control Architecture Regulating Competition between Model-Based and Context-Dependent Model-Free Reinforcement Learning Strategies,IEEE,Conferences,"Recent evidence in neuroscience and psychology suggests that a single reinforcement learning (RL) algorithm only accounts for less than 60% of the variance of human choice behavior in an uncertain and dynamic environment, where the amount of uncertainty in state-action-state transitions drift over time. The prediction performance further decreases when the size of the state space increases. We proposed a hierarchical context-dependent RL control framework that dynamically exerted control weights on model-based (MB) and multiple model-free (MF) RL strategies associated with different task goals. To properly assess the validity of the proposed method, we considered a two-stage Markov decision task (MDT) in which the three different types of context changed over time. We trained 57 different RL control models on a Caltech MDT data set; then, we assessed their prediction performance using a Bayesian model comparison. This large-scale computer simulation analysis revealed that the model providing the most accurate prediction was the version that implemented the competition between the MB and multiple goal-dependent MF RL strategies. The present study demonstrates the applicability of the goal-driven RL control to a variety of real-world human-robot interaction scenarios.",https://ieeexplore.ieee.org/document/8616172/,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",7-10 Oct. 2018,ieeexplore
10.1109/IJCNN.2007.4371289,Hierarchical MMC Networks as a manipulable body model,IEEE,Conferences,"A cognitive control system for a walking robot should be able to solve from simple reactive tasks up to complex tasks, including tasks which need cognitive capabilities and setting up plans. Planning ahead involves some kind of internal representation: most important a model of the own body. Considering planning as mental simulation, this model must be fully functional: it is constrained in the same way as the body itself and it can move and be used in the same way as the body. This model can then be used to try out movements mentally without doing the action in reality. For this purpose it must be possible to decouple the body itself from the action controlling modules to use the original controllers for control of the internal representations. In this publication we introduce a hierarchical model, implemented as an recurrent neural network based on the MMC principle.",https://ieeexplore.ieee.org/document/4371289/,2007 International Joint Conference on Neural Networks,12-17 Aug. 2007,ieeexplore
10.1109/ISIC.1992.225127,Hierarchical architecture for multi-sensor robot cell operation,IEEE,Conferences,"The authors describe a hierarchical architecture designed to carry out experiments in multisensor integration and sensor-based control in robotics. The hierarchical model is composed of three major levels: a high-level information processing and planning structure at the top, a logic-branching control structure at the intermediate level, and a real-time continuous sensory feedback loop at the bottom level. The two lower control structures are addressed. The principal submodules of the intermediate structure are described, with particular emphasis on communication issues and on the available software mechanisms for configuration and online maintenance of the robot cell. The architecture of the real-time continuous control structure that composes the bottom level is also described. The application of the adaptive self-tuning scheme in controlling position and force, specified in task-space coordinates, is discussed. Practical issues and experimental results are summarized.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/225127/,Proceedings of the 1992 IEEE International Symposium on Intelligent Control,11-13 Aug. 1992,ieeexplore
10.1109/ICSMC.1996.565422,High speed neural control for robot navigation,IEEE,Conferences,"This paper addresses the real time control of the Khepera mobile robot navigation in a maze with reflector walls. Boolean neural networks such as RAM and GSN models are applied to drive the vehicle, following a light source, while avoiding obstacles. Both neural networks are implemented with simple logic and arithmetic functions (NOT, AND, OR, Addition, and Comparison), aiming to improve the system speed. The results obtained are compared with two other control strategies: multilayer perceptron and fuzzy logic.",https://ieeexplore.ieee.org/document/565422/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA48506.2021.9561034,High-Speed Robot Navigation using Predicted Occupancy Maps,IEEE,Conferences,"Safe and high-speed navigation is a key enabling capability for real world deployment of robotic systems. A significant limitation of existing approaches is the computational bottleneck associated with explicit mapping and the limited field of view (FOV) of existing sensor technologies. In this paper, we study algorithmic approaches that allow the robot to predict spaces extending beyond the sensor horizon for robust planning at high speeds. We accomplish this using a generative neural network trained from real-world data without requiring human annotated labels. Further, we extend our existing control algorithms to support leveraging the predicted spaces to improve collision-free planning and navigation at high speeds. Our experiments are conducted on a physical robot based on the MIT race car using an RGBD sensor where were able to demonstrate improved performance at 4 m/s compared to a controller not operating on predicted regions of the map.",https://ieeexplore.ieee.org/document/9561034/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2008.4651150,High-dimensional underactuated motion planning via task space control,IEEE,Conferences,"Kinodynamic planning algorithms have the potential to find feasible control trajectories which accomplish a task even in very nonlinear or constrained dynamical systems. Underactuation represents a particular form of a dynamic constraint, inherently present in many machines of interest (e.g., walking robots), and necessitates planning for long-term control solutions. A major limitation in motion planning techniques, especially for real-time implementation, is that they are only practical for relatively low degree-of-freedom problems. Here we present a model-based dimensionality reduction technique based on an extension of partial feedback linearization control into a task-space framework. This allows one to plan motions for a complex underactuated robot directly in a low-dimensional task-space, and to resolve redundancy with lower-priority tasks. We illustrate the potential of this approach with an extremely simple motion planning system which solves the swing-up problem for multi-link underactuated pendula, and discuss extensions to the control of walking.",https://ieeexplore.ieee.org/document/4651150/,2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,22-26 Sept. 2008,ieeexplore
10.1109/ROBOT.1999.770002,High-speed navigation using the global dynamic window approach,IEEE,Conferences,"Many applications in mobile robotics require the safe execution of a collision-free motion to a goal position. Planning approaches are well suited for achieving a goal position in known static environments, while real-time obstacle avoidance methods allow reactive motion behavior in dynamic and unknown environments. This paper proposes the global dynamic window approach as a generalization of the dynamic window approach. It combines methods from motion planning and real-time obstacle avoidance to result in a framework that allows robust execution of high-velocity, goal-directed reactive motion for a mobile robot in unknown and dynamic environments. The global dynamic window approach is applicable to nonholonomic and holonomic mobile robots.",https://ieeexplore.ieee.org/document/770002/,Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C),10-15 May 1999,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/ETFA.2018.8502527,Holo Pick'n'Place,IEEE,Conferences,"In this paper we contribute to the research on facilitating industrial robot programming by presenting a concept for intuitive drag and drop like programming of pick and place tasks with Augmented Reality (AR). We propose a service-oriented architecture to achieve easy exchangeability of components and scalability with respect to AR devices and robot workplaces. Our implementation uses a HoloLens and a UR5 robot, which are integrated into a framework of RESTful web services. The user can drag recognized objects and drop them at a desired position to initiate a pick and place task. Although the positioning accuracy is unsatisfactory yet, our implemented prototype achieves most of the desired advantages to proof the concept.",https://ieeexplore.ieee.org/document/8502527/,2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA),4-7 Sept. 2018,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore
10.1109/YAC53711.2021.9486647,Human-Robot Interaction System Design for Manipulator Control Using Reinforcement Learning,IEEE,Conferences,"In this article, a novel human-robot interaction (HRI) system is presented and applied in the robotic arm coordinated operation control task. The presented HRI system includes two parts, the impedance model controller and the robotic arm controller, which allows the operator to manipulate the robotic arm to accomplish the given task with minimal human effort. First, the model-based reinforcement learning (RL) method is applied in the impedance model for operator adaptation. The impedance model controller can transform human input into the specific signal for the manipulator. Second, a novel adaptive manipulator controller is designed. In contrast to existing controllers, a velocity-free filter is implemented in our controller, which is developed to replace the manipulator actuator's speed signal. The effectiveness of the presented HRI system is verified by the simulation based on real manipulator parameters.",https://ieeexplore.ieee.org/document/9486647/,2021 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC),28-30 May 2021,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/EPIA.2005.341221,Hybrid State Machines with Timed Synchronization for Multi-Robot System Specification,IEEE,Conferences,"In multi-robot systems, the need for precise modeling or specification of agent behaviors arises due to the high complexity of the robot agent interactions and the dynamics of the environment. Since the behavior of agents usually can be understood as driven by external events and internal states, it is obvious to model multiagent systems by state transition diagrams. The corresponding formalisms come equipped with a formal semantics which is advantageous. In this paper, a combination of UML statecharts and hybrid automata is proposed, allowing formal system specification on different levels on abstraction on the one hand, and expressing real-time system behavior with continuous variables on the other hand. One important aspect of multi-robot systems is the need of coordination and hence synchronization of behavior. For both, statecharts and hybrid automata, it is assumed that synchronization takes zero time. This is sometimes unrealistic. Therefore, a new notation and implementation of synchronization is proposed here, which overcomes this problem. The proposed method is illustrated with a case study from the robotic soccer domain",https://ieeexplore.ieee.org/document/4145962/,2005 portuguese conference on artificial intelligence,5-8 Dec. 2005,ieeexplore
10.1109/ROMAN.1992.253866,Hybrid architectures for intelligent robotic systems,IEEE,Conferences,"Hybrid architectures, based on combinations of analogic, symbolic, and neural methods, are well suited for real-time applications in advanced robotics. Real-time industrial applications are mainly based on the correction of preplanned programs. So far, the planning and control modules of these kind of applications are often unable to react and/or classify un-expected events. The approach described attempts to integrate the sensor-based analogic method and the neural method into a multiple-level architecture that operates on an analogic world model, so that the action planning can be performed in a smart, reactive way. Given the task, the system builds the world model of the scenario. The reasoning and planning modules act both at the strategic as well as reactive levels, and the activated sensor-based motor strategies handle the sensorial data inputs and drive the robot controller module in the execution of the stream of motor commands. The interaction between the different levels is mainly based on the idea of maintaining and updating in real-time the world model, so that each module can locally operate on specific parts of the whole world model.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/253866/,[1992] Proceedings IEEE International Workshop on Robot and Human Communication, 1992,ieeexplore
10.1109/ETFA.2005.1612680,Hyper-redundant robotic micro-grippers with neural control,IEEE,Conferences,"The paper introduces a novel approach for the kinematic coordination of mechanical robot micro-grippers on the basis of neural networks. Conventional robot systems use specialized grippers for specific tasks. For objects with an amorphous structure, variable shape or small dimensions, conventional grippers become unreliable due to several reasons. The present paper presents an approach on the basis of a tentacle shaped micro-gripper with a high number of links and rotational articulated joints. The proposed method for gripping an object is based on wrapping the manipulator's links around the object in order to establish a firm grip. Sensors located near the joints of the micro-manipulator detect the corresponding distances to the object. Since the multi-link manipulator has a high degree of kinematic redundancy (consider up to several hundred links in a chain), the implementation of an effective trajectory control unit is a challenging task, especially if sensor-based real-time coordination is required. In this paper, we use an optimized geometrical path generator in order to teach dynamic neural nets a certain motion behavior, dependent on distance sensor signals. We show that the neural net is able to learn the procedural knowledge for the gripping process with ability of generalization and discuss the results",https://ieeexplore.ieee.org/document/1612680/,2005 IEEE Conference on Emerging Technologies and Factory Automation,19-22 Sept. 2005,ieeexplore
10.1109/CEC.2009.4983067,HyperNEAT controlled robots learn how to drive on roads in simulated environment,IEEE,Conferences,"In this paper we describe simulation of autonomous robots controlled by recurrent neural networks, which are evolved through indirect encoding using HyperNEAT algorithm. The robots utilize 180 degree wide sensor array. Thanks to the scalability of the neural network generated by HyperNEAT, the sensor array can have various resolution. This would allow to use camera as an input for neural network controller used in real robot. The robots were simulated using software simulation environment. In the experiments the robots were trained to drive with imaximum average speed. Such fitness forces them to learn how to drive on roads and avoid collisions. Evolved neural networks show excellent scalability. Scaling of the sensory input breaks performance of the robots, which should be gained back with re-training of the robot with a different sensory input resolution.",https://ieeexplore.ieee.org/document/4983067/,2009 IEEE Congress on Evolutionary Computation,18-21 May 2009,ieeexplore
10.1109/HAPTIC.2010.5444617,IN-HAPTICS: Interactive navigation using haptics,IEEE,Conferences,"We present a computational framework and experimental platform for robot navigation that allows for a user-friendly, graphical and haptic interaction with the human operator during the deployment process. The operator can see, feel, and manipulate the artificial potential field that drives the robot through an environment cluttered with obstacles. We present a case study in which the operator rescues a robot trapped in a local minimum of a navigation potential field.",https://ieeexplore.ieee.org/document/5444617/,2010 IEEE Haptics Symposium,25-26 March 2010,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/CISP-BMEI48845.2019.8965907,Implementation and Verification of a Virtual Testing System Based on ROS and Unity for Computer Vision Algorithms,IEEE,Conferences,"With the development of artificial intelligence technology, Computer vision algorithm is playing an increasingly important role. Computer vision algorithm testing is a vital link to ensure the safe and reliable operation of agents. However, the traditional testing methods based on real scenes provide single samples and are challenging to obtain ground truth, which makes it inefficient to test computer vision algorithms. To solve this problem, the testing method of computer vision algorithms using virtual scenes instead of real scenes has been applied. In this paper, Unity and robot operating system (ROS) are selected to build a virtual testing system named URCV for computer vision algorithms. The feasibility of the system and the influence of virtual scene elements on the testing of the monocular ORB_SLAM2 algorithm are verified, including the rendering path of Unity's RGB camera, texture accuracy, and illumination model.",https://ieeexplore.ieee.org/document/8965907/,"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",19-21 Oct. 2019,ieeexplore
10.1109/ISCAS.2003.1205151,Implementation of Turing patterns for bio-inspired motion control,IEEE,Conferences,"In this paper a CNN controlling the reactive behavior of a roving robot by means of Turing patterns is introduced. The Turing pattern represents the fixed-action pattern of the robot, while the initial conditions of the CNN are given by the sensor status. The approach is still valid when the number of sensors is high, being able to perform data fusion in real-time through analog parallel processing. An experiment using a small roving robot is presented to validate the approach.",https://ieeexplore.ieee.org/document/1205151/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/ELECSYM.2018.8615503,Implementation of Victims Detection Framework on Post Disaster Scenario,IEEE,Conferences,"Disasters are prone to occur in Indonesia due to geographical factors, such as tectonic plate movements, which can cause an earthquake. Earthquakes are one of the most frequent disasters, they have broad impacts in a short time and are unpredictable. Thus, an extensive search process in a short time is highly critical to determine the victims location. In this paper, a victims detection framework is developed starting from acquiring images using an unmanned aerial vehicle and further processing using convolutional neural network (CNN) to locate victims robustly on post-disaster. Input images are then sent to victim detector dedicated ground station server for further high processing robustly locating the possibility of victims. A simulation system mimicking a real environment is developed to test our framework in real time. A transmission protocol is also developed for effectively transmitting data between the robot and the server. The treatment on the detection process of the victim is different from the normal human detection, some pre-processing stages are applied to increase the variation of the given dataset. An embedded system is used for taking images and additional sensors data, such as location and time using Global Navigation Satellite System.",https://ieeexplore.ieee.org/document/8615503/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/SSST.1998.660084,Implementation of a navigational neural network on a parallel DSP board,IEEE,Conferences,"This work presents a neural network architecture that is motivated by the learning and memory characteristics of a part of the brain known as hippocampus, which is important in navigational behavior in humans and animals. Neural networks perform nonlinear transformations on data to yield suitable classification or control actions. In our case, the navigation network takes the distance information as data and maps it to control actions by the mobile robot. Navigation is a very important engineering problem for unknown or hazardous environments to ensure the safety of equipment and human life. Hardware implementation can benefit applications in real time where speed is the major concern. Our objective is to implement such a navigational neural network in parallel so that real time performance can be achieved by using a parallel DSP board system. Supplementary studies are also being carried out on the IBM SP2 supercomputer to understand the design and scaling properties of the parallel algorithm.",https://ieeexplore.ieee.org/document/660084/,Proceedings of Thirtieth Southeastern Symposium on System Theory,10-10 March 1998,ieeexplore
10.1109/IJCNN.2008.4633972,Implementation of a neural network based visual motor control algorithm for A 7 DOF redundant manipulator,IEEE,Conferences,"This paper deals with visual-motor coordination of a 7 dof robot manipulator for pick and place applications. Three issues are dealt with in this paper - finding a feasible inverse kinematic solution without using any orientation information, resolving redundancy at position level and finally maintaining the fidelity of information during clustering process thereby increasing accuracy of inverse kinematic solution. A 3-dimensional KSOM lattice is used to locally linearize the inverse kinematic relationship. The joint angle vector is divided into two groups and their effect on end-effector position is decoupled using a concept called function decomposition. It is shown that function decomposition leads to significant improvement in accuracy of inverse kinematic solution. However, this method yields a unique inverse kinematic solution for a given target point. A concept called sub-clustering in configuration space is suggested to preserve redundancy during learning process and redundancy is resolved at position level using several criteria. Even though the training is carried out off-line, the trained network is used online to compute the required joint angle vector in only one step. The accuracy attained is better than the current state of art. The experiment is implemented in real-time and the results are found to corroborate theoretical findings.",https://ieeexplore.ieee.org/document/4633972/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/iFuzzy.2013.6825409,Implementation of human following mission by using fuzzy head motion control and Q-learning wheel motion control for home service robot,IEEE,Conferences,"This paper mainly implements human following function for home service robot, May, developed in our laboratory. In order to follow the operator accurately, visual tracking is composed by Tracing-Learning-Detection (TLD) and Kinect skeleton, where TLD plays the role as re-detecting the situation that operator is occluded or disappeared, and Kinect skeleton is adopted to track all other situations while TLD is learning how to enlarge operator image patterns in order to enhance recognition rates. For the sake of improving tracking capability, fuzzy head motion control is added in the visual tracking system to compensate the constraints that the mobile platform of May cannot react rapidly. Every instant movement of the operator can be captured by fuzzy head motion control in real time. Q-learning is applied to discover the pose switching of the mobile platform such that May possesses more robust following ability. By Q-learning, states setting are based on three dimensional position, actions are created by the pose of four wheel independent steering and four wheel independent driven (4WIS4WID) platform, and rewards are established on state transitions. Finally, both the experimental results in the laboratory and competition consequents of Follow Me Mission in robot@home league at RoboCup Japan Open 2013 Tokyo demonstrate that our robot May can fluently switch its poses to follow operator by utilizing the proposed schemes.",https://ieeexplore.ieee.org/document/6825409/,2013 International Conference on Fuzzy Theory and Its Applications (iFUZZY),6-8 Dec. 2013,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/INES.1997.632397,Implementation of neural network sliding-mode controller for DD robot,IEEE,Conferences,"The experimental development of a trajectory tracking neural network controller based on the theory of continuous sliding-mode controllers is shown in the paper. The neural network control law was verified on a real direct drive 3 DOF PUMA mechanism. The new neural network sliding-mode controller was successfully tested for trajectory tracking sudden changes in the manipulator dynamics (load). The comparision between the neural network sliding mode controller, a computer torque method controller and a continuous sliding mode controller with PI-estimator for sudden load changes on the real robot mechanism is shown.",https://ieeexplore.ieee.org/document/632397/,Proceedings of IEEE International Conference on Intelligent Engineering Systems,17-17 Sept. 1997,ieeexplore
10.1109/IROS.1995.525808,Implementation of real time spatial mapping in robotic systems through self-organizing neural networks,IEEE,Conferences,"Presents a methodology which allows an autonomous agent i.e., a mobile robot, to learn and build maps of its operating environment by relying only on its range sensors. The maps, described with respect to the robot's inertial frame, are developed in real time by correlating robot position and sensory data. This latter feature characterizes part of the uniqueness of the authors' approach. These maps are topologically isomorphic to the maps created for the same room(s) by humans. The methodology exploits the principle of self-organization, implemented as an artificial neural network module which processes incoming sensor range data. The generation of environmental maps can be visualized as an elastic string of neurons whereby every neuron represents a finite portion of the physical world. This elastic string stretches dynamically so as to take on the shape of the environment, a unique characteristic of the authors' methodology. In this respect, the neural net provides a discretized representation of the ""continuous"" physical environment as the latter is seen through the robot's own sensors. Experiments, focused on indoor applications, have successfully demonstrated the ability of a robot to build maps of geometrically complex environments. The results presented in this paper, compared with the authors' earlier efforts, show significant improvement in that every single sensor data point contributes equally to the location of the neurons of the spatial map at the end of the learning process. This is important because the authors wish to minimize the effect of the order in which data points are processed.",https://ieeexplore.ieee.org/document/525808/,Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots,5-9 Aug. 1995,ieeexplore
10.1109/I2CT.2014.7092212,Implementation of synthetic brain concept in humanoid robot,IEEE,Conferences,"This paper is elaborate the model of humanoid robot interacts with human being and perform various operation as per the command given by the human being. A humanoid robot having Synthetic brain can able to do Interaction, communication, Object detection, information acquisition about any object, response to voice command, chatting logically with human beings. Object detection will be done by this robot for that purpose there is use image processing concept (HAAR Technique), And to make the system intelligent that is whenever system interact, communicate, chat with human it gives proper response, question / answers there is integrates artificial intelligence and DFA / NFA automata and Prolog language concept for answering logically over the complex and relevant strings or data.",https://ieeexplore.ieee.org/document/7092212/,International Conference for Convergence for Technology-2014,6-8 April 2014,ieeexplore
10.1109/ICMTMA.2018.00075,Implementing Multi-DOF Trajectory Tracking Control System for Robotic Arm Experimental Platform,IEEE,Conferences,"To implement the control system of a multi-DOF robotic manipulator (Dobot), the robot dynamics, trajectory planning algorithm and motion control strategy are studied for designing the trajectory tracking control system. In this paper, the hardware and software of Dobot magician control system are designed. The hardware mainly includes STM32 controller. The software part mainly builds the host computer display interface, completes the protocol communication between the robot manipulator and the PC, so as to realize the trajectory tracking control of the robot manipulator and implement the track-following in real time. The experimental results show that the control system can accurately track the trajectory of robotic manipulator with a certain degree of real-time and stability.",https://ieeexplore.ieee.org/document/8337386/,2018 10th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),10-11 Feb. 2018,ieeexplore
10.1109/CIMSA.2003.1227232,Improve the position measurement accuracy using a dynamic on-line fuzzy interpolation technique,IEEE,Conferences,"Traditional robot calibration implements model and modeless methods. The compensation of position error in modeless method is to move the end-effector of robot to the target position in the workspace, and to find the position error of that target position by using a bilinear interpolation method based on the neighboring 4-point's errors around the target position. A camera or other measurement devices can be utilized to find or measure this position error, and compensate this error with the interpolation result. This paper provides a novel fuzzy interpolation method to improve the compensation accuracy obtained by using a bilinear interpolation method. A dynamic online fuzzy inference system is implemented to meet the needs of a fast real-time control system and calibration environment. The simulated results show that the compensation accuracy can be greatly improved by using this fuzzy interpolation method compared with the bilinear interpolation method.",https://ieeexplore.ieee.org/document/1227232/,"The 3rd International Workshop on Scientific Use of Submarine Cables and Related Technologies, 2003.",31-31 July 2003,ieeexplore
10.1109/COGINF.2011.6016164,Improved mobile robot's Corridor-Scene Classifier based on probabilistic Spiking Neuron Model,IEEE,Conferences,"The ability of cognition and recognition for complex environment is very important for a real autonomous robot. A improved Corridor-Scene-Classifier based on probabilistic Spiking Neuron Model(pSNM) for mobile robot is designed. In the SNN classifier, the model pSNM is used. As network's training, Thorpe's learning rule is used. The experimental results show that the improved Classifier is more effective and it also has stronger robustness than the previous classifier based on Integrated-and-Fire (IAF) spiking neuron model for the structural corridor-scene. It also has better robustness than the traditional kernel-pca and the BP Corridor-Scene-classifier.",https://ieeexplore.ieee.org/document/6016164/,IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11),18-20 Aug. 2011,ieeexplore
10.1109/ELECSYM.2018.8615506,Improving Field and Ball Detector for Humanoid Robot Soccer EROS Platform,IEEE,Conferences,"Humanoid robot soccer perceives environment mostly through cameras. The performance decrement in our humanoid soccer platform (EROS) is primarily due to the visual perception that is less robust to the RoboCup new rule which specifically reducing color coding in the field. Notable works favorably employ simple color segmentation, image morphology, and blob detector due to simplicity in the implementation and run in real-time for most embedded hardware, while some employ a more advanced supervised learning running in sophisticated hardware to boost detection accuracy. In this paper, a visual perception system consisting of field and ball detection is developed in our platform EROS to address the RoboCup new rule. Color segmentation and image morphology are stacked with a more advanced supervised learning cascade classifier. In this way, the favorable color segmentation and image morphology help to reduce the number of object candidates while the cascade classifier helps to boost the accuracy of detection. Experiments show encouraging result for detecting field and ball position. Our approach has successfully been implemented in practice and achieves remarkably result in Indonesian humanoid robot soccer competition.",https://ieeexplore.ieee.org/document/8615506/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/IROS45743.2020.9341029,Improving Unimodal Object Recognition with Multimodal Contrastive Learning,IEEE,Conferences,"Robots perceive their environment using various sensor modalities, e.g., vision, depth, sound or touch. Each modality provides complementary information for perception. However, while it can be assumed that all modalities are available for training, when deploying the robot in real-world scenarios the sensor setup often varies. In order to gain flexibility with respect to the deployed sensor setup we propose a new multimodal approach within the framework of contrastive learning. In particular, we consider the case of learning from RGB-D images while testing with one modality available, i.e., exclusively RGB or depth. We leverage contrastive learning to capture high-level information between different modalities in a compact feature embedding. We extensively evaluate our multimodal contrastive learning method on the Falling Things dataset and learn representations that outperform prior methods for RGB-D object recognition on the NYU-D dataset. Our code and details on the used datasets are available at: https://github.com/meyerjo/MultiModalContrastiveLearning.",https://ieeexplore.ieee.org/document/9341029/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICPR.1996.547231,Incremental learning for vision-based navigation,IEEE,Conferences,"In this paper, we explore the issue of incremental learning for autonomous navigation of a mobile robot. The autonomous navigation problem is regarded as a content-based retrieval problem where the robot learns the navigation experience using a hierarchical recursive partition tree (RPT). During real navigation, each time a new image is grabbed to retrieve the learned tree. The associated control signals of the retrieved are used to control the new action of the robot. Use of RPT can achieve efficient retrieval. In the proposed incremental learning scheme, a new image with the associated control signals is learned or rejected according to whether its retrieved output control signals are within tolerance of the desired control signals of the input query image. We use the eigen-subspace method for feature extraction in our incremental learning. The proposed algorithm has a real-time implementation for both learning and performance phases. Experimental results are shown to confirm the effectiveness of proposed method.",https://ieeexplore.ieee.org/document/547231/,Proceedings of 13th International Conference on Pattern Recognition,25-29 Aug. 1996,ieeexplore
10.1109/IROS.2010.5650519,Incremental motion primitive learning by physical coaching using impedance control,IEEE,Conferences,"We present an approach for kinesthetic teaching of motion primitives for a humanoid robot. The proposed teaching method allows for iterative execution and motion refinement using a forgetting factor. During the iterative motion refinement, a confidence value specifies an area of allowed refinement around the nominal trajectory. A novel method for continuous generation of motions from a hidden Markov model (HMM) representation of motion primitives is proposed, which incorporates relative time information for each state. On the real-time control level, the kinesthetic teaching is handled by a customized impedance controller, which combines tracking performance with soft physical interaction and allows to implement soft boundaries for the motion refinement. The proposed methods were implemented and tested using DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5650519/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/DEVLRN.2014.6983001,Incremental training of Restricted Boltzmann Machines using information driven saccades,IEEE,Conferences,"In the context of developmental robotics, a robot has to cope with complex sensorimotor spaces by reducing their dimensionality. In the case of sensor space reduction, classical approaches for pattern recognition use either hardcoded feature detection or supervised learning. We believe supervised learning and hard-coded feature extraction must be extended with unsupervised learning of feature representations. In this paper, we present an approach to learn representations using space-variant images and saccades. The saccades are driven by a measure of quantity of information in the visual scene, emerging from the activations of Restricted Boltzmann Machines (RBMs). The RBM, a generative model, is trained incrementally on locations where the system saccades. Our approach is implemented using real data captured by a NAO robot in indoor conditions.",https://ieeexplore.ieee.org/document/6983001/,4th International Conference on Development and Learning and on Epigenetic Robotics,13-16 Oct. 2014,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/ROBOT.2010.5509682,Indoor scene recognition through object detection,IEEE,Conferences,"Scene recognition is a highly valuable perceptual ability for an indoor mobile robot, however, current approaches for scene recognition present a significant drop in performance for the case of indoor scenes. We believe that this can be explained by the high appearance variability of indoor environments. This stresses the need to include high-level semantic information in the recognition process. In this work we propose a new approach for indoor scene recognition based on a generative probabilistic hierarchical model that uses common objects as an intermediate semantic representation. Under this model, we use object classifiers to associate low-level visual features to objects, and at the same time, we use contextual relations to associate objects to scenes. As a further contribution, we improve the performance of current state-of-the-art category-level object classifiers by including geometrical information obtained from a 3D range sensor that facilitates the implementation of a focus of attention mechanism within a Monte Carlo sampling scheme. We test our approach using real data, showing significant advantages with respect to previous state-of-the-art methods.",https://ieeexplore.ieee.org/document/5509682/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ICALT.2006.1652652,Instruction Through The Ages: Building Pervasive Virtual Instructors for Life Long Learning,IEEE,Conferences,"A pervasive virtual instructor is an artificially intelligent instructor that may appear transparent to the learner or appear in the form of a three-dimensional graphical character, digital toy, or robot with capabilities to inhabit mixed reality environments, and provide personalized instruction anytime, anywhere, and at an-pace. Similarly to pedagogical agents, or traditional virtual instructors, pervasive virtual instructors are expected to behave autonomously, respond to human verbal/non-verbal input, and deliver information to human users. Unique to pervasive virtual instructors in this paper are capabilities to provide instruction across distributed networks, interact with human learners using context-aware intelligence, and apply empirically researched pedagogical/andragogical techniques. Technology challenges remain for building pervasive virtual instructors to achieve aforementioned capabilities. This paper summarizes technical challenges and an approach for building pervasive instructors that provide life long instructional services",https://ieeexplore.ieee.org/document/1652652/,Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06),5-7 July 2006,ieeexplore
10.1109/ROBOT.1992.219999,Integrated planning and execution control of autonomous robot actions,IEEE,Conferences,"The authors describe an implemented integrated system allowing a mobile robot to plan its actions, taking into account temporal constraints, and to control their execution in real time. The general architecture has three levels, and the approach is related to hierarchical planning: the plan produced by the temporal planner is further refined at the control level, which in turn supervises its execution by a functional level. The framework of the French Mars Rover project VAP is used as an illustration of the various aspects discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/219999/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ISCAS.2007.378811,Integrating high-level sensor features via STDP for bio-inspired navigation,IEEE,Conferences,"Correlation based algorithms have been found to explain many basic behaviors in simple animals. In this paper the authors investigate the problem of navigation control of a robot from the viewpoint of bio-inspired perception. In this paper the authors study how to go up, through learning, from the implementation of a reactive system, towards behaviors of increasing complexity. The whole control system is based on networks of spiking neurons. A correlation based rule, namely the spike timing dependent plasticity (STDP), is implemented for an efficient learning. The main interesting consequence is that the system is able to learn high-level sensor features, based on a set of basic reflexes, depending on some low-level sensor inputs. The whole methodology is presented through simulation results and also through its implementation on an FPGA based system for real time working on a roving robot.",https://ieeexplore.ieee.org/document/4252708/,2007 IEEE International Symposium on Circuits and Systems,27-30 May 2007,ieeexplore
10.1109/LARS-SBR.2016.49,Integration of People Detection and Simultaneous Localization and Mapping Systems for an Autonomous Robotic Platform,IEEE,Conferences,"This paper presents the implementation of a people detection system for a robotic platform able to perform Simultaneous Localization and Mapping (SLAM), allowing the exploration and navigation of the robot considering people detection interaction. The robotic platform consists of a Pioneer 3DX robot equipped with an RGB-D camera, a Sick Lms200 sensor laser and a computer using the robot operating system ROS. The idea is to integrate the people detection system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. Furthermore, this paper presents an evaluation of two different approaches for the people detection system. The first one uses a manual feature extraction technique, and the other one is based on deep learning methods. The manual feature extraction method in the first approach is based on HOG (Histogram of Oriented Gradients) detectors. The accuracy of the techniques was evaluated using two different libraries. The PCL library (Point Cloud Library) implemented in C ++ and the VLFeat MatLab library with two HOG variants, the original one, and the DPM (Deformable Part Model) variant. The second approaches are based on a Deep Convolutional Neural Network (CNN), and it was implemented using the MatLab MatConvNet library. Tests were made objecting the evaluation of losses and false positives in the people's detection process in both approaches. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.",https://ieeexplore.ieee.org/document/7783535/,2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR),8-12 Oct. 2016,ieeexplore
10.1109/IECON.2011.6119682,Integration of grey model and neural network for robotic application,IEEE,Conferences,"This paper proposes an intelligent forecasting system based on a feedforward neural network aided grey model (FNAGM), integrating a first-order single variable grey model (GM(1,1)) and a feedforward neural network. The system includes three phases: initialization phase, GM(1,1) prediction phase, and FNAGM prediction phase. A number of parameters required for the FNAGM are selected in the initialization phase. A one-step ahead predictive value is generated in the GM(1,1) prediction phase, followed by the implementation of a feedforward neural network used to determine the prediction error of the GM(1,1) and compensate for it in the FNAGM prediction phase. We also adopted on-line batch training to adjust the network according to the Levenberg-Marquardt algorithm in real-time. According to the experimental results of a robot, the proposed intelligent forecasting system can provide high accuracy for both trajectory prediction and target tracking.",https://ieeexplore.ieee.org/document/6119682/,IECON 2011 - 37th Annual Conference of the IEEE Industrial Electronics Society,7-10 Nov. 2011,ieeexplore
10.1109/WOCC.2018.8372718,Integration of open source platform duckietown and gesture recognition as an interactive interface for the museum robotic guide,IEEE,Conferences,"In recent years, population aging becomes a serious problem. To decrease the demand for labor when navigating visitors in museums, exhibitions, or libraries, this research designs an automatic museum robotic guide which integrates image and gesture recognition technologies to enhance the guided tour quality of visitors. The robot is a self-propelled vehicle developed by ROS (Robot Operating System), in which we achieve the automatic driving based on the function of lane-following via image recognition. This enables the robot to lead guests to visit artworks following the preplanned route. In conjunction with the vocal service about each artwork, the robot can convey the detailed description of the artwork to the guest. We also design a simple wearable device to perform gesture recognition. As a human machine interface, the guest is allowed to interact with the robot by his or her hand gestures. To improve the accuracy of gesture recognition, we design a two phase hybrid machine learning-based framework. In the first phase (or training phase), k-means algorithm is used to train historical data and filter outlier samples to prevent future interference in the recognition phase. Then, in the second phase (or recognition phase), we apply KNN (k-nearest neighboring) algorithm to recognize the hand gesture of users in real time. Experiments show that our method can work in real time and get better accuracy than other methods.",https://ieeexplore.ieee.org/document/8372718/,2018 27th Wireless and Optical Communication Conference (WOCC),30 April-1 May 2018,ieeexplore
10.1109/CIRA.1997.613877,Intelligence computing for direct human-robot communication using natural language and cognitive graphics,IEEE,Conferences,"A direct human-robot communication system based on natural language (NL) and cognitive graphics (CG) as a part of a new hierarchical structure of an AI control system of a mobile robot for service use (MRSU) is developed. The software of the simulation system for direct human-robot communication and MRSU behavior based on NL and CG is described. The NL and CG are used for description and representation of possible external worlds in the robot artificial life. This system allows us to evaluate the control algorithms of real time robot behavior and to reduce difficulties connected with such troubles as robot collisions with real objects and robot hardware damage. The mathematical background of direct NL human-robot communication and robot behavior simulation system is knowledge engineering based on spatio-temporal and action logics, default reasoning, cognitive graphics and soft computing. The main concepts, structure, conceptual model of the simulation system for description of the artificial life of the MRSU are discussed. A simulation example and real experimental results are described.",https://ieeexplore.ieee.org/document/613877/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/IJCNN.2014.6889647,Intelligent Facial Action and emotion recognition for humanoid robots,IEEE,Conferences,"This research focuses on the development of a realtime intelligent facial emotion recognition system for a humanoid robot. In our system, Facial Action Coding System is used to guide the automatic analysis of emotional facial behaviours. The work includes both an upper and a lower facial Action Units (AU) analyser. The upper facial analyser is able to recognise six AUs including Inner and Outer Brow Raiser, Upper Lid Raiser etc, while the lower facial analyser is able to detect eleven AUs including Upper Lip Raiser, Lip Corner Puller, Chin Raiser, etc. Both of the upper and lower analysers are implemented using feedforward Neural Networks (NN). The work also further decodes six basic emotions from the recognised AUs. Two types of facial emotion recognisers are implemented, NN-based and multi-class Support Vector Machine (SVM) based. The NN-based facial emotion recogniser with the above recognised AUs as inputs performs robustly and efficiently. The Multi-class SVM with the radial basis function kernel enables the robot to outperform the NN-based emotion recogniser in real-time posed facial emotion detection tasks for diverse testing subjects.",https://ieeexplore.ieee.org/document/6889647/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ARIS50834.2020.9205772,Intelligent Robot for Worker Safety Surveillance: Deep Learning Perception and Visual Navigation,IEEE,Conferences,"The fatal injury rate for the construction industry is higher than the average for all industries. Recently, researchers have shown an increased interest in occupational safety in the construction industry. However, all the current methods using conventional machine learning with stationary cameras suffer from some severe limitations, perceptual aliasing (e.g., different places/objects can appear identical), occlusion (e.g., place/object appearance changes between visits), seasonal / illumination changes, significant viewpoint changes, etc. This paper proposes a perception module using end-to-end deep-learning and visual SLAM (Simultaneous Localization and Mapping) for an effective and efficient object recognition and navigation using a differential-drive mobile robot. Various deep-learning frameworks and visual navigation strategies with evaluation metrics are implemented and validated for the selection of the best model. The deep-learning model's predictions are evaluated via the metrics (model speed, accuracy, complexity, precision, recall, P-R curve, F1 score). The YOLOv3 shows the best trade-off among all algorithms, 57.9% mean average precision (mAP), in real-world settings, and can process 45 frames per second (FPS) on NVIDIA Jetson TX2 which makes it suitable for real-time detection, as well as a right candidate for deploying the neural network on a mobile robot. The evaluation metrics used for the comparison of laser SLAM are Root Mean Square Error (RMSE). The Google Cartographer SLAM shows the lowest RMSE and acceptable processing time. The experimental results demonstrate that the perception module can meet the requirements of head protection criteria in Occupational Safety and Health Administration (OSHA) standards for construction. To be more precise, this module can effectively detect construction worker's non-hardhat-use in different construction site conditions and can facilitate improved safety inspection and supervision.",https://ieeexplore.ieee.org/document/9205772/,2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),19-21 Aug. 2020,ieeexplore
10.1109/ICAMechS.2016.7813486,Intelligent adaptive precrash control for autonmous vehicle agents (CBR Engine &amp; hybrid A∗ path planner),IEEE,Conferences,"PreCrash problem of Intelligent Control of autonomous vehicles robot is a very complex problem, especially vehicle pre-crash scenariws and at points of intersections in real-time environmenta. This Paper presents a novel architecture of Intelligent adaptive control for autonomous vehicle agent that depends on Artificial Intelligence Techniques that applies case-based reasoning techniques, where Parallel CBR Engines are implemented for different scenarios' of PreCrash problem and sub-problems of intersection safety and collision avoidance, in the higher level of the controller and A* path planner for path planning and at lower-levels it also uses some features of autonomous vehicle dynamics. Moreover, the planner is enhanced by combination of Case-Based Planner. All modules are presented and discussed. Experimental results are conducted in the framework of Webots autonomous vehicle tool and overall results are good for the CBR Engine for Adaptive control and also for the hybrid Case-Based Planner, A* and D* motion planner along with conclusion and future work.",https://ieeexplore.ieee.org/document/7813486/,2016 International Conference on Advanced Mechatronic Systems (ICAMechS),30 Nov.-3 Dec. 2016,ieeexplore
10.1109/ICIT.2010.5472498,Intelligent control and evolutionary strategies applied to multirobotic systems,IEEE,Conferences,"This paper describes the modeling, implementation, and evaluation of RoBombeiros multirobotic system. The robotic task in this paper is performed over a natural disaster, simulated as a forest fire. The simulator supports several features to allow realistic simulation, like irregular terrains, natural processes (e.g. fire, wind) and physical constraint in the creation and application of mobile robots. The proposed system relies on two steps: (i) group formation planning and (ii) intelligent techniques to perform robots navigation for fire fighting. For planning, we used genetic algorithms to evolve positioning strategies for firefighting robots performance. For robots operation, physically simulated fire-fighting robots were built, and the sensory information of each robot (e.g. GPS, compass, sonar) was used in the input of an artificial neural network (ANN). The ANN controls the vehicle (robot) actuators and allows navigation with obstacle avoidance. Simulation results show that the ANN satisfactorily controls the mobile robots; the genetic algorithm adequately configures the fire fighting strategy and the proposed multi-robotic system can have an essential hole in the planning and execution of fire fighting in real forests.",https://ieeexplore.ieee.org/document/5472498/,2010 IEEE International Conference on Industrial Technology,14-17 March 2010,ieeexplore
10.1109/ICNN.1988.23981,Intelligent control of the Intelledex 605T robot manipulator,IEEE,Conferences,"The authors present the results of the experiments which indicate how controlled robotic motion might be achieved through pattern-based paradigms, implemented for real-time operation on the Intelledex 605T robot manipulator with artificial neural nets (ANN). Previous attempts at pattern-based control have often failed, primarily because of the need for storage of an enormous number of training-set patterns and the long times required for pattern processing. It is demonstrated that these problems can be overcome through use of artificial neural networks implemented by parallel distributed processing. The feedforward Rumelhart net is investigated for the constrained robot manipulator. The robot arm, with two degrees of freedom, must move its end effector toward an observed target in the presence of disturbances. Such a control action need not be programmed in detail. Presented with a small number of training situations, the ANN can generalize and perform in many different situations. Preliminary results obtained using an Intelledex 605T and an IBM PC/AT are described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/23981/,IEEE 1988 International Conference on Neural Networks,24-27 July 1988,ieeexplore
10.1109/IROS.2005.1545188,Interactive evolution of human-robot communication in real world,IEEE,Conferences,"This paper describes how to implement interactive evolutionary computation (IEC) into a human-robot communication system. IEC is an evolutionary computation (EC) in which the fitness function is performed by human assessors. We used IEC to configure the human-robot communication system. We have already simulated IEC's application. In this paper, we implemented IEC into a real robot. Since this experiment leads considerable burdens on both the robot and experimental subjects, we propose the human-machine hybrid evaluation (HMHE) to increase the diversity within the genetic pool without increasing the number of interactions. We used a communication robot, WAMOEBA-3 (Waseda artificial mind on emotion base), which is appropriate for this experiment. In the experiment, human assessors interacted with WAMOEBA-3 in various ways. The fitness values increased gradually, and assessors felt the robot learnt the motions they desired. Therefore, it was confirmed that the IEC is most suitable as the communication learning system.",https://ieeexplore.ieee.org/document/1545188/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ISIC.2003.1253948,Internet-based remote control by using Adaline neural networks,IEEE,Conferences,"In this paper, we present a remote control scheme for Internet-based teleoperation. This control scheme relies on the real-time estimation of concurrent roundtrip delays in order to optimally assign tasks between the user and the robot. For this purpose, we employ an adaptive linear (Adaline) neural network for which most conventional learning algorithms are infeasible since the computation is usually too intensive to be practical. To get around this problem, we introduce a novel learning algorithm that is based on the maximum entropy principle. Compared to traditional learning algorithms, the computing cost of this algorithm is very low, which makes it possible for the proposed neural network to be implemented on-line in real-time.",https://ieeexplore.ieee.org/document/1253948/,Proceedings of the 2003 IEEE International Symposium on Intelligent Control,8-8 Oct. 2003,ieeexplore
10.1109/ISSCS52333.2021.9497411,Inverted Pendulum Control with a Robotic Arm using Deep Reinforcement Learning,IEEE,Conferences,"Inverted pendulum control is a benchmark control problem that researchers have used to test the new control strategies over the past 50 years. Deep Reinforcement Learning Algorithm is used recently on the inverted pendulum on a straightforward form. The inverted pendulum had only one degree of freedom and was moving on a plane. This paper demonstrates a successful implementation of a deep reinforcement learning algorithm on an inverted pendulum that rotates freely on a spherical joint with an industrial 6 degrees freedom robot arm. This research used the Deep Reinforcement Learning algorithm in Robot Operating System (ROS) and Gazebo Simulation. Experimental results show that the proposed method achieved promising outputs and reaches the control objectives. We were able to control the inverted pendulum upward for 30 and 20 seconds in two case studies. Two other significant novelties in this research are using an inertial measurement unit (IMU) on the tip of the pendulum, that will facilitate implementation on the real robot for future work and different reward functions in comparing to past publications that enable continuous learning and mastering control in a vertical position",https://ieeexplore.ieee.org/document/9497411/,"2021 International Symposium on Signals, Circuits and Systems (ISSCS)",15-16 July 2021,ieeexplore
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/ACC.1994.735001,Investigation of kinematics and inverse dynamics algorithm with a DSP implementation of a neural network,IEEE,Conferences,"An investigation is described to demonstrate the benefits which can be gained by using a digital signal processor (DSP) to implement robot related control schemes, kinematics, and inverse dynamics with a neural network. A neural network adaptive controller is given and applied to a robot manipulator having a closed kinematic chain, a configuration which is not well suited to the popular serial link algorithms. The Lyapunov's stability approach is used to develop a learning rule for the neural network controller that would guarantee the stability of the training process under mild conditions. The controller hardware consists of a PC-386, a fixed point DSP, and a floating point DSP. The software installed on each of these processors has the requirements of satisfying the specific responsibility assigned to that processor and of communicating with other processors so that necessary data is passed on in a timely manner. A computational software package has been built to further enhance the speed of the general control scheme and the neural network algorithm. The techniques used in the DSP implementation of the adaptive control algorithm in real-time are also discussed.",https://ieeexplore.ieee.org/document/735001/,Proceedings of 1994 American Control Conference - ACC '94,29 June-1 July 1994,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/ISIE.2009.5221750,Joint control of ROBOKER arm using a neural chip embedded on FPGA,IEEE,Conferences,"This paper presents implementation of a neural chip to proceed neural processing of the radial basis function (RBF) network. RBF network along with a primary PD controller is trained in on-line fashion. Radial basis function network processing is embedded on a field programmable gate array(FPGA) chip to achieve real-time control. To enable nonlinear function calculation, a floating point processor is designed to allow assembly programming for learning algorithm. Other necessary hardware modules for control purposes are also designed and implemented. A humanoid robot called the ROBOKER with two arms of 6 degrees-of-freedom each is controlled. Joint angles of the ROBOKER arms are controlled and tracking performances by the neural chip are compared with those by PD controllers.",https://ieeexplore.ieee.org/document/5221750/,2009 IEEE International Symposium on Industrial Electronics,5-8 July 2009,ieeexplore
10.1109/ICALT.2003.1215101,Kana-input navigation system for kids based on the cyber assistant,IEEE,Conferences,"In Japan, it has increased the opportunity for young children to experience the personal computer in elementary schools. However, in order to use computer, many domestic barriers have confronted young children (kids) because they cannot read Kanji characters and had not learnt Roman alphabet yet. As a result, they cannot input text strings by JIS keyboard. We developed Kana-input navigation system for kids (KINVS) based on the cyber assistant system (CAS). CAS is a human-style software robot based on the 3D-CG real-time animation and voice synthesis technology. KINVS enables to input Hiragana/Katakana characters by mouse operation only (without keyboard) and CAS supports them by using speaking, facial expression, body action and sound effects. KINVS displays the 3D-stage like a classroom. In this room, blackboard, interactive parts to input Kana-characters, and CAS are placed. Mouse input method of KINVS are designed to use only single click and wheeler rotation. To input characters, kids clicks or rotates the interactive parts. KINVS reports all information by voice speaking and Kana subtitles instead of Kanji text. Furthermore, to verify the functional feature of KINVS, we measured how long kids had taken to input long text by using KINVS.",https://ieeexplore.ieee.org/document/1215101/,Proceedings 3rd IEEE International Conference on Advanced Technologies,9-11 July 2003,ieeexplore
10.1109/AIMSEC.2011.6009874,Kinematics simulation of upper limb rehabilitant robot based on virtual reality techniques,IEEE,Conferences,"The wearable exoskeletal robot for upper extremity rehabilitation is taken as the research object. According to D-H method, an accurate three-dimensional mechanism model for the robot system is established by SolidWorks software. The virtual set was generated in Simulink/VRML to carry out dynamic simulation. The variable parameters were set based on robotic practical joint range movement. The simulation of all joints and terminal trajectory and space motion area provided theoretical basis for position control, remote control and trajectory planning, realizing the rehabilitation robot visualizations and system interaction.",https://ieeexplore.ieee.org/document/6009874/,"2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)",8-10 Aug. 2011,ieeexplore
10.1109/ISORCW.2012.36,Knowledge Representation for Cognitive Robotic Systems,IEEE,Conferences,"Cognitive robotics are autonomous systems capable of artificial reasoning. Such systems can be achieved with a logical approach, but still AI struggles to connect the abstract logic with real-world meanings. Knowledge representation and reasoning help to resolve this problem and to establish the vital connection between knowledge, perception, and action of a robot. Cognitive robots must use their knowledge against the perception of their world and generate appropriate actions in that world in compliance with some goals and beliefs. This paper presents an approach to multi-tier knowledge representation for cognitive robots, where ontologies are integrated with rules and Bayesian networks. The approach allows for efficient and comprehensive knowledge structuring and awareness based on logical and statistical reasoning.",https://ieeexplore.ieee.org/document/6196117/,2012 IEEE 15th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops,11-11 April 2012,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/ROBIO.2007.4522258,Layered omnidirectional walking controller for the humanoid soccer robot,IEEE,Conferences,"This paper proposes the layered omnidirectional walking controller for the humanoid soccer robot. The gait of the robot can be parameterized using the destination posititon and the desired direction while reaching the destination. Its implementation in our RoboCup simulation team - SEU-3D is detailed in this paper. Our approach generates smooth robot trajectories without stop before changing direction or turning, and is fast enough to meet the real-time requirements. The proposed approach has been tested in the RoboCup soccer 3D server platform. The results showed that omnidirectional walking has advantages in dynamic environments.",https://ieeexplore.ieee.org/document/4522258/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICTC49870.2020.9289214,Learning Control Policy with Previous Experiences from Robot Simulator,IEEE,Conferences,"Advances in deep reinforcement learning enabled cost-efficient training of control policy of physical robot actions from robot simulators. Learning control policy in a simulated environment is cost-efficient over learning in a real environment. Reward engineering is one of the key components to train efficient control policy. For tasks with long horizons such as navigation and manipulation, a sparse reward is providing limited information. The robot simulator for a physical engine of physical robot manipulation has made it easy for researchers in the field of deep reinforcement learning to simulate complicated robot manipulation environments. In this paper, A robot manipulation simulator and a deep RL framework are utilized for implement a training control policy by utilizing previous experiences. For implementation, Recent innovation Hindsight Experience Replay (HER) algorithms with previous experiences to calculate dense rewards from a sparse reward is leveraged . Proposed implementation showed an approach to investigate the reward engineering method to formulate dense reward in robot manipulator tasks.",https://ieeexplore.ieee.org/document/9289214/,2020 International Conference on Information and Communication Technology Convergence (ICTC),21-23 Oct. 2020,ieeexplore
10.1109/SMC.2019.8914406,Learning Locomotion Skills via Model-based Proximal Meta-Reinforcement Learning,IEEE,Conferences,"Model-based reinforcement learning methods provide a promising direction for a range of automated applications, such as autonomous vehicles and legged robots, due to their sample-efficiency. However, their asymptotic performance is usually inferior compared to the state-of-the-art model-free reinforcement learning methods in locomotion control domains. One main challenge of model-based reinforcement learning is learning a dynamics model that is accurate enough for planning. This paper mitigates this issue by meta-reinforcement learning from an ensemble of dynamics models. A policy learns from dynamics models that hold different beliefs of a real environment. This procedure improves its adaptability and inaccuracy-tolerance ability. A proximal meta-reinforcement learning algorithm is introduced to improve computational efficiency and reduces variance of higher-order gradient estimation. A heteroscedastic noise is added to the training dataset, thus leading to a robust and efficient model learning. Subsequently, proximal meta-reinforcement learning maximizes the expected returns by sampling “imaginary” trajectories from the learned dynamics, which does not require real environment data and can be deployed on many servers in parallel to speed up the whole learning process. The aim of this work is to reduce the sample-complexity and computational cost of reinforcement learning in robot locomotion tasks. Simulation experiments show that the proposed algorithm achieves an asymptotic performance compared with the state-of-the-art model-free reinforcement learning methods with significantly fewer samples, which confirm our theoretical results.",https://ieeexplore.ieee.org/document/8914406/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/IROS45743.2020.9341458,Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments,IEEE,Conferences,"In this paper, we present an approach and an implemented pipeline for transferring data acquired from observing humans in virtual environments onto robots acting in the real world, and adapting the data accordingly to achieve successful task execution. We demonstrate our pipeline by inferring seven different symbolic and subsymbolic motion parameters of mobile pick and place actions, which allows the robot to set a simple breakfast table. We propose an approach to learn general motion parameter models and discuss, which parameters can be learned at which abstraction level.",https://ieeexplore.ieee.org/document/9341458/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA40945.2020.9196785,Learning Resilient Behaviors for Navigation Under Uncertainty,IEEE,Conferences,"Deep reinforcement learning has great potential to acquire complex, adaptive behaviors for autonomous agents automatically. However, the underlying neural network polices have not been widely deployed in real-world applications, especially in these safety-critical tasks (e.g., autonomous driving). One of the reasons is that the learned policy cannot perform flexible and resilient behaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments while avoiding collisions. We present a novel approach for uncertainty-aware navigation by introducing an uncertainty-aware predictor to model the environmental uncertainty, and we propose a novel uncertainty-aware navigation network to learn resilient behaviors in the prior unknown environments. To train the proposed uncertainty-aware network more stably and efficiently, we present the temperature decay training paradigm, which balances exploration and exploitation during the training process. Our experimental evaluation demonstrates that our approach can learn resilient behaviors in diverse environments and generate adaptive trajectories according to environmental uncertainties.",https://ieeexplore.ieee.org/document/9196785/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/IIAI-AAI.2013.74,Learning Which Features to Imitate in a Painting Task,IEEE,Conferences,"Learning is essential for an autonomous agent to adapt to an environment. One method of learning is through trial and error, however, this method is impractical in a complex environment because of the long learning time required by the agent. Therefore, guidelines are necessary in order to expedite the learning process in such environments, and imitation is one such guideline. Sakato, Ozeki, and Oka (2012) recently proposed a computational model of imitation and autonomous behavior by which an agent can reduce its learning time through imitation. In this paper, we apply the model to a real robot, Nao, and evaluate the model using simple features in a simple environment. We also report on the progress of implementation of the model, and evaluations of the performance of imitation using the implemented model. Our experimental results indicate that the model adapted to the experimental environment by imitation.",https://ieeexplore.ieee.org/document/6630378/,2013 Second IIAI International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2013,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2017.8324818,Learning complex assembly skills from kinect based human robot interaction,IEEE,Conferences,"Acquiring complex assembly skills is still a challenging task for robot programming. Because of the sensory and body structure differences, the human knowledge has to be demonstrated, recorded, converted and finally learned by the robot, in an inexplicit and indirect way. During this process, “how to demonstrate”, “how to convert” and “how to learn” are the key problems. In this paper, Kinect sensor is utilized to provide the behavior information of the human demonstrator. Through natural human robot interaction, body skeleton and joint 3D coordinates are provided in real-time, which can fully describe the human intension and task related skills. To overcome the structural and individual differences, a Cartesian level unified mapping method is proposed to convert the human motion and match the specified robot. The recorded data set are modeled using Gaussian mixture model(GMM) and Gaussian mixture regression(GMR), which can extract redundancies across multiple demonstrations and build robust models to regenerate the dynamics of the recorded movements. The proposed methodologies are implemented in the imNEU humanoid robot platform. Experimental results verify the effectiveness.",https://ieeexplore.ieee.org/document/8324818/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICNN.1994.374669,Learning dynamic balance of a biped walking robot,IEEE,Conferences,"This paper discusses the application of CMAC (cerebellar model arithmetic computer) neural networks to the problem of biped walking with dynamic balance. The project goal is to develop biped control strategies based on a hierarchy of simple gait oscillators, PID controllers and neural network learning, but requiring no detailed dynamic models. The focus of this report is on real-time control studies using a ten axis biped robot with joint position, foot force and body acceleration sensors. While efficient walking has not yet been achieved, the experimental biped has learned the closed chain kinematics necessary to shift body weight from side-to-side while maintaining good foot contact and has learned the dynamic balance required in order to lift a foot off the floor for a desired length of time, during which the foot can be moved to a new location relative to the body. Using these skills, the biped is able to link short steps without falling.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/374669/,Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94),28 June-2 July 1994,ieeexplore
10.1109/IS.2018.8710525,Learning from Virtual Experience: Mapless Navigation with Neuro-Fuzzy Intelligence,IEEE,Conferences,"Traditional robot navigation approaches normally rely on creating a precise map of the environment which is a computationally expensive procedure and highly depends on an accurate sensory system. Even for motion planning in similar terrains, the planner needs to prepare or obtain a map beforehand. In this paper, this issue is addressed, and a neurofuzzy motion planner is presented for mobile robot navigation without a map. We show that, by means of a virtual experience model and a neuro-fuzzy system, a mapless motion planning approach can learn basic navigation primitives in simple obstacle arrangements without any prior demonstration. The virtual experience model creates a large number of test environments with a random set of arbitrarily shaped obstacles and places the robot in a random pose with different start and goal positions in different instances. Then, based on the readings of the robot's sensors and a collection of predefined general linguistic rules, a set of control commands including the robot's linear and angular velocity is calculated as the outputs of the virtual experience. The resulting dataset is then loaded into an adaptive neuro-fuzzy inference system to create and optimize a fuzzy motion planner using the subtractive clustering method and a hybrid technique combining the back-propagation algorithm and the least square adaptation method respectively, which guides the robot in simple unknown environments without requiring a global obstacle map. To validate the effectiveness of the proposed model, the motion planner was implemented on a nonholonomic differential drive robot to test its performance in two real navigation tasks. Experimental studies show that the proposed mapless motion planner can efficiently guide the robot in similar arrangements of convex obstacles.",https://ieeexplore.ieee.org/document/8710525/,2018 International Conference on Intelligent Systems (IS),25-27 Sept. 2018,ieeexplore
10.1109/ICSMC.2010.5641727,Learning from conflicts in real world environments for the realization of Cognitive Technical Systems,IEEE,Conferences,"In this contribution, a novel learning method realizing the refinement of a Cognitive Technical System's pattern recognition and attention capabilities is presented. The method is implemented within a cognitive architecture with a representational level based on Situation-Operator-Modeling and high-level Petri Nets. Through the representational level, it is possible to realize a mental model mapping the complex structure of the real world internally in a compact format reduced to the relevant aspects. The mental model can be created and modified automatically by learning from interaction. If the perceived real world does not correspond to the system's mental model, the system detects ambiguities (or conflicts) inevitably. Then, the system tries to solve the conflicts by a more detailed view to the measured sensor inputs. Thus, new significant features (on a high abstraction level) can be derived from the measurements and taken into account to distinguish different (before apparently equal) situations. The contribution describes the proposed method and its fundamentals in detail. Furthermore, the realization of a cognitive mobile robot is presented as an application example illustrating the proposed method.",https://ieeexplore.ieee.org/document/5641727/,"2010 IEEE International Conference on Systems, Man and Cybernetics",10-13 Oct. 2010,ieeexplore
10.1109/IJCNN.1993.716991,Learning goal-directed navigation as attractor dynamics for a sensory motor system. (An experiment by the mobile robot YAMABICO),IEEE,Conferences,"This paper describes experimental results based on the authors' prior-proposed scheme: learning of sensory-based, goal-directed behavior. The scheme was implemented on the mobile robot ""YAMABICO"" and learning of a set of goal-directed navigations were conducted. The experiment assumed that the robot receives no global information such as position nor prior environment model. Instead, the robot was trained to learn adequate maneuvering in the adopted workspace by building a correct mapping between a spatio-temporal sequence of sensory inputs and maneuvering outputs on a neural structure. The experimental results showed that sufficient training generated rigid dynamical structure of a fixed point and limit cycling in the sensory-based state space, which realized robust navigations of homing and cyclic routing even against certain changes of environment as well as miscellaneous noises in the real world.",https://ieeexplore.ieee.org/document/716991/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/ROMAN.2010.5598659,Learning grasp stability based on tactile data and HMMs,IEEE,Conferences,"In this paper, the problem of learning grasp stability in robotic object grasping based on tactile measurements is studied. Although grasp stability modeling and estimation has been studied for a long time, there are few robots today able of demonstrating extensive grasping skills. The main contribution of the work presented here is an investigation of probabilistic modeling for inferring grasp stability based on learning from examples. The main objective is classification of a grasp as stable or unstable before applying further actions on it, e.g. lifting. The problem cannot be solved by visual sensing which is typically used to execute an initial robot hand positioning with respect to the object. The output of the classification system can trigger a regrasping step if an unstable grasp is identified. An off-line learning process is implemented and used for reasoning about grasp stability for a three-fingered robotic hand using Hidden Markov models. To evaluate the proposed method, experiments are performed both in simulation and on a real robot system.",https://ieeexplore.ieee.org/document/5598659/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/ICRA.2012.6224553,Learning organizational principles in human environments,IEEE,Conferences,"In the context of robotic assistants in human everyday environments, pick and place tasks are beginning to be competently solved at the technical level. The question of where to place objects or where to pick them up from, among other higher-level reasoning tasks, is therefore gaining practical relevance. In this work, we consider the problem of identifying the organizational structure within an environment, i.e. the problem of determining organizational principles that would allow a robot to infer where to best place a particular, previously unseen object or where to reasonably search for a particular type of object given past observations about the allocation of objects to locations in the environment. This problem can be reasonably formulated as a classification task. We claim that organizational principles are governed by the notion of similarity and provide an empirical analysis of the importance of various features in datasets describing the organizational structure of kitchens. For the aforementioned classification tasks, we compare standard classification methods, reaching average accuracies of at least 79% in all scenarios. We thereby show that, in particular, ontology-based similarity measures are well-suited as highly discriminative features. We demonstrate the use of learned models of organizational principles in a kitchen environment on a real robot system, where the robot identifies a newly acquired item, determines a suitable location and then stores the item accordingly.",https://ieeexplore.ieee.org/document/6224553/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/CIRA.1997.613838,Learning strategies for sensor-based manipulation tasks,IEEE,Conferences,"An architecture that incorporates a seamless integration of different learning paradigms is presented. Sensor processing, recurrent neural networks, learning from experience and qualitative knowledge are the key elements of the system. The goal applications are those tasks which cannot be fully programmed due to uncertainties and incomplete knowledge. The proposed sensor-based architecture combines several learning paradigms as well as pre-programmed modules, since experimental evidence suggests that some paradigms are more convenient for learning certain skills. The correspondence between qualitative states and actions is learnt. The qualitative treatment of information makes it suitable for the analysis of system behavior, knowledge extraction and generalization to other more complex tasks. Programming is used to decrease the complexity of the learning process. This general approach is a suitable scheme for a wide range of robot situations. Results are provided for the simulation of a sensor-based goal-finding task as well as for a real application of the architecture in a robotic insertion process in three dimensions.",https://ieeexplore.ieee.org/document/613838/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/IIAI-AAI.2014.174,Learning through Imitation and Reinforcement Learning: Toward the Acquisition of Painting Motions,IEEE,Conferences,"Learning is essential for an autonomous agent to adapt to an environment. One method of learning is through trial and error, however, this method is impractical in a complex environment because of the long learning time required by the agent. Therefore, guidelines are necessary in order to expedite the learning process in such environments, and imitation is one such guideline. Sakato, Ozeki, and Oka (2012-2013) recently proposed a computational model of imitation and autonomous behavior by which an agent can reduce its learning time through imitation. They evaluate the model in discrete and continuous spaces, and apply the model to a real robot in order to acquire painting skills. Their experimental results indicate that the model adapted to the experimental environment by imitation. In this paper, we introduce the model and discuss what are needed to improve the model.",https://ieeexplore.ieee.org/document/6913418/,2014 IIAI 3rd International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2014,ieeexplore
10.1109/ICRA.2016.7487506,Learning time series models for pedestrian motion prediction,IEEE,Conferences,"Robot systems deployed in real-world environments often need to interact with other dynamic objects, such as pedestrians, cars, bicycles or other vehicles. In such cases, it is useful to have a good predictive model of the object's motion to factor in when optimizing the robot's own behaviour. In this paper we consider motion models cast in the Predictive Linear Gaussian (PLG) model, and propose two learning approaches for this framework: one based on the method of moments and the other on a least-squares criteria. We evaluate the approaches on several synthetic datasets, and deploy the system on a wheelchair robot, to improve its ability to follow a walking companion.",https://ieeexplore.ieee.org/document/7487506/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS.2018.8594204,Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation,IEEE,Conferences,"Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.",https://ieeexplore.ieee.org/document/8594204/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICCVW.2019.00309,Learning to Navigate Robotic Wheelchairs from Demonstration: Is Training in Simulation Viable?,IEEE,Conferences,"Learning from demonstration (LfD) enables robots to learn complex relationships between their state, perception and actions that are hard to express in an optimization framework. While people intuitively know what they would like to do in a given situation, they often have difficulty representing their decision process precisely enough to enable an implementation. Here, we are interested in robots that carry passengers, such as robotic wheelchairs, where user preferences, comfort and the feeling of safety are important for autonomous navigation. Balancing these requirements is not straightforward. While robots can be trained in an LfD framework in which users drive the robot according to their preferences, performing these demonstrations can be time-consuming, expensive, and possibly dangerous. Inspired by recent efforts for generating synthetic data for training autonomous driving systems, we investigate whether it is possible to train a robot based on simulations to reduce the time requirements, cost and potential risk. A key characteristic of our approach is that the input is not images, but the locations of people and obstacles relative to the robot. We argue that this allows us to transfer the classifier from the simulator to the physical world and to previously unseen environments that do not match the appearance of the training set. Experiments with 14 subjects providing physical and simulated demonstrations validate our claim.",https://ieeexplore.ieee.org/document/9022271/,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),27-28 Oct. 2019,ieeexplore
10.1109/ICSMC.1993.390770,Learning to coordinate behaviors for real-time path planning of autonomous systems,IEEE,Conferences,"We present a neural network (NN) system which learns the appropriate simultaneous activation of primitive behaviors in order to execute more complex robot behaviors. The NN implementation is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviors in a simultaneous or concurrent fashion. We use a supervised learning technique with a human trainer generating appropriate training for the simultaneous activation of behavior in a simulated environment. The NN implementation has been tested within OPMOR, a simulation environment for mobile robots and several results are presented. The performance of the neural network is adequate. Portions of this work has been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/390770/,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,17-20 Oct. 1993,ieeexplore
10.1109/ROBIO.2009.5420526,Learning-based action planning for real-time robot telecontrol with binocular vision in enhanced reality environment,IEEE,Conferences,"Action planning is one of the pivot issues in robot telecontrol, in which the action instructions are often given by the controller from remote site with the help of vision systems. In this paper, we present a learning-based strategy for action planning in robot telecontrol, in which the parameters of sophisticated actions of the remote robot equipped with a binocular vision system could be pre-scheduled with a virtual robot at the control terminal. The remote robot will then be 'taught' with the scheduled action plan with a series of parameter sets obtained form try-outs with the virtual robot and object in the enhanced environment, thus implementing dedicated actions assigned correctly. The action planning process is implemented within a enhanced reality environment, in which both the virtual and the real robot will be displayed simultaneously for the purpose of being deeply immersed. Experiment results demonstrate that the proposed method is capable of promoting the action precision of the remote robot, and effective and valid to designated applications, where action precision plays a critical role.",https://ieeexplore.ieee.org/document/5420526/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.1109/ISCAS.2015.7169038,Live demonstration: Spiking neural circuit based navigation inspired by C. elegans thermotaxis,IEEE,Conferences,"We demonstrate a Spiking Neural Network (SNN) driven autonomous navigation system implemented on a robot. The neural architecture is inspired by those in nematode Caenorhabditis elegans used for thermotaxis, the behavior of tracking thermal isotherms. Our network uses light intensity as the sensor input, instead of temperature in the worm. The network is able to detect the gradations in sensor-input based on local information, and to make decisions in real time. This enables the robot to do a random search and to track specific intensity regions.",https://ieeexplore.ieee.org/document/7169038/,2015 IEEE International Symposium on Circuits and Systems (ISCAS),24-27 May 2015,ieeexplore
10.23919/ChiCC.2018.8483251,Local Gaussian Processes for Identifying Complex Mobile robot System,IEEE,Conferences,"Nonparametric Gaussian processes regression (GPR) is an important tool in machine learning, can be applied in identifying nonlinear models from experimental data, especially, the prediction of mean and variance present the useful advantage. However, when dealing with the large number of training data for the prediction of a complex dynamics system, GPR is not suitable to implement in real-time learning systems. To reduce the computation effort, local learning algorithm is introduced to improve the global Gaussian processes (GP) model in this paper. In this paper, a convenient and effective method for building local model network is proposed and then local GP for weighted regression is performed. The proposed local GPR method is implemented on a simulated example of online identification and prediction fast for a complex dynamic system of wheeled mobile robot.",https://ieeexplore.ieee.org/document/8483251/,2018 37th Chinese Control Conference (CCC),25-27 July 2018,ieeexplore
10.1109/IROS40897.2019.8968004,Long Range Neural Navigation Policies for the Real World,IEEE,Conferences,"Learned Neural Network based policies have shown promising results for robot navigation. However, most of these approaches fall short of being used on a real robot due to the extensive simulated training they require. These simulations lack the visuals and dynamics of the real world, which makes it infeasible to deploy on a real robot. We present a novel Neural Net based policy, NavNet, which allows for easy deployment on a real robot. It consists of two sub policies - a high level policy which can understand real images and perform long range planning expressed in high level commands; a low level policy that can translate the long range plan into low level commands on a specific platform in a safe and robust manner. For every new deployment, the high level policy is trained on an easily obtainable scan of the environment modeling its visuals and layout. We detail the design of such an environment and how one can use it for training a final navigation policy. Further, we demonstrate a learned low-level policy. We deploy the model in a large office building and test it extensively, achieving 0.80 success rate over long navigation runs and outperforming SLAM-based models in the same settings.",https://ieeexplore.ieee.org/document/8968004/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/SOCC.2016.7905478,Low-power real-time intelligent SoCs for smart machines,IEEE,Conferences,"In this paper, we introduce low-power and real-time intelligent SoCs aimed at smart machines. To implement intelligent functions under low-power consumption, machine learning methods are tightly integrated with the traditional algorithms. At first, an object recognition processor (ORP) accelerating scale-invariant feature transform (SIFT) is presented with a visual attention based on convolutional neural network (CNN). For user interface (UI), a speech and gesture recognition processor (SGRP) based on convolutional deep belief network (CDBN) is presented with a voice activity detection (VAD) and a hand segmentation. At last, an artificial intelligence processor (AIP) for autonomous navigation is presented using A* tree search for path planning and reinforcement learning (RL) for dynamic obstacle avoidance. As a result, a prototype robot system integrating the presented SoCs is implemented and successfully demonstrated in the indoor environment.",https://ieeexplore.ieee.org/document/7905478/,2016 29th IEEE International System-on-Chip Conference (SOCC),6-9 Sept. 2016,ieeexplore
10.1109/CVPRW.2019.00020,M2U-Net: Effective and Efficient Retinal Vessel Segmentation for Real-World Applications,IEEE,Conferences,"In this paper, we present a novel neural network architecture for retinal vessel segmentation that improves over the state of the art on two benchmark datasets, is the first to run in real time on high resolution images, and its small memory and processing requirements make it deployable in mobile and embedded systems. The M2U-Net has a new encoder-decoder architecture that is inspired by the U-Net. It adds pretrained components of MobileNetV2 in the encoder part and novel contractive bottleneck blocks in the decoder part that, combined with bilinear upsampling, drastically reduce the parameter count to 0.55M compared to 31.03M in the original U-Net. We have evaluated its performance against a wide body of previously published results on three public datasets. On two of them, the M2U-Net achieves new state-of-the-art performance by a considerable margin. When implemented on a GPU, our method is the first to achieve real-time inference speeds on high-resolution fundus images. We also implemented our proposed network on an ARM-based embedded system where it segments images in between 0.6 and 15 sec, depending on the resolution. Thus, the M2U-Net enables a number of applications of retinal vessel structure extraction, such as early diagnosis of eye diseases, retinal biometric authentication systems, and robot assisted microsurgery.",https://ieeexplore.ieee.org/document/9025339/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),16-17 June 2019,ieeexplore
10.1109/ICRA48506.2021.9561878,MFPN-6D : Real-time One-stage Pose Estimation of Objects on RGB Images,IEEE,Conferences,"6D pose estimation of objects is an important part of robot grasping. The latest research trend on 6D pose estimation is to train a deep neural network to directly predict the 2D projection position of the 3D key points from the image, establish the corresponding relationship, and finally use Pespective-n-Point (PnP) algorithm performs pose estimation. The current challenge of pose estimation is that when the object texture-less, occluded and scene clutter, the detection accuracy will be reduced, and most of the existing algorithm models are large and cannot take the real-time requirements. In this paper, we introduce a Multi-directional Feature Pyramid Network, MFPN, which can efficiently integrate and utilize features. We combined the Cross Stage Partial Network (CSPNet) with MFPN to design a new network for 6D pose estimation, MFPN-6D. At the same time, we propose a new confidence calculation method for object pose estimation, which can fully consider spatial information and plane information. At last, we tested our method on the LINEMOD and Occluded-LINEMOD datasets. The experimental results demonstrate that our algorithm is robust to textureless materials and occlusion, while running more efficiently compared to other methods.",https://ieeexplore.ieee.org/document/9561878/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/WACV.2009.5403083,ML-fusion based multi-model human detection and tracking for robust human-robot interfaces,IEEE,Conferences,"A novel stereo vision system for real-time human detection and tracking on a mobile service robot is presented in this paper. The system integrates the individually enhanced stereo-based human detection, HOG-based human detection, color-based tracking, and motion estimation for the robust detection and tracking of humans with large appearance and scale variations in real-world environments. A new framework of maximum likelihood based multi-model fusion is proposed to fuse these four human detection and tracking models according to the detection-track associations in 3D space, which is robust to the possible missed detections, false detections, and duplicated responses from the individual models. Multi-person tracking is implemented in a sequential near-to-far way, which well alleviates the difficulties caused by human-over-human occlusions. Extensive experimental results demonstrate the robustness of the proposed system under real-world scenarios with large variations in lighting conditions, cluttered backgrounds, human clothes and postures, and complex occlusion situations. Significant improvements in human detection and tracking have been achieved. The system has been deployed on six robot butlers to serve drinks, and showed encouraging performance in open ceremony events.",https://ieeexplore.ieee.org/document/5403083/,2009 Workshop on Applications of Computer Vision (WACV),7-8 Dec. 2009,ieeexplore
10.1109/ComPE49325.2020.9200129,Machine Learning Algorithm based Disease Detection in Tomato with Automated Image Telemetry for Vertical Farming,IEEE,Conferences,"This paper is highlighting an outline of disease detection in tomato using computer vision and machine learning algorithms. Readily available hardware is used to build a system where a camera mounted system can detect and identify spot disease in tomatoes in real-time. As an initial prototype only spot disease can be detected. The complete development can be divided into two parts. The first part is the software and algorithm which aimed to detect and identify disease in crops and generate a report for the user. It is successful in building the algorithm and GUI (graphical user interface) for the user which can detect spot disease in tomatoes. Using the Viola-Jones algorithm and Haar like feature extraction method for the machine learning process in MATLAB, an XML (an image trained file) file for spot disease in tomatoes is designed using 377 images of infected tomatoes. The second part is the hardware implementation which consists of a simple robot rig that carries the camera and the system scans the tomatoes for the disease. For the vast majority of the time, spot detection is accurate. Many other diseases which exist for the animal, human and crops can easily be added to the system. In terms of reliability, the system is a success with acceptable false positives.",https://ieeexplore.ieee.org/document/9200129/,2020 International Conference on Computational Performance Evaluation (ComPE),2-4 July 2020,ieeexplore
10.23919/SPA.2019.8936736,Machine Learning for Embodied Agents: From Signals to Symbols and Actions,IEEE,Conferences,"The aim of this tutorial lecture is to show the role of machine learning and some other AI-related techniques in embodied autonomous agents, and autonomous robots in particular. In this tutorial we bring to the forefront the aspects of robotics that are closely related to computer science. We believe that the progress in algorithms and data processing methods together with the rapid increase in the available computing power were the driving forces behind the successes of modern robotics in the last decade. During this period robots of various classes migrated from university laboratories to commercial companies and then to our everyday life, as now everybody can buy an autonomous vacuum cleaner or lawnmower, while self-driving cars and drones for goods delivery are waiting for proper legal regulations to enter the market. Robotics and Artificial Intelligence already went a long path of mutual inspiration and common development, starting from the symbolic AI (aka Good Old-Fashioned Artificial Intelligence) and its extensive use in early autonomous robots, such as Shakey the robot, created in SRI International by Nils Nilsson, considered one of the ""fathers"" of modern AI. We briefly characterize the range of the most important applications of typical AI methods in modern robotics, including motion planning algorithms [2,3], interpretation of sensory data leading to creation of a world model [4 ,5], and classical learning methods, such as reinforcement learning [6]. However, what made robotics a part of the new wave of AI applications was the recent ""revolution"" of machine learning, mostly grounded in the enormous success of the deep learning paradigm and its many variants that proved to outclass classic methods in a broad range of problems related to the processing of images and other types of signals. The quick adoption of the recent advances in Machine Learning (ML) in robotics seems to be motivated by the fact that ML gives the possibility to infer solutions from data, as opposed to the classic model-based paradigm that was for decades used in robotics. Whereas the modelbased solutions are mathematically elegant and theoretically provable (with respect to stability, convergence, etc.) they often fail once confronted with real-world problems and real sensory data, as their underlying mathematical models are only a very rough approximation of the real world. Therefore, a wider adoption of ML in robotics gives a chance to make robots more robust and adaptive. On the other hand, we should try to use the new techniques without discarding the knowledge and expertise we already have - machine learning methods can benefit a lot from the prior knowledge and the known structure of the problem that has to be solved by learning. This knowledge and structure can be adopted from the model-based methods that a re already well-established in robotics. In the lecture robots are understood in a broad sense, as all embodied agents that have means to physically interact with the environment. They can be either manipulators, mobile robots, aerial vehicles, self-driving cars, and various ""smart"" devices and sensors. In the second part of the lecture attention is paid to specific problems that appear in application of machine learning to embodied agents, such as the need to search a for solution in huge, multi-dimensional spaces (""curse of dimensionality""), and the ever-present problem of representation and incorporation of uncertainty in the processing of real-world data. Some examples of applications of autonomous robots are given, which were successful due to the use of AI - in particular the probabilistic representation of knowledge and machine learning. The most prominent examples are the DARPA competitions: ""Grand Challenge"", ""Urban Challenge"" and ""Robotics Challenge"" (DRC), and the ""Amazon Picking Challenge"", which proves the interest of large corporations in the development of AI-based robotics [7]. In the third part of the lecture new research directions offered by machine learning and the increased availability of training data are discussed. An overview of the most popular application areas of ML in robotics and other autonomous systems is presented along with the typical machine learning paradigms applied in these areas. The focus is on deep learning, mostly using convolutional neural networks to process various sensory data. We discuss three aspects of embodied agents that make machine learning in robotics quite specific with respect to other application areas, such as medical images or natural language processing. The first aspect is dealing with the ""open world"", in which autonomous robots usually operate. This situation breaks the assumptions underlying some popular ML methods, and creates the need to face the problem of unknown classes identification [8] incremental learning [9], and the uncertainty of sensory data [10]. We also stress out that an embodied agent has the ability to actively acquire information [11]. The second aspect is the inference about the scene seen by the agent, where in the case of robotics, semantics and geometry intermingle [12], because the robot has to work in a three-dimensional world, although it often perceives it through twodimensional images [13,14]. The third aspect of our analysis is related to the most important feature of robots that distinguishes them from all other learning agents (software-based). Robots are embodied agents, that is they have a physical ""body"", and are subject to physical constraints, such as the maximum speed of motion or maximum range of perception. Therefore, in ML for robots analysis of the spatio-temporal dependencies in data is very important [15]. Robots support advanced learning methods thanks to the possibility of interaction with the environment - a simple example is active vision with moving camera, a much more complex one is manipulation with active testing of the behavior of objects (repositioning, pushing) [16]. At the end of the lecture, in the context of specific needs and limitations characteristic to the applications of ML in robotics, new concepts of machine learning (e.g. deep reinforcement learning [17], interactive perception [18]) are presented. The lecture is summarized with a brief discussion of the most important challenges and open problems of ML applied to embodied agents.",https://ieeexplore.ieee.org/document/8936736/,"2019 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",18-20 Sept. 2019,ieeexplore
10.1109/ICRA.2019.8793485,Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks,IEEE,Conferences,"Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",https://ieeexplore.ieee.org/document/8793485/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIKE.2018.00051,Management of Subdivided Dynamic Indoor Environments by Autonomous Scanning System,IEEE,Conferences,"With the development of sensing technologies, various spatial applications have been expanding into indoor spaces. For smooth spatial services, grasping indoor space information is most essential task. However, the indoor spaces is not only becoming increasingly complex, but also frequently changed than outdoor spaces. This makes it hard to provide an accurate location based service in an indoor space. This paper propose a way of managing a dynamic indoor environment by defining a multi-layered indoor model in terms of an object mobility. It allows an indoor space to be managed more elaborate and realistic than up-to-date indoor models which only consider an indoor floor plan. We firstly define a classification of indoor objects based on their characteristic to frequently change location, and propose three-layers indoor model followed by the classified objects with its mobility. Secondly, we design and implement an autonomous scanning system to understand changes of indoor situation quickly and automatically. The system is made up of a combination of IoT devices, including a programmable robot, lidar scanner and single-board computer. Finally, we demonstrate an implementation of the system with constructing the proposed model from a real indoor environment.",https://ieeexplore.ieee.org/document/8527483/,2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),26-28 Sept. 2018,ieeexplore
10.1109/MFI-2003.2003.1232635,Map generation based on the interaction between robot body and its surrounding environment,IEEE,Conferences,"This paper presents a method for map generation based on the interaction between a robot body and its surrounding environment. While a robot moves in the environment, the robot interacts with its surrounding environment. If the effect of the environment on the robot changes, such interactions also change. By observing the robot's body, our method detects such change of the interaction and generates a description representing the type of change and the location where such change is observed. In the current implementation, we assume that there are two types of the change in the interaction. The real robot experiments are conducted in order to show the validity of our method.",https://ieeexplore.ieee.org/document/1232635/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/ICMLA51294.2020.00021,MaskedFusion: Mask-based 6D Object Pose Estimation,IEEE,Conferences,"MaskedFusion is a framework to estimate the 6D pose of objects using RGB-D data, with an architecture that leverages multiple sub-tasks in a pipeline to achieve accurate 6D poses. 6D pose estimation is an open challenge due to complex world objects and many possible problems when capturing data from the real world, e.g., occlusions, truncations, and noise in the data. Achieving accurate 6D poses will improve results in other open problems like robot grasping or positioning objects in augmented reality. MaskedFusion improves the state-of-the-art by using object masks to eliminate non-relevant data. With the inclusion of the masks on the neural network that estimates the 6D pose of an object we also have features that represent the object shape. MaskedFusion is a modular pipeline where each sub-task can have different methods that achieve the objective. MaskedFusion achieved 97.3% on average using the ADD metric on the LineMOD dataset and 93.3% using the ADD-S AUC metric on YCB-Video Dataset, which is an improvement, compared to the state-of-the-art methods.",https://ieeexplore.ieee.org/document/9356139/,2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),14-17 Dec. 2020,ieeexplore
10.1109/ICCCI50826.2021.9402304,Maze Solving with humanoid robot NAO using Real-Time object detection,IEEE,Conferences,"In a future that is not too distant from today, humanoids are surely going to be an integral part of both our professional and private lives, assisting us with various tasks. Unlike normal robots that we may encounter in our everyday lives, humanoids are designed in specific manners to give them more human-like capabilities that enable them to perform complex tasks such as climbing a flight of stairs. In this paper, we present a Maze-Solving Algorithm which is a software developed specifically for the humanoid robot, NAO, and gives it the capability to enter and exit a maze autonomously. NAO is a next-gen humanoid bot developed by SoftBank Robotics using the power of AI. The bot is equipped with numerous sensors and cameras. Though various quantitative approaches were considered and experimented with, we stuck onto the one which had the least average time complexity of all after a thorough comparative study. We suggest an approach where the humanoid can detect and localize objects from a distance and take programmable decisions based on them. AI constantly tries to give robots human-thinking capabilities to make their decision-making skills similar to those of humans, if not better than them. This algorithm was developed taking into consideration how a human intellect would react rationally if he is stuck in a maze. The methodology used revolves primarily around the combined use of SONAR(Sound navigation ranging) and tactical sensors, and cameras equipped within the bot. The output values from this hardware were then evaluated to judge the distance from a wall and the reactions from the bot were calculated by the suggested algorithm accordingly.",https://ieeexplore.ieee.org/document/9402304/,2021 International Conference on Computer Communication and Informatics (ICCCI),27-29 Jan. 2021,ieeexplore
10.1109/IEMBS.2008.4650151,Measurement of reaching movement with 6-DOF upper rehabilitation system “Robotherapist”,IEEE,Conferences,"In recent years, the needs for rehabilitation support systems are increasing, which use robot technology and virtual reality technology. Applying these technologies make efficient rehabilitation possible. We have developed 6-degrees-of-freedom (DOF) upper rehabilitation support system to evaluate synergy pattern of stroke survivors and to train stroke survivors, named “Robotherapist”. When stroke survivors who can move plural joints only along a certain constant pattern called synergy pattern do reaching movement, some of them cannot keep their posture of the arm normal, but can move their hand along the aim orbit. In this study, we experiment on a measurement of reaching movement with our system and make a model of movement peculiar to stroke survivors and a model of movement of healthy people. Additionally, we propose application software for reaching training with this model. In this paper, we report measurement of reaching movement and propose application software for reaching training with our system.",https://ieeexplore.ieee.org/document/4650151/,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,20-25 Aug. 2008,ieeexplore
10.1109/LARS.2008.23,MecaTeam Framework: An Infrastructure for the Development of Soccer Agents for Simulated Robots,IEEE,Conferences,"This paper presents the MecaTeam framework, a solution to reduce the effort on developing new soccer teams of robots for the 2D simulation category of the RoboCup. MecaTeam is an object-oriented framework based on features of two robot soccer teams: the MecaTeam 2006 and Uva Trilearn. The architecture of the proposed framework is presented and aspects of its use are discussed. Besides facilitating the development of new teams, the use of the MecaTeam framework may decrease the impact of changes in chunks of related code. Finally, the MecaTeam framework can be used by new researchers interested in simulated robots for soccer games.",https://ieeexplore.ieee.org/document/4812639/,2008 IEEE Latin American Robotic Symposium,29-30 Oct. 2008,ieeexplore
10.1109/SSCI.2016.7850169,Memetic robot control evolution and adaption to reality,IEEE,Conferences,"Inspired by animals' ability to learn and adapt to changes in their environment during life, hybrid evolutionary algorithms have been developed and successfully applied in a number of research areas. This paper explores the effects of learning combined with a genetic algorithm to evolve control system parameters for a four-legged robot. Here, learning corresponds to the application of a local search algorithm on individuals during evolution. Two types of learning were implemented and tested, i.e. Baldwinian and Lamarckian learning. On the direct results from evolution in simulation, Lamarckian learning showed promising results, with a significant increase in final fitness compared with the results from evolution without learning. Further experiments with learning on the real robot demonstrated an efficient adaptation of the robot gait to the real world environment, and increased the performance to the level measured in simulation. This paper demonstrates that Lamarckian evolution is effective in improving the performance of robot controller evolution, and that the same learning process on the physical robot efficiently reduces the negative impact of the simulation-reality gap.",https://ieeexplore.ieee.org/document/7850169/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICRA40945.2020.9196540,Meta Reinforcement Learning for Sim-to-real Domain Adaptation,IEEE,Conferences,"Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.",https://ieeexplore.ieee.org/document/9196540/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICMLC.2010.71,Microcontroller Based Neural Network Controlled Low Cost Autonomous Vehicle,IEEE,Conferences,"In this paper, design of a low cost autonomous vehicle based on neural network for navigation in unknown environments is presented. The vehicle is equipped with four ultrasonic sensors for hurdle distance measurement, a wheel encoder for measuring distance traveled, a compass for heading information, a GPS receiver for goal position information, a GSM modem for changing destination place on run time and a nonvolatile RAM for storing waypoint data; all interfaced to a low cost AT89C52 microcontroller. The microcontroller processes the information acquired from the sensors and generates robot motion commands accordingly through neural network. The neural network running inside the microcontroller is a multilayer feed-forward network with back-propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that upto twenty neurons can be implemented in hidden layer with this technique. The vehicle is tested with varying destination places in outdoor environments containing stationary as well as moving obstacles and is found to reach the set targets successfully.",https://ieeexplore.ieee.org/document/5460762/,2010 Second International Conference on Machine Learning and Computing,9-11 Feb. 2010,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/AIVR50618.2020.00017,Mirrorlabs - creating accessible Digital Twins of robotic production environment with Mixed Reality,IEEE,Conferences,How to visualize recorded production data in Virtual Reality? How to use state of the art Augmented Reality displays that can show robot data? This paper introduces an opensource ICT framework approach for combining Unity-based Mixed Reality applications with robotic production equipment using ROS Industrial. This publication gives details on the implementation and demonstrates the use as a data analysis tool in the context of scientific exchange within the area of Mixed Reality enabled human-robot co-production.,https://ieeexplore.ieee.org/document/9319071/,2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),14-18 Dec. 2020,ieeexplore
10.1109/AIMS.2014.35,Mobile Robot Performance in Robotics Challenges: Analyzing a Simulated Indoor Scenario and Its Translation to Real-World,IEEE,Conferences,"This paper discusses the pros and cons of using 3D simulators for testing the autonomous behavior of mobile robots in indoor environments. Major contribution of the paper is the discussion about which problems that can be faced using the simulator and those that cannot. We present the integration and calibration of a real non-commercial robot in a simulator, the characterization of the errors in sensing, navigation, and manipulation, and how these errors would impact in the real performance of the robot. The experimental support of the claims made in the paper has been developed using the gazebo simulator. RoCKIn competition rulebook defined the indoor restrictions.",https://ieeexplore.ieee.org/document/7102451/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/SISY.2009.5291131,Mobile robot control using self-learning neural network,IEEE,Conferences,"The paper describes the concept of the navigation system for a mobile robot. The system is using a navigation algorithm based on self-learning neural network, necessary to form a movement plan for a robot. The algorithm is adapted and implemented to navigate real platform of a mobile robot equipped by two independent wheel drives, encoders and a set of short-range sonars. Navigation algorithm is placed into a PC, which is connected to mobile robot by wireless and wired links. Experiments have shown ability of collision-free navigation of mobile robot in real time.",https://ieeexplore.ieee.org/document/5291131/,2009 7th International Symposium on Intelligent Systems and Informatics,25-26 Sept. 2009,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ISIC.1998.713694,Mobile robot localization using the Hough transform and neural networks,IEEE,Conferences,"For an autonomous mobile robot to navigate in an unknown environment it is essential to know the location of the robot on a real-time basis. Finding position and orientation of a mobile robot in a world coordinate system is a problem in localization. Dead-reckoning is commonly used for localization, but position and orientation errors from dead-reckoning tend to accumulate over time. The objective of the paper is to develop a feature-based localization method that uses the Hough transform to detect wall-like features in the environment based on sonar range data. Although the Hough transform is an effective method for detecting lines and curves from noisy data it has the drawback of being sensitive to discretization resolution. Results of line detection using various discretization resolutions and using a winner-take-all neural network are presented and discussed. The results indicate that the Hough transform method is able to reliably recognize wall-like features from noisy sonar data, but the accuracy of detected features is dependent heavily on the choice of resolution of parameter discretization.",https://ieeexplore.ieee.org/document/713694/,Proceedings of the 1998 IEEE International Symposium on Intelligent Control (ISIC) held jointly with IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA) Intell,17-17 Sept. 1998,ieeexplore
10.1109/AMC.2006.1631674,Mobile robot navigation in an unknown environment,IEEE,Conferences,"This paper discusses application of an intelligent system in order to navigate in real-time a small size, four wheeled, indoor mobile robot accurately using ultra-light (160 gr), inexpensive laser range finder without prior information of the environment. A recurrent neural network is used to find the best path to the target of the robot. An accurate grid-based map is generated using a laser range finder scene and location found by a modified dead reckoning system. Finally a motion control method is presented. These approaches are implemented and tested in Resquake mobile robot",https://ieeexplore.ieee.org/document/1631674/,"9th IEEE International Workshop on Advanced Motion Control, 2006.",27-29 March 2006,ieeexplore
10.1109/IWRSP.1999.779052,Model based multi-level prototyping,IEEE,Conferences,"In this paper, we present our approach to rapid prototyping of robot software. We propose model based multi-level prototyping using UML in combination with a refinement design flow to synchronize development of an early virtual prototype, detailed simulation models and the final real prototype. This is achieved by a core model which is the common reference for model based multi-level prototyping. We demonstrate our methodology at hand of the design of a motor control software for the RoboCup robot platform of GMD. We show that parameters obtained with the virtual prototype and tested in the simulation model are well suited estimations for the final real prototype and therefore allow to reduce time-consuming experiments with the real prototype to a minimum.",https://ieeexplore.ieee.org/document/779052/,Proceedings Tenth IEEE International Workshop on Rapid System Prototyping. Shortening the Path from Specification to Prototype (Cat. No.PR00246),16-18 June 1999,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/ROBOT.1991.131806,"Model based, sensor directed remediation of underground storage tanks",IEEE,Conferences,"Experimental investigations into the application of intelligent robot control technology to the problem of removing waste stored in tanks are described. The authors discuss the experimental environment employed, with particular attention to the computing and software control environment. Intelligent system control is achieved through the integration of extensive geometric and kinematic world models with real-time sensor-based control. All operator interactions with the system are through fully animated, graphical representations which validate all operator commands before execution to provide for safe operation. Sensing is used to add information to the robot system's world model and to allow sensor-based servo control during selected operations. Initial test results are reported, and the potential for applying advanced intelligent control concepts to the removal of waste in storage tanks is discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131806/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ROBOT.1992.220046,Model-driven pose correction,IEEE,Conferences,"Pose determination for robot navigation is discussed. The problem is to maintain the system's instantaneous precept of its position and orientation in space for performing various tasks. The authors describe a system in which models were used to guide the sensory interpretation and to correct expectations. In this system, simulated images were used to analyze the real images and to correct the pose parameters. The reported techniques have been implemented and experiments with real images in a real environment have been performed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220046/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/MLSP.2015.7324313,Modelling LGMD2 visual neuron system,IEEE,Conferences,"Two Lobula Giant Movement Detectors (LGMDs) have been identified in the lobula region of the locust visual system: LGMD1 and LGMD2. LGMD1 had been successfully used in robot navigation to avoid impending collision. LGMD2 also responds to looming stimuli in depth, and shares most the same properties with LGMD1; however, LGMD2 has its specific collision selective responds when dealing with different visual stimulus. Therefore, in this paper, we propose a novel way to model LGMD2, in order to emulate its predicted bio-functions, moreover, to solve some defects of previous LGMD1 computational models. The mechanism of ON and OFF cells, as well as bio-inspired nonlinear functions, are introduced in our model, to achieve LGMD2's collision selectivity. Our model has been tested by a miniature mobile robot in real time. The results suggested this model has an ideal performance in both software and hardware for collision recognition.",https://ieeexplore.ieee.org/document/7324313/,2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP),17-20 Sept. 2015,ieeexplore
10.1109/SECON.2014.6950737,Modified reinforcement learning for sequential action behaviors and its application to robotics,IEEE,Conferences,"When developing a robot or other automaton, the efficacy of the agent is highly dependent on the performance of the behaviors which underpin the control system. Especially in the case of agents which must act in real world or disorganized environments, the design of robust behaviors can be both difficult and time consuming, and often requires the use of sensitive tuning. In response to this need, we present a behavioral, goal-oriented, reinforcement-based machine learning strategy which is flexible, simple to implement, and designed for application in real-world environments, but with the capability of software-based training. In this paper, we will explain our design paradigms, the formal implementation thereof, and the algorithm proper. We will show that the algorithm is able to emulate standard reinforcement learning within comparable training time, and to extend the capabilities thereof as well. We also demonstrate extension of learning beyond the scope of training examples, and present an example of a physical robot which learns a sequential action behavior by experimentation.",https://ieeexplore.ieee.org/document/6950737/,IEEE SOUTHEASTCON 2014,13-16 March 2014,ieeexplore
10.1109/ROMAN.2005.1513775,Modularity and integration in the design of a socially interactive robot,IEEE,Conferences,"Designing robots that are capable of interacting with humans in real life settings is a challenging task. One key issue is the integration of multiple modalities (e.g., mobility, physical structure, navigation, vision, audition, dialogue, reasoning) into a coherent framework. Taking the AAAI mobile robot challenge (making a robot attend the national conference on artificial intelligence) as the experimental context, we are currently addressing hardware, software and computation integration issues involved in designing a robot capable of sophisticated interaction with humans. This paper reports on our design solutions and the current status of the work, along with the potential impacts this design on human-robot interaction research.",https://ieeexplore.ieee.org/document/1513775/,"ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",13-15 Aug. 2005,ieeexplore
10.1109/iCMLDE.2018.00023,Monocular SLAM and Obstacle Removal for Indoor Navigation,IEEE,Conferences,"Visual Simultaneous Localization and Mapping (SLAM) is one of the hot topics in computer vision. For the past few years, the AI and deep learning technology research have been widespread used in self-driving technology and surveillance system etc., gaining more and more attention from researchers and public media. The combination of AI technology and robot perception is inevitably going to be a trend. This paper aims at removing the obstacle to enhance the SLAM system performance that based on popular open source framework ORB-SLAM2 in dynamic environment. Moving objects will bring noise in camera pose estimation, besides, when in re-localization, the robot returns to the previous place finding the previous landmark mismatches because of its movement. The system will be confused and misdirected. A novel approach is proposed to remove the obstacle in real environment by using convolutional neural network (CNN) to generate a segmentation mask of obstacle object so as to eliminate the interference by moving object. Our experiment result shows an impressive outcome of practical use and benchmark dataset test.",https://ieeexplore.ieee.org/document/8614006/,2018 International Conference on Machine Learning and Data Engineering (iCMLDE),3-7 Dec. 2018,ieeexplore
10.1109/CBS46900.2019.9114416,"Motion Prediction of Virtual Patterns, Human Hand Motions, and a simplified Hand Manipulation Task with Hierarchical Temporal Memory",IEEE,Conferences,"In this paper we utilize Numenta's Hierarchical Temporal Memory implementation NuPIC for online visual motion pattern prediction and test its performance on virtual animations as well as real world human motion data. For evaluation we run a series of progressively more complex experiments testing specific capabilities: Prediction of fixed-time noise-free motion animations, prediction of protocol-directed tasks with real-world camera captured human motion data, and lastly prediction of repetitive tasks performed without a strict protocol. Results show that the presented setup is able to predict time sequenced images as well as highly variable human motions increasingly well over several iterations. Limits are faced for non sequential variable hand motion execution: Here, predictions are made but do not improve in quality over time. The network runs online in real time and can be transferred to different tasks without expert knowledge. These characteristics qualify the setup for human robot interaction scenarios without the need for verified prediction accuracy.",https://ieeexplore.ieee.org/document/9114416/,2019 IEEE International Conference on Cyborg and Bionic Systems (CBS),18-20 Sept. 2019,ieeexplore
10.1109/ROMAN.2009.5326151,"Motion capture and classification for real-time interaction with a bipedal robot using on-body, fully wireless, motion capture specknets",IEEE,Conferences,"This paper presents, to the best of our knowledge, the first instance of real-time human-robot interaction using motion capture (mocap) data obtained from fully wireless, on-body sensor networks. During the learning phase, data for motion such as waving of the hands, standing on a leg, performing sit-ups and squats is captured from a human strapped with the orient motion capture specks. Key features are extracted from the captured motion data using unsupervised learning algorithms. During subsequent interactions with the robot, the motion of the operator, speckled with orients, is classified and the robot selects to play the closest motion. This approach is particularly useful in situations where the robot operates a well defined vocabulary of motion, and the advantages are the real-time interaction and the rapidity (in a matter of minutes) in programming new behaviour compared to a heuristics-based approach. This paper compares the performances of three unsupervised learning algorithms: c-means, k-means and expectation maximisation (EM) for the four motion scenarios. Nine best candidates for the three learning algorithms for each of the four motion scenarios were selected in the Webots robot simulator and then transferred to the real robot. Metrics were defined for each motion scenario and their performances compared for the three learning algorithms. In all the cases the motions were able to be imitated; c-means was the best, followed closely by the k-means algorithms, and the reasons have been analysed.",https://ieeexplore.ieee.org/document/5326151/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/ROBOT.1990.125999,Motion planning for a whole-sensitive robot arm manipulator,IEEE,Conferences,"A sensor-based motion planning system for a robot arm manipulator must include these four basic components: sensor hardware; real-time signal/sensory data processing hardware/software a local step planning subsystem that works at the basic sample rate of the arm; and a subsystem for global planning. The objective of this work is to develop the fourth component, a real-time implementable algorithm that realizes the upper, global level of planning. Based on the current collection of local normals, the algorithm generates preferable directions of motion around obstacles, in order to guarantee reaching the target position if it is reachable. Experimental results from testing the developed system are also discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/125999/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/CIMSA.2009.5069917,Motion planning in unknown environment using an interval fuzzy type-2 and neural network classifier,IEEE,Conferences,"This paper describes environmental recognition and motion control using weightless neural network classifier and interval type-2 fuzzy logic controller. The weightless neural network classifies geometric feature such as U-shape, corridor and left or right corner using ultrasonic sensors. The neural network utilizes previous sensor data and analyzes the situation of the current environment. The behavior of mobile robot is implemented by means of fuzzy control rules. Based on the performance criteria the quality of controller is evaluated to make navigation decisions. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show that the mobile robot can recognize the current environment and was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/5069917/,2009 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications,11-13 May 2009,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/FUZZ.2002.1005041,Multi-axis fuzzy control and performance analysis for an industrial robot,IEEE,Conferences,"Robot control systems can be considered as complex systems, the design of the controller involving the determination of the dynamic model for the system. Fuzzy logic provides functional capability without the use of a system model or the characteristics associated with capturing the approximate, varying values found in real world systems. Development of a multi-axis fuzzy logic control system was implemented on an industrial robot, replacing the existing control and hardware systems with a new developmental system. During robot control no adaptation of the rule base or membership functions was carried out online; only system gain was modified in relation to link speed and joint error within predetermined design parameters. The fuzzy control system had to manage the effects of frictional and gravitational forces whilst compensating for the varying inertia components when each linkage is moving. Testing based on ISO 9283 for path accuracy and repeatability verified that real time control of three axes was achievable with values of 938 /spl mu/m and 864 /spl mu/m recorded for accuracy and repeatability, respectively.",https://ieeexplore.ieee.org/document/1005041/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/IROS.2001.977153,Multi-robot path planning for dynamic environments: a case study,IEEE,Conferences,"Most multi-robot navigation planning methods make assumptions about the kind of navigation problems they are to solve and the capabilities of the robots they are to control. In this paper, we propose to select problem-adequate navigation planning methods based on empirical investigations, that is, the robots should learn by experimentation to use the best planning methods. To support this development strategy we provide software tools that enable the robots to automatically learn predictive models for the performance of different navigation planning methods in a given application domain. We show, in the context of robot soccer, that the hybrid planning method which selects planning methods based on a learned predictive model outperforms the individual planning methods. The results are validated in extensive experiments using a realistic and accurate robot simulator that has learned the dynamic model of the real robots.",https://ieeexplore.ieee.org/document/977153/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/FUZZY.1997.616431,Multilayered fuzzy behavior fusion for reactive control of an autonomous mobile robot,IEEE,Conferences,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, however, may benefit from qualitative rules as well if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine. A control function is broken down into multiple agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. Using this system, a fuzzy behavior-based reactive control system has been implemented on an autonomous mobile robot MARGE, with great success.",https://ieeexplore.ieee.org/document/616431/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/ISKE.2010.5680764,Multilevel fuzzy navigation control scheme applied to a monitoring mobile robot,IEEE,Conferences,"The design, construction and real time performance of a mobile monitoring system based on a Khepera mobile robot are presented. The functions performed by the system are: (a) line following, (b) obstacle avoidance, (c) identification of test points along the path, (d) recognition of the mark (bar code) located at each test point and, (e) measuring of a physical parameter. For the navigation, an innovative multilevel fuzzy control scheme is implemented in which the fuzzy sensor fusion, related to the perception of the environment, reduces the complexity of the navigation function. Other distinctive characteristics are the identification of test points by means of a Kohonen's neural network and the processing of a one-dimensional video signal for recognition of landmarks located at each test point.",https://ieeexplore.ieee.org/document/5680764/,2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering,15-16 Nov. 2010,ieeexplore
10.1109/ROMAN.1995.531939,Multimedia sensing system for robot,IEEE,Conferences,"The purpose of this study is to realize a multimedia sensing system for robot. Using both image and sound processing, the system makes a robot track the person who is speaking. The sound direction is calculated from the phase difference between the sounds arriving at the right and left microphones (ears) of the robot. Then by detecting the synchronization between the sound and image changes, the system identifies the speaker. Furthermore, by introducing a multi-level synchronization checking and context analysis, the action pattern of the robot can be regulated to make the robot perform in a complicated environment with plural speakers. All the processes are performed in real-time. The proposed system is implemented in the information assistant robot ""Hadaly"".",https://ieeexplore.ieee.org/document/531939/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/MILTECHS.2017.7988861,Multiple people detection and identification system integrated with a dynamic simultaneous localization and mapping system for an autonomous mobile robotic platform,IEEE,Conferences,"This paper presents the integration of a multiple people detection and identification system with a dynamic simultaneous localization and mapping system for an autonomous robotic platform. This integration allows the exploration and navigation of the robot considering people identification. The robotic platform consists of a Pioneer 3DX robot equipped with an RGBD camera, a Sick Lms200 sensor laser and a computer using the robot operating system (ROS). The idea is to integrate the people detection and identification system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. The people detection and identification system is performed in two steps. The first one is for detecting multiple people on scene and the other one is for an individual person identification. Both steps are implemented as ROS nodes that works integrated with the SLAM ROS node. The multiple people detection's node uses a manual feature extraction technique based on HOG (Histogram of Oriented Gradients) detectors, implemented using the PCL library (Point Cloud Library) in C ++. The person's identification node is based on a Deep Convolutional Neural Network (CNN) that are implemented using the MatLab MatConvNet library. This step receives the detected people centroid from the previous step and performs the classification of a specific person. After that, the desired person centroid is send to the SLAM node, that consider it during the mapping process. Tests were made objecting the evaluation of accurateness in the people's detection and identification process. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.",https://ieeexplore.ieee.org/document/7988861/,2017 International Conference on Military Technologies (ICMT),31 May-2 June 2017,ieeexplore
10.1109/CEC.2007.4424774,Multiple sensors data integration using MFAM for mobile robot navigation,IEEE,Conferences,"The mobile robot navigation with complex environment needs more input space to match the environmental data into robot outputs in order to perform realistic task. At the same time, the number of rules at the rule base needs to be optimized to reduce the computing time and to provide the possibilities for real time operation. In this paper, the optimization of fuzzy rules using a modified fuzzy associative memory (MFAM) is designed and implemented. MFAM provides good flexibility to use multiple input space and reduction of rule base for robot navigation. This paper presents the MFAM model to generate the rule base for robot navigation. The behavior rules obtained from MFAM model are tested using simulation and real world experiments, and the results are discussed in the paper and compared with the existing methods.",https://ieeexplore.ieee.org/document/4424774/,2007 IEEE Congress on Evolutionary Computation,25-28 Sept. 2007,ieeexplore
10.1109/IROS45743.2020.9341372,Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer,IEEE,Conferences,"Learning-based approaches often outperform hand-coded algorithmic solutions for many problems in robotics. However, learning long-horizon tasks on real robot hardware can be intractable, and transferring a learned policy from simulation to reality is still extremely challenging. We present a novel approach to model-free reinforcement learning that can leverage existing sub-optimal solutions as an algorithmic prior during training and deployment. During training, our gated fusion approach enables the prior to guide the initial stages of exploration, increasing sample-efficiency and enabling learning from sparse long-horizon reward signals. Importantly, the policy can learn to improve beyond the performance of the sub-optimal prior since the prior's influence is annealed gradually. During deployment, the policy's uncertainty provides a reliable strategy for transferring a simulation-trained policy to the real world by falling back to the prior controller in uncertain states. We show the efficacy of our Multiplicative Controller Fusion approach on the task of robot navigation and demonstrate safe transfer from simulation to the real world without any fine-tuning. The code for this project is made publicly available at https://sites.google.com/view/mcf-nav/home.",https://ieeexplore.ieee.org/document/9341372/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICMLC.2016.7872960,Muscle-gesture robot hand control based on sEMG signals with wavelet transform features and neural network classifier,IEEE,Conferences,"In this paper, we propose a muscle gesture-computer interface (MGCI) system for a five-fingered robotic hand control employing a commercial wearable MYO gesture armband. Eight channels of surface EMG (sEMG) signals were acquired and segmented. Then four levels of Daubechies 5 Wavelet family were performed to analyze the EMG signal. Totally 72 features were extracted from the EMG raw data for 16 hand motions recognition utilizing artificial Neural Networks. The average of best overall classification rate during off-line training is 87.8%. Consequently, real-time hand gesture recognition was implemented to evaluate the performance of the proposed system and the average recognition accuracy was 89.38%. Finally, it was applied to control a five-fingered robot hand.",https://ieeexplore.ieee.org/document/7872960/,2016 International Conference on Machine Learning and Cybernetics (ICMLC),10-13 July 2016,ieeexplore
10.1109/IECON.2000.972604,NN controller of the constrained robot under unknown constraint,IEEE,Conferences,"In this paper, the problems faced in the constrained force control is studied (uncertainties in dynamic model and the unknown constraints). A neural network (NN) controller is proposed based on the derived dynamic model of robot in the task space. The feed-forward neural network is used to adaptively compensate for the uncertainties in the robot dynamics. Training signals are proposed for the feed-forward neural network controller. The NN weights are tuned online, with no off-line learning phase required. An online estimation algorithm is developed to estimate the local shape of the constraint surface by using measured data on the force and position of the end-effector. The suggested controller is simple in structure and can be implemented easily. Real-time experiments are conducted using the five-bar robot to demonstrate the effectiveness of the proposed controller.",https://ieeexplore.ieee.org/document/972604/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/ICMA52036.2021.9512587,Natural Residual Reinforcement Learning for Bicycle Robot Control,IEEE,Conferences,"This work focuses on motion control of the bicycle robot by using the proposed NRRL algorithm. Unlike the traditional RL algorithm, decomposing the main tasks into subtasks manually and introducing qualitative prior knowledge to the agent have been applied in the NRRL algorithm. Simulation results show that better performance and better sample efficiency of the proposed NRRL algorithm have been achieved in terms of balance control and path tracking of bicycle robot. It's believed that the NRRL algorithm is available on the real physical bicycle robot, and the deployment of the algorithm will be realized soon, as the real physical bicycle robot has been constructed currently.",https://ieeexplore.ieee.org/document/9512587/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/CIMCA.2008.133,Neural Dynamic Control of a Nonholonomic Mobile Robot Incorporating the Actuator Dynamics,IEEE,Conferences,"In this paper, a trajectory tracking control for a nonholonomic mobile robot by the integration of a kinematic controller and neural dynamic controller is investigated, where the wheel actuator (e.g., dc motor) dynamics is integrated with mobile robot dynamics and kinematics so that the actuator input voltages are the control inputs. The proposed neural dynamic controller (PNDC), based on the sliding mode theory, is applied to compensate the mobile robot dynamics, bounded unknown disturbances, and influence of payload. This controller is obtained by modeling the Radial Basis Functions Neural Networks (RBFNNs) of the centripetal and Coriolis matrix through of the inertia matrix of the mobile robot dynamics. Thus, PNDC is constituted of static RBFNNs only, what makes possible the reduction of the size of the RBFNNs, of the computational load and the implementation in real time. Stability analysis and numerical simulations are provided to show the effectiveness of the PNDC.",https://ieeexplore.ieee.org/document/5172687/,2008 International Conference on Computational Intelligence for Modelling Control & Automation,10-12 Dec. 2008,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/IROS.1991.174585,Neural network approach to path planning for two dimensional robot motion,IEEE,Conferences,"A method for robot obstacle avoidance and path planning is proposed. The algorithm is based on a camera image feedback loop utilizing a neural network for image processing. The method can successfully generate collision-free paths in a 2D robot workspace containing randomly-placed polygonal obstacles. The control algorithm is simple and robust and has low computational requirements. Controller simulation implemented on a personal computer can generate collision-free robot paths in real time, requiring approximately 1 sec. per robot move.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174585/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ICIT.2004.1490796,Neural network based control of a four rotor helicopter,IEEE,Conferences,"In this paper the design and development of an intelligent controller based on neural networks for a hoverable flying robot to be capable of achieving vertical take off and landing and to be able to sustain a specified attitude is presented. The ability to be able to autonomously navigate through a predefined path was designated for a future phase. This work is different from most autonomous flying robots as it focuses on a four-propeller configuration. This is a very rare helicopter design because of its inherent instability and it is believed that an autonomous robot of this configuration has not yet been successfully developed. In addition, this project uses fixed pitch propellers instead of variable pitch rotors resulting in a greatly reduced cost and mechanical complexity. The downside is that this introduces significant additional challenges in the control. Relative stability was achieved in three axis and all the supporting modules were successfully designed and implemented. However, significant challenges were encountered including the complexities of creating a neural networks controller (NNC) to work in real-time in a slow microcontroller as well as to develop the training process.",https://ieeexplore.ieee.org/document/1490796/,"2004 IEEE International Conference on Industrial Technology, 2004. IEEE ICIT '04.",8-10 Dec. 2004,ieeexplore
10.1109/ROBOT.1995.525344,Neural network based iterative learning controller for robot manipulators,IEEE,Conferences,"An efficient neural network based learning control scheme is proposed to solve the trajectory tracking controI problem of robot manipulators. The proposed approach has four distinctive characteristics: 1) good tracking performance can be achieved during the first learning trial; 2) learning algorithm for adjusting neural network weights is independent of the manipulator dynamic model, thus displays strong robustness to torque disturbances and model parameter uncertainty; 3) no acceleration measurement or estimation is needed; and 4) real-time implementation with a higher sampling rate is readily possible. Simulation results on a 3 degree-of-freedom manipulator are presented to show its validity.",https://ieeexplore.ieee.org/document/525344/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/IJCNN.2001.938487,Neuro-controller for high performance induction motor drives in robots,IEEE,Conferences,"Presents an approach to the speed control of an induction motor (IM) as a robust high performance drive (HPD) using an online self-tuning adapted artificial neural network (ANN). Based on motor dynamics and nonlinear unknown load characteristics such as robot systems, a neuro speed controller is developed. The proposed controller is very simple and serves as an identifier and a controller at the same time. The combination of the adaptive learning rate with the epochs used through the online training offers a unique feature of system identification and adaptive control. The performance of the controller was evaluated under various operating conditions to track different speed trajectories. The results validate the efficacy of the ANN for the precise tracking control of IM. Furthermore the use of the ANN makes the drive system robust, accurate, and insensitive to parameter variations. Also the drive system is implemented in real-time using a digital signal processor (DSP) TMS320C31.",https://ieeexplore.ieee.org/document/938487/,IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222),15-19 July 2001,ieeexplore
10.1109/IJCNN.1998.687181,Neuro-fuzzy posture estimation for visual vehicle guidance,IEEE,Conferences,"This paper presents a neuro-fuzzy approach to visual guidance of a mobile robot vehicle in local manoeuvres. It is based on the transfer of the skills of an experienced driver to an automatic controller. The resulting controller processes video sensor data to generate corresponding steering and velocity commands in real time. Neither a geometric environment model nor analytic models of the video sensor or the vehicle kinematics are required. In contrast to previous work of the authors, the controller commands are generated by a two-stage processing structure. A first stage estimates the vehicle posture relative to the desired goal based on the video images. A guidance controller uses the estimated posture to calculate appropriate commands in a second stage. The approach is exemplified and validated by the design and implementation of a visual parking controller for the experimental robot vehicle MACROBE.",https://ieeexplore.ieee.org/document/687181/,1998 IEEE International Joint Conference on Neural Networks Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36227),4-9 May 1998,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1109/HUMANOIDS.2018.8625038,NimbRo-OP2X: Adult-Sized Open-Source 3D Printed Humanoid Robot,IEEE,Conferences,"Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already open-source software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreál, Canada, where it won all possible awards in the Humanoid AdultSize class.",https://ieeexplore.ieee.org/document/8625038/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/IROS.2003.1250614,Non-learning artificial neural network approach to motion planning for the Pioneer robot,IEEE,Conferences,This paper describes the implementation of a biologically-inspired non-learning artificial neural network for robot motion planning on the Pioneer 2DX robot. This motion planner fits within the Saphira operating system. The deliberative ANN motion planner is able to respond to changing situations in real time and complements the reactive behaviours.,https://ieeexplore.ieee.org/document/1250614/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/IJCNN.1999.832713,Nonlinear system adaptive trajectory tracking by dynamic neural control,IEEE,Conferences,"In this article, new nonlinear control techniques based on dynamic neural networks are presented. The authors discuss the implementation of a modified identification algorithm using dynamic neural networks as well as a control law, based on the neural identifier, which eliminates modeling error effects via sliding mode techniques. Simulation and real time results are presented for systems like an inverted pendulum and a full actuated robot manipulator.",https://ieeexplore.ieee.org/document/832713/,IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339),10-16 July 1999,ieeexplore
10.1109/ISMVL.2015.39,Novel VLSI Architectures for Real-World Intelligent Systems,IEEE,Conferences,"A real-world intelligent systems platform based on novel architectures is presented in this article. As real-world applications, we consider advanced intelligent systems such as a highly-safe system and an intelligent robot system which make our daily life safe and comfortable.",https://ieeexplore.ieee.org/document/7238146/,2015 IEEE International Symposium on Multiple-Valued Logic,18-20 May 2015,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/CISCT.2019.8777441,Object Recognition for Dental Instruments Using SSD-MobileNet,IEEE,Conferences,"In recent technological developments, robot-assisted surgery has become popular due to its tremendous prospects in enhancing the capabilities of surgeons performing open surgery, yet very little effort has been made to make these tools available to dental surgeons. This paper addresses the problem of identifying the problem of real-time object recognition of dental instruments by utilizing deep learning techniques. For this reason, the Single Shot MultiBox Detector (SSD) network was considered as the meta structure and joined with the base Convolutional Neural Network (CNN) MobileNet to shape SSD-MobileNet. The task of object recognition for dental instruments like spatula, elevator, mouth mirror etc is performed, in order to constitute a robotic arm; that works with voice commands using speech recognition, and assists the dentist in surgery. Our method can recognize instruments more precisely and quickly as contrast with other lightweight system strategies and conventional machine learning techniques. We have achieved the precision and accuracy of 87.3% and 98.8% respectively.",https://ieeexplore.ieee.org/document/8777441/,2019 International Conference on Information Science and Communication Technology (ICISCT),9-10 March 2019,ieeexplore
10.1109/ICRA.2016.7487351,Object discovery and grasp detection with a shared convolutional neural network,IEEE,Conferences,"Grasp an object from a stack of objects in real-time is still a challenge in robotics. This requires the robot to have the ability of both fast object discovery and grasp detection: a target object should be picked out from the stack first and then a proper grasp configuration is applied to grasp the object. In this paper, we propose a shared convolutional neural network (CNN) which can simultaneously implement these two tasks in real-time. The processing speed of the model is about 100 frames per second on a GPU which largely satisfies the requirement. Meanwhile, we also establish a labeled RGBD dataset which contains scenes of stacked objects for robotic grasping. At last, we demonstrate the implementation of our shared CNN model on a real robotic platform and show that the robot can accurately discover a target object from the stack and successfully grasp it.",https://ieeexplore.ieee.org/document/7487351/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/ROBIO.2009.4913200,Object orientation recognition based on SIFT and SVM by using stereo camera,IEEE,Conferences,"The goal of this research is to recognize an object and its orientation in space by using stereo camera. The principle of object orientation recognition in this paper was based on the scale invariant feature transform (SIFT) and support vector machine (SVM). SIFT has been successfully implemented on object recognition but it had a problem recognizing the object orientation. For many autonomous robotics applications, such as using a vision-guided industrial robot to grab a product, not only correct object recognition will be needed in this process but also object orientation recognition is required. In this paper we used SVM to recognize object orientation. SVM has been known as a promising method for classification accuracy and its generalization ability. The stereo camera system adopted in this research provided more useful information compared to single camera one. The object orientation recognition technique was implemented on an industrial robot in a real application. The proposed camera system and recognition algorithms were used to recognize a specific object and its orientation and then guide the industrial robot to perform some alignment operations on the object.",https://ieeexplore.ieee.org/document/4913200/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/IECON.2006.347441,Obstacle avoidance algorithm based on biological patterns for anthropomorphic robot manipulator,IEEE,Conferences,"This study addresses the problem of collision-free controlling of 3-DOF (degree of freedom) anthropomorphic manipulators with given a priori unrestricted trajectory. The robot constraints resulting from the physical robot's actuators are also taken into account during the robot movement. Obstacle avoidance algorithm is based on penalty function, which is minimized when collision is predicted. Mathematical construction of penalty function and minimization process allows modeling of variety behaviors of robot elusion moves. Implementation of artificial neural network (ANN) inside the control process gives the additional flexibility needed to remember most important robot behaviors based on biological pattern of human arm moves. Thanks to the fast collisions' detection, the presented algorithm appears to be applicable to the industrial real-time implementations. Numerical simulations of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented",https://ieeexplore.ieee.org/document/4152937/,IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,6-10 Nov. 2006,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ROBOT.2004.1307138,Obstacle avoidance through incremental learning with attention selection,IEEE,Conferences,"This work presents a learning-based approach to the task of generating local reactive obstacle avoidance. The learning is performed online in real-time by a mobile robot. The robot operated in an unknown bounded 2-D environment populated by static or moving obstacles (with slow speeds) of arbitrary shape. The sensory perception was based on a laser range finder. To greatly reduce the number of training samples needed, an attentional mechanism was used. An efficient, real-time implementation of the approach had been tested, demonstrating smooth obstacle-avoidance behaviors in a corridor with a crowd of moving students as well as static obstacles.",https://ieeexplore.ieee.org/document/1307138/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/ICRA48506.2021.9561790,Occupancy Map Inpainting for Online Robot Navigation,IEEE,Conferences,"In this work, we focus on mobile robot navigation in indoor environments where occlusions and field-of-view limitations hinder onboard sensing capabilities. We show that the footprint of a camera mounted on a robot can be drastically improved using learning-based approaches. Specifically, we consider the task of building an occupancy map for autonomous navigation of a robot equipped with a depth camera. In our approach, a local occupancy map is first computed using measurements from the camera directly. Afterwards, an inpainting network adds further information, the occupancy probabilities of unseen grid cells, to the map. A novel aspect of our approach is that rather than direct supervision from ground truth, we combine the information from a second camera with a better field-of-view for supervision. The training focuses on predicting extensions of the sensed data. To test the effectiveness of our approach, we use a robot setup with a single camera placed at 0.5m above the ground. We compare the navigation performance using raw maps from only this camera’s input (baseline) versus using inpainted maps augmented with our network. Our method outperforms the baseline approach even in completely new environments not included in the training set and can yield 21% shorter paths than the baseline approach. A real-time implementation of our method on a mobile robot is also tested in home and office environments.",https://ieeexplore.ieee.org/document/9561790/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2013.6630740,Off-line path integral reinforcement learning using stochastic robot dynamics approximated by sparse pseudo-input Gaussian processes: Application to humanoid robot motor learning in the real environment,IEEE,Conferences,"We develop fast reinforcement learning (RL) framework using the approximated dynamics of a humanoid robot. Although RL is a useful non-linear optimizer, applying it to real robotic systems is usually difficult due to the large number of iterations required to acquire suitable policies. In this study, we approximate the dynamics using data from a real robot with sparse pseudo-input Gaussian processes (SPGPs). By using SPGPs, we estimated the probability distribution considering both the input vector and output signal variances. In real environments, since the observations from robotic sensors include large noise, SPGPs can suitably approximate the stochastic dynamics of a real humanoid robot. We use the approximated dynamics to improve the performance of a movement task in a path integral RL framework, which updates a policy from the sampled trajectories of the state and action vectors and the cost. We implemented our proposed method on a real humanoid robot and tested on a via-point reaching task. The robot achieved successful performance with fewer number of interactions with the real environment by using the proposed method than a conventional approach which dose not use the simulated dynamics.",https://ieeexplore.ieee.org/document/6630740/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/ICAS.2006.40,On the conception of an autonomous and modular robot based on an Event Driven OSEK System with deterministic real-time behavior,IEEE,Conferences,"In this paper, we are interested in the design of an autonomous and modular self-reconfigurable robot having self-assembly capability and deterministic behavior. The ability of a modular robot to meet its mission strongly depends on the artificial intelligence software and on the underlying hardware and software architecture. The artificial intelligence software of a robot is mapped into several elementary tasks with different real-time constraints. We propose in this paper a real-time analysis taking into account kernel overheads for the validation of the real-time behavior of an artificial intelligence software. We study the OSEK operating system that requires few hardware resources and is cost effective. The overheads are due to the context switching mechanism which activates, terminates, and reschedules tasks, and to the periodic timer used to create the time base which is necessary for the periodic tasks model. We show how to take into account those overheads in the feasibility conditions. We compare the theoretical worst case response time obtained with kernel overheads to the response time obtained on a task set, on a real robot, based on the event driven OSEK implementation. We show that the kernel overheads cannot be neglected and that the theoretical results are valid and can be used to ensure a deterministic behavior of the robot",https://ieeexplore.ieee.org/document/1690225/,International Conference on Autonomic and Autonomous Systems (ICAS'06),19-21 July 2006,ieeexplore
10.1109/MWSCAS.1991.251981,On the fast robot dynamic parameters learning,IEEE,Conferences,"A computationally efficient solution to the problem of identifying the dynamic parameters of a robot manipulator is presented. The identification procedure is based on a simplified form of the dynamics. The approach has three important characteristics. First, being based on the Lagrangian representation, the equations are linear in the dynamic parameters, which makes possible the application of linear identification techniques. Second, the dynamic parameters are easily recognized, extracted, and grouped. Third, the equations are amenable to the implementation of parallel processing schemes. For the identification a recursive least squares algorithm is used. The algorithm is distributed over a network of transputers. Real-time results have been produced to demonstrate the speedup and efficiency of the proposed technique. A case study is given for the first three links of the Stanford Arm positioning system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/251981/,[1991] Proceedings of the 34th Midwest Symposium on Circuits and Systems,14-17 May 1992,ieeexplore
10.1109/ROMAN.2007.4415153,Online Affect Detection and Adaptation in Robot Assisted Rehabilitation for Children with Autism,IEEE,Conferences,"This paper presents a novel affect-sensitive human-robot interaction framework for rehabilitation of children with autism spectrum disorder (ASD) where the robot can detect the affective cues of the children implicitly and response to them appropriately. Psychophysiological analysis is performed that uses subjective reports of the affective states from a clinical observer. Comprehensive physiological indices are investigated that may correlate with the affective states of children with ASD. A robot uses a support vector machines based affect model to detect the affective cues. A reinforcement learning based adaptation mechanism is employed to allow the robot to adjust its behaviors autonomously as a function of the predicted children's affective state. Four adolescents diagnosed with high-functioning autism participated in the experiments. This is the first time, to our knowledge, that the affective states of children with ASD have been detected via physiology-based affective modeling technique in real-time. This is also the first time that impact of affect-sensitive interaction between a robot and children with ASD in closed loop has been demonstrated experimentally.",https://ieeexplore.ieee.org/document/4415153/,RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,26-29 Aug. 2007,ieeexplore
10.1109/ICMA.2019.8816298,Online Learning of the Inverse Dynamics with Parallel Drifting Gaussian Processes: Implementation of an Approach for Feedforward Control of a Parallel Kinematic Industrial Robot,IEEE,Conferences,"The present paper deals with an online approach to learn the inverse dynamics of any robot. This is realized by the use of Gaussian Processes drifting parallel along the system data. An extension by a database enables the efficient use of data points from the past. The central component of this work is the implementation of such a method in a controller in order to achieve the actual goal: the feedforward control of an industrial robot by means of machine learning. This is done by splitting the procedure into two threads running parallel so that the prediction is decoupled from the computing-intensive training of the models. Experiments show that the method reduces the tracking errors more clearly than an elaborately identified rigid body model including friction. For a defined trajectory, the squared areas of the tracking errors of all axes are reduced by more than 54% compared to motion without pre-control. In addition, a highly dynamic pick-and-place experiment is used to investigate the possible changes in system dynamics. Compared to an offline trained model, the approximation error of the proposed online approach is smaller for the remaining time of the experiment after an initial phase. Furthermore, this error is smaller throughout the experiment for online learning with parallel drifting Gaussian Processes than when using a single one.",https://ieeexplore.ieee.org/document/8816298/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA40945.2020.9196769,Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure,IEEE,Conferences,"In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",https://ieeexplore.ieee.org/document/9196769/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA.2012.6224998,Online audio beat tracking for a dancing robot in the presence of ego-motion noise in a real environment,IEEE,Conferences,"This paper presents the design and implementation of a real-time real-world beat tracking system which runs on a dancing robot. The main problem of such a robot is that, while it is moving, ego noise is generated due to its motors, and this directly degrades the quality of the audio signal features used for beat tracking. Therefore, we propose to incorporate ego noise reduction as a pre-processing stage prior to our tempo induction and beat tracking system. The beat tracking algorithm is based on an online strategy of competing agents sequentially processing a continuous musical input, while considering parallel hypotheses regarding tempo and beats. This system is applied to a humanoid robot processing the audio from its embedded microphones on-the-fly, while performing simplistic dancing motions. A detailed and multi-criteria based evaluation of the system across different music genres and varying stationary/non-stationary noise conditions is presented. It shows improved performance and noise robustness, outperforming our conventional beat tracker (i.e., without ego noise suppression) by 15.2 points in tempo estimation and 15.0 points in beat-times prediction.",https://ieeexplore.ieee.org/document/6224998/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ROBOT.2008.4543481,Online constraint network optimization for efficient maximum likelihood map learning,IEEE,Conferences,"In this paper, we address the problem of incrementally optimizing constraint networks for maximum likelihood map learning. Our approach allows a robot to efficiently compute configurations of the network with small errors while the robot moves through the environment. We apply a variant of stochastic gradient descent and use a tree-based parameterization of the nodes in the network. By integrating adaptive learning rates in the parameterization of the network, our algorithm can use previously computed solutions to determine the result of the next optimization run. Additionally, our approach updates only the parts of the network which are affected by the newly incorporated measurements and starts the optimization approach only if the new data reveals inconsistencies with the network constructed so far. These improvements yield an efficient solution for this class of online optimization problems. Our approach has been implemented and tested on simulated and on real data. We present comparisons to recently proposed online and offline methods that address the problem of optimizing constraint network. Experiments illustrate that our approach converges faster to a network configuration with small errors than the previous approaches.",https://ieeexplore.ieee.org/document/4543481/,2008 IEEE International Conference on Robotics and Automation,19-23 May 2008,ieeexplore
10.1109/IROS.2017.8202247,Online learning for human classification in 3D LiDAR-based tracking,IEEE,Conferences,"Human detection and tracking are essential aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online learned human classifier matches and in some cases outperforms its offline version.",https://ieeexplore.ieee.org/document/8202247/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ICSMC.1998.726546,Online learning neural network controller for pneumatic robot position control,IEEE,Conferences,"This paper presents the implementation of online learning neural network controller in the pneumatic robot position servo control. The advantages of this design include: the ability to compensate for nonlinearities, and it is insensitive to system parameter time-varying. The traditional PID controller is replaced by neural network controller trained online to learn the inverse model of the pneumatic manipulator by backpropagation of the performance error. The simulation studies and experimental results on the PID controller, online learning neural network controller and off-line training neural network controller, are presented and discussed.",https://ieeexplore.ieee.org/document/726546/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICMA.2012.6285128,Online learning of COM trajectory for humanoid robot locomotion,IEEE,Conferences,"Center Of Mass (COM) trajectory is an essential factor for stable and natural robot locomotion. Unlike previous research in which COM trajectory either restricted by ZMP trajectory or directly predefined by simple function such as sinusoid, this research aims to establish the COM trajectory by online autonomous learning under the objective of locomotion stability and naturalness, which is expressed as a self-consistent measure in this paper. It provides an alternative that may avoid or weaken the mismatch between theoretical planning and practical implementation. The experimental results on a real humanoid robot PKU-HR4 show its effectiveness and promising future.",https://ieeexplore.ieee.org/document/6285128/,2012 IEEE International Conference on Mechatronics and Automation,5-8 Aug. 2012,ieeexplore
10.1109/IROS.2017.8206344,Online multi-target learning of inverse dynamics models for computed-torque control of compliant manipulators,IEEE,Conferences,"Inverse dynamics models are applied to a plethora of robot control tasks such as computed-torque control, which are essential for trajectory execution. The analytical derivation of such dynamics models for robotic manipulators can be challenging and depends on their physical characteristics. This paper proposes a machine learning approach for modeling inverse dynamics and provides information about its implementation on a physical robotic system. The proposed algorithm can perform online multi-target learning, thus allowing efficient implementations on real robots. Our approach has been tested both offline, on datasets captured from three different robotic systems and online, on a physical system. The proposed algorithm exhibits state-of-the-art performance in terms of generalization ability and convergence. Furthermore, it has been implemented within ROS for controlling a Baxter robot. Evaluation results show that its performance is comparable to the built-in inverse dynamics model of the robot.",https://ieeexplore.ieee.org/document/8206344/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/IJCNN.2009.5178844,Online temporal pattern learning,IEEE,Conferences,"This paper describes a biologically motivated approach, using hierarchical temporal memory (HTM), to build a high-level self-organizing visual system for a soccer bot. Meanwhile it presents two unsupervised online learning algorithms for temporal patterns in HTMs. The algorithms were implemented in a simulated soccer bot for a real-world evaluation. After a training phase, the robot was able to recognize different static objects in the soccer field. It also learned and recognized high-level objects that are composed of simpler objects, with position invariance and was also able to learn and recognize motions in the objects, all in a completely unsupervised manner.",https://ieeexplore.ieee.org/document/5178844/,2009 International Joint Conference on Neural Networks,14-19 June 2009,ieeexplore
10.1109/INDIN.2006.275808,"Ontology for Cognitics, Closed-Loop Agility Constraint, and Case Study - a Mobile Robot with Industrial-Grade Components",IEEE,Conferences,"The paper refers to intelligent industrial automation. The objective is to present key elements and methods for best practice, as well as some results obtained. The first part presents an ontology for automated cognition (cognitics), where, based on information and time, the main cognitive concepts, including those of complexity, knowledge, expertise, learning, intelligence abstraction, and concretization are rigorously defined, along with corresponding metrics and specific units. Among important conclusions at this point are the fact that reality is much too complex to be approached better than through much simplified models, in very restricted contexts. Another conclusion is the necessity to be focused on goal. Extensions are made here for group behavior. The second part briefly presents a basic law governing the choice of overall control architecture: achievable performance level of control system in terms of agility, relative to process dynamics, dictates the type of approaches which is suitable, in a spectrum which ranges from simple threshold-based switching, to classical closed-loop calculus (PID, state space multivariable systems, etc.), up to ""impossible"" cases where additional controllers must be considered, leading to cascaded, hierarchical control structures. For complex cases such as latter ones, new tools and methodologies must be designed, as is typical in O<sup>3</sup>NEIDA initiative, at least for software components. Finally, a large part of the paper presents a case study, a mobile robot, i.e. an embedded autonomous system with distributed, networked control, featuring industry-grade components, designed with the main goal of robust functionality. The case illustrates several of the concepts introduced earlier in the paper.",https://ieeexplore.ieee.org/document/4053562/,2006 4th IEEE International Conference on Industrial Informatics,16-18 Aug. 2006,ieeexplore
10.23919/ACC45564.2020.9147898,Optimal Control of Wheeled Mobile Robots: From Simulation to Real World,IEEE,Conferences,"We study the problem of taking simulations to the real world (RW) for autonomous robotic systems with dynamic uncertainties and unknown disturbances while maintaining the optimal performance and stability of the designed controller designed in simulation. In general, an optimal and robust controller that is designed through simulation often does not perform similarly when deployed in the RW. We focus on using simulations to generate an optimal control policy utilizing the Memetic algorithm (MA) iteratively. The simulation-to-RW performance and stability are realized by using an adaptive fuzzy system to learn the uncertain part of the dynamic model, disturbance and noises. We demonstrate experimentally that this method permits the development of optimal control design in simulations and integrates adaptive learning rules to enable precise and repetitive trajectory tracking for the wheeled mobile robot (WMR) with disturbances and uncertainties.",https://ieeexplore.ieee.org/document/9147898/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/SII.2012.6426933,Optimization of obstacle avoidance using reinforcement learning,IEEE,Conferences,Walking through narrow space for multi-legged robot is optimized using reinforcement learning in this paper. The walking is generated by the virtual repulsive force from the estimated obstacle position and the virtual impedance field. The resulted action depends on the parameter of the virtual impedance coefficients. The reinforcement learning is employed to find an optimal motion. The temporal walking through motion consists of each parameter optimized for a situation. Optimization of integrated walking through motion is finally achieved evaluating walking in compound encountering obstacle on simulator. The resulted motion is implemented to a real multi-legged robot and results show the effectiveness of the proposed method.,https://ieeexplore.ieee.org/document/6426933/,2012 IEEE/SICE International Symposium on System Integration (SII),16-18 Dec. 2012,ieeexplore
10.1109/UR49135.2020.9144838,Outdoor Robot Navigation System using Game-Based DQN and Augmented Reality,IEEE,Conferences,"This paper presents a deep reinforcement learning based robot outdoor navigation method using visual information. The deep q network (DQN) maps the visual data to robot action in a goal location reaching task. An advantage of the proposed method is that the implemented DQN is trained in the first-person shooter (FPS) game-based simulated environment provided by ViZDoom. The FPS simulated environment reduces the differences between the training and the real environments resulting in a good performance of trained DQNs. In our implementation a marker-based augmented reality algorithm with a simple object detection method is used to train the DQN. The proposed outdoor navigation system is tested in the simulation and real robot implementation, with no additional training. Experimental results showed that the navigation system trained inside the game-based simulation can guide the real robot in outdoor goal directed navigation tasks.",https://ieeexplore.ieee.org/document/9144838/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/IROS.1997.655095,Output methods for an associative operation of programmable artificial retinas,IEEE,Conferences,"The introduction of intelligence near each photosensitive element in focal plane arrays (FPA) leads to sensory devices-called artificial retinas-which may no longer output raw images but, rather, much more concentrated forms of information. In particular, when the on-sensor image processing facilities are powerful enough to allow some structural pattern recognition, lists of pixels of interest become an output format of choice from retina to microprocessor. This implies the development of specific output techniques and operators to be integrated in the focal plane. After an in-depth presentation of the motivations in the context of programmable artificial retinas (PAR) for robot vision, two original solutions to the problem are presented, corresponding to two different trade-offs between efficiency and VLSI implementation cost. The first one is a compact hardware solution, which allows to sense pixels of interest from the sides of the 2D pixel array. The second one, a mainly software technique, exploits the mathematical concept of de Bruijn arrays for a distributed encoding of pixel addresses on the PAR.",https://ieeexplore.ieee.org/document/655095/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ROBOT.1988.12120,Overview of the multiple autonomous underwater vehicles (MAUV) project,IEEE,Conferences,"The US National Bureau of Standard's multiple autonomous underwater vehicles (MAUV) project involves the development of a real-time intelligent control system that performs sensing, world modeling, planning, and execution for underwater robot vehicles. The goal of the project is to have multiple vehicles exhibiting intelligent, autonomous, cooperative behavior. Initial tests have involved two identical vehicles engaged in various scenarios in Lake Winnipesaukee in New Hampshire. All software for controlling the vehicles reside on computer boards mounted onboard the vehicles.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/12120/,Proceedings. 1988 IEEE International Conference on Robotics and Automation,24-29 April 1988,ieeexplore
10.1109/ROBOT.1991.131722,Parallel robot motion planning,IEEE,Conferences,"A fast, parallel method for computing configuration space maps is presented. The method is made possible by recognizing that one can compute a family of primitive maps which can be combined by superposition based on the distribution of real obstacles. This motion planner has been implemented for the first three degrees-of-freedom of a Puma robot in *Lisp on a Connection Machine with 8 K processors. A six degree-of-freedom version of the algorithm which performs a sequential search of the six-dimensional configuration space, building three-dimensional cross sections in parallel, has also been implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131722/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.23919/ICINS43215.2020.9134006,Path Planning with Improved Artificial Potential Field Method Based on Decision Tree,IEEE,Conferences,"Path planning is one of the key research directions in the field of mobile robots. It ensures that moving objects can reach the target point safely and without collision in a complex obstacle environment. The path planning is to search an optimal path from the starting point to the target point for the mobile robot in an environment with obstacles, according to certain evaluation criteria (such as the time, the best path, the minimum energy consumption, etc.). The path planning based on artificial potential field method has been paid more and more attention because of its advantages such as convenient calculation, simple implementation of hardware and outstanding real-time performance. However, the artificial potential field method has some limitations, such as the local minimum, the oscillation of moving objects among obstacles and so on. To solve these problems, we can introduce the idea of decision tree into the artificial potential field method for improvement. In machine learning, decision tree is usually used for classification. It is a prediction model, which represents a mapping relationship between object attributes and object values. By utilizing the advantages of decision tree in rule expression and extraction, an improved artificial potential field path planning model based on decision tree is constructed, which can realize real-time and accurate identification of current behavior and fast decision-making of next time behavior in path planning. Aiming at the dynamic path planning problem of mobile robots in indoor complex environment, based on the traditional artificial potential field method, this paper introduces the distance term into the potential field function, and proposes an improved artificial potential field method based on the idea of decision tree, to solve the local minimum, the oscillation between obstacles and concave obstacle problems. According to repulsion coefficient, deflection angle of resultant force and velocity, a reasonable classification decision is made to meet the needs of different obstacle distribution scenarios, and the effectiveness of the proposed method is verified by simulation experiments. Simulation results show that, compared with the traditional artificial potential field method, the planning time of improved algorithm is reduced by 50%, and the smoothness of path planning by the improved algorithm is increased by 43.3%.",https://ieeexplore.ieee.org/document/9134006/,2020 27th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS),25-27 May 2020,ieeexplore
10.1109/URAI.2012.6463006,Path planning through maze routing for a mobile robot with nonholonomic constraints,IEEE,Conferences,"A comprehensive technique to plan path for a mobile robot with nonholonomic constraints through maze routing technique has been presented. Our robot uses a stereo vision based approach to detect the obstacles by creating dense 3D point clouds from the stereo images. ROS packages have been implemented on the robot for specific tasks of providing: i) Linear and angular velocity commands, ii) Calibration and rectification of the stereo images for generating point clouds, iii) Simulating the URDF (Unified Robot Description Format) module in real time, with respect to the real robot and iv) For visualizing the sensor data. For efficient path planning a hybrid technique using Lee's algorithm, modified by Hadlock and Soukup's algorithm has been implemented. Different path planning results have been shown using the maze routing algorithms. Preliminary results shows that Lee's algorithm is more time consuming in comparison with other algorithms. A hybrid of Lee's with Soukup's algorithm is more efficient but unpredictable for minimal path. A hybrid of Lee's with Hadlock's algorithm is the most efficient and least time consuming.",https://ieeexplore.ieee.org/document/6463006/,2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),26-28 Nov. 2012,ieeexplore
10.1109/CRV52889.2021.00019,PathBench: A Benchmarking Platform for Classical and Learned Path Planning Algorithms,IEEE,Conferences,"Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Operating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source <sup>1</sup>.",https://ieeexplore.ieee.org/document/9469507/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/VRAIS.1995.512499,Pen-based force display for precision manipulation in virtual environments,IEEE,Conferences,"We describe the structure of a force display recently implemented for precision manipulation of scaled or virtual environments. We discuss the advantages of direct-drive parallel manipulators over geared serial manipulators for human-robot interaction application and introduce the serial-parallel structure we chose for our robot which interfaces with the human operator either at the fingertip or at the tip of a freely held pen-like instrument. We derive the statics and the dynamics, and then introduce the optimization criteria that allowed us to choose the dimensional parameters for the force display. Finally we show some of the potential application for this device.",https://ieeexplore.ieee.org/document/512499/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/ICSMC.1996.571370,Perception-action method for mobile robot plan and control based on driving experience,IEEE,Conferences,"A method of navigation and control for mobile robot is introduced. It combines task planning and path tracking together with the principle of ""perception-action"" under the guidance of ""goal planning"". First, we discuss the behavior of the mobile robot in an outdoor real world for the purpose of setting up a mixed layered architecture with ""perception-action"" and ""goal planning"". Then a simple but effective approach of sensor based navigation and control is described for the implementation of the architecture. Finally, we give some improvements based on the human-driving experience concerning path tracking and control for the mobile robot moving on outdoor semistructured roads. The experiments carried out on our THMR-III (Tsinghua Mobile Robot III) mobile robot navigating in the real world showed the method described was effective and robust.",https://ieeexplore.ieee.org/document/571370/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/IOTSMS48152.2019.8939254,Person Identification using Autonomous Drone through Resource Constraint Devices,IEEE,Conferences,"Detecting a specific person from the crowd using drone along with some resource constraint device is a major concern which we are discussing in the paper. Combining the advanced algorithms and some smart hardware material, we will be finding a way to search for a missing individual in a crowd or at some location. We can also search for a person at a specific location by setting our aerial vehicle to fly autonomously and search for the required person. This will help us to cover areas which cannot be reached by humans easily. The flying robot helps to solve real-time problems and come up with some new and more advanced ways to search for the missing ones with more ease, as advanced technological methods are applied, the probability of getting accurate results increases axiomatically. The drone can fly fully autonomously and search or capture videos/photos of the required location. Location commands could be given using PC, mobile and with the help of IoT, using Raspberry Pi.",https://ieeexplore.ieee.org/document/8939254/,"2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)",22-25 Oct. 2019,ieeexplore
10.1109/ICRA.2011.5979792,Physical human robot interaction in imitation learning,IEEE,Conferences,"This video presents our recent research on the integration of physical human-robot interaction (pHRI) into imitation learning. First, a marker control approach for real time human motion imitation is shown. Secondly, physical coaching in addition to observational learning is applied for the incremental learning of motion primitives. Last, we extend imitation learning to learning pHRI which includes the establishment of intended physical contacts. The proposed methods were implemented and tested using the IRT humanoid robot and DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5979792/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/CNSC.2014.6906671,Pixelwise object class segmentation based on synthetic data using an optimized training strategy,IEEE,Conferences,"In this paper we present an approach for low-level body part segmentation based on RGB-D data. The RGB-D sensor is thereby placed at the ceiling and observes a shared workspace for human-robot collaboration in the industrial domain. The pixelwise information about certain body parts of the human worker is used by a cognitive system for the optimization of interaction and collaboration processes. In this context, for rational decision making and planning, the pixelwise predictions must be reliable despite the high variability of the appearance of the human worker. In our approach we treat the problem as a pixelwise classification task, where we train a random decision forest classifier on the information contained in depth frames produced by a synthetic representation of the human body and the ceiling sensor, in a virtual environment. As shown in similar approaches, the samples used for training need to cover a broad spectrum of the geometrical characteristics of the human, and possible transformations of the body in the scene. In order to reduce the number of training samples and the complexity of the classifier training, we therefore apply an elaborated and coupled strategy for randomized training data sampling and feature extraction. This allows us to reduce the training set size and training time, by decreasing the dimensionality of the sampling parameter space. In order to keep the creation of synthetic training samples and real-world ground truth data simple, we use a highly reduced virtual representation of the human body, in combination with KINECT skeleton tracking data from a calibrated multi-sensor setup. The optimized training and simplified sample creation allows us to deploy standard hardware for the realization of the presented approach, while yielding a reliable segmentation in real-time, and high performance scores in the evaluation.",https://ieeexplore.ieee.org/document/6906671/,2014 First International Conference on Networks & Soft Computing (ICNSC2014),19-20 Aug. 2014,ieeexplore
10.1109/IROS.1991.174701,Planning based sensing and task executing in an autonomous machine,IEEE,Conferences,"Implementing a control system for an autonomous machine is a challenging task. Several techniques have to be applied, such as task planning, hierarchical and/or distributed control, and advanced sensing techniques. In addition, to be useful these various techniques have to be integrated into a system that has to operate more or less in real-time. The authors present a control scheme based on hierarchically organized planning-executing-monitoring-cycles which is used to solve some of the problems related to real-time control of an autonomous machine. The implementation is also presented in which the control system is applied in a pilot system based on an industrial robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174701/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/ICRA48506.2021.9561387,Pointing at Moving Robots: Detecting Events from Wrist IMU Data,IEEE,Conferences,"We propose a practical approach for detecting the event that a human wearing an IMU-equipped bracelet points at a moving robot; the approach uses a learned classifier to verify if the robot motion (as measured by its odometry) matches the wrist motion, and does not require that the relative pose of the operator and robot is known in advance. To train the model and validate the system, we collect datasets containing hundreds of real-world pointing events. Extensive experiments quantify the performance of the classifiers and relevant metrics of the resulting detectors; the approach is implemented in a real-world demonstrator that allows users to land quadrotors by pointing at them.",https://ieeexplore.ieee.org/document/9561387/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICTAI.2006.96,Polynomial Regression with Automated Degree: A Function Approximator for Autonomous Agents,IEEE,Conferences,"In order for an autonomous agent to behave robustly in a variety of environments, it must have the ability to learn approximations to many different functions. The function approximator used by such an agent is subject to a number of constraints that may not apply in a traditional supervised learning setting. Many different function approximators exist and are appropriate for different problems. This paper proposes a set of criteria for function approximators for autonomous agents. Additionally, for those problems on which polynomial regression is a candidate technique, the paper presents an enhancement that meets these criteria. In particular, using polynomial regression typically requires a manual choice of the polynomial's degree, trading off between function accuracy and computational and memory efficiency. Polynomial regression with automated degree (PRAD) is a novel function approximation method that uses training data to automatically identify an appropriate degree for the polynomial. PRAD is fully implemented. Empirical tests demonstrate its ability to efficiently and accurately approximate both a wide variety of synthetic functions and real-world data gathered by a mobile robot",https://ieeexplore.ieee.org/document/4031933/,2006 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'06),13-15 Nov. 2006,ieeexplore
10.1109/ICRA.2014.6907470,Posture control of a three-segmented tracked robot with torque minimization during step climbing,IEEE,Conferences,"In this paper, we present a posture control scheme for step climbing by an in-house developed three-segmented tracked robot, miniUGV. The posture control scheme results in minimum torque at the actuated joints of the segments. Non-linear optimization is carried out offline for progressively decreasing distance of the robot from the step with torque minimization as objective function and force balance, motor torque limits, slippage avoidance and interference avoidance constraints. The resulting angles of the joints are fitted to a third degree polynomial as a function of the robot distance from the step and the step height. It is shown that a single set of polynomial functions is sufficient for climbing steps of all permissible heights and angles of attack of the front segment. The methodology has been verified through simulation followed by implementation on the real robot. As a consequence of this optimization we find that the average current reduced by more than thirty percent, reducing power consumption and confirming the efficacy of the optimization framework.",https://ieeexplore.ieee.org/document/6907470/,2014 IEEE International Conference on Robotics and Automation (ICRA),31 May-7 June 2014,ieeexplore
10.1109/IJCNN.2014.6889830,Predictive Hebbian association of time-delayed inputs with actions in a developmental robot platform,IEEE,Conferences,"The work described here explores a neural network architecture that can be embedded directly in the realtime sensorimotor coordination loop of a developmental robot platform. We take inspiration from the way children are able to learn while interacting with a teacher, in particular the use of prediction of the teacher actions to improve own learning. The architecture is based on two neural networks that operate online, and in parallel, one for learning and one for prediction. A Hebbian learning rule is used to associate the high-dimensional afferent sensor input at different time-delays with the current efferent motor commands corresponding to the teacher demonstration. The predictions of future motor commands are used to limit the growth of the neural network weights, and to enable the robot to smoothly continue movements the teacher has begun. Results on a simulated iCub robot learning object interaction tasks are presented, including an analysis of the sensitivity to changes in the task setup. We also outline the first implementation on the real iCub platform.",https://ieeexplore.ieee.org/document/6889830/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ARITH.2019.00047,Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,IEEE,Conferences,"We aim at creating a society where we can resolve various social challenges by incorporating the innovations of the fourth industrial revolution (e.g. IoT, big data, AI, robot, and the sharing economy) into every industry and social life. By doing so the society of the future will be one in which new values and services are created continuously, making people's lives more conformable and sustainable. This is Society 5.0, a super-smart society. Security and privacy are key issues to be addressed to realize Society 5.0. Privacy-preserving data analytics will play an important role. In this talk we show our recent works on privacy-preserving data analytics such as privacy-preserving logistic regression and privacy-preserving deep learning. Finally, we show our ongoing research project under JST CREST “AI”. In this project we are developing privacy-preserving financial data analytics systems that can detect fraud with high security and accuracy. To validate the systems, we will perform demonstration tests with several financial institutions and solve the problems necessary for their implementation in the real world.",https://ieeexplore.ieee.org/document/8877418/,2019 IEEE 26th Symposium on Computer Arithmetic (ARITH),10-12 June 2019,ieeexplore
10.1109/ROBIO49542.2019.8961870,Probabilistic Inferences on Quadruped Robots: An Experimental Comparison,IEEE,Conferences,"Due to the reality gap, computer software cannot fully model the physical robot in its environment, with noise, ground friction, and energy consumption. Consequently, a limited number of researchers work on applying machine learning in real-world robots. In this paper, we use two intelligent black-box optimization algorithms, Bayesian Optimization (BO) and Covariance Matrix Adaptation Evolution Strategy (CMA-ES), to solve a quadruped robot gait's parametric search problem in 10 dimensions, and compare these two methods to find which one is more suitable for legged robots' controller parameters tuning. Our results show that both methods can find an optimal solution in 130 iterations. BO converges faster than CMA-ES within its constrained range, while CMA-ES finds the optimum in the continuous space. Compared with the specific controller parameters of two methods, we also find that for quadruped robot's oscillators, the angular amplitude is the most important parameter. Thus, it is very beneficial for the quick parametric search of legged robots' controllers and avoids time-consuming manual tuning.",https://ieeexplore.ieee.org/document/8961870/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/IMTC.1999.776982,Problems and solutions in acquisition and interpretation of sensorial data on a mobile robot,IEEE,Conferences,"We discuss some guidelines to cope with problems that arise when using cheap and simple sensors on mobile, autonomous, robotic agents. In particular we focus on the perceptual aliasing problem and on the possibility to perform active sensor data acquisition. We present a robotic architecture that we have implemented on a real robot following the proposed guidelines. The obtained mobile robot satisfies the design specifications, navigating autonomously in an unstructured environment.",https://ieeexplore.ieee.org/document/776982/,IMTC/99. Proceedings of the 16th IEEE Instrumentation and Measurement Technology Conference (Cat. No.99CH36309),24-26 May 1999,ieeexplore
10.1109/IJCNN.1999.832705,Programming robots with associative memories,IEEE,Conferences,"Today, there are several drawbacks that impede the necessary and much needed use of robot learning techniques in real applications. First, the time needed to achieve the synthesis of any behavior is prohibitive. Second, the robot behavior during the learning phase is by definition bad, it may even be dangerous. Third, except within the lazy learning approach, a new behavior implies a new learning phase. We propose in this paper to use self-organizing maps to encode the nonexplicit model of the robot-world interaction sampled by the lazy memory, and then generate a robot behavior by means of situations to be achieved, i.e., points on the self-organizing maps. Any behavior can instantaneously be synthesized by the definition of a goal situation. Its performance will be minimal (not evidently bad) and will improve by the mere repetition of the behavior.",https://ieeexplore.ieee.org/document/832705/,IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339),10-16 July 1999,ieeexplore
10.1109/ICEC.1996.542714,Propagating learned behaviors from a virtual agent to a physical robot in reinforcement learning,IEEE,Conferences,"For a physical robot to acquire behaviors, it is important for it to learn in the physical environment. Since reinforcement learning requires large computation costs as well as a lot of time in the physical environment, most research has performed learning by simulation. However, this does not work well in the real world. Realizing reinforcement learning of a physical robot in a physical environment requires both an adaptation for the diversity of possible situations and a high-speed learning method that can learn from fewer trials. This paper describes cooperative reinforcement learning based on propagating the learned behaviors of a virtual agent to a physical robot in order to accelerate learning in a physical environment. The method consists of two parts: (1) preparation learning in a virtual environment to accelerate initial learning, which accounts for most of the learning cost; and, (2) refinement learning in a physical environment by using the virtual learning results as an initial behavior set of a physical robot. Experimental results are given for a ball-pushing task with the physical robot and a virtual agent.",https://ieeexplore.ieee.org/document/542714/,Proceedings of IEEE International Conference on Evolutionary Computation,20-22 May 1996,ieeexplore
10.1109/EURBOT.1997.633565,Q-learning of complex behaviours on a six-legged walking machine,IEEE,Conferences,"We present work on a six-legged walking machine that uses a hierarchical version of Q-learning (HQL) to learn both the elementary swing and stance movements of individual legs as well as the overall coordination scheme to perform forward movements. The architecture consists of a hierarchy of local controllers implemented in layers. The lowest layer consists of control modules performing elementary actions, like moving a leg up, down, left or right to achieve the elementary swing and stance motions for individual legs. The next level consists of controllers that learn to perform more complex tasks like forward movement by using the previously learned, lower level modules. On the third the highest layer in the architecture presented here the previously learned complex movements are themselves reused to achieve goals in the environment using external sensory input. The work is related to similar, although simulation-based, work by Lin (1993) on hierarchical reinforcement learning and Singh (1994) on compositional Q-learning. We report on the HQL architecture as well as on its implementation on the walking machine SIR ARTHUR. Results from experiments carried out on the real robot are reported to show the applicability of the HQL approach to real world robot problems.",https://ieeexplore.ieee.org/document/633565/,Proceedings Second EUROMICRO Workshop on Advanced Mobile Robots,22-24 Oct. 1997,ieeexplore
10.1109/IJCNN.2014.6889947,Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk,IEEE,Conferences,"Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk.",https://ieeexplore.ieee.org/document/6889947/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/IROS40897.2019.8968551,RONet: Real-time Range-only Indoor Localization via Stacked Bidirectional LSTM with Residual Attention,IEEE,Conferences,"In this study, a three-layered bidirectional Long Short-term Memory (Bi-LSTM) with residual attention, named as RONet, is proposed to achieve localization using range measurements. Accordingly, we acquired our own datasets and tested RONet using realistic conditions. It is shown that the RONet can estimate the position of the mobile robot in real time using the Nvidia Jetson AGX Xavier based only on range measurements. We also analyzed the sequence length of LSTM as a type of hyperparameters. We found that optimal sequence length is eight for more than eight anchors and twelve for fewer anchors compared to sequences with different lengths, given that construction of the network with the optimal sequence length estimates the position precisely and accounts for uncertainties. As verified experimentally, RONet yields more precise performance and results in increased robustness against outliers compared to a conventional range-only approach based on a particle filtering and the other conventional deep-learning-based approaches. We set three cases, reduced the number of anchors, and verified that the RONet was a robust solution. We also confirmed that it is the best solution that yields the smallest Root-Mean-Square-Error (RMSE) values, equal to 4.466 cm, 3.210 cm, and 3.090 cm, in the cases where three, five, and eight anchors were deployed, respectively.",https://ieeexplore.ieee.org/document/8968551/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICARCV.2014.7064347,RSAW: A situation awareness system for autonomous robots,IEEE,Conferences,"Services and technologies are in evolution in order to develop a new generation of robotic systems that might operate in dynamic real-world environments. In this paper, we focus on the ability of robot to understand and to surpass the blocked situations autonomously without operator intervention. Such situations may occur when the robot cannot succeed the current action and cannot move to the next one. We remark that in the literature, the operator has a crucial role consisting in providing all information about the environment and in making interpretations. In this paper, we propose an RSAW (Robot Situation AWareness) system, developed in order to help a robot to surpass a blocked situation and accomplish its goal whilst minimizing the operator intervention. RSAW is a new general system aiming to increase the autonomy of the robot; It is inspired by the notion of Situation Awareness (SA). In fact, RSAW defines a knowledge representation using ontologies and a process in order to surpass a blocked situation. RSAW is designed according to the Model Driven Engineering (MDE) methodology. This choice is done to preserve the generality of our system. This paper focalizes on the process of the RSAW system and the interaction between the process and the knowledge representation. The experimentations conducted in real environment with the Smart Autonomous Majordomo (SAM) robot, have shown the robustness and the efficiency of the proposed system.",https://ieeexplore.ieee.org/document/7064347/,2014 13th International Conference on Control Automation Robotics & Vision (ICARCV),10-12 Dec. 2014,ieeexplore
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ICRoM.2015.7367861,ReMoRo; A mobile robot platform based on distributed I/O modules for research and education,IEEE,Conferences,"We present our recent work on the electrical and hardware design of the mobile robot platform ReMoRo that is based on distributed input/output modules. We have designed three generation of this platform with different specifications, which it help us to design more compatible and applied mobile robot. Nevertheless, the goal of this project was to develop a low-cost and robust but extensible modular robot platform for research and educational purposes. In this paper we describe a new affordable robot structure that enables large-scale innovative, new curriculum, multi robot research and multi-robotics outreach to computer and artificial intelligent students. We introduce the ReMoRo platform, which offers a balance between capabilities, accessibility, cost and an opendesign. All of electrical devices like sensors module, motor drivers and device communication manager are designed based on ARM Cortex M3 microcontrollers that runs under Real-Time Operating System (freeRTOS) for manages each modules internal scheduling and activation control in communication bus. With a range of different sensors, cylindrical manipulator and omnidirectional locomotion system, RoMeRo can interact with environment in multiple ways, handle common objects and therefore be used in various service robot scenarios like warehouse robots or multi agent mobile robots. We demonstrate the usability of our concept by quantifying the object-handling task and also briefly describe the software design based on ROS framework for educational usage.",https://ieeexplore.ieee.org/document/7367861/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/ICRA48506.2021.9562075,Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy,IEEE,Conferences,"We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",https://ieeexplore.ieee.org/document/9562075/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISIC.1992.225088,Reactive behavior design tools,IEEE,Conferences,"The reactive behavior of an autonomous agent can be described as collections of logical behaviors, each member of the collection controlling some aspect of the agent and working in conjunction with all the other behaviors. Such collections of reactive behaviors can be defined as combined, synchronous finite-state automata, using real-time programming languages which have strong formal components. These language tools, such as COSPAN and ESTEREL, require sophisticated users who have deep knowledge of both the syntax and semantics of the language. The authors use the simplicity of graphical finite-state automata editing to specify concurrent synchronous finite-state automata, and from those they produce COSPAN descriptions of these behaviors for analysis, and C language programs to implement the designed behaviors. The usefulness and validity of this approach was confirmed by the design, verification and implementation of several examples, including a controller demon for a robot arm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/225088/,Proceedings of the 1992 IEEE International Symposium on Intelligent Control,11-13 Aug. 1992,ieeexplore
10.1109/ISIE.2005.1529114,Real time implementation of a selective attention model for the intelligent robot with autonomous mental development,IEEE,Conferences,"We propose a biologically motivated selective attention model to find an object based on context free search for an intelligent robot with an autonomous mental development (AMD) mechanism. For real-time operation of the selective attention model in the robot system, we have considered a way to reduce the computational load of the selective attention model, which uses a simplified symmetry operation with retina-topic sampling and look-up table in the localized candidate attention region. As a result, our model can perform within 270 ms at Pentium-4 2.8Ghz, and obtain a plausible human-like visual scan path in order to pay attention to an object preferentially. Then, we implemented an intelligent mobile robot with selective attention for an AMD mechanism.",https://ieeexplore.ieee.org/document/1529114/,"Proceedings of the IEEE International Symposium on Industrial Electronics, 2005. ISIE 2005.",20-23 June 2005,ieeexplore
10.1109/IJCNN.1993.714313,Real time learning algorithm for redundant manipulator movement control,IEEE,Conferences,"We propose a new learning control strategy to solve the ill-posed inverse kinematics of a redundant robot manipulator. Four distinct characteristics are observed: 1) the inverse solution is context-sensitive, which is a requisite when the manipulator starts from an arbitrary joint configuration or moves in a complex environment; 2) learning and execution are both memory-based and can be implemented in real time; 3) the property of conventional pseudoinverse control, i.e. keeping the incremental changes of joint angles minimum, is intrinsic in our scheme; and 4) control is goal-directed in that only the current end-effector position relative to the goal position is needed.",https://ieeexplore.ieee.org/document/714313/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/WCICA.2000.863435,Real time path smoothing schemes in teleoperation system,IEEE,Conferences,"The Robot Teleoperation System (RTS) based on telepresence, which is aided financially by the National 863 High-Tech Development Plan, was set up by the State Key Laboratory of Intelligence Technology and Systems. This system consists of three main parts: robot control, stereo vision and hand gesture tracking. The controlled robot and the operator form a closed loop, and the operator views the robot's status and the environment through the stereo vision subsystem. RTS is developed from SAROT (an intelligent assembly robot system), which is logically divided into 5 layers: real time control, monitoring and coordination, motion planning, task scheduling and task planning. The paper proposes several active ""path smoothing"" schemes implemented in the system, which carry out the operator's hand gesture tracking in 7 DOF (position: 3, orientation: 3, and pitch: 1).",https://ieeexplore.ieee.org/document/863435/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/WCICA.2000.863455,Real time tracking in robot teleoperation system,IEEE,Conferences,"The robot teleoperation system based on stereo vision was developed by the State Key Lab of Intelligent Technology and System of Tsinghua University. The paper presents the design frame of the whole system, and describes in detail some of the key design and implementation problems. Finally, the paper analyses the difficulty of applying this technology to virtual reality and augmented reality systems, and some suggestions are provided. The success of this system can contribute to further research on augmented reality.",https://ieeexplore.ieee.org/document/863455/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ECCTD.2005.1522965,Real time vision by FPGA implemented CNNs,IEEE,Conferences,"In order to get real time image processing for mobile robot vision, we propose to use a discrete time cellular neural network implementation by a convolutional structure on Altora FPGA using VHDL language. We obtain at least 9 times faster processing than other emulations for the same problem.",https://ieeexplore.ieee.org/document/1522965/,"Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.",2-2 Sept. 2005,ieeexplore
10.1109/OCEANSKOBE.2018.8559422,Real-Time Automated Evaluation of COLREGS-Constrained Interactions Between Autonomous Surface Vessels and Human Operated Vessels in Collaborative Human-Machine Partnering Missions,IEEE,Conferences,"This paper explores an extension of the real-time evaluation of COLREGS-based collision avoidance interactions between autonomous surface vessels and human-operated surface vessels. Our previous work developed the algorithms that evaluate and quantify a ship's compliance with the collision regulations, safety, and mission efficiencies with respect to the overall goal(s). Our previous work is extended in this paper by establishing a light-weight program to assign penalties to offenders of safety or protocol violations during human-machine collaborative on-water interactions. Vessels interacting in this DARPA-sponsored Aquaticus mission are grouped into teams consisting of both human and robot counterparts. These teams play a “capture the flag” like game while being required to obey the maritime collision avoidance regulations. This paper is a first step in the field toward evaluating collision avoidance rules in the context of a human or robotic vehicle cheating the COLREGS against its opponent to gain a mission advantage. The problem is representative of interactions likely seen on the open ocean using a combination of autonomous and human-operated multi-vehicle collision avoidance interactions to larger scale maritime vessel traffic interactions operating under COLREGS protocol constraints. The vessels deploy in a distributed collaborative pattern to compete against the opposing team. Upon detection of a violation, the offending vessel(s) are required to complete their penalty actions prior to being allowed to proceed in their mission goal. Human offenders are able to be linked to haptic devices that give real-time feedback using vibrations or similar queuing.",https://ieeexplore.ieee.org/document/8559422/,2018 OCEANS - MTS/IEEE Kobe Techno-Oceans (OTO),28-31 May 2018,ieeexplore
10.1109/ICIA.2006.305830,Real-Time Fusion of Multimodal Tracking Data and Generalization of Motion Patterns for Trajectory Prediction,IEEE,Conferences,"A sensor-based model of a service robot's environment is a prerequisite for interaction. Such a model should contain the positions of the robot's interaction partners. Many reasonable applications require this knowledge in realtime. It could for example be used to realize efficient path planning for delivery tasks. Additionally to the actual positions of the partners it is important for the service robot to predict their possible future positions. In this paper we propose an extensible framework that combines different sensor modalities in a general real-time tracking system. Exemplarily, a tracking system is implemented that fuses tracking algorithms in laser range scans as well as in camera images by a particle filter. Furthermore, human trajectories are predicted by deducing them from learned motion patterns. The observed trajectories are generalized to trajectory patterns by a novel method which uses self organizing maps. Those patterns are used to predict trajectories of the currently observed persons. Practical experiments show that multimodality increases the system's robustness to incorrect measurements of single sensors. It is also demonstrated that a self organizing map is suitable for learning and generalizing trajectories. Convenient predictions of future trajectories are presented which are deduced from these generalizations.",https://ieeexplore.ieee.org/document/4097763/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ICMLC.2006.259112,Real-Time Implementation of a PD+DFNNS Controller for Compliance Robot,IEEE,Conferences,"This paper presents the compliance control of a robot manipulator under a constrained environment. The controller design proposed herein is based on the intelligence adaptive control scheme. In this design, the DFNNs (dynamic fuzzy neural networks) and PD feedback controllers control the position and the contact force of robot end-effector. The DFNNs controller is employed to compensate for environmental variations such as payload mass and disturbance torque during the operation process; PD feedback controllers control the position and the contact force of end-effector. Applying these controllers allows us to adapt the manipulator to the unknown surface of the surrounding environment and to have close contact with the curved surface",https://ieeexplore.ieee.org/document/4028106/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/I2CACIS.2019.8825093,Real-Time Robotic Grasping and Localization Using Deep Learning-Based Object Detection Technique,IEEE,Conferences,"This work aims to increase the impact of computer vision on robotic positioning and grasping in industrial assembly lines. Real-time object detection and localization problem is addressed for robotic grasp-and-place operation using Selective Compliant Assembly Robot Arm (SCARA). The movement of SCARA robot is guided by deep learning-based object detection for grasp task and edge detection-based position measurement for place task. Deep Convolutional Neural Network (CNN) model, called KSSnet, is developed for object detection based on CNN Alexnet using transfer learning approach. SCARA training dataset with 4000 images of two object categories associated with 20 different positions is created and labeled to train KSSnet model. The position of the detected object is included in prediction result at the output classification layer. This method achieved the state-of-the-art results at 100% precision of object detection, 100% accuracy for robotic positioning and 100% successful real-time robotic grasping within 0.38 seconds as detection time. A combination of Zerocross and Canny edge detectors is implemented on a circular object to simplify the place task. For accurate position measurement, the distortion of camera lens is removed using camera calibration technique where the measured position represents the desired location to place the grasped object. The result showed that the robot successfully moved to the measured position with positioning Root Mean Square Error (0.361, 0.184) mm and 100% for successful place detection.",https://ieeexplore.ieee.org/document/8825093/,2019 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS),29-29 June 2019,ieeexplore
10.1109/IROS45743.2020.9341473,Real-World Human-Robot Collaborative Reinforcement Learning,IEEE,Conferences,"The intuitive collaboration of humans and intelligent robots (embodied AI) in the real-world is an essential objective for many desirable applications of robotics. Whilst there is much research regarding explicit communication, we focus on how humans and robots interact implicitly, on motor adaptation level. We present a real-world setup of a human-robot collaborative maze game, designed to be non-trivial and only solvable through collaboration, by limiting the actions to rotations of two orthogonal axes, and assigning each axes to one player. This results in neither the human nor the agent being able to solve the game on their own. We use deep reinforcement learning for the control of the robotic agent, and achieve results within 30 minutes of real-world play, without any type of pre-training. We then use this setup to perform systematic experiments on human/agent behaviour and adaptation when co-learning a policy for the collaborative game. We present results on how co-policy learning occurs over time between the human and the robotic agent resulting in each participant's agent serving as a representation of how they would play the game. This allows us to relate a person's success when playing with different agents than their own, by comparing the policy of the agent with that of their own agent.",https://ieeexplore.ieee.org/document/9341473/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICARM49381.2020.9195281,Real-time Colonoscopy Image Segmentation Based on Ensemble Knowledge Distillation,IEEE,Conferences,"Colonoscopy is an important means of detecting various intestinal diseases such as bleeding, polyps, Merck diverticula, and ulcers. The sooner these diseases are detected, the better the patient's recovery. But colonoscopy is a demanding process, often leads to the high rate of misdiagnosis by experts, professional physicians and nurses and costs a lot of time. Therefore, robot-assisted colonoscopy is considered as an important method to solve this problem. In recent years, many automated deep learning models for colonoscopy have been proposed. However, these models are usually large and time-consuming, and cannot meet actual needs. Besides, due to the disconnection of data between hospitals, the strength of medical resources between different departments in different hospitals is different, so the general multi-classification model cannot fit the characteristics of such data distribution. Therefore, in this article, we ensemble multiple binary classification models (each model detects one disease) and extracted a compression model using knowledge distillation technology, which can simultaneously detect polyps, Merkel diverticula, ulcers and bleeding from colonoscopy. We tested the performance of our model on public and real data sets and found that the model can achieve acceptable results and help doctors make decisions in practice.",https://ieeexplore.ieee.org/document/9195281/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/SYSOSE.2015.7151922,Real-time FPGA decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper presents a field programmable gate array (FPGA) implementation for a decentralized inverse optimal neural controller for unknown nonlinear systems, in presence of external disturbances and parameter uncertainties. This controller is based on two techniques: first, an identifier using a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the neural identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/7151922/,2015 10th System of Systems Engineering Conference (SoSE),17-20 May 2015,ieeexplore
10.1109/CRV50864.2020.00032,Real-time Motion Planning for Robotic Teleoperation Using Dynamic-goal Deep Reinforcement Learning,IEEE,Conferences,"We propose Dynamic-goal Deep Reinforcement Learning (DGDRL) method to address the problem of robot arm motion planning in telemanipulation applications. This method intuitively maps human hand motions to a robot arm in real-time, while avoiding collisions, joint limits and singularities. We further propose a novel hardware setup, based on the HTC VIVE VR system, that enables users to smoothly control the robot tool position and orientation with hand motions, while monitoring its movements in a 3D virtual reality environment. A VIVE controller captures 6D hand movements and gives them as reference trajectories to a deep neural policy network for controlling the robot's joint movements. Our DGDRL method leverages the state-of-art Proximal Policy Optimization (PPO) algorithm for deep reinforcement learning to train the policy network with the robot joint values and reference trajectory observed at each iteration. Since training the network on a real robot is time-consuming and unsafe, we developed a simulation environment called RobotPath which provides kinematic modeling, collision analysis and a 3D VR graphical simulation of industrial robots. The deep neural network trained using RobotPath is then deployed on a physical robot (ABB IRB 120) to evaluate its performance. We show that the policies trained in the simulation environment can be successfully used for trajectory planning on a real robot. The the codes, data and video presenting our experiments are available at https://github.com/kavehkamali/ppoRobotPath.",https://ieeexplore.ieee.org/document/9108691/,2020 17th Conference on Computer and Robot Vision (CRV),13-15 May 2020,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/ICAR46387.2019.8981549,Real-time RGB-D semantic keyframe SLAM based on image segmentation learning from industrial CAD models,IEEE,Conferences,"This paper presents methods for performing realtime semantic SLAM aimed at autonomous navigation and control of a humanoid robot in a manufacturing scenario. A novel multi-keyframe approach is proposed that simultaneously minimizes a semantic cost based on class-level features in addition to common photometric and geometric costs. The approach is shown to robustly construct a 3D map with associated class labels relevant to robotic tasks. Alternatively to existing approaches, the segmentation of these semantic classes have been learnt using RGB-D sensor data aligned with an industrial CAD manufacturing model to obtain noisy pixel-wise labels. This dataset confronts the proposed approach in a complicated real-world setting and provides insight into the practical use case scenarios. The semantic segmentation network was fine tuned for the given use case and was trained in a semi-supervised manner using noisy labels. The developed software is real-time and integrated with ROS to obtain a complete semantic reconstruction for the control and navigation of the HRP4 robot. Experiments in-situ at the Airbus manufacturing site in Saint-Nazaire validate the proposed approach.",https://ieeexplore.ieee.org/document/8981549/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/ECMR.2019.8870936,Real-time Vision-based Depth Reconstruction with NVidia Jetson,IEEE,Conferences,"Vision-based depth reconstruction is a challenging problem extensively studied in computer vision but still lacking universal solution. Reconstructing depth from single image is particularly valuable to mobile robotics as it can be embedded to the modern vision-based simultaneous localization and mapping (vSLAM) methods providing them with the metric information needed to construct accurate maps in real scale. Typically, depth reconstruction is done nowadays via fully-convolutional neural networks (FCNNs). In this work we experiment with several FCNN architectures and introduce a few enhancements aimed at increasing both the effectiveness and the efficiency of the inference. We experimentally determine the solution that provides the best performance/accuracy tradeoff and is able to run on NVidia Jetson with the framerates exceeding 16FPS for 320 × 240 input. We also evaluate the suggested models by conducting monocular vSLAM of unknown indoor environment on NVidia Jetson TX2 in real-time. Open-source implementation of the models and the inference node for Robot Operating System (ROS) are available at https://github.com/CnnDepth/tx2_fcnn_node.",https://ieeexplore.ieee.org/document/8870936/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/WCICA.2000.863254,Real-time bilateral control of Internet-based teleoperation,IEEE,Conferences,"The growth of the Internet has been accompanied by an increase in its applications. One of the most interesting of these is teleoperation, where the Internet is used as a bridge between operators and machines. However, teleoperation over the Internet comes with several problems: delay, lost packets and disconnection. All of these limitations may cause instability in teleoperation systems, especially for those systems include haptic feedback. Most of the previous work in Internet based teleoperation rests on many limiting assumptions, for example, time delay is constant or has an upper bound, control is not in real-time. This paper presents a new real time haptic feedback system that deals with these limitations and difficulties without making any assumptions regarding the time delay. The approach is based on the event based control, which has been implemented or a mobile robot over the Internet. The haptic information include real-time feedback of force and video.",https://ieeexplore.ieee.org/document/863254/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/CCA.1994.381367,Real-time control of a robot using neural networks,IEEE,Conferences,"The real-time computation of the robot kinematics is very important. The basic transformations are the direct kinematic transformation (DKT) and the inverse kinematic transformation (IKT). The DKT can be computed in a straightforward way using the Denavit-Hartenberg notation. No such general method yet exists for the IKT, although this transformation is of major interest for control purposes. In this paper a neural network is presented that maps the IKT independent of the type of robot. After training, the network achieves very good accuracy and may easily be implemented in real-time. The performance of the algorithm is tested an the RTX robot, a SCARA-type robot with six degrees of freedom. This robot is controlled by a distributed control system. A host computer realizes the continuous path control and a network of 5 slave-transputers is used to compute the local controls and to drive the DC servomotors.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/381367/,1994 Proceedings of IEEE International Conference on Control and Applications,24-26 Aug. 1994,ieeexplore
10.1109/IJCNN.2013.6706785,Real-time decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper deals with a decentralized inverse optimal neural controller for MIMO discrete-time unknown nonlinear systems, in a presence of external disturbances and parameter uncertainties. It uses two techniques: first, an identifier based on a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the real identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/6706785/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/CCA.2009.5280998,Real-time decentralized neural backstepping controller for a robot manipulator,IEEE,Conferences,This paper deals with adaptive trajectory tracking for discrete-time MIMO nonlinear systems. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The HONN learning is performed online by an Extended Kalman Filter (EKF) algorithm. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.,https://ieeexplore.ieee.org/document/5280998/,"2009 IEEE Control Applications, (CCA) & Intelligent Control, (ISIC)",8-10 July 2009,ieeexplore
10.1109/IROS.2009.5354338,Real-time decentralized neural block controller for a robot manipulator,IEEE,Conferences,"This paper presents a discrete-time decentralized control scheme for identification and trajectory tracking of a two degrees of freedom (DOF) robot manipulator. A recurrent high order neural network (RHONN) structure is used to identify the plant model and based on this model, a discrete-time control law is derived, which combines discrete-time block control and sliding modes techniques. The neural network learning is performed online by Kalman filtering. A controller is designed for each joint, using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.",https://ieeexplore.ieee.org/document/5354338/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore
10.1109/ROBOT.2003.1241979,Real-time estimation of facial expression intensity,IEEE,Conferences,"Changing facial expressions is a natural and powerful way of conveying personal intention, expressing emotion and regulating interpersonal communication. Automatic estimation of human facial expression intensity is an important step in enhancing the capability of human-robot interfaces. In this research, we have developed a system which can automatically estimate the intensity of facial expression in real-time. Based on isometric feature mapping, the intensity of expression is extracted from training facial transition sequences. Then, intelligent models including cascade neural networks and support vector machines are applied to model the relationship between the trajectories of facial feature points and expression intensity level. We have implemented a vision system which can estimate the expression intensity of happiness, anger and sadness in real-time.",https://ieeexplore.ieee.org/document/1241979/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/ISIC.2010.5612924,Real-time five DOF robot control using a decentralized neural backstepping scheme,IEEE,Conferences,This paper presents a discrete-time decentralized control scheme for trajectory tracking of a five degrees of freedom (DOF) redundant robot. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The neural network learning is performed on-line by Kalman filtering. The controllers are designed for each joint using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The applicability of the proposed scheme is illustrated via real-time implementation.,https://ieeexplore.ieee.org/document/5612924/,2010 IEEE International Symposium on Intelligent Control,8-10 Sept. 2010,ieeexplore
10.1109/IRIA53009.2021.9588681,Real-time gesture control UAV with a low resource framework,IEEE,Conferences,"This study showcases a low-resource framework that enables people with no technical know-how to interact with drones, it also explores the capabilities of 2D- computer vision and deep learning techniques for gesture based interface systems on a low-cost micro drone with an onboard RGB camera. This Human-Robot Interaction system processes the real-time human pose to allow a user to command the drone, i.e., by providing direction to move and execute actions. A linear PD controller and image processing techniques are implemented to track humans whilst maintaining a safe distance from the user by perceiving depth information through pose estimation. We incorporated the gesture recognition results into a drone using the Robot Operating System (ROS) and evaluated system performance indoor and outdoor. This low computation framework can be applied further to control robotic arms or mobile robots.",https://ieeexplore.ieee.org/document/9588681/,2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA),20-22 Sept. 2021,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/ROBOT.1993.291973,Real-time implementation of neural network learning control of a flexible Space manipulator,IEEE,Conferences,"A neural network approach to online learning control and real-time implementation for a flexible space robot manipulator is presented. An overview of the motivation and system development of the self-mobile space modulator (SM/sup 2/) is given. The neural network learns control by updating feedforward dynamics based on feedback control input. Implementation issues associated with online training strategies are addressed and a single stochastic training scheme is presented. A recurrent neural network architecture with improved performance is proposed. Using the proposed learning scheme, the manipulator tracking error is reduced by 85% compared to that of conventional proportional-integral-derivative (PID) control. The approach possesses a high degree of generality and adaptability to various applications. It will be a valuable learning control method for robots working in unconstructed environments.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/291973/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/BIOROB.2008.4762823,Real-time isometric pinch force prediction from sEMG,IEEE,Conferences,"This paper describes a real-time isometric pinch force prediction algorithm using surface electromyogram (sEMG). The activities of seven muscles related to the movements of the thumb and index finger joints, which are observable using surface electrodes, were recorded during pinch force experiments. For the successful implementation of the real-time prediction algorithm, an off-line analysis was performed using the recorded activities. From the seven muscles, four muscles were selected for monitoring using the Fisher linear discriminant paradigm in an off-line analysis, and the recordings from these four muscles provided the most effective information for mapping sEMG to the pinch force. An ANN structure was designed to perform efficient training and to avoid both under-fitting and over-fitting problems. Finally, the pinch force prediction algorithm was tested with five volunteers and the results were evaluated using two criteria: normalized root mean squared error (NRMSE) and correlation (CORR). The training time for the subjects was only 2 min 29 sec, but the prediction results were successful with NRMSE = 0.093 plusmn0.047 and CORR = 0.957 plusmn0.031. These results imply that the proposed algorithm is useful to measure the generated pinch force without force sensors. The possible applications of the proposed method include controlling bionic finger robot systems to overcome finger paralysis or amputation.",https://ieeexplore.ieee.org/document/4762823/,2008 2nd IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics,19-22 Oct. 2008,ieeexplore
10.1109/ICAR.1997.620222,Real-time navigation of a mobile robot using Kohonen's topology conserving neural network,IEEE,Conferences,"This paper proposes a real-time sensor based navigation method using Kohonen's topology conserving network for navigation of a mobile robot in any uncertain environment. The sensory information including target location with respect to current location of the mobile robot, have been discretely conserved using a two dimensional Kohonen lattice. Reinforcement learning based on a stochastic real valued technique have been implemented to compute the action space for this Kohonen lattice. The proposed scheme learns the input and output weight space of the Kohonen lattice which is generalized to any workspace. The effectiveness of the proposed scheme has been established by simulation where the complete domain of the input-space is quantized based on experience on sensory data encountered in real-time. The input-output mapping conserved by the Kohonen lattice during simulation was used to guide a mobile robot in a real-time environment. Successful navigation of the mobile robot without further training confirms the robustness of the proposed scheme.",https://ieeexplore.ieee.org/document/620222/,1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97,7-9 July 1997,ieeexplore
10.1109/ACIIW.2019.8925192,Real-time pain detection in facial expressions for health robotics,IEEE,Conferences,"Automatic pain detection is an important challenge in health computing. In this paper we report on our efforts to develop a real-time, real-world pain detection system from human facial expressions. Although many studies addressed this challenge, most of them use the same dataset for training and testing. There is no cross-check with other datasets or implementation in real-time to check performance on new data. This is problematic, as evidenced in this paper, because the classifiers overtrain on dataset-specific features. This limits realtime, real-world usage. In this paper, we investigate different methods of real-time pain detection. The training data uses a combination of pain and emotion datasets, unlike other papers. The best model shows an accuracy of 88.4% on a dataset including pain and 7 non-pain emotional expressions. Results suggest that convolutional neural networks (CNN) are not the best methods in some cases as they easily overtrain if the dataset is biased. Finally we implemented our pain detection method on a humanoid robot for physiotherapy. Our work highlights the importance of cross-corpus evaluation &amp; real-time testing, as well as the need for a well balanced and ecologically valid pain dataset.",https://ieeexplore.ieee.org/document/8925192/,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),3-6 Sept. 2019,ieeexplore
10.1109/ROBOT.2001.932598,Real-time robot learning,IEEE,Conferences,"This paper presents the design, implementation and testing of a real-time system using computer vision and machine learning techniques to demonstrate learning behavior in a miniature mobile robot. The miniature robot, through environmental sensing, learns to navigate a maze choosing the optimum route. Several reinforcement learning based algorithms, such as the Q-learning, Q(/spl lambda/)-learning, fast online Q(/spl lambda/)-learning and DYNA structure, are considered. Experimental results based on simulation and an integrated real-time system are presented for varying density of obstacles in a 15/spl times/15 maze.",https://ieeexplore.ieee.org/document/932598/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICUAS.2016.7502588,Real-time unmanned aerial vehicle 3D environment exploration in a mixed reality environment,IEEE,Conferences,"This paper presents a novel human robot interaction system that can be used for real-time 3D environment exploration with an unmanned aerial vehicle (UAV). The method creates a mixed reality environment, in which a user can interactively control a UAV and visualize the exploration data in real-time. The method uses a combination of affordable sensors, and transforms the control and viewing space from the UAV to the controller's perspective. Different hardware and software configurations are studied so that the system can be adjusted to meet different needs and environments. A prototype system is presented and test results are discussed.",https://ieeexplore.ieee.org/document/7502588/,2016 International Conference on Unmanned Aircraft Systems (ICUAS),7-10 June 2016,ieeexplore
10.1109/ICMLA.2017.0-161,Realistic Traffic Generation for Web Robots,IEEE,Conferences,"Critical to evaluating the capacity, scalability, and availability of web systems are realistic web traffic generators. Web traffic generation is a classic research problem, no generator accounts for the characteristics of web robots or crawlers that are now the dominant source of traffic to a web server. Administrators are thus unable to test, stress, and evaluate how their systems perform in the face of ever increasing levels of web robot traffic. To resolve this problem, this paper introduces a novel approach to generate synthetic web robot traffic with high fidelity. It generates traffic that accounts for both the temporal and behavioral qualities of robot traffic by statistical and Bayesian models that are fitted to the properties of robot traffic seen in web logs from North America and Europe. We evaluate our traffic generator by comparing the characteristics of generated traffic to those of the original data. We look at session arrival rates, inter-arrival times and session lengths, comparing and contrasting them between generated and real traffic. Finally, we show that our generated traffic affects cache performance similarly to actual traffic, using the common LRU and LFU eviction policies.",https://ieeexplore.ieee.org/document/8260631/,2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA),18-21 Dec. 2017,ieeexplore
10.1109/SII.2010.5708353,Realization and analysis of giant-swing motion using Q-Learning,IEEE,Conferences,"Many research papers have reported studies on sports robots that realize giant-swing motion. However, almost all these robots were controlled using trajectory planning methods, and few robots realized giant-swing motion by learning. Consequently, in this study, we attempted to construct a humanoid robot that realizes giant-swing motion by Q-learning, a reinforcement learning technique. The significant aspect of our study is that few robotic models were constructed beforehand; the robot learns giant-swing motion only by interaction with the environment during simulations. Our implementation faced several problems such as imperfect perception of the velocity state and robot posture issues caused by using only the arm angle. However, our real robot realized giant-swing motion by averaging the Q value and by using rewards - the absolute angle of the foot angle and the angular velocity of the arm angle-in the simulated learning data; the sampling time was 250 ms. Furthermore, the feasibility of generalization of learning for realizing selective motion in the forward and backward rotational directions was investigated; it was revealed that the generalization of learning is feasible as long as it does not interfere with the robot's motions.",https://ieeexplore.ieee.org/document/5708353/,2010 IEEE/SICE International Symposium on System Integration,21-22 Dec. 2010,ieeexplore
10.1109/ICACEH51803.2020.9366217,Realization of Human and Fish Robot Interaction with Artificial Intelligence Using Hand Gesture,IEEE,Conferences,This study mimicked a real fish movement in the aquarium which was controlled by hand signals. The main idea to develop an aquarium robotic fish with hand gestures. Control actions include directions and stop and go of the fish. The inputs are given by human hands known as bio-mimetic ornamental. We implemented control algorithms to recognize hand gestures. The experimental results showed the effective control of robot fish with hand gestures.,https://ieeexplore.ieee.org/document/9366217/,"2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH)",25-27 Dec. 2020,ieeexplore
10.1109/GTSD50082.2020.9303087,Receptionist and Security Robot Using Face Recognition with Standardized Data Collecting Method,IEEE,Conferences,"Face recognition has become the front runner for deep learning applications in the real world and this paper focuses on its implementation in a human-robot interaction and security system. For this specific project, it is inherent that restraints are created to allow the system to produce greater performance within the requirements of a receptionist and security robot. A k-nearest neighbors classifier is applied to further enhance the accuracy of face recognition. By sequencing images from videos, we create large datasets to train our own classifier in various conditions to increase its accuracy and lower false-positive rates in poor lighting environments. With the goal of creating a service robot, we have standardized our method of data collection for new inputs that will assist the recognition process in variable conditions of operation. The resulting product is a system that can accurately predict known and unknown faces with Asian features.",https://ieeexplore.ieee.org/document/9303087/,2020 5th International Conference on Green Technology and Sustainable Development (GTSD),27-28 Nov. 2020,ieeexplore
10.1109/ICCCT.2010.5640434,Recognizing &amp; interpreting Indian Sign Language gesture for Human Robot Interaction,IEEE,Conferences,"This paper describes a novel approach towards recognizing of Indian Sign Language (ISL) gestures for Humanoid Robot Interaction (HRI). An extensive approach is being introduced for classification of ISL gesture which imparts an elegant way of interaction between humanoid robot HOAP-2 and human being. ISL gestures are being considered as a communicating agent for humanoid robot which is being used in this context explicitly. It involves different image processing techniques followed by a generic algorithm for feature extraction process. The classification technique deals with the Euclidean distance metric. The concrete HRI system has been established for initiation based learning mechanism. The Real time robotics simulation software, WEBOTS has been adopted to simulate the classified ISL gestures on HOAP-2 robot. The JAVA based software has been developed to deal with the entire HRI process.",https://ieeexplore.ieee.org/document/5640434/,2010 International Conference on Computer and Communication Technology (ICCCT),17-19 Sept. 2010,ieeexplore
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ECAI.2014.7090222,Reconfigurable robotic system based on mono-camera guidance,IEEE,Conferences,"The paper proposes an intelligent robotic system which is able to be (re)configured, at demand, for two deployment scenarios. a) The first task is to move the platform after a trajectory determined by the direction to a fixed point and avoid any obstacles occurring in the route. a) The second task is to identify and track a spherical object. The robot is equipped with a navigation system designed to maintain direction in case of interruption of video contact with the target (landmark), meaning when an obstacle interposes. It has two main subsystems: the mobile platform, which is equipped with a video camera and sensors for path correction, and the central processing system for the analysis of received information. The task control is based on extracted features from images. The communication between them is done via a wireless protocol. Algorithms for controlling the mobile platform are implemented on the embedded microcontroller and algorithms for image processing are implemented on the central system.",https://ieeexplore.ieee.org/document/7090222/,"Proceedings of the 2014 6th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",23-25 Oct. 2014,ieeexplore
10.1109/BioRob49111.2020.9224392,Reinforcement Learning Assist-as-needed Control for Robot Assisted Gait Training,IEEE,Conferences,"The primary goal of an assist-as-needed (AAN) controller is to maximize subjects' active participation during motor training tasks while allowing moderate tracking errors to encourage human learning of a target movement. Impedance control is typically employed by AAN controllers to create a compliant force-field around the desired motion trajectory. To accommodate different individuals with varying motor abilities, most of the existing AAN controllers require extensive manual tuning of the control parameters, resulting in a tedious and time-consuming process. In this paper, we propose a reinforcement learning AAN controller that can autonomously reshape the force-field in real-time based on subjects' training performances. The use of action-dependent heuristic dynamic programming enables a model-free implementation of the proposed controller. To experimentally validate the controller, a group of healthy individuals participated in a gait training session wherein they were asked to learn a modified gait pattern with the help of a powered ankle-foot orthosis. Results indicated the potential of the proposed control strategy for robot-assisted gait training.",https://ieeexplore.ieee.org/document/9224392/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ICRA.2019.8793627,Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT,IEEE,Conferences,"The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.",https://ieeexplore.ieee.org/document/8793627/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICAMechS49982.2020.9310129,Reinforcement Learning based Method for Autonomous Navigation of Mobile Robots in Unknown Environments,IEEE,Conferences,"The Reinforcement Learning is a subset of machine learning that deals with learning decisions from rewards given by the environment. The model classic reinforcement learning (RL) algorithms are usually applied to small sets of states and an action. However, in real applications, the state spaces are of a large scale and this will bring the problems in the generalization and the curse of dimensionality. In this research, authors integrate neural networks into reinforcement learning methods to generalize the value of all the states. The simulation results on the Gazebo software framework show the feasibility of the model proposed method algorithm. The robot can safely navigate an unprotected work environment and becomes a truly intelligent system with the ability to learn and adapt itself to the model.",https://ieeexplore.ieee.org/document/9310129/,2020 International Conference on Advanced Mechatronic Systems (ICAMechS),10-13 Dec. 2020,ieeexplore
10.1109/AI4I46381.2019.00027,Reinforcement Learning of a Robot Cell Control Logic using a Software-in-the-Loop Simulation as Environment,IEEE,Conferences,"This paper introduces a method for automatic robot programming of industrial robots using reinforcement learning on a Software-in-the-loop simulation. The focus of the the paper is on the higher levels of a hierarchical robot programming problem. While the lower levels the skills are stored as domain specific program code, the combination of the skills into a robot control program to solve a specific task is automated. The reinforcement learning learning approach allows the shopfloor workers and technicians just to define the end result of the manufacturing process through a reward function. The programming and process optimization is done within the learning procedure. The Software-in-the-loop simulation with the robot control software makes it possible to to interpret the real program code and generate the exact motion. The exact motion of the robot is needed in order to find not just an optimal but also a collision-free policy.",https://ieeexplore.ieee.org/document/9027783/,2019 Second International Conference on Artificial Intelligence for Industries (AI4I),25-27 Sept. 2019,ieeexplore
10.1109/ROMAN.2006.314459,Reinforcement Learning with Human Teachers: Understanding How People Want to Teach Robots,IEEE,Conferences,"While reinforcement learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a robot a task through reinforcement learning: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback -possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. In conclusion, we discuss future extensions to RL to accommodate these lessons",https://ieeexplore.ieee.org/document/4107833/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/CIRA.2007.382878,Reinforcement Learning with a Supervisor for a Mobile Robot in a Real-world Environment,IEEE,Conferences,"This paper describes two experiments with supervised reinforcement learning (RL) on a real, mobile robot. Two types of experiments were preformed. One tests the robot's reliability in implementing a navigation task it has been taught by a supervisor. The other, in which new obstacles are placed along the previously learned path to the goal, measures the robot's robustness to changes in environment. Supervision consisted of human-guided, remote-controlled runs through a navigation task during the initial stages of reinforcement learning. The RL algorithms deployed enabled the robot to learn a path to a goal yet retain the ability to explore different solutions when confronted with a new obstacle. Experimental analysis was based on measurements of average time to reach the goal, the number of failed states encountered during an episode, and how closely the RL learner matched the supervisor's actions.",https://ieeexplore.ieee.org/document/4269878/,2007 International Symposium on Computational Intelligence in Robotics and Automation,20-23 June 2007,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1109/ICMA.2005.1626784,Reinforcement learning based group navigation approach for multiple autonomous robotic system,IEEE,Conferences,"In several complex applications, the use of multiple autonomous robotic systems (ARS) becomes necessary to achieve different tasks such as foraging and transport of heavy and large objects with less cost and more efficiency. They have to achieve a high level of flexibility, adaptability and efficiency in real environments. In this paper, a reinforcement learning (RL) based group navigation approach for multiple ARS is suggested. Indeed, the robots must have the ability to form geometric figures and navigate without collisions while maintaining the formation. Thus, each robot must learn how to take its place in the formation and avoid obstacles and other ARS from its interaction with the environment. This approach must provide ARS with capability to acquire the group navigation approach among several ARS from elementary behaviors by learning with trial and error search. Then, simulation results display the ability of the suggested approach to provide ARS with capability to navigate in a group formation in dynamic environments.",https://ieeexplore.ieee.org/document/1626784/,"IEEE International Conference Mechatronics and Automation, 2005",29 July-1 Aug. 2005,ieeexplore
10.1109/ICSMC.2012.6377767,Reinforcement learning-based tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal adaptive control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6377767/,"2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",14-17 Oct. 2012,ieeexplore
10.1109/CYBER.2012.6392582,Reinforecement learning-based optimal tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6392582/,"2012 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 May 2012,ieeexplore
10.1109/WCICA.2000.863464,Related value set algorithm for robot to distinguish image,IEEE,Conferences,"The image recognition from image database is different from robot vision in real world because the robot concerned is movable. The size of the image that captured by the robot varies with the distance between robot's camera and the real picture, or object. We analyzed the process of how human remembers and identifies an image. We derived eight properties of the key feature in an image. We then developed a related value set algorithm. With the algorithm, we defined a set to represent the key features of an image. The elements of the set are represented with the related value. The key features retrieved from an image with the algorithm satisfied the eight properties, thus the algorithm can be used for robot to distinguish images or object. The key features can also be used in image knowledge representation.",https://ieeexplore.ieee.org/document/863464/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ISSRE.1993.624285,Reliability of uniprocessor and multiprocessor real-time artificial intelligence planning systems,IEEE,Conferences,"By real-time artificial intelligence (AI) planning systems, we mean those systems embedded in process-control systems that must plan and execute control strategies in response to external events within a real-time constraint. We propose a methodology for estimating the reliability of uniprocessor and multiprocessor real-time AI planning systems. We first discuss why there are intrinsic faults in AI planning programs that must be considered in the reliability modeling of real-time AI planning systems. Then, we show that for uniprocessor systems, no single planning algorithm can avoid all types of intrinsic faults. Finally, we investigate a multiprocessor architecture with parallel planning with the objective of reducing intrinsic faults of real-time AI planning systems and improving the reliability of embedded systems. A robot path-planning system in static domains is used as an example to illustrate our methodology.",https://ieeexplore.ieee.org/document/624285/,Proceedings of 1993 IEEE International Symposium on Software Reliability Engineering,3-6 Nov. 1993,ieeexplore
10.1109/AIID51893.2021.9456477,Research on Privacy Protection Technology in Face Identity Authentication System Based on Edge Computing,IEEE,Conferences,"In today's society, the rapid development of the Internet makes People's Daily life become more intelligent and diversified. Today's society has entered a multifaceted era where everything is interconnected. Artificial intelligence technology is gradually replacing some traditional human services, such as intelligent robot customer service instead of traditional human customer service, intelligent face scanning security check in railway stations instead of traditional manual ticket checking, unmanned supermarket automatic checkout has liberated some social labor costs. All these changes are the result of the development of artificial intelligence technology in today's society. In recent years, unicorn startups focused on biometrics have sprung up all around us, such as BTU and its MEG VII (Face ++). Thanks to the development of Internet and artificial intelligence technology, in many application fields, the traditional access control and identity authentication technology based on password verification is gradually transforming to the scheme based on biometric identification verification. Secure identity authentication is very important to the application of Internet. Face recognition is the most popular technology among all biometric identification technologies. In the field of biometric identification technology, it has become the most widely used technology in the field of identity authentication because of its unique non-invasive, support for infrared and visible light, no need for user cooperation and many other advantages. In the field of education, examinee identification, pedestrian identification detection at the entrance of railway stations, face electronic payment, intelligent video surveillance system, intelligent attendance and access control system, intelligent unmanned supermarkets and customs clearance ports become the pioneer fields of face recognition applications. It can be seen that the era of “national face brushing” has arrived, and the application of face recognition technology will only be more and more widespread in the current era and in the future. However, due to the sensitivity of biometric data and the heterogeneity and openness of network environment, the privacy leakage of biometric data is difficult to avoid. At present, fog computing and edge computing have been paid more and more attention in many fields. In the case that cloud service providers are unable to provide sufficient security, edge computing shows its advantages. In this paper, mobile edge computing is introduced for the first time into the face privacy protection identity authentication system based on cloud server outsourcing computing. It can not only greatly reduce the interaction frequency between users and cloud server, improve the availability and fault tolerance of the system, but also contribute to the implementation of privacy protection scheme. A deep constitutional neural network for face feature extraction is trained using deep learning framework Cafe. Cosine similarity is used to complete face verification. A privacy protection scheme based on the secure nearest neighbor algorithm is proposed, which can not only protect the security of the face feature data at the edge computing node, but also allow the edge computing node to complete the face recognition operation against the encrypted face feature data. In addition, the encryption scheme does not require large computing resources, and the accuracy of face recognition in cipher text is exactly the same as that in explain. At present, most of the solutions either have high computational complexity or poor security performance. How to reduce the computational complexity and improve the real-time performance of the system while ensuring the high security of the private data has important research significance and value. Therefore, in the cloud server outsourcing computing environment, how to complete biometric identification on the premise of protecting the privacy of biological data has become a research hot spot.",https://ieeexplore.ieee.org/document/9456477/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/ICMA.2019.8816557,Research on V-SLAM Methods,IEEE,Conferences,"With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.",https://ieeexplore.ieee.org/document/8816557/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/RCAR47638.2019.9044114,Research on omnidirectional mobile robot motion control based on integration of traction and steering wheel,IEEE,Conferences,"In order to solve the automatic transportation of heavy materials under the limited working space of production workshops and warehouses, two sets of heavy-duty omnidirectional mobile robot motion control systems with steering wheel drive units were designed. The steering wheel combination drive unit of the “walking + steering” set is used to build the mobile robot chassis, and the mechatronics servo system and mathematical model of multi-motor coordinated motion are constructed. The communication between the controller and the steering wheel combination drive unit is established through the CAN bus. The specific implementation is to capture and analyze the control signal through the controller to obtain the desired motion mode, to obtain the motion of each set of steering wheel unit through the mathematical model, and to realize the desired motion through the synthesis of each set of steering wheel unit motion. It has been verified by experiments that the two sets of steering wheel unit-driven mobile robot control system realizes the zero turning radius, 360-degree omnidirectional movement of the robot and rotation during the movement. It can be used for flexible work in tight spaces.",https://ieeexplore.ieee.org/document/9044114/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/WCICA.2004.1343675,Research on remote controlled robot motion control system based on agent theory,IEEE,Conferences,"This paper introduces remote controlled robot motion control system based on agent theory. Task planning and reactive behavior control are discussed and implemented. This paper describes design of manager agent and motion control agent in detail. Agent theory are implemented in the robot control system to realize distributed intelligence based on M/A/R(Man/Agent/Robot) architecture. Thereby autonomy, reliability and real-time operation are improved.",https://ieeexplore.ieee.org/document/1343675/,Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788),15-19 June 2004,ieeexplore
10.1109/ICRA.2019.8794127,Residual Reinforcement Learning for Robot Control,IEEE,Conferences,"Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",https://ieeexplore.ieee.org/document/8794127/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICCSCE.2015.7482163,Review on simultaneous localization and mapping (SLAM),IEEE,Conferences,"Simultaneous localization and mapping (SLAM) is a technique applied in artificial intelligence mobile robot for a self-exploration in numerous geographical environment. SLAM becomes fundamental research area in recent days as it promising solution in solving most of problems which related to the self-exploratory oriented artificial intelligence mobile robot field. For example, the capability to explore without any prior knowledge on environment it explores and without any human interference. The unique feature in SLAM is that the process of mapping and localization is done concurrently and recursively. Since SLAM introduction, many SLAM algorithms have been proposed to apply SLAM technique in real practice. The aim of this paper is to provide an insightful review on information background, recent development, feature, implementation and recent issue in SLAM.",https://ieeexplore.ieee.org/document/7482163/,"2015 IEEE International Conference on Control System, Computing and Engineering (ICCSCE)",27-29 Nov. 2015,ieeexplore
10.1109/AIM.2019.8868670,Rhino: An Open-source Embedded Motherboard Design Enabling Complex Behavior of Intelligent Robots,IEEE,Conferences,"In recent years, Robot Operating System (ROS) has become a de facto standard for many robotic systems. However, there lacks a general-purpose control hardware to perfectly support ROS applications in an embedded fashion. In this paper, we take a hardware/software co-design methodology and a loosely coupled design methodology to develop a ROSoriented motherboard dedicatedly for facilitating high-end intelligent robotic applications. First, orienting around the ROS computational graph level, the hardware/software co-design is proposed to realize a mirrored modular design paradigm. Second, an open-source ROS motherboard, namely the ""Rhino"", is accordingly designed with the highlight of accelerating the embedded neuromorphic computation. Third, real-time performance and feasibility of Rhino are validated at different scales. Experimentation shows that the open-source prototype motherboard is eligible for ROS-based robot development and outperforms the conventional IPC and tailor-made control board. ROS-oriented hardware/software codesign paradigm complements the ROS ecosystem with an open-source AI-enabled motherboard for developing intelligent robots.",https://ieeexplore.ieee.org/document/8868670/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/IROS.1997.656813,RoboCup as a research program,IEEE,Conferences,"An overview of RoboCup (The World Cup Robot Soccer), which offers opportunities for AI and robotics research by providing an attractive but formidable challenge. It also provides a range of challenge programs which is designed to evaluate specific technical issues. The challenge program will be up-dated and new challenges will be offered as technology progresses. Along with other programs such as an education program, RoboCup offers a comprehensive research program which promotes AI and robotics.",https://ieeexplore.ieee.org/document/656813/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/SAIS53221.2021.9483964,Robot First Aid: Autonomous Vehicles Could Help in Emergencies,IEEE,Conferences,"Safety is of critical importance in designing autonomous vehicles (AVs) that will be able to perform effectively in complex, mixed-traffic, real-world urban environments. Some prior research has looked at how to proactively avoid accidents with safe distancing and driver monitoring, but currently little research has explored strategies to recover afterwards from emergencies, from crime to natural disasters. The current short paper reports on our ongoing work using a speculative prototyping approach to explore this expansive design space, in the context of how a robot inside an AV could be deployed to support first aid. As a result, we present some proposals for how to detect emergencies, and examine and help victims, as well as lessons learned in prototyping. Thereby, our aim is to stimulate discussion and ideation that-by considering the prevalence of Murphy's law in our complex world, and the various technical, ethical, and practical concerns raised-could potentially lead to useful safety innovations.",https://ieeexplore.ieee.org/document/9483964/,2021 Swedish Artificial Intelligence Society Workshop (SAIS),14-15 June 2021,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICNSC48988.2020.9238090,Robot Navigation with Map-Based Deep Reinforcement Learning,IEEE,Conferences,"This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",https://ieeexplore.ieee.org/document/9238090/,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",30 Oct.-2 Nov. 2020,ieeexplore
10.1109/IJCNN.2010.5596709,Robot guiding with obstacle avoidance algorithm for uncertain enviroments based on DTCNN,IEEE,Conferences,"This paper introduces two applications of Discrete Time Cellular Non-Linear Networks (DTCNN) in a robot guiding avoiding obstacles algorithm and prove the feasibility of both applications: a high data rate one, using a CMOS camera, and small data rate one, using ultrasonic sensors. The key value of DTCNNs is the locally connections and the parallelism in processing. These characteristics permit a hardware implementation, in our case over a Field Programmable Gate Arraw (FPGA) and a real time template based algorithm processing. A camera and an ultrasonic sensor are used as avoiding obstacles system, requiring both implementations, different inputs informations: the first one complex environment information and the later for basic situations information where impulsive response is required. Both input can have an enhanced behaviour within DTCNN structure.",https://ieeexplore.ieee.org/document/5596709/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/MECHATRONIKA.2014.7018286,Robot imitation of human arm via Artificial Neural Network,IEEE,Conferences,"In this study, a robot arm that can imitate human arm is designed and presented. The potentiometers are located to the joints of the human arm in order to detect movements of human gestures, and data were collected by this way. The collected data named as “movement of human arm” are classified by the help of Artificial Neural Network (ANN). The robot performs its movements according to the classified movements of the human. Real robot and real data are used in this study. Obtained results show that the learning application of imitating human action via the robot was successfully implemented. With this application, the platforms of robot arm in an industrial environment can be controlled more easily; on the other hand, robotic automation systems which have the capability of making a standard movements of a human can become more resistant to the errors.",https://ieeexplore.ieee.org/document/7018286/,Proceedings of the 16th International Conference on Mechatronics - Mechatronika 2014,3-5 Dec. 2014,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ASAMA.1999.805407,Robot media communication: an interactive real-world guide agent,IEEE,Conferences,"Describes a guide system and the software architecture for an autonomous, interactive robot based on a multi-agent system. A robot navigation system has been developed allowing the robot to guide people through halls in various types of exhibitions. Our approach uses an infrared location system in the hallway ceilings, making the environment part of a sensor-distributed robot system. The real-world guide agent is composed of a guide agent on a hand-held mobile computer and a robot agent on an autonomous mobile robot. The guide agent plays the role of ""robot media"" in order to integrate information in the information space of the mobile computer and the physical space of the exhibits in order to guide visitors through the physical space. This research aims to develop a cooperative adaptive system using two-way communication among spaces, media and human beings to construct transparent knowledge boundaries between the real space and the virtual space. The virtual space is generated from computer data using shared space technology and it creates a distributed intelligence in order to manage the communication and control the guide in a laboratory. We have experimented with and verified this software architecture using a prototype autonomous mobile robot equipped with a compass.",https://ieeexplore.ieee.org/document/805407/,"Proceedings. First and Third International Symposium on Agent Systems Applications, and Mobile Agents",6-6 Oct. 1999,ieeexplore
10.1109/ICSMC.2008.4811760,Robot navigation using KFLANN place field,IEEE,Conferences,"This paper presents an implementation of place cells for a robot navigation using the K-iterations fast learning artificial neural networks (KFLANN) clustering algorithm. The KFLANN possesses several desirable properties suitable for place cell robot navigation tasks. The technique proposed is able to autonomously adjust the resolution of cells according to the complexity of the environment. This is achieved through two parameters known as the tolerance and the vigilance of the network. In addition, a navigation system consisting of a topological map building and a place cell path planning strategy is presented. A physical implementation of the system was developed on an autonomous platform and actual results were obtained. The experimental results obtained indicate that the system was able to navigate successfully through the experimental space and also tolerate unexpected discrepancies arising from motor and sensor errors present in a real environment. Furthermore, despite abrupt changes in an environment due to the deliberate introduction of obstacles, the system was still able to cope without changes to the program. The experiment was also extended to include a kidnapped robot scenario and the results were favorable, indicating a positive use of allothetic cue recognition capabilities.",https://ieeexplore.ieee.org/document/4811760/,"2008 IEEE International Conference on Systems, Man and Cybernetics",12-15 Oct. 2008,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/SMC.2016.7844958,Robot position control in pipes using Q Learning,IEEE,Conferences,"In the most critical hydro crisis in Brazil, 37 percent of the whole amount of treated water is wasted before reaching consumers. A robot with a position control to travel inside a pipe is an important step in the pursuit of an autonomous solution to detect and correct pipes failures. This paper shows a Q Learning controller algorithm implemented using a microcontroller in a mechanical body of a commercial pipe inspection robot. Using only the measurements of a gyroscope, and controlling the wheels' motors on the left and right sides, the controller learned the best set of movements to ride inside a 300mm sewer pipe, in the tested conditions. Real tests in a 300mm pipe were performed using the developed algorithm and it was compared to a random movement and to a straight forward movement.",https://ieeexplore.ieee.org/document/7844958/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1145/1957656.1957814,Robot self-initiative and personalization by learning through repeated interactions,IEEE,Conferences,"We have developed a robotic system that interacts with the user, and through repeated interactions, adapts to the user so that the system becomes semi-autonomous and acts proactively. In this work we show how to design a system to meet a user's preferences, show how robot pro-activity can be learned and provide an integrated system using verbal instructions. All these behaviors are implemented in a real platform that achieves all these behaviors and is evaluated in terms of user acceptability and efficiency of interaction.",https://ieeexplore.ieee.org/document/6281377/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/ROBOT.2001.933270,Robotic Antarctic meteorite search: outcomes,IEEE,Conferences,"Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",https://ieeexplore.ieee.org/document/933270/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/IROS.2015.7354310,Robotic agents capable of natural and safe physical interaction with human co-workers,IEEE,Conferences,"Many future application scenarios of robotics envision robotic agents to be in close physical interaction with humans: On the factory floor, robotic agents shall support their human co-workers with the dull and health threatening parts of their jobs. In their homes, robotic agents shall enable people to stay independent, even if they have disabilities that require physical help in their daily life - a pressing need for our aging societies. A key requirement for such robotic agents is that they are safety-aware, that is, that they know when actions may hurt or threaten humans and actively refrain from performing them. Safe robot control systems are a current research focus in control theory. The control system designs, however, are a bit paranoid: programmers build “software fences” around people, effectively preventing physical interactions. To physically interact in a competent manner robotic agents have to reason about the task context, the human, and her intentions. In this paper, we propose to extend cognition-enabled robot control by introducing humans, physical interaction events, and safe movements as first class objects into the plan language. We show the power of the safety-aware control approach in a real-world scenario with a leading-edge autonomous manipulation platform. Finally, we share our experimental recordings through an online knowledge processing system, and invite the reader to explore the data with queries based on the concepts discussed in this paper.",https://ieeexplore.ieee.org/document/7354310/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/SMC.2016.7844571,Robotic attention manager using fuzzy controller with fractal analysis,IEEE,Conferences,"This paper is focused on the application of fractal analysis in the attention management of humanoid robot. We designed a fuzzy controller to combine the face detection, movement detection and the fractal dimension signals to control the head movement of robot Nao. Also, the gaze problem is addressed by the controller. Implementation details are included in the paper, including configuration parameters, which we found optimal according to subjective analysis and possibilities of current hardware. We found the fuzzy controller to be advantageous for implementation of attention manager because of smoothing of the movement of robot when compared to the simple rule based implementation, and also because the fuzzy controller implementation of manager is more clear than a naive if-then heuristics code. We also found the fractal dimension to be useful additional signal for attention management of robot, which can be computed in near real-time on current hardware and static input images.",https://ieeexplore.ieee.org/document/7844571/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1109/ICNN.1993.298695,Robotic modeling and control using a fuzzy neural network,IEEE,Conferences,"A fuzzy neural network (FNN) is applied to modeling and control of a robot. Comparisons are made between the FNN and standard back propagation neural networks, as well as commercially available neural network software packages for modeling the robot. Observations on the robustness of these networks are presented. A number of experiments demonstrate that the FNN can learn faster and more accurately than the back propagation and commercial neural networks for modeling and control of a real robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/298695/,IEEE International Conference on Neural Networks,28 March-1 April 1993,ieeexplore
10.1109/C-CODE.2017.7918964,Robotic navigation based on logic-based planning,IEEE,Conferences,"Logic and Planning are interesting artificial intelligence problems in the context of robotic systems, i.e., robotic navigation. For such an autonomous system one of the requisites is that the goal has to be achieved without intervention of human being. We present a practical implementation of autonomous robotic navigation based on logic-based planning. We achieve this by using strength of PROLOG in order to generate plan to reach goal position from an initial. We utilize First Order Logic (FOL) that automatically asserts and retracts facts at runtime dynamically. All possible plans are computed using local search strategies (e.g., Depth and Breadth First) on state space representing a real, dynamic, and unpredictable environment. In order to navigate in the environment following optimized plan - one with fewest states, a balanced size 4-wheel differential drive robot has been carefully constructed. It can turn 90° and actuate forward by controlling linear (ν<sub>t</sub> = 0.25m/s) and angular (ω<sub>t</sub> = Π/8 rad/s) velocities of two rear motorized wheels. It is also equipped with an Ultrasonic sensor to avoid collision with obstacles. The system is evaluated in an environment comprising of corridors with adjacent rooms. Graphical User Interface (GUI) is developed in .Net (C#) to map situation in Prolog and transmit plan to hardware for execution. Average time calculated for a plan to generate is 0.065 seconds. The robot moves block by block where each block in the state space represents 2m<sup>2</sup> area. In addition to minors, our major contribution is that we offer a unified scheme for robotic navigation without calculating odometry data with the assumption the robot cannot be kidnapped nor slipped.",https://ieeexplore.ieee.org/document/7918964/,"2017 International Conference on Communication, Computing and Digital Systems (C-CODE)",8-9 March 2017,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CVPR46437.2021.00844,Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments,IEEE,Conferences,"Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation, AR, etc. Recent advances estimate the camera pose via optimization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classification network, employed for better 3D scene understanding; and (c) an outlier rejection module used to filter out dynamic points during the hierarchical routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments. It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation.",https://ieeexplore.ieee.org/document/9577932/,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),20-25 June 2021,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/RO-MAN47096.2020.9223566,Robust Real-Time Hand Gestural Recognition for Non-Verbal Communication with Tabletop Robot Haru,IEEE,Conferences,"In this paper, we present our work in close-distance non-verbal communication with tabletop robot Haru through hand gestural interaction. We implemented a novel hand gestural understanding system by training a machine-learning architecture for real-time hand gesture recognition with the Leap Motion. The proposed system is activated based on the velocity of a user's palm and index finger movement, and subsequently labels the detected movement segments under an early classification scheme. Our system is able to combine multiple gesture labels for recognition of consecutive gestures without clear movement boundaries. System evaluation is conducted on data simulating real human-robot interaction conditions, taking into account relevant performance variables such as movement style, timing and posture. Our results show robustness in hand gesture classification performance under variant conditions. We furthermore examine system behavior under sequential data input, paving the way towards seamless and natural real-time close-distance hand-gestural communication in the future.",https://ieeexplore.ieee.org/document/9223566/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CCDC.2019.8832613,Robust Zhang Neural Network for Tracking Control of Parallel Robot Manipulators With Unknown Parameters,IEEE,Conferences,"Under the situation of parameter uncertainty, the tracking control of parallel robot manipulators is a challenging problem in robotic research. Unlike conventional Zhang neural network (ZNN) relying on the assumption that the robot parameter information is fully and accurately known, this paper proposes a robust Zhang neural network (RZNN) for tracking control problems solving of parallel robot manipulators in the absence of parameter information. The proposed RZNN features the full utilization of effector feedback information, and shows a robust tracking performance even with unknown robot parameter information. Then, the continuous-time model of the RZNN is discretized via Euler forward formula (EFF) for numerical implementation. Finally, comprehensive simulative experiments including robustness test verify the effectiveness of the RZNN model for the real-time tracking control of parallel robot manipulators with unknown parameters.",https://ieeexplore.ieee.org/document/8832613/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/HUMANOIDS.2014.7041487,Robust fall detection with an assistive humanoid robot,IEEE,Conferences,"Summary form only given. In this video we introduce a robot assistant that monitors a person in a household environment to promptly detect fall events. In contrast to the use of a fixed sensor, the humanoid robot will track and keep the moving person in the scene while performing daily activities. For this purpose, we extended the humanoid Nao<sup>1</sup> with a depth sensor<sup>2</sup> attached to its head. The tracking framework implemented with OpenNI<sup>3</sup> segments and tracks the person's position and body posture. We use a learning neural framework for processing the extracted body features and detecting abnormal behaviors, e.g. a fall event [1]. The neural architecture consists of a hierarchy of self-organizing neural networks for attenuating noise caused by tracking errors and detecting fall events from video stream in real time. The tracking application, the neural framework, and the humanoid actuators communicate over Robot Operating System (ROS)<sup>4</sup>. We use communication over the ROS network implemented with publisher-subscriber nodes. When a fall event is detected, Nao will approach the person and ask whether assistance is needed. In any case, Nao will take a picture of the scene that can be sent to the caregiver or a relative for further human evaluation and agile intervention. The combination of this sensor technology with our neural network approach allows to tailor the robust detection of falls independently from the background surroundings and in the presence of noise (tracking errors and occlusions) introduced by a real-world scenario. The video shows experiments run in a home-like environment.",https://ieeexplore.ieee.org/document/7041487/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/SII.2011.6147636,Robust localization system using online / offline hybrid learning,IEEE,Conferences,"In this paper, we propose an online motion model parameter estimation method. To achieve accurate localization, accurate estimation of motion model parameters is needed. However, the true values of motion model parameters change sequentially according to alteration of surrounding environments. Therefore the online estimation is absolutely imperative. As a typical method to estimate motion model parameters sequentially, Augmented Kalman Filter (AKF) is there. AKF achieves parameter estimation through Kalman filtering algorithm. However, AKF has serious problems to be implemented in real robot operation. These problems are the accuracy of observation and the limitation to motion control of robots. To solve these problems and achieve accurate motion model parameter estimation, proposed method introduces discriminative training. The introduction of discriminative training increases the convergence performance and stability of parameter estimation through AKF. The proposal method achieves accurate motion model parameter estimation in real robot operation. This paper describes the efficiency of our technique through simulations and an outdoor experiment.",https://ieeexplore.ieee.org/document/6147636/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/ROBOT.2009.5152197,Robust servo-control for underwater robots using banks of visual filters,IEEE,Conferences,"We present an application of machine learning to the semi-automatic synthesis of robust servo-trackers for underwater robotics. In particular, we investigate an approach based on the use of Boosting for robust visual tracking of color objects in an underwater environment. To this end, we use AdaBoost, the most common variant of the Boosting algorithm, to select a number of low-complexity but moderately accurate color feature trackers and we combine their outputs. The novelty of our approach lies in the design of this family of weak trackers, which enhances a straightforward color segmentation tracker in multiple ways. From a large and diverse family of possible filters, we select a small subset that optimizes the performance of our trackers. The tracking process applies these trackers on the input video frames, and the final tracker output is chosen based on the weights of the final array of trackers. By using computationally inexpensive, but somewhat accurate trackers as members of the ensemble, the system is able to run at quasi real-time, and thus, is deployable on-board our underwater robot. We present quantitative cross-validation results of our spatio-chromatic visual tracker, and conclude by pointing out some difficulties faced and subsequent shortcomings in the experiments we performed, along with directions of future research in the area of ensemble tracking in real-time.",https://ieeexplore.ieee.org/document/5152197/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/ICIAS.2012.6306173,SCARA robot control using neural networks,IEEE,Conferences,"A SCARA industrial robot model is identified based on a 4-axis structure using Lagrangian mechanics, also the dynamic model for the electromechanical actuator and motion transmission systems is identified. A conventional PD controller is implemented and compared to neural networks control system to achieve precise position control of SCARA manipulator. The performance of the modeled system is simulated using several desired tracking motion for each joint. Neural networks control method has shown a remarkable improvement of tracking capabilities for the SCARA robot over conventional PD controller. The proposed neural network controller has the potential to accurately control real-time manipulator applications.",https://ieeexplore.ieee.org/document/6306173/,2012 4th International Conference on Intelligent and Advanced Systems (ICIAS2012),12-14 June 2012,ieeexplore
10.1109/ICRA48506.2021.9561020,SQRP: Sensing Quality-aware Robot Programming System for Non-expert Programmers,IEEE,Conferences,"Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot’s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",https://ieeexplore.ieee.org/document/9561020/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICSMC.2001.969840,STNS-R: a learning method for seamless transplantation from a virtual agent to a physical robot,IEEE,Conferences,"In this paper, we are concerned with the problem of how a physical robot can get an appropriate internal representation to its task and environment. Learning from experience is effective for the problem, but it is very time-consuming to learn a representation from the beginning in a real environment. On the other hand, the representation learned only in a simulated environment has the risk of not serving the purpose in a real environment because of the uncertainty in sensors, actuators, and the environment. In, order to have the best of both worlds, it is effective to transplant the learned state representation of a virtual agent to a physical robot. For this purpose., we improved our developed incremental learning architecture for use in the real environment and developed a new architecture, called STNS-R. In this architecture, inappropriate negative instances caused by uncertainties are found on the basis of the distribution of instances and removed in order to correct the distorted shapes of the states. The effectiveness of STNS-R is shown in the experimental results.",https://ieeexplore.ieee.org/document/969840/,"2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236)",7-10 Oct. 2001,ieeexplore
10.23919/ACC.2018.8430770,Safe Reinforcement Learning: Learning with Supervision Using a Constraint-Admissible Set,IEEE,Conferences,"Despite recent advances in Reinforcement Learning (RL), its applications in real-world engineering systems are still rare. The primary reason is that RL algorithms involve exploratory actions that can lead to system constraint violations. These violations can damage physical systems and even cause safety issues, e.g., battery overheat, robot breakdown, and car crashes, hindering RL deployment in many engineering applications. In this paper, we develop a novel safe RL framework that guarantees safety during learning by exploiting a constraint-admissible set for supervision. System knowledge and recursive feasibility techniques are exploited to construct a state-dependent constraint-admissible set. We develop a new learning scheme where the constraint-admissible set regulates the exploratory actions from the RL agent and simultaneously guides the agent to learn the system constraints with a penalty for control regulation. The proposed safe RL algorithm is demonstrated in an adaptive cruise control example where a nonlinear fuel economy cost function is optimized without violating system constraints. We demonstrate that the safe RL agent is able to learn the system constraints to gradually fade out the control supervisor.",https://ieeexplore.ieee.org/document/8430770/,2018 Annual American Control Conference (ACC),27-29 June 2018,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/CCIOT45285.2018.9032441,Segmental Deployment of Neural Network in Cloud Robotic System,IEEE,Conferences,"In this paper, we describe a new method for ep neural networks in the field of computer vision, which can effectively solve the difficulty of applying deep learning in the cloud robotic system. By segmenting the trained network, most of the computing tasks can be cut out and offloaded to the cloud. By effective feature extraction and compression methods, the computing power of robot and cloud can be integrated and coordinated. A method of selecting the split points of the network model and a method of data transmission and compression in the communication between robots and cloud after segmenting are given based on the characteristics of machine vision tasks, and the theoretical analysis is carried out. In the experiment, the effectiveness of all the above methods is verified by comparing the compression capability, response time and network performance of the actual network model. The experimental results show that with the use of segmental methods in cloud robotic system, the task of deep network is processed in real time, while the performance is almost guaranteed.",https://ieeexplore.ieee.org/document/9032441/,2018 IEEE 3rd International Conference on Cloud Computing and Internet of Things (CCIOT),20-21 Oct. 2018,ieeexplore
10.1109/CSSE.2008.1256,Segmentation Methods of Fruit Image and Comparative Experiments,IEEE,Conferences,"Fruit image segmentation issue on color difference between mature fruits and backgrounds under natural illumination condition is an important and difficult content of fruit-harvesting robot vision. Some studies concerning fruit image segmentation have been presented in the last few years. However, these studies are focused on particular fruit and different from segmentation results. In this paper, four kinds of segmentation methods are presented and applied into fruit image segmentation. The tests show that these methods can segment successful several kinds of fruits image, such as apple, tomato, strawberry, persimmon and orange. Dynamic threshold segmentation method has better performance and least cost time than extended Otsu method, improved Otsu combined with genetic arithmetic and adaptive segmentation method based on LVQ network. Meanwhile, it has satisfactory effect upon fruit image under natural illumination condition. Adaptive segmentation method based on LVQ network can only be applied into balanced color instance of particular fruit, and it isnpsilat adapt to be applied into real-time occasion because of high cost time.",https://ieeexplore.ieee.org/document/4721944/,2008 International Conference on Computer Science and Software Engineering,12-14 Dec. 2008,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CIMCA.2005.1631415,Self-Organization of Spiking Neural Network Generating Autonomous Behavior in a Real Mobile Robot,IEEE,Conferences,"In this paper, we study the relation between neural dynamics and robot behavior to develop self-organization algorithm of spiking neural network applicable to autonomous robot. We first formulated a spiking neural network model whose inputs and outputs were analog. We then implemented it into a miniature mobile robot Khepera. In order to see whether or not a solution(s) for the given task exists with the spiking neural network, the robot was evolved with the genetic algorithm (GA) in an environment. The robot acquired the obstacle avoidance and navigation task successfully, exhibiting the presence of the solution. Then, a self-organization algorithm based on the use-dependent synaptic potentiation and depotentiation was formulated and implemented into the robot. In the environment, the robot gradually organized the network and the obstacle avoidance behavior was formed. The time needed for the training was much less than with genetic evolution, approximately one fifth (1/5)",https://ieeexplore.ieee.org/document/1631415/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CEC.2002.1006258,Self-adaptive systems using a massive multi-agent system,IEEE,Conferences,"We deal with systems using massive multi-agent organizations and expressing complex problems like the representation of the world sub-system managing the behavior of a robot. We propose an analysis and an operating representation of multi-agent organization in a geometric way, using specific multi-agent organization in a morphologic agent space. We propose also an architecture expressing the behavior of the massive multi-agent organization. So we open the way to the implementation of self-adaptive systems. We present an application for the behavior of an autonomous robot.",https://ieeexplore.ieee.org/document/1006258/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/TAI.1993.633961,Self-adjusting real-time search: a summary of results,IEEE,Conferences,"Real-time search algorithms need to address the deadlines imposed by applications like process control and robot navigation. Possible deadline violations should be predicted ahead of time to allow remedial actions to prevent the undesirable consequences of missing deadlines. The algorithms should also demonstrate progressively optimizing behavior. That is, they should improve the quality of the solutions as time constraints are relaxed. To successfully address these issues, a real-time search algorithm must address the central problem of choosing the proper values for its parameters, which control the time allocated to planning. The authors propose a new approach to determine the parameter values of a real-time search algorithm, in order to enable the algorithm to meet deadlines, exhibit progressively optimizing behavior, and to predict deadline violation prior to the deadline. They provide a theoretical and experimental characterization of the proposed algorithm.",https://ieeexplore.ieee.org/document/633961/,Proceedings of 1993 IEEE Conference on Tools with Al (TAI-93),8-11 Nov. 1993,ieeexplore
10.1109/ICRA.2016.7487178,Self-learning and adaptation in a sensorimotor framework,IEEE,Conferences,"We present a general framework to autonomously achieve the task of finding a sequence of actions that result in a desired state. Autonomy is acquired by learning sensorimotor patterns of a robot, while it is interacting with its environment. Gaussian processes (GP) with automatic relevance determination are used to learn the sensorimotor mapping. In this way, relevant sensory and motor components can be systematically found in high-dimensional sensory and motor spaces. We propose an incremental GP learning strategy, which discerns between situations, when an update or an adaptation must be implemented. The Rapidly exploring Random Tree (RRT*) algorithm is exploited to enable long-term planning and generating a sequence of states that lead to a given goal; while a gradient-based search finds the optimum action to steer to a neighbouring state in a single time step. Our experimental results prove the suitability of the proposed framework to learn a joint space controller with high data dimensions (10×15). It demonstrates short training phase (less than 12 seconds), real-time performance and rapid adaptations capabilities.",https://ieeexplore.ieee.org/document/7487178/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ISSCAA.2008.4776238,Self-motion planning of redundant robot manipulators based on quadratic program and shown via PA10 example,IEEE,Conferences,"In this paper, a criterion is proposed in the form of a quadratic function for the purpose of self-motion planning of redundant robot arms. The proposed self-motion scheme with joint physical limits considered could be formulated as a quadratic programming (QP) problem subject to equality, (inequality) and bound constraints. A primal-dual neural network based on linear variational inequalities (LVI) is developed as the real-time solver for the resultant quadratic-program. The so-called LVI-based primal-dual neural network has a simple piecewise-linear dynamics and a global exponential convergence to optimal solutions of QP problems. Computer-simulations performed based on PA10 robot arm substantiate the efficacy of the proposed QP-based neural self-motion-planning scheme.",https://ieeexplore.ieee.org/document/4776238/,2008 2nd International Symposium on Systems and Control in Aerospace and Astronautics,10-12 Dec. 2008,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/ICSMC.1997.625763,Self-organized learning and its implementation of robot movements,IEEE,Conferences,The self-organizing map algorithm using an artificial neural network originally developed by Kohonen and extended and modified later provides a distributed and autonomous learning procedure in engineering modeling of the human sensory-motor mapping mechanism. Its extension and adaptation to a control problem of a robot manipulator has been intensively discussed in past years. In this article the application of the self-organizing map algorithm to the generation of a visuo-motor map is focused on. A task-oriented inverse kinematic solution to a redundant manipulator is formed and real-time implementation of the map on a mechanical manipulator is performed.,https://ieeexplore.ieee.org/document/625763/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ROBOT.2006.1642213,Self-organizing approach for robot's behavior imitation,IEEE,Conferences,"In this paper, an approach for behavior imitation using visual information was introduced. The imitation process is done by a self organizing neural network module. From several demonstrations of task operation, a vision system captures movement of the demonstrator mobile robot and associated objects in an operation field. Then, the movement features are extracted to present to an imitation engine. Finally, skill or decision policy from teacher's demonstration is extracted and embedded into a self organizing neural network without explicit external supervisory signals. A simple action selection algorithm for choosing action from learned network is proposed. The algorithm was implemented and tested on a simulated robot and a real mobile robot to imitate two simple robot soccer behaviors: approaching the target and obstacle avoidance. Furthermore, the concept of similarity measure is introduced to evaluate imitation performance from the demonstrator",https://ieeexplore.ieee.org/document/1642213/,"Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.",15-19 May 2006,ieeexplore
10.1109/FPA.1994.636137,Self-organizing map for reinforcement learning: obstacle-avoidance with Khepera,IEEE,Conferences,We present a self-organizing map implementation of the Q-learning algorithm. Our goal is to overcome the problems of reinforcement learning: memory requirement and generalization. We consider the map as an associative memory and we use it for obstacle avoidance with the mobile robot Khepera. Results allow real world applications to be envisaged using neural reinforcement learning.,https://ieeexplore.ieee.org/document/636137/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/IJCNN.2016.7727359,Self-repairing mobile robotic car using astrocyte-neuron networks,IEEE,Conferences,"A self-repairing robot utilising a spiking astrocyte-neuron network is presented in this paper. It uses the output spike frequency of neurons to control the motor speed and robot activation. A software model of the astrocyte-neuron network previously demonstrated self-detection of faults and its self-repairing capability. In this paper the application demonstrator of mobile robotics is employed to evaluate the fault-tolerant capabilities of the astrocyte-neuron network when implemented in a hardware-based robotic car system. Results demonstrated that when 20% or less synapses associated with a neuron are faulty, the robot car can maintain system performance and complete the task of forward motion correctly. If 80% synapses are faulty, the system performance shows a marginal degradation, however this degradation is much smaller than that of conventional fault-tolerant techniques under the same levels of faults. This is the first time that astrocyte cells merged within spiking neurons demonstrates a self-repairing capabilities in the hardware system for a real application.",https://ieeexplore.ieee.org/document/7727359/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/IROS45743.2020.9340814,SelfieDroneStick: A Natural Interface for Quadcopter Photography,IEEE,Conferences,"A physical selfie stick extends the user's reach, enabling the acquisition of personal photos that include more of the background scene. Similarly, a quadcopter can capture photos from vantage points unattainable by the user; but teleoperating a quadcopter to good viewpoints is a difficult task. This paper presents a natural interface for quadcopter photography, the SelfieDroneStick that allows the user to guide the quadcopter to the optimal vantage point based on the phone's sensors. Users specify the composition of their desired long-range selfies using their smartphone, and the quadcopter autonomously flies to a sequence of vantage points from where the desired shots can be taken. The robot controller is trained from a combination of real-world images and simulated flight data. This paper describes two key innovations required to deploy deep reinforcement learning models on a real robot: 1) an abstract state representation for transferring learning from simulation to the hardware platform, and 2) reward shaping and staging paradigms for training the controller. Both of these improvements were found to be essential in learning a robot controller from simulation that transfers successfully to the real robot.",https://ieeexplore.ieee.org/document/9340814/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROMAN.2008.4600739,Semantic category acquisition in dialogue for interactive object learning,IEEE,Conferences,"An important aspect of humanoid robots in a natural environment is the ability to acquire new knowledge through learning mechanisms, which enhances an artificial system with the ability to adapt to a changing or new environment. In contrast to most learning algorithms applied in machine learning today, which mainly work with offline learning on training samples, such learning mechanisms need to be performed autonomously and through interaction with the environment or with other agents/humans. In this paper we describe a learning algorithm as a dialogue approach for learning semantic categories and object description in object learning. New objects are introduced to the robot and learning dialogues are conducted as a means of information acquisition. In dialogue, the robot can acquire semantic categories, type and properties of objects, learn new words for object descriptions and learn and association to visual identification from object recognition. In contrast to existing work, this approach combines recognition of real objects, new words learning and semantic categories in one learning dialogue. The presented approach has been implemented in a dialogue system and evaluated on the humanoid robot Armar III.",https://ieeexplore.ieee.org/document/4600739/,RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,1-3 Aug. 2008,ieeexplore
10.1109/ROBOT.1996.506506,Semantic learning by an autonomous mobile robot,IEEE,Conferences,Describes the design and implementation of a learning system for control of an autonomous mobile robot. The robot learns reactive behaviors that allow it to retreat from potential collisions and to explore its environment by seeking out nearby objects. No external teaching input is required. Results from experiments with a real robot are presented. The learned reactive behaviors become the basis for the acquisition of more complex behaviors. Sensory/motor states are classified and then associated with lexical items to form a simple command language which is then used to direct the robot.,https://ieeexplore.ieee.org/document/506506/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/ICUAS48674.2020.9214063,Semantic situation awareness of ellipse shapes via deep learning for multirotor aerial robots with a 2D LIDAR,IEEE,Conferences,"In this work, we present a semantic situation awareness system for multirotor aerial robots equipped with a 2D LIDAR sensor, focusing on the understanding of the environment, provided to have a drift-free precise localization of the robot (e.g. given by GNSS/INS or motion capture system). Our algorithm generates in real-time a semantic map of the objects of the environment as a list of ellipses represented by their radii, and their pose and velocity, both in world coordinates. Two different Convolutional Neural Network (CNN) architectures are proposed and trained using an artificially generated dataset and a custom loss function, to detect ellipses in a segmented (i.e. with one single object) LIDAR measurement. In cascade, a specifically designed indirect-EKF estimates the ellipses based semantic map in world coordinates, as well as their velocity. We have quantitative and qualitatively evaluated the performance of our proposed situation awareness system. Two sets of Software-In-The-Loop simulations using CoppeliaSim with one and multiple static and moving cylindrical objects are used to evaluate the accuracy and performance of our algorithm. In addition, we have demonstrated the robustness of our proposed algorithm when handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) objects and moving persons.",https://ieeexplore.ieee.org/document/9214063/,2020 International Conference on Unmanned Aircraft Systems (ICUAS),1-4 Sept. 2020,ieeexplore
10.1109/IROS.2017.8206048,Sensor fusion for robot control through deep reinforcement learning,IEEE,Conferences,"Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information generated by multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",https://ieeexplore.ieee.org/document/8206048/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/RO-MAN50785.2021.9515358,Sequential Prediction with Logic Constraints for Surgical Robotic Activity Recognition,IEEE,Conferences,"Many real-world time-sensitive and high-stake applications (e.g., surgical, rescue, and recovery robotics) exhibit sequential nature; thus, applying Recurrent Neural Network (RNN)-based sequential models is an attractive approach to detect robotic activity. One limitation of such approaches is data scarcity. As a result, limited training samples may lead to over-fitting, producing incorrect predictions during deployment. Nevertheless, abundant domain knowledge may still be available, which may help formulate logic constraints. In this paper, we propose a novel way to integrate domain knowledge into RNN-based sequential prediction. We build a Markov Logic Network (MLN)-based classifier that automatically learns constraint weights from data. We propose two methods to incorporate this MLN-based prediction: (i) PriorLayer, in which the values of the hidden layer of the RNN are combined with weights learned from logic constraints in an additional neural network layer, and (ii) Conflation, in which class probabilities from RNN predictions and constraint weights are combined based on the conflation of class probabilities. We evaluate robotic activity classification methods on a simulated OpenAI Gym environment and a real-world DESK dataset for surgical robotics. We observe that our proposed MLN-based approaches boost the performance of LSTM-based networks. In particular, MLN boosts the accuracy of LSTM from 71% to 84% on the Gym dataset and from 68% to 72% on the Taurus robot dataset. Furthermore, MLN (i.e., PriorLayer) shows regularization capability where it improves accuracy in initial LSTM training while avoiding over-fitting early, thus improves the final classification accuracy on unseen data. The code is available at https://github.com/masud99r/prediction-with-logic-constraints.",https://ieeexplore.ieee.org/document/9515358/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/KIMAS.2003.1245110,Sharing learning policies between multiple mobile robots,IEEE,Conferences,"Learning of a complex task usually requires a long learning period. In order to reduce the time of learning, the task is divided into several subtasks. Multiple agents can be used to serve a complex task by learning these subtasks concurrently. With a good knowledge sharing mechanism, the learning policy can be shared or exchanged among these agents and can enhance their learning efficiency. The learning policy is a mapping from system states to actions. The mechanism of sharing or exchanging learning knowledge among multiagent system is proposed. An index of expertise, which indicates the skill level of each learning agent, is presented. This index is used to select the best preferable advice among multiple advices, which can increase the probability of finding solution in the search space. The experiment in which the learning knowledge is exchanged between a mobile robot and a computer simulated agent is implemented in order to verify the validity of the proposed algorithm. The experimental results show that the learning efficiency of the advisor agent is increased and the advisee robot can use the given advice for avoiding collision with obstacle successfully in the real world implementation.",https://ieeexplore.ieee.org/document/1245110/,IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change (IEEE Cat. No.03CH37502),30 Sept.-4 Oct. 2003,ieeexplore
10.1109/CVPR.2019.01165,Sim-Real Joint Reinforcement Transfer for 3D Indoor Navigation,IEEE,Conferences,"There has been an increasing interest in 3D indoor navigation, where a robot in an environment moves to a target according to an instruction. To deploy a robot for navigation in the physical world, lots of training data is required to learn an effective policy. It is quite labour intensive to obtain sufficient real environment data for training robots while synthetic data is much easier to construct by render-ing. Though it is promising to utilize the synthetic environments to facilitate navigation training in the real world, real environment are heterogeneous from synthetic environment in two aspects. First, the visual representation of the two environments have significant variances. Second, the houseplans of these two environments are quite different. There-fore two types of information,i.e. visual representation and policy behavior, need to be adapted in the reinforce mentmodel. The learning procedure of visual representation and that of policy behavior are presumably reciprocal. We pro-pose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy. Specifically, our method employs an adversarial feature adaptation model for visual representation transfer anda policy mimic strategy for policy behavior imitation. Experiment shows that our method outperforms the baseline by 19.47% without any additional human annotations.",https://ieeexplore.ieee.org/document/8953924/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/ICRA40945.2020.9197512,Sim-to-Real Transfer for Optical Tactile Sensing,IEEE,Conferences,"Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.",https://ieeexplore.ieee.org/document/9197512/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/LARS-SBR-WRE48964.2019.00060,Sim-to-Real in Reinforcement Learning for Everyone,IEEE,Conferences,"In reinforcement learning (RL), it remains a challenge to have a robotic agent perform a task in the real world for which it was trained in simulation. In this paper, we present our work training a low-cost robotic arm in simulation to move towards a predefined target in space, represented by a red ball in an RGB image, and transferring the capability to the real arm. We exercised the entire end-to-end flow including the 3D modeling of the arm, training of a state-of-the-art RL policy in simulation with multiple actors in a distributed fashion, domain randomization in order to close the sim-to-real gap, and finally the execution of the trained model in the real robot. We also implemented a mechanism to edit the image captured from the camera before sending it to the model for inference, which allowed us to automate reward computation in the physical world. Our work highlights important challenges of training RL agents and moving them to the real world, validating important aspects shown by other works as well as detailing steps not explained by some of them (e.g. how to compute the reward in the real world). The conducted experiments show the improvements observed as the techniques were added to the final solution.",https://ieeexplore.ieee.org/document/9018558/,"2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE)",23-25 Oct. 2019,ieeexplore
10.1109/EMBC44109.2020.9176182,Simple Kinematic Feedback Enhances Autonomous Learning in Bio-Inspired Tendon-Driven Systems,IEEE,Conferences,"Error feedback is known to improve performance by correcting control signals in response to perturbations. Here we show how adding simple error feedback can also accelerate and robustify autonomous learning in a tendon-driven robot. We have implemented two versions of the General-to-Particular (G2P) autonomous learning algorithm using a tendon-driven leg with two joints and three tendons: one with and one without real-time kinematic feedback. We have performed a rigorous study on the performance of each system, for both simulation and physical implementation cases, over a wide range of tasks. As expected, feedback improved performance in simulation and hardware. However, we see these improvements even in the presence of sensory delays of up to 100 ms and when experiencing substantial contact collisions. Importantly, feedback accelerates learning and enhances G2P's continual refinement of the initial inverse map by providing the system with more relevant data to train on. This allows the system to perform well even after only 60 seconds of initial motor babbling.",https://ieeexplore.ieee.org/document/9176182/,2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),20-24 July 2020,ieeexplore
10.1109/IJCNN.2000.859462,"Simulating the evolution of 2D pattern recognition on the CAM-Brain Machine, an evolvable hardware tool for building a 75 million neuron artificial brain",IEEE,Conferences,"This paper presents some simulation results of the evolution of 2D visual pattern recognizers to be implemented very shortly on real hardware, namely the ""CAM-Brain Machine"" (CBM), an FPGA based piece of evolvable hardware which implements a genetic algorithm (GA) to evolve a 3D cellular automata (CA) based neural network circuit module, of approximately 1,000 neurons, in about a second, i.e. a complete run of a GA, with tens of thousands of circuit growths and performance evaluations. Up to 65,000 of these modules, each of which is evolved with a humanly specified function, can be downloaded into a large RAM space, and interconnected according to humanly specified artificial brain architectures. This RAM, containing an artificial brain with up to 75 million neurons, is then updated by the CBM at a rate of 130 billion CA cells per second. Such speeds will enable real time control of robots and hopefully the birth of a new research field that we call ""brain building"". The first such artificial brain, to be built at STARLAB in 2000 and beyond, will be used to control the behaviors of a life sized kitten robot called ""Robokitty"". This kitten robot will need 2D pattern recognizers in the visual section of its artificial brain. This paper presents simulation results on the evolvability and generalization properties of such recognizers.",https://ieeexplore.ieee.org/document/859462/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/CCDC.2008.4597309,Simulation of robot localization based on virtual sensors,IEEE,Conferences,"A flexible simulation frame based on concept of component is presented. An indoor robots localization simulation environment based on virtual sensors RoboSimer is built with OpenGL. The parameters here are easily adjusted and controlled by customs and the simulation module is easy to integrate. It can integrate any sensors, environment and robot shape into the simulation software. The interfaces of simulation software are coincided with the real hardware platform. It provides a convenient condition for the further study on robot localization.",https://ieeexplore.ieee.org/document/4597309/,2008 Chinese Control and Decision Conference,2-4 July 2008,ieeexplore
10.1109/ICBAIE52039.2021.9390015,Simulation of underwater vehicle control based on code generation technology,IEEE,Conferences,"Model-based design is an effective means for rapid development of embedded software, and automatic code generation is an important technology for model-based development. Combining the automatic code generation method of Matlab and STM32 with the operation and control of the autonomous underwater robot makes the design of the system more convenient. Use tools such as the Simulink library STM32 MAT/Target and STM32 CubeMX of the STM32 microcontroller to realize the automatic generation of readable and portable C code project files. At the same time, based on the design of the model, the control code of the autonomous underwater robot(AUV) is automatically generated, and the control code is added to the automatically generated C code project file. With Matlab/Simulink as the basic software platform, the motion controller of AUV is mounted on the STM32F407, and a real-time simulation system for the closed-loop control of AUV manipulation motion is constructed. The results of the semiphysical real-time simulation test show that the AUV motion controller has good heading depth control performance, realizes the manipulation and control of AUV, and verifies the practicability of the automatically generated code.",https://ieeexplore.ieee.org/document/9390015/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore
10.1109/IROS.2018.8593518,Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization,IEEE,Conferences,"Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.",https://ieeexplore.ieee.org/document/8593518/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICAR.2015.7251437,Simultaneous human-robot adaptation for effective skill transfer,IEEE,Conferences,"In this paper, we propose and implement a human-in-the loop robot skill synthesis framework that involves simultaneous adaptation of the human and the robot. In this framework, the human demonstrator learns to control the robot in real-time to make it perform a given task. At the same time, the robot learns from the human guided control creating a non-trivial coupled dynamical system. The research question we address is how this system can be tuned to facilitate faster skill transfer or improve the performance level of the transferred skill. In the current paper we report our initial work for the latter. At the beginning of the skill transfer session, the human demonstrator controls the robot exclusively as in teleoperation. As the task performance improves the robot takes increasingly more share in control, eventually reaching full autonomy. The proposed framework is implemented and shown to work on a physical cart-pole setup. To assess whether simultaneous learning has advantage over the standard sequential learning (where the robot learns from the human observation but does not interfere with the control) experiments with two groups of subjects were performed. The results indicate that the final autonomous controller obtained via simultaneous learning has a higher performance measured as the average deviation from the upright posture of the pole.",https://ieeexplore.ieee.org/document/7251437/,2015 International Conference on Advanced Robotics (ICAR),27-31 July 2015,ieeexplore
10.1109/IROS.1990.262374,"Single leg walking with integrated perception, planning and control",IEEE,Conferences,"Describes an integrated system capable of walking over rugged terrain using a single leg suspended below a carriage that rolls along rails. To walk, the system uses a laser scanner to find a foothold, positions the leg above the foothold, contacts the terrain with the foot, and applies force enough to advance the carriage along the rails. Walking both forward and backward, the system has traversed hundreds of meters of rugged terrain including obstacles too tall to step over, trenches too deep to step in, closely spaced rocks, and sand hills. The implemented system consists of a number of task-specific processes (two for planning, two for perception, one for real-time control) and a central control process that directs the flow of communication between processes. Implementing this integrated system is a significant step toward the goal of the CMU Planetary Rover project: to prototype a autonomous six-legged robot for planetary exploration.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/262374/,"EEE International Workshop on Intelligent Robots and Systems, Towards a New Frontier of Applications",3-6 July 1990,ieeexplore
10.1109/ICCVW.2017.84,SkiMap++: Real-Time Mapping and Object Recognition for Robotics,IEEE,Conferences,"We introduce SkiMap++, an extension to the recently proposed SkiMap mapping framework for robot navigation [1]. The extension deals with enriching the map with semantic information concerning the presence in the environment of certain objects that may be usefully recognized by the robot, e.g. for the sake of grasping them. More precisely, the map can accommodate information about the spatial locations of certain 3D object features, as determined by matching the visual features extracted from the incoming frames through a random forest learned off-line from a set of object models. Thereby, evidence about the presence of object features is gathered from multiple vantage points alongside with the standard geometric mapping task, so to enable recognizing the objects and estimating their 6 DOF poses. As a result, SkiMap++ can reconstruct the geometry of large scale environments as well as localize some relevant objects therein (Fig.1) in real-time on CPU. As an additional contribution, we present an RGB-D dataset featuring ground-truth camera and object poses, which may be deployed by researchers interested in pursuing SLAM alongside with object recognition, a topic often referred to as Semantic SLAM<sup>1</sup>.",https://ieeexplore.ieee.org/document/8265293/,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),22-29 Oct. 2017,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICHR.2010.5686285,SkyAI: Highly modularized reinforcement learning library,IEEE,Conferences,"This paper introduces a software library of reinforcement learning (RL) methods, named SkyAI. SkyAI is a highly modularized RL library for real/simulated robots to learn behaviors. Our ultimate goal is to develop an artificial intelligence (AI) program with which the robots can learn to behave as their users' wish. In this paper, we describe the concepts, the requirements, and the current implementation of SkyAI. SkyAI provides two conflicting features: high execution-speed enough for real robot systems and high flexibility to design learning systems. We also demonstrate the applications to crawling tasks of both a humanoid robot in simulation and a real spider robot.",https://ieeexplore.ieee.org/document/5686285/,2010 10th IEEE-RAS International Conference on Humanoid Robots,6-8 Dec. 2010,ieeexplore
10.1109/SaCoNeT.2018.8585616,Smart Navigation of Mobile Robot Using Neural Network Controller,IEEE,Conferences,"The field of autonomous navigation of mobile robot is advancing so fast especially with the development of machine learning algorithms. This study aims to introduce a neural network controller that controls the trajectory and the obstacle avoidance of a non-holonomic mobile robot.We train the robot in environment containing multiple obstacles with different places. This paper includes both a kinematic and a dynamic study of a mobile robot. Different training schemes have been studied that tackle the learning objectives differently. The trained controller is producing the Pulse Width Modulation (PWM) signals that could be implemented in a microprocessor and validated by simulations. Unlike some other recent approaches, this work was validated by a 3D simulation which is similar to the real model.",https://ieeexplore.ieee.org/document/8585616/,2018 International Conference on Smart Communications in Network Technologies (SaCoNeT),27-31 Oct. 2018,ieeexplore
10.1109/ISC2.2016.7580798,SmartSEAL: A ROS based home automation framework for heterogeneous devices interconnection in smart buildings,IEEE,Conferences,"With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",https://ieeexplore.ieee.org/document/7580798/,2016 IEEE International Smart Cities Conference (ISC2),12-15 Sept. 2016,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/IROS45743.2020.9341328,Software Development Framework for Cooperating Robots with High-level Mission Specification,IEEE,Conferences,"In recent years, there has been a growing interest in multiple robots performing a single task through different types of collaboration. There are two software challenges when deploying collaborative robots: how to specify a cooperative mission and how to program each robot to accomplish its mission. In this paper, we propose a novel software development framework to support distributed robot systems, swarm robots, and their hybrid. We extend the service-oriented and model-based (SeMo) framework [1] to improve the robustness, scalability, and flexibility of robot collaboration. To enable a casual user to specify various types of cooperative missions easily, the high-level mission scripting language is extended with new features such as team hierarchy, group service, one-to-many communication. The script program is refined to the robot codes through two intermediate steps, strategy description and task graph generation, in the proposed framework. The viability of the proposed framework is evidenced by two preliminary experiments using real robots and a robot simulator.",https://ieeexplore.ieee.org/document/9341328/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROBOT.2004.1308781,Software approach for the autonomous inspection robot MAKRO,IEEE,Conferences,"The sewer inspection robot MAKRO is an autonomous multi-segment robot with worm-like shape driven by wheels. It is currently under development in the project MAKRO-PLUS. The robot has to navigate autonomously within sewer systems. Its first tasks is to take water probes, analyze them onboard, and measure positions of manholes and pipes to detect pollution loaded sewage and to improve current maps of sewer systems. One of the challenging problems is the control software, which should enable the robot to navigate in the sewer system and perform the inspection tasks autonomously, while always taking care of its own safety. Tests in our test environment and in a real sewer system show promising results. This paper focuses on the software approach. To manage the complexity a layered architecture has been chosen, each layer defining a different level of abstraction. After determining the abstraction levels, we use different methods for implementation. For the highest abstraction level a standard AI-planning algorithm is used. For the next level, finite state automata has been chosen. For ""simple"" task implementation we use a modular C++ based method (MCA2), which is also used on the lowest software level.",https://ieeexplore.ieee.org/document/1308781/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/ICMLC.2003.1259766,Spatio-temporal representation for multi-dimensional occlusion relation,IEEE,Conferences,"Occlusion relation is the topological relation between the images of two bodies from a viewpoint. Qualitative representation of occlusion relation has been investigated in qualitative spatial reasoning. This research is important for computer vision and robot navigation. The previous models such as LOS and ROC-20 are all based on RCC (the famous topological theory). But those models couldn't support abstract objects such as point and line which are very common in real applications. To deal with this, multi-dimensional spatial occlusion relation (MSO) is put forward. The foundation of MSO is MRCC which is the multi-dimensional extension of RCC. So MSO is suitable for both real and abstract objects. The conception neighborhood and composition of MSO is given. Finally MSO is extended to spatio-temporal relation by adding time feature. MSO is an appropriate frame to express spatio-temporal knowledge.",https://ieeexplore.ieee.org/document/1259766/,Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693),5-5 Nov. 2003,ieeexplore
10.1109/IROS.1996.570655,Specification and validation of a control architecture for autonomous mobile robots,IEEE,Conferences,"We describe the specification of a software control architecture for autonomous mobile robots. The architecture, designed to provide the robot (in a task-dependent context) with the capacity to react to events but also to intelligently anticipate the future and plan its actions, is based on the decomposition of the robot system into a functional and a decisional level. The article is mainly focused on some aspects of the organisation and of the operation of the system such as execution control, inter-levels communication, reactivity. An important aspect that is developed is the possibility to prove some temporal and logical properties of parts of the system.",https://ieeexplore.ieee.org/document/570655/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/HPCS48598.2019.9188104,Staged deployment of interactive multi-application HPC workflows,IEEE,Conferences,"Running scientific workflows on a supercomputer can be a daunting task for a scientific domain specialist. Workflow management solutions (WMS) are a standard method for reducing the complexity of application deployment on high performance computing (HPC) infrastructure. We introduce the design for a middleware system that extends and combines the functionality from existing solutions in order to create a high-level, staged usercentric operation/deployment model. This design addresses the requirements of several use cases in the life sciences, with a focus on neuroscience. In this manuscript we focus on two use cases: 1) three coupled neuronal simulators (for three different space/time scales) with in-transit visualization and 2) a closed-loop workflow optimized by machine learning, coupling a robot with a neural network simulation. We provide a detailed overview of the application-integrated monitoring in relationship with the HPC job. We present here a novel usage model for large scale interactive multi-application workflows running on HPC systems which aims at reducing the complexity of deployment and execution, thus enabling new science.",https://ieeexplore.ieee.org/document/9188104/,2019 International Conference on High Performance Computing & Simulation (HPCS),15-19 July 2019,ieeexplore
10.1109/ROBOT.1996.506888,Stereo sketch: stereo vision-based target reaching behavior acquisition with occlusion detection and avoidance,IEEE,Conferences,"In this paper, we proposed a method by which a stereo vision-based mobile robot learns to reach a target by detecting and avoiding occlusions. We call the internal representation that describes the learning behavior ""stereo sketch"". First, an input scene is segmented into homogeneous regions by the enhanced ISODATA algorithm with minimum description length principle in terms of image coordinates and disparity information obtained from the fast stereo matching unit based on the coarse-to-fine control method. Then, in terms of the segmented regions including the target area and their occlusion status identified during the stereo and motion disparity estimation process, we construct a state space for the reinforcement learning method to obtain a target reaching behavior. As a result the robot can avoid obstacles without explicitly describing them. We give the computer simulation results and real robot implementation to show the validity of our method.",https://ieeexplore.ieee.org/document/506888/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/CISIM.2008.21,Strategy Description and Modelling for Multi-Agent Systems,IEEE,Conferences,"The field of robot soccer provides numerous opportunities for the application of AI methods for game strategy development. Robot soccer is a part of standard applications of distributed system control in real time. The software part of a distributed control system is realized by decision making and executive agents. The algorithm of agents' cooperation was proposed with the control agent on a higher level. The algorithms for agents realized in robots are the same. Real-time dynamic simple strategy description and strategy learning possibility based on game observation is important for discovering opponent's strategies and searching for tactical group movements, simulation and synthesis of suitable counter-strategies. For the improvement of game strategy, we are developing an abstract description of the game and propose ways to use this description (e.g. for learning rules and adapting team strategies to every single opponent).",https://ieeexplore.ieee.org/document/4557834/,2008 7th Computer Information Systems and Industrial Management Applications,26-28 June 2008,ieeexplore
10.1109/UKSIM.2008.117,Strategy Description and Modelling for Multi-agent Systems (Invited Paper),IEEE,Conferences,"The field of robot soccer provides numerous opportunities for the application of AI methods for game strategy development. Robot soccer is a part of standard applications of distributed system control in real time. The software part of a distributed control system is realized by decision making and executive agents. The algorithm of agents’ cooperation was proposed with the control agent on a higher level. The algorithms for agents realized in robots are the same. Real-time dynamic simple strategy description and strategy learning possibility based on game observation is important for discovering opponents strategies and searching for tactical group movements, simulation and synthesis of suitable counter-strategies. For the improvement of game strategy, we are developing an abstract description of the game and propose ways to use this description (e.g. for learning rules and adapting team strategies to every single opponent).",https://ieeexplore.ieee.org/document/4489006/,Tenth International Conference on Computer Modeling and Simulation (uksim 2008),1-3 April 2008,ieeexplore
10.1109/ICCE46568.2020.9042995,Stroke Signs Detection System by SNS Agency Robot,IEEE,Conferences,"This paper proposes a system which implements the Cincinnati Prehospital Stroke Scale (CPSS), the widely used screening method for the initial symptoms of a stroke, in a communication robot. AI on cloud analyses an acquired video through a conversation with the robot in real time and automatically determines the abnormalities. The judgement result is informed to his/her families by SNS. This study implemented two of the three CPSS scales such as “Arms” and “Speech”, we confirmed that the system enables to acquire, analyze and notify the information in real time.",https://ieeexplore.ieee.org/document/9042995/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/RTAS48715.2020.00-20,SubFlow: A Dynamic Induced-Subgraph Strategy Toward Real-Time DNN Inference and Training,IEEE,Conferences,"We introduce SubFlow-a dynamic adaptation and execution strategy for a deep neural network (DNN), which enables real-time DNN inference and training. The goal of SubFlow is to complete the execution of a DNN task within a timing constraint that may dynamically change while ensuring comparable performance to executing the full network by executing a subset of the DNN at run-time. To this end, we propose two online algorithms that enable SubFlow: 1) dynamic construction of a sub-network which constructs the best subnetwork of the DNN in terms of size and configuration, and 2) time-bound execution which executes the sub-network within a given time budget either for inference or training. We implement and open-source SubFlow by extending TensorFlow with full compatibility by adding SubFlow operations for convolutional and fully-connected layers of a DNN. We evaluate SubFlow with three popular DNN models (LeNet-5, AlexNet, and KWS), which shows that it provides flexible run-time execution and increases the utility of a DNN under dynamic timing constraints, e.g., lx-6.7x range of dynamic execution speed with average -3% of performance (inference accuracy) difference. We also implement an autonomous robot as an example system that uses SubFlow and demonstrate that its obstacle detection DNN is flexibly executed to meet a range of deadlines that varies depending on its running sped.",https://ieeexplore.ieee.org/document/9113121/,2020 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS),21-24 April 2020,ieeexplore
10.1109/IJCNN.2008.4634389,Supporting mixed initiative human-robot interaction: A script-based cognitive architecture approach,IEEE,Conferences,"As complex indoor-robot systems are developed and deployed into the real-world, the demand for human-robot interaction is increasing. Mixed-initiative human-robot interaction is a good method to coordinate actions of a human and a robot in a complementary fashion. In order to support such interactions, we employ scripts that are rich, flexible, and extensible for a robotpsilas interactions in a variety of situations. Scripts are amenable for expressing knowledge in an applicable form, especially describing a sequence of actions in organizing tasks. In this paper, we propose a script-based cognitive architecture for collaboration, which is based on three-level cognitive models. It incorporates dynamic Bayesian network (DBN) to automatically govern action sequences in the scripts and detect userpsilas intention or goal. Starting from an understanding of user initiatives, our intelligent task manager suggests the most relevant initiatives for an efficient collaboration. DBN has been evaluated in real indoor task scenarios for its efficacy in interaction reduction, error minimization, and task satisfaction.",https://ieeexplore.ieee.org/document/4634389/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ISIC.1991.187403,Symbolic feature-based representation and planning for an agent based robot controller,IEEE,Conferences,"A prototype system has been developed to input 3-D computer-aided-design (CAD) data to automatically generate and implement robot trajectories for such application as waterjet cutting, surface finishing and polishing. The system can drive various robot configurations and handle contingencies such as collisions and singularities. The system provides a framework for integration of high-level reasoning, real-time path and trajectory planning, and various levels of feedback based on contingency detection algorithms or sensor data. Although initial CAD data have been in the form of IGES geometric entities, a higher-level CAD description based on manufacturing features which incorporates both geometric and process information is being developed. This feature-based CAD representation provides a direct interface between the CAD design data and the planning system for robot control. An agent actor paradigm is proposed as the representation for software/hardware system specifications and associated software and hardware modules.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/187403/,Proceedings of the 1991 IEEE International Symposium on Intelligent Control,13-15 Aug. 1991,ieeexplore
10.1109/ICSICT.2018.8565654,System Simulation for Robot Control Based on AI Approach,IEEE,Conferences,"In this paper, we focus on real robot development and control for different surface conditions using an AI based approach. The core components of our existing robot are pressure sensor, servomotor and software-driven microcontroller. We performed robot system simulation for various ground surface conditions to control the robot with respect to pressure-sensing data that incorporates the two-way interactions between robot and ground. We have used an artificial neural network (ANN) approach for pressure-sensor-data analysis. The analysis result shows that above 25 hidden neurons and an increasing number of training cycles will deliver better performance in terms of mean square error (mse), learning time and improved nearest surface-pattern recognition. The analysis results are useful for next generation AI-chip development for real-time robot control and movement.",https://ieeexplore.ieee.org/document/8565654/,2018 14th IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT),31 Oct.-3 Nov. 2018,ieeexplore
10.1109/IJCNN.2003.1223978,Systemic intelligence: methods for growing up artefacts that live,IEEE,Conferences,"The ideas of systemic intelligence provide a set of methodologies and paradigms that are, beside other advantages, suitable for constructing control systems that are capable of growing up. In particular the promising methods of systemic architecture, schedule of structural development, memory organization and rules for learning and adaptation are presented and discussed with respect to grow up an artifact. Of special interest is the concept of growth in the sense of growing up from a kind of infantile stage to a fully matured entity. To grow up an artifact from an infantile stage via a sequence of learned abilities to,a fully matured entity is still a feature of life not yet sufficiently transposed onto technical systems. To enable the capability to grow up artifacts, a set of methodologies and principles is presented in this paper. The developed methodologies are already implemented into physically existing test beds that operate, adapt (and grow up) in real time and in the real world to prove that the proposed approach is feasible under real conditions. Two realizations (robot control, audio signal processing) of a systemic architecture for an up-growing system are presented in this paper.",https://ieeexplore.ieee.org/document/1223978/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IIAI-AAI.2014.4,Table of contents,IEEE,Conferences,The following topics are dealt with: data mining; Japanese WordNet synonym misplacement detection; social network; recommender system; sentiment analysis; workshop-based instruction; Japanese public libraries; machine learning methods; collaborative Web presentation support system; SMS4 ultracompact hardware implementation; wireless sensor networks; personalized public transportation recommendation system; adaptive user interface; NIS-Apriori algorithm; GetRNIA software tool; rough set-based rule generation; tree-Ga bump hunting; neural network model; weighted citation network analysis; sound proofing ventilation unit; touch interaction; mutually dependent Markov decision processes; ozone treatment; dynamic query optimization; big data; learner activity recognition; IoT-security approach; nutrition-based vegetable production; farm product cultivation; polynomial time mat learning; C-deterministic regular formal graph system; article abstract key expression extraction; English text comprehension; online social games; knowledge creation; knowledge utilization; online stock trading; customer behavior analysis; project-based collaborative learning; in-field mobile game-based learning activities; e-portfolio system design; self-regulated learning ontological model; mobile augmented reality based scaffolding platform; context-aware mobile Japanese conversation learning system; English writing error classification; image processing; outside-class learning; exercise-centric teaching materials; UML modeling; online historical document reading literacy; MMORPG-based learning environment; computer courses; undergraduate education; energy management system; higher education; decentralised auction-based bandwidth allocation; wireless networked control systems; resource scheduling algorithm; embedded cloud computing; Poisson distribution; Japanese seismic activity; suspect vehicle detection; 3D network traffic visualization; Web information retrieval; agent based disaster evacuation assist system; electroencephalogram; random number generator; multiagent simulations; multicore environment; CPU scheduler; multithreaded processes; reserve-price biddings; real-time traffic signal control; evolutionary computation; robot-assisted rehabilitation system; hybrid automata; Batik motif classification; color-texture-based feature extraction; backpropagation; multimedia storytelling; e-tourism service; Web mining; search engine; simulation-based e-learning mobile application software; library classification training system; WebQuest learning strategy; context-aware ubiquitous English learning; support vector machine; RFID tag ownership transfer protocol; cognitive linguistics; collaborative software engineering learning; write-access reduction method; NVM-DRAM hybrid memory; garbage collection; parallel indexing scheme; lazy-updating snoop cache protocol; distributed storage system; ITS application; software engineering education; ophthalmic multimodal imaging system; injected bug classification; secure live virtual machine migration; flash memory management; genetic programming; heterogeneous databases; time series similarity search; concurrency control program generation; incremental data migration; multidatabase system; software release time decision making; analytic hierarchy process; interactive genetic algorithm; biometric intelligence; talking robots; archaeological ruin analysis; GIS; optical wireless pedestrian-support systems; visual impairment; extreme programming; Japanese e-commerce Web sites; Chinese sign language animation; hearing-impaired people mammography inspection; geographical maps; electroculogram; XML element retrieval technique; image recognition; reinforcement learning; ECU formal verification; gasoline direct injection engines; earthquake disaster simulation; smart devices for autistic children; RoboCup rescue simulation; inductive logic programming; master-slave asynchronous evolutionary hybrid algorithm; VANET routing optimization; and Web image sharing services.,https://ieeexplore.ieee.org/document/6913248/,2014 IIAI 3rd International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2014,ieeexplore
10.1109/CYBConf.2017.7985742,Table of contents,IEEE,Conferences,The following topics are dealt with: face identification; SDN; robot vision; video classification; multi-agent systems; information security management system; electric vehicle charging stations; LTI MIMO discrete-time systems; personal health indicators; UAV swarm target tracking; hybrid cyber-physical systems; online feature selection; interactive multimedia system; 3D virtual objects selection; neural networks; microfluidics chip production; face biometrics; palmprint multimodal biometrics; mobile visualization platform; agriculture; pointillistic art; human gender classification; protein structure prediction; PPI network; spectral-spatial hyperspectral image destriping; object tracking; crowd preference mining; ELM-based privacy preserving protocol; smart tourism destinations; dynamic firmware updates; virtual reality; bioinformatics; drug repositioning; image enhancement; and phishing Web sites.,https://ieeexplore.ieee.org/document/7985742/,2017 3rd IEEE International Conference on Cybernetics (CYBCONF),21-23 June 2017,ieeexplore
10.1109/WORV.2013.6521908,Table of contents,IEEE,Conferences,The following topics are dealt with: human-object-object-interaction; vision-based navigation; robot visual tracking; image-guided robot interventions; range imaging; vision for haptics; aerial robot vision; underwater robot vision; software tools for robot vision; visual servoing; servo control; learning from sensor/visual data; real-time sensing and control; active sensing; sensor fusion; sensor networks; and multirobot system with vision sensors.,https://ieeexplore.ieee.org/document/6521908/,2013 IEEE Workshop on Robot Vision (WORV),15-17 Jan. 2013,ieeexplore
10.1109/BRC.2014.6880952,Table of contents,IEEE,Conferences,The following topics are dealt with: positron range effect; ModPET reconstruction; optimized moving-average filtering; gradient artefact correction; simultaneous EEG-fMRI; SSVEP classification; PSO approach; learning transition structures; higher-order dynamic Bayesian networks; robotic walker; post-stroke hemiparetic individuals; muscle pattern analysis; autism spectrum disorder; brain-computer interface; avatar control; virtual reality environment; myoelectric signal acquisition; myoelectric signal processing; support-vector machine; hand-arm movement characterization; partial directed coherence; physiotherapy data; stress level analysis; alpha rhythm asymmetry patterns; EEG signal acquisition; Ethernet sniffer; BrainNet36 device; three-dimensional brain mapping system; knee analysis; linear discriminant function; eye closing activity detection; open-source three-dimensional reconstruction system; telediagnostic system; automatic lesion detection; digital mammograms; hybrid lower limb orthoses; electric stimulation technology; motor imagery recognition; cerebral mapping; JPEG algorithm; optimized quantization matrices; ultrasound image compression; stress-related emotional state computation; frontal cortex asymmetry; passive-ssBCI; hidden Markov models; upper extremity arm motion tracking; surface electromyographic based robot teleoperation; WBAN mobility enhancement; patient body monitoring; sagittal lung MR image segmentation; coronal lung MR image segmentation; automated EEG-based Alzheimer disease diagnosis; relevance vector machines; automatic sleep stage detection; FPGA based ultrasound backend system; image enhancement technique; fetal genital organs; differential evolution algorithm; electrical impedance tomography image reconstruction; automatic optical disc localization; automatic optical disc segmentation; fundus image segmentation; level set method; semiautomatic intervertebral disc degeneration classification; magnetic resonance images; spine; accelerometer-based human computer interface; parametric sEMG muscle activity detection; sample entropy; tibialis anterior muscle; electroencephalographic power bands; electrocardiographic power bands; empirical rhythm analysis; password typing; soft biometrics; single braille cell; finger prosthesis; heart rate variability analysis; feature selection; particle swarm optimization; genetic algorithms; nonblind search; automatic vowel recognition based articulation mode; noise reduction technique; adaptive filters; retinal vessel length measurement; retinal vessel diameter measurement; microcontroller network; assisted robot navigation; speech recognition; and speech synthesis.,https://ieeexplore.ieee.org/document/6880952/,5th ISSNIP-IEEE Biosignals and Biorobotics Conference (2014): Biosignals and Robotics for Better and Safer Living (BRC),26-28 May 2014,ieeexplore
10.1109/ITCS.2009.8,Table of contents - Volume 1,IEEE,Conferences,The following topics are dealt with: e-learning; mobile learning; computer aided instruction; information hiding; digital watermark; management information system; decision supposed system; e-business; e-hospital; e-society; network engineering; software engineering; mobile communication; artificial intelligent system; pattern recognition; data mining; ubiquitous computing; computer vision; rough set technology; robot technology; multimedia technology; search engine technology; virtual reality technology; database technology; intelligent transportation technology; and image processing.,https://ieeexplore.ieee.org/document/5190166/,2009 International Conference on Information Technology and Computer Science,25-26 July 2009,ieeexplore
10.1109/ICMA52036.2021.9512666,Target Detection and Tracking of Ground Mobile Robot Based on Improved Single Shot Multibox Detector Network,IEEE,Conferences,"To solve the problems of slow labeling speed of the traditional labellmg data set establishment method, and slow running speed of target classification and detection algorithm based on Single Shot Multibox Detector(SSD) deep learning network, this paper proposes a fast data set labeling algorithm and a fast SSD network for target real-time detection and tracking research. First, a data set is established quickly by using TLD target detection and tracking algorithms, cropping and mirroring methods are used to strengthen the data set. Then, SSD backbone network is improved based on depth-wise separable convolution to establish a fast SSD network. Finally, the ground mobile robot in RoboMasters(RM) competition is used as the detection and tracking target indoors and outdoors, as well as with other different scenarios with shield to test the real-time performance, accuracy and effectiveness of the algorithm. The results show that compared with traditional SSD network research, in terms of the analysis and processing system deployed on low-performance hardware, the improved fast SSD network can better meet the real-time requirements of target detection and tracking.",https://ieeexplore.ieee.org/document/9512666/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/CIRA.1997.613854,Task decomposition and dynamic policy merging in the distributed Q-learning classifier system,IEEE,Conferences,A distributed reinforcement learning system is designed and implemented on a mobile robot for the study of complex task decomposition and dynamic policy merging in real robot learning environments. The distributed Q-learning classifier system (DBLCS) is evolved from the standard LCS proposed by Holland (1996). We address two of the limitations of the LCS through the use of Q-learning as the apportionment of credit component and a distributed learning architecture to facilitate complex task decomposition. The Q-learning update equation is derived and its advantages over the complex bucket brigade algorithm (BBA) are discussed. Holistic and monolithic shaping approaches are used to distribute reward among the learning modules of the DBLCS and allow dynamic policy merging in a variety of real robot learning experiments.,https://ieeexplore.ieee.org/document/613854/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/IROS.1999.812762,Task-model based human robot cooperation using vision,IEEE,Conferences,"In order to assist a human, the robot must recognize human motion in real time by vision, and must plan and execute the needed assistance motion based on the task purpose and the context. In this research, we tried to solve such problems. We defined the abstract task model, analyzed the human demonstration by using events and an event stack, and automatically generated the task models needed in the assistance by the robot. The robot planned and executed the appropriate assistance motions based on the task: models according to the human motions in the cooperation with the human. We implemented a 3D object recognition system and a human grasp recognition system by using trinocular stereo color cameras and a real time range finder. The effectiveness of these methods was tested through an experiment in which the human and the robotic hand assembled toy parts in cooperation.",https://ieeexplore.ieee.org/document/812762/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/EIT51626.2021.9491894,Teaching Vehicles to Steer Themselves with Deep Learning,IEEE,Conferences,Traditional approaches for steering a vehicle using machine vision require large amounts of robust hand-crafted software which is both time consuming and expensive. The presented method uses a deep neural network to teach cars to steer themselves without any additional software. We created a labeled dataset for the ACTor (Autonomous Campus TranspORt) electric vehicle by pairing real world images taken during a drive with the associated steering wheel angle. We trained a model end to end using modern deep learning techniques including convolutional neural networks and transfer learning to automatically detect relevant features in the input and provide a predicted output. This means that no traditional hand engineered algorithm features were required for this implementation. We currently use an pretrained inception network on the ImageNet dataset to leverage the high level features learned from ImageNet to the steering problem through transfer learning. We removed the top portion of the network and replaced it with a linear regression node to provide the output. The model is trained end to end using backpropagation. The trained model is integrated with vehicle software on ROS (Robot Operating System) to read image data and provide a corresponding steering angle in real time. The current model achieves 15.2 degree error on average. As development continues the model may replace the current lane centering software and will be used for IGVC Self-Drive competition and campus transportation.,https://ieeexplore.ieee.org/document/9491894/,2021 IEEE International Conference on Electro Information Technology (EIT),14-15 May 2021,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/PADSW.2000.884672,Teleoperation system for real world robots-adaptive robot navigation based on sensor fusion,IEEE,Conferences,"The authors propose a teleoperation system with an autonomous robot which is able to solve tasks even without a large load for the operator and the system. Most teleoperation systems require skilled operators and expensive interfaces to solve tasks because they assume that the operator controls a robot completely. For these problems, we propose a teleoperation system which consists of an operation system and an autonomous robot. The operation system has a man-machine interface and allows a user to specify the working space and the tasks to be done. The autonomous robot follows the instruction from the operation system to solve the specific tasks. The paper focuses on navigation problems of the autonomous robot as an essential part of the proposed system. Namely, the autonomous robot should keep on the instructed paths in the real world to achieve a goal of the tasks. Our approach is based on a sensor fusion method based on two learning schemes: self-organizing map (SOM) and reinforcement learning. These learning schemes allow the system to be able to solve the tasks in an unreliable environment such as outdoors. Computational simulations reveal the effectiveness and robustness of the proposed method in the navigation problem.",https://ieeexplore.ieee.org/document/884672/,Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops,4-7 July 2000,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICEKIM52309.2021.00100,The Creation of Multi Intelligence Music Classroom in Children's Enlightenment Stage Based on Virtual Reality Technology,IEEE,Conferences,"With the development of virtual reality technology, the real realization of virtual reality will cause great changes in human life and development. VR is the abbreviation of virtual reality, which means virtual reality in Chinese. Virtual reality is the ultimate application form of multimedia technology. It is the crystallization of the rapid development of computer hardware and software technology, sensor technology, robot technology, artificial intelligence and behavioral psychology. Because of this, the combination of VR and education classroom will become the inevitable trend of future education development. In the context of the development of traditional education, the enlightenment and influence of music education classroom on children is point like, and through the intervention and influence of VR technology, the influence of VR on music education begins to appear face like, and can maximize the mental and thinking ability of preschool children. Through the above analysis, this paper concludes the feasibility and importance of introducing VR technology into the current music education classroom, and will explore for the development of multiple intelligence education.",https://ieeexplore.ieee.org/document/9479537/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ETFA.1995.496802,The REAKT project: environment and methodology for the development of real-time knowledge-based systems,IEEE,Conferences,"This paper outlines the main results of the REAKT and REAKT II ESPRIT projects (EP 5146 and 7805). The primary objective of those projects was to develop a set of tools and the associated methodology for applying knowledge-based systems in real-time domains. Two REAKT applications which we think are typical of the kind of real-time knowledge-based systems that can be developed with REAKT are presented. The first application is an online alarm management system which has been running for about one year in a large oil refinery in Italy. This application was developed within the REAKT project to act as a demonstrator for the project results. The second application is a prototype mobile robot system, currently being developed at CRIN-INRIA.",https://ieeexplore.ieee.org/document/496802/,Proceedings 1995 INRIA/IEEE Symposium on Emerging Technologies and Factory Automation. ETFA'95,10-13 Oct. 1995,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/ROBOT.2004.1308800,The artificial ecosystem: a distributed approach to service robotics,IEEE,Conferences,"We propose a multiagent, distributed approach to autonomous mobile robotics which is an alternative to most existing systems in literature: robots are thought of as mobile units within an intelligent environment where they coexist and co-operate with fixed, intelligent devices that are assigned different roles: helping the robot to localize itself, controlling automated doors and elevators, detecting emergency situations, etc. To achieve this, intelligent sensors and actuators (i.e. physical agents) are distributed both onboard the robot and throughout the environment, and they are handled by Real-Time software agents which exchange information on a distributed message board. The paper outlines the benefits of the approach in terms of efficiency and Real-Time responsiveness.",https://ieeexplore.ieee.org/document/1308800/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IRI-05.2005.1506505,The behavior evolving model and application of virtual robots,IEEE,Conferences,"We suggest a model that evolves the behavioral knowledge of a virtual robot. The knowledge is represented in classification rules and a neural network, and is learned by a genetic algorithm. The model consists of a virtual robot with behavior knowledge, an environment that it moves in, and an evolution performer that includes a genetic algorithm. We have also applied our model to an environment where the robots gather food into a nest. When comparing our model with the conventional method on various test cases, our model showed superior overall learning.",https://ieeexplore.ieee.org/document/1506505/,"IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.",15-17 Aug. 2005,ieeexplore
10.1109/IROS.2010.5650765,The design of LEO: A 2D bipedal walking robot for online autonomous Reinforcement Learning,IEEE,Conferences,"Real robots demonstrating online Reinforcement Learning (RL) to learn new tasks are hard to find. The specific properties and limitations of real robots have a large impact on their suitability for RL experiments. In this work, we derive the main hardware and software requirements that a RL robot should fulfill, and present our biped robot LEO that was specifically designed to meet these requirements. We verify its aptitude in autonomous walking experiments using a pre-programmed controller. Although there is room for improvement in the design, the robot was able to walk, fall and stand up without human intervention for 8 hours, during which it made over 43; 000 footsteps.",https://ieeexplore.ieee.org/document/5650765/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IJCNN.2008.4633777,"The development of a hybrid, distributed architecture for multiagent systems and its application in robot soccer",IEEE,Conferences,"Several issues still need to be unraveled in the development of multiagent systems equipped with global vision, as in robot soccer leagues. Here, we underscore three of them (1) real-time constraints on recognition of scene objects; (2) acquisition of environment knowledge; and (3) distribution and allocation of control competencies shared between the repertoire of the agentpsilas reactive behavior, and the central control entitypsilas strategic and deliberative behavior. The objective of this article is to describe the implementation of a distributed and hybrid reactive-deliberative control architecture for a multiagent system, equipped with global vision camera and agent local sensor and cameras. This multiple agent system was developed for application in robot soccer. We present the digital image processing techniques applied, as well as the proposed control architecture aimed at satisfying the constraints of this kind of application.",https://ieeexplore.ieee.org/document/4633777/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/VECIMS.2009.5068923,The hand shape recognition of Human Computer Interaction with Artificial Neural Network,IEEE,Conferences,"The hand gestures used in Human Computer Interaction (HCI) are generally posed by complicated and large amplitude actions of arm /hand. Thus usable HCI instructions are few and HCI efficiency is low. This paper presents new hand shapes and the corresponding recognition system for the HCI with robot or Coordinate Measuring Machine. Using a touch pad to precept the touching of fingers, hand shapes posed to express HCI instructions are defined by the combinations of 2 binary status, i.e. status of touching /detaching on touch pad and status of stretching /retracting over touch pad, of Index, Middle, Ring and Little fingers. Method of extracting the features in hand shape image is presented. Based on Neural Network, a decision binary tree is used in the real-time recognition of the hand shapes. A correctness ratio of about 95% is obtained when implemented by DSP processor in the recognition of 12 hand shapes.",https://ieeexplore.ieee.org/document/5068923/,"2009 IEEE International Conference on Virtual Environments, Human-Computer Interfaces and Measurements Systems",11-13 May 2009,ieeexplore
10.1109/ICSESS.2015.7339119,The research and implementation of artificial intelligence in mobile applications,IEEE,Conferences,"This paper designs and implements the bionic robot which is as an implementation of soldiers in the strategy game, and the robot has three parts: perception system, target and path system and decision-making system. The perception system is responsible for perceiving information inside the scene; the target and path system is to find the best position for attacking and the optimal path for the robot; the decision-making system determines the behavior of the robot in the next frame. This paper also introduces map information updated in real time in the game. The bionic robot system designed has a good expansibility, and soldiers of different arms using this system, the game is running well.",https://ieeexplore.ieee.org/document/7339119/,2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS),23-25 Sept. 2015,ieeexplore
10.1109/ROMAN.2003.1251856,The role that the internal model of the others plays in cooperative behavior,IEEE,Conferences,"Internal model of the others is claimed to be essential for the prediction of the others' behavior to realize a cooperative behavior. ""Theory of mind"" is known as a leading framework of the internal modeling. The present research consists of two parts. In the former part, experimental results are shown on the cooperation between a human subject and a software model of a mobile robot. The cooperative task given to the human subject is to carry a stick from a start point to a goal point by holding the one edge of the stick, in a simulation world displayed on a computer terminal. A virtual robot holds the other edge, whose behavior is controlled by a simple deterministic rule. The human subject is asked to perform the task under the following two different conditions A and B. In condition A, the subject is not told about the existence of the robot which holds the other edge, and only the stick is displayed. In condition B, the existence of the robot is told, but still not shown on the display. The performance of the carrying task is much better in the condition A, under which the subject can separate the movements of the stick and of the robot for their prediction. This result suggests that a construction of a behavior model of the other robot is helpful to carry out the cooperative task. In the latter part, a neural network replaces the human subject to perform the same cooperative task with the robot. The network outputs a motion to move the stick, and has a simple layered structure with an additional part to learn to predict the next motion of the robot. The experiments show the improvement in the task performance through learning the prediction. This also suggests the explicit modeling of the others is effective for the cooperation.",https://ieeexplore.ieee.org/document/1251856/,"The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.",2-2 Nov. 2003,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/ACSSC.2003.1292255,The use of CNN models and vertical rectification for a direct trigonometric recovery of 3D scene geometry from a stream of images,IEEE,Conferences,"The exploration of unknown environment autonomously and intelligently by autonomous mobile robot is one of the main problems that still have to be solved. From the biological systems it appears that it is not only a matter of computational power but also the right sensors and methods of implementation. In this work we understood that the invention of the powerful and practically realizable, emerging paradigm called cellular nonlinear network (CNN) fully realized the concept of real-time handling of time signals coining from space distribution sources. On the other hand inertial gyro sensor can increase the robustness and computing efficiency of vision system, which is subject to signal degradation and high computational expense, by providing a frame-to-frame prediction of camera orientation and position. Since most of the earlier or recent studies have tackled the artificial vision with two or three views in account, in this work we present a direct trigonometric recovery of 3D scene geometry from a stream of images. These images are vertically rectified using gyroscopes' output to minimize the token relative displacements between each frame. To match this vertically rectified stream of images in real-tune we borrow the strength of CNN, and the matching results are trigonometrically processed for 3D range estimation.",https://ieeexplore.ieee.org/document/1292255/,"The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003",9-12 Nov. 2003,ieeexplore
10.1109/BEC.2010.5631008,Timed Automata based provably correct robot control,IEEE,Conferences,"This paper presents a feasibility study on the usage of Uppaal Timed Automata (UPTA) for deliberative level robotic control. The study is based on the Scrub Nurse Robot case-study. Our experience confirms that UPTA model based control enables the control loop to be defined and maintained during the robot operation autonomously with minimum human intervention. Specifically, in our robot architecture the control model is constructed automatically using unsupervised learning. Correctness of the model is verified on-the-fly against safety, reachability, and performance requirements. Finally, it is demonstrated that UPTA model based robot control, action planning and model updates have natural implementation based on existing model execution and conformance testing tool Uppaal Tron.",https://ieeexplore.ieee.org/document/5631008/,2010 12th Biennial Baltic Electronics Conference,4-6 Oct. 2010,ieeexplore
10.1109/IROS40897.2019.8968514,Timepix Radiation Detector for Autonomous Radiation Localization and Mapping by Micro Unmanned Vehicles,IEEE,Conferences,"A system for measuring radiation intensity and for radiation mapping by a micro unmanned robot using the Timepix detector is presented in this paper. Timepix detectors are extremely small, but powerful 14 × 14 mm, 256 × 256 px CMOS hybrid pixel detectors, capable of measuring ionizing alpha, beta, gamma radiation, and heaving ions. The detectors, developed at CERN, produce an image free of any digital noise thanks to per-pixel calibration and signal digitization. Traces of individual ionizing particles passing through the sensors can be resolved in the detector images. Particle type and energy estimates can be extracted automatically using machine learning algorithms. This opens unique possibilities in the task of flexible radiation detection by very small unmanned robotic platforms. The detectors are well suited for the use of mobile robots thanks to their small size, lightweight, and minimal power consumption. This sensor is especially appealing for micro aerial vehicles due to their high maneuverability, which can increase the range and resolution of such novel sensory system. We present a ROS-based readout software and real-time image processing pipeline and review options for 3-D localization of radiation sources using pixel detectors. The provided software supports off-the-shelf FITPix, USB Lite readout electronics with Timepix detectors.",https://ieeexplore.ieee.org/document/8968514/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IECON.2016.7793038,Tool compensation in walk-through programming for admittance-controlled robots,IEEE,Conferences,"This paper describes a walk-through programming technique, based on admittance control and tool dynamics compensation, to ease and simplify the process of trajectory learning in common industrial setups. In the walk-through programming, the human operator grabs the tool attached at the robot end-effector and “walks” the robot through the desired positions. During the teaching phase, the robot records the positions and then it will be able to interpolate them to reproduce the trajectory back. In the proposed control architecture, the admittance control allows to provide a compliant behavior during the interaction between the human operator and the robot end-effector, while the algorithm of compensation of the tool dynamics allows to directly use the real tool in the teaching phase. In this way, the setup used for the teaching can directly be the one used for performing the reproduction task. Experiments have been performed to validate the proposed control architecture and a pick and place example has been implemented to show a possible application in the industrial field.",https://ieeexplore.ieee.org/document/7793038/,IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society,23-26 Oct. 2016,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/ASAP.2018.8445099,Towards Hardware Accelerated Reinforcement Learning for Application-Specific Robotic Control,IEEE,Conferences,"Reinforcement Learning (RL) is an area of machine learning in which an agent interacts with the environment by making sequential decisions. The agent receives reward from the environment based on how good the decisions are and tries to find an optimal decision-making policy that maximises its longterm cumulative reward. This paper presents a novel approach which has showon promise in applying accelerated simulation of RL policy training to automating the control of a real robot arm for specific applications. The approach has two steps. First, design space exploration techniques are developed to enhance performance of an FPGA accelerator for RL policy training based on Trust Region Policy Optimisation (TRPO), which results in a 43% speed improvement over a previous FPGA implementation, while achieving 4.65 times speed up against deep learning libraries running on GPU and 19.29 times speed up against CPU. Second, the trained RL policy is transferred to a real robot arm. Our experiments show that the trained arm can successfully reach to and pick up predefined objects, demonstrating the feasibility of our approach.",https://ieeexplore.ieee.org/document/8445099/,"2018 IEEE 29th International Conference on Application-specific Systems, Architectures and Processors (ASAP)",10-12 July 2018,ieeexplore
10.1109/ROBOT.2007.364220,Towards Mapping of Cities,IEEE,Conferences,"Map learning is a fundamental task in mobile robotics because maps are required for a series of high level applications. In this paper, we address the problem of building maps of large-scale areas like villages or small cities. We present our modified car-like robot which we use to acquire the data about the environment. We introduce our localization system which is based on an information filter and is able to merge the information obtained by different sensors. We furthermore describe out mapping technique that is able to compactly model three-dimensional scenes and allows us efficient and accurate incremental map learning. We additionally apply a global optimization techniques in order to accurately close loops in the environment. Our approach has been implemented and deeply tested on a real car equipped with a series of sensors. Experiments described in this paper illustrate the accuracy and efficiency of the presented techniques.",https://ieeexplore.ieee.org/document/4209838/,Proceedings 2007 IEEE International Conference on Robotics and Automation,10-14 April 2007,ieeexplore
10.1109/RO-MAN50785.2021.9515348,Towards Out-of-Sight Predictive Tracking for Long-Term Indoor Navigation of Non-Holonomic Person Following Robot<sup>*</sup>,IEEE,Conferences,"The ability to predict the movements of the target person allows a person following robot (PFR) to coexist with the person while still complying with the social norms. In human-robot collaboration, this is an essential requisite for long-term time-dependent navigation and not losing sight of the person during momentary occlusions that may arise from a crowd due to static or dynamic obstacles, other human beings, or intersections in the local surrounding. The PFR must not only traverse to the previously unknown goal position but also relocate the target person after the miss, and resume following. In this paper, we try to solve this as a coupled motion-planning and control problem by formulating a model predictive control (MPC) controller with non-linear constraints for a wheeled differential-drive robot. And, using a human motion prediction strategy based on the recorded pose and trajectory information of both the moving target person and the PFR, add additional constraints to the same MPC, to recompute the optimal controls to the wheels. We make comparisons with RNNs like LSTM and Early Relocation for learning the best-predicted reference path.MPC is best suited for complex constrained problems because it allows the PFR to periodically update the tracking information, as well as to adapt to the moving person’s stride. We show the results using a simulated indoor environment and lay the foundation for its implementation on a real robot. Our proposed method offers a robust person following behaviour without the explicit need for policy learning or offline computation, allowing us to design a generalized framework.",https://ieeexplore.ieee.org/document/9515348/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ICRA40945.2020.9197446,Towards Plan Transformations for Real-World Mobile Fetch and Place,IEEE,Conferences,"In this paper, we present an approach and an implemented framework for applying plan transformations to real-world mobile manipulation plans, in order to specialize them to the specific situation at hand. The framework can improve execution cost and achieve better performance by autonomously transforming robot's behavior at runtime. To demonstrate the feasibility of our approach, we apply three example transformations to the plan of a PR2 robot performing simple table setting and cleaning tasks in the real world. Based on a large amount of experiments in a fast plan projection simulator, we make conclusions on improved execution performance.",https://ieeexplore.ieee.org/document/9197446/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/DEVLRN.2005.1490968,Towards Robot Soccer Team Behaviours Through Approximate Simulation,IEEE,Conferences,"Robot soccer is now recognized as one of the most popular and efficient testbeds for intelligent robotics. It involves many challenges for computation, mechanics, control, software engineering, machine learning, and other fields. The international RoboCup initiative supports research into robot soccer and provides an excellent environment to investigate machine learning for robotics in simulation and the real world",https://ieeexplore.ieee.org/document/1490968/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/AIVR.2018.00060,Towards a Music Visualization on Robot (MVR) Prototype,IEEE,Conferences,"This paper presents a Music Visualization on Robot (MVR) prototype system which automatically links the flashlight, color and emotion of a robot through music. The MVR system is divided into three portions. Firstly, the system calculates the waiting time for a flashlight by beat tracking. Secondly, the system calculates the emotion correlated with music mood. Thirdly, the system links the color with emotion. To illustrate the prototype on a robot, the prototype implementation is based on a programmable robot called Zenbo because Zenbo has 8 LED light colors on 2 wheels and 24 face emotions to support various compositions.",https://ieeexplore.ieee.org/document/8613679/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/MFI.2001.1013553,Towards a learning model for feature integration in attention control,IEEE,Conferences,"We present current efforts towards an approach for the integration of features extracted from multi-modal sensors, with which to guide the attentional behavior of robotic agents. The model can be applied in many situations and different tasks including top-down or bottom-up aspects of attention control. Basically, a pre-attention mechanism enhances attentional features that are relevant to the current task according to a weight function that can be learned. Then, an attention shift mechanism can select one between the various activated stimuli, in order for a robot to foveate on it. Also, in this approach, we consider the robot moving resources or to improve the (visual) sensory information.",https://ieeexplore.ieee.org/document/1013553/,Conference Documentation International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI 2001 (Cat. No.01TH8590),20-22 Aug. 2001,ieeexplore
10.1109/ROBOT.1990.126044,Towards a real-time architecture for obstacle avoidance and path planning in mobile robots,IEEE,Conferences,"The design and partial implementation of a real-time architecture for a mobile robot, aimed particularly towards a vehicle developed for factory automation, is described. The authors develop a layered design to equip the robot with a number of behavioral competences. They examine sensing and a potential field algorithm especially to achieve modification of behavior at a speed close to the robot's operational speed. It is shown how the layered architecture interfaces to the original onboard architecture, which provided sophisticated localization but no ability to deal with environmental exceptions.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126044/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/AIM43001.2020.9158908,Towards accelerated robotic deployment by supervised learning of latent space observer and policy from simulated experiments with expert policies,IEEE,Conferences,"Up until today robotic tasks in highly variable environments remain very difficult to solve. We propose accelerated robotic deployment through task solving on low-level sensor data in simulation. A simulation allows for a lot of data, which is usually not available in a real world robotic setup due to cost and feasibility. Solving tasks in simulation is safe and a lot easier due to the huge amount of feedback from virtual sensory data. We present a novel sim2real architecture for converting simulated low level sensor data policies to high level real world policies. After solving a task we let the robot complete it a number of times in simulation using domain randomization, while doing so we save the simulated sensor data corresponding to the real robotic setup and actions taken. Given these sensor data and actions a task specific policy can be trained using our architecture. In this paper we work towards a proof of concept by simulating a simple low cost manipulator in pybullet to pick and place an object based on image observations.",https://ieeexplore.ieee.org/document/9158908/,2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),6-9 July 2020,ieeexplore
10.1109/SMC42975.2020.9283277,Towards an Extended POMDP Planning Approach with Adjoint Action Model for Robotic Task,IEEE,Conferences,"In real-world environments, robotic task planning is expected to handle both partial observability and unexpected dynamics of the environment. A robust plan for the task requires the robot's observation actions to concurrently run with the task actions, to observe and adapt to environmental changes. The Partially Observable Markov Decision Process (POMDP) has been widely applied for planning under partially observable domains. For realistic robotic tasks, however, the POMDP model and planning algorithm are quite restrictive and unrealistic. One limitation is that task actions are modelled as atomic entities that only have endpoint effects, with no conditions specified at arbitrary points during task action execution. Also, the observation is obtained only after each task action execution, with no intermediate observations and decision-making during task action execution. To mitigate the limitations of POMDP planning, this paper first proposes an Adjoint Action Model (AAM) that explicitly defines the continuous interaction between robot's observation and task actions. Then we extend the POMDP task action model with intermediate invariant conditions which specifies the runtime properties of action execution. Finally, we propose the AAM-extended POMDP planning approach which handles observation action planning and task replanning for task action execution. We experimentally demonstrate that the plan from our proposed approach is more effective and robust to cope with the environment dynamics, comparing with the standard POMDP planning approach.",https://ieeexplore.ieee.org/document/9283277/,"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",11-14 Oct. 2020,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/CIRA.1999.810023,Towards focused plan monitoring: a technique and an application to mobile robots,IEEE,Conferences,"Until recently, techniques for AI plan generation relied on highly restrictive assumptions that were almost always violated in real-world environments; consequently, robot designers adopted reactive architectures and avoided AI planning techniques. Some recent research efforts have focused on obviating such assumptions by developing techniques that enable the generation and execution of plans in dynamic, uncertain environments. In this paper, we discuss one such technique, rationale-based monitoring, originally introduced by Veloso, Pollack, and Cox (1998), and describe our use of it in a simple mobile robot environment. We review the original approach, describe how it can be adapted for a causal-link planner, and provide experimental results demonstrating that it can lead to improved plans without consuming excessive overhead. We also describe our use of rationale-based monitoring in a mobile robot office-assistant project currently in progress.",https://ieeexplore.ieee.org/document/810023/,Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375),8-9 Nov. 1999,ieeexplore
10.1109/ROMAN.2002.1045641,Towards grounded human-robot communication,IEEE,Conferences,"Future robots are expected to communicate with humans using natural language. The naive human user will expect a robot to easily understand what he/she is meaning by instructions concerning robot's tasks. This implies that the robot will need to have a means of grounding, in its own sensors, the natural language terms and constructions used by the human user. This paper presents an approach to solve this problem that is based on the integration of a ""learning server"" in the software architecture of the robot. Such server should be capable of on-line, incremental learning from examples; it should handle multiple problems concurrently and it should have meta-learning capabilities. A learning server already developed by the authors is presented. Complementarily, the dimensionality reduction problem is also addressed, using a Blocked DCT approach. Experimental results are obtained in a scenario in which three concepts (corresponding to natural language expressions) are concurrently learned.",https://ieeexplore.ieee.org/document/1045641/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/DEVLRN.2011.6037332,Towards incremental learning of task-dependent action sequences using probabilistic parsing,IEEE,Conferences,"We study an incremental process of learning where a set of generic basic actions are used to learn higher-level task-dependent action sequences. A task-dependent action sequence is learned by associating the goal given by a human demonstrator with the task-independent, general-purpose actions in the action repertoire. This process of contextualization is done using probabilistic parsing. We propose stochastic context-free grammars as the representational framework due to its robustness to noise, structural flexibility, and easiness on defining task-independent actions. We demonstrate our implementation on a real-world scenario using a humanoid robot and report implementation issues we had.",https://ieeexplore.ieee.org/document/6037332/,2011 IEEE International Conference on Development and Learning (ICDL),24-27 Aug. 2011,ieeexplore
10.1109/IJCNN.2017.7966054,Towards real-time robot simulation on uneven terrain using neural networks,IEEE,Conferences,"Simulation is a valuable tool for robotics research and development, and various simulation packages have been proposed. However, we are aware of no freely-available packages which implement the required fidelity to accurately model earth-moving robots that manipulate the terrain itself. The software which does exist for this is difficult if not impossible to run in real-time while achieving the desired accuracy. This paper proposes a simulation system in which a neural network is trained using data generated in a 3D high-fidelity, non-real-time simulator. The resulting neural network is used to accurately predict the motion of a robot in a 2D simulator, while also taking into consideration a height-field representing a 3D terrain. Using a trained neural network to drive the new simulation provides considerable speedup over the high-fidelity 3D simulation, allowing behaviour to be simulated in real-time while still capturing the physics of the agents and the environment.",https://ieeexplore.ieee.org/document/7966054/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/SIPROCESS.2016.7888345,Towards robust ego-centric hand gesture analysis for robot control,IEEE,Conferences,"Wearable device with an ego-centric camera would be the next generation device for human-computer interaction such as robot control. Hand gesture is a natural way of ego-centric human-computer interaction. In this paper, we present an ego-centric multi-stage hand gesture analysis pipeline for robot control which works robustly in the unconstrained environment with varying luminance. In particular, we first propose an adaptive color and contour based hand segmentation method to segment hand region from the ego-centric viewpoint. We then propose a convex U-shaped curve detection algorithm to precisely detect positions of fingertips. And parallelly, we utilize the convolutional neural networks to recognize hand gestures. Based on these techniques, we combine most information of hand to control the robot and develop a hand gesture analysis system on an iPhone and a robot arm platform to validate its effectiveness. Experimental result demonstrates that our method works perfectly on controlling the robot arm by hand gesture in real time.",https://ieeexplore.ieee.org/document/7888345/,2016 IEEE International Conference on Signal and Image Processing (ICSIP),13-15 Aug. 2016,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/IJCNN.2011.6033258,Towards the grounding of abstract words: A Neural Network model for cognitive robots,IEEE,Conferences,"In this paper, a model based on Artificial Neural Networks (ANNs) extends the symbol grounding mechanism to abstract words for cognitive robots. The aim of this work is to obtain a semantic representation of abstract concepts through the grounding in sensorimotor experiences for a humanoid robotic platform. Simulation experiments have been developed on a software environment for the iCub robot. Words that express general actions with a sensorimotor component are first taught to the simulated robot. During the training stage the robot first learns to perform a set of basic action primitives through the mechanism of direct grounding. Subsequently, the grounding of action primitives, acquired via direct sensorimotor experience, is transferred to higher-order words via linguistic descriptions. The idea is that by combining words grounded in sensorimotor experience the simulated robot can acquire more abstract concepts. The experiments aim to teach the robot the meaning of abstract words by making it experience sensorimotor actions. The iCub humanoid robot will be used for testing experiments on a real robotic architecture.",https://ieeexplore.ieee.org/document/6033258/,The 2011 International Joint Conference on Neural Networks,31 July-5 Aug. 2011,ieeexplore
10.1109/IJCNN.2008.4633874,Tracking a moving object with mobile robot based on vision,IEEE,Conferences,"The paper proposes a real-time tracking algorithm for a moving object with mobile robot based on vision using adaptive color matching and Kalman filter. The adaptive color matching can limit the region containing moving object on vision image plane. It can adjust color matching threshold to reduce the influence of lighting variations in the scene. Kalman filter is used as our prediction module to calculate motion vectors of moving object in the robot coordinate system. A view window containing the position of moving object estimated by Kalman filter is determined on image plane to reduce the image processing area. Color matching threshold can adjust itself adaptively in view window, which is used as an updating module. Experimental results show that the algorithm can adapt to lighting variations and has good tracking precision. It can also be implemented in real time.",https://ieeexplore.ieee.org/document/4633874/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ICCICT.2012.6398104,Tracking of a target person using face recognition by surveillance robot,IEEE,Conferences,"In this paper we designed an experimental setup in order to have human-robot interaction i.e. first we are going to detect the face and after that we recognise the detected face. Afterwards we get the persons upper body torso color as a key feature. As we extracted the color feature we can compute the moments and also evaluate the motion parameters so that the surveillance robot can track the person accordingly. We also had introduced Speech module in order to have a interaction between the remote and base station. Surveillance robot must track the targeted person in a robust manner in indoor and outdoor environment in different light and dynamic varying conditions. In our proposed setup we use PCA which is going to recognise the person in a real time environment and should communicate to the person via speech module deployed in the surveillance robot, as face recognition works on real time environment we are getting average recognition rate of 98%. Experiment demonstration validates the efficient performance of the approach.",https://ieeexplore.ieee.org/document/6398104/,"2012 International Conference on Communication, Information & Computing Technology (ICCICT)",19-20 Oct. 2012,ieeexplore
10.1109/LARS/SBR/WRE.2018.00068,Traffic Signs Recognition System with Convolution Neural Networks,IEEE,Conferences,"The purpose of this paper is to develop an automatic traffic sign recognition system, making use of computation vision techniques and convolution neural networks. The work is divided in two phases, namely detection and classification, and here is presented a different approach on the detection phase. The tests were performed in a simulator and in a real controlled environment using the framework ROS (Robot Operating System) and implemented with the AmigoBot robot.",https://ieeexplore.ieee.org/document/8588574/,"2018 Latin American Robotic Symposium, 2018 Brazilian Symposium on Robotics (SBR) and 2018 Workshop on Robotics in Education (WRE)",6-10 Nov. 2018,ieeexplore
10.1109/ROMOCO.2005.201413,Trajectory realization with collision avoidance algorithm,IEEE,Conferences,"This paper describes the approach to collision avoidance problem for 3-DOF anthropomorphic robot manipulators. The novelty of the approach is the decomposition of 3D space to two 2D spaces. Resulting is the computationally efficient algorithm, suitable for implementation in the real-time systems. Simulation of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented.",https://ieeexplore.ieee.org/document/1554392/,"Proceedings of the Fifth International Workshop on Robot Motion and Control, 2005. RoMoCo '05.",23-25 June 2005,ieeexplore
10.1109/IROS.2004.1389956,Trajectory tracking control of a rotational joint using feature-based categorization learning,IEEE,Conferences,"Real world robot applications have to cope with large variations in the operating conditions due to the variability and unpredictability of the environment and its interaction with the robot. Performing an adequate control using conventional control techniques, that require the model of the plant and some knowledge about the influence of the environment, could be almost impossible. An alternative to traditional control techniques is to use an automatic learning system that uses previous experience to learn an adequate control policy. Learning by experience has been formalized in the field of reinforcement learning. But the application of reinforcement learning techniques in complex environments is only feasible when some generalization can be made in order to reduce the required amount of experience. This work presents an algorithm that performs a kind of generalization called categorization. This algorithm is able to perform efficient generalization of the observed situations, and learn accurate control policies in a short time without any previous knowledge of the plant and without the need of any kind of traditional control technique. Its performance is evaluated on the trajectory tracking control with simulated DC motors and compared with PID systems specifically tuned for the same problem.",https://ieeexplore.ieee.org/document/1389956/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICACR51161.2020.9265509,Transfer of Inter-Robotic Inductive Classifier,IEEE,Conferences,"In multi-robot deployments, the robots need to share and integrate their own experience and perform transfer learning. Under the assumption that the robots have the same morphology and carry equivalent sensory equipment, the problem of transfer learning can be considered incremental learning. Thus, the transfer learning problem inherits the challenges of incremental learning, such as catastrophic forgetting and concept drift. In catastrophic forgetting, the model abruptly forgets the previously learned knowledge during the learning process. The concept drift arises with different experiences between consecutively sampled models. However, state-of-the-art robotic transfer learning approaches do not address both challenges at once. In this paper, we propose to use an incremental classifier on a transfer learning problem. The feasibility of the proposed approach is demonstrated in a real deployment. The robot consistently merges two classifiers learned on two different tasks into a classifier that performs well on both tasks.",https://ieeexplore.ieee.org/document/9265509/,"2020 4th International Conference on Automation, Control and Robots (ICACR)",11-13 Oct. 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956420,Trust Repair in Human-Swarm Teams+,IEEE,Conferences,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",https://ieeexplore.ieee.org/document/8956420/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA.2019.8793644,Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes,IEEE,Conferences,"In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.",https://ieeexplore.ieee.org/document/8793644/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/MED48518.2020.9183337,Unsupervised Learning for Subterranean Junction Recognition Based on 2D Point Cloud,IEEE,Conferences,"This article proposes a novel unsupervised learning framework for detecting the number of tunnel junctions in subterranean environments based on acquired 2D point clouds. The implementation of the framework provides valuable information for high level mission planners to navigate an aerial platform in unknown areas or robot homing missions. The framework utilizes spectral clustering, which is capable of uncovering hidden structures from connected data points lying on non-linear manifolds. The spectral clustering algorithm computes a spectral embedding of the original 2D point cloud by utilizing the eigen decomposition of a matrix that is derived from the pairwise similarities of these points. We validate the developed framework using multiple data-sets, collected from multiple realistic simulations, as well as from real flights in underground environments, demonstrating the performance and merits of the proposed methodology.",https://ieeexplore.ieee.org/document/9183337/,2020 28th Mediterranean Conference on Control and Automation (MED),15-18 Sept. 2020,ieeexplore
10.1109/IROS.2013.6696581,Unsupervised learning of predictive parts for cross-object grasp transfer,IEEE,Conferences,"We present a principled solution to the problem of transferring grasps across objects. Our approach identifies, through autonomous exploration, the size and shape of object parts that consistently predict the applicability of a grasp across multiple objects. The robot can then use these parts to plan grasps onto novel objects. By contrast to most recent methods, we aim to solve the part-learning problem without the help of a human teacher. The robot collects training data autonomously by exploring different grasps on its own. The core principle of our approach is an intensive encoding of low-level sensorimotor uncertainty with probabilistic models, which allows the robot to generalize the noisy autonomously-generated grasps. Object shape, which is our main cue for predicting grasps, is encoded with surface densities, that model the spatial distribution of points that belong to an object's surface. Grasp parameters are modeled with grasp densities, that correspond to the spatial distribution of object-relative gripper poses that lead to a grasp. The size and shape of grasp-predicting parts are identified by sampling the cross-object correlation of local shape and grasp parameters. We approximate sampling and integrals via Monte Carlo methods to make our computer implementation tractable. We demonstrate the applicability of our method in simulation. A proof of concept on a real robot is also provided.",https://ieeexplore.ieee.org/document/6696581/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ROBOT.1998.680515,Unsupervised learning to recognize environments from behavior sequences in a mobile robot,IEEE,Conferences,"We describe the development of a mobile robot which does unsupervised learning for recognizing environments from behavior sequences. Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may not be obtained in real environments. Furthermore unsupervised-learning is necessary for recognition in unknown environments without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in enclosures. Then the sequences of behaviors executed in each enclosure are transformed into input vectors for a self-organizing network. Learning without a teacher is done, and the robot becomes able to identify enclosures. Moreover we developed a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",https://ieeexplore.ieee.org/document/680515/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICSMC.1993.385064,Use of case-based reasoning techniques for intelligent computer-aided-design systems,IEEE,Conferences,"Reuse of designs is an important research direction for the future intelligent CAD systems. The main applications of such a research are various, from mechanical systems design (spacecraft, robot, ...) to software design. This paper will present a survey of the use of case-based reasoning (CBR) techniques for intelligent CAD systems in order to reuse designs or parts of designs. First, we will briefly resume some work issued from cognitive psychology, showing the importance of analogical-reasoning for design activities and then the origins of the CBR technology in AI. Second, we will then present the main systems using case-based reasoning for design activities followed by a comparative analysis between these systems. To conclude, we will indicate the main directions in CBR for design and will propose to adopt a cognitive approach from knowledge acquisition until the development of real design support systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/385064/,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,17-20 Oct. 1993,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/SPW50608.2020.00045,Using Taint Analysis and Reinforcement Learning (TARL) to Repair Autonomous Robot Software,IEEE,Conferences,"It is important to be able to establish formal performance bounds for autonomous systems. However, formal verification techniques require a model of the environment in which the system operates; a challenge for autonomous systems, especially those expected to operate over longer timescales. This paper describes work in progress to automate the monitor and repair of ROS-based autonomous robot software written for an apriori partially known and possibly incorrect environment model. A taint analysis method is used to automatically extract the dataflow sequence from input topic to publish topic, and instrument that code. A unique reinforcement learning approximation of MDP utility is calculated, an empirical and non-invasive characterization of the inherent objectives of the software designers. By comparing design (a-priori) utility with deploy (deployed system) utility, we show, using a small but real ROS example, that it's possible to monitor a performance criterion and relate violations of the criterion to parts of the software. The software is then patched using automated software repair techniques and evaluated against the original off-line utility.",https://ieeexplore.ieee.org/document/9283859/,2020 IEEE Security and Privacy Workshops (SPW),21-21 May 2020,ieeexplore
10.1109/IDAACS-SWS50031.2020.9297062,Using a COTS Smartphone to Control an Autonomous Self-Driving Platform,IEEE,Conferences,"Recent interest in self-driving cars has boosted related fields like autonomous systems and robotics. This paper describes a simple and inexpensive small-scale self driving platform called ASV, which is based on a lowcost microcontroller and a COTS smartphone connected via WiFi. The camera of the phone, which is fixed to the platform, acquires images which are processed in a Convolutional Neural Network (CNN) inspired by the Nvidia's PilotNet. The network is trained in end-to-end learning to produce steering command to follow highway style lanes with markers on both sides. On the microcontroller, the steering commands are used for motor actuation and control of the physical movement of the platform. This paper presents the structure and implementation of ASV and evaluates its real-time performance and latency. For typical speeds encountered in small-scale systems, the performance is found more than sufficient for lane following with the CNN, leaving plenty of room for extensions. The platform's simplicity allows it to be used in research, education, and to spark interest in self-driving systems and neural networks. It can form the basis for general robot control.",https://ieeexplore.ieee.org/document/9297062/,2020 IEEE 5th International Symposium on Smart and Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS),17-18 Sept. 2020,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/HNICEM.2018.8666242,Utilization of Fuzzy Logic Control in a Waste Robot,IEEE,Conferences,"This research aimed to design and develop an autonomous robot to feasibly address waste disposal issues in common indoor places. The researchers explored opportunities to improve path planning using Fuzzy Logic Control (FLC). The researchers utilized a Microcontroller Unit (MCU) to control input proximity, sound, and infrared sensors, and output geared Direct Current (DC) motors through machine learning and electromechanical interface. The researchers simulated an adaptive algorithm using Mamdani-type FLC model, implemented using C programming language, then downloaded as machine code to a real prototype. Based on significant test results, the waste robot accurately detected human interference, a feature that would be pivotal in overcoming individual indifferences on waste management.",https://ieeexplore.ieee.org/document/8666242/,"2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)",29 Nov.-2 Dec. 2018,ieeexplore
10.1109/AERO.2015.7119180,Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft,IEEE,Conferences,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.",https://ieeexplore.ieee.org/document/7119180/,2015 IEEE Aerospace Conference,7-14 March 2015,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA48506.2021.9561936,ViNG: Learning Open-World Navigation with Visual Goals,IEEE,Conferences,"We propose a learning-based navigation system for reaching visually indicated goals and demonstrate this system on a real mobile robot platform. Learning provides an appealing alternative to conventional methods for robotic navigation: instead of reasoning about environments in terms of geometry and maps, learning can enable a robot to learn about navigational affordances, understand what types of obstacles are traversable (e.g., tall grass) or not (e.g., walls), and generalize over patterns in the environment. However, unlike conventional planning algorithms, it is harder to change the goal for a learned policy during deployment. We propose a method for learning to navigate towards a goal image of the desired destination. By combining a learned policy with a topological graph constructed out of previously observed data, our system can determine how to reach this visually indicated goal even in the presence of variable appearance and lighting. Three key insights, waypoint proposal, graph pruning and negative mining, enable our method to learn to navigate in real-world environments using only offline data, a setting where prior methods struggle. We instantiate our method on a real outdoor ground robot and show that our system, which we call ViNG, outperforms previously-proposed methods for goal-conditioned reinforcement learning, including other methods that incorporate reinforcement learning and search. We also study how ViNG generalizes to unseen environments and evaluate its ability to adapt to such an environment with growing experience. Finally, we demonstrate ViNG on a number of real-world applications, such as last-mile delivery and warehouse inspection. We encourage the reader to visit the project website for videos of our experiments and demonstrations <sup>1</sup>.",https://ieeexplore.ieee.org/document/9561936/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.23919/WAC50355.2021.9559586,Virtual Testing and Policy Deployment Framework for Autonomous Navigation of an Unmanned Ground Vehicle Using Reinforcement Learning,IEEE,Conferences,"The use of deep reinforcement learning (DRL) as a framework for training a mobile robot to perform optimal navigation in an unfamiliar environment is a suitable choice for implementing AI with real-time robotic systems. In this study, the environment and surrounding obstacles of an Ackermann-steered UGV are reconstructed into a virtual setting for training the UGV to centrally learn the optimal route (guidance actions to be taken at any given state) towards a desired goal position using Multi-Agent Virtual Exploration in Deep Q-Learning (MVEDQL) for various model configurations. The trained model policies are to be transferred to a physical vehicle and compared based on their individual effectiveness for performing autonomous waypoint navigation. Prior to incorporating the learned model with the physical UGV for testing, this paper outlines the development of a GUI application to provide an interface for remotely deploying the vehicle and a virtual reality framework reconstruction of the training environment to assist safely testing the system using the reinforcement learning model.",https://ieeexplore.ieee.org/document/9559586/,2021 World Automation Congress (WAC),1-5 Aug. 2021,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/OCEANS.1995.528724,Virtual world visualization for an autonomous underwater vehicle,IEEE,Conferences,"A critical bottleneck exists in autonomous underwater vehicle (AUV) design and development. It is tremendously difficult to observe, communicate with and test underwater robots, because they operate in a remote and hazardous environment where physical dynamics and sensing modalities are counterintuitive. An underwater virtual world can comprehensively model all necessary functional characteristics of the real world in real time. This virtual world is designed from the perspective of the robot, enabling realistic AUV evaluation and testing in the laboratory. 3D real-time graphics are our window into the virtual world, enabling multiple observers to visualize complex interactions. A networked architecture enables multiple world components to operate collectively in real time, and also permits world-wide observation and collaboration with other scientists interested in the robot and virtual world.",https://ieeexplore.ieee.org/document/528724/,'Challenges of Our Changing Global Environment'. Conference Proceedings. OCEANS '95 MTS/IEEE,9-12 Oct. 1995,ieeexplore
10.1109/ISWCS.2019.8877305,Visible Light Positioning for Location-Based Services in Industry 4.0,IEEE,Conferences,"Industry 4.0 refers to the evolution in manufacturing from computerization to fully cyberphysical systems that exploit rich sensor data, adaptive real-time safety-critical control, and machine learning. An important aspect of this vision is the sensing and subsequent association of objects in the physical world with their cyber and virtual counterparts. In this paper we propose Visible Light Positioning (VLP) as an enabler for these Industry 4.0 applications. We also explore sensing techniques, including cameras (and depth sensors), and other light-based solutions for object positioning and detection along with their respective limitations. We then demonstrate an application of positioning for real time robot control in an interactive multiparty cyber-physical-virtual deployment. Lastly, based on our experience with this cyberphysical-virtual application, we propose Ray-Surface Positioning (RSP), a novel VLP technique, as a low cost positioning system for Industry 4.0.",https://ieeexplore.ieee.org/document/8877305/,2019 16th International Symposium on Wireless Communication Systems (ISWCS),27-30 Aug. 2019,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/I2MTC.2019.8826921,Vision-Based Deep Learning Approach for Real-Time Detection of Weeds in Organic Farming,IEEE,Conferences,"Vision-based detection and classification systems for identifying crops and weeds in captured color images have recently being extensively researched due to the advantages that they offer. The use of chemical or synthetic pesticides could drastically be reduced. One of the critical aspects of these systems is the requirement for high data volumes and the resulting lack of real time capability. This paper presents a method for detecting weeds in carrot fields in real time without segmentation and the need of a large dataset. In most vision-based measurement systems the task is divided into multiple processes like separating the objects from the background followed by the detection of the object and lastly the object classification. Our approach uses a convolution neural network to localize and classify the plants simultaneously. A precision of 89 % was achieved with a calculation rate of 18,56 FPS. A lower precision was accepted in favor of a higher calculation rate of about 56 FPS. We implemented and evaluated our system using a multi-platform robot on an organic carrot field located in Germany.",https://ieeexplore.ieee.org/document/8826921/,2019 IEEE International Instrumentation and Measurement Technology Conference (I2MTC),20-23 May 2019,ieeexplore
10.1109/ICMLC.2018.8526952,Vision-Based Line-Following Control of a Two-Wheel Self-Balancing Robot,IEEE,Conferences,"This paper presents a vision-based two-wheel self-balancing (TWSB) robot to follow a black line using visual feedback. We use MATLAB software to connect to the URL of IP camera and use image processing toolbox to process the image from the IP camera. After image processing, this paper sets 10 coordinates to detect if the black line is straight or the black line is in different kind of situation. This paper considers the black line including straight line, curve line, intersection and inconsecutive line. Thus, a cascade intelligent motion control system is proposed to control the balancing and moment of the vision-based TWSB robot with tracking the position and direction commands from MATLAB software. Finally, it shows that the vision-based TWSB robot can trace the black line on the map very well from the real-time experimental results.",https://ieeexplore.ieee.org/document/8526952/,2018 International Conference on Machine Learning and Cybernetics (ICMLC),15-18 July 2018,ieeexplore
10.1109/ICOVET50258.2020.9230275,Vision-Based Robot Hand Using Open Source Software,IEEE,Conferences,"The robot hand can plan grasp movements based on the position of the target object and the motion of the robot hand. The position of the target object is recognized from the image captured by a camera mounted on the robot arm, and the motion of the robot hand is estimated from the inertial measurement unit (IMU). We also adopt a variety of mechanisms to determine the target object among the objects detected in the camera scene. Experiments are conducted to verify the validity of control system. The experiments proved that the developed system can support the user to grasp the target object.",https://ieeexplore.ieee.org/document/9230275/,2020 4th International Conference on Vocational Education and Training (ICOVET),19-19 Sept. 2020,ieeexplore
10.1109/ROBOT.1995.525277,Vision-based reinforcement learning for purposive behavior acquisition,IEEE,Conferences,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal, and discusses several issues in applying the reinforcement learning method to a real robot with vision sensor. First, a ""state-action deviation"" problem is found as a form of perceptual aliasing in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To cope with this, an action set is constructed in such a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of learning form easy missions (or LEM) which is a similar technique to ""shaping"" in animal learning is implemented. LEM reduces the learning time from the exponential order in the size of the state space to about the linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",https://ieeexplore.ieee.org/document/525277/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/ICSTCC.2019.8885611,Visual Analytics Framework for Condition Monitoring in Cyber-Physical Systems,IEEE,Conferences,"One of the biggest challenges facing the factory of the future today is to reduce the time-to-market access and increase through the improvement of competitiveness and efficiency. In order to achieve this target, data analytics in Industrial Cyber-Physical System becomes a feasible option. In this paper, a visual analytics framework for condition monitoring of the machine tool is presented with the aim to manage events and alarms at factory level. The framework is assessed in a particular use case that consists in a multi-threaded cloud-based solution for the global analysis of the behaviour of variables acquired from PLC, CNC and robot manipulator. A human-machine interface is also designed for the real-time visualization of the key performance indicators according to the user's criteria. This tool implemented is a great solution for condition monitoring and decision-making process based on data analytics from simple statistics to complex machine learning methods. The results achieved are part of the vision and implementation of the industrial test bed of “Industry and Society 5.0” platform.",https://ieeexplore.ieee.org/document/8885611/,"2019 23rd International Conference on System Theory, Control and Computing (ICSTCC)",9-11 Oct. 2019,ieeexplore
10.1109/IECON.2019.8926916,Visual Subterranean Junction Recognition for MAVs based on Convolutional Neural Networks,IEEE,Conferences,"This article proposes a novel visual framework for detecting tunnel crossings/junctions in underground mine areas towards the autonomous navigation of Micro Aerial Vehicles (MAVs). Usually mine environments have complex geometries, including multiple crossings with different tunnels that challenge the autonomous planning of aerial robots. Towards the envisioned scenario of autonomous or semi-autonomous deployment of MAVs with limited Line-of-Sight in subterranean environments, the proposed module acknowledges the existence of junctions by providing crucial information to the autonomy and planning layers of the aerial vehicle. The capability for a junction detection is necessary in the majority of mission scenarios, including unknown area exploration, known area inspection and robot homing missions. The proposed novel method has the ability to feed the image stream from the vehicles on-board forward facing camera in a Convolutional Neural Network (CNN) classification architecture, expressed in four categories: 1) left junction, 2) right junction, 3) left &amp; right junction, and 4) no junction in the local vicinity of the vehicle. The core contribution stems for the incorporation of AlexNet in a transfer learning scheme for detecting multiple branches in a subterranean environment. The validity of the proposed method has been validated through multiple data-sets collected from real underground environments, demonstrating the performance and merits of the proposed module.",https://ieeexplore.ieee.org/document/8926916/,IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society,14-17 Oct. 2019,ieeexplore
10.1109/FSKD.2017.8393254,Visual control system design of wheeled inverted pendulum robot based on Beaglebone Black,IEEE,Conferences,"The wheeled inverted pendulum robot has broad prospects of applications in real life. It can use two coaxial wheels to achieve the body self-balancing, forward moving and turning. But the general wheeled inverted pendulum robot seldom has vision function to perceive enviromental change. In order to realize the robust visual control, a wheeled inverted-pendulum vision robot with attitude sensors, photoelectric encoders, ultrasonic sensors and so on is designed based on Beaglebone Black board. The moving object is separated in the space domain by obtaining the image sequence which is sent by a robot-mounted camera, and the modeling, identification and tracking of target sequence are implemented in the time domain. The balance PD, speed PI and steering PD controllers are designed to realize the dynamic balance, forward and steering function of the robot. To satisfy the functional requirements of the visual tracking system, an improved tracking-learning-detection algorithm based on kernelized correlation filtering is used, and a tracking anomaly based on spatial context is detected to determine the tracking state and reduce the error rate. Experimental results show that the robot reaches the requirement of design and achieves better visual control effectiveness.",https://ieeexplore.ieee.org/document/8393254/,"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)",29-31 July 2017,ieeexplore
10.1109/CNNA.2002.1035063,Visual feedback by using a CNN chip prototype system,IEEE,Conferences,"Robot locomotion control passes through a series of sensors that, according to information from the environment, allow the robot to adapt, in real time, its locomotion scheme or trajectory. When the goal of the robot is to reach a target in a non-structured environment the best approach is visual control realized by a fast image processing system. Fast parallel image processing of the CNN-UM cP4000 chip prototype permits one to obtain good performance, even in a real time control problem. The robot controlled by the implemented CNN visual feedback has a hexapod configuration and its locomotion system is also implemented by a multi-layer CNN structure. In this paper a CNN approach for both locomotion generation and visual control of the bio-inspired robot is presented.",https://ieeexplore.ieee.org/document/1035063/,Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications,24-24 July 2002,ieeexplore
10.1109/ROBOT.1991.131999,Visual navigation around curved obstacles,IEEE,Conferences,"An approach to path-planning around smooth obstacles that exploits visually derived geometry is proposed. A moving robot can scan the silhouette or apparent contour of an obstacle and estimate a minimum length path. This is done by seeking geodesics which can be extrapolated smoothly, around the obstacle and towards the goal. Preliminary implementation of this idea uses a real-time visual contour tracker running at 16 Hz, with a camera mounted on an Adept robot arm. The camera first dithers to generate visual motion, a safe path is estimated, and the robot steers the camera around the obstacle with a clearance of a few millimeters.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131999/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/IROS.1997.655065,Visual navigation in an open environment without map,IEEE,Conferences,We describe how a mobile robot controlled only by visual information can retrieve a particular goal location in an open environment. Our model does not need a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired from neurobiological studies using the recognition of visual patterns called landmarks. The robot merges this visual information and its azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast online learning of a few places located near the goal allows the robot to reach the goal from anywhere in its neighborhood. The system uses only an egocentric representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation tested on our robot in two real indoor environments. We show the limitations of the model and its possible extensions to create autonomous robots only guided by visual information.,https://ieeexplore.ieee.org/document/655065/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICRoM.2014.6990935,Visual servoing control of robot manipulator with Jacobian matrix estimation,IEEE,Conferences,"Visual servoing system is a system to control a robot by visual feedback. This paper presents a visual servoing control that drives the end-effector of a real robot manipulator from any arbitrary start position to the desired positions. The control law is obtained using inverse Jacobian matrix. Since there is not access to the model of the robot, artificial neural networks are used to estimate of inverse Jacobian matrix. There are many challenges in practical implementation such as: how to calculate Jacobian matrix, determining the intelligent structure for estimation of Jacobian matrix, recognition coordinate of each joint with image processing and changes in illumination. We proposed appropriate solutions to solve the mentioned challenges. The experimental results in the real robot show that the control system can move the end-effector to target positions from any arbitrary start position with good accuracy.",https://ieeexplore.ieee.org/document/6990935/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/IROS.1997.649086,Visually-guided obstacle avoidance in unstructured environments,IEEE,Conferences,"This paper presents an autonomous vision-based obstacle avoidance system. The system consists of three independent vision modules for obstacle detection, each of which is computationally simple and uses a different criterion for detection purposes. These criteria are based on brightness gradients, RGB (red, green, blue) color, and HSV (hue, saturation, value) color, respectively. Selection of which modules are used to command the robot proceeds exclusively from the outputs of the modules themselves. The system is implemented on a small monocular mobile robot and uses very lour resolution images. It has been tested for over 200 hours in diverse environments.",https://ieeexplore.ieee.org/document/649086/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICMLA.2006.53,Web Robot Learning Powered by Bluetooth Communication System,IEEE,Conferences,"This paper presents a web robot web-robot learning powered by Bluetooth communication system. The web-robot system is used as the virtual robot laboratory integrating a number of disciplines in engineering. This virtual laboratory is a valuable teaching tool for engineering education used at any time and from any location through Internet. The mobile robot was controlled with robot server named as control center. The server can be connected to mobile robot via Bluetooth adapter. The mobile robot system focuses on vision sensing. Real time image processing techniques are realized by the web robot system. This system can also realize monitoring, tele-controlling, parameter adjusting and reprogramming through Internet exclusively with a standard Web browser without the need of any additional software",https://ieeexplore.ieee.org/document/4041484/,2006 5th International Conference on Machine Learning and Applications (ICMLA'06),14-16 Dec. 2006,ieeexplore
10.1109/ICMLA.2007.19,Web-based maze robot learning using fuzzy motion control system,IEEE,Conferences,"In this study, a Web based maze robot system has been designed and implemented for solving different maze algorithms with the help of machine learning approaches. The robot system has a map-based heuristic maze solving algorithm. The algorithm used for solving the maze is based on map creation and produces a control signal for robot direction. Robot motions were controlled by a fuzzy motion control system running on a chip. The control algorithm can be easily changed with the help of an algorithm via web interface controlled by the control center. The control center program powered by MATLAB functions and special libraries (image and control) in DELPHI manage all robotic activities. These activities are: command interpreter, image capturing, processing and serving, machine learning techniques, Web serving, database management, communication with robot, and compiling microcontroller programs. The results have shown that the proposed, designed and implemented system provides amazing new features to the applicants doing their real-time programming exercises on Web.",https://ieeexplore.ieee.org/document/4457243/,Sixth International Conference on Machine Learning and Applications (ICMLA 2007),13-15 Dec. 2007,ieeexplore
10.1109/IROS.1999.811679,What we learned from RoboCup-97 and RoboCup-98,IEEE,Conferences,"RoboCup is an increasingly successful attempt to promote the full integration of robotics and AI research. The most prominent feature of RoboCup is that it provides the researchers with the opportunity to demonstrate their research results as a form of competition in a dynamically changing hostile environment, defined as the international standard game definition, in which the gamut of intelligent robotics research issues are naturally involved. The article describes what we have learned from the past RoboCup activities, and overview the future perspectives of RoboCup in the next century, mainly focusing on the real robot leagues. Finally, we introduce the new leagues, one of which will have been held at RoboCup-99 in Stockholm.",https://ieeexplore.ieee.org/document/811679/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/ICSMC.2011.6083632,[Copyright notice],IEEE,Conferences,The following topics are dealt with: brain-machine interface; machine learning technology; service systems; homeland security systems; virtual reality; agent-based modeling; human centered transportation systems; awareness science and engineering; soft computing; enterprise information systems; social signal processing; infrastructure system; manufacturing systems; pattern recognition; medical mechatronics; minimally invasive surgery; medical robotics; medical technology; intelligent power systems; discrete event systems; Petri nets; biometrics; bioinformatics; computational intelligence; supply chain management; shared control; fault diagnosis; systems engineering; Internet; support vector machines; knowledge acquisition; cloud computing; grey systems; humanoid robots; redundant manipulators; formal methods; granular computing; wireless sensor networks; nonlinear control systems; gesture-based interaction; software engineering; multi-agent systems; cognitive computing; social robotics; natural language processing; conflict resolution; intelligent transportation systems; human-robot interaction; image processing; medical informatics; decision support systems; assistive technology; human-centered design; data mining; and anti-terrorism applications.,https://ieeexplore.ieee.org/document/6083632/,"2011 IEEE International Conference on Systems, Man, and Cybernetics",9-12 Oct. 2011,ieeexplore
10.1109/INES.2015.7329762,[Front cover],IEEE,Conferences,The following topics are dealt with: learning; Web; urban water-supply system; IP Core; DCI approach; real-time sensor network; linked open data source; process mining; image coding; deep neural network architecture; human computer interaction; social human-robot interaction; VANET; authorized V2V communication; MIMO system; surgical robotics; ontologies; genetic algorithm; image reconstruction; mobile robot; artificial neural network; fuzzy reasoning; heat exchanger; fuzzy controller design; mobile device; human machine interface design; decision support system; data mining technique; discrete-time SISO system; augmented reality; visual analysis; content management system; Androids; nonlinear MPC; collaborative filtering; recommendation; wireless sensor networks;; humidity control; temperature control and stability.,https://ieeexplore.ieee.org/document/7329762/,2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES),3-5 Sept. 2015,ieeexplore
10.1109/ICCSCE.2011.6190480,[Front cover],IEEE,Conferences,The following topics are dealt with: output membership function; fuzzy logic controller; self adaptive neuro-fuzzy control; FES-assisted paraplegics indoor rowing exercise; indoor empirical path loss prediction model; 2.4 GHz 802.11N network; moving vehicle detection; RGB removal shadow segmentation; modeling virtual driving environment; regressive linear prediction; speech signals; wheel acceleration/deceleration; integrated stability control systems; nonlinear PID control; multiple input-single output model; MPPT; electronically tunable voltage-mode MIMO universal filter; high input impedance voltage-mode universal filter; OTA; parallel distributed fuzzy LQR controller; double-pendulum-type overhead cranes; ANFIS based modeling; overtaking maneuver trajectory; ASTER satellite data; spline interpolation technique; sea bed logging method; evolutionary normal-boundary intersection method; heterogeneous wireless sensor network; high precision laser tracker system; contactless position measurement; semantic Web ontologies; social network sites; Malay text-to-speech system; allophone synthesis; dynamic programming approach; pipelined optical bus systems; mainstream software sharing platform; oil &amp; gas exploration and development; remotely operated vehicle control system; surrogate modeling; model based sensor fault tolerant control system; micromachined thermal conductivity sensor; dual stack IPv4/IPv6 testbed; malware detection; digital evidence container; security convergence; global stability; continuous time delayed linear system; LMI based approach; robust adaptive controller; observer design; discrimination electrical power; multistage centrifugal compressors; remote controlled HD videoconference system; knowledge management; wave generator system; STATCOM; blood cell image segmentation; wireless controller area ;ARM microcontroller; ECG signals based mental stress assessment; wavelet transform; genetic-optimized neuro-fuzzy inference system; meshless local Petrov-Galerkin method; power plant automation; SCADA systems:; energy potential detection; autarkic smart object design; liquid level control; focal epileptic seizure forecasting; artificial neural networks; patch antennas arrayanti-swing control; double-pendulum-type overhead crane; distributed fuzzy LQR controller; genetic fuzzy rule set selection;force control; SMA actuated gripper; self tuning fuzzy PID controller; multivariable system; recurrent diagonal neural network; customized mobile learning management system; multi-flow rate mode selection; pneumatic dispensing valve system; clonal selection based artificial immune system algorithm; adaptive nonlinear PID controller; nonholonomic mobile robot; data compression technique; global solar radiation;1.8GHz electromagnetic field exposure; electro-hydraulic actuator; Methyl Tert-butyl Ether production; reactive distillation; robust control design; spacecraft attitude systems; level drum process control training system; time-delayed feedback control; chaotic T-S fuzzy systems; photovoltaic panels Perturbation; MPPT Method; island-mode doubly-fed induction generator; reactive power control; active power control; contactless optical sensor system; automatic column-based data object clustering; multilingual databases; mycobacterium tuberculosis detection; intelligent software agents; auditory wavelet packet filters; multiple intersections traffic signal timing optimization; overlapping vehicle tracking; adaptive particle filter; endoscopic image compression; double density discrete wavelet transform; Malaysian English accents identification; AR modeling techniques; online news management; double weight codes amplitude coding optical CDMA system network; output feedback sliding mode control; chaotic trajectory tracking; electro-hydraulic actuator system; discrete sliding mode control; retentive backtracking bit ; anti-collision algorithm; RFID systems; humanoid robot NAO; face detection technique; robotic assistive therapy; fractional order PI controller; modular general purpose controller board; biologically inspired robot; bundle branch blocks; multilayered perceptron network; helical antenna prototype; wireless power transmission; optimal control; nonlinear inverted pendulum dynamical system; 1.8 GHz radio frequency signal radiation effects; WiFi electromagnetic radiation; MRI brain classification; principal component analysis; electromagnetic generator; speed sensorless field oriented control; parallel- connected dual PMSM; solar radiation data analysis; Daubechies wavelets; dual-power PV-grid energy system; thermal energy storage system; single ortho-rectified high resolution satellite imagery; TopoMap revision; free swinging shank; hemiplegics; scanning resolution and laser scanner.,https://ieeexplore.ieee.org/document/6190480/,"2011 IEEE International Conference on Control System, Computing and Engineering",25-27 Nov. 2011,ieeexplore
10.1109/CISIS.2012.1,[Title page i],IEEE,Conferences,The following topics are dealt with: artificial intelligence; agent technology; support systems; software modeling; data mining; database; multimedia system; virtual reality; trusted computing; Web services; data integration; cloud computing; energy aware information systems; ad hoc networks; sensor networks; mesh networks; vehicular networks; complex distributed systems; software intensive system; parallel system; multicore systems; human-robot interaction; intelligent interfaces; network-oriented applications; autonomic distributed systems; semantic Web information; service discovery; service management; intelligent computing; large-scale systems; adaptive learning; collaborative learning; emotion management; intelligent context aware system; hybrid computing infrastructure; e-science applications; service-oriented architecture; knowledge processing; intelligent informatic in biology and medicine; and modern enterprises.,https://ieeexplore.ieee.org/document/6245736/,"2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems",4-6 July 2012,ieeexplore
10.1109/ICAS.2009.2,[Title page iii],IEEE,Conferences,The following topics are dealt with: real-time chain-structured synchronous dataflow; memory requirement formal determination; linear singular descriptor differential system; execution-optimized paths; greedy strategy; load trend evaluation; self-managed P2P streaming; context-aware ambient assisted living application; self-adaptive distributed model; autonomic systems; wireless sensor networks; topology control; learning based method; self-recovery method; mobile data sharing; heterogeneous QoS resource manager; component-based self-healing; NGN mobility; interactive user activity; .NET Windows service agent technology; agent based Web browser; resource-definition policies; autonomic computing; autonomic system administration; automatic database performance tuning; knowledge management; adaptive reinforcement learning; VoIP services; autonomic RSS: distributed virtual reality simulations; virtual machines resources allocation; multi-lier distributed systems; network I/O extensibility; virtual keyboards; self-configuring smart homes; legged underwater vehicles; particle filters; reusable semantic components; multi-agent systems; fixed-wing unmanned aerial vehicles; fuzzy inference system; robot swarms; mobile robots; optimization architecture; autonomous unmanned helicopter landing system design; heterogeneous multi-database environments; autonomic software license management system; Web server crashes prediction; laser range finder; video quality; wireless networks; ITU-T G.1030; open IMS core; context-aware data mining methodology; supply chain finance cooperative systems; autonomous pervasive environments; distributed generic stress tool; dynamic adaptive systems; multisensory media effects and user preference.,https://ieeexplore.ieee.org/document/4976566/,2009 Fifth International Conference on Autonomic and Autonomous Systems,20-25 April 2009,ieeexplore
10.1109/ICSMC.2009.5346382,[Title page],IEEE,Conferences,"The following topics are dealt with: human-computer interaction; assistive technology; systems safety; systems security; human-computer symbiosis; information retrieval; soft computing; image processing; pattern recognition; discrete event systems; computational intelligence; human centered transportation systems; type-2 fuzzy logic systems; type-2 fuzzy logic control; manufacturing systems; manufacturing automation; smart sensor networks; environmental decision support systems; environmental visualization systems; intelligent learning; user interface design; biometric systems; bioinformatics; evolutionary computation; grey systems; human-machine cooperation; human-machine systems; virtual reality systems; augmented reality systems; systems engineering; systems sustainability; medical systems; health care systems; conflict resolution; intelligent Internet systems; intelligent RFID systems; Web intelligence; Web interaction; agent-based modeling; intelligent signal processing; human-machine interface; human-machine communications; human factors; design information systems; marketing information systems; brain-based information communications; swarm intelligence; management engineering; machine learning; cognitive radio; mobile robot intelligent control; distributed intelligent systems; vehicle, driver, environment and control system; multimedia systems; knowledge acquisition; robotic systems; human performance modeling; interactive media; digital media; granular computing; heuristic algorithms; fuzzy systems; self-organization systems; complex distributed systems; Petri nets; Kansei; image sharing; image retrieval; collaborative wireless sensor networks; enterprise information systems; visual information processing; fault monitoring; fault diagnosis; large-scale systems; intelligent transportation systems; neural networks; machine vision; fuzzy forecasting; information assurance; homeland security; intelligent multimedia computation; decision making; infrastructure systems management; collaborative virtual workspaces; distributed software systems; media computing; optimization; collaborative commerce; uncertain systems control; cybernetics; intelligent power systems; artificial immune systems; systems biology; collaborative manufacturing; supply chains; mechatronics; nonlinear control systems; intelligent multimedia-mobile communications; nano systems; micro systems; reliability engineering; role-based systems; role-based quality; and cooperative systems.",https://ieeexplore.ieee.org/document/5346382/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/ICITSI.2016.7858181,[Title page],IEEE,Conferences,"The following topics are dealt with: SDLC SPASI v. 4.0. business process; information extraction; statistics indicator tables; rule generalizations; ontology; conventional learning system; ICT-based learning; job training system; time-series data; RAID; software-based accelerator; virtualization environment; enterprise architecture government organization; TOGAF ADM; SONA; e- library; modified quantitative models for performance measurement system method; business process improvement; district government innovation service case study; government organization; m-government implementation evaluation; trusted Big Data; official statistics study case; data profiling; data quality improvement; secure internet access; copyright protection; color images; transform domain; luminance component; information network architecture; local government; software as a service; expert system; meningitis disease; certainty factor method; digital asset management system; broadcasting organizations; e-portofolio definition; system security requirement identification; electronic payment system; Internet-based long distance education; operational model data governance; requirement engineering; open government information network development; process capability assessment; information security management; information security governance; national cyber physical systems; e-learning readiness; remote control system; serial communications mobile; microcontroller; knowledge sharing; indonesia higher educational institutions; cultural heritage metadata; geo linked open data; NUSANTARA: knowledge management system; adaptive personalized learning system; interactive learning media; RPP ICT; government human capital management; knowledge management tools utilization; knowledge management readiness; analytic hierarchy process; government institutions; usability testing; scrum methodology; assistant information system; automatic arowana raiser; pSPEA2; strength Pareto evolutionary algorithm 2; early diagnosis expert system deficiency; digital forensic; user acceptance; human resource information system; automated plasmodium detection; malaria diagnosis; thin blood smear image; 3D virtual game; MOODLE; SLOODLE; open simulator case study; color-based segmentation; feature detection; ball post; goal post; mobile soccer robot game field; smart farming; real time q-log-based feature normalization; distant speech recognition; Monte Carlo localization; robot operating system; finite element method; 3D DC resistivity modeling; multi GPU; breast cancer lesions; adaptive thresholding; morphological operation; gamification framework; online training; collaborative working system; classification breast cancer ultrasound images; posterior features; three-wheeled omnidirectional robot controller; public services satisfaction; sentiment analysis; color blind test quantification; RGB primary color cluster; ERP modules requirement; micro, small and medium enterprise fashion industry; small culinary enterprises; business system requirement; small craft companies ; power analysis attack; DES and IT value model.",https://ieeexplore.ieee.org/document/7858181/,2016 International Conference on Information Technology Systems and Innovation (ICITSI),24-27 Oct. 2016,ieeexplore
10.1109/AICAS51828.2021.9458401,iELAS: An ELAS-Based Energy-Efficient Accelerator for Real-Time Stereo Matching on FPGA Platform,IEEE,Conferences,"Stereo matching is a critical task for robot navigation and autonomous vehicles, providing the depth estimation of surroundings. Among all stereo matching algorithms, Efficient Large-scale Stereo (ELAS) offers one of the best tradeoffs between efficiency and accuracy. However, due to the inherent iterative process and unpredictable memory access pattern, ELAS can only run at 1.5-3 fps on high-end CPUs and difficult to achieve real-time performance on low-power platforms. In this paper, we propose an energy-efficient architecture for real-time ELAS-based stereo matching on FPGA platform. Moreover, the original computational-intensive and irregular triangulation module is reformed in a regular manner with points interpolation, which is much more hardware-friendly. optimizations, including memory management, parallelism, and pipelining, are further utilized to reduce memory footprint and improve throughput. Compared with Intel i7 CPU and the state-of-the-art $\mathrm{C}\mathrm{P}\mathrm{U}+$FPGA implementation, our FPGA realization achieves up to $ 38.4\times$ and $ 3.32\times$ frame rate improvement, and up to $ 27.1\times$ and $ 1.13\times$ energy efficiency improvement, respectively.",https://ieeexplore.ieee.org/document/9458401/,2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS),6-9 June 2021,ieeexplore
10.1109/RCAR47638.2019.9043946,libSmart: an Open-Source Tool for Simple Integration of Deep Learning into Intelligent Robotic Systems,IEEE,Conferences,"Intelligent robotic systems can be empowered by advanced deep learning techniques. Robotic operations such as object recognition are well investigated by researchers involved in machine learning. However, these solutions have often led to ad-hoc implementation in experimental settings. Less reported is systematic implementation of deep learning models in industrial robots. The lack of standard implementation platforms has impeded widespread use of deep learning modules in industrial robots. It is of great importance to have development platforms that can coordinate several deep learning modules of a complex system. In this paper, a scalable deep-learning friendly robot task organization system named libSmart is introduced. Similar to ROS, the architecture of the proposed system allows users to plug and play various devices but the proposed architecture is also highly compatible with deep learning modules. Specifically, the deployment of deep learning models is handled using a novel data graph method with distributed computing. In this way, the computationally expensive training and inferencing processes of deep learning models can be handled with isolated accelerating hardware to reduce the overall system latency. Successful implementation of simultaneous object recognition and pose estimation by an industrial robot has been presented as a case study. The proposed system is open source for all users to build their own intelligent systems with customized deep-learning models. (https://github.com/RustIron/libSmart.git).",https://ieeexplore.ieee.org/document/9043946/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/IROS45743.2020.9340956,robo-gym – An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots,IEEE,Conferences,"Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and reduce the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym<sup>1</sup>. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to application on the robot. We showcase the capabilities and the effectiveness of the framework with two real world applications featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally, we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.",https://ieeexplore.ieee.org/document/9340956/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/CBS.2018.8612261,sEMG-Based Torque Estimation Using Time-Delay ANN for Control of an Upper-Limb Rehabilitation Robot,IEEE,Conferences,"Robotic-assisted rehabilitation of the upper limb following neurological injury can achieve best possible functional recovery when patients are engaged in the therapy. However, implementation of active training is still difficult as it's challenging to detect human motion intention online and impose corresponding robot control. This paper introduces a novel upper-limb rehabilitation robot, and proposes a sEMG-driven (sEMG: surface Electromyography) torque estimation model based on artificial neural networks (ANN). The robot has three DOFs, of which the first two DOFs adopt a planar parallel structure, and the wrist module has an exoskeleton form. In this study, we design an impedance controller and an admittance controller for the first two DOFs and the wrist module, respectively. Specifically, for the first two DOFs, the assistance/resistance force at the end-effector was controlled according to its motions and desired interaction impedance; for the wrist module, an sEMG armband was used to collect 8 channels of sEMG signals from the forearm muscles, and a time-delay ANN model was developed to estimate the wrist pronation/supination torque, based on which the wrist rotation was controlled according to the human motion intention. To overcome the overfitting problem, besides the experimental samples of wrist rotation, both resting and co-contraction samples were collected for training. Finally, combining with the design of a virtual reality game and force fields, the proposed methods were implemented and tested experimentally on the upper-limb rehabilitation robot.",https://ieeexplore.ieee.org/document/8612261/,2018 IEEE International Conference on Cyborg and Bionic Systems (CBS),25-27 Oct. 2018,ieeexplore
10.1109/TSMCC.2004.840063,"""Sticky Hands"": learning and generalization for cooperative physical interactions with a humanoid robot",IEEE,Journals,"""Sticky Hands"" is a physical game for two people involving gentle contact with the hands. The aim is to develop relaxed and elegant motion together, achieve physical sensitivity-improving reactions, and experience an interaction at an intimate yet comfortable level for spiritual development and physical relaxation. We developed a control system for a humanoid robot allowing it to play Sticky Hands with a human partner. We present a real implementation including a physical system, robot control, and a motion learning algorithm based on a generalizable intelligent system capable itself of generalizing observed trajectories' translation, orientation, scale and velocity to new data, operating with scalable speed and storage efficiency bounds, and coping with contact trajectories that evolve over time. Our robot control is capable of physical cooperation in a force domain, using minimal sensor input. We analyze robot-human interaction and relate characteristics of our motion learning algorithm with recorded motion profiles. We discuss our results in the context of realistic motion generation and present a theoretical discussion of stylistic and affective motion generation based on, and motivating cross-disciplinary research in computer graphics, human motion production and motion perception.",https://ieeexplore.ieee.org/document/1522534/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",Nov. 2005,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2021.3061477,A Cloud-Based Platform for Big Data-Driven CPS Modeling of Robots,IEEE,Journals,"This paper proposes an improved cyber-physical systems (CPS) architecture for a smart robotic factory based on an industrial cloud platform driven by big data based on the traditional CPS architecture. This paper uses the architecture analysis and design language to model and design a total of three scales for the underlying cell-level robot, the system-level robot shop, and the overall robotic smart factory CPS, respectively, to complete the conceptual scheme for building a robotic smart factory from a local to an overall CPS system. Using the advantages of cloud computing and combining robotic CPS with cloud computing, an architecture for an industrial management system for CPS cloud computing is proposed. Base based distributed storage architecture with Storm based distributed real-time processing architecture. In terms of modeling, the advantages and disadvantages of using AADL, structural analysis, and design language, and modelers, a physical device modeling language, are combined to analyze the advantages and disadvantages of architecture analysis &amp; design language (AADL) for modeling CPS and propose a CPS analysis and design based on AADL and applicable to it. The paper also investigates the use of LeNet models for state identification in the HSV color space. The algorithm was verified on a self-built power equipment indicator dataset with a 100% detection rate and 99.8% state recognition accuracy after four consecutive frames of fusion detection. Simulink simulation of the trolley was carried out in terms of a cell-level robotic trolley CPS system to demonstrate the effectiveness of the design of a robotic CPS system driven by soaring data based on the industrial cloud platform proposed in this paper.",https://ieeexplore.ieee.org/document/9360827/,IEEE Access,2021,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2020.3042439,A Fuzzy Ensemble Method With Deep Learning for Multi-Robot System,IEEE,Journals,"In a multi-robot system, situation assessment evaluates the current situation quantitatively to help decision-makers make the best decision. Conventional situation assessment methods ignore the initiative of each robot, so it often encounters bottlenecks. Collaborative intelligence shows better performance than a single global decision. To address this problem, this work introduces a deep learning-based fuzzy adaptive method (DLFA) to achieve the real-time situation assessment for a multi-robot system. The proposed method employs the shortest path faster algorithm to achieve information sharing between agents. The shortest path faster algorithm ensures that the agent distributes its state information to its teammates in the fastest way. Each agent gets the information from teammates and treats their state as the observation of the scene. Deep neural network maps current observations into a local situation assessment result by combining a large number of nonlinear processing layers. Finally, each local assessment result is regarded as a brick to construct the final situation assessment via a fuzzy ensemble method. Experimental results show that the proposed method outperforms competitors.",https://ieeexplore.ieee.org/document/9279196/,IEEE Access,2020,ieeexplore
10.1109/TAMD.2011.2164404,A Multiple Context Brain for Experiments With Robot Consciousness,IEEE,Journals,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",https://ieeexplore.ieee.org/document/5986693/,IEEE Transactions on Autonomous Mental Development,Dec. 2011,ieeexplore
10.1109/ACCESS.2021.3124386,A Multiple Pheromone Communication System for Swarm Intelligence,IEEE,Journals,"Pheromones are chemical substances essential for communication among social insects. In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual pheromone has emerged recently as a powerful real-time method for indirect communication. However, these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviors such as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula>) to support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones simultaneously. The proposed system ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula> uses optical signals to emulate different evaporating chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The color sensors beneath the robots can detect and identify lingering “pheromones” on the screen. Meanwhile, the release of any pheromone from each robot is enabled by monitoring its positional information over time with an overhead camera. No other communication methods apart from virtual pheromones are employed in this system. Two case studies have been carried out which have verified the feasibility and effectiveness of the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel platform is a timely and powerful tool for research into swarm intelligence.",https://ieeexplore.ieee.org/document/9594791/,IEEE Access,2021,ieeexplore
10.1109/TSMC.2013.2297398,A Multiple-Feature and Multiple-Kernel Scene Segmentation Algorithm for Humanoid Robot,IEEE,Journals,"This paper presents a multiple-feature and multiple-kernel support vector machine (MFMK-SVM) methodology to achieve a more reliable and robust segmentation performance for humanoid robot. The pixel wise intensity, gradient, and C1 SMF features are extracted via the local homogeneity model and Gabor filter, which would be used as inputs of MFMK-SVM model. It may provide multiple features of the samples for easier implementation and efficient computation of MFMK-SVM model. A new clustering method, which is called feature validity-interval type-2 fuzzy C-means (FV-IT2FCM) clustering algorithm, is proposed by integrating a type-2 fuzzy criterion in the clustering optimization process to improve the robustness and reliability of clustering results by the iterative optimization. Furthermore, the clustering validity is employed to select the training samples for the learning of the MFMKSVM model. The MFMK-SVM scene segmentation method is able to fully take advantage of the multiple features of scene image and the ability of multiple kernels. Experiments on the BSDS dataset and real natural socene images demonstrate the superior performance of our proposed method.",https://ieeexplore.ieee.org/document/6717184/,IEEE Transactions on Cybernetics,Nov. 2014,ieeexplore
10.1109/ACCESS.2017.2787738,A Neuro-Fuzzy Visual Servoing Controller for an Articulated Manipulator,IEEE,Journals,"The challenges of selecting appropriate image features, optimizing complex nonlinear computations, and minimizing the approximation errors always exist in visual servoing. A fuzzy neural network controller is developed for a six-degrees-of-freedom robot manipulator to perform visual servoing is proposed to tackle these problems. To increase the accuracy of the image preprocesses, a synthetic image process performs feature extraction for the controller. The method combines a support vector machine contour recognition algorithm and a color-based feature recognition algorithm. For visual servoing, a control method based on the fuzzy cerebellar model articulation controller with the Takagi-Sugeno framework is proposed to directly map an image feature error vector to a desired robot end-effector velocity. This approach achieves visual servoing control without the need of computing the inverse interaction matrix. The control variables are learned and updated by the T-S fuzzy inference. This simplifies the implementation of visual servoing in real-time applications. The proposed control method is used to control an articulated manipulator with an eye-in-hand configuration. The results of simulations and experiments demonstrate that the proposed visual servoing controller has good performance, in terms of stability and convergence.",https://ieeexplore.ieee.org/document/8247175/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2020.2973756,A New Automatic Real-Time Crop Row Recognition Based on SoC-FPGA,IEEE,Journals,"With the development of artificial intelligence technology, agricultural robot plays a significantly important role for agricultural intelligence. Crop row line detection is a critical and fundamental step for agricultural robot navigation. Although there are some crop row lines detection methods, few of them can meet the real-time requirement for agricultural robot under complex fields conditions. In view of this, a real-time crop detection system implemented on a SoC FPGA (System-on-a-Chip Field Programmable Gate Array) is first proposed in this paper, which contains crop segmentation and crop row detection, where we design parallel pipeline architecture to enhance real-time performance by using line buffer and sliding windows technologies. At the same time, the fixed point representation is used to reduce the memory resource in this system. The proposed system is evaluated and implemented on Xilinx Zynq UltraScale+ MPSoC ZCU102 SoC-FPGA. The experimental results show that the proposed system can process an image with 1920×1080 resolution only within 210 ms with the average accuracy of 89.7%, which satisfies the real-time requirements of the crop rows recognition.",https://ieeexplore.ieee.org/document/8998211/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2019.2946848,A New Multi-Agent Reinforcement Learning Method Based on Evolving Dynamic Correlation Matrix,IEEE,Journals,"Multi-agent reinforcement learning approaches can be roughly classified into two categories. One is the agent-based approach which can be implemented in real distributed systems, though most approaches of this type cannot provide meaningful theoretical verifications. The other can be seen as the more formalized approach, which can provide theoretical results. However, most of current algorithms usually require unrealistic global communication, which makes them impractical for real distributed systems. In this article, we propose a dynamic correlation matrix based multi-agent reinforcement learning approach where the meta-parameters are evolved using an evolutionary algorithm. We believe that our approach is able to fill the gap between the two kinds of traditional multi-agent reinforcement learning approaches by providing both agent-level implementation and system-level convergence verification. The basic idea of this approach is that agents learn not only from local environmental feedback, i.e., their own experiences and rewards, but also from other agents' experiences. In this way, the agents' learning speed can be increased significantly. The performance of the proposed algorithm is demonstrated on a number of application scenarios, including blackjack games, urban traffic control systems and multi-robot foraging.",https://ieeexplore.ieee.org/document/8864051/,IEEE Access,2019,ieeexplore
10.1109/TSMC.2019.2956321,A Novel Approach to Image-Sequence-Based Mobile Robot Place Recognition,IEEE,Journals,"Visual place recognition is a challenging problem in simultaneous localization and mapping (SLAM) due to a large variability of the scene appearance. A place is usually described by a single-frame image in conventional place recognition algorithms. However, it is unlikely to completely describe the place appearance using a single frame image. Moreover, it is more sensitive to the change of environments. In this article, a novel image-sequence-based framework for place detection and recognition is proposed. Rather than a single frame image, a place is represented by an image sequence in this article. Position invariant robust feature (PIRF) descriptors are extracted from images and processed by the incremental bag-of-words (BoWs) for feature extraction. The robot automatically partitions the sequentially acquired images into different image sequences according to the change of the environmental appearance. Then, the echo state network (ESN) is applied to model each image sequence. The resultant states of the ESN are used as features of the corresponding image sequence for place recognition. The proposed method is evaluated on two public datasets. Experimental comparisons with the FAB-MAP 2.0 and SeqSLAM are conducted. Finally, a real-world experiment on place recognition with a mobile robot is performed to further verify the proposed method.",https://ieeexplore.ieee.org/document/8931657/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Sept. 2021,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/TSMC.2019.2917034,A Real-Time Robotic Grasping Approach With Oriented Anchor Box,IEEE,Journals,"Grasping is an essential skill for robots to interact with humans and the environment. In this paper, we build a vision-based, robust, and real-time robotic grasping approach with fully convolutional neural network. The main component of our approach is a grasp detection network with oriented anchor boxes as detection priors. Because the orientation of detected grasps is significant, which determines the rotation angle configuration of the gripper, we propose the orientation anchor box mechanism to regress grasp angle based on predefined assumption instead of classification or regression without any priors. With oriented anchor boxes, the grasps can be predicted more accurately and efficiently. Besides, to accelerate the network training and further improve the performance of angle regression, angle matching is proposed during training instead of Jaccard index matching. Fivefold cross-validation results demonstrate that our proposed algorithm achieves an accuracy of 98.8% and 97.8% in image-wise split and object-wise split, respectively, and the speed of our detection algorithm is 67 frames per second (FPS) with GTX 1080Ti, outperforming all the current state-of-the-art grasp detection algorithms on Cornell Dataset both in speed and accuracy. Robotic experiments demonstrate the robustness and generalization ability in unseen objects and real-world environment, with the average success rate of 90.0% and 84.2% of familiar things and unseen things, respectively, on Baxter robot platform.",https://ieeexplore.ieee.org/document/8734882/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",May 2021,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/JSEN.2020.3042665,A Searching Space Constrained Partial to Full Registration Approach With Applications in Airport Trolley Deployment Robot,IEEE,Journals,"For airports with high passenger and luggage flows, a large number of staff members have to be hired to deploy the scattered passenger luggage trolleys. To release humans from the repetitive and laborious job, we develop an autonomous trolley deployment robot to detect, transport and collect the scattered idle trolleys to recycling points. This paper will firstly illustrate the entire collection pipeline of the deployment robot system and then address the key challenge: partial to full point set registration. With the perception framework, the robot can detect the idle trolleys and acquire the pose of the trolleys on the ground, and then capture the trolley from behind, along the same direction for subsequent grasping and manipulation. With RGB-D camera and a segmentation Convolutional Neural Network, the robot can generate a partial surface point cloud of the detected trolley. The resulting point cloud, data and a pre-scanned full trolley point cloud, model, are matched by an implicit pose. To tackle the low accuracy and long computation time issues, a novel searching space-constrained point set registration algorithm is proposed to register the two overlapping point sets. Based on Branch-and-Bound (BnB) mechanism, the error between data and model is iteratively optimized. The constraint of searching space speeds up the global searching of the optimal pose, by pruning the candidate spaces which is impossible to contain the optimal result. To evaluate the performance, an airport trolley segmentation dataset and a point cloud dataset for registration are constructed. Experimental results on the datasets and synthetic dataset show that our method achieves higher accuracy and success rate than the previous methods. The experiments demonstrated in video clips validate the developed system works in real-world applications.",https://ieeexplore.ieee.org/document/9281085/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/TRO.2011.2119910,A Simple Tactile Probe for Surface Identification by Mobile Robots,IEEE,Journals,"This paper describes a tactile probe designed for surface identification in a context of all-terrain low-velocity mobile robotics. The proposed tactile probe is made of a small metallic rod with a single-axis accelerometer attached near its tip. Surface identification is based on analyzing acceleration patterns induced at the tip of this mechanically robust tactile probe, while it is passively dragged along a surface. A training dataset was collected over ten different indoor and outdoor surfaces. Classification results for an artificial neural network were positive, with an 89.9% and 94.6% success rate for 1- and 4-s time windows of data, respectively. We also demonstrated that the same tactile probe can be used for unsupervised learning of terrains. For 1-s time windows of data, the classification success rate was only reduced to 74.1%. Finally, a blind mobile robot, performing real-time classification of surfaces, demonstrated the feasibility of this tactile probe as a guidance mechanism.",https://ieeexplore.ieee.org/document/5752869/,IEEE Transactions on Robotics,June 2011,ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/TASE.2020.2980628,A System Architecture for CAD-Based Robotic Assembly With Sensor-Based Skills,IEEE,Journals,"Specifying assembly tasks in computer-aided design (CAD) level is a promising approach to intuitively program complex robot skills. In this article, a three-layered system architecture is presented to generate sensor-based robot skills from an assembly task instance. The architecture consists of an application layer where the user instantiates assembly tasks by specifying CAD constraints between geometric primitives pairs. A process layer infers the most suitable robot skills and their appropriate parameters. This inference is made possible by reasoning on a knowledge database represented as an ontology. The ontology contains semantic models of relevant classes such as tasks, skills, and geometric primitives as well as the relations between them. A control layer executes the sensor-based skills in real time using the eTaSL programming framework. A software implementation for the three layers is presented. The application layer is implemented in FreeCAD, whereas the process layer consists of a Web ontology language (OWL) ontology, a Prolog-based reasoner, and fuzzy inference to correctly select the skill and generate its parameters. In the control layer, the instantiated eTaSL skills execute the assembly tasks by sending an optimized control command to the robot. The system is validated on two challenging assembly cases with two distinct robot types, thus demonstrating the system's capability across different scenarios. Note to Practitioners-The widespread use of computer-aided design (CAD) models for describing parts assembly has motivated the research community to create systems that automatically generate robot programs satisfying the assembly goal. While most of the existing literature focuses on generating the assembly sequence, this article deals with the aspect of translation from CAD-level assembly specification to executable robot motion, also called skills. This article systematically addresses the problem by dividing it into different layers and solving them separately. Parameters that influence the successful execution of an assembly task are identified and categorized into application- and process-related parameters. Different inference techniques are employed to address each parameter category. Experimental results show that the proposed system can successfully generate and execute robot skills for assembly scenarios of an air compressor and an electric motor.",https://ieeexplore.ieee.org/document/9061146/,IEEE Transactions on Automation Science and Engineering,July 2020,ieeexplore
10.1109/JPROC.2018.2840045,A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm,IEEE,Journals,"In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare.",https://ieeexplore.ieee.org/document/8500162/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/TASE.2020.3032075,A Virtual Mechanism Approach for Exploiting Functional Redundancy in Finishing Operations,IEEE,Journals,"We propose a new approach to programming by the demonstration of finishing operations. Such operations can be carried out by industrial robots in multiple ways because an industrial robot is typically functionally redundant with respect to a finishing task. In the proposed system, a human expert demonstrates a finishing operation, and the demonstrated motion is recorded in the Cartesian space. The robot’s kinematic model is augmented with a virtual mechanism, which is defined according to the applied finishing tool. This way, the kinematic model is expanded with additional degrees of freedom that can be exploited to compute the optimal joint space motion of the robot without altering the essential aspects of the Cartesian space task execution as demonstrated by the human expert. Finishing operations, such as polishing and grinding, occur in contact with the treated workpiece. Since information about the contact point position is needed to control the robot during the operation, we have developed a novel approach for accurate estimation of contact points using the measured forces and torques. Finally, we applied iterative learning control to refine the demonstrated operations and compensate for inaccurate calibration and different dynamics of the robot and human demonstrator. The proposed method was verified on real robots and real polishing and grinding tasks. <italic>Note to Practitioners</italic>—This work was motivated by the need for automation of finishing operations, such as polishing and grinding, on contemporary industrial robots. Existing approaches are both too complex and too time-consuming to be applied in flexible and small-scale production, which often requires the frequent deployment of new applications. Our approach is based on programming by demonstration and enables the programming of finishing operations also for users who are not specialists in robot programming. Programming by demonstration is especially useful for teaching finishing operations because it enables the transfer of expert knowledge about finishing skills to robots without providing lengthy task descriptions or manual coding. Besides the human demonstration of the desired operation, the proposed approach also requires the availability of the kinematic model for the machine tool applied to carry out the finishing operation. We provide several practical examples of grinding and polishing tools and how to integrate them into our approach. Another feature of the proposed system is that user demonstrations of finishing operations can be transferred between different combinations of robots and machine tools.",https://ieeexplore.ieee.org/document/9246671/,IEEE Transactions on Automation Science and Engineering,Oct. 2021,ieeexplore
10.1109/TIE.2017.2764849,A Vision-Aided Approach to Perching a Bioinspired Unmanned Aerial Vehicle,IEEE,Journals,"This paper presents the implementation of a machine learning approach for replicating highly adaptive avian perching behavior. With full consideration of both the configuration of flying vehicles and perching principles, a bioinspired aerial robot comprising one flight subsystem and one perching subsystem is designed. Based on the real-time landing speed and attitude, a novel type of soft grasping mechanism for dexterous perching is proposed to provide adhesive force and absorb impact force. During the critical perching phase, the dynamics of the perching actuator change with the touchdown conditions and the type of perching target. A hybrid automation of a time-to-contact theory-based attitude controller and a robust self-localization system are utilized to regulate the desired perching maneuvers. The experimental results are provided to attest to the effectiveness of the proposed perching method.",https://ieeexplore.ieee.org/document/8074761/,IEEE Transactions on Industrial Electronics,May 2018,ieeexplore
10.1109/70.88099,A behavior-based arm controller,IEEE,Journals,"The author presents a working, implemented controller for an actual mobile robot arm. The goal of the system is to locate and retrieve empty soda cans in an unstructured environment using a variety of local sensors. The controller, however, is not a centralized sequential program, but rather a collection of 15 independent behaviors. Each of these behaviors contains some grain of expertise concerning the collection task and cooperates with the others to accomplish its goal. These behaviors run concurrently, in real time, on a set of eight loosely coupled on-board 8-bit microprocessors. The author describes the methodology used to decompose the collection task and discusses the types of implicit spatial representation and reasoning used by the system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88099/,IEEE Transactions on Robotics and Automation,Dec. 1989,ieeexplore
10.1109/TITB.2004.840062,A tele-operated mobile ultrasound scanner using a light-weight robot,IEEE,Journals,"This paper presents a new tele-operated robotic chain for real-time ultrasound image acquisition and medical diagnosis. This system has been developed in the frame of the Mobile Tele-Echography Using an Ultralight Robot European Project. A light-weight six degrees-of-freedom serial robot, with a remote center of motion, has been specially designed for this application. It holds and moves a real probe on a distant patient according to the expert gesture and permits an image acquisition using a standard ultrasound device. The combination of mechanical structure choice for the robot and dedicated control law, particularly nearby the singular configuration allows a good path following and a robotized gesture accuracy. The choice of compression techniques for image transmission enables a compromise between flow and quality. These combined approaches, for robotics and image processing, enable the medical specialist to better control the remote ultrasound probe holder system and to receive stable and good quality ultrasound images to make a diagnosis via any type of communication link from terrestrial to satellite. Clinical tests have been performed since April 2003. They used both satellite or Integrated Services Digital Network lines with a theoretical bandwidth of 384 Kb/s. They showed the tele-echography system helped to identify 66% of lesions and 83% of symptomatic pathologies.",https://ieeexplore.ieee.org/document/1402447/,IEEE Transactions on Information Technology in Biomedicine,March 2005,ieeexplore
10.1109/TNSRE.2020.3038175,AI Therapist Realizing Expert Verbal Cues for Effective Robot-Assisted Gait Training,IEEE,Journals,"Repetitive and specific verbal cues by a therapist are essential in aiding a patient's motivation and improving the motor learning process. The verbal cues comprise various expressions, sentences, volumes, and timings, depending on the therapist's proficiency. This paper proposes an AI therapist (AI-T) that implements the verbal cues of professional therapists having extensive experience with robot-assisted gait training using the SUBAR for stroke patients. The AI-T was developed using a neuro-fuzzy system, a machine learning technique leveraging the benefits of fuzzy logic and artificial neural networks. The AI-T was trained with the professional therapist's verbal cue data, as well as clinical and robotic data collected from robot-assisted gait training with real stroke patients. Ten clinical data and 16 robotic data are input variables, and six verbal cues are output variables. Fifty-eight stroke patients wore the SUBAR, a gait training robot, and participated in the robot-assisted gait training. A total of 9059 verbal cue data, 580 clinical data of stroke patients, and 144 944 robotic data were collected from 693 training sessions. Test results show that the trained AI-T can implement six types of verbal cues with 93.7% accuracy for the 1812 verbal cue data of the professional therapist. Currently, the trained AI-T is deployed in the SUBAR and provides six verbal cues to stroke patients in robot-assisted gait training.",https://ieeexplore.ieee.org/document/9260225/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1162/NECO_a_00376,ANUBIS: Artificial Neuromodulation Using a Bayesian Inference System,MIT Press,Journals,"Gain tuning is a crucial part of controller design and depends not only on an accurate understanding of the system in question, but also on the designer's ability to predict what disturbances and other perturbations the system will encounter throughout its operation. This letter presents ANUBIS (artificial neuromodulation using a Bayesian inference system), a novel biologically inspired technique for automatically tuning controller parameters in real time. ANUBIS is based on the Bayesian brain concept and modifies it by incorporating a model of the neuromodulatory system comprising four artificial neuromodulators. It has been applied to the controller of EchinoBot, a prototype walking rover for Martian exploration. ANUBIS has been implemented at three levels of the controller; gait generation, foot trajectory planning using Bézier curves, and foot trajectory tracking using a terminal sliding mode controller. We compare the results to a similar system that has been tuned using a multilayer perceptron. The use of Bayesian inference means that the system retains mathematical interpretability, unlike other intelligent tuning techniques, which use neural networks, fuzzy logic, or evolutionary algorithms. The simulation results show that ANUBIS provides significant improvements in efficiency and adaptability of the three controller components; it allows the robot to react to obstacles and uncertainties faster than the system tuned with the MLP, while maintaining stability and accuracy. As well as advancing rover autonomy, ANUBIS could also be applied to other situations where operating conditions are likely to change or cannot be accurately modeled in advance, such as process control. In addition, it demonstrates one way in which neuromodulation could fit into the Bayesian brain framework.",https://ieeexplore.ieee.org/document/6797771/,Neural Computation,Jan. 2013,ieeexplore
10.1109/TIE.2016.2538741,Adaptive Impedance Control for an Upper Limb Robotic Exoskeleton Using Biological Signals,IEEE,Journals,"This paper presents adaptive impedance control of an upper limb robotic exoskeleton using biological signals. First, we develop a reference musculoskeletal model of the human upper limb and experimentally calibrate the model to match the operator's motion behavior. Then, the proposed novel impedance algorithm transfers stiffness from human operator through the surface electromyography (sEMG) signals, being utilized to design the optimal reference impedance model. Considering the unknown deadzone effects in the robot joints and the absence of the precise knowledge of the robot's dynamics, an adaptive neural network control incorporating with a high-gain observer is developed to approximate the deadzone effect and robot's dynamics and drive the robot tracking desired trajectories without velocity measurements. In order to verify the robustness of the proposed approach, the actual implementation has been performed using a real robotic exoskeleton and a human operator.",https://ieeexplore.ieee.org/document/7426396/,IEEE Transactions on Industrial Electronics,Feb. 2017,ieeexplore
10.1109/TMECH.2015.2396114,Adaptive Neural Network Control of a Compact Bionic Handling Arm,IEEE,Journals,"In this paper, autonomous control problem of a class of bionic continuum robots named “Compact Bionic Handling Arm” (CBHA) is addressed. These robots can reproduce biological behaviors of trunks, tentacles, or snakes. The modeling problem associated with continuum robots includes nonlinearities, structured and unstructured uncertainties, and the hyperredundancy. In addition to these problems, the CBHA comprises the hysteresis behavior of its actuators and a memory phenomenon related to its structure made of polyamide materials. These undesirable effects make it difficult to design a control system based on quantitative models of the CBHA. Thus, two subcontrollers are proposed in this paper. One, encapsulated in the other, and both implemented in real time allow controlling of the CBHA's end-effector position. The first subcontroller controls the CBHA's kinematics based on a distal supervised learning scheme. The second subcontroller controls the CBHA's kinetics based on an adaptive neural control. These subcontrollers allow a better assessment of the stability of the control architecture while ensuring the convergence of Cartesian errors. The obtained experimental results using a CBHA robot show an accurate tracking of the CBHA's end-effector position.",https://ieeexplore.ieee.org/document/7057549/,IEEE/ASME Transactions on Mechatronics,Dec. 2015,ieeexplore
10.1109/TCST.2012.2191969,Adaptive PD Controller Modeled via Support Vector Regression for a Biped Robot,IEEE,Journals,"The real-time balance control of an eight link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, an intelligent computing control technique is used. This technique is based on support vector regression (SVR). The method uses the ZMP error and its variation as inputs, and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR is trained based on simulation data and their performance is verified with a real biped robot. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that is acquired and adapted to the robot's size. Some experiments are presented, and the results show that the implemented gait combined with the SVR controller can be used to control this biped robot. The SVR controller performs the control in 0.2 ms.",https://ieeexplore.ieee.org/document/6180212/,IEEE Transactions on Control Systems Technology,May 2013,ieeexplore
10.1109/TNNLS.2012.2204771,Adaptive Visual and Auditory Map Alignment in Barn Owl Superior Colliculus and Its Neuromorphic Implementation,IEEE,Journals,"Adaptation is one of the most important phenomena in biology. A young barn owl can adapt to imposed environmental changes, such as artificial visual distortion caused by wearing a prism. This adjustment process has been modeled mathematically and the model replicates the sensory map realignment of barn owl superior colliculus (SC) through axonogenesis and synaptogenesis. This allows the biological mechanism to be transferred to an artificial computing system and thereby imbue it with a new form of adaptability to the environment. The model is demonstrated in a real-time robot environment. Results of the experiments are compared with and without prism distortion of vision, and show improved adaptability for the robot. However, the computation speed of the embedded system in the robot is slow. A digital and analog mixed signal very-large-scale integration (VLSI) circuit has been fabricated to implement adaptive sensory pathway changes derived from the SC model at higher speed. VLSI experimental results are consistent with simulation results.",https://ieeexplore.ieee.org/document/6255791/,IEEE Transactions on Neural Networks and Learning Systems,Sept. 2012,ieeexplore
10.1109/JIOT.2020.2979413,Adversarial Learning-Enabled Automatic WiFi Indoor Radio Map Construction and Adaptation With Mobile Robot,IEEE,Journals,"Location-based service (LBS) has become an indispensable part of our daily lives. Realizing accurate LBS in indoor environments is still a challenging task. WiFi fingerprinting-based indoor positioning system (IPS) has achieved encouraging results recently, but the time and labor overhead of constructing a dense WiFi radio map remains the key bottleneck that hinders it for real-world large-scale implementation. In this article, we propose WiGAN an automatic fine-grained indoor ratio map construction and the adaptation scheme empowered by the Gaussian process regression conditioned least-squares generative adversarial networks (GPR-GANs) with a mobile robot. First, we develop a mobile robotic platform that constructs the spatial map and radio map simultaneously in the easily accessed free space. GPR-GAN first establishes a Gaussian process regression (GPR) model using the real received signal strength (RSS) measurements collected by our robotic platform via LiDAR SLAM in the free space. Then, the outputs of the GPR are adopted as the input of GAN's generator. The learning objective of GAN is to synthesize realistic RSS data in a constrained space where it has not been covered and model the irregular RSS distributions in complex indoor environments. Real-world experiments were conducted in a real-world indoor environment, which confirms the feasibility, high accuracy, and superiority of WiGAN over existing solutions in terms of both RSS estimation accuracy and localization accuracy.",https://ieeexplore.ieee.org/document/9031749/,IEEE Internet of Things Journal,Aug. 2020,ieeexplore
10.1109/LRA.2020.2965911,Aggressive Perception-Aware Navigation Using Deep Optical Flow Dynamics and PixelMPC,IEEE,Journals,"Recently, vision-based control has gained traction by leveraging the power of machine learning. In this work, we couple a model predictive control (MPC) framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics, which is a combination of optical flow and robot dynamics. Using the DOF dynamics, MPC explicitly incorporates the predicted movement of relevant pixels into the planned trajectory of a robot. Our implementation of DOF is memory-efficient, data-efficient, and computationally cheap so that it can be computed in real-time for use in an MPC framework. The suggested Pixel Model Predictive Control (PixelMPC) algorithm controls the robot to accomplish a high-speed racing task while maintaining visibility of the important features (gates). This improves the reliability of vision-based estimators for localization and can eventually lead to safe autonomous flight. The proposed algorithm is tested in a photorealistic simulation with a high-speed drone racing task.",https://ieeexplore.ieee.org/document/8957291/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/OJCS.2020.3001839,An Instrument for Remote Kissing and Engineering Measurement of Its Communication Effects Including Modified Turing Test,IEEE,Journals,"Various communication systems have been developed to integrate the haptic channel in digital communication. Future directions of such haptic technologies are moving towards realistic virtual reality applications and human-robot social interaction. With the digitisation of touch, robots equipped with touch sensors and actuators can communicate with humans on a more emotional and intimate level, such as sharing a hug or kiss just like humans do. This paper presents the design guideline, implementation and evaluations of a novel haptic kissing machine for smart phones - the Kissenger machine. The key novelties and contributions of the paper are: (i) A novel haptic kissing device for mobile phones, which uses dynamic perpendicular force stimulation to transmit realistic sensations of kissing in order to enhance intimacy and emotional connection of digital communication; (ii) Extensive evaluations of the Kissenger machine, including a lab experiment that compares mediated kissing with Kissenger to real kissing, a unique haptic Turing test that involves the first academic study of human-machine kiss, and a field study of the effects of Kissenger on long distance relationships. The first experiment showed that mediated kissing with Kissenger elicited similar ratings for pleasure, arousal and user experience as real kissing. Experiment 2 confirmed our hypothesis that interrogators have a higher chance of winning the Imitation Game (Turing test) when Kissenger is used during the game. Results from experiment 3 showed that long relationship couples who used Kissenger for a week experienced increased relationship satisfaction and decreased perceived stress.",https://ieeexplore.ieee.org/document/9119758/,IEEE Open Journal of the Computer Society,2020,ieeexplore
10.1109/TIE.2020.2979561,An Intelligent Non-Integer PID Controller-Based Deep Reinforcement Learning: Implementation and Experimental Results,IEEE,Journals,"In this article, a noninteger proportional integral derivative (PID)-type controller based on the deep deterministic policy gradient algorithm is developed for the tracking problem of a mobile robot. This robot system is a typical case of nonholonomic plants and is exposed to the measurement noises and external disturbances. To accomplish the control methodology, two control mechanisms are established independently: a kinematic controller (which is designed based on the kinematic model of the vehicle), and a dynamic controller (which is realized according to the physical specifications of the vehicle dynamics). In particular, an optimal noninteger PID controller is initially designed as the primary dynamic controller for the tracking problem of a nonholonomic wheeled mobile robot. Then, a DDPG algorithm with the actor-critic framework is established for the supplementary dynamic controller, which is beneficial to the tracking stabilization by adapting to the uncertainties and disturbances. This strategy implements the supplementary based control to compensate for what the original controller is unable to handle. A prototype of the WMR was also adopted to investigate the applicability of the suggested controller from a real-time platform perspective. The outcomes in experimental environments are presented to affirm the effectiveness of the suggested control methodology.",https://ieeexplore.ieee.org/document/9042812/,IEEE Transactions on Industrial Electronics,April 2021,ieeexplore
10.1109/JTEHM.2018.2822681,An IoT-Enabled Stroke Rehabilitation System Based on Smart Wearable Armband and Machine Learning,IEEE,Journals,"Surface electromyography signal plays an important role in hand function recovery training. In this paper, an IoT-enabled stroke rehabilitation system was introduced which was based on a smart wearable armband (SWA), machine learning (ML) algorithms, and a 3-D printed dexterous robot hand. User comfort is one of the key issues which should be addressed for wearable devices. The SWA was developed by integrating a low-power and tiny-sized IoT sensing device with textile electrodes, which can measure, pre-process, and wirelessly transmit bio-potential signals. By evenly distributing surface electrodes over user's forearm, drawbacks of classification accuracy poor performance can be mitigated. A new method was put forward to find the optimal feature set. ML algorithms were leveraged to analyze and discriminate features of different hand movements, and their performances were appraised by classification complexity estimating algorithms and principal components analysis. According to the verification results, all nine gestures can be successfully identified with an average accuracy up to 96.20%. In addition, a 3-D printed five-finger robot hand was implemented for hand rehabilitation training purpose. Correspondingly, user's hand movement intentions were extracted and converted into a series of commands which were used to drive motors assembled inside the dexterous robot hand. As a result, the dexterous robot hand can mimic the user's gesture in a real-time manner, which shows the proposed system can be used as a training tool to facilitate rehabilitation process for the patients after stroke.",https://ieeexplore.ieee.org/document/8356006/,IEEE Journal of Translational Engineering in Health and Medicine,2018,ieeexplore
10.1109/21.3461,An approach to an expert robot welding system,IEEE,Journals,"Adaptive control and sensory processing techniques in robotic arc welding are discussed. The gas metal arc welding and gas tungsten arc welding processes are considered, along with a literature review of aspects of welding automation. Topics covered include process modeling, detection and measurement of process features, real-time control, and implementation considerations. An approach for an adaptive welding system is presented. The proposed architecture fits within the scope of an ambitious project to develop an expert welding robot. Different levels of automation are discussed, from the decision level to the closed-loop control of process variables and torch trajectory.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/3461/,"IEEE Transactions on Systems, Man, and Cybernetics",March-April 1988,ieeexplore
10.1109/70.68083,An automatic navigation system for vision guided vehicles using a double heuristic and a finite state machine,IEEE,Journals,"A navigation system for automatic vision-guided vehicles which uses an efficient double heuristic search algorithm for path planning is presented. It is capable of avoiding unknown obstacles and recovering from unidentifiable locations. A linked list representation of the path network database makes the implementation feasible in any high-level language and renders it suitable for real-time application. Extensive simulated experiments have been conducted to verify the validity of the proposed algorithms. The combination of the techniques of robot navigation in unexplored terrain and the global map method proved to be a valid technique for automated guided vehicle (AGV) guidance. A learning mechanism is used in the AGV by updating the path network during navigation. Simulated results supported all the theoretically expected conclusions, since the robot planned its path correctly between the requested nodes and maneuvered its way around the obstacles. Overall, the results were very encouraging.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/68083/,IEEE Transactions on Robotics and Automation,Feb. 1991,ieeexplore
10.1109/TNN.2005.845217,Auditory learning: a developmental method,IEEE,Journals,"Motivated by the human autonomous development process from infancy to adulthood, we have built a robot that develops its cognitive and behavioral skills through real-time interactions with the environment. We call such a robot a developmental robot. In this paper, we present the theory and the architecture to implement a developmental robot and discuss the related techniques that address an array of challenging technical issues. As an application, experimental results on a real robot, self-organizing, autonomous, incremental learner (SAIL), are presented with emphasis on its audition perception and audition-related action generation. In particular, the SAIL robot conducts the auditory learning from unsegmented and unlabeled speech streams without any prior knowledge about the auditory signals, such as the designated language or the phoneme models. Neither available before learning starts are the actions that the robot is expected to perform. SAIL learns the auditory commands and the desired actions from physical contacts with the environment including the trainers.",https://ieeexplore.ieee.org/document/1427765/,IEEE Transactions on Neural Networks,May 2005,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/ACCESS.2021.3079427,Autonomous Endoscope Robot Positioning Using Instrument Segmentation With Virtual Reality Visualization,IEEE,Journals,"This paper presents a method for endoscope's autonomous positioning by a robotic endoscope holder for minimally invasive surgery. The method improves human-robot cooperation in robot-assisted surgery by allowing the endoscope holder to acknowledge the surgeon's view projection and navigate the camera without manual control. The real-time prediction of next desired camera location is estimated using segmented instrument's tip locations from endoscope video and surgeon's attention focus given by tracked virtual reality headset. To tackle the issue of real-time surgical instrument segmentation for more precise instrument tip localization, we propose the YOLOv3 and ResNet Combined Neural Network. The method showed an 86.6% IoU across MICCAI'17 Endovis datasets with 30 frames per second processing speed. The proposed pipeline was implemented in ROS on Ubuntu with visualization running under Windows operating system in Unity3D. The simulation demonstrates the robotic arm, endoscope, and surgical environment visualized in 3D in the virtual reality headset to provide a stable view of the endoscope and improve the surgeon's perception of the operating environment.",https://ieeexplore.ieee.org/document/9429186/,IEEE Access,2021,ieeexplore
10.1109/TSMCA.2003.811766,Autonomous fuzzy parking control of a car-like mobile robot,IEEE,Journals,"This paper is devoted to design and implement a car-like mobile robot (CLMR) that possesses autonomous garage-parking and parallel-parking capability by using real-time image processing. For fuzzy garage-parking control (FGPC) and fuzzy parallel-parking control (FPPC), feasible reference trajectories are provided for the fuzzy logic controller to maneuver the steering angle of the CLMR. We propose two FGPC methods and two FPPC methods to back-drive or head-in the CLMR to the garage and the parking lot, respectively. Simulation results illustrate the effectiveness of the developed schemes. The overall experimental setup of the parking system developed in this paper is composed of a host computer, a communication module, a CLMR, and a vision system. Finally, the image-based real-time implementation experiments of the CLMR demonstrate the feasibility and effectiveness of the proposed schemes.",https://ieeexplore.ieee.org/document/1235979/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/ACCESS.2021.3093340,Ball Motion Control in the Table Tennis Robot System Using Time-Series Deep Reinforcement Learning,IEEE,Journals,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball’s accurate motion control, which depends on various factors such as the incoming ball’s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball’s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball’s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable “target landing location” and the “over-net height” which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70%.",https://ieeexplore.ieee.org/document/9467347/,IEEE Access,2021,ieeexplore
10.1109/LRA.2017.2737046,Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing,IEEE,Journals,"We demonstrate a low-cost telerobotic system that leverages commercial virtual reality (VR) technology and integrates it with existing robotics control infrastructure. The system runs on a commercial gaming engine using off-the-shelf VR hardware and can be deployed on multiple network architectures. The system is based on the homunculus model of mind wherein we embed the user in a VR control room. The control room allows for multiple sensor displays, and dynamic mapping between the user and robot. This dynamic mapping allows for selective engagement between the user and the robot. We compared our system with state-of-the-art automation algorithms and standard VR-based telepresence systems by performing a user study. The study showed that new users were faster and more accurate than the automation or a direct telepresence system. We also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",https://ieeexplore.ieee.org/document/8003431/,IEEE Robotics and Automation Letters,Jan. 2018,ieeexplore
10.1109/LRA.2021.3062303,Bi-Directional Domain Adaptation for Sim2Real Transfer of Embodied Navigation Agents,IEEE,Journals,"Deep reinforcement learning models are notoriously data hungry, yet real-world data is expensive and time consuming to obtain. The solution that many have turned to is to use simulation for training before deploying the robot in a real environment. Simulation offers the ability to train large numbers of robots in parallel, and offers an abundance of data. However, no simulation is perfect, and robots trained solely in simulation fail to generalize to the real-world, resulting in a “sim-vs-real gap”. How can we overcome the trade-off between the abundance of less accurate, artificial data from simulators and the scarcity of reliable, real-world data? In this letter, we propose Bi-directional Domain Adaptation (BDA), a novel approach to bridge the sim-vs-real gap in both directions- real2sim to bridge the visual domain gap, and sim2real to bridge the dynamics domain gap. We demonstrate the benefits of BDA on the task of PointGoal Navigation. BDA with only 5 k real-world (state, action, next-state) samples matches the performance of a policy fine-tuned with ~ 600 k samples, resulting in a speed-up of ~ 120×.",https://ieeexplore.ieee.org/document/9363564/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TSMCB.2009.2018138,Cerebellar-Inspired Adaptive Control of a Robot Eye Actuated by Pneumatic Artificial Muscles,IEEE,Journals,"In this paper, a model of cerebellar function is implemented and evaluated in the control of a robot eye actuated by pneumatic artificial muscles. The investigated control problem is stabilization of the visual image in response to disturbances. This is analogous to the vestibuloocular reflex (VOR) in humans. The cerebellar model is structurally based on the adaptive filter, and the learning rule is computationally analogous to least-mean squares, where parameter adaptation at the parallel fiber/Purkinje cell synapse is driven by the correlation of the sensory error signal (carried by the climbing fiber) and the motor command signal. Convergence of the algorithm is first analyzed in simulation on a model of the robot and then tested online in both one and two degrees of freedom. The results show that this model of neural function successfully works on a real-world problem, providing empirical evidence for validating: 1) the generic cerebellar learning algorithm; 2) the function of the cerebellum in the VOR; and 3) the signal transmission between functional neural components of the VOR.",https://ieeexplore.ieee.org/document/4814555/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Dec. 2009,ieeexplore
10.1109/ACCESS.2020.2990405,Clustering-Based Speech Emotion Recognition by Incorporating Learned Features and Deep BiLSTM,IEEE,Journals,"Emotional state recognition of a speaker is a difficult task for machine learning algorithms which plays an important role in the field of speech emotion recognition (SER). SER plays a significant role in many real-time applications such as human behavior assessment, human-robot interaction, virtual reality, and emergency centers to analyze the emotional state of speakers. Previous research in this field is mostly focused on handcrafted features and traditional convolutional neural network (CNN) models used to extract high-level features from speech spectrograms to increase the recognition accuracy and overall model cost complexity. In contrast, we introduce a novel framework for SER using a key sequence segment selection based on redial based function network (RBFN) similarity measurement in clusters. The selected sequence is converted into a spectrogram by applying the STFT algorithm and passed into the CNN model to extract the discriminative and salient features from the speech spectrogram. Furthermore, we normalize the CNN features to ensure precise recognition performance and feed them to the deep bi-directional long short-term memory (BiLSTM) to learn the temporal information for recognizing the final state of emotion. In the proposed technique, we process the key segments instead of the whole utterance to reduce the computational complexity of the overall model and normalize the CNN features before their actual processing, so that it can easily recognize the Spatio-temporal information. The proposed system is evaluated over different standard dataset including IEMOCAP, EMO-DB, and RAVDESS to improve the recognition accuracy and reduce the processing time of the model, respectively. The robustness and effectiveness of the suggested SER model is proved from the experimentations when compared to state-of-the-art SER methods with an achieve up to 72.25%, 85.57%, and 77.02% accuracy over IEMOCAP, EMO-DB, and RAVDESS dataset, respectively.",https://ieeexplore.ieee.org/document/9078789/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2018.2845855,Color Transfer Pulse-Coupled Neural Networks for Underwater Robotic Visual Systems,IEEE,Journals,"With rapid developments in cloud computing, artificial intelligence, and robotic systems, ever more complex tasks, such as space and ocean exploration, are being implemented by intelligent robots. Here, we propose an underwater image enhancement scheme for robotic visual systems. The proposed algorithm and its implementation enhances and outputs an image captured by an underwater robot in real time. In this scheme, pulse-coupled neural network (PCNN)-based image enhancement and color transfer algorithms are combined to enhance the underwater image. To avoid color imbalance in the underwater image and enhance details while suppressing noise, color correction is first carried out on the underwater image before converting it into the hue-saturation-intensity domain and enhancing it by PCNN. The enhanced result improves the color and contrast of the source image and enhances the details and edges of darker regions. Experiments are performed on real world data to demonstrate the effectiveness of the proposed scheme.",https://ieeexplore.ieee.org/document/8377996/,IEEE Access,2018,ieeexplore
10.1109/TSMCB.2006.874131,Control Architecture for Human–Robot Integration: Application to a Robotic Wheelchair,IEEE,Journals,"Completely autonomous performance of a mobile robot within noncontrolled and dynamic environments is not possible yet due to different reasons including environment uncertainty, sensor/software robustness, limited robotic abilities, etc. But in assistant applications in which a human is always present, she/he can make up for the lack of robot autonomy by helping it when needed. In this paper, the authors propose human-robot integration as a mechanism to augment/improve the robot autonomy in daily scenarios. Through the human-robot-integration concept, the authors take a further step in the typical human-robot relation, since they consider her/him as a constituent part of the human-robot system, which takes full advantage of the sum of their abilities. In order to materialize this human integration into the system, they present a control architecture, called architecture for human-robot integration, which enables her/him from a high decisional level, i.e., deliberating a plan, to a physical low level, i.e., opening a door. The presented control architecture has been implemented to test the human-robot integration on a real robotic application. In particular, several real experiences have been conducted on a robotic wheelchair aimed to provide mobility to elderly people",https://ieeexplore.ieee.org/document/1703648/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2006,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.3003256,Denoising IMU Gyroscopes With Deep Learning for Open-Loop Attitude Estimation,IEEE,Journals,"This article proposes a learning method for denoising gyroscopes of Inertial Measurement Units (IMUs) using ground truth data, and estimating in real time the orientation (attitude) of a robot in dead reckoning. The obtained algorithm outperforms the state-of-the-art on the (unseen) test sequences. The obtained performances are achieved, thanks to a well-chosen model, a proper loss function for orientation increments, and through the identification of key points when training with high-frequency inertial data. Our approach builds upon a neural network based on dilated convolutions, without requiring any recurrent neural network. We demonstrate how efficient our strategy is for 3D attitude estimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead reckoning algorithm manages to beat top-ranked visual-inertial odometry systems in terms of attitude estimation although it does not use vision sensors. We believe this article offers new perspectives for visual-inertial localization and constitutes a step toward more efficient learning methods involving IMUs. Our open-source implementation is available at https://github.com/mbrossar/denoise-imu-gyro.",https://ieeexplore.ieee.org/document/9119813/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/ACCESS.2020.3033550,Developing a Lightweight Rock-Paper-Scissors Framework for Human-Robot Collaborative Gaming,IEEE,Journals,"We present a novel implementation of a Rock-Paper-Scissors (RPS) game interaction with a social robot. The framework is tailored to be computationally lightweight, as well as entertaining and visually appealing through collaboration with designers and animators. The fundamental gesture recognition pipeline employs a Leap motion device and two separate machine learning architectures to evaluate kinematic hand data on-the-fly. The first architecture is used to recognize and segment human motion activity in order to initialize the RPS play, and the second architecture is used to classify hand gestures into rock, paper or scissors. The employed tabletop robot interacts in the RPS play through unique animated gestural movements and vocalizations designed by animators which communicate the robot's choices as well as cognitive reflection on winning, losing and draw states. Performance of both learning architectures is carefully evaluated with respect to accuracy, reliability and run time performance under different feature and classifier types. Moreover, we assess our system during an interactive RPS play between robot and human. Experimental results show that the proposed system is robust to user variations and play style in real environment conditions. As such, it offers a powerful application for the subsequent exploration of social human-machine interaction.",https://ieeexplore.ieee.org/document/9239276/,IEEE Access,2020,ieeexplore
10.1109/3516.537045,Development and integration of generic components for a teachable vision-based mobile robot,IEEE,Journals,"This paper presents a mobile robotic system for human assistance in navigation-the robot navigates by receiving visual instructions from a human being and is able to replicate them autonomously. We describe three generic components defined as the HOST, the VISION, and the CONTROL components as well as their integration in our teachable mobile robot. These components are connected to each other via a transputer serial link, namely they are loosely coupled, they work in parallel and are asynchronous with each other. Each component is described with a peculiar feature of extensibility. Especially in the VISION component, there are two major features. The first one is a correlator which each vision board possesses. The correlator does block-matching between the template and the grabbed images in real-time. The other is the PIM library which manages the visual tasks over limited parallel visual resources of the mobile robot. These features of our design enable the system to be real-time and allow for efficient and extensible software development. In order to show the feasibility of our system design, we present a preliminary experiment of the route teaching on our mobile robot.",https://ieeexplore.ieee.org/document/537045/,IEEE/ASME Transactions on Mechatronics,Sept. 1996,ieeexplore
10.1109/TMECH.2013.2294180,Development of a Laser-Range-Finder-Based Human Tracking and Control Algorithm for a Marathoner Service Robot,IEEE,Journals,"This paper presents a human detection algorithm and an obstacle avoidance algorithm for a marathoner service robot (MSR) that provides a service to a marathoner while training. To be used as a MSR, the mobile robot should have the abilities to follow a running human and avoid dynamically moving obstacles in an unstructured outdoor environment. To detect a human by a laser range finder (LRF), we defined features of the human body in LRF data and employed a support vector data description method. In order to avoid moving obstacles while tracking a running person, we defined a weighted radius for each obstacle using the relative velocity between the robot and an obstacle. For smoothly bypassing obstacles without collision, a dynamic obstacle avoidance algorithm for the MSR is implemented, which directly employed a real-time position vector between the robot and the shortest path around the obstacle. We verified the feasibility of these proposed algorithms through experimentation in different outdoor environments.",https://ieeexplore.ieee.org/document/6690173/,IEEE/ASME Transactions on Mechatronics,Dec. 2014,ieeexplore
10.1109/TSMCB.2004.831151,Development of a biomimetic robotic fish and its control algorithm,IEEE,Journals,"This paper is concerned with the design of a robotic fish and its motion control algorithms. A radio-controlled, four-link biomimetic robotic fish is developed using a flexible posterior body and an oscillating foil as a propeller. The swimming speed of the robotic fish is adjusted by modulating joint's oscillating frequency, and its orientation is tuned by different joint's deflections. Since the motion control of a robotic fish involves both hydrodynamics of the fluid environment and dynamics of the robot, it is very difficult to establish a precise mathematical model employing purely analytical methods. Therefore, the fish's motion control task is decomposed into two control systems. The online speed control implements a hybrid control strategy and a proportional-integral-derivative (PID) control algorithm. The orientation control system is based on a fuzzy logic controller. In our experiments, a point-to-point (PTP) control algorithm is implemented and an overhead vision system is adopted to provide real-time visual feedback. The experimental results confirm the effectiveness of the proposed algorithms.",https://ieeexplore.ieee.org/document/1315762/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Aug. 2004,ieeexplore
10.1109/56.802,Dynamic multi-sensor data fusion system for intelligent robots,IEEE,Journals,"The objective of the authors is to develop an intelligent robot workstation capable of integrating data from multiple sensors. The investigation is based on a Unimation PUMA 560 robot and various external sensors. These include overhead vision, eye-in-hand vision, proximity, tactile array, position, force/torque, cross-fire, overload, and slip-sensing devices. The efficient fusion of data from different sources will enable the machine to respond promptly in dealing with the 'real world'. Towards this goal, the general paradigm of a sensor data fusion system has been developed, and some simulation results, as well as results from the actual implementation of certain concepts of sensor data fusion, have been demonstrated.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/802/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/TPAMI.2019.2899570,End-to-End Active Object Tracking and Its Real-World Deployment via Reinforcement Learning,IEEE,Journals,"We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.",https://ieeexplore.ieee.org/document/8642452/,IEEE Transactions on Pattern Analysis and Machine Intelligence,1 June 2020,ieeexplore
10.1109/TNNLS.2018.2830119,Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source Localization,IEEE,Journals,"Inspired by the behavior of humans talking in noisy environments, we propose an embodied embedded cognition approach to improve automatic speech recognition (ASR) systems for robots in challenging environments, such as with ego noise, using binaural sound source localization (SSL). The approach is verified by measuring the impact of SSL with a humanoid robot head on the performance of an ASR system. More specifically, a robot orients itself toward the angle where the signal-to-noise ratio (SNR) of speech is maximized for one microphone before doing an ASR task. First, a spiking neural network inspired by the midbrain auditory system based on our previous work is applied to calculate the sound signal angle. Then, a feedforward neural network is used to handle high levels of ego noise and reverberation in the signal. Finally, the sound signal is fed into an ASR system. For ASR, we use a system developed by our group and compare its performance with and without the support from SSL. We test our SSL and ASR systems on two humanoid platforms with different structural and material properties. With our approach we halve the sentence error rate with respect to the common downmixing of both channels. Surprisingly, the ASR performance is more than two times better when the angle between the humanoid head and the sound source allows sound waves to be reflected most intensely from the pinna to the ear microphone, rather than when sound waves arrive perpendicularly to the membrane.",https://ieeexplore.ieee.org/document/8371531/,IEEE Transactions on Neural Networks and Learning Systems,Jan. 2019,ieeexplore
10.1109/70.650165,Environment prediction for a mobile robot in a dynamic environment,IEEE,Journals,"The problem of navigating a mobile robot among moving obstacles is usually solved on the condition of knowing the velocity of obstacles. However, it is difficult to provide such information to a robot in real time. In this paper, we present an environment predictor that provides an estimate of future environment configuration by fusing multisensor data in real time. The predictor is implemented by an artificial neural network (ANN) trained using a relative-error-backpropagation (REBP) algorithm. The REBP algorithm enables the ANN to provide output data with a minimum relative error, which is better than conventional backpropagation (BP) algorithms in this prediction application. The mobile robot can, therefore, respond to anticipated changes in the environment. The performance is verified by prediction simulation and navigation experiments.",https://ieeexplore.ieee.org/document/650165/,IEEE Transactions on Robotics and Automation,Dec. 1997,ieeexplore
10.1109/TIM.2021.3089240,Fault Diagnosis of Harmonic Drive With Imbalanced Data Using Generative Adversarial Network,IEEE,Journals,"Harmonic drive is the core component of the industrial robot, and its fault diagnosis is crucial to the reliability and performance of the equipment. Most machine learning methods achieve good results based on the assumption of data balance. However, the scarce fault data of harmonic drive is difficult to collect, resulting in various imbalanced health status samples, which has an adverse effect on fault diagnosis. In this article, we propose a data generation method based on generative adversarial networks (GANs) to solve the problem of data imbalance and utilize the multiscale convolutional neural network (MSCNN) to realize the fault diagnosis of the harmonic drive. First, the data collected from three vibration acceleration sensors are preprocessed by fast Fourier transform (FFT) to obtain the frequency spectrum of the vibration signal. Second, multiple GANs were adopted to generate various fault spectrum data and the data selection module (DSM) is elaborately designed to filter and purify these data. Third, the filtered generated data will be combined with the real data to form a balanced dataset, and then the MSCNN is used to achieve multiclassification of the health status of the harmonic drive. Finally, the experiments have been implemented on an industrial robot vibration test bench to validate the effectiveness of our approach. The results have shown the fault multiclassification accuracy as 98.49% under imbalanced fault data conditions, which outperforms that of the other compared methods.",https://ieeexplore.ieee.org/document/9454583/,IEEE Transactions on Instrumentation and Measurement,2021,ieeexplore
10.1109/JPROC.2002.801451,First steps of robotic perception: the turning point of the 1990s,IEEE,Journals,"In this paper we analyze the early evolution of robot perception toward robot autonomy: respective impacts of the bare technology and of advanced control are put in perspective. At first, the UniBuM's vehicle, operational in the 1990s, is taken as a study example. The strong points of such systems suggest a discussion of the software technology in image processing and of the hardware technological concept of silicon retina regarding their respective contribution to real machine vision. This second part elicits limitations, which lead again to concepts and realizations in control, through the need for sensor fusion and active vision. The ultimate step to robot autonomy would be learning, and this is considered in the conclusion.",https://ieeexplore.ieee.org/document/1032796/,Proceedings of the IEEE,July 2002,ieeexplore
10.1109/TOH.2017.2753233,Functional Contour-following via Haptic Perception and Reinforcement Learning,IEEE,Journals,"Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",https://ieeexplore.ieee.org/document/8039205/,IEEE Transactions on Haptics,1 Jan.-March 2018,ieeexplore
10.1109/LRA.2019.2955941,Generative Localization With Uncertainty Estimation Through Video-CT Data for Bronchoscopic Biopsy,IEEE,Journals,"Robot-assisted endobronchial intervention requires accurate localization based on both intra- and pre-operative data. Most existing methods achieve this by registering 2D videos with 3D CT models according to a defined similarity metric with local features. Instead, we formulate the bronchoscopic localization as a learning-based global localisation using deep neural networks. The proposed network consists of two generative architectures and one auxiliary learning component. The cycle generative architecture bridges the domain variance between the real bronchoscopic videos and virtual views derived from pre-operative CT data so that the proposed approach can be trained through a large number of generated virtual images but deployed through real images. The auxiliary learning architecture leverages complementary relative pose regression to constrain the search space, ensuring consistent global pose predictions. Most importantly, the uncertainty of each global pose is obtained through variational inference by sampling within the learned underlying probability distribution. Detailed validation results demonstrate the localization accuracy with reasonable uncertainty achieved and its potential clinical value. A demonstration video demo can be found on the website <uri>https://youtu.be/ci9LMY49aF8</uri>.",https://ieeexplore.ieee.org/document/8913461/,IEEE Robotics and Automation Letters,Jan. 2020,ieeexplore
10.1109/ACCESS.2019.2938366,Grasping Objects From the Floor in Assistive Robotics: Real World Implications and Lessons Learned,IEEE,Journals,"This paper presents a system enabling a mobile robot to autonomously pick-up objects a human is pointing at from the floor. The system does not require object models and is designed to grasp unknown objects. The robot decides by itself if an object is suitable for grasping by considering measures of size, position and the environment suitability. The implementation is built on the second prototype of the home care robot Hobbit, thereby verifying that complex robotic manipulation tasks can be performed with economical hardware. The presented system was already tested in real apartments with elderly people. We highlight this by discussing the additional complexity for complete autonomous behavior in apartments compared with tests in labs.",https://ieeexplore.ieee.org/document/8819885/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2020.3043662,Ground-Level Mapping and Navigating for Agriculture Based on IoT and Computer Vision,IEEE,Journals,"Autonomous agricultural systems are a promising solution to bridge the gap between labor shortage for agriculture tasks and the continuing needs for increasing productivity in agriculture. Automated mapping and navigation system will be a cornerstone of most autonomous agricultural system. Accordingly, we propose a ground-level mapping and navigating system based on computer vision technology (Mesh Simultaneous Localization and Mapping algorithm, Mesh-SLAM) and Internet of Things (IoT), to generate a 3D farm map on both the edge side and cloud. The innovation of this system includes three layers as sub-systems that are 1) ground-level robot vehicles' layer for conducting frames collection only with a monocular camera, 2) edge node layer for image feature data edge computing and communication, and 3) cloud layer for general management and deep computing. High efficiency and speed of mapping stage are enabled by making the robot vehicles directly stream continuous frames to their corresponding edge node. Then each edge node, that coordinate a certain range of robots, applies a new Mesh-SLAM frame by frame, whose core is reconstructing the features map by a mesh-based algorithm with scalable units and reduce the feature data size by a filtering algorithm. Additionally, the cloud-computing allows comprehensive arrangement and heavily deep computing. The system is scalable to larger-scale fields and more complex environment by taking advantage of dynamically distributing the computation power to edges. Our evaluation indicates that: 1) this Mesh-SLAM algorithm outperforms in mapping and localization precision, accuracy, and yield prediction error (resolution at centimeter); and 2) The scalability and flexibility of the IoT architecture make the system modularized, easy adding/removing new functional modules or IoT sensors. We conclude the trade-off between cost and performance widely augments the feasibility and practical implementation of this system in real farms.",https://ieeexplore.ieee.org/document/9288741/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.2979656,Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion,IEEE,Journals,"Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",https://ieeexplore.ieee.org/document/9028178/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TIE.2006.888791,Hardware Implementation of a Real-Time Neural Network Controller With a DSP and an FPGA for Nonlinear Systems,IEEE,Journals,"In this paper, we implement the intelligent neural network controller hardware with a field programmable gate array (FPGA)-based general purpose chip and a digital signal processing (DSP) board to solve nonlinear system control problems. The designed intelligent control hardware can perform real-time control of the backpropagation learning algorithm of a neural network. The basic proportional-integral-derivative (PID) control algorithms are implemented in an FPGA chip and a neural network controller is implemented in a DSP board. By using a high capacity of an FPGA chip, the additional hardware such as an encoder counter and a pulsewidth modulation (PWM) generator is implemented in a single FPGA chip. As a result, the controller becomes cost effective. It was tested for controlling nonlinear systems such as a robot finger and an inverted pendulum on a moving cart to show performance of the controller",https://ieeexplore.ieee.org/document/4084734/,IEEE Transactions on Industrial Electronics,Feb. 2007,ieeexplore
10.1109/3477.499796,Hidden state and reinforcement learning with instance-based state identification,IEEE,Journals,"Real robots with real sensors are not omniscient. When a robot's next course of action depends on information that is hidden from the sensors because of problems such as occlusion, restricted range, bounded field of view and limited attention, we say the robot suffers from the hidden state problem. State identification techniques use history information to uncover hidden state. Some previous approaches to encoding history include: finite state machines, recurrent neural networks and genetic programming with indexed memory. A chief disadvantage of all these techniques is their long training time. This paper presents instance-based state identification, a new approach to reinforcement learning with state identification that learns with much fewer training steps. Noting that learning with history and learning in continuous spaces both share the property that they begin without knowing the granularity of the state space, the approach applies instance-based (or ""memory-based"") learning to history sequences-instead of recording instances in a continuous geometrical space, we record instances in action-percept-reward sequence space. The first implementation of this approach, called Nearest Sequence Memory, learns with an order of magnitude fewer steps than several previous approaches.",https://ieeexplore.ieee.org/document/499796/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/ACCESS.2021.3063782,Hierarchical Decomposed-Objective Model Predictive Control for Autonomous Casualty Extraction,IEEE,Journals,"In recent years, several robots have been developed and deployed to perform casualty extraction tasks. However, the majority of these robots are overly complex, and require teleoperation via either a skilled operator or a specialised device, and often the operator must be present at the scene to navigate safely around the casualty. Instead, improving the autonomy of such robots can reduce the reliance on expert operators and potentially unstable communication systems, while still extracting the casualty in a safe manner. There are several stages in the casualty extraction procedure, from navigating to the location of the emergency, safely approaching and loading the casualty, to finally navigating back to the medical assistance location. In this paper, we propose a Hierarchical Decomposed-Objective based Model Predictive Control (HiDO-MPC) method for safely approaching and manoeuvring around the casualty. We implement this controller on ResQbot — a proof-of-concept mobile rescue robot we previously developed — capable of safely rescuing an injured person lying on the ground, i.e. performing the casualty extraction procedure. HiDO-MPC achieves the desired casualty extraction behaviour by decomposing the main objective into multiple sub-objectives with a hierarchical structure. At every time step, the controller evaluates this hierarchical decomposed objective and generates the optimal control decision. We have conducted a number of experiments both in simulation and using the real robot to evaluate the proposed method’s performance, and compare it with baseline approaches. The results demonstrate that the proposed control strategy gives significantly better results than baseline approaches in terms of accuracy, robustness, and execution time, when applied to casualty extraction scenarios.",https://ieeexplore.ieee.org/document/9369351/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/JSEN.2019.2956901,Human Action Recognition Using Deep Learning Methods on Limited Sensory Data,IEEE,Journals,"In recent years, due to the widespread usage of various sensors action recognition is becoming more popular in many fields such as person surveillance, human-robot interaction etc. In this study, we aimed to develop an action recognition system by using only limited accelerometer and gyroscope data. Several deep learning methods like Convolutional Neural Network(CNN), Long-Short Term Memory (LSTM) with classical machine learning algorithms and their combinations were implemented and a performance analysis was carried out. Data balancing and data augmentation methods were applied and accuracy rates were increased noticeably. We achieved new state-of-the-art result on the UCI HAR dataset by 97.4% accuracy rate with using 3 layer LSTM model. Also, we implemented same model on collected dataset (ETEXWELD) and 99.0% accuracy rate was obtained which means a solid contribution. Moreover, the performance analysis is not only based on accuracy results, but also includes precision, recall and f1-score metrics. Additionally, a real-time application was developed by using 3 layer LSTM network for evaluating how the best model classifies activities robustly.",https://ieeexplore.ieee.org/document/8918509/,IEEE Sensors Journal,"15 March15, 2020",ieeexplore
10.1109/ACCESS.2020.3012557,Human Interaction Anticipation by Combining Deep Features and Transformed Optical Flow Components,IEEE,Journals,"The anticipation of ongoing human interactions is not only highly dynamic and challenging problem but extremely crucial in applications such as remote monitoring, video surveillance, human-robot interaction, anti-terrorists and anti-crime securities. In this work, we address the problem of anticipating the interactions between people monitored by single as well as multiple camera views. To this end, we propose a novel approach that integrates Deep Features with novel hand-crafted features, namely Transformed Optical Flow Components (TOFCs). In order to validate the performance of the proposed approach, we have tested the proposed approach in real outdoor environments, captured using single as well as multiple cameras, having shadow and illumination variations as well as cluttered backgrounds. The results of the proposed approach are also compared with the state-of-the-art approaches. The experimental results show that the proposed approach is promising to anticipate real human interactions.",https://ieeexplore.ieee.org/document/9151125/,IEEE Access,2020,ieeexplore
10.1109/TOH.2020.3029043,Human-Inspired Haptic Perception and Control in Robot-Assisted Milling Surgery,IEEE,Journals,"Bone milling is one of the most widely used and high-risk procedures in various types of surgeries, and it is important to be noted that the experienced surgeon can perform such an operation safely. The objective of this article is to enhance the safety of the robot-assisted milling operation with the inspiration of human haptic perception. The emergence, coding and perception of the human haptic are introduced. Following this, a single axis accelerometer that measures the vibration of the surgical power tool is mounted in the robot arm, and the recorded acceleration signal is encoded as parallel stream of binary data. The data are subsequently inputted to the Hopfield network so as to identify the milling state. Inspired by human inference procedure, the fuzzy logic controller is introduced to control the robot to track the desired state when performing bone milling operations. A real-time implementation of the proposed method on a digital signal processing is also described. The experimental results in milling porcine spines prove that the robot accurately discriminates different milling states even when the additive noise is serious, and the safe motion control of the robot is also realized.",https://ieeexplore.ieee.org/document/9220848/,IEEE Transactions on Haptics,1 April-June 2021,ieeexplore
10.1109/TCDS.2019.2954289,Human-in-the-Loop Control Strategy of Unilateral Exoskeleton Robots for Gait Rehabilitation,IEEE,Journals,"In this article, a human-in-the-loop control methodology is proposed for the gait rehabilitation of patients with hemiplegia. It utilizes a unilateral exoskeleton system consisting of a unilateral lower limb exoskeleton and a real-time robot follower, such that the affected legs can be coordinated with the healthy legs with the assistance of the exoskeleton robot. In order to achieve immersive training during the physical therapy, the human-in-the-loop controller is developed. Furthermore, a region-based barrier Lyapunov function (BLF) is designed to separate the task workspace of the exoskeleton into a human region and a robot region, enabling the human leg to follow the desired motion trajectory in a compliant region, and the motion control of the exoskeleton is determined by humans; while in the robot region, the exoskeleton dominates the movement of human subjects. In order to make the motion control transit smoothly between the robot region and the human region, an adaptive controller is exploited to counteract the system's nonlinear uncertainties. Both the theoretical analysis and experimental results support the effectiveness and practicability on hemiplegic patients of our control strategy.",https://ieeexplore.ieee.org/document/8906035/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TMECH.2013.2245337,Image-Based Visual Servoing of a 7-DOF Robot Manipulator Using an Adaptive Distributed Fuzzy PD Controller,IEEE,Journals,"This paper is concerned with the design and implementation of a distributed proportional-derivative (PD) controller of a 7-degrees of freedom (DOF) robot manipulator using the Takagi-Sugeno (T-S) fuzzy framework. Existing machine learning approaches to visual servoing involve system identification of image and kinematic Jacobians. In contrast, the proposed approach actuates a control signal primarily as a function of the error and derivative of the error in the desired visual feature space. This approach leads to a significant reduction in the computational burden as compared to model-based approaches, as well as existing learning approaches to model inverse kinematics. The simplicity of the controller structure will make it attractive in industrial implementations where PD/PID type schemes are in common use. While the initial values of PD gain are learned with the help of model-based controller, an online adaptation scheme has been proposed that is capable of compensating for local uncertainties associated with the system and its environment. Rigorous experiments have been performed to show that visual servoing tasks such as reaching a static target and tracking of a moving target can be achieved using the proposed distributed PD controller. It is shown that the proposed adaptive scheme can dynamically tune the controller parameters during visual servoing, so as to improve its initial performance based on parameters obtained while mimicking the model-based controller. The proposed control scheme is applied and assessed in real-time experiments using an uncalibrated eye-in-hand robotic system with a 7-DOF PowerCube robot manipulator.",https://ieeexplore.ieee.org/document/6471828/,IEEE/ASME Transactions on Mechatronics,April 2014,ieeexplore
10.1109/TAMD.2011.2106781,Implicit Sensorimotor Mapping of the Peripersonal Space by Gazing and Reaching,IEEE,Journals,"Primates often perform coordinated eye and arm movements, contextually fixating and reaching towards nearby objects. This combination of looking and reaching to the same target is used by infants to establish an implicit visuomotor representation of the peripersonal space, useful for both oculomotor and arm motor control. In this work, taking inspiration from such behavior and from primate visuomotor mechanisms, a shared sensorimotor map of the environment, built on a radial basis function framework, is configured and trained by the coordinated control of eye and arm movements. Computational results confirm that the approach seems especially suitable for the problem at hand, and for its implementation on a real humanoid robot. By exploratory gazing and reaching actions, either free or goal-based, the artificial agent learns to perform direct and inverse transformations between stereo vision, oculomotor, and joint-space representations. The integrated sensorimotor map that allows to contextually represent the peripersonal space through different vision and motor parameters is never made explicit, but rather emerges thanks to the interaction of the agent with the environment.",https://ieeexplore.ieee.org/document/5703113/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/TIE.2018.2864707,Incremental Updating Multirobot Formation Using Nonlinear Model Predictive Control Method With General Projection Neural Network,IEEE,Journals,"In this paper, an incremental centralized formation system is developed for controlling the multirobot formation with joining robots, and a nonlinear model predictive control (NMPC) method is implemented as the controller. The incremental updating method is used to update the system's state in real time, when there is a new robot joining during the formation process. Then, an NMPC approach is developed to reformulate the formation system into a convex nonlinear minimization problem, which can be further transformed into a quadratic programming (QP) with constraints. Then, a general projection neural network (GPNN) is implemented for solving this QP problem online to get the optimal inputs. In the end, two examples of incremental multirobot formation are demonstrated to verify the effectiveness of this method.",https://ieeexplore.ieee.org/document/8437254/,IEEE Transactions on Industrial Electronics,June 2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/ACCESS.2021.3057808,Intuitive Robot Teleoperation Through Multi-Sensor Informed Mixed Reality Visual Aids,IEEE,Journals,"Mobile robotic systems have evolved to include sensors capable of truthfully describing robot status and operating environment as accurately and reliably as never before. This possibility is challenged by effective sensor data exploitation, because of the cognitive load an operator is exposed to, due to the large amount of data and time-dependency constraints. This paper addresses this challenge in remote-vehicle teleoperation by proposing an intuitive way to present sensor data to users by means of using mixed reality and visual aids within the user interface. We propose a method for organizing information presentation and a set of visual aids to facilitate visual communication of data in teleoperation control panels. The resulting sensor-information presentation appears coherent and intuitive, making it easier for an operator to catch and comprehend information meaning. This increases situational awareness and speeds up decision-making. Our method is implemented on a real mobile robotic system operating outdoor equipped with on-board internal and external sensors, GPS, and a reconstructed 3D graphical model provided by an assistant drone. Experimentation verified feasibility while intuitive and comprehensive visual communication was confirmed through an assessment, which encourages further developments.",https://ieeexplore.ieee.org/document/9349454/,IEEE Access,2021,ieeexplore
10.1109/LRA.2020.3013937,Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning,IEEE,Journals,"Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].",https://ieeexplore.ieee.org/document/9158366/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/LRA.2020.2975706,Learning Task-Oriented Grasping From Human Activity Datasets,IEEE,Journals,"We propose to leverage a real-world, human activity RGB dataset to teach a robot Task-Oriented Grasping (TOG). We develop a model that takes as input an RGB image and outputs a hand pose and configuration as well as an object pose and a shape. We follow the insight that jointly estimating hand and object poses increases accuracy compared to estimating these quantities independently of each other. Given the trained model, we process an RGB dataset to automatically obtain the data to train a TOG model. This model takes as input an object point cloud and outputs a suitable region for task-specific grasping. Our ablation study shows that training an object pose predictor with the hand pose information (and vice versa) is better than training without this information. Furthermore, our results on a real-world dataset show the applicability and competitiveness of our method over state-of-the-art. Experiments with a robot demonstrate that our method can allow a robot to preform TOG on novel objects.",https://ieeexplore.ieee.org/document/9006947/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JETCAS.2020.3033135,<italic>Learning to Walk</italic>: Bio-Mimetic Hexapod Locomotion via Reinforcement-Based Spiking Central Pattern Generation,IEEE,Journals,"Online learning for the legged robot locomotion under performance and energy constraints remains to be a challenge. Methods such as stochastic gradient, deep reinforcement learning (RL) have been explored for bipeds, quadrupeds and hexapods. These techniques are computationally intensive and thus difficult to implement on edge computing platforms. These methods are also inefficient in energy consumption and throughput because of their reliance on complex sensors and pre-processing of data. On the other hand, neuromorphic computing paradigms, such as spiking neural networks (SNN), become increasingly favorable in low power computing on edge intelligence. SNN has exhibited the capability of performing reinforcement learning mechanisms with biomimetic spike time-dependent plasticity (STDP) of synapses. However, training a legged robot to walk in the synchronized gait patterns generated by a central pattern generator (CPG) in an SNN framework has not yet been explored. Such a method can combine the efficiency of SNNs with the synchronized locomotion of CPG based systems - providing breakthrough performance improvement of end-to-end learning in mobile robotics. In this paper, we propose a reinforcement based stochastic learning technique for training a spiking CPG for a hexapod robot which learns to walk using bio-inspired tripod gait without prior knowledge. The whole system is implemented on a lightweight raspberry pi platform with integrated sensors. Our method opens new opportunities for online learning with limited edge computing resources.",https://ieeexplore.ieee.org/document/9235477/,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,Dec. 2020,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/TASE.2017.2783342,MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration,IEEE,Journals,"Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to task efficiently. The biggest bottleneck here is the tedious programming, which also has high prerequisites for most practitioners in manufacturing. This situation motivates the development of a PBD system that can understand the assembly skills performed by the human experts in the demonstration and accordingly generate the program for robot's execution of the taught task. In this paper, we present a skill decoding system to parse the observational raw demonstration into symbolic sequences, which is the crucial bridge to enable the automatic programming. The system achieves high performance in recognition and is tailored for the PBD in assembly tasks by considering both advantages and disadvantages in the background of assembly, such as controllable environment and limited computational resources. It is particularly useful for assembly tasks with modularized actions based on a set of standard parts. At the perspective of industrial application, the PBD upon the proposed system is a promising solution to improve the flexibility of manufacture, which is expected to be true in midterm but an important step toward this goal.",https://ieeexplore.ieee.org/document/8263146/,IEEE Transactions on Automation Science and Engineering,Oct. 2018,ieeexplore
10.1109/TVT.2019.2952926,Mechanism Design for Wireless Powered Spatial Crowdsourcing Networks,IEEE,Journals,"Wireless power transfer (WPT) is a promising technology to prolong the lifetime of the sensors and communication devices, i.e., workers, in completing crowdsourcing tasks by providing continuous and cost-effective energy supplies. In this paper, we propose a wireless powered spatial crowdsourcing framework which consists of two mutually dependent phases: task allocation phase and data crowdsourcing phase. In the task allocation phase, we propose a Stackelberg game based mechanism for the spatial crowdsourcing platform to efficiently allocate spatial tasks and wireless charging power to each worker. In the data crowdsourcing phase, the workers may have an incentive to misreport its real working location to improve its utility, which causes adverse effects to the spatial crowdsourcing platform. To address this issue, we present three strategyproof deployment mechanisms for the spatial crowdsourcing platform to place a mobile base station, e.g., vehicle or robot, which is responsible for transferring the wireless power and collecting the crowdsourced data. As the benchmark, we first apply the classical median mechanism and evaluate its worst-case performance. Then, we design a conventional strategyproof deployment mechanism to improve the expected utility of the spatial crowdsourcing platform under the condition that the workers' locations follow a known geographical distribution. For a more general case with only the historical location data available, we propose a deep learning based strategyproof deployment mechanism to maximize the spatial crowdsourcing platform's utility. Extensive experimental results based on synthetic and real-world datasets reveal the effectiveness of the proposed framework in allocating tasks and charging power to workers while avoiding the dishonest worker's manipulation.",https://ieeexplore.ieee.org/document/8895988/,IEEE Transactions on Vehicular Technology,Jan. 2020,ieeexplore
10.1109/TII.2012.2205395,Minimal Resource Allocating Networks for Discrete Time Sliding Mode Control of Robotic Manipulators,IEEE,Journals,"This paper presents a discrete-time sliding mode control based on neural networks designed for robotic manipulators. Radial basis function neural networks are used to learn about uncertainties affecting the system. The online learning algorithm combines the growing criterion and the pruning strategy of the minimal resource allocating network technique with an adaptive extended Kalman filter to update all the parameters of the networks. A method to improve the run-time performance for the real-time implementation of the learning algorithm has been considered. The analysis of the control stability is given and the controller is evaluated on the ERICC robot arm. Experiments show that the proposed controller produces good trajectory tracking performance and it is robust in the presence of model inaccuracies, disturbances and payload perturbations.",https://ieeexplore.ieee.org/document/6221995/,IEEE Transactions on Industrial Informatics,Nov. 2012,ieeexplore
10.1109/TITB.2004.840064,Mobile tele-echography: user interface design,IEEE,Journals,"Ultrasound imaging allows the evaluation of the degree of emergency of a patient. However, in some instances, a well-trained sonographer is unavailable to perform such echography. To cope with this issue, the Mobile Tele-Echography Using an Ultralight Robot (OTELO) project aims to develop a fully integrated end-to-end mobile tele-echography system using an ultralight remote-controlled robot for population groups that are not served locally by medical experts. This paper focuses on the user interface of the OTELO system, consisting of the following parts: an ultrasound video transmission system providing real-time images of the scanned area, an audio/video conference to communicate with the paramedical assistant and with the patient, and a virtual-reality environment, providing visual and haptic feedback to the expert, while capturing the expert's hand movements. These movements are reproduced by the robot at the patient site while holding the ultrasound probe against the patient skin. In addition, the user interface includes an image processing facility for enhancing the received images and the possibility to include them into a database.",https://ieeexplore.ieee.org/document/1402446/,IEEE Transactions on Information Technology in Biomedicine,March 2005,ieeexplore
10.1109/41.704895,Modeling of ultrasonic range sensors for localization of autonomous mobile robots,IEEE,Journals,"This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",https://ieeexplore.ieee.org/document/704895/,IEEE Transactions on Industrial Electronics,Aug. 1998,ieeexplore
10.1109/41.499811,Multilayered fuzzy behavior fusion for real-time reactive control of systems with multiple sensors,IEEE,Journals,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, with large numbers of inputs, may also benefit from the use of qualitative linguistic rules if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine that can be used to control complex systems. The control function is broken down into multiple local agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. A development tool is used to translate a fuzzy programming language offline for fast execution at run time. Using this system, a multilayered fuzzy behavior fusion based reactive control system has been implemented on an autonomous mobile robot, MARGE, with great success. MARGE won first place in Event III of the 1993 Robot Competition sponsored by the American Association for Artificial Intelligence.",https://ieeexplore.ieee.org/document/499811/,IEEE Transactions on Industrial Electronics,June 1996,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/TIE.2007.903993,Multimodal Approach to Human-Face Detection and Tracking,IEEE,Journals,"The constructive need for robots to coexist with humans requires human-machine interaction. It is a challenge to operate these robots in such dynamic environments, which requires continuous decision-making and environment-attribute update in real-time. An autonomous robot guide is well suitable in places such as museums, libraries, schools, hospital, etc. This paper addresses a scenario where a robot tracks and follows a human. A neural network is utilized to learn the skin and nonskin colors. The skin-color probability map is utilized for skin classification and morphology-based preprocessing. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification. A face-detection module, based on a 2D color model in the and YUV color space, is selected over the traditional skin-color model in a 3D color space. A modified continuously adaptive mean shift tracking mechanism in a 1D hue, saturation, and value color space is developed and implemented onto the mobile robot. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person's distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. The proposed approach is orientation invariant under varying lighting conditions and invariant to natural transformations such as translation, rotation, and scaling. Such a multimodal solution is effective for face detection and tracking.",https://ieeexplore.ieee.org/document/4392479/,IEEE Transactions on Industrial Electronics,March 2008,ieeexplore
10.1109/TCYB.2017.2718037,Multiobjective Evolution of Biped Robot Gaits Using Advanced Continuous Ant-Colony Optimized Recurrent Neural Networks,IEEE,Journals,"This paper proposes the optimization of a fully connected recurrent neural network (FCRNN) using advanced multiobjective continuous ant colony optimization (AMO-CACO) for the multiobjective gait generation of a biped robot (the NAO). The FCRNN functions as a central pattern generator and is optimized to generate angles of the hip roll and pitch, the knee pitch, and the ankle pitch and roll. The performance of the FCRNN-generated gait is evaluated according to the walking speed, trajectory straightness, oscillations of the body in the pitch and yaw directions, and walking posture, subject to the basic constraints that the robot cannot fall down and must walk forward. This paper formulates this gait generation task as a constrained multiobjective optimization problem and solves this problem through an AMO-CACO-based evolutionary learning approach. The AMO-CACO finds Pareto optimal solutions through ant-path selection and sampling operations by introducing an accumulated rank for the solutions in each single-objective function into solution sorting to improve learning performance. Simulations are conducted to verify the AMO-CACO-based FCRNN gait generation performance through comparisons with different multiobjective optimization algorithms. Selected software-designed Pareto optimal FCRNNs are then applied to control the gait of a real NAO robot.",https://ieeexplore.ieee.org/document/7964700/,IEEE Transactions on Cybernetics,June 2018,ieeexplore
10.1109/TLA.2019.8896824,Navigation System for MACÁBOT an Autonomous Surface Vehicles Using GPS Aided Strapdown Inertial Navigation System,IEEE,Journals,"In this work the design, implementation and real-time tests of a navigation system for the autonomous surface vehicle MACÁBOT is presented. This vehicle represents a versatile platform to perform several tasks in the marine environment, such as; ports maintenance, marine productive ecosystems studies and bathymetries. The navigation system is responsible for accurately determining the position, velocity and attitude of the vehicle. It represents a fundamental component to autonomously carry out any of the aforementioned tasks. In this work, the navigation system is developed based on a GPS aided strap-down inertial navigation system using an extended Kalman filter sensor fusion algorithm. In order to provide an adaptive approach to the sensor fusion algorithm tuning a fuzzy inference system is used. The navigation system was implemented as a package for the Robot Operating System, benefiting from the advantages of heterogeneity, integration and hardware abstraction. Real time tests of the MACÁBOT on a local creek were carried out, showing satisfactory performance of the navigation system in both position and velocity estimates. In addition to these tests, simulations of GPS outages were carried out with the registered data to evaluate the performance of the navigation system in such cases.",https://ieeexplore.ieee.org/document/8896824/,IEEE Latin America Transactions,June 2019,ieeexplore
10.1109/ACCESS.2018.2863736,Noise-Resistant Discrete-Time Neural Dynamics for Computing Time-Dependent Lyapunov Equation,IEEE,Journals,"Z-type neural dynamics, which is a powerful calculating tool, is widely used to compute various time-dependent problems. Most Z-type neural dynamics models are usually investigated in a noise-free situation. However, noises will inevitably exist in the implementation process of a neural dynamics model. To deal with such an issue, this paper considers a new discrete-time Z-type neural dynamics model, which is analyzed and investigated to calculate the real-time-dependent Lyapunov equation in the form A<sup>T</sup>(t)X(t) + X(t)A(t) + C(t) = 0 in different types of noisy circumstances. Related theoretical analyses are provided to illustrate that, the proposed neural dynamics model is intrinsically noise-resistant and has the advantage of high precision in real-time calculation. This model is called the noise-resistant discrete-time Z-type neural dynamics (NRDTZND) model. For comparison, the conventional discrete-time Z-type neural dynamics model is also proposed and used for solving the same time-dependent problem in noisy environments. Finally, three illustrative examples, including a real-life application to the inverse kinematics motion planning of a robot arm, are performed and analyzed to prove the validity and superiority of the proposed NRDTZND model in computing the real-time-dependent Lyapunov equation under various types of noisy situations.",https://ieeexplore.ieee.org/document/8425977/,IEEE Access,2018,ieeexplore
10.1109/TIE.2005.847576,Obstacle avoidance of a mobile robot using hybrid learning approach,IEEE,Journals,"in this paper, a hybrid learning approach for obstacle avoidance of a mobile robot is presented. the key features of the approach are, firstly, innate hardwired behaviors which are used to bootstrap learning in the mobile robot system. a neuro-fuzzy controller is developed from a pre-wired or innate controller based on supervised learning in a simulation environment. the fuzzy inference system has been constructed based on the generalized dynamic fuzzy neural networks learning algorithm of Wu and Er, whereby structure and parameters identification are carried out automatically and simultaneously. Secondly, the neuro-fuzzy controller is capable of re-adapting in a new environment. After carrying out the learning phase on a simulated robot, the controller is implemented on a real robot. A reinforcement learning method based on the fuzzy actor-critic learning algorithm is employed so that the system can re-adapt to a new environment without human intervention. In this phase, the structure of the fuzzy inference system and the parameters of the antecedent parts of fuzzy rules are frozen, and reinforcement learning is applied to further tune the parameters in the consequent parts of the fuzzy rules. Through the hybrid learning approach, an efficient and compact neuro-fuzzy system is generated for obstacle avoidance of a mobile robot in the real world.",https://ieeexplore.ieee.org/document/1435700/,IEEE Transactions on Industrial Electronics,June 2005,ieeexplore
10.1109/JPROC.2019.2898267,"On Proactive, Transparent, and Verifiable Ethical Reasoning for Robots",IEEE,Journals,"Previous work on ethical machine reasoning has largely been theoretical, and where such systems have been implemented, it has, in general, been only initial proofs of principle. Here, we address the question of desirable attributes for such systems to improve their real world utility, and how controllers with these attributes might be implemented. We propose that ethically critical machine reasoning should be proactive, transparent, and verifiable. We describe an architecture where the ethical reasoning is handled by a separate layer, augmenting a typical layered control architecture, ethically moderating the robot actions. It makes use of a simulation-based internal model and supports proactive, transparent, and verifiable ethical reasoning. To do so, the reasoning component of the ethical layer uses our Python-based belief-desire-intention (BDI) implementation. The declarative logic structure of BDI facilitates both transparency, through logging of the reasoning cycle, and formal verification methods. To prove the principles of our approach, we use a case study implementation to experimentally demonstrate its operation. Importantly, it is the first such robot controller where the ethical machine reasoning has been formally verified.",https://ieeexplore.ieee.org/document/8648363/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/56.812,On terrain acquisition by a point robot amidst polyhedral obstacles,IEEE,Journals,"The authors consider the problem of terrain model acquisition by a roving point placed in an unknown terrain populated by stationary polyhedral obstacles in two/three dimensions. The motivation for this problem is that after the terrain model is completely acquired, navigation from a source point to a destination point can be achieved along the collision-free paths. This can be done without the usage of sensors by applying the existing techniques for the find-path problem. In the paper, the point robot autonomous machine (PRAM) is used as a simplified abstract model for real-life roving robots. An algorithm is presented that enables PRAM to autonomously acquire the model of an unexplored obstacle terrain composed of an unknown number of polyhedral obstacles in two/three dimensions. In this method, PRAM undertakes a systematic exploration of the obstacle terrain with its sensor that detects all the edges and vertices visible from the present location, and builds the complete obstacle terrain model.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/812/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/ACCESS.2020.3048877,"Online Measuring of Robot Positions Using Inertial Measurement Units, Sensor Fusion and Artificial Intelligence",IEEE,Journals,"This research introduces a new method to estimate the position of a robot's Tool Center Point (TCP) using Inertial Measurement Units (IMUs), sensor fusion and Artificial Neural Networks (ANNs). The objective is to make an accurate estimate of TCP navigation, using the signals from an IMU as resources of a neural network capable of predicting the position. Considering that the IMU sensors suffer noise in the measurements and the noise progresses over time, this proposal employs a technique that eliminates the filtering step, and the process is done internally by the network. The work employs a non-parametric approach to reset the reference dynamically, minimize noise from sensors, and converge positioning to a nominal result. This method offers a solution for fast, cheap, and efficient robot calibration. The work does not want to replace current techniques but to introduce a new design to the literature. The concept does not require sophisticated mechanical parts and the production line to be idle during the calibration process, and the results show that the developed technique can accurately predict the TCP position with millimeter errors and in real-time. The study also implemented the concept with other neural networks, for which it used a smaller set of data in an attempt to reduce training time. The research used the Multilayer Perceptron and XGBRegressor networks to test the approach introduced with others algorithms. Different applications that need real-time positioning can benefit from the proposal.",https://ieeexplore.ieee.org/document/9312193/,IEEE Access,2021,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/ACCESS.2018.2882875,RL and ANN Based Modular Path Planning Controller for Resource-Constrained Robots in the Indoor Complex Dynamic Environment,IEEE,Journals,"Traditional Reinforcement Learning (RL) approaches are designed to work well in static environments. In many real-world scenarios, the environments are complex and dynamic, in which the performance of traditional RL approaches may drastically degrade. One of the factors which results in the dynamicity and complexity of the environment is a change in the position and number of obstacles. This paper presents a path planning approach for autonomous mobile robots in a complex dynamic indoor environment, where the dynamic pattern of obstacles will not drastically affect the performance of RL models. Two independent modules, collision avoidance without considering the goal position and goal-seeking without considering obstacles avoidance, are trained independently using artificial neural networks and RL to obtain their best control policies. Then, a switching function is used to combine the two trained modules for realizing the obstacle avoidance and global path planning in a complex dynamic indoor environment. Furthermore, this control system is designed with a special focus on the computational and memory requirements of resource-constrained robots. The design was tested in a real-world environment on a mini-robot with constrained resources. Along with the static and dynamic obstacles' avoidance, this system has the ability to achieve both static and dynamic targets. This control system can also be used to train a robot in the real world using RL when the robot cannot afford to collide. Robot behavior in the real ground shows a very strong correlation with the simulation results.",https://ieeexplore.ieee.org/document/8543176/,IEEE Access,2018,ieeexplore
10.1109/TCSI.2004.827654,Reaction-diffusion navigation robot control: from chemical to VLSI analogic processors,IEEE,Journals,"We introduce a new methodology and experimental implementations for real-time wave-based robot navigation in a complex, dynamically changing environment. The main idea behind the approach is to consider the robot arena as an excitable medium, in which moving objects-obstacles and the target-are represented by sites of autowave generation: the target generates attractive waves, while the obstacles repulsive ones. The moving robot detects traveling and colliding wave fronts and uses the information about dynamics of the autowaves to adapt its direction of collision-free motion toward the target. This approach allows us to achieve a highly adaptive robot behavior and thus an optimal path along which the robot reaches the target while avoiding obstacles. At the computational and experimental levels, we adopt principles of computation in reaction-diffusion (RD) nonlinear active media. Nonlinear media where autowaves are used for information processing purposes can therefore be considered as RD computing devices. In this paper, we design and experiment with three types of RD processors: experimental and computational Belousov-Zhabotinsky chemical processor, computational CNN processor, and experimental RD-CNN very large-scale integration chip-the complex analog and logic computing engine (CACE1k). We demonstrate how to experimentally implement robot navigation using space-time snapshots of active chemical medium and how to overcome low-speed limitation of this ""wetware"" implementation in CNN-based silicon processors.",https://ieeexplore.ieee.org/document/1296805/,IEEE Transactions on Circuits and Systems I: Regular Papers,May 2004,ieeexplore
10.1109/LRA.2018.2798286,Real-Time 3-D Shape Instantiation From Single Fluoroscopy Projection for Fenestrated Stent Graft Deployment,IEEE,Journals,"Robot-assisted deployment of fenestrated stent grafts in fenestrated endovascular aortic repair (FEVAR) requires accurate geometrical alignment. Currently, this process is guided by two-dimensional (2-D) fluoroscopy, which is insufficiently informative and error prone. In this letter, a real-time framework is proposed to instantiate the 3-D shape of a fenestrated stent graft by utilizing only a single low-dose 2-D fluoroscopic image. First, markers were placed on the fenestrated stent graft. Second, the 3-D pose of each stent segment was instantiated by the robust perspective-n-point method. Third, the 3-D shape of the whole stent graft was instantiated via graft gap interpolation. Focal UNet was proposed to segment the markers from 2-D fluoroscopic images to achieve semiautomatic marker detection. The proposed framework was validated on five patient-specific 3-D printed aortic aneurysm phantoms and three stent grafts with new marker placements, showing an average distance error of 1-3 mm and an average angular error of 4°. Shape instantiation codes are available online.",https://ieeexplore.ieee.org/document/8269290/,IEEE Robotics and Automation Letters,April 2018,ieeexplore
10.1109/TDSC.2019.2903049,Real-Time Error Detection in Nonlinear Control Systems Using Machine Learning Assisted State-Space Encoding,IEEE,Journals,"Successful deployment of autonomous systems in a wide range of societal applications depends on error-free operation of the underlying signal processing and control functions. Real-time error detection in nonlinear systems has mostly relied on redundancy at the component or algorithmic level causing expensive area and power overheads. This paper describes a real-time error detection methodology for nonlinear control systems for detecting sensor and actuator degradations as well as malfunctions due to soft errors in the execution of the control algorithm on a digital processor. Our approach is based on creation of a redundant check state in such a way that its value can be computed from the current states of the system as well as from a history of prior observable state values and inputs (via machine learning algorithms). By checking for consistency between the two, errors are detected with low latency. The method is demonstrated on two test case simulations - an inverted pendulum balancing problem and a sliding mode controller driven brake-by-wire (BBW) system. In addition, hardware results from error injection experiments in an ARM core representation on an FPGA and artificial sensor degradations on a self-balancing robot prove the practical feasibility of implementation.",https://ieeexplore.ieee.org/document/8658148/,IEEE Transactions on Dependable and Secure Computing,1 March-April 2021,ieeexplore
10.1109/TCYB.2013.2275291,Real-Time Multiple Human Perception With Color-Depth Cameras on a Mobile Robot,IEEE,Journals,"The ability to perceive humans is an essential requirement for safe and efficient human-robot interaction. In real-world applications, the need for a robot to interact in real time with multiple humans in a dynamic, 3-D environment presents a significant challenge. The recent availability of commercial color-depth cameras allow for the creation of a system that makes use of the depth dimension, thus enabling a robot to observe its environment and perceive in the 3-D space. Here we present a system for 3-D multiple human perception in real time from a moving robot equipped with a color-depth camera and a consumer-grade computer. Our approach reduces computation time to achieve real-time performance through a unique combination of new ideas and established techniques. We remove the ground and ceiling planes from the 3-D point cloud input to separate candidate point clusters. We introduce the novel information concept, depth of interest, which we use to identify candidates for detection, and that avoids the computationally expensive scanning-window methods of other approaches. We utilize a cascade of detectors to distinguish humans from objects, in which we make intelligent reuse of intermediary features in successive detectors to improve computation. Because of the high computational cost of some methods, we represent our candidate tracking algorithm with a decision directed acyclic graph, which allows us to use the most computationally intense techniques only where necessary. We detail the successful implementation of our novel approach on a mobile robot and examine its performance in scenarios with real-world challenges, including occlusion, robot motion, nonupright humans, humans leaving and reentering the field of view (i.e., the reidentification challenge), human-object and human-human interaction. We conclude with the observation that the incorporation of the depth information, together with the use of modern techniques in new ways, we are able to create an accurate system for real-time 3-D perception of humans by a mobile robot.",https://ieeexplore.ieee.org/document/6583249/,IEEE Transactions on Cybernetics,Oct. 2013,ieeexplore
10.1109/LRA.2021.3102318,Real-Time Obstacle Avoidance Using Dual-Type Proximity Sensor for Safe Human-Robot Interaction,IEEE,Journals,"This letter introduces a dual-type proximity sensor and a control strategy for a robot manipulator to realize safe human-robot interactions (HRI) by using the sensor. Safety is an essential condition for HRI in practical scenarios. To achieve this condition, information about the relationship between an external objects and the robot is required. To obtain this information, we employ a dual-type proximity sensor, which consists of capacitive and inductive transducers and can detect the distance between a robot and external objects. Further, we propose a real-time trajectory planning method to deal with obstacles by using admittance control and distance measurements. To update the motion of the manipulator according to our control strategy, a Weight-Prioritized solution based on a QP (quadratic programming) formalism was applied. Further, the problem of self-sensing is solved via machine learning using a training dataset consisting of data corresponding to random joint positions. The proposed method was implemented on a collaborate robot (UR10). Experiments were conducted considering realistic human-robot interactions, and safety improvement was validated.",https://ieeexplore.ieee.org/document/9508896/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/LRA.2021.3063992,Real-Time Path Planning With Virtual Magnetic Fields,IEEE,Journals,"Humans and animals have learned or evolved to use magnetic fields for navigation. Knowing how to model and estimate these fields can be used for motion planning. However, computing the propagation of electromagnetic fields in a given environment requires solving complex differential equations with advanced numerical methods, and therefore it is not suitable for real-time decision making. In this latter, we present a real-time approximator for Maxwell's equations based on deep neural networks that predicts the distribution of a virtual magnetic field. We show how our approximator can be used to perform autonomous 2D navigation tasks, outperforming state-of-the-art navigation algorithms, ensuring completeness, and providing a near-optimal path up to 200 times per second without any post processing stage. We demonstrate the effectiveness of our method with physics-based simulations of an unmanned aerial vehicle, an autonomous car, as well as real-world experiments using a small off-road autonomous racing vehicle. Furthermore, we show how the approach can be applied to multi-robot systems, video game technology, and can be extended to 3D problems.",https://ieeexplore.ieee.org/document/9369851/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/70.265922,Real-time vision-based robot localization,IEEE,Journals,"This paper describes an algorithm for determining robot location from visual landmarks. This algorithm determines both the correspondence between observed landmarks (in this case vertical edges in the environment) and a stored map, and computes the location of the robot using those correspondences. The primary advantages of this algorithm are its use of a single geometric tolerance to describe observation error, its ability to recognize ambiguous sets of correspondences, its ability to compute bounds on the error in localization, and fast execution. The algorithm has been implemented and tested on a mobile robot system. In several hundred trials it has never failed, and computes location accurate to within a centimeter in less than 0.5 s.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/265922/,IEEE Transactions on Robotics and Automation,Dec. 1993,ieeexplore
10.1109/ACCESS.2020.3018026,Reinforcement Learning for Position Control Problem of a Mobile Robot,IEEE,Journals,"Due to the increase in complexity in autonomous vehicles, most of the existing control systems are proving to be inadequate. Reinforcement Learning is gaining traction as it is posed to overcome these difficulties in a natural way. This approach allows an agent that interacts with the environment to get rewards for appropriate actions, learning to improve its performance continuously. The article describes the design and development of an algorithm to control the position of a wheeled mobile robot using Reinforcement Learning. One main advantage of this approach concerning traditional control algorithms is that the learning process is carried out automatically with a recursive procedure forward in time. Moreover, given the fidelity of the model for the particular implementation described in this work, the whole learning process can be carried out in simulation. This fact avoids damages to the actual robot during the learning stage. It shows that the position control of the robot (or similar specific tasks) can be done without the need to know the dynamic model of the system explicitly. Its main drawback is that the learning stage can take a long time to finish and that it depends on the complexity of the task and the availability of adequate hardware resources. This work provides a comparison between the proposed approach and traditional existing control laws in simulation and real environments. The article also discusses the main effects of using different controlled variables in the performance of the developed control law.",https://ieeexplore.ieee.org/document/9171241/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2021.3061634,RnR: Retrieval and Reprojection Learning Model for Camera Localization,IEEE,Journals,"Camera localization is an essential technique in many applications, such as robot navigation, mixed reality, and unmanned vehicle. We are committed to solving the problem of predicting the 6-DoF pose of cameras from a single color image in a given three-Dimensional (3D) environment. In this paper, we proposed a robust learning model for it. Basically, our proposed methodology consists of two steps: image retrieval and space reprojection. The former is in charge of simultaneous localization and mapping based on pre-captured reference images that rely on the correspondence between pixel points and scene coordinates; whereas the latter carries out camera calibration between the 2D image plane and the 3D scene. Given a two-Dimensional (2D) image, the initial localization is accomplished rapidly by matching a reference image using Siamese networks. More precise localization is achieved by camera calibration between the 2D image and the 3D scene using a fully convolutional network. The experimental results on the public dataset show that our model is more robust and expandable than the previous methods. At the end of this paper, we also apply the system to Unmanned Aerial Vehicle (UAV) localization and achieve good results.",https://ieeexplore.ieee.org/document/9361658/,IEEE Access,2021,ieeexplore
10.1109/TASE.2014.2377791,RoboEarth Semantic Mapping: A Cloud Enabled Knowledge-Based Approach,IEEE,Journals,"The vision of the RoboEarth project is to design a knowledge-based system to provide web and cloud services that can transform a simple robot into an intelligent one. In this work, we describe the RoboEarth semantic mapping system. The semantic map is composed of: 1) an ontology to code the concepts and relations in maps and objects and 2) a SLAM map providing the scene geometry and the object locations with respect to the robot. We propose to ground the terminological knowledge in the robot perceptions by means of the SLAM map of objects. RoboEarth boosts mapping by providing: 1) a subdatabase of object models relevant for the task at hand, obtained by semantic reasoning, which improves recognition by reducing computation and the false positive rate; 2) the sharing of semantic maps between robots; and 3) software as a service to externalize in the cloud the more intensive mapping computations, while meeting the mandatory hard real time constraints of the robot. To demonstrate the RoboEarth cloud mapping system, we investigate two action recipes that embody semantic map building in a simple mobile robot. The first recipe enables semantic map building for a novel environment while exploiting available prior information about the environment. The second recipe searches for a novel object, with the efficiency boosted thanks to the reasoning on a semantically annotated map. Our experimental results demonstrate that, by using RoboEarth cloud services, a simple robot can reliably and efficiently build the semantic maps needed to perform its quotidian tasks. In addition, we show the synergetic relation of the SLAM map of objects that grounds the terminological knowledge coded in the ontology.",https://ieeexplore.ieee.org/document/7015601/,IEEE Transactions on Automation Science and Engineering,April 2015,ieeexplore
10.1109/ACCESS.2020.2992701,Robot Formation Control Based on Internet of Things Technology Platform,IEEE,Journals,"The cooperative control technology of robot formation can sense all kinds of external environment in real time. It is a multi-functional control and management system including visual recognition, task management execution and distribution, behavior decision-making and so on. It can easily adapt to all kinds of harsh environment. In order to meet the efficient response requirements of robot formation control, a real-time transmission system of robot cooperative motion control is built based on the Internet of things platform, which collects and feeds back the trajectory of multiple robots. Through particle swarm optimization deep learning algorithm, more accurate identification, prediction and guidance of the robot's next action. Finally, the simulation of robot formation motion is established by MATLAB software, which verifies the feasibility of particle swarm optimization deep learning neural network algorithm under the Internet of things technology. Compared with the traditional robot formation control method, the optimized control method has faster convergence speed, smaller error and more accurate position, which provides method guidance for the accuracy and efficiency of robot formation control technology.",https://ieeexplore.ieee.org/document/9087868/,IEEE Access,2020,ieeexplore
10.1109/13.485240,Robotics laboratory exercises,IEEE,Journals,"The authors report new laboratory exercises in robotic manipulation, computer vision, artificial intelligence, and mechatronics, four areas that are central to any robotics curriculum. The laboratory exercises supply the student with hands-on experience that complements classroom lectures and software development. Through this experience, the student confronts the hard realities of robot systems and learns to deal with them. Such hands-on experience is essential for a sound robotics education, because many critical lessons about the real world can only be learned through personal experience.",https://ieeexplore.ieee.org/document/485240/,IEEE Transactions on Education,Feb. 1996,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TASE.2019.2940543,Robust Visual Localization in Dynamic Environments Based on Sparse Motion Removal,IEEE,Journals,"Visual localization has been well studied in recent decades and applied in many fields as a fundamental capability in robotics. However, the success of the state of the arts usually builds on the assumption that the environment is static. In dynamic scenarios where moving objects are present, the performance of the existing visual localization systems degrades a lot due to the disturbance of the dynamic factors. To address this problem, we propose a novel sparse motion removal (SMR) model that detects the dynamic and static regions for an input frame based on a Bayesian framework. The similarity between the consecutive frames and the difference between the current frame and the reference frame are both considered to reduce the detection uncertainty. After the detection process is finished, the dynamic regions are eliminated while the static ones are fed into a feature-based visual simultaneous localization and mapping (SLAM) system for further visual localization. To verify the proposed method, both qualitative and quantitative experiments are performed and the experimental results have demonstrated that the proposed model can significantly improve the accuracy and robustness for visual localization in dynamic environments.&lt;;/p&gt;&lt;;p&gt;&lt;;italic&gt;Note to Practitioners&lt;;/italic&gt;-This article was motivated by the visual localization problem in dynamic environments. Visual localization is well applied in many robotic fields such as path planning and exploration as the basic capability for a mobile robot. In the GPS-denied environments, one robot needs to localize itself through perceiving the unknown environment based on a visual sensor. In real-world scenes, the existence of the moving objects will significantly degrade the localization accuracy, which makes the robot implementation unreliable. In this article, an SMR model is designed to handle this problem. Once receiving a frame, the proposed model divides it into dynamic and static regions through a Bayesian framework. The dynamic regions are eliminated, while the static ones are maintained and fed into a feature-based visual SLAM system for further visual localization. The proposed method greatly improves the localization accuracy in dynamic environments and guarantees the robustness for robotic implementation.",https://ieeexplore.ieee.org/document/8855084/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/TNN.2009.2032183,SVR Versus Neural-Fuzzy Network Controllers for the Sagittal Balance of a Biped Robot,IEEE,Journals,"The real-time balance control of an eight-link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, two alternative intelligent computing control techniques were compared: one based on support vector regression (SVR) and another based on a first-order Takagi-Sugeno-Kang (TSK)-type neural-fuzzy (NF) network. Both methods use the ZMP error and its variation as inputs and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR and the NF were trained based on simulation data and their performance was verified with a real biped robot. Two performance indexes are proposed to evaluate and compare the online performance of the two control methods. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that was acquired and adapted to the robot's size. Some experiments are presented and the results show that the implemented gait combined either with the SVR controller or with the TSK NF network controller can be used to control this biped robot. The SVR and the NF controllers exhibit similar stability, but the SVR controller runs about 50 times faster.",https://ieeexplore.ieee.org/document/5276806/,IEEE Transactions on Neural Networks,Dec. 2009,ieeexplore
10.1109/TASE.2019.2938316,Semiautomatic Labeling for Deep Learning in Robotics,IEEE,Journals,"In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35 000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets. Note to Practitioners-This article was motivated by the lack of a simple and effective solution for the generation of data sets usable to train a data-driven model, such as a modern deep neural network, so as to make them accessible in an industrial environment. Specifically, a deep learning robot guidance vision system would require such a large amount of manually labeled images that it would be too expensive and impractical for a real use case, where system reconfigurability is a fundamental requirement. With our system, on the other hand, especially in the field of industrial robotics, the cost of image labeling can be reduced, for the first time, to nearly zero, thus paving the way for self-reconfiguring systems with very high performance (as demonstrated by our experimental results). One of the limitations of this approach is the need to use a manual method for the detection of objects of interest in the preliminary stages of the pipeline (ARP or graphical interface). A feasible extension, related to the field of collaborative robotics, could be used to exploit the robot itself, manually moved by the user, even for this preliminary stage, so as to eliminate any source of inaccuracy.",https://ieeexplore.ieee.org/document/8844069/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/LRA.2020.3013848,Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?,IEEE,Journals,"Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCC<sub>Succ</sub> from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.",https://ieeexplore.ieee.org/document/9158349/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/JSYST.2008.925270,Sonar-Based Rover Navigation for Single or Multiple Platforms: Forward Safe Path and Target Switching Approach,IEEE,Journals,"In this paper, we have proposed a sensor fusion scheme along with the geometrical modeling of mobile robot navigation path in an unknown environment. In this scheme, the physical placement of sonars, their ranging limits and beam opening angles are considered. A simple 2-D axis transformation is proposed to relate local robot frame with the actual navigation environment. forward safe path (FSP) and target switching approach (TSA) are proposed for efficient obstacle avoidance and target tracking of mobile robot. FSP greatly simplifies the environment conditions as sensed by the robot and also provides minimum turning path during avoidance of obstacles. This method also removes the ldquooscillationrdquo in the mobile robot navigation path. TSA technique gives highest priority on the target tracking during the obstacle avoidance and seeks minimum distance path towards the target. These methods remove unnecessary turning of mobile robot during navigation. A scheme for target directional motion is also proposed. So, mobile robot takes the minimum turning path required towards the target. These methods also ensure the avoidance of ldquodead cycle problemrdquo. These schemes are successfully implemented on a model of <i>PatrolBot</i> mobile robot from <i>ActivMedia</i> Robotics. The overview of current research work on multi-domain robotic system namely system-of-systems is also presented. This paper also describes the Global Positioning System-based navigation of rovers. Results of real-time experiments with Pioneer II P2AT-8 from <i>ActivMedia</i> are included in this paper to show the future aspect of this research work.",https://ieeexplore.ieee.org/document/4550588/,IEEE Systems Journal,June 2008,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/TCDS.2018.2826921,The Perception of Emotion in Artificial Agents,IEEE,Journals,"Given recent technological developments in robotics, artificial intelligence, and virtual reality, it is perhaps unsurprising that the arrival of emotionally expressive and reactive artificial agents is imminent. However, if such agents are to become integrated into our social milieu, it is imperative to establish an understanding of whether and how humans perceive emotion in artificial agents. In this review, we incorporate recent findings from social robotics, virtual reality, psychology, and neuroscience to examine how people recognize and respond to emotions displayed by artificial agents. First, we review how people perceive emotions expressed by an artificial agent, such as facial and bodily expressions. Second, we evaluate the similarities and differences in the consequences of perceived emotions in artificial compared to human agents. Besides accurately recognizing the emotional state of an artificial agent, it is critical to understand how humans respond to those emotions. Does interacting with an angry robot induce the same responses in people as interacting with an angry person? Similarly, does watching a robot rejoice when it wins a game elicit similar feelings of elation in the human observer? Here, we provide an overview of the current state of emotion expression and perception during interactions with artificial agents, as well as a clear articulation of the challenges and guiding principles to be addressed as we move ever closer to truly emotional artificial agents.",https://ieeexplore.ieee.org/document/8341761/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2018,ieeexplore
10.1109/PROC.1983.12684,The Stanford Cart and the CMU Rover,IEEE,Journals,"The Stanford Cart was a remotely controlled TV-equipped mobile robot. A computer program was written which drove the Cart through cluttered spaces, gaining its knowledge of the world entirely from images broadcast by an on-board TV system. The CMU Rover is a more capable, and neatly operational, robot being built to develop and extend the Stanford work and to explore new directions. The Cart used several kinds of stereopsis to locate objects around it in three dimensions and to deduce its own motion. It planned an obstacle-avoiding path to a desired destination on the basis of a model built with this information. The plan changed as the Cart perceived new obstacles on its journey. The system was reliable for short runs, but slow. The Cart moved 1 m every 10 to 15 min, in lurches. After rolling a meter it stopped, took some pictures, and thought about them for a long time. Then it planned a new path, executed a little of it, and paused again. It successfully drove the Cart through several 20-m courses (each taking about 5 h) complex enough to necessitate three or four avoiding swerves; it failed in other trials in revealing ways. The Rover system has been designed with maximum mechanical and control system flexibility to support a wide range of research in perception and control. It features an omnidirectional steering system, a dozen on-board processors for essential real-time tasks, and a large remote computer to be helped by a high-speed digitizing/data playback unit and a high-performance array processor. Distributed high-level control software similar in organization to the Hearsay II speech-understanding system and the beginnings of a vision library are being readied. By analogy with the evolution of natural intelligence, we believe that incrementally solving the control and perception problems of an autonomous mobile mechanism is one of the best ways of arriving at general artificial intelligence.",https://ieeexplore.ieee.org/document/1456952/,Proceedings of the IEEE,July 1983,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TII.2019.2954956,Toward New Retail: A Benchmark Dataset for Smart Unmanned Vending Machines,IEEE,Journals,"Deep learning is a popular direction in computer vision and digital image processing. It is widely utilized in many fields, such as robot navigation, intelligent video surveillance, industrial inspection, and aerospace. With the extensive use of deep learning techniques, classification and object detection algorithms have been rapidly developed. In recent years, with the introduction of the concept of “unmanned retail,” object detection, and image classification play a central role in unmanned retail applications. However, open-source datasets of traditional classification and object detection have not yet been optimized for application scenarios of unmanned retail. Currently, classification and object detection datasets do not exist that focus on unmanned retail solely. Therefore, in order to promote unmanned retail applications by using deep learning-based classification and object detection, in this article we collected more than 30 000 images of unmanned retail containers using a refrigerator affixed with different cameras under both static and dynamic recognition environments. These images were categorized into ten kinds of beverages. After manual labeling, images in our constructed dataset contained 155 153 instances, each of which was annotated with a bounding box. We performed extensive experiments on this dataset using ten state-of-the-art deep learning-based models. Experimental results indicate great potential of using these deep learning-based models for real-world smart unmanned vending machines.",https://ieeexplore.ieee.org/document/8908822/,IEEE Transactions on Industrial Informatics,Dec. 2020,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2019.2939195,Toward a Clustering-Based Approach for Self-Adjusting Impact Factors in Robotic Control Model,IEEE,Journals,"In mobile robotic control models, control parameters are always generated by sensors' information and a set of Impact Factors (IFs, such as the P-value in the PID model). The IFs take forms of fixed coefficients in control models and need to be pre-defined at design-time. However, when operating in an open environment, IFs of the control model are expected to be adjusted automatically at run-time in order to adapt to the environment changes and improve the operation of robotics. This paper presents a clustering-based approach to continuously updating the IFs in robot control model. The proposed approach utilizes the density-based clustering method to classify environmental changes based on the effects of these changes on robots. In each cluster, the regression method is designed to learn the relationship between IFs and environment changes, and therefore generate corresponding IF adjustment model. Such approach can decrease the mutual interference of environmental changes and enhance the rationality of robotic actions. The paper presents the self-adjusting framework and designs corresponding IFs update algorithms. This paper develops robotics path-following scenario and object-following scenario in open environment and conducts experiments to evaluate the effectiveness of the proposed approach. The results show that the proposed approach has faster response to environmental changes than DQN and MPC approaches, along with a lower deviation of robot's actions.",https://ieeexplore.ieee.org/document/8822939/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2021.3080517,Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning,IEEE,Journals,"Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.",https://ieeexplore.ieee.org/document/9431107/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2020.3046730,Tracking In-Cabin Astronauts Using Deep Learning and Head Motion Clues,IEEE,Journals,"A person-following robot is under development for astronaut assistance on the Chinese Space Station. Real-time astronaut detection and tracking are the most important prerequisites for in-cabin flying assistant robots so that they can follow a specific astronaut and offer him/her assistance. In the limited space in the space station cabin, astronauts stand close to each other when working collaboratively; thus, large regions of their bodies tend to overlap in the image. In addition, because astronauts wear the same clothes most of the time, it is difficult to distinguish an individual astronaut using human body features. In this paper, we distinguish the astronauts by tracking their heads in the image. A deep learning model trained using big data is proposed for effective head detection. In addition, a motion model based on spatial clues is combined with the head detection results to track astronauts in the scene. A complete pipeline of the algorithm has been implemented and run efficiently on the Tegra X2 embedded AI microprocessor. A set of experiments were carried out and successfully validated the effectiveness of the proposed tracking algorithm. This algorithm is a step toward the implementation of robot assistants, especially in resource-limited environments.",https://ieeexplore.ieee.org/document/9305234/,IEEE Access,2021,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/70.508435,Virtual-reality-based point-and-direct robotic inspection in manufacturing,IEEE,Journals,"This paper explores a flexible manufacturing paradigm in which robot grasping is interactively specified and skeletal images are efficiently used in combination to allow rapidly setting up surface flaw identification tasks in small-quantity/large-variety manufacturing. Two complementary technologies are combined to make implementation of inspection as rapid as possible. First, a novel material handling approach is described for robotic picking and placing of parts onto an inspection table using virtual tools. This allows an operator to point and give directives to set up robotic inspection tasks. Second, since specification may be approximate using this method, a fast and flexible means of identifying images of perfect and flawed parts is explored that avoids rotational or translational restrictions on workpiece placement. This is accomplished by using skeleton pixel counts as neural network inputs. The total system, including material handling and skeleton-based inspection, features flexibility during manufacturing set-up, and reduces the process time and memory requirements for workpiece inspection.",https://ieeexplore.ieee.org/document/508435/,IEEE Transactions on Robotics and Automation,Aug. 1996,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/LRA.2019.2961598,When Your Robot Breaks: Active Learning During Plant Failure,IEEE,Journals,"Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.",https://ieeexplore.ieee.org/document/8938725/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.2986685,WiFi-Based Indoor Robot Positioning Using Deep Fuzzy Forests,IEEE,Journals,"Addressing the positioning problem of a mobile robot remains challenging to date despite many years of research. Indoor robot positioning strategies developed in the literature either rely on sophisticated computer vision techniques to handle visual inputs or require strong domain knowledge for nonvisual sensors. Although some systems have been deployed, the former may be lacking due to the intrinsic limitation of cameras (such as calibration, data association, system initialization, etc.) and the latter usually only works under certain environment layouts and additional equipment. To cope with those issues, we design a lightweight indoor robot positioning system which operates on cost-effective WiFi-based received signal strength (RSS) and could be readily pluggable into any existing WiFi network infrastructures. Moreover, a novel deep fuzzy forest is proposed to inherit the merits of decision trees and deep neural networks within an end-to-end trainable architecture. Real-world indoor localization experiments are conducted and results demonstrate the superiority of the proposed method over the existing approaches.",https://ieeexplore.ieee.org/document/9060874/,IEEE Internet of Things Journal,Nov. 2020,ieeexplore
10.1109/JSEN.2020.3024094,k-Nearest Neighbor Classification for Pattern Recognition of a Reference Source Light for Machine Vision System,IEEE,Journals,"The design of machine vision applications allows automatic inspection, measuring systems, and robot guidance. Typical applications of industrial robots are based on no-contact sensors to give the robot information about the environment. Robot's machine vision requires photosensors or video cameras to make intelligent decisions about its localization. Video cameras used as image-capturing equipment are too costly in comparison with optical scanning systems (OSS). The OSS system provides spatial coordinates measurements that can be exploited to solve a wide variety of structural problems in real-time. Localization and guidance using machine learning (ML) techniques offer advantages due to signals captured can be transformed and be reduced for processing, storage, and displaying. The use of algorithms of ML enhances the performance of the optical system based on localization and guidance. Feature extraction represents an important part of ML techniques to transform the original raw data onto a low-dimensional subspace and holding relevant information. This work presents an improvement of an optical system based on <i>k</i>-nearest neighbor ( <i>k</i>-NN) technique to solve the object detection and localization problem. The utility of this improvement allows the optical system can discriminate between the reference source and the optical noise or interference. The OSS system presented in this article has been implemented in structural health monitoring to measure the angular position even under “lighting and weather conditions”. The feature extraction techniques used in this article were linear predictive coding (LPC), quartiles ( <i>Q</i><sub>iquartile</sub>), and autocorrelation coefficients (ACC). The results of using <i>k</i>-NN and autocorrelation coefficients and quartiles predicted more than 98% of correct classification by using a reference source light as a class 1 and a light bulb as an optical noise and called class 2.",https://ieeexplore.ieee.org/document/9195874/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
