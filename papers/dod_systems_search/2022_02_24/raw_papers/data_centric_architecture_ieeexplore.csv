doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/ASRU.2007.4430168,A data-centric architecture for data-driven spoken dialog systems,IEEE,Conferences,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",https://ieeexplore.ieee.org/document/4430168/,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),9-13 Dec. 2007,ieeexplore
10.1109/ICDCSW.2003.1203556,"""Data-centric to the max"", the SPLICE architecture experience",IEEE,Conferences,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",https://ieeexplore.ieee.org/document/1203556/,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",19-22 May 2003,ieeexplore
10.1109/CLUSTER.2012.80,A Decoupled Execution Paradigm for Data-Intensive High-End Computing,IEEE,Conferences,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",https://ieeexplore.ieee.org/document/6337781/,2012 IEEE International Conference on Cluster Computing,24-28 Sept. 2012,ieeexplore
10.1109/ASRU.2007.4430168,A data-centric architecture for data-driven spoken dialog systems,IEEE,Conferences,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",https://ieeexplore.ieee.org/document/4430168/,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),9-13 Dec. 2007,ieeexplore
10.1109/SIoT.2016.007,Addressing Data-Centric Security Requirements for IoT-Based Systems,IEEE,Conferences,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",https://ieeexplore.ieee.org/document/7913560/,2016 International Workshop on Secure Internet of Things (SIoT),26-30 Sept. 2016,ieeexplore
10.1109/ICCE-China.2017.7991141,An IoT framework for intelligent roadside assistance system,IEEE,Conferences,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",https://ieeexplore.ieee.org/document/7991141/,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),12-14 June 2017,ieeexplore
10.1109/ISSNIP.2005.1595552,Architectures for Wireless Sensor Networks,IEEE,Conferences,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,https://ieeexplore.ieee.org/document/1595552/,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",5-8 Dec. 2005,ieeexplore
10.1109/CAST.2016.7914932,Big data architecture with mobile cloud in CDroid operating system for storing huge data,IEEE,Conferences,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,https://ieeexplore.ieee.org/document/7914932/,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",19-21 Dec. 2016,ieeexplore
10.1109/LANMAN.2015.7114718,Boosting named data networking for efficient packet forwarding in urban VANET scenarios,IEEE,Conferences,"Named Data Networking (NDN) is a data-centric architecture designed for the future Internet. Existing works show that NDN brings significant performance improvement for typical content-centric applications, and can also fit the mobile environment well. However, directly applying NDN to Vehicular Ad hoc NETworks (VANETs) is confronted with great challenges due to the high mobility of vehicles. Most applications in VANETs are relied on data dissemination mechanisms. Therefore, we aim to improve the performance of NDN packet forwarding for the efficient content delivery in urban VANET scenarios. Specifically, we introduce the geo-location information to the NDN forwarding plane, and propose a geo-based forwarding strategy to make NDN fit the urban VANETs. Simulation results show our strategy can achieve 27% ~ 75% higher request success ratio, and 40% ~ 80% lower delay compared with the default NDN strategy in urban scenarios with different vehicle densities.",https://ieeexplore.ieee.org/document/7114718/,The 21st IEEE International Workshop on Local and Metropolitan Area Networks,22-24 April 2015,ieeexplore
10.1109/Innovate-Data.2017.14,Bringing Big Data into the Car: Does it Scale?,IEEE,Conferences,"The increasing velocity of big data captured by various sensors and processed in real-time offers support for a range of new application domains. For car information systems (CIS), data from different sources including IoT needs to be combined to offer an adequate service to the user. In this paper, we introduce a novel CIS big data-centric architecture based on a smart streaming infrastructure integrating data source in and outside of the car. We have created a prototype implementation of this architecture and run several experiments to validate the quality of our solution. Especially, we have examined the fault tolerance of the architecture by systematically introducing failures and evaluating their effects on the car information system. The experimental results show that our solution for a smart data based car information system is both scalable and fault tolerant.",https://ieeexplore.ieee.org/document/8316294/,2017 International Conference on Big Data Innovations and Applications (Innovate-Data),21-23 Aug. 2017,ieeexplore
10.1109/WAINA.2013.19,CCN-TV: A Data-centric Approach to Real-Time Video Services,IEEE,Conferences,"Content-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCN-TV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies.",https://ieeexplore.ieee.org/document/6550523/,2013 27th International Conference on Advanced Information Networking and Applications Workshops,25-28 March 2013,ieeexplore
10.1109/BigData.2015.7363971,Component based dataflow processing framework,IEEE,Conferences,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",https://ieeexplore.ieee.org/document/7363971/,2015 IEEE International Conference on Big Data (Big Data),29 Oct.-1 Nov. 2015,ieeexplore
10.1109/ICSEA.2010.30,Content Server Architecture Pattern for Evolvability and Scalability,IEEE,Conferences,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",https://ieeexplore.ieee.org/document/5615125/,2010 Fifth International Conference on Software Engineering Advances,22-27 Aug. 2010,ieeexplore
10.1109/APWiMob.2014.6920286,Critical security review and study of DDoS attacks on LTE mobile network,IEEE,Conferences,"Mobile network is currently evolving into data centric architecture. Long Term Evolution (LTE) based next generation 4G technology is being deployed by cellular operators around the globe. LTE supports all-IP based data, voice and streaming network with speeds in the order of hundreds of megabits per seconds. Increased speed in accessing Internet and other advanced services exposes mobile data network to be attacked by hackers using spyware, malware, phishing and distributed denial-of-service (DDoS) attacks, which were predominantly affecting Internet-only datacentres in the past. This paper presents a detailed review of security framework and authentication procedures built into the LTE system architecture evolution (SAE). A brief summary of DDoS attacks and security vulnerabilities in LTE network included. This paper reviews the diameter interface and associated security problems using it in LTE network. This paper proposes using explicit-congestion notification (ECN) based method to address congestion issues in diameter interface.",https://ieeexplore.ieee.org/document/6920286/,2014 IEEE Asia Pacific Conference on Wireless and Mobile,28-30 Aug. 2014,ieeexplore
10.1109/AERO.2005.1559422,"Data centric, position-based routing in space networks",IEEE,Conferences,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",https://ieeexplore.ieee.org/document/1559422/,2005 IEEE Aerospace Conference,5-12 March 2005,ieeexplore
10.1109/ICCCN.2019.8847129,Data-Centric Video for Mixed Reality,IEEE,Conferences,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",https://ieeexplore.ieee.org/document/8847129/,2019 28th International Conference on Computer Communication and Networks (ICCCN),29 July-1 Aug. 2019,ieeexplore
10.1109/CTS.2014.6867550,Defining architecture components of the Big Data Ecosystem,IEEE,Conferences,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a socalled Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.",https://ieeexplore.ieee.org/document/6867550/,2014 International Conference on Collaboration Technologies and Systems (CTS),19-23 May 2014,ieeexplore
10.1109/NetSys.2019.8854515,Information-Centric IoT Middleware Overlay: VSL,IEEE,Conferences,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",https://ieeexplore.ieee.org/document/8854515/,2019 International Conference on Networked Systems (NetSys),18-21 March 2019,ieeexplore
10.1109/SERVICES51467.2021.00054,Keynote 1: DBOS: A Database-Oriented Operating System,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Current operating systems are complex systems that were designed long before today’s computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today’s most important applications, propose a plan for the development of a DBOS proof of concept, and give results on a pilot that suggest the approach has merit.",https://ieeexplore.ieee.org/document/9604388/,2021 IEEE World Congress on Services (SERVICES),5-10 Sept. 2021,ieeexplore
10.1109/PES.2005.1489657,Moving from data architecture to event architecture in the EMS environment,IEEE,Conferences,"Information models and databases are at the center of the design of most current software systems. The job done by the active portions, the applications, is to transform the data as needed. If the applications can, they work in a strictly stateless, data transforming paradigm, because this creates the simplest sort of reliable system. Our EMS systems are complex, real-time systems that cannot adopt this simplest paradigm, but they nevertheless follow a data-centric architecture. This is about to change. ""Message buses"" or ""integration buses"" or ""event buses"" are different names for the ability to connect applications with high speed flexible messaging. This technology is now ready for prime time and the question is - how are we going to use it? Are we going to take advantage of the active voice communication that events can provide? Or, are we going to stay predominantly in the familiar data orientation? The situation is somewhat analogous to the now-familiar experience that procedural programmers, when given object oriented languages, often did not go through the paradigm-shift and produced procedural code written in object languages. In this paper, we focus on the advantages that can be achieved in the temporal domain - a long-standing trouble-spot in EMS design.",https://ieeexplore.ieee.org/document/1489657/,"IEEE Power Engineering Society General Meeting, 2005",16-16 June 2005,ieeexplore
10.1109/AERO.2010.5446746,Pnpsat-2 SPA Technology Testbed initial results and development status,IEEE,Conferences,"Abstract-This paper presents the initial results and development status of the AFRL sponsored PnPSat-2 SPA Technology Testbed. The purpose of the testbed is to integrate the next generation of radiation hardened SPA technology and components (hardware and software) with a representative tactical satellite bus structure. The resulting system will be used to demonstrate system performance using Hardware in the Loop (HWIL) techniques for representative (e.g. ORS Tactical) scenarios. AFRL has led two efforts in SPA technology development to both solidify the SPA technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) was the first spacecraft to utilize the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. PnPSat-2 integrates the next generation of radiation hardened SPA components on a larger bus focused on ORS needs. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insulates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in development and test time.",https://ieeexplore.ieee.org/document/5446746/,2010 IEEE Aerospace Conference,6-13 March 2010,ieeexplore
10.1109/TrustCom.2016.0248,Rethinking High Performance Computing System Architecture for Scientific Big Data Applications,IEEE,Conferences,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",https://ieeexplore.ieee.org/document/7847131/,2016 IEEE Trustcom/BigDataSE/ISPA,23-26 Aug. 2016,ieeexplore
10.1109/PDCAT.2010.72,Sharing In-Memory Game States,IEEE,Conferences,"Massively multi-user virtual environments (MMVEs)are becoming increasingly popular with millions of users. Typically, commercial implementations rely on client/server architectures for managing the game state and use message passing mechanisms to communicate state changes to the clients. We have developed the Typed Grid Object Sharing (TGOS)service providing data sharing of in-memory data. TGOS aims at simplifying the development of MMVEs by sharing scene graphs in a peer-to-peer way and also data of backend services. Replication is controlled by different consistency models, including restartable transactions combined with optimistic synchronization for strong consistency. In this paper we describe the data centric architecture of the Wissenheim Worlds application and relevant parts of TGOS. Furthermore, we present an evaluation showing the feasibility and efficiency of the proposed approach.",https://ieeexplore.ieee.org/document/5704404/,"2010 International Conference on Parallel and Distributed Computing, Applications and Technologies",8-11 Dec. 2010,ieeexplore
10.1109/AERO.2017.7943816,Software architecture and design of the Kontur-2 mission,IEEE,Conferences,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",https://ieeexplore.ieee.org/document/7943816/,2017 IEEE Aerospace Conference,4-11 March 2017,ieeexplore
10.1109/CIOT.2018.8627124,"fogØ5: Unifying the computing, networking and storage fabrics end-to-end",IEEE,Conferences,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",https://ieeexplore.ieee.org/document/8627124/,2018 3rd Cloudification of the Internet of Things (CIoT),2-4 July 2018,ieeexplore
10.1109/TCC.2015.2474385,Cross-Cloud MapReduce for Big Data,IEEE,Journals,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",https://ieeexplore.ieee.org/document/7229313/,IEEE Transactions on Cloud Computing,1 April-June 2020,ieeexplore
10.1109/JIOT.2021.3061531,SmartDetour: Defending Blackhole and Content Poisoning Attacks in IoT NDN Networks,IEEE,Journals,"Named data networking (NDN) recently arises as a promising networking paradigm to support the Internet of Things (IoT) due to its data-centric architecture. However, NDN integrates application-layer semantics into the packet forwarding plane, which presents new attack faces. In this article, we aim to handle two attacks that exploit such vulnerabilities, namely the blackhole attack and the content poisoning attack. The two attacks are not handled efficiently by existing approaches due to the challenge in minimizing routers that need to be detoured to isolate attackers. Therefore, in this article, we propose a novel method named SmartDetour to tackle the challenge in a distributed manner. SmartDetour contains two components: 1) a proactive reputation updating algorithm and 2) a reputation-based probabilistic forwarding strategy. The former updates the reputation of forwarding candidates based on whether they must be detoured upon packet failures. The latter selects the next-hop router for interest packets probabilistically based on the reputations of forwarding candidates. The two components work together to isolate attackers with minimal detouring needed. Extensive ndnSIM-based simulation shows that SmartDetour can effectively identify and isolate attackers.",https://ieeexplore.ieee.org/document/9360863/,IEEE Internet of Things Journal,"1 Aug.1, 2021",ieeexplore
10.1147/JRD.2019.2960220,The CORAL supercomputer systems,IBM,Journals,"In 2014, the U.S. Department of Energy (DoE) initiated a multiyear collaboration between Oak Ridge National Laboratory (ORNL), Argonne National Laboratory, and Lawrence Livermore National Laboratory (LLNL), known as “CORAL,” the next major phase in the DoE's scientific computing roadmap. The IBM CORAL systems are based on a fundamentally new data-centric architecture, where compute power is embedded everywhere data resides, combining powerful central processing units (CPUs) with graphics processing units (GPUs) optimized for scientific computing and artificial intelligence workloads. The IBM CORAL systems were built on the combination of mature technologies: 9th-generation POWER CPU, 6th-generation NVIDIA GPU, and 5th-generation Mellanox InfiniBand. These systems are providing scientists with computing power to solve challenges in many research areas beyond previously possible. This article provides an overview of the system solutions deployed at ORNL and LLNL.",https://ieeexplore.ieee.org/document/8935422/,IBM Journal of Research and Development,1 May-July 2020,ieeexplore
10.1109/ASRU.2007.4430168,A data-centric architecture for data-driven spoken dialog systems,IEEE,Conferences,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",https://ieeexplore.ieee.org/document/4430168/,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),9-13 Dec. 2007,ieeexplore
10.1109/ICDCSW.2003.1203556,"""Data-centric to the max"", the SPLICE architecture experience",IEEE,Conferences,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",https://ieeexplore.ieee.org/document/1203556/,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",19-22 May 2003,ieeexplore
10.1109/CLUSTER.2012.80,A Decoupled Execution Paradigm for Data-Intensive High-End Computing,IEEE,Conferences,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",https://ieeexplore.ieee.org/document/6337781/,2012 IEEE International Conference on Cluster Computing,24-28 Sept. 2012,ieeexplore
10.1109/ASRU.2007.4430168,A data-centric architecture for data-driven spoken dialog systems,IEEE,Conferences,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",https://ieeexplore.ieee.org/document/4430168/,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),9-13 Dec. 2007,ieeexplore
10.1109/SIoT.2016.007,Addressing Data-Centric Security Requirements for IoT-Based Systems,IEEE,Conferences,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",https://ieeexplore.ieee.org/document/7913560/,2016 International Workshop on Secure Internet of Things (SIoT),26-30 Sept. 2016,ieeexplore
10.1109/ICCE-China.2017.7991141,An IoT framework for intelligent roadside assistance system,IEEE,Conferences,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",https://ieeexplore.ieee.org/document/7991141/,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),12-14 June 2017,ieeexplore
10.1109/ISSNIP.2005.1595552,Architectures for Wireless Sensor Networks,IEEE,Conferences,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,https://ieeexplore.ieee.org/document/1595552/,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",5-8 Dec. 2005,ieeexplore
10.1109/CAST.2016.7914932,Big data architecture with mobile cloud in CDroid operating system for storing huge data,IEEE,Conferences,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,https://ieeexplore.ieee.org/document/7914932/,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",19-21 Dec. 2016,ieeexplore
10.1109/LANMAN.2015.7114718,Boosting named data networking for efficient packet forwarding in urban VANET scenarios,IEEE,Conferences,"Named Data Networking (NDN) is a data-centric architecture designed for the future Internet. Existing works show that NDN brings significant performance improvement for typical content-centric applications, and can also fit the mobile environment well. However, directly applying NDN to Vehicular Ad hoc NETworks (VANETs) is confronted with great challenges due to the high mobility of vehicles. Most applications in VANETs are relied on data dissemination mechanisms. Therefore, we aim to improve the performance of NDN packet forwarding for the efficient content delivery in urban VANET scenarios. Specifically, we introduce the geo-location information to the NDN forwarding plane, and propose a geo-based forwarding strategy to make NDN fit the urban VANETs. Simulation results show our strategy can achieve 27% ~ 75% higher request success ratio, and 40% ~ 80% lower delay compared with the default NDN strategy in urban scenarios with different vehicle densities.",https://ieeexplore.ieee.org/document/7114718/,The 21st IEEE International Workshop on Local and Metropolitan Area Networks,22-24 April 2015,ieeexplore
10.1109/Innovate-Data.2017.14,Bringing Big Data into the Car: Does it Scale?,IEEE,Conferences,"The increasing velocity of big data captured by various sensors and processed in real-time offers support for a range of new application domains. For car information systems (CIS), data from different sources including IoT needs to be combined to offer an adequate service to the user. In this paper, we introduce a novel CIS big data-centric architecture based on a smart streaming infrastructure integrating data source in and outside of the car. We have created a prototype implementation of this architecture and run several experiments to validate the quality of our solution. Especially, we have examined the fault tolerance of the architecture by systematically introducing failures and evaluating their effects on the car information system. The experimental results show that our solution for a smart data based car information system is both scalable and fault tolerant.",https://ieeexplore.ieee.org/document/8316294/,2017 International Conference on Big Data Innovations and Applications (Innovate-Data),21-23 Aug. 2017,ieeexplore
10.1109/WAINA.2013.19,CCN-TV: A Data-centric Approach to Real-Time Video Services,IEEE,Conferences,"Content-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCN-TV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies.",https://ieeexplore.ieee.org/document/6550523/,2013 27th International Conference on Advanced Information Networking and Applications Workshops,25-28 March 2013,ieeexplore
10.1109/BigData.2015.7363971,Component based dataflow processing framework,IEEE,Conferences,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",https://ieeexplore.ieee.org/document/7363971/,2015 IEEE International Conference on Big Data (Big Data),29 Oct.-1 Nov. 2015,ieeexplore
10.1109/ICSEA.2010.30,Content Server Architecture Pattern for Evolvability and Scalability,IEEE,Conferences,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",https://ieeexplore.ieee.org/document/5615125/,2010 Fifth International Conference on Software Engineering Advances,22-27 Aug. 2010,ieeexplore
10.1109/APWiMob.2014.6920286,Critical security review and study of DDoS attacks on LTE mobile network,IEEE,Conferences,"Mobile network is currently evolving into data centric architecture. Long Term Evolution (LTE) based next generation 4G technology is being deployed by cellular operators around the globe. LTE supports all-IP based data, voice and streaming network with speeds in the order of hundreds of megabits per seconds. Increased speed in accessing Internet and other advanced services exposes mobile data network to be attacked by hackers using spyware, malware, phishing and distributed denial-of-service (DDoS) attacks, which were predominantly affecting Internet-only datacentres in the past. This paper presents a detailed review of security framework and authentication procedures built into the LTE system architecture evolution (SAE). A brief summary of DDoS attacks and security vulnerabilities in LTE network included. This paper reviews the diameter interface and associated security problems using it in LTE network. This paper proposes using explicit-congestion notification (ECN) based method to address congestion issues in diameter interface.",https://ieeexplore.ieee.org/document/6920286/,2014 IEEE Asia Pacific Conference on Wireless and Mobile,28-30 Aug. 2014,ieeexplore
10.1109/AERO.2005.1559422,"Data centric, position-based routing in space networks",IEEE,Conferences,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",https://ieeexplore.ieee.org/document/1559422/,2005 IEEE Aerospace Conference,5-12 March 2005,ieeexplore
10.1109/ICCCN.2019.8847129,Data-Centric Video for Mixed Reality,IEEE,Conferences,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",https://ieeexplore.ieee.org/document/8847129/,2019 28th International Conference on Computer Communication and Networks (ICCCN),29 July-1 Aug. 2019,ieeexplore
10.1109/CTS.2014.6867550,Defining architecture components of the Big Data Ecosystem,IEEE,Conferences,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a socalled Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.",https://ieeexplore.ieee.org/document/6867550/,2014 International Conference on Collaboration Technologies and Systems (CTS),19-23 May 2014,ieeexplore
10.1109/NetSys.2019.8854515,Information-Centric IoT Middleware Overlay: VSL,IEEE,Conferences,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",https://ieeexplore.ieee.org/document/8854515/,2019 International Conference on Networked Systems (NetSys),18-21 March 2019,ieeexplore
10.1109/SERVICES51467.2021.00054,Keynote 1: DBOS: A Database-Oriented Operating System,IEEE,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Current operating systems are complex systems that were designed long before today’s computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today’s most important applications, propose a plan for the development of a DBOS proof of concept, and give results on a pilot that suggest the approach has merit.",https://ieeexplore.ieee.org/document/9604388/,2021 IEEE World Congress on Services (SERVICES),5-10 Sept. 2021,ieeexplore
10.1109/PES.2005.1489657,Moving from data architecture to event architecture in the EMS environment,IEEE,Conferences,"Information models and databases are at the center of the design of most current software systems. The job done by the active portions, the applications, is to transform the data as needed. If the applications can, they work in a strictly stateless, data transforming paradigm, because this creates the simplest sort of reliable system. Our EMS systems are complex, real-time systems that cannot adopt this simplest paradigm, but they nevertheless follow a data-centric architecture. This is about to change. ""Message buses"" or ""integration buses"" or ""event buses"" are different names for the ability to connect applications with high speed flexible messaging. This technology is now ready for prime time and the question is - how are we going to use it? Are we going to take advantage of the active voice communication that events can provide? Or, are we going to stay predominantly in the familiar data orientation? The situation is somewhat analogous to the now-familiar experience that procedural programmers, when given object oriented languages, often did not go through the paradigm-shift and produced procedural code written in object languages. In this paper, we focus on the advantages that can be achieved in the temporal domain - a long-standing trouble-spot in EMS design.",https://ieeexplore.ieee.org/document/1489657/,"IEEE Power Engineering Society General Meeting, 2005",16-16 June 2005,ieeexplore
10.1109/AERO.2010.5446746,Pnpsat-2 SPA Technology Testbed initial results and development status,IEEE,Conferences,"Abstract-This paper presents the initial results and development status of the AFRL sponsored PnPSat-2 SPA Technology Testbed. The purpose of the testbed is to integrate the next generation of radiation hardened SPA technology and components (hardware and software) with a representative tactical satellite bus structure. The resulting system will be used to demonstrate system performance using Hardware in the Loop (HWIL) techniques for representative (e.g. ORS Tactical) scenarios. AFRL has led two efforts in SPA technology development to both solidify the SPA technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) was the first spacecraft to utilize the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. PnPSat-2 integrates the next generation of radiation hardened SPA components on a larger bus focused on ORS needs. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insulates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in development and test time.",https://ieeexplore.ieee.org/document/5446746/,2010 IEEE Aerospace Conference,6-13 March 2010,ieeexplore
10.1109/TrustCom.2016.0248,Rethinking High Performance Computing System Architecture for Scientific Big Data Applications,IEEE,Conferences,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",https://ieeexplore.ieee.org/document/7847131/,2016 IEEE Trustcom/BigDataSE/ISPA,23-26 Aug. 2016,ieeexplore
10.1109/PDCAT.2010.72,Sharing In-Memory Game States,IEEE,Conferences,"Massively multi-user virtual environments (MMVEs)are becoming increasingly popular with millions of users. Typically, commercial implementations rely on client/server architectures for managing the game state and use message passing mechanisms to communicate state changes to the clients. We have developed the Typed Grid Object Sharing (TGOS)service providing data sharing of in-memory data. TGOS aims at simplifying the development of MMVEs by sharing scene graphs in a peer-to-peer way and also data of backend services. Replication is controlled by different consistency models, including restartable transactions combined with optimistic synchronization for strong consistency. In this paper we describe the data centric architecture of the Wissenheim Worlds application and relevant parts of TGOS. Furthermore, we present an evaluation showing the feasibility and efficiency of the proposed approach.",https://ieeexplore.ieee.org/document/5704404/,"2010 International Conference on Parallel and Distributed Computing, Applications and Technologies",8-11 Dec. 2010,ieeexplore
10.1109/AERO.2017.7943816,Software architecture and design of the Kontur-2 mission,IEEE,Conferences,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",https://ieeexplore.ieee.org/document/7943816/,2017 IEEE Aerospace Conference,4-11 March 2017,ieeexplore
10.1109/CIOT.2018.8627124,"fogØ5: Unifying the computing, networking and storage fabrics end-to-end",IEEE,Conferences,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",https://ieeexplore.ieee.org/document/8627124/,2018 3rd Cloudification of the Internet of Things (CIoT),2-4 July 2018,ieeexplore
10.1109/TCC.2015.2474385,Cross-Cloud MapReduce for Big Data,IEEE,Journals,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",https://ieeexplore.ieee.org/document/7229313/,IEEE Transactions on Cloud Computing,1 April-June 2020,ieeexplore
10.1109/JIOT.2021.3061531,SmartDetour: Defending Blackhole and Content Poisoning Attacks in IoT NDN Networks,IEEE,Journals,"Named data networking (NDN) recently arises as a promising networking paradigm to support the Internet of Things (IoT) due to its data-centric architecture. However, NDN integrates application-layer semantics into the packet forwarding plane, which presents new attack faces. In this article, we aim to handle two attacks that exploit such vulnerabilities, namely the blackhole attack and the content poisoning attack. The two attacks are not handled efficiently by existing approaches due to the challenge in minimizing routers that need to be detoured to isolate attackers. Therefore, in this article, we propose a novel method named SmartDetour to tackle the challenge in a distributed manner. SmartDetour contains two components: 1) a proactive reputation updating algorithm and 2) a reputation-based probabilistic forwarding strategy. The former updates the reputation of forwarding candidates based on whether they must be detoured upon packet failures. The latter selects the next-hop router for interest packets probabilistically based on the reputations of forwarding candidates. The two components work together to isolate attackers with minimal detouring needed. Extensive ndnSIM-based simulation shows that SmartDetour can effectively identify and isolate attackers.",https://ieeexplore.ieee.org/document/9360863/,IEEE Internet of Things Journal,"1 Aug.1, 2021",ieeexplore
10.1147/JRD.2019.2960220,The CORAL supercomputer systems,IBM,Journals,"In 2014, the U.S. Department of Energy (DoE) initiated a multiyear collaboration between Oak Ridge National Laboratory (ORNL), Argonne National Laboratory, and Lawrence Livermore National Laboratory (LLNL), known as “CORAL,” the next major phase in the DoE's scientific computing roadmap. The IBM CORAL systems are based on a fundamentally new data-centric architecture, where compute power is embedded everywhere data resides, combining powerful central processing units (CPUs) with graphics processing units (GPUs) optimized for scientific computing and artificial intelligence workloads. The IBM CORAL systems were built on the combination of mature technologies: 9th-generation POWER CPU, 6th-generation NVIDIA GPU, and 5th-generation Mellanox InfiniBand. These systems are providing scientists with computing power to solve challenges in many research areas beyond previously possible. This article provides an overview of the system solutions deployed at ORNL and LLNL.",https://ieeexplore.ieee.org/document/8935422/,IBM Journal of Research and Development,1 May-July 2020,ieeexplore
10.1109/IDT.2008.4802501,"Challenges and solutions in configuring, rapid developing and deploying of a QoS-enabled component middleware",IEEE,Conferences,"Data-centric design is emerging as a key tenet for building advanced data-critical distributed real-time and embedded systems. These systems must find the right data, know where to send it, and deliver it to the right place at the right time. Data distribution service (DDS) specifies an API designed for enabling real-time data distribution and is well suited for such complex distributed systems and QoS-enabled applications. It is also, widely known that control area networks (CAN) are used in real-time, distributed and parallel processing. Thus, this paper provides an overview about the problem caused by some combinations of QoS policies and gives ideas about the emerging of the new paradigm of Model Driven Middleware with QoS-enabled component, including DDS.",https://ieeexplore.ieee.org/document/4802501/,2008 3rd International Design and Test Workshop,20-22 Dec. 2008,ieeexplore
10.1109/WSC.2018.8632446,DATA-CENTRIC CYBER-PHYSICAL SYSTEMS DESIGN WITH SMARTDATA,IEEE,Conferences,"Timeliness is a fundamental property of Cyber-Physical Systems that has been intensively investigated within the scope of real-time and critical systems. The advent of the Internet of Things, however, brings an intense communication flow between devices and the Internet. In this scenario, modeling time requirements in terms of data, rather than the tasks that manipulate them, may be advantageous as a data-centric design can promptly encompass other first-order requirements, such as geolocation, security, and trustworthiness. In this paper, we propose a strategy to design complex CPSs by modeling their data using the SmartData construct, which, besides encompassing means to handle the aforementioned requirements, also defines the concept of data expiry to guide scheduling decisions. With SmartData, local tasks are scheduled to produce the freshest data and to manipulate them before expiration. Likewise, network packets are scheduled prioritizing data whose expiry is close. We validate the strategy through simulations using Castalia.",https://ieeexplore.ieee.org/document/8632446/,2018 Winter Simulation Conference (WSC),9-12 Dec. 2018,ieeexplore
10.1049/cp.2012.1116,Design of real-time distributed system using DDS,IET,Conferences,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,https://ieeexplore.ieee.org/document/6492723/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
,Dr. BFS: Data Centric Breadth-First Search on FPGAs,IEEE,Conferences,"The flexible architectures of Field Programmable Gate Arrays (FPGAs) lend themselves to an array of data analytical applications, among which Breadth-First Search (BFS), due to its vital importance, draws particular attention. Recent attempts that omoad BFS on FPGAs either simply imitate the existing CPU- or Graphics Processing Units (GPU)based mechanisms or suffer from scalability issues. To this end, we introduce a novel data centric design which extensively extracts the potential of FPGAs for BFS with the following two techniques. First, we advocate to partition and compress the BFS algorithmic metadata in order to buffer them in fast on-chip memory and circumvent the expensive metadata access. Second, we propose a hierarchical coalescing method to improve the throughput of graph data access. Taken together, our evaluation demonstrates that the proposed design achieves, on average, 1.6× and 2.2× speedups over the state-of-the-art FPGA designs TorusBFS and Umuroglu, respectively, across a collection of graph datasets.",https://ieeexplore.ieee.org/document/8806902/,2019 56th ACM/IEEE Design Automation Conference (DAC),2-6 June 2019,ieeexplore
10.1109/HotICN50779.2020.9350821,Hierarchical Identity-Based Security Mechanism Using Blockchain in Named Data Networking,IEEE,Conferences,"Named Data Networking (NDN) with the data-centric design has been viewed as a promising future Internet architecture. It requires a new security model orienting data but not host. In this paper, a Hierarchical Identity-based Security Mechanism by Blockchain (HISM-B) is to be proposed for NDN networks. It could satisfy the two assumptions specified in the NDN testbed to maintain the data-oriented authentication. At one hand, the hierarchical identity-based cryptology is used to bind the data name with the public key and then two signatures are encapsulated in the data packet so that the data source authentication and the integrity of data packet can be supported. At the other hand, a blockchain is employed to manage public keys for different domains to avoid catastrophes due to a single node failure. The validation result shows that the proposed HISM-B is safe.",https://ieeexplore.ieee.org/document/9350821/,2020 3rd International Conference on Hot Information-Centric Networking (HotICN),12-14 Dec. 2020,ieeexplore
10.1109/BigData47090.2019.9006235,Hybrid 2D and 3D Visual Analytics of Network Simulation Data,IEEE,Conferences,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,https://ieeexplore.ieee.org/document/9006235/,2019 IEEE International Conference on Big Data (Big Data),9-12 Dec. 2019,ieeexplore
10.1109/ISQED.2003.1194734,Interoperability beyond design: sharing knowledge between design and manufacturing,IEEE,Conferences,"The nature of IC design is necessarily evolving to a more data-centric design flow in which EDA tools share a common information in a design database without the negative cost and quality impacts of data translation from sequential files. In support of this new paradigm, a collection of mainstream companies within the IC supply chain have sponsored the development of an open industry data model and application program interface for IC design tools, along with a database that fully implements this. This technology, called OpenAccess, is now available and being adopted by the IC design community. Another industry effort is in operation with the goal of greatly improving the cost and efficiency for IC photomasks. That effort is exploring a new paradigm similar in nature to OpenAccess in that a common data model and data access language is proposed. This data model would span both the design and mask-making communities, and possibly expand into wafer fabrication over time. Thus, it has become known as the Universal Data Model (UDM). This paper discusses some of the rationale for the UDM and highlights the attributes of the OpenAccess technology that make it the ideal base on which to build an open industry UDM.",https://ieeexplore.ieee.org/document/1194734/,"Fourth International Symposium on Quality Electronic Design, 2003. Proceedings.",24-26 March 2003,ieeexplore
10.1109/SEARIS44442.2018.9180229,Realtime Interactive Hybrid 2D and 3D Visual Analytics on Large High Resolution Display and Immersive Virtual Environment,IEEE,Conferences,We present a data-flow-oriented scalable and extensible visualization system for supporting hybrid 2D and 3D visual analytics. Our application allows users to visually analyze the results of a complex multivariate Monte Carlo simulation. The simulation outputs variables describing various properties of 3D objects interacting in a dynamic 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the 3D simulation in a virtual environment showing the time-varying results of the dynamics in a 3D environment. The Unity application runs on both a 2D high resolution display system and a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the 2D and 3D visualization components. Preliminary results show our data-centric design provides a user-centric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,https://ieeexplore.ieee.org/document/9180229/,2018 IEEE 11th Workshop on Software Engineering and Architectures for Real-time Interactive Systems (SEARIS),19-19 March 2018,ieeexplore
10.1109/ICCWorkshops49005.2020.9145301,Supporting Delay Tolerant Networking: A Comparative Study of Epidemic Routing and NDN,IEEE,Conferences,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",https://ieeexplore.ieee.org/document/9145301/,2020 IEEE International Conference on Communications Workshops (ICC Workshops),7-11 June 2020,ieeexplore
10.1109/ICDEW.2016.7495633,Towards a distributed multi-tier file system for cluster computing,IEEE,Conferences,"Distributed storage systems running on clusters of commodity hardware are challenged by the ever-growing data storage and I/O demands of modern large-scale data analytics. A promising trend is to exploit the recent improvements in memory, storage media, and network technologies for sustaining high performance at low cost. While recent work explores using memory and SSDs as a cache for local storage or combining local with network-attached storage, no work has ever looked at all layers together in a distributed setting. We present a novel design for a distributed file system that is aware of heterogeneous storage media (e.g., memory, SSDs, HDDs, NAS) with different capacities and performance characteristics. The storage media are explicitly exposed to users and applications, allowing them to choose the distribution and placement of replicas in the cluster based on their own performance and fault tolerance requirements. At the same time, the system offers a variety of pluggable policies for automating data management for increased performance and better cluster utilization. We analyze the new trends and challenges that led to our application- and data-centric design choices, and discuss how those choices inspire new research opportunities for data-intensive processing systems.",https://ieeexplore.ieee.org/document/7495633/,2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW),16-20 May 2016,ieeexplore
10.1109/CSCWD.2006.253098,Universal data model platform: the data-centric evolution for system level codesign,IEEE,Conferences,"The rapidly increasing complexity of integrated circuit design is evolving to a more data-centric design scenario that supports sharing of design information. This paper presents the concepts of universal data model platform (UDMP) which introduce the data-centric design revolution into the domain of system level design to support better cooperation of individual steps in electronic design automation (EDA) industry. The goal of UDMP is to provide a set of universal data models which enables wide variety of codesign tools to be integrated tightly and revitalizes the connection between universities and the EDA industry. Furthermore, an application programming interface (API) takes the place of traditional low-bandwidth file formats to provide access to the internal data models, thus improves efficiency of design iteration. The well-constructed structure of UDMP brings some challenges for the architects as well as current system level researchers and designers. The concepts of UDMP are applied to a simplified interface synthesis flow which contains three algorithms. Primary experiment results show that these algorithms are simplified with a running time reduction by about 10% for selected designs",https://ieeexplore.ieee.org/document/4019134/,2006 10th International Conference on Computer Supported Cooperative Work in Design,3-5 May 2006,ieeexplore
10.1109/IDT.2008.4802501,"Challenges and solutions in configuring, rapid developing and deploying of a QoS-enabled component middleware",IEEE,Conferences,"Data-centric design is emerging as a key tenet for building advanced data-critical distributed real-time and embedded systems. These systems must find the right data, know where to send it, and deliver it to the right place at the right time. Data distribution service (DDS) specifies an API designed for enabling real-time data distribution and is well suited for such complex distributed systems and QoS-enabled applications. It is also, widely known that control area networks (CAN) are used in real-time, distributed and parallel processing. Thus, this paper provides an overview about the problem caused by some combinations of QoS policies and gives ideas about the emerging of the new paradigm of Model Driven Middleware with QoS-enabled component, including DDS.",https://ieeexplore.ieee.org/document/4802501/,2008 3rd International Design and Test Workshop,20-22 Dec. 2008,ieeexplore
10.1109/WSC.2018.8632446,DATA-CENTRIC CYBER-PHYSICAL SYSTEMS DESIGN WITH SMARTDATA,IEEE,Conferences,"Timeliness is a fundamental property of Cyber-Physical Systems that has been intensively investigated within the scope of real-time and critical systems. The advent of the Internet of Things, however, brings an intense communication flow between devices and the Internet. In this scenario, modeling time requirements in terms of data, rather than the tasks that manipulate them, may be advantageous as a data-centric design can promptly encompass other first-order requirements, such as geolocation, security, and trustworthiness. In this paper, we propose a strategy to design complex CPSs by modeling their data using the SmartData construct, which, besides encompassing means to handle the aforementioned requirements, also defines the concept of data expiry to guide scheduling decisions. With SmartData, local tasks are scheduled to produce the freshest data and to manipulate them before expiration. Likewise, network packets are scheduled prioritizing data whose expiry is close. We validate the strategy through simulations using Castalia.",https://ieeexplore.ieee.org/document/8632446/,2018 Winter Simulation Conference (WSC),9-12 Dec. 2018,ieeexplore
10.1049/cp.2012.1116,Design of real-time distributed system using DDS,IET,Conferences,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,https://ieeexplore.ieee.org/document/6492723/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
,Dr. BFS: Data Centric Breadth-First Search on FPGAs,IEEE,Conferences,"The flexible architectures of Field Programmable Gate Arrays (FPGAs) lend themselves to an array of data analytical applications, among which Breadth-First Search (BFS), due to its vital importance, draws particular attention. Recent attempts that omoad BFS on FPGAs either simply imitate the existing CPU- or Graphics Processing Units (GPU)based mechanisms or suffer from scalability issues. To this end, we introduce a novel data centric design which extensively extracts the potential of FPGAs for BFS with the following two techniques. First, we advocate to partition and compress the BFS algorithmic metadata in order to buffer them in fast on-chip memory and circumvent the expensive metadata access. Second, we propose a hierarchical coalescing method to improve the throughput of graph data access. Taken together, our evaluation demonstrates that the proposed design achieves, on average, 1.6× and 2.2× speedups over the state-of-the-art FPGA designs TorusBFS and Umuroglu, respectively, across a collection of graph datasets.",https://ieeexplore.ieee.org/document/8806902/,2019 56th ACM/IEEE Design Automation Conference (DAC),2-6 June 2019,ieeexplore
10.1109/HotICN50779.2020.9350821,Hierarchical Identity-Based Security Mechanism Using Blockchain in Named Data Networking,IEEE,Conferences,"Named Data Networking (NDN) with the data-centric design has been viewed as a promising future Internet architecture. It requires a new security model orienting data but not host. In this paper, a Hierarchical Identity-based Security Mechanism by Blockchain (HISM-B) is to be proposed for NDN networks. It could satisfy the two assumptions specified in the NDN testbed to maintain the data-oriented authentication. At one hand, the hierarchical identity-based cryptology is used to bind the data name with the public key and then two signatures are encapsulated in the data packet so that the data source authentication and the integrity of data packet can be supported. At the other hand, a blockchain is employed to manage public keys for different domains to avoid catastrophes due to a single node failure. The validation result shows that the proposed HISM-B is safe.",https://ieeexplore.ieee.org/document/9350821/,2020 3rd International Conference on Hot Information-Centric Networking (HotICN),12-14 Dec. 2020,ieeexplore
10.1109/BigData47090.2019.9006235,Hybrid 2D and 3D Visual Analytics of Network Simulation Data,IEEE,Conferences,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,https://ieeexplore.ieee.org/document/9006235/,2019 IEEE International Conference on Big Data (Big Data),9-12 Dec. 2019,ieeexplore
10.1109/ISQED.2003.1194734,Interoperability beyond design: sharing knowledge between design and manufacturing,IEEE,Conferences,"The nature of IC design is necessarily evolving to a more data-centric design flow in which EDA tools share a common information in a design database without the negative cost and quality impacts of data translation from sequential files. In support of this new paradigm, a collection of mainstream companies within the IC supply chain have sponsored the development of an open industry data model and application program interface for IC design tools, along with a database that fully implements this. This technology, called OpenAccess, is now available and being adopted by the IC design community. Another industry effort is in operation with the goal of greatly improving the cost and efficiency for IC photomasks. That effort is exploring a new paradigm similar in nature to OpenAccess in that a common data model and data access language is proposed. This data model would span both the design and mask-making communities, and possibly expand into wafer fabrication over time. Thus, it has become known as the Universal Data Model (UDM). This paper discusses some of the rationale for the UDM and highlights the attributes of the OpenAccess technology that make it the ideal base on which to build an open industry UDM.",https://ieeexplore.ieee.org/document/1194734/,"Fourth International Symposium on Quality Electronic Design, 2003. Proceedings.",24-26 March 2003,ieeexplore
10.1109/SEARIS44442.2018.9180229,Realtime Interactive Hybrid 2D and 3D Visual Analytics on Large High Resolution Display and Immersive Virtual Environment,IEEE,Conferences,We present a data-flow-oriented scalable and extensible visualization system for supporting hybrid 2D and 3D visual analytics. Our application allows users to visually analyze the results of a complex multivariate Monte Carlo simulation. The simulation outputs variables describing various properties of 3D objects interacting in a dynamic 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the 3D simulation in a virtual environment showing the time-varying results of the dynamics in a 3D environment. The Unity application runs on both a 2D high resolution display system and a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the 2D and 3D visualization components. Preliminary results show our data-centric design provides a user-centric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,https://ieeexplore.ieee.org/document/9180229/,2018 IEEE 11th Workshop on Software Engineering and Architectures for Real-time Interactive Systems (SEARIS),19-19 March 2018,ieeexplore
10.1109/ICCWorkshops49005.2020.9145301,Supporting Delay Tolerant Networking: A Comparative Study of Epidemic Routing and NDN,IEEE,Conferences,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",https://ieeexplore.ieee.org/document/9145301/,2020 IEEE International Conference on Communications Workshops (ICC Workshops),7-11 June 2020,ieeexplore
10.1109/ICDEW.2016.7495633,Towards a distributed multi-tier file system for cluster computing,IEEE,Conferences,"Distributed storage systems running on clusters of commodity hardware are challenged by the ever-growing data storage and I/O demands of modern large-scale data analytics. A promising trend is to exploit the recent improvements in memory, storage media, and network technologies for sustaining high performance at low cost. While recent work explores using memory and SSDs as a cache for local storage or combining local with network-attached storage, no work has ever looked at all layers together in a distributed setting. We present a novel design for a distributed file system that is aware of heterogeneous storage media (e.g., memory, SSDs, HDDs, NAS) with different capacities and performance characteristics. The storage media are explicitly exposed to users and applications, allowing them to choose the distribution and placement of replicas in the cluster based on their own performance and fault tolerance requirements. At the same time, the system offers a variety of pluggable policies for automating data management for increased performance and better cluster utilization. We analyze the new trends and challenges that led to our application- and data-centric design choices, and discuss how those choices inspire new research opportunities for data-intensive processing systems.",https://ieeexplore.ieee.org/document/7495633/,2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW),16-20 May 2016,ieeexplore
10.1109/CSCWD.2006.253098,Universal data model platform: the data-centric evolution for system level codesign,IEEE,Conferences,"The rapidly increasing complexity of integrated circuit design is evolving to a more data-centric design scenario that supports sharing of design information. This paper presents the concepts of universal data model platform (UDMP) which introduce the data-centric design revolution into the domain of system level design to support better cooperation of individual steps in electronic design automation (EDA) industry. The goal of UDMP is to provide a set of universal data models which enables wide variety of codesign tools to be integrated tightly and revitalizes the connection between universities and the EDA industry. Furthermore, an application programming interface (API) takes the place of traditional low-bandwidth file formats to provide access to the internal data models, thus improves efficiency of design iteration. The well-constructed structure of UDMP brings some challenges for the architects as well as current system level researchers and designers. The concepts of UDMP are applied to a simplified interface synthesis flow which contains three algorithms. Primary experiment results show that these algorithms are simplified with a running time reduction by about 10% for selected designs",https://ieeexplore.ieee.org/document/4019134/,2006 10th International Conference on Computer Supported Cooperative Work in Design,3-5 May 2006,ieeexplore
