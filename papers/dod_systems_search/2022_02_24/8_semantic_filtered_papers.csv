doi,url,database,title,abstract,publisher,publication_date,domain,id,type,status
5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,https://www.semanticscholar.org/paper/5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,semantic_scholar,application design over named data networking with its features in mind,"Designed around host-reachability, today’s Internet architecture faces many limitations while serving data-oriented applications, which produce most traffic load to the Internet. Many clean-slate designs of the content/data oriented network have emerged to adapt to these needs. Named Data Networking (also known as CCN) is one of these designs to address these limitations from the fundamental level by building network architecture around named data. In this paper, we identify five key features crucial to application design over Named Data Networking and take the voice conference system as an example to show how this features impact the application design significantly in detail. We identify three major challenges facing current voice conference system and illustrate how NDN could help to solve these challenges. A NDN-based design of voice conference system is presented along with discussing its reliability and congestion control. Keywords-Named Data Networking; Application Design;",ICON 2012,2012,citation,1,to_check,included
bdd38349d22ab12ddd44a500d5720853ee17286b,https://www.semanticscholar.org/paper/bdd38349d22ab12ddd44a500d5720853ee17286b,semantic_scholar,traffic engineering for information-centric networks,"Information-centric networking (ICN) proposes a networking architecture that uses methodologies such as publish-subscribe to achieve a data-oriented approach as opposed to a destination based approach found in the current Internet. This new architecture brings both new problems to be solved and also natural solutions to existing problems. This paper investigates an intra-domain traffic engineering (TE) problem for an information-centric networking (ICN) architecture where a form of source routing is used as the forwarding mechanism. The TE goal is to maximise the residual capacity in the network so that the load is spread evenly. A network flow approach is used and it is shown that the source routing mechanism allows the traffic to be split across multiple paths in a manner that is difficult to achieve using existing IP or IP/MPLS networks. Allowing splittable flows means that a fully polynomial-time approximation scheme can be used that has superior results when compared to existing constraint based routing schemes for flows that cannot be split. Consequently, this work demonstrates that the ICN architecture can simplify the given TE problem in a natural manner.",2012 IEEE International Conference on Communications (ICC),2012,citation,2,to_check,included
5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,https://www.semanticscholar.org/paper/5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,semantic_scholar,a survey of information-centric networking (draft),"In this paper we compare and discuss some of the features and design choices 
of the 4WARD Networking of Information architecture (NetInf), PARC's Content Centric Networking(CCN), the Publish-Subscribe Internet Routing Paradigm (PSIRP), and the Data Oriented Network Architecture (DONA). All four projects take an information-centric approach to designing a future network architecture, where the information objects themselves are the primary focus rather than the network nodes.",Information-Centric Networking,2010,citation,3,to_check,included
a312fd2a6feffb5bd907a08548a359f071b1e2fe,https://www.semanticscholar.org/paper/a312fd2a6feffb5bd907a08548a359f071b1e2fe,semantic_scholar,lipsin: line speed publish/subscribe inter-networking,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.
 In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.",SIGCOMM '09,2009,citation,4,to_check,included
8859ac6c40996bad1c2b74ba97fe81fcede7181f,https://www.semanticscholar.org/paper/8859ac6c40996bad1c2b74ba97fe81fcede7181f,semantic_scholar,performance comparison of content-oriented networking alternatives : a hierarchical tree versus a flat distributed hash table,"The internet was designed with host-oriented networking applications such as file transfer and remote login. However, recent internet statistics show that content-oriented traffic (e.g. web pages, multimedia clips) becomes more and more dominant. Even though content-oriented networking has received increasing attention, there have been few comprehensive and quantitative studies on how to realize a content-oriented networking framework. In this paper, we focus on the operational issues of the new networking framework: (i) how to locate contents, (ii) how to deliver contents, and (iii) how to cache contents. There are two major infrastructure alternatives in substantiating these mechanisms: a tree and a distributed hash table (DHT). We carry out comprehensive simulation experiments to compare these alternatives in terms of content transfer latency, cache effectiveness, and failure resilience. I. I NTRODUCTION The Internet has evolved from a small-scale academic testbed into a crucial social infrastructure. For 40 years since its inception, the Internet has tried to accommodate new and unanticipated requirements. However, its rigid design based on TCP/IP, internet service providers’ exclusive control of networks and so on have ossified the Internet [6]. One of the Internet design principles that hinders the current Internet evolution is the host-oriented communications. That is, the early stage Internet applications, such as remote login, file transfer, and e-mail, focused strictly on host-to-host communications, where an end user explicitly directs his/her host to communicate with another host. Over the past several years, however, the vast majority of Internet usage has become data retrieval and service access [23], [3], [16] (i.e.,data-orientedusage), where an end user cares about contents 1 but is oblivious to or less aware of the host (or its location) [16]. For example, (i) many people often use search engines like Google from which they jump to the data or service page irrespective of the location in which the desired data/service resides, (ii) web intermediaries such as web caches and content delivery networks (CDNs) [18] transparently redirect web clients to a nearby copy of the requested data without contacting the original Web server, and (iii) peer-to-peer (P2P) applications enable users to search and 1In this paper, we use “data” and “contents” almost interchangeably. In the literature, “contents” often have more semantics than “data”. retrieve the data without making them know the location or identity of the host. The common viable contribution of search engines, web caching, CDNs, and P2P applications is that they all seek to support data-oriented applications. They improve the data availability, ease-of-use, performance, and scalability of applications by overcoming the limitations of the host-oriented principles of the legacy Internet by manipulating DNS naming and/or name resolution. In other words, they decouple content files from their locations (or hosts) using various techniques such as caching, replication with transparent request redirection, maintenance of a searching infrastructure, etc. [16]. Recently, lessons from these several application/servicedependent ad-hoc solutions, have motivated “clean-slate” efforts [1], [16], [10], termed data-oriented or content-centric networking, which strive to redesign the host-oriented Internet to accommodate more and more dominant data-oriented Internet usage at the architectural level. The essence of contentoriented networking lies in decoupling contents from the service host/location not at application levels, but at networking levels. That is, content-oriented networking shifts the focus from transmitting data between two hosts (or their locations) to delivering data via a content identifier 2. The content-oriented networking architecture is expected to (i) free application/service developers from re-inventing the necessary mechanisms, and (ii) provide scalable and efficient delivery of the requested contents. However, there have been few studies that how to substantiate the content-oriented networking infrastructure in terms of performance metrics. In order to address the operational issues that are missing in the recent architectural studies on content-oriented networking in the literature, this paper explores two alternatives for content-oriented network infrastructures: a hierarchical tree and a flat distributed hash table (DHT). Whether we choose a tree or a DHT for the infrastructure affects almost every aspect of network operations: name resolution, content delivery, caching, and so on. We will compare these two alternatives in terms of scalability, robustness, transfer latency thoroughly. 2As an example, the Data-Oriented Network Architecture (DONA) [16] r places endpoint-based DNS by a new name resolution mechanism using flat, certifying names and name-based anycast primitives above the IP layer.",,2008,citation,5,to_check,included
585b18385db6eb806e207b797ae7262143b9bd28,https://www.semanticscholar.org/paper/585b18385db6eb806e207b797ae7262143b9bd28,semantic_scholar,data-oriented architecture of sine and cosine functions,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),2010,citation,6,to_check,included
7f7553beefdf3579a6759b97ef41948c1fc79c57,https://www.semanticscholar.org/paper/7f7553beefdf3579a6759b97ef41948c1fc79c57,semantic_scholar,a data-oriented architecture for loosely coupled real-time information systems,"In this paper, we present an architectural pattern called Data Oriented Architecture (DOA). Motivation is the fact that on the one hand we face a shift to the usage of more and more mobile devices but on the other hand most services in the Internet still use a classic client-server-approach. Data is mainly produced at private devices today and put on centralized servers afterwards. This situation reflects the actual reality better: data is shared directly among users without the need of centralized sources. Three key facts distinguish DOA from existing approaches: First, DOA does not bind data to a specific location. Data is defined by the application which produced it and not an address of a location where it is currently stored. Second, DOA is a holistic approach that comprises a suitable data structure, data access methods and a message exchange protocol. Thus, DOA can be easily implemented and used right away. Third, in DOA, users can decide which data they want to keep private and which data they want to share. Shared data becomes a ""public good"" that is not owned by a specific entity but belongs to the community.",iiWAS,2017,citation,7,to_check,included
045c7665e95ae9f0dbdac771ca307c5427ab6426,https://www.semanticscholar.org/paper/045c7665e95ae9f0dbdac771ca307c5427ab6426,semantic_scholar,data-oriented architecture of ln function,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",2010 2nd International Conference on Advanced Computer Control,2010,citation,8,to_check,included
442567e7d47373f6d305a249b7ae05b81d15782e,https://www.semanticscholar.org/paper/442567e7d47373f6d305a249b7ae05b81d15782e,semantic_scholar,consideration and research on data architecture for the future cyber society,"The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",2019,citation,9,to_check,included
4784c2c7418311172150b606b87c71d24ea12e5b,https://www.semanticscholar.org/paper/4784c2c7418311172150b606b87c71d24ea12e5b,semantic_scholar,enhanced forwarding strategies in information centric networking,"Network use has evolved over time to be dominated by content distribution and retrieval, while networking technology is mainly concerned with connections between named hosts. Accessing contents and services require the mapping of what users care about to where the content is located. Information Centric Networking (ICN) is a new paradigm in networking and a future Internet architecture which treats content as the primitive decoupling location from identity, security and access to retrieve content by name. Together with built-in capabilities for caching content, multi-path communications, disruption tolerance and security, ICN is able to leverage advancements in technology to address the issues associated with the mismatch between today’s network use and network architecture. There are a number of ICN architectures, viz., Network of Information (NetInf), Publish-Subscribe Internet Routing Paradigm (PSIRP), Data Oriented Network Architecture (DONA) and Content Centric Networking (CCN) being developed by researchers worldwide with the ultimate focus of replacing the current Internet. CCN, a ""Clean Slate"" architecture to ICN, uses new approaches to routing named content, achieving scalability, security and performance. Most computing devices of today (user devices as well as in the core network) are equipped with multiple networking interfaces and hence, have the ability to use multiple paths within or over different networks. The widest possible experience in using multi-path is mostly available in Internet Protocol (TCP/IP) based networks and the research done shows that multi-path routing can achieve robustness, load balancing, congestion reduction, low power consumption, and higher throughput. CCN, which has built-in capabilities to handle multiple networking attachments proposes two forwarding strategies, viz., the standard strategy which replicates network traffic into multiple paths and the best-face strategy which uses the discovered multiple paths one at a time, alternatively. However, these forwarding strategies do not exploit the full potential of CCN, especially the multi-path capability to improve performance in CCN based networks. The main objective of this thesis therefore, is to identify a set of mechanisms that capitalize on the multipath capability of CCN to improve the overall performance of user applications and the deployed networks.",,2015,citation,10,to_check,not included
2627cdd58ecc81e6176de44724a26ae1bec6b273,https://www.semanticscholar.org/paper/2627cdd58ecc81e6176de44724a26ae1bec6b273,semantic_scholar,energy-aware data management on numa architectures,"The ever-increasing need for more computing and data processing power demands for a continuous and rapid growth of power-hungry data center capacities all over the world. As a first study in 2008 revealed, energy consumption of such data centers is becoming a critical problem, since their power consumption is about to double every 5 years. However, a recently (2016) released follow-up study points out that this threatening trend was dramatically throttled within the past years, due to the increased energy efficiency actions taken by data center operators. Furthermore, the authors of the study emphasize that making and keeping data centers energy-efficient is a continuous task, because more and more computing power is demanded from the same or an even lower energy budget, and that this threatening energy consumption trend will resume as soon as energy efficiency research efforts and its market adoption are reduced. An important class of applications running in data centers are data management systems, which are a fundamental component of nearly every application stack. While those systems were traditionally designed as disk-based databases that are optimized for keeping disk accesses as low a possible, modern state-of-the-art database systems are main memory-centric and store the entire data pool in the main memory, which replaces the disk as main bottleneck. To scale up such in-memory database systems, non-uniform memory access (NUMA) hardware architectures are employed that face a decreased bandwidth and an increased latency when accessing remote memory compared to the local memory. In this thesis, we investigate energy awareness aspects of large scale-up NUMA systems in the context of in-memory data management systems. To do so, we pick up the idea of a fine-grained data-oriented architecture and improve the concept in a way that it keeps pace with increased absolute performance numbers of a pure in-memory DBMS and scales up on NUMA systems in the large scale. To achieve this goal, we design and build ERIS, the first scale-up in-memory data management system that is designed from scratch to implement a data-oriented architecture. With the help of the ERIS platform, we explore our novel core concept for energy awareness, which is Energy Awareness by Adaptivity. The concept describes that software and especially database systems have to quickly respond to environmental changes (i.e., workload changes) by adapting themselves to enter a state of low energy consumption. We present the hierarchically organized Energy-Control Loop (ECL), which is a reactive control loop and provides two concrete implementations of our Energy Awareness by Adaptivity concept, namely the hardware-centric Resource Adaptivity and the software-centric Storage Adaptivity. Finally, we will give an exhaustive evaluation regarding the scalability of ERIS as well as our adaptivity facilities.",,2017,citation,11,to_check,not included
5cefcd5ead9e05871710d75da2d1db75ba9a33bf,https://www.semanticscholar.org/paper/5cefcd5ead9e05871710d75da2d1db75ba9a33bf,semantic_scholar,satellite network architecture design based on sdn and icn technology,"In order to solve the problems of traditional integrated space-terrestrial network control and service deployment complexity and large request delay of streaming media data such as video in big data environment, this paper proposes ContentSDSN architecture. By introducing the idea of SDN and ICN, on the one hand, SDN framework is used to simplify the control of the integrated space-terrestrial network and improve the efficiency of network service deployment; on the other hand, by using of the inherent request aggregation and data distribution capabilities of network forwarding nodes, as well as the forwarding node has high sensitivity to content and optional cache features, in order to achieve the overall performance of the integrated space-terrestrial network upgrade. The simulation results show that ContentSDSN architecture has the advantages of flexible network control and small request delay compared with the integrated space-terrestrial network architecture.",2018 8th International Conference on Electronics Information and Emergency Communication (ICEIEC),2018,citation,12,to_check,included
116a89b6aeb5c99a19ca75b88a93748cd73da5b2,https://www.semanticscholar.org/paper/116a89b6aeb5c99a19ca75b88a93748cd73da5b2,semantic_scholar,an aggregatable name-based routing for energy-efficient data sharing in big data era,"Big data strongly demands a network infrastructure having the capability to efficiently collect, process, cache, share, and deliver the data, instead of simple transmissions. Such network designs show the requirements of energy efficiency, availability, high performance, and data-aware intelligence. To meet these requirements, we adopt the information-centric networking (ICN) approach, where data are retrieved through names and in-network caching is utilized. However, as the typical existing ICN architectures, content centric network (CCN) cannot efficiently utilize the caches for data sharing because of the on-path caching strategy, and network of information (NetInf) demonstrates the resolution latency for data retrievals. To design an efficient and effective ICN architecture for big data sharing, we combine the strong points of CCN and NetInf, where information islands (IOIs) and management plane are utilized for direct data retrieval and global data discovery, respectively. We provide a reference architecture and propose an aggregatable name-based routing (ANBR), which can naturally enable consumers to retrieve the closest copy of information. In this network, each piece of data can be cached at one IOI at most once, which greatly improves the efficiency of cache usages. The consumers first try to retrieve the data in the local IOI, and then try to globally retrieve it from the closest IOI, holding the copy of the data if necessary. We investigate the impact from the key factor, IOI size, to the energy consumption of ANBR. It shows that energy consumption first decreases and then increases as the IOI size increases, and the optimized IOI size can be found for deployment. Furthermore, we study the relation between the optimized IOI size and the average retrieval times for the data. The result shows that the optimized IOI size increases as the average retrieval times increase.",IEEE Access,2015,citation,13,to_check,included
63ee066ff5bb3fca0cd924e8ebeff84a1d308fad,https://www.semanticscholar.org/paper/63ee066ff5bb3fca0cd924e8ebeff84a1d308fad,semantic_scholar,topology-based data dissemination approaches for large scale data centric networking architecture,"Massive information flows are generated from interactive processing and visualizations. To efficiently support information transmission over the Internet, information centric architecture has been recently proposed. In this paper, we consider an information centric architecture, called the data centric networking architecture to provide communication services to big data, where a service identifier is used to name the data objects. We propose different approaches for the dissemination of data objects in a large-scale data centric network. In particular, we propose various approaches to link the data dissemination approach with the topology of the Internet. Further, we evaluate the proposed approaches with respect to data delivery efficiency, round-trip time improvement, and deployment cost. Based on the results obtained from this study, it can be shown that by disseminating data objects to small ISPs, the data delivery efficiency can be significantly improved within an acceptable deployment cost.",China Communications,2013,citation,14,to_check,not included
5045fb290a1ab454ef18d1ab3ae1444712739529,https://www.semanticscholar.org/paper/5045fb290a1ab454ef18d1ab3ae1444712739529,semantic_scholar,towards a service-oriented architecture for the energy efficiency of buildings: a systematic review,"Currently, smart buildings generate large amounts of data due to the many devices and equipment available. Hence, buildings implement building management systems (BMSs), which monitor, control, manage and analyze each of these components. However, current BMSs are incapable of managing a massive amount of data (big data) and therefore cannot extract knowledge or make intelligent decisions in quasi real time. In addition, there are serious limitations to integrating BMSs with other services since they generally use proprietary software. In this sense, service-oriented architecture (SOA) is an architectural style that allows one to build distributed systems and provide functionalities such as services to end users or other types of services. Therefore, an SOA has the great advantage of allowing the expansion of the functionalities of BMSs. In fact, there are several studies that address SOAs for building management. However, we have not found any description or systematic analysis in the literature that allows the development of a versatile and interoperable SOA focused on the energy efficiency of buildings and that can integrate massive data analysis features. For these reasons, this study seeks to fill this knowledge gap and, more specifically, to identify and analyze the various software requirements proposed in the literature and the characteristics of big data that allow for improving the energy efficiency of buildings. To this end, we performed an in-depth review of the literature according to the methodology proposed by Kitchenham. As a result of this review, we provide researchers with a specific vision of the requirements and characteristics to consider for software development aimed at the energy efficiency of unique or historic buildings.",IEEE Access,2021,citation,15,to_check,not included
b0e3120aa51446006c5bfe53dc1ad4a66f4768af,https://www.semanticscholar.org/paper/b0e3120aa51446006c5bfe53dc1ad4a66f4768af,semantic_scholar,medical prognosis of infectious diseases in nursing homes by applying machine learning on clinical data collected in cloud microservices,"Background: treating infectious diseases in elderly individuals is difficult; patient referral to emergency services often occurs, since the elderly tend to arrive at consultations with advanced, serious symptoms. Aim: it was hypothesized that anticipating an infectious disease diagnosis by a few days could significantly improve a patient’s well-being and reduce the burden on emergency health system services. Methods: vital signs from residents were taken daily and transferred to a database in the cloud. Classifiers were used to recognize patterns in the spatial domain process of the collected data. Doctors reported their diagnoses when any disease presented. A flexible microservice architecture provided access and functionality to the system. Results: combining two different domains, health and technology, is not easy, but the results are encouraging. The classifiers reported good results; the system has been well accepted by medical personnel and is proving to be cost-effective and a good solution to service disadvantaged areas. In this context, this research found the importance of certain clinical variables in the identification of infectious diseases. Conclusions: this work explores how to apply mobile communications, cloud services, and machine learning technology, in order to provide efficient tools for medical staff in nursing homes. The scalable architecture can be extended to big data applications that may extract valuable knowledge patterns for medical research.",International Journal of Environmental Research and Public Health,2021,citation,16,to_check,not included
2d89fa83d6e68d0f9b8914a65778c65b2cf03d3c,https://www.semanticscholar.org/paper/2d89fa83d6e68d0f9b8914a65778c65b2cf03d3c,semantic_scholar,cost-effective vital signs collecting system based on fast biosensors and a flexible cloud microservices architecture for the prognosis of infectious diseases (preprint),"
 BACKGROUND
 Quite often, patients arrive to consultation when the symptoms of an infectious disease are already serious, forcing doctors to divert them to the emergency services. Particularly, the possible anticipation of the diagnosis -prognostic- for institutionalized people would lead to soften the treatment, increasing resident’s wellness and alleviating the degradation of the emergency services. Big data, mobile communications, cloud services or machine learning technologies applied in medicine -e-Health- assist practitioners with efficient tools.
 
 
 OBJECTIVE
 This article describes a new data collection system for predicting infectious diseases in elderly people, supporting future telecare and medical recommender applications.
 
 
 METHODS
 The system provides a medical database updated with vital signs that nurses take with medical sensors from residents. The Cloud database is accessible with a flexible microservices software architecture.
 
 
 RESULTS
 The e-Health system components are cost-effective, leading to massive implementations for servicing disadvantaged areas. The scalable architecture is prepared for big data applications that may extract valuable knowledge patterns for medical research.
 
 
 CONCLUSIONS
 The innovation relies in the combination of advanced e-Health technologies and procedures that delivers ubiquitously available quality data to provide multifaceted scalable low-cost applications to improve resident’s wealth and release public health care services.
",,2019,citation,17,to_check,not included
355f2e5901d31fe22594bf1d8cecead117212c40,https://www.semanticscholar.org/paper/355f2e5901d31fe22594bf1d8cecead117212c40,semantic_scholar,api deployment for big data management towards sustainable energy prosumption in smart cities-a layered architecture perspective,"ABSTRACT The smart city has emerged as a universal term for the pervasive utilisation of information and communication technologies deployed to provide value-added services to citizens based on data generated from sectors such as energy, mobility, etc. However, current approaches are faced with interoperability as a challenging issue in processing big data. Therefore, this study explores the role of application programming interfaces (APIs) for managing real-time, online, and historical energy data in the context of residential buildings and electric vehicles. Moreover, a layered architecture that employs APIs in big data is developed for district energy management towards providing energy information intelligence and support decision-making on energy sustainability in facilitating prosumption operations. Practically, the layered architecture collects energy data and provides data to prosumers who are citizens that produce, consume, share, and sell energy generated from renewable sources such as solar and wind to better improve energy prosumption in smart grid.",International Journal of Sustainable Energy,2020,citation,18,to_check,not included
ee4488c2b59bbddd571e7657309b27ebe64d1d6a,https://www.semanticscholar.org/paper/ee4488c2b59bbddd571e7657309b27ebe64d1d6a,semantic_scholar,big data-oriented energy prosumption service in smart community districts: a multi-case study perspective,"The smart grid achieves bidirectional information and energy flow between energy consumer and utility grid, aiding energy users not only to utilize energy, but also to produce, sell, and share energy with other consumers or with the utility grid. This type of energy user is referred to as the “prosumer”. Thus, prosumer management structures are important within energy market. However, prior studies on energy sustainability has paid little attention on prosumer involvement and management. Likewise, the continuous growth of cities has increased data processing complexity. Consequently, processing and analysis of historical, online, and real-time streaming data from energy sensors and metering devices has become a major issue in smart cities. Therefore, this research aims to present an architecture based on big data to improve energy prosumption in smart community districts by applying enterprise architecture approach grounded on The Open Group Architecture Framework (TOGAF). Accordingly, qualitative methodology is adopted to collect data by employing case study by focus group interview from two energy companies in Norway to preliminarily validate the architecture. Findings from the case studies was demonstrated in ArchiMate modeling language to evaluate the applicability of the architecture. Moreover, findings from this study provides practical scenario that energy service providers can refer to in designing their own energy data platforms. Essentially, the architecture can be utilized as a guide to help municipalities and policy makers in creating approach for energy data analytics in smart community districts towards making decisions for future energy prosumption planning.",Energy Inform.,2019,citation,19,to_check,included
93897f6f3f30ca3029ca7ed86892eefde373d816,https://www.semanticscholar.org/paper/93897f6f3f30ca3029ca7ed86892eefde373d816,semantic_scholar,enabling global big data computations,"Most analytics projects focus on the management of the 3Vs of big data and use specific stacks to support this variety. However, they constrain themselves to “local” data, data that exists within or “close” to the organization, or external data imported to local systems. And yet, as it has been recently pointed out, “the value of data explodes when it can be linked with other data.” In this paper we present our vision for a global marketplace of analytics—either in the form of per-entity metrics or per-entity data, provided by globally accessible data management tasks— where a data scientist can pick and combine data at will in her data mining algorithms, possibly combining with her own data. The main idea is to use the dataframe, a popular data structure in R and Python. Currently, the columns of a dataframe contain computations or data found within the data infrastructure of the organization. We propose to extend the concept of a column. A column is now a collection of key-value pairs, produced anywhere by a remotely accessed program (e.g., an SQL query, a MapReduce job, even a continuous query.) The key is used for the outer join with the existing dataframe, the value is the content of the column. This whole process should be orchestrated by a set of well-defined, standardized APIs. We argue that the proposed architecture presents numerous challenges and could be beneficial for big data interoperability. In addition, it can be used to build mediation systems involving local or global columns. Columns correspond to attributes of entities, where the primary key of the entity is the key of the involved columns.",DOLAP,2018,citation,20,to_check,not included
261746995b755658f33eb65d33e45fd11dce56e2,https://www.semanticscholar.org/paper/261746995b755658f33eb65d33e45fd11dce56e2,semantic_scholar,the data management entity: a simple abstraction to facilitate big data systems interoperability,"big data era is described by intense variety in data management systems, query languages and programming paradigms. Each system targets well a specific application area, reinforcing the belief that the era of one-size fits all has gone. Interoperability, systems' connectivity and high-level data models become once again the core of research initiatives. In this paper we present our vision for a layered architecture to support interoperability among different data management systems, generalized under the term data management entities (DMEs). DMEs range from JVMs running java programs to Hadoop systems employing complex MapReduce jobs to traditional RDBMS running SQL queries to stream engines and CEP scripts. The top layer consists of a universe of DMEs, communicating through a well defined http-like protocol: a DME transparently invokes another DME's data manipulation task, regardless task's nature. Communicating DMEs share/operate on a shared data object, a key-value set (KVS) - just a set of key-value pairs - which exists in the layer below and is referenced through a unique (internet-wide) address via a well-defined API. This layer serves as the transient common memory space for communicating DMEs and consists of globally addressable KVSs, organized in domains, sub-domains, etc. In a way, this approach constitutes a form of remote procedure call by reference (the KVS is the common reference). We argue that this architecture allows the construction of high level query languages and cost-based distributed query processing engines, involving completely heterogeneous data manipulation tasks. For example, we show that MapReduce evaluation algorithm and distributed relational query processing are just instances of the proposed architecture. We also claim that it can easily facilitate the end-to-end processing in big data applications, an established goal in the research agenda set by the Beckman report.",EDBT/ICDT Workshops,2016,citation,21,to_check,not included
48a27b7f2dff8a148e4a6ed18eefe024f0edc55c,https://www.semanticscholar.org/paper/48a27b7f2dff8a148e4a6ed18eefe024f0edc55c,semantic_scholar,applying security to a big stream cloud architecture for the internet of things,"The Internet of Things IoT is expected to interconnect billions around 50 by 2020 of heterogeneous sensor/actuator-equipped devices denoted as ""Smart Objects"" SOs, characterized by constrained resources in terms of memory, processing, and communication reliability. Several IoT applications have real-time and low-latency requirements and must rely on architectures specifically designed to manage gigantic streams of information in terms of number of data sources and transmission data rate. We refer to ""Big Stream"" as the paradigm which best fits the selected IoT scenario, in contrast to the traditional ""Big Data"" concept, which does not consider real-time constraints. Moreover, there are many security concerns related to IoT devices and to the Cloud. In this paper, we analyze security aspects in a novel Cloud architecture for Big Stream applications, which efficiently handles Big Stream data through a Graph-based platform and delivers processed data to consumers, with low latency. The authors detail each module defined in the system architecture, describing all refinements required to make the platform able to secure large data streams. An experimentation is also conducted in order to evaluate the performance of the proposed architecture when integrating security mechanisms.",Int. J. Distributed Syst. Technol.,2016,citation,22,to_check,included
ad280d4e5f7fc42cc792d5b4a7cd7d63abb39fcc,https://www.semanticscholar.org/paper/ad280d4e5f7fc42cc792d5b4a7cd7d63abb39fcc,semantic_scholar,information-centric iot middleware overlay: vsl,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",2019 International Conference on Networked Systems (NetSys),2019,citation,23,to_check,included
998285364a6d51cc6ba089993c30197a006423d2,https://www.semanticscholar.org/paper/998285364a6d51cc6ba089993c30197a006423d2,semantic_scholar,the use of computational intelligence for security in named data networking,"Information-Centric Networking (ICN) has recently been considered as a promising paradigm for the next-generation Internet, shifting from the sender-driven end-to-end communication paradigma to a receiver-driven content retrieval paradigm. In ICN, content -rather than hosts, like in IP-based design- plays the central role in the communications. This change from host-centric to content-centric has several significant advantages such as network load reduction, low dissemination latency, scalability, etc. One of the main design requirements for the ICN architectures -since the beginning of their design- has been strong security. 
Named Data Networking (NDN) (also referred to as Content-Centric Networking (CCN) or Data-Centric Networking (DCN)) is one of these architectures that are the focus of an ongoing research effort that aims to become the way Internet will operate in the future. Existing research into security of NDN is at an early stage and many designs are still incomplete. To make NDN a fully working system at Internet scale, there are still many missing pieces to be filled in. In this dissertation, we study the four most important security issues in NDN in order to defense against new forms of -potentially unknown- attacks, ensure privacy, achieve high availability, and block malicious network traffics belonging to attackers or at least limit their effectiveness, i.e., anomaly detection, DoS/DDoS attacks, congestion control, and cache pollution attacks. In order to protect NDN infrastructure, we need flexible, adaptable and robust defense systems which can make intelligent -and real-time- decisions to enable network entities to behave in an adaptive and intelligent manner. In this context, the characteristics of Computational Intelligence (CI) methods such as adaption, fault tolerance, high computational speed and error resilient against noisy information, make them suitable to be applied to the problem of NDN security, which can highlight promising new research directions. Hence, we suggest new hybrid CI-based methods to make NDN a more reliable and viable architecture for the future Internet.",,2015,citation,24,to_check,not included
b24f6f73476ee73b601763ef64c4654b22949946,https://www.semanticscholar.org/paper/b24f6f73476ee73b601763ef64c4654b22949946,semantic_scholar,energy efficient and enhanced-type data-centric network architecture,"Information-centric networking (ICN) as an alternative has been researched for future Internet architecture. In this paper, a novel network architecture called Energy Efficient and Enhanced-type Data-centric Network (E 3 -DCN) is proposed for ICN. E 3 -DCN not only realizes ICN but also has the ability of data generation by organizing and combining relevant resource such as original data and kinds of processing services. In addition, in order to improve energy efficiency of data transmission, E 3 -DCN chooses optimal transmission path to transmit data based on packet switching and optical switching. Moreover, based on current traffic situation, E 3 -DCN reconfigures network topology such as unused nodes and links to operate in sleep mode for energy saving dynamically. And meanwhile, data caching strategies are applied into E 3 -DCN for data distribution based on the distribution of users. Data caching shortens transmission distance, so data transmission energy, latency and network load is decreased. Based on these approaches, E 3 -DCN achieves an energy efficient network.",,2015,citation,25,to_check,included
d3f73e7cd304551750db38db67863799ed93f7a0,https://www.semanticscholar.org/paper/d3f73e7cd304551750db38db67863799ed93f7a0,semantic_scholar,an incrementally deployable data centric architechture using particle swarm optimization algorithm,"Today’s Internet users are majorly interested in accessing data only from server i.e. interested in data networks instead of host networks. But the current Internet architectures are host centric network and it is not practically possible to deploy a pure data-centric architecture. Therefore this paper describes such architecture which is future proof DCNA for Internet which is incrementally deployable that supports both data centric and host centric services having features like multi-homing and mobility. Keywords:-Ad-hoc network, incrementally deployable, future proof. Keywords: Ad-hoc network, Dyanamic route guidance, future proof, incrementally deployable.",,2014,citation,26,to_check,included
517f56cf1ede34324c3b697aa16fb72a3d15457b,https://www.semanticscholar.org/paper/517f56cf1ede34324c3b697aa16fb72a3d15457b,semantic_scholar,"sedax: a scalable, resilient, and secure platform for smart grid communications","Smart Grid applications are imposing challenging requirements of security and reliability on the N-way communication infrastructure being designed to support multiple grid applications. These challenges stem from the increasing incorporation of distributed renewable energy sources on to the grid, the rising deployment of electric vehicles, and active consumer participation into power grid operations, all of which communicate with the utility control center with varying degrees of priority and security. To address these challenging requirements, we propose SeDAX, a SEcure Data-centric Application eXtensible platform for Smart Grid applications. SeDAX implements scalable, resilient and secure data delivery and data sharing in a wide area network. The platform can scalably handle high volumes of data generated by both applications and sensors. The SeDAX architecture has as its basis a Delaunay Triangulation (DT) network. The properties of the DT graph are leveraged to scalably support secure data-centric (or information-centric) group communication. The primary goals of this platform are to support communication resilience and data availability. The key functional blocks of the SeDAX platform are: (1) a geographic hash forwarding algorithm that operates over the DT graph (DT-GHF), and (2) a DT-based data replication scheme. The forwarding and replication schemes are scalable and cost effective in terms of communication overhead and memory. We describe the design details of the SeDAX platform and present empirical results on the performance of SeDAX as compared with other geometric-based alternatives such as Geographic Hash Table (GHT) forwarding and Content Addressable Networking (CAN). The operation of SeDAX is illustrated in the context of implementing demand response, a known Smart Grid application.",IEEE Journal on Selected Areas in Communications,2012,citation,27,to_check,included
a6a2935c5b9bb9fbd1f04febffa0d6d5f1219359,https://www.semanticscholar.org/paper/a6a2935c5b9bb9fbd1f04febffa0d6d5f1219359,semantic_scholar,data-centric network for highly distributed and mobile data distribution,"The conventional telephony networking was used mainly for communication between two terminals. However, recent network such as the Internet is mainly used for data distribution and access via the network. Recent research efforts are conducted to realize new network architecture that is optimized for this kind of communication, but it lacked in scalability when the data is added, moved, or updated. In this paper, we propose a new architecture called Data-centric Network (DCN) that allows scalable access to dynamic data in a widely distributed environment. Keyword Data-centric Network,Mobility 1. はじめに TCP/IP に代表される IP ネットワーク技術は,その 接続の容易性と構築・運用の低コスト性から,1990 年 代より急速に普及し,現在ではインターネット,企業 LAN,VPN,データセンタ,ホームネットワークなど で広く使われており,情報化社会を支える最も重要な ネットワーク技術の一つとなっている。 一方,近年では高度な信頼性の実現,IP ノードの消 費電力量増加への対策,ネットワーク管理コスト増加 への対策,エンド・エンドでの帯域確保など IP ネット ワーク技術では解決が難しい課題も顕在化し始めてい る。そこで日米欧では,2015 年から 2020 年あたりの 実現を見据えて,これらの課題の抜本的な対策を全く 白紙状態(Clean Slate)から検討する試みとして,新 世代ネットワークの研究が進められている。 [1][2][3] 新世代ネットワークの研究では 2006 年より各種技 術分野の抽出と絞り込みが進んでおり、現在は主要な 技術分野としてネットワーク仮想化 [4]とデータ指向 型ネットワーク [12][13][5]が注目されている。ネット ワーク仮想化は、新世代ネットワークの様々なアプリ ケーションやプロトコル( IP ではない新たなプロトコ ルを含む)の実験を行うテストベッドを実現する技術 として開発が行われている。一方、データ指向型ネッ トワークに関しても近年多方面でコンセプトレベルの 方式提案や実証実験が行われるようになっている。 2. M2M サービスの要件と提案アーキテクチャ 2.1. M2M サービスの要件 新世代ネットワークの要件としては、過去に NICT 研究開発戦略本部や研究プロジェクト(AKARI)によ って、特定のサービスを想定しない一般的な要件(大 容量、スケーラブル、オープン性など)が提言されて いる。 [1] 本研究ではこれらの要件を更に具体化するために、 サービスの一例として今後急速な普及が予想される M2M サービスを想定し、その要件を抽出した。  要件 1:端末(M2M 機器)の大量化、低価格化、 低機能化 500 億個以上の端末がネットワークに接続され、そ の大半がセンサなど低機能且つ低価格な端末とな るため、簡易なネットワーク接続方式や通信方式が 必要となる。  要件 2:端末やネットワークの移動、更新の容易化 端末の移動・移設(仮想サーバのマイグレーション を含む)や交換は最小限の設定だけで容易に実現で きることが必要となる。端末が接続されるネットワ ークもイーサネットと同等のネットワーク構成の 更新容易性が必要となる。  要件 3:データのダイナミックな変化への対応 M2M 機器が発信するデータはダイナミックに変化 し、データの追加・移動・更新・削除が頻繁且つ不 規則に発生する。データが利用されるタイミングの 予測は困難であり、センサの状態データのように一 時的に蓄積された後削除されるデータも多い。ネッ トワークはこのようなデータに逐次追随しつつア クセス可能とすることが必要となる。  要件 4:多対多通信 大量の端末が発信するデータを多数のサービスサ ーバが利用する多対多の通信が増加し、 unicast 以 外の通信形態(broadcast、multicast、publish/subscribe、 クエリ /key-value-store)が通信の大半を占めるよう になるため、ネットワークはこれらの通信形態をサ ポートする必要がある。 2.2. 提案アーキテクチャ 本研究では、前述の新世代ネットワークの要件に適 した新たなネットワークアーキテクチャとして、 Data-centric Network(DCN)を提案する。従来のネッ トワークは端末間のデータ通信を主目的としていた。 一方現在では、所望のデータを取得することがネット ワークの主目的となっている。DCN はこのようなネッ トワークの利用形態の変化を踏まえ、膨大な量のデー タから容易にデータを取得することができるネットワ ークアーキテクチャの実現を目指す。 図 1 に本研究で想定するネットワークアーキテク チャの変遷を示す。従来の PSTN が音声通話などの人 対人の通信が中心で、現在のインターネットが WEB などの人対モノの 1 対 1 通信が中心であるのに対し、 DCN は将来のセンサや機器同士が通信するモノ対モ ノの多対多通信に適したアーキテクチャを目指す。 DCN では端末は通信相手の端末を意識せずに、取得し たいデータの ID を指定するだけで通信を行う。 図 1 ネットワークアーキテクチャの遷移 2.1 章で挙げた要件に対し、現状の IP ネットワーク と将来求められる DCN の比較を表 1 に示す。 表 1 IP ネットワークと DCN の比較",,2012,citation,28,to_check,included
15f7d293a8e3cd621b16be0fabf1796505b0146f,https://www.semanticscholar.org/paper/15f7d293a8e3cd621b16be0fabf1796505b0146f,semantic_scholar,security design for an inter-domain publish/subscribe architecture,"Several new architectures have been recently proposed to replace the Internet Protocol Suite with a data-centric or publish/subscribe (pub/sub) network layer waist for the Internet. The clean-slate design makes it possible to take into account issues in the current Internet, such as unwanted traffic, from the start. If these new proposals are ever deployed as part of the public Internet as an essential building block of the infrastructure, they must be able to operate in a hostile environment, where a large number of users are assumed to collude against the network and other users. In this paper we present a security design through the network stack for a data-centric pub/sub architecture that achieves availability, information integrity, and allows application-specific security policies while remaining scalable. We analyse the solution and examine the minimal trust assumptions between the stakeholders in the system to guarantee the security properties advertised.",Future Internet Assembly,2011,citation,29,to_check,included
3502f23932655f3f8b2b995926a5c9060588fb49,https://www.semanticscholar.org/paper/3502f23932655f3f8b2b995926a5c9060588fb49,semantic_scholar,proposal of data-centric network for mobile and dynamic machine-to-machine communication,"SUMMARY Machine-to-Machine (M2M) communication is expected to grow in networks of the future, where massive numbers of low cost, low function M2M terminals communicate in many-to-many manner in an extremely mobile and dynamic environment. We propose a network architecture called Data-centric Network (DCN) where communication is done using a data identifier (ID) and the dynamic data registered by mobile terminals can be retrieved by specifying the data ID. DCN mitigates the problems of prior arts, which are large size of routing table and transaction load of name resolution service. DCN introduces concept of route attraction and aggregation in which the related routes are attracted to an aggregation point and aggregated to reduce routing table size, and route optimization in which optimized routes are established routes to reduce access transaction load to the aggregation points. These allow the proposed architecture to deal with ever increasing number of data and terminals with frequent mobility and changes in data.",IEICE Trans. Commun.,2013,citation,30,to_check,included
87eacd05c95bac1adc4df045463ad434e515c09c,https://www.semanticscholar.org/paper/87eacd05c95bac1adc4df045463ad434e515c09c,semantic_scholar,"architectural middleware that supports building high-performance, scalable, ubiquitous, intelligent personal assistants","Intelligent Personal Assistants (IPAs) are software agents that can perform tasks on behalf of individuals and assist them on many of their daily activities. IPAs capabilities are expanding rapidly due to the recent advances on areas such as natural language processing, machine learning, artificial cognition, and ubiquitous computing, which equip the agents with competences to understand what users say, collect information from everyday ubiquitous devices (e.g., smartphones, wearables, tablets, laptops, cars, household appliances, etc.), learn user preferences, deliver data-driven search results, and make decisions based on user's context. Apart from the inherent complexity of building such IPAs, developers and researchers have to address many critical architectural challenges (e.g., low-latency, scalability, concurrency, ubiquity, code mobility, interoperability, support to cognitive services and reasoning, to name a few.), thereby diverting them from their main goal: building IPAs. Thus, our contribution in this paper is twofold: 1) we propose an architecture for a platform-agnostic, high-performance, ubiquitous, and distributed middleware that alleviates the burdensome task of dealing with low-level implementation details when building IPAs by adding multiple abstraction layers that hide the underlying complexity; and 2) we present an implementation of the middleware that concretizes the aforementioned architecture and allows the development of high-level capabilities while scaling the system up to hundreds of thousands of IPAs with no extra effort. We demonstrate the powerfulness of our middleware by analyzing software metrics for complexity, effort, performance, cohesion and coupling when developing a conversational IPA.",ArXiv,2019,citation,31,to_check,not included
6f8157d52d07286c18c4d72dcd15bf035683a4b6,https://www.semanticscholar.org/paper/6f8157d52d07286c18c4d72dcd15bf035683a4b6,semantic_scholar,a robust predicted performance analysis approach for data-driven product development in the industrial internet of things,"Industrial Internet of Things (IoT) is a ubiquitous network integrating various sensing technologies and communication technologies to provide intelligent information processing and smart control abilities for the manufacturing enterprises. The aim of applying industrial IoT is to assist manufacturers manage and optimize the entire product manufacturing process to improve product quality and production efficiency. Data-driven product development is considered as one of the critical application scenarios of industrial IoT, which is used to acquire the satisfied and robust design solution according to customer demands. Performance analysis is an effective tool to identify whether the key performance have reached the requirements in data-driven product development. The existing performance analysis approaches mainly focus on the metamodel construction, however, the uncertainty and complexity in product development process are rarely considered. In response, this paper investigates a robust performance analysis approach in industrial IoT environment to help product developers forecast the performance parameters accurately. The service-oriented layered architecture of industrial IoT for product development is first described. Then a dimension reduction approach based on mutual information (MI) and outlier detection is proposed. A metamodel based on least squares support vector regression (LSSVR) is established to conduct performance prediction process. Furthermore, the predicted performance analysis method based on confidence interval estimation is developed to deal with the uncertainty to improve the robustness of the forecasting results. Finally, a case study is given to show the feasibility and effectiveness of the proposed approach.",Sensors,2018,citation,32,to_check,not included
