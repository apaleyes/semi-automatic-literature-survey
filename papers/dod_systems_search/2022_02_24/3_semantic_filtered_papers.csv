doi,type,publication,publisher,publication_date,database,title,url,abstract,domain,id,status
10.1109/iccda.2010.5540715,to_check,2010 International Conference On Computer Design and Applications,IEEE,2010-06-27 00:00:00,ieeexplore,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://ieeexplore.ieee.org/document/5540715/,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,1,included
10.1109/icacc.2010.5487131,to_check,2010 2nd International Conference on Advanced Computer Control,IEEE,2010-03-29 00:00:00,ieeexplore,data-oriented architecture of ln function,https://ieeexplore.ieee.org/document/5487131/,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,2,included
10.1109/icetc.2010.5529337,to_check,2010 2nd International Conference on Education Technology and Computer,IEEE,2010-06-24 00:00:00,ieeexplore,data-oriented architecture of sine,https://ieeexplore.ieee.org/document/5529337/,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,3,included
10.1109/icacte.2010.5579358,to_check,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),IEEE,2010-08-22 00:00:00,ieeexplore,data-oriented architecture of sine and cosine functions,https://ieeexplore.ieee.org/document/5579358/,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,4,included
10.1109/icepe.2014.6970070,to_check,2014 International Conference and Exposition on Electrical and Power Engineering (EPE),IEEE,2014-10-18 00:00:00,ieeexplore,domain specific languages in power systems engineering,https://ieeexplore.ieee.org/document/6970070/,"This paper proposes an information system for data mining that allows the specification of ad-hoc queries on a data warehouse, which contain historical information relative to exceptions (i.e., operating faults) recorded by a SCADA system in a power distribution network. The proposed application can be used by the power system engineers to explore the existent historical data, with no need for any “low level” programming expertise. The data-oriented architecture of the system provides important advantages related to application development and system maintainability.",data oriented architecture,5,included
10.1109/cse.2014.128,to_check,2014 IEEE 17th International Conference on Computational Science and Engineering,IEEE,2014-12-21 00:00:00,ieeexplore,exploring the benefits of introducing network coding into named data networking,https://ieeexplore.ieee.org/document/7023638/,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,6,included
http://arxiv.org/abs/1706.03968v2,to_check,arxiv,arxiv,2017-06-13 00:00:00,arxiv,asynchronous graph pattern matching on multiprocessor systems,http://arxiv.org/abs/1706.03968v2,"Pattern matching on large graphs is the foundation for a variety of
application domains. Strict latency requirements and continuously increasing
graph sizes demand the usage of highly parallel in-memory graph processing
engines that need to consider non-uniform memory access (NUMA) and concurrency
issues to scale up on modern multiprocessor systems. To tackle these aspects,
graph partitioning becomes increasingly important. Hence, we present a
technique to process graph pattern matching on NUMA systems in this paper. As a
scalable pattern matching processing infrastructure, we leverage a
data-oriented architecture that preserves data locality and minimizes
concurrency-related bottlenecks on NUMA systems. We show in detail, how graph
pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,7,included
10.15598/aeee.v19i4.4183,to_check,core,"'VSB Technical University of Ostrava, Faculty of Electrical Engineering and Computer Sciences'",2021-01-01 00:00:00,core,intelligent bearing fault diagnosis method based on hnr envelope and classification using supervised machine learning algorithms,https://core.ac.uk/download/490710719.pdf,"Research on data-driven bearing fault diagnosis techniques has recently drawn more and more attention due to the availability of massive condition monitoring data. The research work presented in this paper aims to develop an architecture for the detection and diagnosis of bearing faults in the induction machines. The developed data-oriented architecture uses vibration signals collected by sensors placed on the machine, which is based, in the first place, on the extraction of fault indicators based on the harmonics-to-noise ratio envelope. Normalisation is then applied to the extracted indicators to create a well-processed data set. The evolution of these indicators will be studied afterwards according to the type and severity of defects using sequential backward selection technique. Supervised machine learning classification methods are developed to classify the measurements described by the feature vector with respect to the known modes of operation. In the last phase concerning decision making, ten classifiers are tested and applied based on the selected and combined indicators. The developed classification methods allow classifying the observations, with respect to the different modes of bearing condition (outer race, inner race fault or healthy condition). The proposed method is validated on data collected using an experimental bearing test bench. The experimental results indicate that the proposed architecture achieves high accuracy in bearing fault detection under all operational conditions. The results show that, compared to some proposed approaches, our proposed architecture can achieve better performance overall in terms of the number of optimal features and the accuracy of the tests",data oriented architecture,8,not included
10.3390/electronics10151810,to_check,core,'MDPI AG',2021-07-01 00:00:00,core,on-board data management layer: connected vehicle as data platform,,"For connected vehicles, as well as generally for the transportation sector, data are now seen as a precious resource. They can be used to make right decisions, improve road safety, reduce CO2 emissions, or optimize processes. However, analyzing these data is not so much a question of which technologies to use, but rather about where these data are analyzed. Thereby, the emerging vehicle architecture has to become a data-oriented architecture based on embedded computing platforms and take into account new applications, artificial intelligence elements, advanced analytics, and operating systems. Accordingly, in this paper, we introduce the concept of data management to the vehicle by proposing an on-board data management layer, so that the vehicle can play the role of data platform capable of storing, processing, and diffusing data. Our proposed layer supports analytics and data science to deliver additional value from the connected vehicle data and stimulate the development of new services. In addition, our data platform can also form or contribute to shaping the backbone of data-driven transport. An on-board platform was built where the dataset size was reduced 80% and a rate of 99% accuracy was achieved in a 5 min traffic flow prediction using artificial neural networks (ANNs)",data oriented architecture,9,included
987f1feddb599eac1c924ce5dc39f9c57e93d5e0,to_check,semantic_scholar,,2012-01-01,semantic_scholar,data-oriented architecture for system integration,https://www.semanticscholar.org/paper/987f1feddb599eac1c924ce5dc39f9c57e93d5e0,"According to the problem that,in the process of integrating large-scale distributed system,the subsystems are difficult to manage,extend,and maintenance,which caused by their different implementation technologies and tightly-coupled design.A pattern of data-oriented design is introduced,and the principle based on the pattern and the related middleware technology were discussed.A data-oriented architecture for system integration was proposed.Finally,based on the example of a real-time package tracking system-of-systems,the architecture of data-oriented integration was discussed in detail.",data oriented architecture,10,included
6d5165205564bc98c1afcf20a1652a21f1e3e61e,to_check,semantic_scholar,,2007-01-01,semantic_scholar,data-oriented architecture: a loosely-coupled real-time soa,https://www.semanticscholar.org/paper/6d5165205564bc98c1afcf20a1652a21f1e3e61e,"2007 August "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,11,included
9fc03132540aa5d53f50b875bb4ccb620dee09ea,to_check,semantic_scholar,,2007-01-01,semantic_scholar,data-oriented architecture,https://www.semanticscholar.org/paper/9fc03132540aa5d53f50b875bb4ccb620dee09ea,"2007 January "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,12,included
f7946ea31a3da644fd59303be9fff721579987fd,to_check,semantic_scholar,IEEE Internet of Things Journal,2017-01-01,semantic_scholar,a data-oriented m2m messaging mechanism for industrial iot applications,https://www.semanticscholar.org/paper/f7946ea31a3da644fd59303be9fff721579987fd,"Machine-to-machine (M2M) communication is a key enabling technology for the future industrial Internet of Things applications. It plays an important role in the connectivity and integration of computerized machines, such as sensors, actuators, controllers, and robots. The requirements in flexibility, efficiency, and cross-platform compatibility of the intermodule communication between the connected machines raise challenges for the M2M messaging mechanism toward ubiquitous data access and events notification. This investigation determines the challenges facing the M2M communication of industrial systems and presents a data-oriented M2M messaging mechanism based on ZeroMQ for the ubiquitous data access in rich sensing pervasive industrial applications. To prove the feasibility of the proposed solution, the EU funded PickNPack production line with a reference industrial network architecture is presented, and the communication between a microwave sensor device and the quality assessment and sensing module controller of the PickNPack line is illustrated as a case study. The evaluation is carried out through qualitative analysis and experimental studies, and the results demonstrate the feasibility of the proposed messaging mechanism. Due to the flexibility in dealing with hierarchical system architecture and cross-platform heterogeneity of industrial applications, this messaging mechanism deserves extensive investigations and further evaluations.",data oriented architecture,13,included
86cd3e57dd5d31c025543d96dc271da365d61a90,to_check,semantic_scholar,SIGCOMM,2007-01-01,semantic_scholar,a data-oriented (and beyond) network architecture,https://www.semanticscholar.org/paper/86cd3e57dd5d31c025543d96dc271da365d61a90,"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, we propose the Data-Oriented Network Architecture (DONA), which involves a clean-slate redesign of Internet naming and name resolution.",data oriented architecture,14,included
b0e0e1172296a6da7de25aa40f51cce9614ae8fc,to_check,semantic_scholar,,2015-01-01,semantic_scholar,allocation strategies for data-oriented architectures,https://www.semanticscholar.org/paper/b0e0e1172296a6da7de25aa40f51cce9614ae8fc,"Data orientation is a common design principle in distributed data management systems. In contrast to process-oriented or transaction-oriented system designs, dataoriented architectures are based on data locality and function shipping. The tight coupling of data and processing thereon is implemented in different systems in a variety of application scenarios such as data analysis, database-as-a-service, and data management on multiprocessor systems. Data-oriented systems, i.e., systems that implement a data-oriented architecture, bundle data and operations together in tasks which are processed locally on the nodes of the distributed system. Allocation strategies, i.e., methods that decide the mapping from tasks to nodes, are core components in data-oriented systems. Good allocation strategies can lead to balanced systems while bad allocation strategies cause skew in the load and therefore suboptimal application performance and infrastructure utilization. Optimal allocation strategies are hard to find given the complexity of the systems, the complicated interactions of tasks, and the huge solution space. To ensure the scalability of dataoriented systems and to keep them manageable with hundreds of thousands of tasks, thousands of nodes, and dynamic workloads, fast and reliable allocation strategies are mandatory. In this thesis, we develop novel allocation strategies for data-oriented systems based on graph partitioning algorithms. Therefore, we show that systems from different application scenarios with different abstraction levels can be generalized to generic infrastructure and workload descriptions. We use weighted graph representations to model infrastructures with bounded and unbounded, i.e., overcommited, resources and possibly non-linear performance characteristics. Based on our generalized infrastructure and workload model, we formalize the allocation problem, which seeks valid and balanced allocations that minimize communication. Our allocation strategies partition the workload graph using solution heuristics that work with single and multiple vertex weights. Novel extensions to these solution heuristics can be used to balance penalized and secondary graph partition weights. These extensions enable the allocation strategies to handle infrastructures with non-linear performance behavior. On top of the basic algorithms, we propose methods to incorporate heterogeneous infrastructures and to react to changing workloads and infrastructures by incrementally updating the partitioning. We evaluate all components of our allocation strategy algorithms and show their applicability and scalability with synthetic workload graphs. In end-to-end– performance experiments in two actual data-oriented systems, a database-as-aservice system and a database management system for multiprocessor systems, we prove that our allocation strategies outperform alternative state-of-the-art methods.",data oriented architecture,15,included
d202d37f5d90cb7fbb7dff2d454fcad944a3176e,to_check,semantic_scholar,GeoInfo,2005-01-01,semantic_scholar,local spatial data infrastructures based on a service-oriented architecture,https://www.semanticscholar.org/paper/d202d37f5d90cb7fbb7dff2d454fcad944a3176e,"Sharing geographic information is an essential activity which has been sought since the early days of GIS, mostly due to the cost of information collection and maintenance. Having once depended on the establishment of data transfer standards, sharing initiatives gradually evolved towards the creation of clearinghouses, Web resources that centralize links to various GI sources, but are still data-oriented. The current focus on spatial data infrastructures changes that, by establishing a service-oriented view, thus allowing for the creation of shared, distributed, and interoperable environments through Web services. This paper explores, in a preliminary fashion, such an architecture as applied to distributed geographic applications, focusing on the potential for local services and local uses, and proposing specialized services deemed essential for urban-scale applications.",data oriented architecture,16,not included
0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,to_check,semantic_scholar,J. Database Manag.,2001-01-01,semantic_scholar,a metadata oriented architecture for building datawarehouse,https://www.semanticscholar.org/paper/0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,"Data warehouse is an intelligent store of data that can aggregate vast amounts of information. A metadata is critical for implementing data warehouse. Therefore, integrating data warehouse with its metadata offers a new opportunity to create a more adaptive information system. This paper proposes a metadata-oriented data warehouse architecture that consists of seven components: legacy system, extracting software, operational data store, data warehouse, data mart, application, and metadata. A taxonomy for dataflow and metaflow is proposed for better understanding of the architecture. In addition, a metadata schema is built within the framework of the seven components. The architecture with its metadata component is applied to a real-life data warehouse for a large medical center in order to illustrate its practical usefulness.",data oriented architecture,17,included
a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,to_check,semantic_scholar,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019-01-01,semantic_scholar,auto-fpn: automatic network architecture adaptation for object detection beyond classification,https://www.semanticscholar.org/paper/a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,"Abstract Neural architecture search (NAS) has shown great potential in automating the manual process of designing a good CNN architecture for image classification. In this paper, we study NAS for object detection, a core computer vision task that classifies and localizes object instances in an image. Existing works focus on transferring the searched architecture from classification task (ImageNet) to the detector backbone, while the rest of the architecture of the detector remains unchanged. However, this pipeline is not task-specific or data-oriented network search which cannot guarantee optimal adaptation to any dataset. Therefore, we propose an architecture search framework named Auto-FPN specifically designed for detection beyond simply searching a classification backbone. Specifically, we propose two auto search modules for detection: Auto-fusion to search a better fusion of the multi-level features; Auto-head to search a better structure for classification and bounding-box(bbox) regression. Instead of searching for one repeatable cell structure, we relax the constraint and allow different cells. The search space of both modules covers many popular designs of detectors and allows efficient gradient-based architecture search with resource constraint (2 days for COCO on 8 GPU cards). Extensive experiments on Pascal VOC, COCO, BDD, VisualGenome and ADE demonstrate the effectiveness of the proposed method, e.g. achieving around 5% improvement than FPN in terms of mAP while requiring around 50% fewer parameters on the searched modules.",data oriented architecture,18,not included
a323992739aaa0e477c206fdcad9f7cb87139360,to_check,semantic_scholar,IEEE Transactions on Nanotechnology,2015-01-01,semantic_scholar,an energy-efficient nonvolatile in-memory computing architecture for extreme learning machine by domain-wall nanowire devices,https://www.semanticscholar.org/paper/a323992739aaa0e477c206fdcad9f7cb87139360,"The data-oriented applications have introduced increased demands on memory capacity and bandwidth, which raises the need to rethink the architecture of the current computing platforms. The logic-in-memory architecture is highly promising as future logic-memory integration paradigm for high throughput data-driven applications. From memory technology aspect, as one recently introduced nonvolatile memory device, domain-wall nanowire (or race-track) not only shows potential as future power efficient memory, but also computing capacity by its unique physics of spintronics. This paper explores a novel distributed in-memory computing architecture where most logic functions are executed within the memory, which significantly alleviates the bandwidth congestion issue and improves the energy efficiency. The proposed distributed in-memory computing architecture is purely built by domain-wall nanowire, i.e., both memory and logic are implemented by domain-wall nanowire devices. As a case study, neural network-based image resolution enhancement algorithm, called DW-NN, is examined within the proposed architecture. We show that all operations involved in machine learning on neural network can be mapped to a logic-in-memory architecture by nonvolatile domain-wall nanowire. Domain-wall nanowire-based logic is customized for in machine learning within image data storage. As such, both neural network training and processing can be performed locally within the memory. The experimental results show that the domain-wall memory can reduce 92% leakage power and 16% dynamic power compared to main memory implemented by DRAM; and domain-wall logic can reduce 31% both dynamic and 65% leakage power under the similar performance compared to CMOS transistor-based logic. And system throughput in DW-NN is improved by 11.6x and the energy efficiency is improved by 56x when compared to conventional image processing system.",data oriented architecture,19,not included
e0b54bc395fccf323645a4839d04b646431eb369,to_check,semantic_scholar,IEEE Transactions on Circuits and Systems II: Express Briefs,2015-01-01,semantic_scholar,a fast integral image computing hardware architecture with high power and area efficiency,https://www.semanticscholar.org/paper/e0b54bc395fccf323645a4839d04b646431eb369,"Integral image computing is an important part of many vision applications and is characterized by intensive computation and frequent memory accessing. This brief proposes an approach for fast integral image computing with high area and power efficiency. For the data flow of the integral image computation a dual-direction data-oriented integral image computing mechanism is proposed to improve the processing efficiency, and then a pipelined parallel architecture is designed to support this mechanism. The parallelism and time complexity of the approach are analyzed and the hardware implementation cost of the proposed architecture is also presented. Compared with the state-of-the-art methods this architecture achieves the highest processing speed with comparatively low logic resources and power consumption.",data oriented architecture,20,included
a312fd2a6feffb5bd907a08548a359f071b1e2fe,to_check,semantic_scholar,SIGCOMM '09,2009-01-01,semantic_scholar,lipsin: line speed publish/subscribe inter-networking,https://www.semanticscholar.org/paper/a312fd2a6feffb5bd907a08548a359f071b1e2fe,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.
 In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.",data oriented architecture,21,included
70e6fa53b806b17d603bdc7d47a7d615d7834670,to_check,semantic_scholar,2011 IEEE Third International Conference on Cloud Computing Technology and Science,2011-01-01,semantic_scholar,a cloud environment for data-intensive storage services,https://www.semanticscholar.org/paper/70e6fa53b806b17d603bdc7d47a7d615d7834670,"The emergence of cloud environments has made feasible the delivery of Internet-scale services by addressing a number of challenges such as live migration, fault tolerance and quality of service. However, current approaches do not tackle key issues related to cloud storage, which are of increasing importance given the enormous amount of data being produced in today's rich digital environment (e.g. by smart phones, social networks, sensors, user generated content). In this paper we present the architecture of a scalable and flexible cloud environment addressing the challenge of providing data-intensive storage cloud services through raising the abstraction level of storage, enabling data mobility across providers, allowing computational and content-centric access to storage and deploying new data-oriented mechanisms for QoS and security guarantees. We also demonstrate the added value and effectiveness of the proposed architecture through two real-life application scenarios from the healthcare and media domains.",data oriented architecture,22,not included
bb4b9316c514860dbfd54bbd50baec757e37b83d,to_check,semantic_scholar,,2012-01-01,semantic_scholar,data as a service (daas) in cloud computing,https://www.semanticscholar.org/paper/bb4b9316c514860dbfd54bbd50baec757e37b83d,"Data has become the enabling technology for many of the recent innovations. ""More data trumps smarter algorithms"" has been the mantra behind this revolution in computing. Given the rate at which the data is produced, there is need for scalable solutions to extract information out of them. Allowing the data to be stored in the cloud and be accessed without geographical and scalability limitations will remove many bottlenecks in bringing data-oriented innovations. Current cloud architecture solves the issues of accessibility and scalability, but poses several new challenges such as automatic management of the service, pricing the data, and security of the data. This talk will include several techniques to address these challenges using automatic physical design, servicebased pricing, and cryptographic mechanisms. Data Information Knowledge Intelligence.",data oriented architecture,23,included
78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,to_check,semantic_scholar,IEEE Communications Magazine,2013-01-01,semantic_scholar,on functionality separation for green mobile networks: concept study over lte,https://www.semanticscholar.org/paper/78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,"Traditional wireless networks are designed for ubiquitous network access provision with low-rate voice services, which thus preserve the homogeneous architecture and tight coupling for infrastructures such as base stations. With the traffic explosion and the paradigm shift from voice-oriented services to data-oriented services, traditional homogeneous architecture no longer maintains its optimality, and heterogeneous deployment with flexible network control capability becomes a promising evolution direction. To achieve this goal, in this article, we propose a two-layer network functionality separation scheme, targeting at low control signaling overhead and flexible network reconfiguration for future mobile networks. The proposed scheme is shown to support all kinds of user activities defined in current networks. Moreover, we give two examples to illustrate how the proposed scheme can be applied to multicarrier networks and suggest two important design principles for future green networks. Numerical results show that the proposed scheme achieves significant energy reduction over traditional LTE networks, and can be recommended as a candidate solution for future green mobile networks.",data oriented architecture,24,not included
4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,to_check,semantic_scholar,IEEE Transactions on Industrial Electronics,2015-01-01,semantic_scholar,design and optimization of multiclocked embedded systems using formal techniques,https://www.semanticscholar.org/paper/4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,"Today's system-on-chip and distributed systems are commonly equipped with multiple clocks. The key challenge in designing such systems is that two situations have to be captured and evaluated in a single framework. The first is the heterogeneous control-oriented and data-oriented behaviors within one clock domain, and the second is the asynchronous communications between two clock domains. In this paper, we propose to use timed automata and synchronous dataflow to model the dynamic behaviors of the multiclock train-control system, and a multiprocessor architecture for the implementation from our model to the real system. Data-oriented behaviors are captured by synchronous dataflow, control-oriented behaviors are captured by timed automata, and asynchronous communications of the interclock domain can be modeled as an interface timed automaton or a synchronous dataflow module. The behaviors of synchronous dataflow are interpreted by some equivalent timed automata to maintain the semantic consistency of the mixed model. Then, various functional properties that are important to guarantee the correctness of the system can be simulated and verified within the framework. We apply the framework to the design of a control system described in the standard IEC 61 375 and several bugs are detected. The bugs in the standard have been fixed, and the new version has been implemented and used in the real-world subway communication control system.",data oriented architecture,25,not included
5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,to_check,semantic_scholar,Information-Centric Networking,2010-01-01,semantic_scholar,a survey of information-centric networking (draft),https://www.semanticscholar.org/paper/5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,"In this paper we compare and discuss some of the features and design choices 
of the 4WARD Networking of Information architecture (NetInf), PARC's Content Centric Networking(CCN), the Publish-Subscribe Internet Routing Paradigm (PSIRP), and the Data Oriented Network Architecture (DONA). All four projects take an information-centric approach to designing a future network architecture, where the information objects themselves are the primary focus rather than the network nodes.",data oriented architecture,26,included
1112c1cd0e7b0c96a1f5231bd1767603466d4300,to_check,semantic_scholar,CIDR,2006-01-01,semantic_scholar,turning cluster management into data management; a system overview,https://www.semanticscholar.org/paper/1112c1cd0e7b0c96a1f5231bd1767603466d4300,"This paper introduces the CondorJ2 cluster management system. Traditionally, cluster management systems such as Condor employ a process-oriented approach with little or no use of modern database system technology. In contrast, CondorJ2 employs a data-centric, 3-tier web-application architecture for all system functions (e.g., job submission, monitoring and scheduling; node configuration, monitoring and management, etc.) except for job execution. Employing a data-oriented approach allows the core challenge (i.e., managing and coordinating a large set of distributed computing resources) to be transformed from a relatively low-level systems problem into a more abstract, higher-level data management problem. Preliminary results suggest that CondorJ2’s use of standard 3-tier software represents a significant step forward to the design and implementation of large clusters (1,000 to 10,000 nodes).",data oriented architecture,27,not included
f1d7ddb9bc63fee86bfece409732bd977899b254,to_check,semantic_scholar,CFI,2012-01-01,semantic_scholar,on adapting http protocol to content centric networking,https://www.semanticscholar.org/paper/f1d7ddb9bc63fee86bfece409732bd977899b254,"Designed around host-reachability, today's Internet architecture faces many limitations while serving content-oriented applications which generate most traffic load to the Internet. CCN (Content Centric Networking) [1] is one of the most important proposals for future Internet architecture, which aims to build a content/data oriented network to solve these limitations. On the other hand, HTTP is the most important protocol to deploy new services and applications on current TCP/IP-based Internet. In this paper, we attempt to run HTTP protocol on CCN and combine the two by stitching them semantically on their content-oriented features, such as content caching. We expect that this combination can be leveraged to build CCN testbed with real HTTP traffic which is vital to validation and redesigning of specific mechanisms of CCN and to finding a transition way of CCN in which great incentive is provided for service providers in the economic ecosystem of content distribution. We designed and implemented a HTTP-CCN gateway to transform HTTP request and HTTP response into CCN Interest and Data respectively. We illustrate how to semantically map HTTP caching to CCN caching, which is one of the most attractive properties of CCN. We also discuss how to achieve transparent caching with CCN and find out that it is nontrivial to achieve complete transparency of caching with CCN given no cooperation with CDNs and content providers.",data oriented architecture,28,included
96be97fc6ec58a35601ada2e353e17b1afa09335,to_check,semantic_scholar,IEEE J. Sel. Areas Commun.,2003-01-01,semantic_scholar,a summary of the hornet project: a next-generation metropolitan area network,https://www.semanticscholar.org/paper/96be97fc6ec58a35601ada2e353e17b1afa09335,"Metropolitan area networks are currently undergoing an evolution aimed at more efficiently transport of data-oriented traffic. However, the incoming generation of metro networks is based on conventional technology, which prevents them scaling cost-effectively to ultrahigh capacities. We have developed a new architecture and set of protocols for the next generation of metro networks. The architecture, named HORNET (hybrid optoelectronic ring network), is a packet-over-wavelength-division multiplexing ring network that utilizes fast-tunable packet transmitters and wavelength routing to enable it to scale cost-effectively to ultrahigh capacities. A control-channel-based media access control (MAC) protocol enables the network nodes to share the bandwidth of the network while preventing collisions. The MAC protocol is designed to transport variable-sized packets and to provide fairness control to all network end users. The efficiency and the fairness of the MAC protocol is demonstrated with custom-designed simulations. The implementation of the MAC protocol and the survivability of the network have been demonstrated in a laboratory experimental testbed. The article summarizes the accomplishments of the HORNET project, including the design, analysis, and demonstration of a metro architecture and a set of protocols. The HORNET architecture is an excellent candidate for next-generation high-capacity metro networks.",data oriented architecture,29,not included
ea835ee626baa1d719a54206f4af3f5e6349173e,to_check,semantic_scholar,Third IEEE International Conference on Data Mining,2003-01-01,semantic_scholar,a dynamic adaptive self-organising hybrid model for text clustering,https://www.semanticscholar.org/paper/ea835ee626baa1d719a54206f4af3f5e6349173e,"Clustering by document concepts is a powerful way of retrieving information from a large number of documents. This task in general does not make any assumption on the data distribution. For this task we propose a new competitive self-organising (SOM) model, namely the dynamic adaptive self-organising hybrid model (DASH). The features of DASH are a dynamic structure, hierarchical clustering, nonstationary data learning and parameter self-adjustment. All features are data-oriented: DASH adjusts its behaviour not only by modifying its parameters but also by an adaptive structure. The hierarchical growing architecture is a useful facility for such a competitive neural model which is designed for text clustering. We have presented a new type of self-organising dynamic growing neural network which can deal with the nonuniform data distribution and the nonstationary data sets and represent the inner data structure by a hierarchical view.",data oriented architecture,30,not included
cf99bc5412e2513b97cf6d4cbbb0e427a973c528,to_check,semantic_scholar,Proc. VLDB Endow.,2017-01-01,semantic_scholar,analyzing the impact of system architecture on the scalability of oltp engines for high-contention workloads,https://www.semanticscholar.org/paper/cf99bc5412e2513b97cf6d4cbbb0e427a973c528,"Main-memory OLTP engines are being increasingly deployed on multicore servers that provide abundant thread-level parallelism. However, recent research has shown that even the state-of-the-art OLTP engines are unable to exploit available parallelism for high contention workloads. While previous studies have shown the lack of scalability of all popular concurrency control protocols, they consider only one system architecture---a non-partitioned, shared everything one where transactions can be scheduled to run on any core and can access any data or metadata stored in shared memory.In this paper, we perform a thorough analysis of the impact of other architectural alternatives (Data-oriented transaction execution, Partitioned Serial Execution, and Delegation) on scalability under high contention scenarios. In doing so, we present Trireme, a main-memory OLTP engine testbed that implements four system architectures and several popular concurrency control protocols in a single code base. Using Trireme, we present an extensive experimental study to understand i) the impact of each system architecture on overall scalability, ii) the interaction between system architecture and concurrency control protocols, and iii) the pros and cons of new architectures that have been proposed recently to explicitly deal with high-contention workloads.",data oriented architecture,31,not included
ac3df9cff34e5b9331a114c70d5e308f03370bfd,to_check,semantic_scholar,"2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems",2015-01-01,semantic_scholar,a data-oriented method for scheduling dependent tasks on high-density multi-gpu systems,https://www.semanticscholar.org/paper/ac3df9cff34e5b9331a114c70d5e308f03370bfd,"The rapidly-changing computer architectures, though improving the performance of computers, have been challenging the programming environments for efficiently harnessing the potential of novel architectures. In this area, though the high-density multi-GPU architecture enabled unparalleled performance advantage of dense GPUs in a single server, it has increased the difficulty for scheduling diversified and dependent tasks. We therefore propose a data-oriented method for scheduling dependent tasks for this architecture while providing its implementation. In our method, we model a parallel program as a collection of data-dependent tasks for which data dependencies are managed by an expressive matrix. Accordingly, we develop a hierarchical scheduler infrastructure for our model. In this, a top scheduler is built for querying the data-dependency matrix; three downstream schedulers for queuing computation tasks that are exclusively assigned to processor, accelerator or either; and a multitude of bottom schedulers each for providing a processing element with assigned tasks. We experiment our scheduler for examples of Strassen matrix multiplication and Cholesky matrix inversion algorithms on a computer that has 8 Tesla K40 GPUs. The results show that our method is capable of offering the efficient task parallelism while fulfilling the complex task dependencies. When advanced task-oriented schedulers have been widely designed for distributed systems, a lightweight data-driven scheduler could be an alternative and handy approach that can handle the dependent yet diversified tasks of data-intensive applications for the novel high-density multi-accelerator system.",data oriented architecture,32,included
f66df4762da27773e3a6ed820665aa74d4db0e76,to_check,semantic_scholar,2018 IEEE European Symposium on Security and Privacy (EuroS&P),2018-01-01,semantic_scholar,security risks in asynchronous web servers: when performance optimizations amplify the impact of data-oriented attacks,https://www.semanticscholar.org/paper/f66df4762da27773e3a6ed820665aa74d4db0e76,"Over the past decade, many innovations have been achieved with respect to improving the responsiveness of highly-trafficked servers. These innovations are fueled by a desire to support complex and data-rich web applications while consuming minimal resources. One of the chief advancements has been the emergence of the asynchronous web server architecture, which is built from the ground up for scalability. While this architecture can offer a significant boost in performance over classic forking servers, it does so at the cost of abandoning memory space isolation between client interactions. This shift in design, that delegates the handling of many unrelated requests within the same process, enables powerful and covert data-oriented attacks that rival complete web server takeover — without ever hijacking the control flow of the server application. To demonstrate the severity of this threat, we present a technique for identifying security-critical web server data by tracing memory accesses committed by the program in generating responses to client requests. We further develop a framework for performing live memory analysis of a running server in order to understand how low-level memory structures can be corrupted for malicious intent. A fundamental goal of our work is to assess the realism of such data-oriented attacks in terms of the types of memory errors that can be leveraged to perform them, and to understand the prominence of these errors in real-world web servers. Our case study on a leading asynchronous architecture, namely Nginx, shows how dataoriented attacks allow an adversary to re-configure an Nginx instance on the fly in order to degrade or disable services (e.g., error reporting, security headers like HSTS, access control), steal sensitive information, as well as distribute arbitrary web content to unsuspecting clients — all by manipulating only a few bytes in memory. Our empirical findings on the susceptibility of modern asynchronous web servers to two wellknown CVEs show that the damage could be severe. To address this threat, we also discuss several potential mitigations. Taken as a whole, our work tells a cautionary tale regarding the risks of blindly pushing forward with performance optimizations.",data oriented architecture,33,included
85d191b722bf7e0724cb431d7bef69d1cad8b54a,to_check,semantic_scholar,China Communications,2017-01-01,semantic_scholar,"digital rights management: model, technology and application",https://www.semanticscholar.org/paper/85d191b722bf7e0724cb431d7bef69d1cad8b54a,"with rapid achievement of current information technology and computing ability and applications, much more digital content such as films, cartoons, design drawings, office documents and software source codes are produced in daily work, however to protect the content being copying, shared or deliberately stolen by inside or outside, digital rights management (DRM) became more and more important for digital content protection. In this paper, we studied various DRM model, technology and application, and first proposed DRM Security Infrastructure (DSI), in which we defined encryption, hash, signature algorithm, watermarking algorithms, authentication, usage control, trusted counter, conditional trace, secure payment, and based on the DSI we then proposed a whole classification approach and architecture of all kinds of DRMs, in which we proposed 6 typical classes of copyrights and content protection DRMs architecture: (1) Software-oriented DRM,(2) eBook-oriented DRM, (3) Video-oriented DRM, (4)Image-Oriented DRM (5) Unstructured data oriented DRM, (6) Text-oriented DRM. Based on the above DSI, we then proposed a dynamic DRM model selection method for various DRM application, which can be adapted dynamically for different technology of different applications, which can provide a whole solution for variant DRM development in a rapid and customized mode. The proposed DRM method, technology and application in this paper provided a common, flexible and extendable solution for variant DRM scenes, and can support rapid and customized development. Moreover, we proposed an opinion that the future life will enter into a new era that the content usage and consumption will not again adopt DRM technology rather than with law, liberty and morality.",data oriented architecture,34,not included
3c43e848a6cf8f90c17298d6298ce0b58007881e,to_check,semantic_scholar,,2012-01-01,semantic_scholar,generic adaptation framework for unifying adaptive web-based systems,https://www.semanticscholar.org/paper/3c43e848a6cf8f90c17298d6298ce0b58007881e,"The Generic Adaptation Framework (GAF) research project first and foremost creates a common formal framework for describing current and future adaptive hypermedia (AHS) and adaptive webbased systems in general. It provides a commonly agreed upon taxonomy and a reference model that encompasses the most general architectures of the present and future, including conventional AHS, and different types of personalization-enabling systems and applications such as recommender systems (RS) personalized web search, semantic web enabled applications used in personalized information delivery, adaptive e-Learning applications and many more. At the same time GAF is trying to bring together two (seemingly not intersecting) views on the adaptation: a classical pre-authored type, with conventional domain and overlay user models and data-driven adaptation which includes a set of data mining, machine learning and information retrieval tools. To bring these research fields together we conducted a number GAF compliance studies including RS, AHS, and other applications combining adaptation, recommendation and search. We also performed a number of real systems’ case-studies to prove the point and perform a detailed analysis and evaluation of the framework. Secondly it introduces a number of new ideas in the field of AH, such as the Generic Adaptation Process (GAP) which aligns with a layered (data-oriented) architecture and serves as a reference adaptation process. This also helps to understand the compliance features mentioned earlier. Besides that GAF deals with important and novel aspects of adaptation enabling and leveraging technologies such as provenance and versioning. The existence of such a reference basis should stimulate AHS research and enable researchers to demonstrate ideas for new adaptation methods much more quickly than if they had to start from scratch. GAF will thus help bootstrap any adaptive web-based system research, design, analysis and evaluation.",data oriented architecture,35,not included
bdd38349d22ab12ddd44a500d5720853ee17286b,to_check,semantic_scholar,2012 IEEE International Conference on Communications (ICC),2012-01-01,semantic_scholar,traffic engineering for information-centric networks,https://www.semanticscholar.org/paper/bdd38349d22ab12ddd44a500d5720853ee17286b,"Information-centric networking (ICN) proposes a networking architecture that uses methodologies such as publish-subscribe to achieve a data-oriented approach as opposed to a destination based approach found in the current Internet. This new architecture brings both new problems to be solved and also natural solutions to existing problems. This paper investigates an intra-domain traffic engineering (TE) problem for an information-centric networking (ICN) architecture where a form of source routing is used as the forwarding mechanism. The TE goal is to maximise the residual capacity in the network so that the load is spread evenly. A network flow approach is used and it is shown that the source routing mechanism allows the traffic to be split across multiple paths in a manner that is difficult to achieve using existing IP or IP/MPLS networks. Allowing splittable flows means that a fully polynomial-time approximation scheme can be used that has superior results when compared to existing constraint based routing schemes for flows that cannot be split. Consequently, this work demonstrates that the ICN architecture can simplify the given TE problem in a natural manner.",data oriented architecture,36,included
536ab937378e5965f8687b5bf29af2e360aac3bb,to_check,semantic_scholar,2006 ieee/aiaa 25TH Digital Avionics Systems Conference,2006-01-01,semantic_scholar,system-wide information management (swim) demonstration security architecture,https://www.semanticscholar.org/paper/536ab937378e5965f8687b5bf29af2e360aac3bb,"System-wide information management (SWIM) is a Federal Aviation Administration (FAA) network-centric environment that facilitates software application integration in the National Airspace System (NAS). Built on a set of five core service types - interfaces, registries, message brokers, information assurance and system management - SWIM accelerates NAS evolution by defining a secure common infrastructure for application integration and a framework for information modeling and exchange. Providing information security in this distributed network-centric environment is a significant challenge. System users must be confident that their critical data is protected. Competing requirements, the transportation of sensitive data and air-to-ground bandwidth constraints mean that a network layer-based approach to security is no longer sufficient. Trusted security at every layer of a network-centric architecture - combined with strong identity management and a data-oriented approach to information assurance - is the key to success. This paper introduces the FAA SWIM demonstration security architecture, and explores some of the methods and mechanisms used to provide end-to-end security, confidentiality, integrity, availability and privacy for NAS applications and their users",data oriented architecture,37,not included
b728578e4b46a145a24cf02a2f5b70c01eb9b78a,to_check,semantic_scholar,FM,2005-01-01,semantic_scholar,verification of a signature architecture with hol-z,https://www.semanticscholar.org/paper/b728578e4b46a145a24cf02a2f5b70c01eb9b78a,"We report on a case study in using HOL-Z, an embedding of Z in higher-order logic, to specify and verify a security architecture for administering digital signatures. We have used HOL-Z to formalize and combine both data-oriented and process-oriented architectural views. Afterwards, we formalized temporal requirements in Z and carried out verification in higher-order logic. 
 
The same architecture has been previously verified using the SPIN model checker. Based on this, we provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with rich data. Moreover, our comparison highlights the advantages of this approach and provides evidence that, in the hands of experienced users, theorem proving is neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,38,not included
cb4fb34f4c165913a98692dea22a0eb965cefb12,to_check,semantic_scholar,SIGMOD Conference,2010-01-01,semantic_scholar,docqs: a prototype system for supporting data-oriented content query,https://www.semanticscholar.org/paper/cb4fb34f4c165913a98692dea22a0eb965cefb12,"Witnessing the richness of data in document content and many ad-hoc efforts for finding such data, we propose a Data-oriented Content Query System(DoCQS), which is oriented towards fine granularity data of all types by searching directly into document content. DoCQS uses the relational model as the underlying data model, and offers a powerful and flexible Content Query Language(CQL) to adapt to diverse query demands. In this demonstration, we show how to model various search tasks by CQL statements, and how the system architecture efficiently supports the CQL execution. Our online demo of the system is available at http://wisdm.cs.uiuc.edu/demos/docqs/.",data oriented architecture,39,included
449b756485d77d452b0cc0805b1a7a6767d8f525,to_check,semantic_scholar,IEEE Transactions on Industrial Informatics,2017-01-01,semantic_scholar,iot-based techniques for online m2m-interactive itemized data registration and offline information traceability in a digital manufacturing system,https://www.semanticscholar.org/paper/449b756485d77d452b0cc0805b1a7a6767d8f525,"The integration of internet-of-things (IoT) technologies in the industry benefits digital manufacturing applications by allowing ubiquitous interaction and collaborative automation between machines. Online data collection and data interaction are critical for real-time decision making and machine collaborations. However, due to the specificity of digital manufacturing applications, the technical gap between IoT techniques and practical machine operation could hinder the efficient data interactions, collaborations between machines, and the effectiveness as well as the accuracy of itemized data collection. This investigation, therefore, identifies some major technical problems and challenges that current IoT-based digital manufacturing is facing, and proposes a method to bridge the technical gap for itemized product management. The highlights of this investigation are: 1) a data-oriented system architecture toward flexible data interaction between machines, 2) a customized machine-to-machine protocol for machine discovery, presence, and messaging, (3) flexible data structure and data presentation for interoperability, and (4) versatile information tracing approaches for product management. The proposed solutions have been implemented in PicknPack digital food manufacturing line, and achieved ubiquitous data interaction, online data collection, and versatile product information tracing methods have shown the feasibility and significance of the presented methods.",data oriented architecture,40,not included
e4313c807b2de4d0d1c4078cb2bebdd6a4576022,to_check,semantic_scholar,Wirel. Pers. Commun.,2005-01-01,semantic_scholar,analysis of sub-carrier multiplexed radio over fiber link for the simultaneous support of wlan and wcdma systems,https://www.semanticscholar.org/paper/e4313c807b2de4d0d1c4078cb2bebdd6a4576022,"The present third generation (3G) wireless technology can provide data oriented applications. However, the bit rate is limited to around 2 Mbps with limited mobility. Today, more applications demand high data rate and reasonable mobility. Therefore, by integrating 3G cellular system and wireless local area network (WLAN), there is a potential to push the data rate higher. This integration means 3G cellular users can enjoy high data rate at a location that is within WLAN coverage area. Similarly, WLAN users also can have data services as long as they are under the coverage of the 3G cellular system. The 3G cellular system has a much larger coverage than the WLAN. In this paper, we present the first step toward an integration of the two systems. This paper presents a fiber-wireless architecture that simultaneously supports the wideband code division multiple access (WCDMA) system and the IEEE 802.11b WLAN. Our approach uses sub-carrier multiplexed (SCM) architecture to combine and transmit 2.4 GHz WLAN and 1.9 GHz WCDMA signals through an optical fiber from a central base station (CBS) to a radio access point (RAP, single antenna unit). After the fiber, the signals continue to propagate through the air interface to respective mobile stations. The WLAN access point is also located at the CBS. For the SCM architecture, we investigate three areas: i) the signal to noise ratio of the uplink and the downlink, ii) the cell coverage area for the WCDMA and WLAN systems, and iii) the throughput of the IEEE 802.11b WLAN. Our results show that with up to 2.5 km cell radius, better than 18 dB SNR is possible with 5 km fiber link for WLAN system. Simultaneously, the WCDMA system has at least 18 dB SNR for a cell coverage radius of 8 km. These numbers depend on the relative RF power of each system in the fiber.",data oriented architecture,41,not included
9703eec800ca2f2cbbcdb8edc565da15ba15af8c,to_check,semantic_scholar,Formal Aspects of Computing,2007-01-01,semantic_scholar,verifying a signature architecture: a comparative case study,https://www.semanticscholar.org/paper/9703eec800ca2f2cbbcdb8edc565da15ba15af8c,"We report on a case study in applying different formal methods to model and verify an architecture for administrating digital signatures. The architecture comprises several concurrently executing systems that authenticate users and generate and store digital signatures by passing security relevant data through a tightly controlled interface. The architecture is interesting from a formal-methods perspective as it involves complex operations on data as well as process coordination and hence is a candidate for both data-oriented and process-oriented formal methods.We have built and verified two models of the signature architecture using two representative formal methods. In the first, we specify a data model of the architecture in Z that we extend to a trace model and interactively verify by theorem proving. In the second, we model the architecture as a system of communicating processes that we verify by finite-state model checking. We provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with complex operations on data. Moreover, our comparison highlights the advantages of proving theorems about such models and provides evidence that, in the hands of an experienced user, theorem proving may be neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,42,not included
3fa248cfa1491c657bb5f32f237fac4a6a882bfe,to_check,semantic_scholar,,1994-01-01,semantic_scholar,communications architecture: towards a more robust understanding of information flows and emergent patterns of communication in organizations,https://www.semanticscholar.org/paper/3fa248cfa1491c657bb5f32f237fac4a6a882bfe,"With the proliferation of telecommunications technologies, the information-based communication infrastructure is becoming an increasingly critical organization resource. In order effectively to channel limited resources (skills, capital, technology) to the most strategically critical communication needs of the organization, the development of business driven planning methodologies which result in a well-defined architecture (blueprint) of organizational communication processes are needed. Unfortunately, while architectural issues are of utmost importance today, researchers have focused almost exclusively on data oriented models. This study attempts to expand this view and provide a holistic representation of information architecture. With the perspective provided by this definitional framework, two methods for development of communications architecture are discussed and evaluated: (1) a flow based approach; and (2) network analysis. Network analysis in particular shows great promise in constructing robust representations of organizational communication processes.",data oriented architecture,43,not included
5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,to_check,semantic_scholar,ICON 2012,2012-01-01,semantic_scholar,application design over named data networking with its features in mind,https://www.semanticscholar.org/paper/5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,"Designed around host-reachability, today’s Internet architecture faces many limitations while serving data-oriented applications, which produce most traffic load to the Internet. Many clean-slate designs of the content/data oriented network have emerged to adapt to these needs. Named Data Networking (also known as CCN) is one of these designs to address these limitations from the fundamental level by building network architecture around named data. In this paper, we identify five key features crucial to application design over Named Data Networking and take the voice conference system as an example to show how this features impact the application design significantly in detail. We identify three major challenges facing current voice conference system and illustrate how NDN could help to solve these challenges. A NDN-based design of voice conference system is presented along with discussing its reliability and congestion control. Keywords-Named Data Networking; Application Design;",data oriented architecture,44,included
102b85595c9d0ffddf74517124ad3e9dca61b271,to_check,semantic_scholar,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),2020-01-01,semantic_scholar,making iot data ready for smart city applications,https://www.semanticscholar.org/paper/102b85595c9d0ffddf74517124ad3e9dca61b271,"Modern smart city projects are evolving to the next level of data-centric situation awareness and decision makings, thereby requiring much intensive data integration over various data sources made from city space. In order to satisfy a variety of data demands for diverse smart city applications, we have been developing an integrated IoT data service, IoTDA, to provide essential data-oriented services from data collecting to deep learning based data analysis. In this paper, we introduce the overall architecture and functions of the service platform and explain how the platform will be used with a case study of road surface analysis. In particular, we examine how our data service can be connected to public smart city applications and present the common direction that these types of urban data services should provide for advanced city services.",data oriented architecture,45,included
407ebbe7b9a024c71d459a370deaf614455e3c8e,to_check,semantic_scholar,,2017-01-01,semantic_scholar,named data networking in vanet: a survey,https://www.semanticscholar.org/paper/407ebbe7b9a024c71d459a370deaf614455e3c8e,"Named Data Networking is futuristic data oriented communication model, currently applied to different area of networking. VANET is one area of networking, that named data networking applied on it, to overcome the problem of classically TCP/IP based architecture. As VANET has become a likely area in wireless communication, which can provide a lot of service: traffic efficiency, road safety, and driving comfort. So, Named data networking architecture provide a lot purpose for VANET such as in network caching, security and efficient data distribution between vehicles due to caching capabilities in NDN, this feature make VANET more efficient than TCP/IP network. In existing IP based internet architecture the end points identified by IP addresses but in NDN contents are named with human readable names that provide VANET to retrieve data by sending content name without knowing the location of the provider. This paper also present some research challenge in the VANET via NDN. Keywords— NDN, VANET, Caching, ICN.",data oriented architecture,46,included
328fb04c4cfe6a90de32041c31810c6d8908e439,to_check,semantic_scholar,IEEE Transactions on Circuits and Systems for Video Technology,2011-01-01,semantic_scholar,communication mechanisms and middleware for distributed video surveillance,https://www.semanticscholar.org/paper/328fb04c4cfe6a90de32041c31810c6d8908e439,"A new generation of advanced surveillance systems is being conceived as a collection of multisensor components such as video, audio, and mobile robots interacting in a cooperating manner to enhance situation awareness capabilities to assist surveillance personnel. The prominent issues that these systems face are the improvement of existing intelligent video surveillance systems, the inclusion of wireless networks, the use of low power sensors, the design architecture, the communication between different components, the fusion of data emerging from different type of sensors, the location of personnel (providers and consumers), and the scalability of the system. This paper focuses on the aspects pertaining to real-time distributed architecture and scalability. For example, to meet real-time requirements, these systems need to process data streams in concurrent environments, designed by taking into account scheduling and synchronization. This paper proposes a framework for the design of visual surveillance systems based on components derived from the principles of real-time networks/data-oriented requirements implementation scheme. It also proposes the implementation of these components using the well-known middleware technology common object request broker architecture. Results using this architecture for video surveillance are presented through an implemented prototype.",data oriented architecture,47,not included
48d9424e505f7be05ff74d68229fcf96c00929e0,to_check,semantic_scholar,Bell Labs Technical Journal,2000-01-01,semantic_scholar,the enhanced service manager: a service management system for next-generation networks,https://www.semanticscholar.org/paper/48d9424e505f7be05ff74d68229fcf96c00929e0,"In this paper, we describe a service management product, the Enhanced Service Manager (eSM), that provides not only fast service development and easy maintenance but also performance, reliability, and Web-enabled provisioning. Competition is fierce in the business world, especially in telecommunications. Being first to offer a service is typically a key decision-making factor for service providers in selecting an operations support system product to manage their services. Furthermore, we have seen the operations network landscape evolving from switch-based to intelligent network-oriented services and from circuit-based to more data-oriented networks. This paper illustrates how open architecture elements such as Common Object Request Broker Architecture (CORBA∗), Extensible Markup Language (XML), and Java∗/JavaServer Pages∗ (JSP∗) technology have been woven with off-the-shelf components into a product designed to meet current business needs. We discuss our architectural approach as well as a future direction.",data oriented architecture,48,not included
eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,to_check,semantic_scholar,2009 Seventh Annual Communication Networks and Services Research Conference,2009-01-01,semantic_scholar,optical access-metro network architecture based on passive access and burst-mode transmission,https://www.semanticscholar.org/paper/eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,"A network architecture that integrates several WDM PON access segments in a metropolitan area network and uses optical circuit/burst switching is presented here. This architecture targets the delivery of very high speed end to end optical communications between the edge nodes connecting the end users. The combination of circuit switching and burst transmission allows the simultaneous delivery of real-time applications (VoIP, Video) and other data-oriented applications (Internet, peer-to-peer). In the proposed architecture there is a clear separation of the functions in data plane and a control plane. A centralized control entity manages the overall architecture. A dedicated aggregation node acts as a gateway to external networks. After a presentation of the proposed network architecture, this paper focuses on the performance evaluation of the control plane using simulation. Our results show that the queuing delay remains acceptable even under heavy traffic loads.",data oriented architecture,49,not included
f925f3d29d9161514719651dd16a7310e051d56b,to_check,semantic_scholar,2005 Asia-Pacific Conference on Communications,2005-01-01,semantic_scholar,a conceptual architecture for adaptation in remote desktop systems driven by the user perception of multimedia,https://www.semanticscholar.org/paper/f925f3d29d9161514719651dd16a7310e051d56b,Current thin-client remote desktop systems were designed for data-oriented applications over low-quality LAN links and they do not provide satisfactory end-user performance in enterprise environment for more and more popular graphical and multimedia applications. To improve perception of those applications in thin-client environment we propose architecture of a server-side quality of service (QoS) management component responsible for mapping application QoS requirements into network QoS. We analyze how service differentiation and traffic management techniques combined with user perception monitoring can be used in order to adjust network level resource allocation when performance of multimedia applications in remote desktop environment is not meeting user requirements. Our objective is to provide QoS-aware remote desktop systems which will be able to manage available resources in intelligent manner and meet end-user performance expectations,data oriented architecture,50,not included
13acc27d419769500af8c3b0d04ad065402f816e,to_check,semantic_scholar,ISPRS Int. J. Geo Inf.,2018-01-01,semantic_scholar,hibuffer: buffer analysis of 10-million-scale spatial data in real time,https://www.semanticscholar.org/paper/13acc27d419769500af8c3b0d04ad065402f816e,"Buffer analysis, a fundamental function in a geographic information system (GIS), identifies areas by the surrounding geographic features within a given distance. Real-time buffer analysis for large-scale spatial data remains a challenging problem since the computational scales of conventional data-oriented methods expand rapidly with increasing data volume. In this paper, we introduce HiBuffer, a visualization-oriented model for real-time buffer analysis. An efficient buffer generation method is proposed which introduces spatial indexes and a corresponding query strategy. Buffer results are organized into a tile-pyramid structure to enable stepless zooming. Moreover, a fully optimized hybrid parallel processing architecture is proposed for the real-time buffer analysis of large-scale spatial data. Experiments using real-world datasets show that our approach can reduce computation time by up to several orders of magnitude while preserving superior visualization effects. Additional experiments were conducted to analyze the influence of spatial data density, buffer radius, and request rate on HiBuffer performance, and the results demonstrate the adaptability and stability of HiBuffer. The parallel scalability of HiBuffer was also tested, showing that HiBuffer achieves high performance of parallel acceleration. Experimental results verify that HiBuffer is capable of handling 10-million-scale data.",data oriented architecture,51,not included
dc9df4822e7e894c8da4b936599be6cffb17ea29,to_check,semantic_scholar,,1998-01-01,semantic_scholar,hoss: an environment to support structural computing,https://www.semanticscholar.org/paper/dc9df4822e7e894c8da4b936599be6cffb17ea29,"There have been two distinct trends in hypermedia work over the last decade. One has concerned the construction of increasingly more powerful infrastructure for the support of open hypermedia navigation systems, while the other has concerned the application of hypermedia technologies and concepts to increasingly diverse domains. This dissertation addresses how these trends can be merged, resulting in a framework for design of powerful, general infrastructure. 
An examination of the domains to which hypermedia concepts have been applied yields to the conclusion that all rely on general structure and general structural computation. A philosophy of computation is presented called structural computing that stresses the primacy of these concepts. Without such a philosophy, structure is seen as an ad hoc functionality to be added over data-oriented programs. Different structure-oriented domains are seen as special cases of navigational hypertext, with a corresponding confusion of basic terminologies. 
An analysis of the historical development of hypermedia systems leads to the conclusion that current open hypermedia systems can be modified in a straightforward way to support structural computing by opening the link server layer in traditional hypermedia architectures. The resultant generalized link server is called a structure processor (Sproc). Different Sprocs encapsulate tailoring and extension of the structure and structural computation models provided by the structure store of the system. 
A conceptual architecture for an environment to support structural computing (named HOSS) is presented. This architecture is divided into two parts. The operating system layer describes the basic services available to all HOSS programs. The computing environment layer consists of an open set of programs that run address specific structural computing domains. A prototypic implementation of the operating system layer and several example computing environment layer programs is described, which provides a proof of concept of the structural computing environment architecture presented. The sample programs substantiate the claims that such an environment can support the design and implementation of a wide variety of structural computing programs. 
The dissertation concludes with an evaluation of the philosophy of structural computing and the design and implementation of HOSS, a description of directions for possible future work, and conclusions.",data oriented architecture,52,not included
3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,to_check,semantic_scholar,EMISA,2006-01-01,semantic_scholar,challenges and solutions in planning information systems for networked value constellations,https://www.semanticscholar.org/paper/3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,"Nowadays businesses often decide to form networked value constellations in order to satisfy complex customer needs. To fulfill the value-based requirements of an e-Business idea and to realize the coordination of such a multi-actor network an adequate underlying information systems architecture has to be conceptualized. This paper discusses the applicability of classical information system planning approaches, such as Information Engineering to cross-organizational settings expressed
through value-based requirements. On the basis of this analysis several requirements for the enhancement and adaptation of Information Engineering-like methodologies
for e-Business ideas are defined for the purpose of enabling alignment between a value-based business context and the information systems architecture in a networked environment.
The paper proposes a way to derive data-orientation from value-orientation,
i.e. an enterprise model from a value model. This in turn enables afterwards the
straightforward use of traditional data-oriented techniques for value-based business
models.",data oriented architecture,53,not included
b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,to_check,semantic_scholar,Defense + Security,2016-01-01,semantic_scholar,icrowd: agent-based behavior modeling and crowd simulator,https://www.semanticscholar.org/paper/b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,"Initially designed in the context of the TASS (Total Airport Security System) FP-7 project, the Crowd Simulation platform developed by the Integrated Systems Lab of the Institute of Informatics and Telecommunications at N.C.S.R. Demokritos, has evolved into a complete domain-independent agent-based behavior simulator with an emphasis on crowd behavior and building evacuation simulation. Under continuous development, it reﬂects an eﬀort to implement a modern, multithreaded, data-oriented simulation engine employing latest state-of-the-art programming technologies and paradigms. It is based on an extensible architecture that separates core services from the individual layers of agent behavior, oﬀering a concrete simulation kernel designed for high-performance and stability. Its primary goal is to deliver an abstract platform to facilitate implementation of several Agent-Based Simulation solutions with applicability in several domains of knowledge, such as: (i) Crowd behavior simulation during [in/out] door evacuation. (ii) Non-Player Character AI for Game-oriented applications and Gamiﬁcation activities. (iii) Vessel traﬃc modeling and simulation for Maritime Security and Surveillance applications. (iv) Urban and Highway Traﬃc and Transportation Simulations. (v) Social Behavior Simulation and Modeling.",data oriented architecture,54,included
060477ed830f344a2e012aff637bb21b33e492c5,to_check,semantic_scholar,,2007-01-01,semantic_scholar,closer to the edge,https://www.semanticscholar.org/paper/060477ed830f344a2e012aff637bb21b33e492c5,"The next generation of distributed systems will be loosely-coupled systems that: support incremental and independent development, and are tolerant of interface changes; can systematically deal with impedance mismatches; and work well in dynamically changing realtime situations; and can scale in complexity while delivering the required real-time performance. Popular architectural styles, including data flow architecture, event driven architecture and service-oriented architecture, can be regarded as special cases, by the appropriate assignment of roles and choice of quality of service in the interfaces between components. Data-oriented application architecture coupled with an appropriate standards based messaging software bus such as DDS can cut down the complexity of the integration problem from O(N*N) to O(N), while preserving loose-coupling and ensuring scalability. Having readily available middleware infrastructure bridges for popular application platform components can greatly boost productivity and the pace of integration.",data oriented architecture,55,included
7261028c80d1ac82828f26c46318557a50c42176,to_check,semantic_scholar,,2007-01-01,semantic_scholar,biofederator: a data federation system for bioinformatics on the web,https://www.semanticscholar.org/paper/7261028c80d1ac82828f26c46318557a50c42176,"A problem facing many bioinformatics researchers today is the aggregation and analysis of vast amounts of data produced by large scale projects from various laboratories around the world. Depositing such data into centralized web-based repositories (e.g. NCBI, UCSCGenome Browser) is the common approach. However, the distributed nature of the data, its growth rate, and increased collaborative needs represent real challenges calling for novel decentralized web architectures. The BioFederator is a web services-based data federation architecture for bioinformatics applications. Based on collaborations with bioinformatics researchers, several domainspecific data federation challenges and needs are identified. The BioFederator addresses such challenges and provides an architecture that incorporates a series of utility services. These address issues like automatic workflow composition, domain semantics, and the distributed nature of the data. It also incorporates a series of data-oriented services that facilitate the actual integration of data. The BioFederator is deployed on a grid environment over the web. The proposed design, services, and usage scenarios are discussed in detail. We demonstrate how our architecture can be leveraged for a real-world bioinformatics problem involving tissue specificity of gene expression.",data oriented architecture,56,included
52c5ec6acd2dfb2194ec655bd695474f76876754,to_check,semantic_scholar,,2003-01-01,semantic_scholar,when theory meets practice: building traffic control systems made easy,https://www.semanticscholar.org/paper/52c5ec6acd2dfb2194ec655bd695474f76876754,"Two separate road developments in traffic management in the Netherlands have been the Motorway Traffic Control Architecture (MTCA) and the implementation of data-oriented middleware by Trinite in the first Traffic Management Centre in the Netherlands. The move towards integration in different systems at the traffic management level is described. The principles behind the MTCA are outlined. The architecture had to offer a framework for existing and future traffic control (TC) measures, to adopt an infrastruture-oriented approach and the different parts had to be integrated. Measures are controlled by so-called Traffic Controls, software components that are based on the composite design pattern. The programmable distributed architecture developed by Trinite is the platform on which Traffic Controls are realised in the software. The implementation of an infrastructural system with Traffic Controls involves determining the information needs, adding information elements and adding functionality.",data oriented architecture,57,not included
44f46dbb8eec8fb695e7008b1e3d4f5ef467305f,to_check,semantic_scholar,ICCSP,2019-01-01,semantic_scholar,the study of data-oriented and ownership-based security architecture in open internet environment,https://www.semanticscholar.org/paper/44f46dbb8eec8fb695e7008b1e3d4f5ef467305f,"DOSA (Data-Oriented Security Architecture, or Data Ownership-based Security Architecture) is an architecture for data protection and application in an open Internet environment. DOSA combines data with ownership by using digital certification authentication (CA) and public key infrastructure (PKI). The DOSA is simply described as one body with two wings. The one body is that the data must be combined with ownership. The one wing is that the data should be innately registered. Another wing is that the data should be innately encrypted with the data owner's public key. To share data and make data applicable, DOSA also establishes the authorization of data ownership for data sharing, the recording of data operation for data history tracing, the data behaviour analysis for the discovery of illegal use of data, and the data usage statistics for the assessment of data value, etc. Therefore, data can be securely shared and used in an open environment with ownership authorization. At the same time, data ownership is clarified; the interests of the data owner can be guaranteed.",data oriented architecture,58,included
09d08d03be2e49b58e2888b5d5b0e3a38cfb1305,to_check,semantic_scholar,IEEE Communications Magazine,2010-01-01,semantic_scholar,end-to-end flexible transport service provisioning in inter-csp environments [next-generation telco it architectures],https://www.semanticscholar.org/paper/09d08d03be2e49b58e2888b5d5b0e3a38cfb1305,"Communication service providers deliver value-added services to customers based on their available network transport services. Some services extend beyond the boundaries of a single CSP and require the collaboration of several CSPs to provide inter-CSP services. Transport services for next-generation value-added services are currently based on expensive connection oriented technologies such as synchronous digital hierarchy and optical transport networks. Data-oriented technologies have recently been considered for transport networks (e.g., Ethernet and MPLS variants) due to their efficiency, simplicity, and better suitability for data traffic, which dominates the transport networks. Currently, CSP transport networks are isolated and inter-CSP transport service provisioning involves human-to-human negotiations and manual setup of network devices. Next-generation CSPs must provide QoS intra-service-to-customer, inter-CSP, and customer-to-customer transport services that are generic, automatically provisioned, and based on business logic that can be expressed easily and uniformly. A transport service layer architecture for automatic provisioning of inter-CSP transport services is suggested here, based on standard Ethernet technology. This transport service layer architecture is part of the Ethernet transport network architecture that takes into account business relations among carriers. It enables various class-of-service transport services based on multi-constraint matching and optimizations. The resulting transport service provisioning is automated and optimized, and significantly decreases the involved inter-CSP service setup operations.",data oriented architecture,59,not included
60881ba191ac396c88bf081b940b547c51d1b5b0,to_check,semantic_scholar,,1999-01-01,semantic_scholar,a scalable service architecture for computer-telephony integration,https://www.semanticscholar.org/paper/60881ba191ac396c88bf081b940b547c51d1b5b0,"The convergence of traditional voice-oriented telecommunications networks and data-oriented computer communications networks is yielding new challenges for building systems equally adept at handling voice and data applications. While there is much discussion about packetized voice over IP networks, a little explored opportunity is the ability to more easily deploy innovative new services based on the Internet’s client-server paradigm and the ease with which software agents can be introduced and migrated around the network. We discuss our new architecture for middleware services that more effectively enables the integration of telephone and data application. This horizontally-integrated architecture supports competition between interchangeable service implementations, based upon features, cost, etc. It is characterized by pervasive and seamless access across multiple cascaded networks. We describe our experiences in integrating an Internet-based core with cellular and other access networks, and our analysis of IP performance in this testbed using a graphical multi-layer protocol analysis tool. Based on our architecture, we have developed prototype converged applications for voice-actuated room control and personal “universal in-box” information management.",data oriented architecture,60,not included
c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,to_check,semantic_scholar,"2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools",2009-01-01,semantic_scholar,run-time reconfigurable array using magnetic ram,https://www.semanticscholar.org/paper/c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,"This paper presents the implementation of a coarse-grained Magnetic RAM based Reconfigurable Array. The Reconfigurable Array architecture is organized as a one- dimensional array of programmable ALU, with the configura- tion bits stored in magnetic random-access memories. The use of MRAM technology to implement run-time reconfigurable hardware devices is a very promising technological solution because MRAM can provide non-volatility with cell areas and access speeds comparable to those of SRAM, and with lower process complexity than flash memory. This type of coarse- grained array, where each reconfigurable element computes on 4-bit or larger input words, is more suitable to execute data-oriented algorithms and is more able to exploit larger amounts of operation-level parallelism than common fine- grained architectures. By substantially reducing the overhead for configurability, this coarse-grain architecture is also more apt to efficiently exploit run-time reconfiguration and therefore to take advantage of multi-context MRAM-based configuration memories. Keywords-reconfigurable array; MRAM; programmable fab- rics;",data oriented architecture,61,not included
826ac2113812ee288da45f585759f81318ce4c85,to_check,semantic_scholar,,2017-01-01,semantic_scholar,information management for enabling systems medicine,https://www.semanticscholar.org/paper/826ac2113812ee288da45f585759f81318ce4c85,"Abstract Systems medicine is a data-oriented approach in research and clinical practice to support study and treatment of complex diseases. It relies on well-defined information management processes providing comprehensive and up to date information as basis for electronic decision support. The authors suggest a three-layer information technology (IT) architecture for systems medicine and a cyclic data management approach including a knowledge base that is dynamically updated by extract, transform, and load (ETL) procedures. Decision support is suggested as case-based and rule-based components. Results are presented via a user interface to acknowledging clinical requirements in terms of time and complexity. The systems medicine application was implemented as a prototype.",data oriented architecture,62,not included
61f0f98f644912b1c71d137a829db60782eebd63,to_check,semantic_scholar,IEEE Access,2020-01-01,semantic_scholar,cyber physical and social networks in iov (cpsn-iov): a multimodal architecture in edge-based networks for optimal route selection using 5g technologies,https://www.semanticscholar.org/paper/61f0f98f644912b1c71d137a829db60782eebd63,"Humans are blessed with the intelligence to create links, develop semantic metaphors and models for reasoning; construct rules for decision making; and to form bounded loops for interaction, socialization and knowledge sharing. But machines are inadequate with these extraordinary abilities rather, numerous algorithms and mathematical models can be used to connect physical resources with cyberspaces to control objects and, develop cognitive learning for optimal decision making. Connected users and devices in closed virtual and physical proximity give direction towards the plethora of real-world applications for physical, social and, cyber computing. Because of the increase in social media networking and 5G communication links offer real-time crowdsourcing and sensing as a complementary base for information. Proceeding this idea, in this study we have proposed Cyber-Physical and Social Networks (CPSN) for two fundamental operations in IoV (Internet of Vehicles) as CPSN-IoV; (1) to define conceptual architecture of CPSN-IoV for data-oriented network for smart infrastructure and, (2) to create the significant virtual space where the instances of smart vehicles, devices, and things will have meaningful links with the real world objects where, CPSN-IoV will evolve, emerge, compete, and collaborate with all connected objects to strengthen the decision making process. To investigate the potential impact of our proposed study, we have simulated the taxicab trajectory data of the urban city of Portugal in OMNeT++ for the in-depth understanding of road topology, connected vehicles and things, and their traffic trends; and users’ social media streams in respective edge for efficient route planning. The results of simulation demonstrate that our proposed framework has the ability to achieve human-machine intellectual association for managing the smart environment.",data oriented architecture,63,not included
141ac67c51134b03e993dca1a4e038266c6a45aa,to_check,semantic_scholar,WABBWUAS@UMAP,2010-01-01,semantic_scholar,generic adaptation process,https://www.semanticscholar.org/paper/141ac67c51134b03e993dca1a4e038266c6a45aa,Adaptive Hypermedia Systems (AHS) have long been mainly represented by domain- or application-specific systems. Few reference models exist and they provide only a brief overview of how to describe and organize the ‘adaptation process’ in a generic way. In this paper we consider the process aspects of AHS from the very first classical ‘user modelling-adaptation’ loop to a generic detailed flowchart of the adaptation in AHS.We introduce a Generic Adaptation Process and by aligning it with a layered (data-oriented) AHS architecture we show that it can serve as the process part of a new reference model for AHS.,data oriented architecture,64,not included
2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,to_check,semantic_scholar,,2005-01-01,semantic_scholar,model checking circus,https://www.semanticscholar.org/paper/2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,"As software complexity increases, so does the need for precision. For some areas, such as high-integrity and safety-critical domains, this precision is imperative rather than optional. To address this issue, both academia and industry have been applying formal methods and formal verification techniques, where model checking and theorem proving are the most successful. Model checking is a verification technique that exhaustively searches the state space of a system represented by some formal notation. It became a successful technique applied by both academia and industry, due to its high level of automation and the ability to provide counter-examples as a debugging device in the case of failure. The difficulty of applying this technique is the state explosion problem that often happens in software verification, hence making such technique unsuitable for representation by computer. In order to finitely represent infinite state systems to be analysed by computer, one needs to resort to the more powerful technique of theorem proving. It allows precise description with less compromise on the state representation, as it uses symbols and quantifiers rather than actual values. The problem is that the higher the expressiveness of a notation, the lower the level of automation that it supports and greater the demand for user expertise and interactivity. The maturity of these techniques, as well as the wide availability of tools, pushed the demand for more expressive techniques with powerful automation tool support. Thus, combination of formalisms and their tools have become a topic of great interest in current research in formal methods. The combination of formalisms usually involve blending mature techniques that cover different aspects of software development in a common semantical framework. For instance, combining data oriented languages, such as Z and B, with behaviour oriented languages, such as CCS and CSP has been the focus of considerable research. The next step in this direction is to provide tool support for these combined languages. The combination of model checking and theorem proving have become the state-of-the-art in terms of tool development for formal verification techniques, as it combines expressiveness with high levels of automation. In this thesis, our main goal is to provide model checking support with integrated theorem proving for Circus, a concurrent language for refinement that combines Z, CSP, and the refinement calculus. Its semantic model is based on Hoare and He’s Unifying Theories of Programming (UTP), which provides an integrated theoretical framework for development and extension of different programming paradigms. From the partnership of our research group with QinetiQ Malvern, it is clear that there is demand for integrated formalisms and respective tool support. Our aim is to provide tool support for Circus, in order to allow its use in real applications, where we are able to formally specify different aspects of systems including, but not limited to, data and behaviour. As Circus is based in UTP, it is possible to integrate other aspects, such as mobility, and real-time, and research in these fronts is well advanced. To fulfill our goal, we provided an operational semantics for model checking Circus, which enables the representation of Circus programs as automata, as well as a search algorithm enabling us to establish refinement between two programs. Throughout the development process, we have decided to take our own medicine and use formal specification and verification, in order to increase the levels of integrity of our tools and techniques. The semantics and the underlying automata theory has been formally defined and mechanised in the Z/Eves theorem prover. Next, we proposed a model checking architecture, which integrates theorem proving facilities, and is implemented as a model checker prototype in Java. This architecture has been formally defined in Circus itself, and we augmented the Java code with JML annotations and assertions representing our findings from the formal specification. Finally, from the abstract Circus specification of the model checker architecture, we calculated a sequential refinement search algorithm using Circus refinement laws, where generated proof obligations have been discharged using Z/Eves again. This effort gave rise to a prototype model checking tool for Circus, which integrates refinement model checking with theorem proving in an extensible framework compliant with the Z Standard.",data oriented architecture,65,not included
44c75858494b9aecb62b9c50fe4cea48a7e045d1,to_check,semantic_scholar,"CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.",2003-01-01,semantic_scholar,a method to find unique sequences on distributed genomic databases,https://www.semanticscholar.org/paper/44c75858494b9aecb62b9c50fe4cea48a7e045d1,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled. Hence, it becomes feasible to analyze the entire genomic information all at once. On the other hand, the quantity of the genomic information stocked on databases is increasing day after day. In order to process the whole information, we have to develop an effective method to deal with lots of data. Therefore, it is indispensable not only to make an effective and rapid algorithm but also to use high-speed computer resource so as to analyze the biological information. For this purpose, as one of the most promised computing environments, the grid computing architecture has appeared recently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11]. In the field of bioinformatics, it is important to find unique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found they can be useful for target specific probes/primers design, gene sequence comparison and so on. In this paper, we propose a method to discover unique sequences from among genomic databases located in a distributed environment. Next, we implement this method upon the European Data Grid and show the calculation results for E. coli genomes.",data oriented architecture,66,not included
59bb50285c3e3807a03617b98aac00233cc5ce28,to_check,semantic_scholar,2010 IFIP Wireless Days,2010-01-01,semantic_scholar,a software radio architecture for the baseband level of the multi-standard user terminal: design methodology and computational assessment,https://www.semanticscholar.org/paper/59bb50285c3e3807a03617b98aac00233cc5ce28,In this paper we present a design methodology and system prototyping for the baseband level of the Software Defined Radio (SDR)-based portable multi-standard terminal. The SDR-based architecture consists of three main layers denoted as: i) Upper Layer to provide communication with an end user and a network; ii) Middle Layer to establish the required protocol configuration; and iii) Bottom Layer to execute the protocol algorithm. Main concern was based on the examination of the SDR-based module behavior in the heterogeneous environment. As a case study we have chosen two different wireless communication standards: data-oriented WiMAX (IEEE 802.16d) and voice-oriented UMTS (release 1999). The simulation of the digital signal processing for both standards was performed in the MATLAB environment. The goal is to achieve and to verify the given system configuration depending on the environment characteristics. For this reason we show that SDR-based module can recognize the required protocol configuration and tune the system accordingly.,data oriented architecture,67,not included
96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,to_check,semantic_scholar,Proceedings 11th International Workshop on Database and Expert Systems Applications,2000-01-01,semantic_scholar,an object-based architecture for wap-compliant applications,https://www.semanticscholar.org/paper/96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,"The Wireless Application Protocol (WAP) is an emerging standard for the deployment of data oriented applications in wireless environments. Although some components of the WAP suite have been developed, it lacks a complete general architecture integrating software components of both the Internet and wireless contexts in a transparent way. The paper presents a general architectural framework to develop and deploy portable applications and services accessible by WAP-compliant mobile terminals, extending end-to-end services between terminal and business applications. Moreover, a technique to handle client disconnection is presented.",data oriented architecture,68,not included
a96539c753dd3b547cd5a3f390b6678b63c0d648,to_check,semantic_scholar,2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS),2021-01-01,semantic_scholar,iot microservice architecture for iotaas device users,https://www.semanticscholar.org/paper/a96539c753dd3b547cd5a3f390b6678b63c0d648,"Scaling up the Internet of Things (IoT) as a service (IoTaaS) is still facing many challenges including the demand of IoTass users to gain a more privilege access on IoT device to configure necessary parameters such as data rate and actuator rotation speed for custom object tracking methods. To address this challenge, this paper aims to propose a micro service architecture of IoT, particularly to provide configurable IoT device platform. Compared to previous works focusing on data-oriented high-level architecture of IoT solution, the proposed architecture provides a solution for IoT device users and, hence, this study is critical to extend the capabilities of IoTaaS.",data oriented architecture,69,not included
00c4a804484051d385c992e2221bc406a54aa598,to_check,semantic_scholar,Int. J. Digit. Libr. Syst.,2011-01-01,semantic_scholar,a presentation-preserved compositional approach for integrating heterogeneous systems: using e-learning as an example,https://www.semanticscholar.org/paper/00c4a804484051d385c992e2221bc406a54aa598,"In traditional SCW environments, related web services are integrated into business processes. Web service still brings less than expected benefits to small corporations and end-users for two reasons: 1 the web service only focuses on data level and is difficult to implement the presentation-centric business contexts. 2 The small corporations and end-users usually do not have enough IT competences to write a client or user interface to interact with web services. In order to solve these problems, the author proposes a presentation-preserved compositional approach for service-oriented architecture PCSOA, which extends the existing data-oriented compositional approaches for web services to provide a more flexible methodology to orchestrate both data level and presentation level services during the workflow integration. A prototype is also built to validate the feasibility of the approach.",data oriented architecture,70,not included
fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,to_check,semantic_scholar,,2018-01-01,semantic_scholar,a research on the security of wisdom campus based on geospatial big data,https://www.semanticscholar.org/paper/fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,"Wang Haiying School of Land and Resource China West Normal University Nanchong, China e-mail: wanghaiying8228@163.com Abstract— There are some difficulties in wisdom campus, such as geospatial big data sharing, function expansion, data management, analysis and mining geospatial big data for a characteristic, especially the problem of data security can't guarantee cause prominent attention increasingly. In this article we put forward a data-oriented software architecture which is designed by the ideology of orienting data and data as kernel, solve the problem of traditional software architecture broaden the campus space data research, develop the application of wisdom campus.",data oriented architecture,71,not included
442567e7d47373f6d305a249b7ae05b81d15782e,to_check,semantic_scholar,"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",2019-01-01,semantic_scholar,consideration and research on data architecture for the future cyber society,https://www.semanticscholar.org/paper/442567e7d47373f6d305a249b7ae05b81d15782e,"The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.",data oriented architecture,72,included
7f7553beefdf3579a6759b97ef41948c1fc79c57,to_check,semantic_scholar,iiWAS,2017-01-01,semantic_scholar,a data-oriented architecture for loosely coupled real-time information systems,https://www.semanticscholar.org/paper/7f7553beefdf3579a6759b97ef41948c1fc79c57,"In this paper, we present an architectural pattern called Data Oriented Architecture (DOA). Motivation is the fact that on the one hand we face a shift to the usage of more and more mobile devices but on the other hand most services in the Internet still use a classic client-server-approach. Data is mainly produced at private devices today and put on centralized servers afterwards. This situation reflects the actual reality better: data is shared directly among users without the need of centralized sources. Three key facts distinguish DOA from existing approaches: First, DOA does not bind data to a specific location. Data is defined by the application which produced it and not an address of a location where it is currently stored. Second, DOA is a holistic approach that comprises a suitable data structure, data access methods and a message exchange protocol. Thus, DOA can be easily implemented and used right away. Third, in DOA, users can decide which data they want to keep private and which data they want to share. Shared data becomes a ""public good"" that is not owned by a specific entity but belongs to the community.",data oriented architecture,73,included
01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,to_check,semantic_scholar,,2018-01-01,semantic_scholar,research on digital power grid information integration solution,https://www.semanticscholar.org/paper/01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,"Information integration is an important part of the digital grid architecture. The purpose is to solve the information interaction obstacles between heterogeneous systems on the basis of making full use of the old system. This paper analyzes the development stage of digital power grid information integration from the perspective of information integration, and points out that the information integration of current digital power grid is mainly data-oriented integration. Based on the characteristics of digital power grid information integration, this paper puts forward a digital power grid information Integration solution combining horizontal information integration and vertical information integration, designs the overall architecture of digital power grid information integration, and elaborates the horizontal integration and vertical integration respectively.",data oriented architecture,74,not included
cddb42247b854abce14ee1e059f332f42be54c5d,to_check,semantic_scholar,2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP),2015-01-01,semantic_scholar,rapid customization of image processors using halide,https://www.semanticscholar.org/paper/cddb42247b854abce14ee1e059f332f42be54c5d,"Image processing applications typically involve data-oriented kernels with limited control divergence. In order to efficiently exploit the data level parallelism, image processors include SIMD instructions and other parallel computation resources. Generic processors that can be purchased off-the-shelf are adequate for most of the use scenarios of image processing. However, especially with embedded mobile devices, they might not be optimal for the algorithm, the environment, or the energy budget at hand. Such cases call for programmable customized architectures with just enough hardware resources to ensure the high priority applications reach their real time goals with minimal overheads. In order to maintain high engineer productivity, implementing image algorithms for customized processors should be as easy as with standard processors. This is emphasized at the processor co-design time; because the program is used to drive the processor design space exploration towards an optimized architecture, assembly programming is not feasible due to the required porting effort whenever the architecture is modified. In this paper we propose an image processor customization flow that exploits the domain-specific Halide language as an input to a processor co-design environment. In addition to efficiently exploiting standard resources in the customized processors, the flow provides an easy way to invoke special instructions from Halide programs. We validate the performance benefits of custom operations using example filters described with the Halide language.",data oriented architecture,75,not included
de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,to_check,semantic_scholar,2017 International Carnahan Conference on Security Technology (ICCST),2017-01-01,semantic_scholar,"encrypted computing: speed, security and provable obfuscation against insiders",https://www.semanticscholar.org/paper/de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,"Over the past few years we have articulated theory that describes ‘encrypted computing’, in which data remains in encrypted form while being worked on inside a processor, by virtue of a modified arithmetic. The last two years have seen research and development on a standards-compliant processor that shows that near-conventional speeds are attainable via this approach. Benchmark performance with the US AES-128 flagship encryption and a 1GHz clock is now equivalent to a 433MHz classic Pentium, and most block encryptions fit in AES's place. This summary article details how user data is protected by a system based on the processor from being read or interfered with by the computer operator, for those computing paradigms that entail trust in data-oriented computation in remote locations where it may be accessible to powerful and dishonest insiders. We combine: (i) the processor that runs encrypted; (ii) a slightly modified conventional machine code instruction set architecture with which security is achievable; (iii) an ‘obfuscating’ compiler that takes advantage of its possibilities, forming a three-point system that provably provides cryptographic ‘semantic security’ for user data against the operator and system insiders.",data oriented architecture,76,not included
1ee9b2571008acac45a7f27b205df71b6cbf756a,to_check,semantic_scholar,2019 IEEE Global Communications Conference (GLOBECOM),2019-01-01,semantic_scholar,mc-track: a cloud based data oriented vehicular tracking system with adaptive security,https://www.semanticscholar.org/paper/1ee9b2571008acac45a7f27b205df71b6cbf756a,"In this paper, we propose Mc-Track, a new secure data oriented Cloud based vehicular tracking system. We introduced in Mc-Track an adaptive approach which consists in selection of security level according to data kinds. The architecture of the Mc-Track is composed of three levels: the vehicular network, the Cloud service, and proxies called Tracking Authorities, in charge of performing Attribute Based Encryption (ABE). We provided selective encryption and adaptive security in the Tracking Authority (TA), using the machine learning classifier k-Nearest Neighbours (k-NN). We conducted experimental study to evaluate the efficiency of the proposed k-NN classifier in selective encryption and adaptive security. So we compared the accuracy of the predictions of k-NN classifier to the accuracy of predictions using Support Vector Machine (SVM) classifier. Experimental results, has shown that the k-NN classifier is more accurate than SVM classifier.",data oriented architecture,77,included
bf25baf2eac5677cad335addbfab8b1c51ee360e,to_check,semantic_scholar,,2003-01-01,semantic_scholar,a method to find uniq e sequences on distrib ted genomic databases,https://www.semanticscholar.org/paper/bf25baf2eac5677cad335addbfab8b1c51ee360e,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled.Hence, it becomes feasible to analyze the entire genomicinformation all at once. On the other hand, the quantity ofthe genomic information stocked on databases is increasingday after day. In order to process the whole information, wehave to develop an effective method to deal with lots of data.Therefore, it is indis ensable not only to make an effectiveand rapid algorithm but also to use high-speed computerresource so as to analyze the biological information. Forthis purpose, as one of the most promised computing environments, the grid computing architecture has appearedrecently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11].In the field of bioinformatics, it is important to findunique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found, theycan be useful for target specific probes/primers design, genesequence comparison and so on. In this paper, we propose amethod to discover unique sequences from among genomicdatabases located in a distributed environment. Next, weimplement this method upon the European Data Grid andshow the calculation results for E. coli genomes.",data oriented architecture,78,not included
88af34df634edebdfe39871f82166e61ad0a4835,to_check,semantic_scholar,,2010-01-01,semantic_scholar,electronic communications of the easst volume 28 ( 2010 ) proceedings of the third international discotec workshop on context-aware adaptation mechanisms for pervasive and ubiquitous services ( campus 2010 ) modelling feedback control loops for self-adaptive systems,https://www.semanticscholar.org/paper/88af34df634edebdfe39871f82166e61ad0a4835,"Feedback Control Loops (FCLs) are the heart of any self-adaptive system. Existing engineering approaches for building self-ad aptive systems mask FCL by providing abstraction layers that hide the application c mplexity. In this paper, we investigate a model-driven approach for the engineering of FCLs whose architecture is based on the Service Component Architecture (SCA) model. Our proposal consists in exploiting the data streaming model, to specify the characteristics of the control policies, and to generate FCLs of self-adaptive sys tem deployed in largescale environment. We argue that the use of a data-oriented m odel for designing self-adaptive systems significantly increases FCL visibil ity.",data oriented architecture,79,not included
05fbbfb5cdab641e15c49690064b9aa1728bd2c3,to_check,semantic_scholar,,2015-01-01,semantic_scholar,non-volatile in-memory computing,https://www.semanticscholar.org/paper/05fbbfb5cdab641e15c49690064b9aa1728bd2c3,"The analysis of big-data at exa-scale (1018 bytes or flops) has called for an urgent need to re-examine the existing hardware platform that can support intensive data-oriented computing. A big-data-driven application requires huge bandwidth and yet able to ensure low-power density. For example, web-searching application involves crawling, comparing, ranking, and paging of billions of web-pages with extensive memory access. The existing memory technologies have critical challenges of scaling at nano-scale due to process variation, leakage current and I/O access limitations. Recently, the emerging non-volatile memory (NVM) technologies such as resistive-RAM (ReRAM), spintransfer torque RAM (STT-RAM), domain-wall nanowire racetrack memory etc., have all shown significantly reduced standby power and increased integration density, not forgetting the close-to DRAM/SRAM access speed. Therefore, they are considered as promising candidates of universal memory for future big-data applications. The primary challenge to validate a hybrid design with both CMOS and nonvolatile devices is the lack of design platform that can validate the large-scale NVM circuit and system design accurately and efficiently. In addition, due to the use of non-electrical states of emerging NVM devices, new cells structures and their agreeing circuits for both read and write operations are needed to harness non-volatile memory with unique operations. For example, the transistor-free crossbar array that associates with NVM is different from conventional access transistor based memory structure. What is more, leveraging the NVM for computing, one also needs to examine the potential logic-inmemory computing architecture with significantly improved bandwidth and reduced power. In order to tackle above challenges ranging from device to system levels, this PhD thesis has explored the development of NVM design platform to support designs of non-volatile memories, readout and logic circuit designs, as well as the in-memory computing architecture. For the NVM design platform, the target is to perform accurate yet efficient circuit level simulation. The previous approaches either ignore dynamic effect without considering non-volatile states for dynamic behavior, or need equivalent circuits with high complexity to curve-fit non-linearity of those devices. We proposed a SPICE simulaiii tor named NVM-SPICE. This tool takes advantages of its new modified nodal analysis (MNA) framework, which can effectively support the non-electrical state variables of emerging non-volatile devices, such as ReRAM and spintronics devices. Due to the physics based modeling approach, NVM-SPICE is able to perform hybrid NVM/CMOS circuits efficiently and accurately. Compared to the equivalent circuit model based approach, the NVM-SPICE simulator exhibits more than 117x faster simulation speed for spintronics category devices and 40x faster speed for RRAM category devices. For NVM in-memory architecture, both memory elements and logic elements are implemented by emerging spintronics devices, which leads to a system purely composed of non-volatile devices. The detailed non-volatile memory and logic circuits are explored within the NVM-SPICE platform. In addition, logic is built inside the memory so that the I/O workload can be alleviated. Applications such as data retention, encryption, machine learning that play critical roles for big-data computing are explored within the non-volatile in-memory architecture. The evaluation results show that the purely non-volatile memory based platforms with in-memory architecture greatly contribute to power efficiency and throughput improvement for big-data oriented applications, and thus are potential candidates to be next generation information and communication technology.",data oriented architecture,80,not included
04887833a763e3025714350a9ec3b547be731214,to_check,semantic_scholar,Wirel. Pers. Commun.,2017-01-01,semantic_scholar,trends in the evolution of voice services: a comprehensive survey,https://www.semanticscholar.org/paper/04887833a763e3025714350a9ec3b547be731214,"Mobile network operators are increasingly striving to substitute legacy telecommunication technologies in their networks with the contemporary ones. Modern, future-proof architecture that provides better service quality, requires easier and cheaper maintenance, and consequently brings greater financial benefits is the main driving force for that action. In this moment, Long Term Evolution (LTE) deployment is a goal most mobile network operators are aspiring to. This paper describes presently ongoing changes in the mobile communication networks from the perspective of voice services they provide. Namely, LTE network is, so far, mainly recognized as a “data oriented” network. Having in mind enormous mobile data traffic increase, deployment of that kind of network is fully understandable and justified. However, voice services are still important part of telecommunications’ market offer. So, the above mentioned changes are leading not only toward satisfaction of growing needs regarding mobile data traffic, but also toward utilization of LTE network attributes for the purposes of voice communication. Complete transformation of mobile networks architecture and evolution of traditional voice communication will occur in the process. So far, that evolution has resulted with development of a mechanism know as voice over LTE. However, the mentioned changes are coming gradually and will take a certain time to be fully accomplished. In the meantime, some transition solutions are defined and deployed, in order to enable uninterrupted provisioning of voice services. Their description is included in the paper as well. At the end, relevant forecasts of several network parameters have been discussed.",data oriented architecture,81,not included
47963243de795b321fe10edb46a3a9d1931960ec,to_check,semantic_scholar,,1998-01-01,semantic_scholar,toward an exemplar-based computational model for cognitive grammar,https://www.semanticscholar.org/paper/47963243de795b321fe10edb46a3a9d1931960ec,"An exemplar-based computational framework is presented which is compatible with Cognitive Grammar. In an exemplar-based approach, language acquisition is modeled as the incremental, data-oriented storage of experiential patterns, and language performance as the extrapolation of information from those stored patterns on the basis of a language-independent information-theoretic similarity metric. We show that this simple architecture works for many aspects of phonological, morphological, and morphosyntactic acquisition and processing. Furthermore, we sketch how the approach may also work for syntactic processing. A central insight of the approach, based on the results of computational modeling experiments, is that abstraction of representations is not only unnecessary to achieve generalization (i.e. to make the system productive, and to make it gòbeyond' the learned patterns), but even harmful, and that useful language-independent metrics can be found for deening similarity in the context of language processing. In the generative tradition, generality is achieved by means of abstraction, and the representations of choice to describe these abstractions are rules. This implies that redundancy and the storage of individual instances are to be avoided, except for exceptions to the generalizations expressed in rules. In Langacker, 1991 (Chapter 10), this methodology is critically examined, and cognitive grammar is described as an alternative usage-based model of language structure. In the latter, bottom-up, approach, patterns (rules, generalizations) and (redundant) instantiations of those rules are assumed to co-exist in the grammar, describing phenomena at all levels of generality, from exceptionless regularities to idiosyncratic exceptions. Rules are presumed to be necessary for the computation of novel instantiations. In the remainder of this paper we will introduce an exemplar-based approach to language acquisition and processing. The approach is in large part compatible with Lan-gacker's usage-based model, but is more radical in its ""maximalism"": language knowledge is supposed to consist only of ""instantiations"" (exemplars); there is no role for explicit abstractions corresponding to (sub)regularities. We will argue on the basis of computational modeling experiments that the adoption of abstractions (rules, patterns), taken as necessary for explaining generalization and productivity in both the generative and the cognitive grammar approach, is misguided. Furthermore, the exemplar-based approach contributes to making cognitive grammar ideas more concrete by providing computational operationalisations of both acquisition and processing in such a framework.",data oriented architecture,82,not included
5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,to_check,semantic_scholar,,2010-01-01,semantic_scholar,software design and class diagrams,https://www.semanticscholar.org/paper/5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,"ion • ignoring detail to get the high level structure right Decomposition and Modularization • big systems are composed from small components Encapsulation/information hiding • the ability to hide detail (linked to abstraction) Defined interfaces • separable from implementation Evaluation of structure • Coupling: How interlinked a component is • Cohesion: How coherent a component is © 2004-2007 SEOC Lecture Note 04 5 Architecture and Structure Architectural structures and viewpoints Architectural styles Design patterns • small-scale patterns to guide the designer Families and frameworks • component sets and ways of plugging them together • software product lines Architectural design Architectural structures and viewpoints deal with system facets (e.g., physical view, functional or logical view, security view, etc.) separately. Depending on the architectural emphasis, there are different styles, for example, Three-tier architecture for a distributed system (interface, middleware, back-end database), Blackboard, Layered architectures, Model-View-Controller, Time-triggered and so forth. Architectural Design supports stakeholder communication, system analysis and large-scale reuse. It is possible to distinguish diverse design strategies: function oriented (sees the design of the functions as primary), data oriented (sees the data as the primary structured element and drives design from there), object oriented (sees objects as the primary element of design). There is no clear distinction between Sub-systems and modules. Intuitively, sub-systems are independent and composed of modules, have defined interfaces for communication with other sub-systems. Modules are system components and provide/make use of service(s) to/provided by other modules. The system architecture affects the quality attributes (e.g., performance, security, availability, modifiability, portability, reusability, testability, maintainability, etc.) of a system. It supports quality analysis (e.g., reviewing techniques, static analysis, simulation, performance analysis, prototyping, etc.). It allows to define (predictive) measures (i.e., metrics) on the design, but they are usually very dependent on the process in use. The software architecture is the fundamental framework for structuring the system. Different architectural models (e.g., system organizational models, modular decomposition models and control models) may be developed. Design decisions enhance system attributes like, for instance, performance (e.g., localize operations to minimize sub-system communication), security (e.g., use a layered architecture with critical assets in inner layers), safety (e.g., isolate safety-critical components), availability (e.g., include redundant components in the architecture) and maintainability (e.g., use fine-grain self-contained components). Readings • P. Kruchten, H. Obbink, J. Stafford. The Past, Present and Future of Software Architecture. IEEE Software, March/April 2006. © 2004-2007 SEOC Lecture Note 04 6 Architecture Models A static structural model that shows the subsystems or components that are to be developed as separate units. A dynamic process model that shows how the system is organized into processes at run-time. This may be different from the static model. An interface model that defines the services offered by each sub-system through their public interface. A relationship model that shows relationships such as data flow between the sub-systems. Comparing Architecture Design Notations • Modeling Components: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Connectors: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Configurations: Understandable Specifications, Compositionality (and Conposability), Refinement and Traceability, Heterogeneity, Scalability, Evolvability, Dynamism, Constraints, Non-functional Properties UML Design Notations • Static Notations: Class and object diagrams, Component diagrams, Deployment diagrams, CRC Cards • Dynamic Notations: Activity diagrams, Communication diagrams, Statecharts, Sequence diagrams What are the Architect’s Duties? • Get it Defined, documented and communicated, Act as the emissary of the architecture, Maintain morale • Make sure everyone is using it (correctly), management understands it, the software and system architectures are in synchronization, the right modeling is being done, to know that quality attributes are going to be met, the architecture is not only the right one for operations, but also for deployment and maintenance • Identify architecture timely stages that support the overall organization progress, suitable tools and design environments, (and interact) with stakeholders • Resolve disputes and make tradeoffs, technical problems • Manage risk identification and risk mitigation strategies associated with the architecture, understand and plan for evolution © 2004-2007 SEOC Lecture Note 04 7 Class Diagrams Support architectural design • Provide a structural view of systems Represent the basics of Object-Oriented systems • identify what classes there are, how they interrelate and how they interact • Capture the static structure of Object-Oriented systems how systems are structured rather than how they behave Constrain interactions and collaborations that support functional requirements • Link to Requirements",data oriented architecture,83,not included
f323b4f434bdfc48836d8eebd5cf267c9258aa09,to_check,semantic_scholar,BDCA'17,2017-01-01,semantic_scholar,exploiting open data to improve the business intelligence & business discovery experience,https://www.semanticscholar.org/paper/f323b4f434bdfc48836d8eebd5cf267c9258aa09,"The extent to which data mining tools are able to make efficient use of an open data oriented strategy in a smart city is limited. In a sense that it is not fully automated, incompatible or has to be supervised. These sets of tools may offer the possibility to import a dataset in a certain predefined standardized format, still, they do not make it a part of their workflow and algorithms in a fully unsupervised manner (i.e without ongoing human guidance). In a departure from previous research works, in this paper, we present a middleware architecture that exploits open data as background knowledge by acting as a bridge between data mining tools and open data resources.",data oriented architecture,84,not included
10.1007/978-3-030-88207-5_17,to_check,"Cooperative Design, Visualization, and Engineering",Springer,2021-01-01 00:00:00,springer,building a big data oriented architecture for enterprise integration,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88207-5_17,"Digital transformation is happening across all industries and affecting all facets of our daily life. However, in many corporations, this important process is fragmented and is undertaken without a farsighted plan to take advantage of an invaluable resource: data. This can be due to a variety of reasons, for example, lack of funding, poor business vision, inappropriate consulting or deployment. Digital transformation is a considerable investment since it will determine the system’s ability to grow and adapt to the company’s changing requirements. To achieve that end, the architecture must be flexible both in development and deployment and must also be able to harness the ever-increasing data of the corporation. Among the widely used information system architectures being used in the world, Micro-service is a standout with many advantages. The adaptation of this architecture to work with Big Data, as well as to tackle different aspects of a data system such as load-balancing, file handling and storage, etc. is a very practical area of research. This paper presents such an enterprise integration solution for a mega-corporation client in Vietnam, the An Pha Petrol Group Joint Stock Company, including the architecture and technologies used to build a comprehensive system that brings novel experiences to its 2,000 internal users. It consists of building the information infrastructure and system, super applications for both desktop and mobile devices to enhance the work performance and quality. The approaches and results of this paper are applicable to similar large enterprise solutions.",data oriented architecture,85,included
10.1109/cast.2016.7914932,to_check,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",IEEE,2016-12-21 00:00:00,ieeexplore,big data architecture with mobile cloud in cdroid operating system for storing huge data,https://ieeexplore.ieee.org/document/7914932/,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,data centric architecture,86,included
10.1109/trustcom.2016.0248,to_check,2016 IEEE Trustcom/BigDataSE/ISPA,IEEE,2016-08-26 00:00:00,ieeexplore,rethinking high performance computing system architecture for scientific big data applications,https://ieeexplore.ieee.org/document/7847131/,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",data centric architecture,87,included
10.1109/tcc.2015.2474385,to_check,IEEE Transactions on Cloud Computing,IEEE,2020-06-01 00:00:00,ieeexplore,cross-cloud mapreduce for big data,https://ieeexplore.ieee.org/document/7229313/,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",data centric architecture,88,included
http://arxiv.org/abs/1705.04958v1,to_check,arxiv,arxiv,2017-05-14 00:00:00,arxiv,a proposed architecture for big data driven supply chain analytics,http://arxiv.org/abs/1705.04958v1,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.",data centric architecture,89,included
10.1007/978-3-319-75429-1_18,to_check,Integrated Uncertainty in Knowledge Modelling and Decision Making,Springer,2018-01-01 00:00:00,springer,big data driven architecture for medical knowledge management systems in intracranial hemorrhage diagnosis,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75429-1_18,"Stroke is the most common and dangerous cerebrovascular disease. According to the statistics from World Health Organization (WHO), only following heart attack, stroke is one of the two leading causes of human deaths. In addition, in Vietnam, a shortage of specialized equipment and qualified professionals is becoming a significant problem for not only accurate diagnosis but also timely and effective treatment of stroke, especially intracranial hemorrhage (ICH), an acute case of stroke. This research will analyze challenges and show solutions for constructing an effective knowledge system in ICH diagnosis and treatment that helps to shorten professional gap among hospitals and regions. We suggest a service-oriented architecture for the big data driven knowledge system based on medical imaging of ICH. The architecture ensures the development of knowledge obeying a systematic and complete process including the exploration and exploitation of knowledge from medical imaging. Besides, the architecture adapts to modern trends in knowledge service modeling.",data driven architecture,90,included
10.1007/978-3-319-07863-2_21,to_check,Human Interface and the Management of Information. Information and Knowledge in Applications and Services,Springer,2014-01-01 00:00:00,springer,data driven enterprise ux: a case study of enterprise management systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07863-2_21,"This paper describes and makes a case for a data driven user experience design process for Enterprise IT. The method described employs an approach that focuses on defining the key modules (objects) in an enterprise IT software and the data sets used by these modules very early in the design process. We discuss how mapping parent child relationships between key entities in the software and the linked data helps create a holistic view of the product ecosystem which in turn allows the designer to create an uncluttered information architecture and user journey that maps closely to mental construct of the system in the user’s mind. We further argue that in the present age of big data, working with well-defined data sets and visible data relationships creates a valuable information repository for the designer to take decisions regarding task optimization and building business intelligence in the system itself. We also discuss the urgent need, advantages and methods of ‘consumerizing’ the Enterprise UI to increase users productivity and reduce the learning curve. Lastly, these ideas are exemplified through a real life case study for an enterprise server management system.",data driven architecture,91,not included
7ee214c411ca42c323af6e6cdc96058d5140aefe,to_check,semantic_scholar,"2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)",2018-01-01,semantic_scholar,service-oriented architecture for big data analytics in smart cities,https://www.semanticscholar.org/paper/7ee214c411ca42c323af6e6cdc96058d5140aefe,"A smart city has recently become an aspiration for many cities around the world. These cities are looking to apply the smart city concept to improve sustainability, quality of life for residents, and economic development. The smart city concept depends on employing a wide range of advanced technologies to improve the performance of various services and activities such as transportation, energy, healthcare, and education, while at the same time improve the city's resources utilization and initiate new business opportunities. One of the promising technologies to support such efforts is the big data technology. Effective and intelligent use of big data accumulated over time in various sectors can offer many advantages to enhance decision making in smart cities. In this paper we identify the different types of decision making processes involved in smart cities. Then we propose a service-oriented architecture to support big data analytics for decision making in smart cities. This architecture allows for integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations needed to effectively utilize available big data. It provides different functions and capabilities to use big data and provide smart capabilities as services that the architecture supports. As a result, different big data applications will be able to access and use these services for varying proposes within the smart city.",data oriented architecture,92,not included
af225b810dfc8a90eb07c8f225dbf530fbb7c1dd,to_check,semantic_scholar,Big Data Cogn. Comput.,2020-01-01,semantic_scholar,mobda: microservice-oriented big data architecture for smart city transport systems,https://www.semanticscholar.org/paper/af225b810dfc8a90eb07c8f225dbf530fbb7c1dd,"Highly populated cities depend highly on intelligent transportation systems (ITSs) for reliable and efficient resource utilization and traffic management. Current transportation systems struggle to meet different stakeholder expectations while trying their best to optimize resources in providing various transport services. This paper proposes a Microservice-Oriented Big Data Architecture (MOBDA) incorporating data processing techniques, such as predictive modelling for achieving smart transportation and analytics microservices required towards smart cities of the future. We postulate key transportation metrics applied on various sources of transportation data to serve this objective. A novel hybrid architecture is proposed to combine stream processing and batch processing of big data for a smart computation of microservice-oriented transportation metrics that can serve the different needs of stakeholders. Development of such an architecture for smart transportation and analytics will improve the predictability of transport supply for transport providers and transport authority as well as enhance consumer satisfaction during peak periods.",data oriented architecture,93,not included
f64c7a9a3be492f749dfe7ac3c2c8111ed5d0139,to_check,semantic_scholar,IEEE Network,2016-01-01,semantic_scholar,big data in mobile social networks: a qoe-oriented framework,https://www.semanticscholar.org/paper/f64c7a9a3be492f749dfe7ac3c2c8111ed5d0139,"Due to the rapid development of mobile social networks, mobile big data play an important role in providing mobile social users with various mobile services. However, as mobile big data have inherent properties, current MSNs face a challenge to provide mobile social user with a satisfactory quality of experience. Therefore, in this article, we propose a novel framework to deliver mobile big data over content- centric mobile social networks. At first, the characteristics and challenges of mobile big data are studied. Then the content-centric network architecture to deliver mobile big data in MSNs is presented, where each datum consists of interest packets and data packets, respectively. Next, how to select the agent node to forward interest packets and the relay node to transmit data packets are given by defining priorities of interest packets and data packets. Finally, simulation results show the performance of our framework with varied parameters.",data oriented architecture,94,included
b727a990d5a408542afe1bba8bbaca8a53b0fc5f,to_check,semantic_scholar,Softw. Pract. Exp.,2018-01-01,semantic_scholar,towards a data‐driven iot software architecture for smart city utilities,https://www.semanticscholar.org/paper/b727a990d5a408542afe1bba8bbaca8a53b0fc5f,"The Internet of things (IoT) is emerging as the next big wave of digital presence for billions of devices on the Internet. Smart cities are a practical manifestation of IoT, with the goal of efficient, reliable, and safe delivery of city utilities like water, power, and transport to residents, through their intelligent management. A data‐driven IoT software platform is essential for realizing manageable and sustainable smart utilities and for novel applications to be developed upon them. Here, we propose such service‐oriented software architecture to address 2 key operational activities in a smart utility: the IoT fabric for resource management and the data and application platform for decision‐making. Our design uses Open Web standards and evolving network protocols, cloud and edge resources, and streaming big data platforms. We motivate our design requirements using the smart water management domain; some of these requirements are unique to developing nations. We also validate the architecture within a campus‐scale IoT testbed at the Indian Institute of Science, Bangalore and present our experiences. Our architecture is scalable to a township or city while also generalizable to other smart utility domains. Our experiences serve as a template for other similar efforts, particularly in emerging markets and highlight the gaps and opportunities for a data‐driven IoT software architecture for smart cities.",data oriented architecture,95,included
a4146945c83ff6bd6fab6d0e43e655790a4e52ef,to_check,semantic_scholar,WEA 2013,2013-01-01,semantic_scholar,towards an integrated service-oriented reference enterprise architecture,https://www.semanticscholar.org/paper/a4146945c83ff6bd6fab6d0e43e655790a4e52ef,"New business information systems are integrating emerging cloud infrastructures with service-oriented platforms and intelligent user-centered mobile systems. Both architecture engineering and management of service-oriented enterprise architectures is complex and has to integrate synergistic disciplines like EAM - Enterprise Architecture and Management for Services & Cloud Computing, Semantic-based Decision Support through Ontologies and Knowledge-based Systems, Big Data Management, as well as Mobility and Collaboration Systems. It is necessary to identify affected decisions by runtime changes of a service-oriented runtime environment and architecture. We have to make transparent the impact of these changes over the integral landscape of affected EAM-capabilities, like directly and transitively impacted business categories, processes, applications, services, platforms and infrastructures. The paper describes a new Metamodel-based integration approach for Service-oriented Reference Enterprise Architectures.",data oriented architecture,96,not included
051f1e01908ecf02735910828cbdf6d74b1e79b8,to_check,semantic_scholar,2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops,2013-01-01,semantic_scholar,towards service-oriented enterprise architectures for big data applications in the cloud,https://www.semanticscholar.org/paper/051f1e01908ecf02735910828cbdf6d74b1e79b8,"Applications with Service-oriented Enterprise Architectures in the Cloud are emerging and will shape future trends in technology and communication. The development of such applications integrates Enterprise Architecture and Management with Architectures for Services & Cloud Computing, Web Services, Semantics and Knowledge-based Systems, Big Data Management, among other Architecture Frameworks and Software Engineering Methods. In the present work in progress research, we explore Service-oriented Enterprise Architectures and application systems in the context of Big Data applications in cloud settings. Using a Big Data scenario, we investigate the integration of Services and Cloud Computing architectures with new capabilities of Enterprise Architectures and Management. The underlying architecture reference model can be used to support semantic analysis and program comprehension of service-oriented Big Data Applications. Enterprise Services Computing is the current trend for powerful large-scale information systems, which increasingly converge with Cloud Computing environments. In this paper we combine architectures for services with cloud computing. We propose a new integration model for service-oriented Enterprise Architectures on basis of ESARC - Enterprise Services Architecture Reference Cube, which is our previous developed service-oriented enterprise architecture classification framework, with MFESA - Method Framework for Engineering System Architectures - for the design of service-oriented enterprise architectures, and the systematic development, diagnostics and optimization of architecture artifacts of service-oriented cloud-based enterprise systems for Big Data applications.",data oriented architecture,97,not included
83aa94353bb6b870e9f57a2567358b29fcb83507,to_check,semantic_scholar,J. Comput. Inf. Syst.,2018-01-01,semantic_scholar,big data analytics services for enhancing business intelligence,https://www.semanticscholar.org/paper/83aa94353bb6b870e9f57a2567358b29fcb83507,"ABSTRACT This article examines how to use big data analytics services to enhance business intelligence (BI). More specifically, this article proposes an ontology of big data analytics and presents a big data analytics service-oriented architecture (BASOA), and then applies BASOA to BI, where our surveyed data analysis shows that the proposed BASOA is viable for enhancing BI and enterprise information systems. This article also explores temporality, expectability, and relativity as the characteristics of intelligence in BI. These characteristics are what customers and decision makers expect from BI in terms of systems, products, and services of organizations. The proposed approach in this article might facilitate the research and development of business analytics, big data analytics, and BI as well as big data science and big data computing.",data oriented architecture,98,not included
812550cee7ddf225f282d5086a7fb2759cf806fc,to_check,semantic_scholar,Emerging Trends in the Evolution of Service-Oriented and Enterprise Architectures,2016-01-01,semantic_scholar,emerging trends in the evolution of service-oriented and enterprise architectures,https://www.semanticscholar.org/paper/812550cee7ddf225f282d5086a7fb2759cf806fc,"This book presents emerging trends in the evolution of service-oriented and enterprise architectures. New architectures and methods of both business and IT are integrating services to support mobility systems, Internet of Things, Ubiquitous Computing, collaborative and adaptive business processes, Big Data, and Cloud ecosystems. They inspire current and future digital strategies and create new opportunities for the digital transformation of next digital products and services. Services Oriented Architectures (SOA) and Enterprise Architectures (EA) have emerged as a useful framework for developing interoperable, large-scale systems, typically implementing various standards, like Web Services, REST, and Microservices. Managing the adaptation and evolution of such systems presents a great challenge. Service-Oriented Architecture enables flexibility through loose coupling, both between the services themselves and between the IT organizations that manage them. Enterprises evolve continuously by transforming and extending their services, processes and information systems. Enterprise Architectures provide a holistic blueprint to help define the structure and operation of an organization with the goal of determining how an organization can most effectively achieve its objectives. The book proposes several approaches to address the challenges of the service-oriented evolution of digital enterprise and software architectures.",data oriented architecture,99,not included
dfd468bd962a7c6edeeeb1fb3e8250a853608189,to_check,semantic_scholar,ASE BD&SI,2015-01-01,semantic_scholar,fog data: enhancing telehealth big data through fog computing,https://www.semanticscholar.org/paper/dfd468bd962a7c6edeeeb1fb3e8250a853608189,"The size of multi-modal, heterogeneous data collected through various sensors is growing exponentially. It demands intelligent data reduction, data mining and analytics at edge devices. Data compression can reduce the network bandwidth and transmission power consumed by edge devices. This paper proposes, validates and evaluates Fog Data, a service-oriented architecture for Fog computing. The center piece of the proposed architecture is a low power embedded computer that carries out data mining and data analytics on raw data collected from various wearable sensors used for telehealth applications. The embedded computer collects the sensed data as time series, analyzes it, and finds similar patterns present. Patterns are stored, and unique patterns are transmited. Also, the embedded computer extracts clinically relevant information that is sent to the cloud. A working prototype of the proposed architecture was built and used to carry out case studies on telehealth big data applications. Specifically, our case studies used the data from the sensors worn by patients with either speech motor disorders or cardiovascular problems. We implemented and evaluated both generic and application specific data mining techniques to show orders of magnitude data reduction and hence transmission power savings. Quantitative evaluations were conducted for comparing various data mining techniques and standard data compression techniques. The obtained results showed substantial improvement in system efficiency using the Fog Data architecture.",data oriented architecture,100,not included
a4584baccf772622e5dfd57db4f19290ac5f0d73,to_check,semantic_scholar,,2017-01-01,semantic_scholar,a survey of big data architectures and machine learning algorithms in healthcare,https://www.semanticscholar.org/paper/a4584baccf772622e5dfd57db4f19290ac5f0d73,"Big Data has gained much attention from researchers in healthcare, bioinformatics, and information sciences. As a result, data production at this stage will be 44 times greater than that in 2009. Hence, the volume, velocity, and variety of data rapidly increase. Hence, it is difficult to store, process and visualise this huge data using traditional technologies. Many organisations such as Twitter, LinkedIn, and Facebook are used big data for different use cases in the social networking domain. Also, implementations of such architectures of the use cases have been published worldwide. However, a conceptual architecture for specific big data application has been limited. The intention of this paper is application-oriented architecture for big data systems, which is based on a study of published big data architectures for specific use cases. This paper also provides an overview of the state-of-the-art machine learning algorithms for processing big data in healthcare and other applications.",data oriented architecture,101,not included
6c401ae38727e2b6ccc168a7d519a5ca871c7540,to_check,semantic_scholar,Int. J. Syst. Serv. Oriented Eng.,2015-01-01,semantic_scholar,a scalable big stream cloud architecture for the internet of things,https://www.semanticscholar.org/paper/6c401ae38727e2b6ccc168a7d519a5ca871c7540,"The Internet of Things IoT will consist of billions 50 billions by 2020 of interconnected heterogeneous devices denoted as ""Smart Objects:"" tiny, constrained devices which are going to be pervasively deployed in several contexts. To meet low-latency requirements, IoT applications must rely on specific architectures designed to handle the gigantic stream of data coming from Smart Objects. This paper propose a novel Cloud architecture for Big Stream applications that can efficiently handle data coming from Smart Objects through a Graph-based processing platform and deliver processed data to consumer applications with low latency. The authors reverse the traditional ""Big Data"" paradigm, where real-time constraints are not considered, and introduce the new ""Big Stream"" paradigm, which better fits IoT scenarios. The paper provides a performance evaluation of a practical open-source implementation of the proposed architecture. Other practical aspects, such as security considerations, and possible business oriented exploitation plans are presented.",data oriented architecture,102,included
5d93748040f20eb0cf76c417ef96ef39699af610,to_check,semantic_scholar,,2012-01-01,semantic_scholar,editorial: big services era: global trends of cloud computing and big data,https://www.semanticscholar.org/paper/5d93748040f20eb0cf76c417ef96ef39699af610,"N the hot topics on novel information technology include cloud computing, social networking, mobile Internet, and big data. The major goal of cloud computing is to share resources, which consist of infrastructure, platform, software, and business process. When those resources are provisioned as services, the value of cloud computing is realized. From a cloud offering perspective, Infrastructure As A Service (IaaS), Platform As A Service (PaaS), Software As A Service (SaaS), and Business Process As A Service (BPaaS) are typical service delivery types in cloud computing. “Servicelization” is the way of defi ning interfaces for resource sharing. Servicelization is also the way of offering social networking services, big data analytics, and mobile Internet services. In short, “everything as a service” is creating a Big Services era due to the foundational architecture (i.e., Service-Oriented Architecture) of services computing. Those new technologies are creating differentiating business models, application innovations, and computing patterns. In order to illustrate the global trends of cloud computing and associated technologies, I would like to use enterprise architecture as a base to articulate the innovations created and consumed by enterprises. The most popular enterprise architecture standard is The Open Group Architectural Framework (TOGAF), which covers business architecture, application architecture, data architecture, and technology architecture. From a business architecture perspective, cloud computing is creating brand new business models. For example, Instagram leverages cloud computing as a platform to offer photo sharing services integrated with popular social networking sites. After 19 months in operation, it only had 12 employees when it was acquired by Facebook at $1.1 billion. EdX online education service is also built on Amazon’s cloud computing platform to offer courses for students worldwide. A course has been offered to more than 120,000 students in a virtual classroom over the Internet. As for innovations in application architectures, cloud computing speeds up the servicelization of application software. Software has been componentized for reuse and recomposition for creating value-added services. Building APIs-based platforms has become a mainstream approach to focus on extensibility and scalability. Domain-specifi c applications such as human resource management and customer relationship management have dominated the SaaS market. Social networking aspects have been integrated as core enablers of enterprise applications to facilitate effective communications. Large application software vendors are transforming their packaged applications to cloud-based, social-network-enabled, analytics-intensive, and mobile-reachable SaaS offerings. In terms of innovations in data architecture, cloud computing is driven by killer applications. The more applications there are, the more data there is. Moreover, big data needs more computing power and storage provided by cloud computing platforms. Data architecture needs to be redesigned to elaborate on massive domain and industry-specifi c data. Hadoop type of infrastructure has been offered as a service for researchers, data analysts, and developers to process big data in a cost-effective manner. In addition, cloud database is another direction to leverage data and fi les as a base and offer identity management and fi ne-grained APIs. New applications can be built on those APIs and run on mobile devices, web browsers, and other programming tools and environments. The next innovations are around technology architecture. There are three major trends. The fi rst innovation trend is to integrate hardware, software, and service into one box. This type of innovation can hide the complexity of the enterprises’ IT systems and make them cloud ready. Most importantly, the services aspect of the box can capture best practices of operations in various scenarios. Meanwhile, the box provides a development toolkit to enable developers to import knowledge and experiences into the integrated black box. The second innovation trend is to provide open cloud platforms by leading Internet service providers. Application engines, big data analyzing algorithms, cloud storage APIs, and prediction and translation APIs are gradually becoming important tools and assets for open innovations. The third technology architecture innovation comes from mobile Internet and social networking services. Technology architecture is used to realize application architecture and data architecture, which further supports business architecture. The last innovation is around architecture governance for cloud computing. It includes the standardization of individual architectural building blocks within business architecture, application architecture, data architecture, and technology architecture. For each of the four architectures, we need to create unifi ed interfaces and protocols to exchange information. The semantics of the exchanged information and data structure also needs to be standardized to build an interoperable ecosystem for cloud computing. For example, the Distributed Management Task Force (DMTF)",data oriented architecture,103,not included
687735e9ee544c12b100845e8e605fd7b1366315,to_check,semantic_scholar,2013 IEEE International Conference on Big Data,2013-01-01,semantic_scholar,big data analytics on high velocity streams: a case study,https://www.semanticscholar.org/paper/687735e9ee544c12b100845e8e605fd7b1366315,"Big data management is often characterized by three Vs: Volume, Velocity and Variety. While traditional batch-oriented systems such as MapReduce are able to scale-out and process very large volumes of data in parallel, they also introduce some significant latency. In this paper, we focus on the second V (Velocity) of the Big Data triad; We present a case-study where we use a popular open-source stream processing engine (Storm) to perform real-time integration and trend detection on Twitter and Bitly streams. We describe our trend detection solution below and experimentally demonstrate that our architecture can effectively process data in real-time - even for high-velocity streams.",data oriented architecture,104,not included
6cbec639e12c882f75f6b6c1d82d7576a3cd3aca,to_check,semantic_scholar,J. Comput. Inf. Syst.,2017-01-01,semantic_scholar,business analytics-based enterprise information systems,https://www.semanticscholar.org/paper/6cbec639e12c882f75f6b6c1d82d7576a3cd3aca,"ABSTRACT Big data analytics and business analytics are a disruptive technology and innovative solution for enterprise development. However, what is the relationship between business analytics, big data analytics, and enterprise information systems (EIS)? How can business analytics enhance the development of EIS? How can analytics be incorporated into EIS? These are still big issues. This article addresses these three issues by proposing ontology of business analytics, presenting an analytics service-oriented architecture (ASOA) and applying ASOA to EIS, where our surveyed data analysis showed that the proposed ASOA is viable for developing EIS. This article then examines incorporation of business analytics into EIS through proposing a model for business analytics service-based EIS, or ASEIS for short. The proposed approach in this article might facilitate the research and development of EIS, business analytics, big data analytics, and business intelligence.",data oriented architecture,105,not included
796d48dd013668369d29840675405cdcc044a477,to_check,semantic_scholar,2014 IEEE 18th International Enterprise Distributed Object Computing Conference Workshops and Demonstrations,2014-01-01,semantic_scholar,adaptable enterprise architectures for software evolution of smartlife ecosystems,https://www.semanticscholar.org/paper/796d48dd013668369d29840675405cdcc044a477,"SmartLife ecosystems are emerging as intelligent user-centered systems that will shape future trends in technology and communication. Biological metaphors of living adaptable ecosystems provide the logical foundation for self-optimizing and self-healing run-time environments for intelligent adaptable business services and related information systems with service-oriented enterprise architectures. The present research in progress work investigates mechanisms for adaptable enterprise architectures for the development of service-oriented ecosystems with integrated technologies like Semantic Technologies, Web Services, Cloud Computing and Big Data Management. With a large and diverse set of ecosystem services with different owners, our scenario of service-based SmartLife ecosystems can pose challenges in their development, and more importantly, for maintenance and software evolution. Our research explores the use of knowledge modeling using ontologies and flexible metamodels for adaptable enterprise architectures to support program comprehension for software engineers during maintenance and evolution tasks of service-based applications. Our previous reference enterprise architecture model ESARC -- Enterprise Services Architecture Reference Cube -- and the Open Group SOA Ontology was extended to support agile semantic analysis, program comprehension and software evolution for a SmartLife applications scenario. The Semantic Browser is a semantic search tool that was developed to provide knowledge-enhanced investigation capabilities for service-oriented applications and their architectures.",data oriented architecture,106,not included
3c95cebb6eeef8b3b57f8b8c6b92dfb98c23bf6f,to_check,semantic_scholar,2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC),2018-01-01,semantic_scholar,service-oriented big data analytics for improving buildings energy management in smart cities,https://www.semanticscholar.org/paper/3c95cebb6eeef8b3b57f8b8c6b92dfb98c23bf6f,"This paper proposes a service-oriented architecture to support big data analytics for buildings energy management in smart cities. This architecture allows for seamlessly integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations. These operations are needed to effectively utilize available big data for optimizing energy consumption for residential, industrial, and commercial buildings in smart cities. The paper also recognizes the different kinds of decision making processes required by a smart city to effectively manage energy efficiency for its buildings. These decision-making processes can be implemented and deployed as services in the proposed architecture.",data oriented architecture,107,not included
9fcedc58a28937e2fabafde45c711b0801cadc3f,to_check,semantic_scholar,Journal of Management Inquiry,2018-01-01,semantic_scholar,gamification in management: between choice architecture and humanistic design,https://www.semanticscholar.org/paper/9fcedc58a28937e2fabafde45c711b0801cadc3f,"Gamification in management is currently informed by two contradicting framings or rhetorics: the rhetoric of choice architecture casts humans as rational actors and games as perfect information and incentive dispensers, giving managers fine-grained control over people’s behavior. It aligns with basic tenets of neoclassical economics, scientific management, operations research/management science, and current big data-driven decision making. In contrast, the rhetoric of humanistic design casts humans as growth-oriented and games as environments optimally designed to afford positive, meaningful experiences. This view, fitting humanistic management ideas and the rise of design and customer experience, casts managers as “second order” designers. While both rhetorics highlight important aspects of games and management, the former is more likely to be adopted and absorbed into business as usual, whereas the latter holds more uncertainty, but also transformative potential.",data oriented architecture,108,not included
b0647805b29395239aaada60a3911812433610ef,to_check,semantic_scholar,Grid 2012,2012-01-01,semantic_scholar,distributed and big data storage management in grid computing,https://www.semanticscholar.org/paper/b0647805b29395239aaada60a3911812433610ef,"Big data storage management is one of the most challenging issues for Grid computing environments, since large amount of data intensive applications frequently involve a high degree of data access locality. Grid applications typically deal with large amounts of data. In traditional approaches high-performance computing consists dedicated servers that are used to data storage and data replication. In this paper we present a new mechanism for distributed and big data storage and resource discovery services. Here we proposed an architecture named Dynamic and Scalable Storage Management (DSSM) architecture in grid environments. This allows in grid computing not only sharing the computational cycles, but also share the storage space. The storage can be transparently accessed from any grid machine, allowing easy data sharing among grid users and applications. The concept of virtual ids that, allows the creation of virtual spaces has been introduced and used. The DSSM divides all Grid Oriented Storage devices (nodes) into multiple geographically distributed domains and to facilitate the locality and simplify the intra-domain storage management. Grid service based storage resources are adopted to stack simple modular service piece by piece as demand grows. To this end, we propose four axes that define: DSSM architecture and algorithms description, Storage resources and resource discovery into Grid service, Evaluate purpose prototype system, dynamically, scalability, and bandwidth, and Discuss results. Algorithms at bottom and upper level for standardization dynamic and scalable storage management, along with higher bandwidths have been designed.",data oriented architecture,109,not included
fa1a329f59595d88d3cd7c5f3a7a73f615fb7d03,to_check,semantic_scholar,Softw. Pract. Exp.,2015-01-01,semantic_scholar,breeze graph grammar: a graph grammar approach for modeling the software architecture of big data‐oriented software systems,https://www.semanticscholar.org/paper/fa1a329f59595d88d3cd7c5f3a7a73f615fb7d03,"Various technologies have been proposed to support the processing of big data. However, such technologies require software architectures not only to adapt to the changes and achieve dynamic evolution but also to be reliable. Most of the architecture description techniques are not able to directly capture the dynamic changes in the definition of the software architecture and cannot analyze or evaluate the system reliability. In this paper, we provide a breeze graph grammar (BGG) to model the software architecture in both static and dynamic aspects and give a BGG reliability model to help supporting software system reliability modeling and evaluation. Our work expands this idea in three directions. We first present the definition of BGG to specify the software architecture and map the system dynamic evolution to BGG transformation rules. Second, a BGG reliability model is proposed in which we add error attributes to the BGG graph for capturing the system error information, and the system error state transition is performed through BGG graph rewriting rules. Then, we study the rules to map the BGG reliability model to a generalized stochastic Petri net (GSPN) model, which can be used for reliability evaluation. Throughout this paper, we use a big data‐based centralized system to demonstrate our approach. The BGG graph rewriting characteristic supports the dynamic change requirements, and the architecture is statically checked through the BGG productions. Moreover, system reliability modeling and evaluation can be achieved through the BGG reliability model by combining GSPN. Copyright © 2014 John Wiley & Sons, Ltd.",data oriented architecture,110,included
4ea53f634ae78d1fc5533551b67236e0b6dab74f,to_check,semantic_scholar,"Proceedings of 2013 IEEE International Conference on Service Operations and Logistics, and Informatics",2013-01-01,semantic_scholar,a system for green personal integrated mobility: a research in progress,https://www.semanticscholar.org/paper/4ea53f634ae78d1fc5533551b67236e0b6dab74f,"We present an ongoing research on an Integrated Real-time Mobility Assistant (IRMA). IRMA is a software system that targets the personal mobility in a near future scenario, based on green, shared and public transports. IRMA handles end-to-end itineraries that may involve multiple transport systems, and encompasses both commuter mobility and visitor mobility. The objective of IRMA is to make practically feasible a mobility that balances efficiency of time, energy/pollution and cost. Therefore, IRMA supports users in plotting the itinerary and also when en-route. IRMA architecture includes a smartphone application and a set of web services to gather and interpret any relevant source of information, that includes open data, crowd data and big data. The technology is SOA/EDA (Service Oriented Architecture / Event Driven Architecture) and uses GTFS format to access open data. IRMA, after being proved on test cases, shall be tested by the students of University of Pavia. IRMA concept is a step ahead current personal mobility systems that simply suggest and track itineraries.",data oriented architecture,111,not included
a761198f4df06973a68cfd70e96877abe9c4f5e9,to_check,semantic_scholar,International Symposium on Low Power Electronics and Design (ISLPED),2013-01-01,semantic_scholar,an ultralow-power memory-based big-data computing platform by nonvolatile domain-wall nanowire devices,https://www.semanticscholar.org/paper/a761198f4df06973a68cfd70e96877abe9c4f5e9,"As one recently introduced non-volatile memory (NVM) device, domain-wall nanowire (or race-track) has shown potential for main memory storage but also computing capability. In this paper, the domain-wall nanowire is studied for a memory-based computing platform towards ultra-low-power big-data processing. One domain-wall nanowire based logic-in-memory architecture is proposed for big-data processing, where the domain-wall nanowire memory is deployed as main memory for data storage as well as XOR-logic for comparison and addition operations. The domain-wall nanowire based logic-in-memory circuits are evaluated by SPICE-level verifications. Further evaluated by applications of general-purpose SPEC2006 benchmark and also web-searching oriented Phoenix benchmark, the proposed computing platform can exhibit a significant power saving on both main memory and ALU under the similar performance when compared to CMOS based designs.",data oriented architecture,112,not included
4d1b8d46560d08b59d41b24ebedd8aa018d6b0a0,to_check,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,a survey of distributed data stream processing frameworks,https://www.semanticscholar.org/paper/4d1b8d46560d08b59d41b24ebedd8aa018d6b0a0,"Big data processing systems are evolving to be more stream oriented where each data record is processed as it arrives by distributed and low-latency computational frameworks on a continuous basis. As the stream processing technology matures and more organizations invest in digital transformations, new applications of stream analytics will be identified and implemented across a wide spectrum of industries. One of the challenges in developing a streaming analytics infrastructure is the difficulty in selecting the right stream processing framework for the different use cases. With a view to addressing this issue, in this paper we present a taxonomy, a comparative study of distributed data stream processing and analytics frameworks, and a critical review of representative open source (Storm, Spark Streaming, Flink, Kafka Streams) and commercial (IBM Streams) distributed data stream processing frameworks. The study also reports our ongoing study on a multilevel streaming analytics architecture that can serve as a guide for organizations and individuals planning to implement a real-time data stream processing and analytics framework.",data oriented architecture,113,included
064f532b6b67817988a60bcb7a28de1803665e5f,to_check,semantic_scholar,iiWAS,2015-01-01,semantic_scholar,sqltokeynosql: a layer for relational to key-based nosql database mapping,https://www.semanticscholar.org/paper/064f532b6b67817988a60bcb7a28de1803665e5f,"Today, many applications produce and manipulate a large volume of data, the so-called Big Data. Traditional databases (DB), like relational databases, are not suitable to Big Data management. In order to solve this problem, a new category of DB has been proposed, the so-called NoSQL DB. NoSQL DB have different data models, as well as different access methods which are not usually compatible with the SQL language. In this context, approaches have been proposed for providing mapping of relational DB schemata and operations to equivalent ones in NoSQL DB to deal with large relational data sets in the cloud, focusing on scalability and availability. However, these approaches map relational DB only to a single NoSQL data model and, sometimes, to a specific NoSQL DB product. This paper presents SQLtoKeyNoSQL, a layer able to translate relational schemata as well as SQL commands to equivalent schemata and access methods to any key-oriented NoSQL DB (document-oriented, key-value and column-oriented). We present the architecture of our layer focusing on our mapping strategies, as well as some preliminary experiments that evaluate the impact of SQLtoKeyNoSQL as a solution for transparent mapping of relational DB to key-based NoSQL DB.",data oriented architecture,114,not included
bb5d26da72bfe7030dbc6650b686b210ae661f2c,to_check,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,a new data processing architecture for multi-scenario applications in aviation manufacturing,https://www.semanticscholar.org/paper/bb5d26da72bfe7030dbc6650b686b210ae661f2c,"The development of industry 4.0 has spurred the transformation of traditional manufacturing into modern industrial Internet-of-Things. The most notable feature during this transition is the improvement of digitization and intelligence based on the massive data drives. In such a data-driven environment, the processing, storage, and utilization of the industry data get more and more important. Usually, the traditional data processing architecture runs as a one-way streamline, which cannot adapt to the different requirements of the multi-scenario application. This paper proposed a new industrial big data processing architecture called Phi architecture, which can realize many functions such as batch data processing and stream data processing, distributed storage and access, and real-time control. Compared with other data processing architecture, the Phi architecture combined with edge computing and feedback control has the ability to deal with the different demands in aviation manufacturing. Next, the new architecture is designed for microservices pattern, which improves the flexibility and stability of the architecture, and makes it independent operated in multi-scenarios, such as state monitoring of workshop, adaptive data acquisition, feedback control, and user-oriented information classification. As a proof of concept, the architecture has been tested in a simulation digital manufacturing workshop. The results verify the improved effectiveness of the Phi architecture on the data feedback control and real-time processing. And, the development of microservices architecture greatly improves the efficiency, adaptability, and extensibility of the manufacturing process.",data oriented architecture,115,not included
d9347d02a6642030b4d30db956103a9cae02078c,to_check,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,real-time context-aware microservice architecture for predictive analytics and smart decision-making,https://www.semanticscholar.org/paper/d9347d02a6642030b4d30db956103a9cae02078c,"The impressive evolution of the Internet of Things and the great amount of data flowing through the systems provide us with an inspiring scenario for Big Data analytics and advantageous real-time context-aware predictions and smart decision-making. However, this requires a scalable system for constant streaming processing, also provided with the ability of decision-making and action taking based on the performed predictions. This paper aims at proposing a scalable architecture to provide real-time context-aware actions based on predictive streaming processing of data as an evolution of a previously provided event-driven service-oriented architecture which already permitted the context-aware detection and notification of relevant data. For this purpose, we have defined and implemented a microservice-based architecture which provides real-time context-aware actions based on predictive streaming processing of data. As a result, our architecture has been enhanced twofold: on the one hand, the architecture has been supplied with reliable predictions through the use of predictive analytics and complex event processing techniques, which permit the notification of relevant context-aware information ahead of time. On the other, it has been refactored towards a microservice architecture pattern, highly improving its maintenance and evolution. The architecture performance has been evaluated with an air quality case study.",data oriented architecture,116,not included
ed497f674af7d9c729f06bba3639d612c4bc019d,to_check,semantic_scholar,GvD,2016-01-01,semantic_scholar,the gobia method: fusing data warehouses and big data in a goal-oriented bi architecture,https://www.semanticscholar.org/paper/ed497f674af7d9c729f06bba3639d612c4bc019d,"Traditional Data Warehouse (DWH) architectures are challenged by numerous novel Big Data products. These tools are typically presented as alternatives or extensions for one or more of the layers of a typical DWH reference architecture. Still, there is no established joint reference architecture for both DWH and Big Data that is inherently aligned with business goals as implied by Business Intelligence (BI) projects. In this paper, the current iteration of a work-inprogress approach towards such custom BI architectures, the GOBIA method, is presented to address this gap, combining a BI reference architecture and a development process. A use case example is presented to illustrate the proposed method.",data oriented architecture,117,not included
e641f72738bea9c196eaf0a6fca2663a57192589,to_check,semantic_scholar,AMCIS,2016-01-01,semantic_scholar,towards an architecture for big data-driven knowledge management systems,https://www.semanticscholar.org/paper/e641f72738bea9c196eaf0a6fca2663a57192589,"Nowadays, knowledge management systems are confronted with a variety and unprecedented amount of data, resulting from big data sources. A new generation of knowledge management systems for exploring and exploiting big data becomes a major need for organizations. For this reason, the paper proposes a novel service-oriented architecture for big data-driven knowledge management systems. The purpose of this research is to support organizations to leverage their knowledge-based assets for improving decisionmaking and facilitating organizational learning. The proposed architecture is based on the principles of design science research, including a set of constructs, a model and a method. The design evaluation is presented based on the analytical evaluation method. By applying the architecture, an organization can manage and govern business and digital transformation, setting them apart from their competitors.",data oriented architecture,118,not included
574bf669d6d26df693023588492b40a9dd4917e9,to_check,semantic_scholar,The Journal of Supercomputing,2014-01-01,semantic_scholar,cloud computing in e-science: research challenges and opportunities,https://www.semanticscholar.org/paper/574bf669d6d26df693023588492b40a9dd4917e9,"Service-oriented architecture (SOA), workflow, the Semantic Web, and Grid computing are key enabling information technologies in the development of increasingly sophisticated e-Science infrastructures and application platforms. While the emergence of Cloud computing as a new computing paradigm has provided new directions and opportunities for e-Science infrastructure development, it also presents some challenges. Scientific research is increasingly finding that it is difficult to handle “big data” using traditional data processing techniques. Such challenges demonstrate the need for a comprehensive analysis on using the above-mentioned informatics techniques to develop appropriate e-Science infrastructure and platforms in the context of Cloud computing. This survey paper describes recent research advances in applying informatics techniques to facilitate scientific research particularly from the Cloud computing perspective. Our particular contributions include identifying associated research challenges and opportunities, presenting lessons learned, and describing our future vision for applying Cloud computing to e-Science. We believe our research findings can help indicate the future trend of e-Science, and can inform funding and research directions in how to more appropriately employ computing technologies in scientific research. We point out the open research issues hoping to spark new development and innovation in the e-Science field.",data oriented architecture,119,not included
0f1d4f233d8a29c3c55d899027b3618533f366e7,to_check,semantic_scholar,Briefings Bioinform.,2016-01-01,semantic_scholar,how computer science can help in understanding the 3d genome architecture,https://www.semanticscholar.org/paper/0f1d4f233d8a29c3c55d899027b3618533f366e7,"Chromosome conformation capture techniques are producing a huge amount of data about the architecture of our genome. These data can provide us with a better understanding of the events that induce critical regulations of the cellular function from small changes in the three-dimensional genome architecture. Generating a unified view of spatial, temporal, genetic and epigenetic properties poses various challenges of data analysis, visualization, integration and mining, as well as of high performance computing and big data management. Here, we describe the critical issues of this new branch of bioinformatics, oriented at the comprehension of the three-dimensional genome architecture, which we call 'Nucleome Bioinformatics', looking beyond the currently available tools and methods, and highlight yet unaddressed challenges and the potential approaches that could be applied for tackling them. Our review provides a map for researchers interested in using computer science for studying 'Nucleome Bioinformatics', to achieve a better understanding of the biological processes that occur inside the nucleus.",data oriented architecture,120,not included
b0bf8eff2eb6465ff170219272c0bd84156a395b,to_check,semantic_scholar,,2015-01-01,semantic_scholar,intelligent cities: enabling tools and technology,https://www.semanticscholar.org/paper/b0bf8eff2eb6465ff170219272c0bd84156a395b,"The emergence of highly promising and potent technologies has enabled the transition of ordinary objects into smart artifactsproviding wider connectivity of digitized entities that can facilitate the building of connected cities. This book provides readers with a solid foundation on the latest technologies and tools required to develop and enhance smart cities around the world.The book begins by examining the rise of the cloud as the fundamental technology for establishing and sustaining smart cities and enterprises. Explaining the principal technologies and platform solutions for implementing intelligent cities, the book details the role of various technologies, standards, protocols, and tools in establishing flexible homes and the buildings of the future. Examines IT platforms and tools from various product vendors Considers service-oriented architecture and event-driven architecture for smart city applications Explains how to leverage big data analytics for smart city enhancement and improved decision making Includes case studies of intelligent cities, smart homes, buildings, transports, healthcare systems, and airports The authors explore the convergence of cloud computing and enterprise architecture and present valuable information on next-generation cloud computing. They also cover the various architectural types, including enterprise-scale integration, security, management, and governance.The book concludes by explaining the various security requirements of intelligent cities as well as the threats and vulnerabilities of the various components that form the basis of the intelligent city framework, including cloud, big data, Internet of Things, and mobile technologies.",data oriented architecture,121,not included
481eb088af92e3865f21c9bd293bf9cb6cab4a19,to_check,semantic_scholar,IEEE Transactions on Services Computing,2018-01-01,semantic_scholar,data-driven and feedback-enhanced trust computing pattern for large-scale multi-cloud collaborative services,https://www.semanticscholar.org/paper/481eb088af92e3865f21c9bd293bf9cb6cab4a19,"Multi-cloud collaborative environment consists of multiple data centers, which is a typical processing platform for big data. This paper focuses on the trust computing requirement of multi-cloud collaborative services and develops a Data-driven and Feedback-Enhanced Trust (DFET) computing pattern across multiple data centers with several innovative mechanisms. First, a trust-aware service monitoring architecture is proposed based on distributed soft agents to serve as middleware for multi-cloud trust computing and task scheduling. A data-driven trust computation scheme based on multi-indicator monitoring data is then proposed. The integration of several key service indicators into trust computing makes this scheme suitable for service-oriented cloud applications. More importantly, according to the intrinsic relationship among users, monitors, and service providers, we propose an enhanced and hierarchical feedback mechanism that can effectively reduce networking risk while improving system dependability. Theoretical analysis shows that DFET pattern is highly dependable against garnished and bad-mouthing attacks. We also build a prototype system to verify the feasibility of DFET pattern and the experiments yield meaningful observations that can facilitate the effective utilization of DFET in the large-scale multi-cloud collaborative environment.",data oriented architecture,122,not included
aac1d360dcb6b9f296f9195b9d07cb33527d11d9,to_check,semantic_scholar,2016 IEEE 2nd International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow (RTSI),2016-01-01,semantic_scholar,towards better scalability for iot-cloud interactions via combined exploitation of mqtt and coap,https://www.semanticscholar.org/paper/aac1d360dcb6b9f296f9195b9d07cb33527d11d9,"It is manifest the growing research and industrial interest in scalable solutions for the efficient integration of large amounts of deployed sensors and actuators (Internet of Things - IoT-devices) and cloud-hosted virtualized resources for elastic storage and processing (including big data online stream processing). Such relevant attention is also demonstrated by the emergence of interesting IoT-cloud platforms from industry and open-source communities, as well as by the flourishing research area of fog/edge computing, where decentralized virtual resources at edge nodes can support enhanced scalability and reduced latency via locality-based optimizations. In this perspective, this paper proposes an innovative distributed architecture combining machine-to-machine industry-mature protocols (i.e., MQTT and CoAP) in an original way to enhance the scalability of gateways for the efficient IoT-cloud integration. In addition, the paper presents how we have applied the approach in the practical experience of efficiently and effectively extending the implementation of the open-source gateway that is available in the industry-oriented Kura framework for IoT.",data oriented architecture,123,included
2d0e36ae78978b829e7ba544fbaa67043bc87938,to_check,semantic_scholar,,2015-01-01,semantic_scholar,agent-based manufacturing service discovery method for cloud manufacturing,https://www.semanticscholar.org/paper/2d0e36ae78978b829e7ba544fbaa67043bc87938,"The development of new generation information technology has brought opportunities for industrial production model innovation. Especially, the cloud computing, Internet of Things, and big data technology are widespread applied in industrial fields. Based on this tendency, a service-oriented networked manufacturing model called cloud manufacturing (CM) was proposed in 2010. In order to realize this manufacturing model, one of the key technologies is how to achieve the discovery of manufacturing service which has not found a suitable solution. In this paper, a manufacturing service discovery framework based on agent is provided. The architecture consists of two parts: one is that manufacturing task agent and manufacturing service agent based on the expansion of the object model, and the other one is task and service matching process knowledge base. Furthermore, a structural matching method is proposed to implement the static parameters matching of task agent and service agent, and a multi-agent system bid mechanism is built to accomplish the dynamic parameters matching of the two agents. A simulation environment based on JADE has been properly developed. The simulation shows that the discovery method can effectively achieve the manufacturing service discovery in CM environment, which provides technical support for the cloud manufacturing service platform development.",data oriented architecture,124,not included
9b716916628ab9003f87bf5841350a847ff09c38,to_check,semantic_scholar,TheScientificWorldJournal,2014-01-01,semantic_scholar,cloud computing based systems for healthcare,https://www.semanticscholar.org/paper/9b716916628ab9003f87bf5841350a847ff09c38,"The emergence of cloud computing leads to new developments for diverse application domains. This is particularly true for healthcare with its tremendous importance in today's society, thus making it worth to investigate the relevant perspectives and insights. In this special issue, readers will find the foundations together with cutting-edge developments in the state-of-the-art of cloud computing based systems for healthcare. 
 
Cloud computing is getting increasing attention and represents nowadays one of the most important research topics in computing science and information systems. Cloud computing refers to both the applications delivered as services over the Internet and the hardware and software systems within the data centers which provide those services. Cloud is now seen as a valid strategy and specific applications based on these technologies have become widespread. 
 
Healthcare, as with any other service operation, has been impacted by the cloud computing phenomenon with the literature reporting both benefits and challenges of cloud computing in the area. However, the evolving nature of science and technology creates new scenarios that must be studied using interdisciplinary and holistic means. 
 
The aim of this special issue was to collect innovative and high-quality research contributions regarding the advances in the healthcare domain that are enabled by the use of cloud computing architectures and techniques. The focus is intended to be integral for cloud computing in healthcare, but emphasizing not only the IT side of the phenomenon but also the managerial and the health practitioner side. 
 
Editors received a considerable amount of submissions that were peer-reviewed by top experts in the field. Based on the reviews and our reading of the papers, editors selected seven high-quality ones to be published. Contributions of these papers are summarized as follows. 
 
Two contributions deal with scenarios where cloud computing can serve as an enabler for improved decision making and contribute to systemic improvements in healthcare domain. In “Usalpharma: a cloud-based architecture to support Quality Assurance training processes in health area using Virtual Worlds” by F. J. Garcia-Penalvo et al., the authors discuss ways cloud-based architectures can extend and enhance the functionality of training environments based on Virtual Worlds with focus on training processes in Quality Assurance for pharmaceutical laboratories. In “Cloud based meta-learning system for predictive modeling of biomedical data” by M. Vukicevic et al., the authors propose a cloud-based system that integrates a meta-learning framework for ranking and selection of the best predictive algorithms for data at hand and open-source big data technologies for analysis of biomedical data. 
 
Two contributions focus on the topics of risk and security as management issues in cloud computing based systems for healthcare. In “Proposal for a security management in cloud computing for health care” K. by Haufe et al., the authors propose a framework that aims to cover the most important security processes related to cloud computing in the healthcare sector. The approach considers both the standards of the ISO 27000 family, as well as specific aspects of healthcare organizations using cloud computing. In “Risks and crises for healthcare providers: the impact of cloud computing” by R. Glasberg et al., the multidisciplinary team of authors analyze risks and crises for healthcare providers and discuss the impact of cloud computing in such scenarios. 
 
Three contributions deal with specific healthcare-related use cases of cloud computing in diverse application scenarios. In “SAMuS: service-oriented architecture for multisensor surveillance in smart homes,” S. Van Hoecke et al. present the design of a service-oriented architecture (SOA) for multisensor surveillance in smart homes. The solution is evaluated by building a smart Kinect sensor that is able to dynamically switch between IR and RGB and improves person detection by incorporating feedback from pressure sensors within the SOA. In “A cloud-based X73 ubiquitous mobile healthcare system: design and implementation” by Z. Ji et al., a ubiquitous mobile healthcare uHealth system is presented. It is based on the ISO/IEEE11073 personal health data (PHD) standards (X73) and cloud computing techniques. In “An expert fitness diagnosis system based on elastic cloud computing,” K. C. Tseng et al. describe an expert diagnosis system based on cloud computing that is able to classify a user's fitness level based on supervised machine learning techniques. This system uses parameters such as user's physiological data, age, gender, and body mass index (BMI) and utilizes an elastic algorithm based on Poisson distribution to allocate computation resources dynamically. 
 
The special issue editors would like to take this opportunity to thank the authors for their papers and the reviewers for their valuable comments and suggestions. Special thanks also to the editorial team for its help and also for providing us an opportunity to edit this special issue.",data oriented architecture,125,not included
291b3c452df36eef8578ebb02e80879df86cb390,to_check,semantic_scholar,Int. J. Intell. Inf. Technol.,2018-01-01,semantic_scholar,towards a service-oriented architecture for knowledge management in big data era,https://www.semanticscholar.org/paper/291b3c452df36eef8578ebb02e80879df86cb390,"Nowadays, big data is a revolution that transforms conventional enterprises into data-driven organizations in which knowledge discovered from big data will be integrated into traditional knowledge to improve decision-making and to facilitate organizational learning. Consequently, a major concern is how to evolve current knowledge management systems, which are confronted with a various and unprecedented amount of data, resulting from different data sources. Therefore, a new generation of knowledge management systems is required for exploring and exploiting big data as well as for facilitating the knowledge co-creation between the society and its business environment to foster innovation. This article proposes a service-oriented architecture for elaborating a new generation of big data-driven knowledge management systems to help enterprises to promote knowledge co-creation and to obtain more business value from big data. The proposed architecture is presented based on the principles of design science research and its evaluation uses the analytical evaluation method.",data oriented architecture,126,not included
874ea834b5150072a90079ac4fba1e78999d8ed0,to_check,semantic_scholar,International Journal of Advanced Computer Science and Applications,2019-01-01,semantic_scholar,towards an architecture for handling big data in oil and gas industries: service-oriented approach,https://www.semanticscholar.org/paper/874ea834b5150072a90079ac4fba1e78999d8ed0,"Existing architectures to handle big data in Oil & gas industry are based on industry-specific platforms and hence limited to specific tools and technologies. With these architectures, we are confined to big data single-provider solutions. The idea of multi-provider big data solutions is essential. When building up big data solutions, organizations should embrace the best-in-class technologies and tools that different providers offer. In this article, we hypothesize that the limitations of the proposed big-data architectures for oil and gas industries can be addressed by a Service Oriented Architecture approach. In this article, we are proposing the idea of breaking complex systems to simple separate yet reliable distributed services. It should be noted that loose coupling exists between the interacting services. Thus, our proposed architecture enables petroleum industries to select the necessary services from the SOA-based ecosystem and create viable big data solutions.",data oriented architecture,127,not included
fd64738c9015e8fa6643359b1cad007c806f6368,to_check,semantic_scholar,LWA,2015-01-01,semantic_scholar,the gobia method: towards goal-oriented business intelligence architectures,https://www.semanticscholar.org/paper/fd64738c9015e8fa6643359b1cad007c806f6368,"Traditional Data Warehouse (DWH) architectures are chal- lenged by numerous novel Big Data products. These tools are typically presented as alternatives or extensions for one or more of the layers of a typical DWH reference architecture. Still, there is no established joint reference architecture for both DWH and Big Data that is inher- ently aligned with business goals as implied by Business Intelligence (BI) projects. In this paper, a work-in-progress approach towards such cus- tom BI architectures, the GOBIA method, is presented to address this gap, combining a BI reference architecture and a development process.",data oriented architecture,128,not included
5b6069aacf586b51364218ca76dd7b764088eb17,to_check,semantic_scholar,ISPRS Int. J. Geo Inf.,2018-01-01,semantic_scholar,an efficient graph-based spatio-temporal indexing method for task-oriented multi-modal scene data organization,https://www.semanticscholar.org/paper/5b6069aacf586b51364218ca76dd7b764088eb17,"Task-oriented scene data in big data and cloud environments of a smart city that must be time-critically processed are dynamic and associated with increasing complexities and heterogeneities. Existing hybrid tree-based external indexing methods are input/output (I/O)-intensive, query schema-fixed, and difficult when representing the complex relationships of real-time multi-modal scene data; specifically, queries are limited to a certain spatio-temporal range or a small number of selected attributes. This paper proposes a new spatio-temporal indexing method for task-oriented multi-modal scene data organization. First, a hybrid spatio-temporal index architecture is proposed based on the analysis of the characteristics of scene data and the driving forces behind the scene tasks. Second, a graph-based spatio-temporal relation indexing approach, named the spatio-temporal relation graph (STR-graph), is constructed for this architecture. The global graph-based index, internal and external operation mechanisms, and optimization strategy of the STR-graph index are introduced in detail. Finally, index efficiency comparison experiments are conducted, and the results show that the STR-graph performs excellently in index generation and can efficiently address the diverse requirements of different visualization tasks for data scheduling; specifically, the STR-graph is more efficient when addressing complex and uncertain spatio-temporal relation queries.",data oriented architecture,129,not included
aa282e85218d0842fb7774cbf50b15da9925060a,to_check,semantic_scholar,2014 IEEE 10th International Conference on e-Science,2014-01-01,semantic_scholar,a scalable planetary science information architecture for big science data,https://www.semanticscholar.org/paper/aa282e85218d0842fb7774cbf50b15da9925060a,"Research has shown that the amount of data now available often overwhelms key functions of an information system. This situation necessitates the design of information architectures that scale to meet the challenges. The Planetary Data System, a NASA funded project, has developed an information architecture for the planetary science community that addresses this and other big science data issues noted in a National Research Council report regarding architectures for big data management and analysis and end-to-end data lifecycle management across diverse disciplines. The report identified enabling technology trends including distributed systems, service-oriented architectures, ontologies, models and information representation, scalable database systems, federated data security mechanisms, and technologies for moving big data. This paper will present the PDS4 information architecture, its successful implementation in a multi-discipline big-data environment.",data oriented architecture,130,not included
537819f9d8561791bfd308942fe399bb95e8c20d,to_check,semantic_scholar,,2017-01-01,semantic_scholar,investigating an architectural framework for small data platforms,https://www.semanticscholar.org/paper/537819f9d8561791bfd308942fe399bb95e8c20d,"The potential of data to support solutions to some of the global grand challenges is uncontested. This potential is recognized and confirmed through the articulation of technology as an explicit Means of Implementation for the Sustainable Development Goals. In particular the advent of big data has introduced not only new data sources and data providers, but also new data analytics and processing algorithms that are having an impact across national and global data ecosystems. The major investments to harness this potential for data are being made in the private sector, to provide insights to inform better decision making for business; and also in the public sector where governments are exploring the use of data for better governance and service delivery. The role of data to make an impact on societal challenges, especially in the context of challenges related to social wellbeing and the Sustainable Development Goals, is typically considered from the macro and meso levels where the trends about national or state/district level phenomenon are observed. This macro level (also called ecological level) perspective, with its associated instruments of analysis, techniques of visualization, is in contrast to another growing perspective which is encapsulated in the small data approach. The small data approach seeks to connect individuals with ‘timely, meaningful insights, organized to be accessible, understandable, and actionable for everyday tasks’. Thus within this approach the unit of sampling (which is usually an individual or a household) is maintained as the same unit at which data analysis is undertaken. Consequently the target of consumption of the derived insights and knowledge is the individual, which implies the use of reporting and visualization techniques that are similarly geared at the individuals. This paper revisits an architectural framework for knowledge-oriented, context-sensitive platforms, and evaluates this architecture for the realization of systems and platforms that embody the small data approach. Through a layered and modular separation of data, access, social networking, interaction and presentation components, this architecture seeks to achieve the interaction and presentation personalization for individuals while ensuring not only improved data provenance preservation but also the security of the underlying data.",data oriented architecture,131,not included
f0de9750a851ee6c88ca1e64b1fa95cf6af537a3,to_check,semantic_scholar,BIS,2016-01-01,semantic_scholar,multi-perspective digitization architecture for the internet of things,https://www.semanticscholar.org/paper/f0de9750a851ee6c88ca1e64b1fa95cf6af537a3,"Social networks, smart portable devices, Internet of Things (IoT) on base of technologies like analytics for big data and cloud services are emerging to support flexible connected products and agile services as the new wave of digital transformation. Biological metaphors of living and adaptable ecosystems with service-oriented enterprise architectures provide the foundation for self-optimizing and resilient run-time environments for intelligent business services and related distributed information systems. We are extending Enterprise Architecture (EA) with mechanisms for flexible adaptation and evolution of information systems having distributed IoT and other micro-granular digital architecture to support next digitization products, services, and processes. Our aim is to support flexibility and agile transformation for both IT and business capabilities through adaptive digital enterprise architectures. The present research paper investigates additionally decision mechanisms in the context of multi-perspective explorations of enterprise services and Internet of Things architectures by extending original enterprise architecture reference models with state of art elements for architectural engineering and digitization.",data oriented architecture,132,not included
7101e554b086cdb8a7b3e58d202fbf472f8a105d,to_check,semantic_scholar,,2017-01-01,semantic_scholar,big data analytics with service-oriented architecture,https://www.semanticscholar.org/paper/7101e554b086cdb8a7b3e58d202fbf472f8a105d,"This chapter focuses on Big Data and its relation with Service-Oriented Architecture. We start with the introduction to Big Data Trends in recent times, how data explosion is not only faced by web and retail networks but also the enterprises. The notorious “V’s” – Variety, volume, velocity and value can cause a lot of trouble. We emphasize on the fact that Big Data is much more than just size, the problem that we face today is neither the amount of data that is created nor its consumption, but the analysis of all those data. In our next step, we describe what service-oriented architecture is and how SOA can efficiently handle the increasingly massive amount of transactions. Next, we focus on the main purpose of SOA here is to meaningfully interoperate, trade, and reuse data between IT systems and trading partners. Using this Big Data scenario, we investigate the integration of Services with new capabilities of Enterprise Architectures and Management. This has had varying success but it remains the dominant mode for data integration as data can be managed with higher flexibility.",data oriented architecture,133,not included
be1d99414e1aa806a89229e8175ceb5d0a51b4fa,to_check,semantic_scholar,Electronics,2019-01-01,semantic_scholar,"intelligent micro energy grid in 5g era: platforms, business cases, testbeds, and next generation applications",https://www.semanticscholar.org/paper/be1d99414e1aa806a89229e8175ceb5d0a51b4fa,"As fifth-generation mobile communication systems give rise to new smart grid technologies, such as distributed energy resources, advanced communication systems, the Internet of Things, and big data analytics, the development of novel platforms and business models that ensure reliability and profitability of microgrid operations become increasingly important. In this study, we introduce an open micro energy grid platform to operate the widely distributed microgrids in Korea. Subsequently, we present commercial microgrid business models supported by the open micro energy grid platform equipped with an artificial intelligence engine and provide test results from testbeds connected to the platform. In contrast to the existing microgrid business models in the market, we propose a universal architecture and business model of the future microgrid, comprising (i) an energy robot-management operation business model, (ii) electric vehicle-based demand response, (iii) blockchain technology for energy trading, and (iv) a service-oriented business model. Finally, we propose a new business model for an intelligent virtual power plant (VPP) operator along with the architecture of the VPP and its proof of concept (PoC). We expect the proposed business model to provide energy solution providers with guidelines to develop various VPP services.",data oriented architecture,134,not included
cc6f299a33009d6bd13ac69fd742f1a0504ffba3,to_check,semantic_scholar,IEEE Access,2018-01-01,semantic_scholar,a secured data management scheme for smart societies in industrial internet of things environment,https://www.semanticscholar.org/paper/cc6f299a33009d6bd13ac69fd742f1a0504ffba3,"Smart societies have an increasing demand for quality-oriented services and infrastructure in an industrial Internet of Things (IIoT) paradigm. Smart urbanization faces numerous challenges. Among them, secured energy demand-side management (DSM) is of particular concern. The IIoT renders the industrial systems to malware, cyberattacks, and other security risks. The IIoT with the amalgamation of big data analytics can provide efficient solutions to such challenges. This paper proposes a secured and trusted multi-layered DSM engine for a smart social society using IIoT-based big data analytics. The major objective is to provide a generic secured solution for smart societies in IIoT environment. The proposed engine uses a centralized approach to achieve optimum DSM over a home area network. To enhance the security of this engine, a payload-based authentication scheme is utilized that relies on a lightweight handshake mechanism. Our proposed method utilizes the lightweight features of the constrained application protocol to facilitate the clients in monitoring various resources residing over the server in an energy-efficient manner. In addition, data streams are processed using big data analytics with MapReduce parallel processing. The proposed authentication approach is evaluated using NetDuino Plus 2 boards that yield a lower connection overhead, memory consumption, response time, and a robust defense against various malicious attacks. On the other hand, our data processing approach is tested on reliable datasets using Apache Hadoop with Apache Spark to verify the proposed DMS engine. The test results reveal that the proposed architecture offers valuable insights into the smart social societies in the context of IIoT.",data oriented architecture,135,not included
5045fb290a1ab454ef18d1ab3ae1444712739529,to_check,semantic_scholar,IEEE Access,2021-01-01,semantic_scholar,towards a service-oriented architecture for the energy efficiency of buildings: a systematic review,https://www.semanticscholar.org/paper/5045fb290a1ab454ef18d1ab3ae1444712739529,"Currently, smart buildings generate large amounts of data due to the many devices and equipment available. Hence, buildings implement building management systems (BMSs), which monitor, control, manage and analyze each of these components. However, current BMSs are incapable of managing a massive amount of data (big data) and therefore cannot extract knowledge or make intelligent decisions in quasi real time. In addition, there are serious limitations to integrating BMSs with other services since they generally use proprietary software. In this sense, service-oriented architecture (SOA) is an architectural style that allows one to build distributed systems and provide functionalities such as services to end users or other types of services. Therefore, an SOA has the great advantage of allowing the expansion of the functionalities of BMSs. In fact, there are several studies that address SOAs for building management. However, we have not found any description or systematic analysis in the literature that allows the development of a versatile and interoperable SOA focused on the energy efficiency of buildings and that can integrate massive data analysis features. For these reasons, this study seeks to fill this knowledge gap and, more specifically, to identify and analyze the various software requirements proposed in the literature and the characteristics of big data that allow for improving the energy efficiency of buildings. To this end, we performed an in-depth review of the literature according to the methodology proposed by Kitchenham. As a result of this review, we provide researchers with a specific vision of the requirements and characteristics to consider for software development aimed at the energy efficiency of unique or historic buildings.",data oriented architecture,136,not included
184c3915fe0aefc21aecc8d0fcb3db0b45348240,to_check,semantic_scholar,,2016-01-01,semantic_scholar,cloud big data application for transport,https://www.semanticscholar.org/paper/184c3915fe0aefc21aecc8d0fcb3db0b45348240,This paper presents a cloud service oriented approach for managing and analysing big data required by transport applications. Big data analytics brings new insights and useful correlations of large data collections providing undiscovered knowledge. Applying it to transport systems brings better understanding to the transport networks revealing unexpected choking points in cities. This facility is still largely inaccessible to small companies due to their limited access to computational resources. A cloud-oriented architecture opens new perspectives for providing efficient and personalised big data management and analytics services to (small) companies.,data oriented architecture,137,not included
ad3e23bbac51d2c053305aedd9864676c88210ae,to_check,semantic_scholar,"2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)",2016-01-01,semantic_scholar,i-hastream: density-based hierarchical clustering of big data streams and its application to big graph analytics tools,https://www.semanticscholar.org/paper/ad3e23bbac51d2c053305aedd9864676c88210ae,"Big Data Streams are very popular at now, as stirred-up by a plethora of modern applications such as sensor networks, scientific computing tools, Web intelligence, social network analysis and mining tools, and so forth. Here, the main research issue consists in how to effectively and efficiently extract useful knowledge from (streaming) big data, in order to support innovative big data analytics platforms. To this end, clustering analysis is a well-known tool for extracting knowledge from big data streams, as also confirmed by recent trends in active literature. A special applicative case is represented by so-called graph-shaped data (big) streams, which are produced by graph sources providing both structure-and content-oriented knowledge. On top of such sources, big graph analytics is a leading scientific area to be considered. At the convergence of these emerging topics, in this paper we provide the following contributions: (i) I-HASTREAM, a novel density-based hierarchical clustering algorithm for evolving big data streams that founds on it predecessor, namely HASTREAM, (ii) the architecture of a big graph analytics engine that embeds I-HASTREAM in its core layer.",data oriented architecture,138,included
a6a457a80114a57b7857568227daf95806656770,to_check,semantic_scholar,2018 13th Iberian Conference on Information Systems and Technologies (CISTI),2018-01-01,semantic_scholar,integration through mapping — an openehr based approach for research oriented integration of health information systems,https://www.semanticscholar.org/paper/a6a457a80114a57b7857568227daf95806656770,"The growing need for Healthcare Information Systems that meets standards of rigor and demand, as well as the need to provide health researchers with the best quality data, has created a major challenge with regard to interoperability in information systems. Nowadays it is common patient data to be dispersed by various systems. Modern systems are tending to adopt standards for modelling and communicating information, but this is not true for legacy systems, where the precision in terms of medical concepts are not standardized. Many times these systems are developed solutions to a specific needs of a medical service, without care for the terminology of clinical concepts representation or how it is structured in terms of semantic. Research relies heavily on the available data, and in context of Big Data analysis, the possibility of aggregating data from multiple, different and distributed sources in a meaningful and straightforward way is relevant. The main objective of this work is to propose an integration architecture that enables access to clinical data from different heterogeneous sources for research purposes. This paper presents an architecture based on the openEHR standard and a proof of concept of the mapping component that provides a tool for matching the attributes of openEHR Archetypes/Templates and fields of databases. With this approach all the data distributed in various repositories, legacy or openEHR are potentially available to the researcher, through the creation of AQL queries in order to get aggregated results for additional research activities.",data oriented architecture,139,not included
e73438185bce358ddaf0eb330cb216970d79df63,to_check,semantic_scholar,,2021-01-01,semantic_scholar,secured big data analytics for decision-oriented medical system using internet of things,https://www.semanticscholar.org/paper/e73438185bce358ddaf0eb330cb216970d79df63,"The Internet of Medical Things (IoMT) has shown incredible development with the growth of medical systems using wireless information technologies. Medical devices are biosensors that can integrate with physical things to make smarter healthcare applications that are collaborated on the Internet. In recent decades, many applications have been designed to monitor the physical health of patients and support expert teams for appropriate treatment. The medical devices are attached to patients’ bodies and connected with a cloud computing system for obtaining and analyzing healthcare data. However, such medical devices operate on battery powered sensors with limiting constraints in terms of memory, transmission, and processing resources. Many healthcare solutions are helping the community with the efficient monitoring of patients’ conditions using cloud computing, however, mostly incur latency in data collection and storage. Therefore, this paper presents a model for the Secured Big Data analytics using Edge–Cloud architecture (SBD-EC), which aims to provide distributed and timely computation of a decision-oriented medical system. Moreover, the mobile edges cooperate with the cloud level to present a secure algorithm, achieving reliable availability of medical data with privacy and security against malicious actions. The performance of the proposed model is evaluated in simulations and the results obtained demonstrate significant improvement over other solutions.",data oriented architecture,140,not included
a6ae7ad3b0fb61846ea3b3b397e6b186284dc2f4,to_check,semantic_scholar,Ann. des Télécommunications,2017-01-01,semantic_scholar,cloudification of the internet of things,https://www.semanticscholar.org/paper/a6ae7ad3b0fb61846ea3b3b397e6b186284dc2f4,"The focus of this special issue is on the Internet of Things (IoT) with particular emphasis on the use of the Cloud as a central component of the IoTarchitecture and a key infrastructural support for IoT applications. With its virtualized infrastructure and software-defined networking substrate, the Cloud is in a good position to provide a flexible and scalable hosting environment for the plethora of emerging IoT applications in health, transportation, smart cities, and many other application areas. The shared infrastructure as service-oriented architecture of the Cloud can be indeed leveraged in support of IoT-generated data and control flows, Machine-to-Machine (M2M) communication, Big-data analytics, IoT management systems, security solutions, Network Function Virtualization (NFV), and SDN-based data forwarding to name a few. This special issue addresses a wide spectrum of research issues pertaining to the use of Cloud infrastructures in support of IoT systems from the sensors and machines to the end users and applications hosted in the Cloud. It comprises selected papers that provide an overview of and in-depth research, development, and deployment efforts on the Cloudification of IoT, specifically IoT infrastructure, IoT gateways, and IoT cloud environments. Hereafter, a summary of each paper accepted in this special issue is described.",data oriented architecture,141,not included
5acd17eabd994cf851ff9ee8e4b30317eda1e2a4,to_check,semantic_scholar,2015 IEEE/ACIS 14th International Conference on Computer and Information Science (ICIS),2015-01-01,semantic_scholar,a big data approach to enhance the integration of access control policies for web services,https://www.semanticscholar.org/paper/5acd17eabd994cf851ff9ee8e4b30317eda1e2a4,"Service-oriented Architecture (SoA) is a layered architecture used to organize software resources as services that can be deployed, discovered and combined to produce new services. The interactions between services can be affected in situations where a destination service becomes unavailable. Herein, the Protocol service is introduced as a solution to coordinate interactions between services. The method is then extended to consider the automatic assignment of access control policies by the generation of a new service, called the Access Control Policies (AC_Policies) service, which is linked to the Protocol service. In this context, the Protocol service manages a large amount of data. The analysis of such data sets may help improving the Protocol service performance. Dealing with such a large data sets is referred recently as “Big Data”, is a term related to large set of data that is complicated to be analyzed using traditional applications. One of the most successful implementations of Big Data is the Hadoop Framework. This paper proposes an extension to automate the integration of the Hadoop platform. This aims to breaks individual problems down into multiple subtasks, using a simple programming model (MapReduce). After the analysis is computed, the result is submitted to a Score table linked with the Protocol service. The approach harnesses the capability of Model-Driven Architecture (MDA) to automate the creation, and integration of the architecture. As a proof of concept, the approach is then implemented as a tool.",data oriented architecture,142,not included
716a313d921b30b4e5e05b428733b68fd0257f28,to_check,semantic_scholar,Innovations in Systems and Software Engineering,2019-01-01,semantic_scholar,performance analysis of an efficient object-based schema oriented data storage system handling health data,https://www.semanticscholar.org/paper/716a313d921b30b4e5e05b428733b68fd0257f28,"Object-based cloud storage system has an important role in handling big data. All available cloud storage systems deal with scalability, reliability or durability issues. However, there is lack of work addressing data variety. In a previous paper, a basic architecture of an object-based schema oriented data storage system has been proposed which stores data in an encapsulated way. The system comprises account layer, container layer, object layer, database layer and schema layer. In this paper, the architecture proposed in our previous paper has been elaborated. For example, the communication protocols of the proposed system are explained. Moreover, this architecture is realized to test its effectiveness on health data in terms of query execution performance and flexibility on the basis of four different queries of database computation (e.g., append, read, aggregate and delete). The result set are collected on three types of datasets (table, document, file) taken from healthcare scenario. Each type of dataset consists of four different sets of data records. The performance is compared with Amazon S3 (i.e., bucket oriented object-based data storage system) and Microsoft Azure (i.e., account-container oriented object-based data storage system). Flexibility property is also analyzed with respect to these three database operations (i.e., READ, WRITE and DELETE) on three types of experimental datasets (table, document, file) with Amazon S3.",data oriented architecture,143,not included
cd022843689dc7a55c0da5fb046fd81990dd7d9a,to_check,semantic_scholar,APMS,2017-01-01,semantic_scholar,advances in internet of things (iot) in manufacturing,https://www.semanticscholar.org/paper/cd022843689dc7a55c0da5fb046fd81990dd7d9a,"As a promising technology with increased adoption in recent years, Internet of Things (IoT) realizes ubiquitous interconnection of physical devices through internet, opening doors for building powerful industrial applications by leveraging the advances in sensor technology and wireless networks. IoT technologies can be viewed as enablers for smart manufacturing and Industry 4.0. This review paper focuses on applications of IoT in manufacturing, which is also known as Industrial Internet of Things IIoT. To that end, technologies relevant to the application of IoT in manufacturing, such as wireless sensor networks (WSNs), smart sensors, big data analytics, and cloud computing are discussed. A service oriented architecture (SOA) based four-layer model for realizing IoT applications in manufacturing is proposed. Finally, a review of the state of art of IoT applications in manufacturing including shop floor automation, predictive maintenance, energy aware manufacturing, and smart workers is presented with relevant industry use cases.",data oriented architecture,144,not included
6904341803304d39eaa86f7634e1a3501a02139b,to_check,semantic_scholar,,2018-01-01,semantic_scholar,architecture for the strategy-planning techniques using big data analytics,https://www.semanticscholar.org/paper/6904341803304d39eaa86f7634e1a3501a02139b,"The rapid growth in technology and market has posed a throat-cut competition among the service providers. Retaining of existing customers in place of catching new one is 90% cheaper, but it needs to know the customer very well, which is possible by analyzing the customer data. To analyze customer data and provide customer-oriented services, this paper recommends an architecture for the development of techniques which would further be able to design strategies, such as tariff plan, on the basis of available information from the customer relationship management system of any service-based company, which is finally known as customer-oriented data product. This architecture has five phases with data source, data collection, data refinement, analysis of collected data, and generation of data product. This paper summarizes the requirement of data sets and systems to develop strategy-planning techniques with the study of available architectures in the big data and CRM environment.",data oriented architecture,145,not included
5dcda12a9c710f1c2c9af617208d40f2b2812cd0,to_check,semantic_scholar,,2017-01-01,semantic_scholar,big data in building information modeling research survey and exploratory text mining,https://www.semanticscholar.org/paper/5dcda12a9c710f1c2c9af617208d40f2b2812cd0,It has been argued that Building Information Modeling BIM can transform the landscape of Architecture Engineering and Construction AEC and Facility Management FM industries with its potential to reduce cost project delivery time and increase productivity Going beyond traditional Computer Aided Design CAD BIM has emerged as a data rich object oriented shared digital representation of a facility that can serve as a reliable basis for decision making across the entire life cycle of a construction project Simultaneous advancements in big data analytics storage as well as information visualization seem to hold the potential to enable truly n dimensional BIMs integrated with other data intensive sources such as Geographic Information Systems GIS Building Automation Systems BAS Energy Management Systems EMS etc A number of recently published articles in the literature seem to indicate that the AEC industry can significantly benefit from big data analytics and architecture and make data driven decisions considering the volume and variety of information resulting from BIM integration approaches This paper presents a concise survey of recently published articles highlighting the big data based BIM challenges as well as some exploratory text analysis using bag of words text mining a Natural Language Processing NLP technique,data oriented architecture,146,not included
4c9c01fd4e1a65e17df74925ad9cc324f7843e9f,to_check,semantic_scholar,J. Intell. Manuf.,2017-01-01,semantic_scholar,holonic and multi-agent technologies for service and computing oriented manufacturing,https://www.semanticscholar.org/paper/4c9c01fd4e1a65e17df74925ad9cc324f7843e9f,"This special feature aims at shedding light on new emerging holonic and multi-agent systems operating in a service-and computing oriented manufacturing environment, using the latest ICT technologies such as service-orientation, mobile agents, Web-and Cloud services, virtualization, big data and analytics to name a few. Industrials are seeking for models and solutions that are not only able to provide efficient overall production performance, but also to face reactively a growing set of unpredicted events. The demand for large scale industrial systems running in complex and even chaotic environments requires the consideration of new paradigms and technologies that provide flexibility, robustness, agility and responsiveness. Holonic systems are, actually by definition, targeting challenges that include coping with the heterogeneous nature of manufacturing systems and their on-line interactive nature in combination with competitive pressures. Multi-agent systems is a suitable implementing approach to address these challenge by offering an alternative way to design control systems, based on the decentralization of control functions over distributed autonomous and cooperative entities. Moreover, virtualization of manufacturing execution system workloads offers a set of design and operational advantages to enterprises, the most visible being improved resource utilization and flexibility of the overall solution. At the manufacturing execution system level, cloud computing adoption refers mainly to virtualization of MES workloads. While MES implementations are different and usually depend directly on the actual physical shop floor layout, the general MES functions are aligned with the set of functions defined by ISA-95.03 specification. To achieve high levels of productivity growth and agility to market changes, manufacturers will need to leverage Big Data sets to drive efficiency across the networked enterprise. There is need for a framework allowing the development of manufacturing cyber physical systems that include capabilities for complex event processing and Big Data analytics, which are expected to move the manufacturing domain closer to digital transformation and cloud services within the contextual enterprise. On the other hand, service orientation is emerging at multiple organizational levels in enterprise business, and leverages technology in response to the growing need for greater business integration, flexibility and agility of manufacturing enterprises. Close related to IT infrastructures of Web Services, the Service Oriented Enterprise Architecture represents a technical architecture, a business modelling concept, an integration source and a new way of viewing units of control within the enterprise. Business and process information systems integration and interoperability are feasible by considering the customized product as ""active controller"" of the enterprise resources – thus providing consistency between material and informational flows. The areas of Service Oriented Computing and Multi-agent Systems are getting closer, both trying to deal with the same kind of environments formed by loose-coupled, flexible, persistent and distributed tasks. An example is the new approach of Service Oriented Multi-agent Systems (SoMAS).",data oriented architecture,147,not included
64c5a749ff57f35356d1066661c34ba68785a172,to_check,semantic_scholar,Communications in Computer and Information Science,2018-01-01,semantic_scholar,multi-domain and sub-role oriented software architecture for managing scientific big data,https://www.semanticscholar.org/paper/64c5a749ff57f35356d1066661c34ba68785a172,"The existing Scientific Data Management Systems (SDMSs) usually focus on a single domain and the interaction pattern of each subsystem is complex. What’s more, the heterogeneity and multi-source of Scientific Big Data (SBD), resulting in a wide variety of databases, scientific devices and functional areas, make the incompatibility and conflict between system modules inevitable. In this context, the paper focuses on the design and technology requirements of a multi-domain and sub-role oriented software architecture. Through integrating multiple databases, third-party systems and related tools, this architecture realizes both the storage and the sharing of multi-domain and multi-type SBD. Particularly, this architecture is divided into four independent functional areas and corresponding roles are designed, which enhances the decoupling and extensibility of the architecture. In addition, this paper has a formal description of the partition design from the perspective of role. On this basis, this paper also shows the typical application scenarios under different roles. The rationality and comprehensiveness of the proposed architecture are proved by describing the architectures design and technology.",data oriented architecture,148,not included
88bb6767030f6f72760211db08a269138278ce24,to_check,semantic_scholar,2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA),2017-01-01,semantic_scholar,prospects and potential application of cloud drilling,https://www.semanticscholar.org/paper/88bb6767030f6f72760211db08a269138278ce24,"Cloud computing technology changes the world, and creates new solutions and opportunities to the enterprises, including petroleum engineering companies. In order to solve more complex drilling problems and optimize oil-field services process control system, the impediments to existing drilling system were analyzed. New technologies, such as cloud computing, cloud manufacturing, internet of things (IoT), big data have been used to solve the complex problems. We propose a unique service-oriented drilling system called Cloud Drilling for petroleum engineering and oil-field services, based on these new technologies. This paper will present the concept of Cloud Drilling and the characteristics of Cloud Drilling system. The architecture and key technology points will be also presented. Finally, we will discuss future prospects of Cloud Drilling and its application potential.",data oriented architecture,149,not included
28b0a6c933e33f5cba484c43e09210fe8f8b7d09,to_check,semantic_scholar,I-ESA,2018-01-01,semantic_scholar,toward information system architecture to support predictive maintenance approach,https://www.semanticscholar.org/paper/28b0a6c933e33f5cba484c43e09210fe8f8b7d09,"The prognostic and health management (PHM) approach aims at supporting maintenance operations in order to ensure the functionality of a system. In order to achieve this objective, a PHM approach is composed of a prognostic component, able to send a prognostic of failure, and a component able to give the health status of the system. Nowadays, this approach suffers from a lack of exploitation of the emerging technologies. This article presents a novel architecture for PHM approach able to extract added value from data. This lambda architecture embeds two layers: a speed layer and a storage layer. Thanks to the storage layer, maintenance rules can be applied as well as the result of machine learning algorithms to the speed layer in order to realize the prognostic aspect of the PHM. In addition, the system has to deal with heterogeneous data, which comes with the necessity to handle the big data issues as well as making it interoperable. This is achieved thanks to a service-oriented architecture approach and the use of complex event processing.",data oriented architecture,150,not included
8ee544932422fab1774db86f60a4840843ae0ffb,to_check,semantic_scholar,2013 IEEE Seventh International Symposium on Service-Oriented System Engineering,2013-01-01,semantic_scholar,performance and reliability effects of multi-tier bidding on mapreduce in auction-based clouds,https://www.semanticscholar.org/paper/8ee544932422fab1774db86f60a4840843ae0ffb,"Hadoop has become a central big data processing framework in today's cloud environments. Ensuring the good performance and cost effectiveness of Hadoop is crucial for the numerous applications that rely on it. In this paper we analyze Hadoop's performance in a multi-tier market-oriented cloud infrastructure known as Spot Instances. Amazon Spot Instances (SIs) are designed to deliver a cheap but transient alternative to fixed cost On-Demand (ODIs) instances. Recently, AWS introduced SIs in their managed Elastic Map Reduce offering. This managed framework lets the users design a multi-tier Hadoop architecture using fine grained controls to define the instance types both in terms of capacity, i.e. compute/storage/network, but also in terms of costs, i.e. ODI vs SI. The performance effects of such fine grained configurations are not yet well understood. First, we analyze a set of cluster configurations that can lead to important performance effects that can affect both the running time and the cost of such cloud Hadoop clusters. Second, we examine Hadoop's fault tolerance mechanisms and show the inadequacy of these mechanisms for multi-tier bidding architectures. Third, we discuss directions for making the Hadoop framework more market-aware without losing its focus on extreme scalability.",data oriented architecture,151,included
f723b71864734944abefeb2775b3fc3baf179a90,to_check,semantic_scholar,,2012-01-01,semantic_scholar,my cray can do that ? supporting diverse workloads on the cray xe-6,https://www.semanticscholar.org/paper/f723b71864734944abefeb2775b3fc3baf179a90,"The Cray XE architecture has been optimized to support tightly coupled MPI applications, but there is an increasing need to run more diverse workloads in the scientific and technical computing domains. These needs are being driven by trends such as the increasing need to process “Big Data”. In the scientific arena, this is exemplified by the need to analyze data from instruments ranging from sequencers, telescopes, and X-ray light sources. These workloads are typically throughput oriented and often involve complex task dependencies. Can platforms like the Cray XE line play a role here? In this paper, we will describe tools we have developed to support high-throughput workloads and data intensive applications on NERSC’s Hopper system. These tools include a custom task farmer framework, tools to create virtual private clusters on the Cray, and using Cray’s Cluster Compatibility Mode (CCM) to support more diverse workloads. In addition, we will describe our experience with running Hadoop, a popular open-source implementation of MapReduce, on Cray systems. We will present our experiences with this work including successes and challenges. Finally, we will discuss future directions and how the Cray platforms could be further enhanced to support these class of workloads.",data oriented architecture,152,not included
06c6044e1a36b767142c846b3cf264b3faf810de,to_check,semantic_scholar,ACM Trans. Internet Techn.,2019-01-01,semantic_scholar,bpms-ra,https://www.semanticscholar.org/paper/06c6044e1a36b767142c846b3cf264b3faf810de,"A growing number of business process management systems is under development both in academia and in practice. These systems typically are based on modern system engineering principles, such as service-oriented architecture. At the same time, the advent of big data analytics has changed the scope of these systems, including functionality such as data mining. However, existing reference architectures for business process management systems date back 20 years and, consequently, are not up-to-date with these modern developments. To fill the gap, this article proposes an up-to-date reference architecture, called BPMS-RA, for modern business process management systems. BPMS-RA is based on analysis of recent literature and of existing commercial implementations. This reference architecture aims to provide a guideline template for the development of modern-day business process management systems by specifying functions and interfaces that need to be provided by these systems as well as a set of quality criteria that they need to meet.",data oriented architecture,153,not included
400a9c04bca46f0355d6b88b451ccbf05e0ae0f7,to_check,semantic_scholar,HEART,2017-01-01,semantic_scholar,dataflow based near data computing achieves excellent energy efficiency,https://www.semanticscholar.org/paper/400a9c04bca46f0355d6b88b451ccbf05e0ae0f7,"The emergence of 3D-DRAM has rekindled interest in near data computing (NDC) research. This article introduces dataflow processing in memory (DFPIM) which melds near data computing, dataflow architecture, coarse-grained reconfigurable logic (CGRL), and 3D-DRAM technologies to provide high performance and very high energy efficiency for stream oriented and big data application kernels. The application of dataflow architecture with a CGRL implementation provides a flexible, energy efficient computing platform. The initial evaluation presented in this paper shows an average speedup of 5.5 is achieved with an energy efficiency factor of 460.",data oriented architecture,154,included
45f717f571bc1d477191e107264db33cf9dde7c7,to_check,semantic_scholar,WAIM Workshops,2013-01-01,semantic_scholar,a cloud computation architecture for unconventional emergency management,https://www.semanticscholar.org/paper/45f717f571bc1d477191e107264db33cf9dde7c7,"With the development of technologies and the deterioration of natural environment, unconventional emergencies outbreak more unexpectedly and diffuse more quickly and broadly. Secondary and derived disasters increase, and the impacts tend to be indirect and tremendous. Emergency management decisions are facing great challenges, and have attracted great concerns from government departments, academia and industries. In recent years, as a service-oriented computing mode, the cloud computing technology brings advantage in information sharing, resource allocating, and distributed high-performance computing, which makes it a feasible solution to unconventional emergency management, research, quick response and decision support. In this paper, we propose a cloud computation architecture for unconventional emergency management, which involves the key technologies including computation resource pooling, scalable extension of computation resource and services and user-centroid service management. The proposed architecture supports multilevel demand in computation and storage resource by providing services such as virtual machine, big data storage, web information detection and spatio-temporal data visualization. Three experimental scenarios are designed to validate the improvement of decision support capabilities and emergency response speed.",data oriented architecture,155,not included
886c398deebeaaa148ff227b9f8aa5cfcdc52241,to_check,semantic_scholar,J. Intell. Manuf.,2021-01-01,semantic_scholar,designing and developing smart production planning and control systems in the industry 4.0 era: a methodology and case study,https://www.semanticscholar.org/paper/886c398deebeaaa148ff227b9f8aa5cfcdc52241,"In furtherance of emerging research within smart production planning and control (PPC), this paper prescribes a methodology for the design and development of a smart PPC system. A smart PPC system uses emerging technologies such as the internet of things, big-data analytics tools and machine learning running on the cloud or on edge devices to enhance performance of PPC processes. It achieves this by using a wider range of data sources from the production system, capturing and utilizing the experience of production planners, using analytics and machine learning to harness insights from the data and allowing dynamic and near real-time action to the continuously changing production system. The proposed methodology is illustrated with a case study in a sweets and snacks manufacturing company, to highlight the key considerations and challenges production managers might face during its application. The case further demonstrates considerations for scalability and flexibility via a loosely coupled, service-oriented architecture and the selection of fitting algorithms respectively to address a business requirement for a short-term, multi-criteria and event-driven production planning and control solution. Finally, the paper further discusses the challenges of PPC in smart manufacturing and the importance of fitting smart technologies to planning environment characteristics.",data oriented architecture,156,not included
9ded38d29a6f4dfa5357cdb061b3772823ecf322,to_check,semantic_scholar,Journal of Grid Computing,2018-01-01,semantic_scholar,big data-oriented paas architecture with disk-as-a-resource capability and container-based virtualization,https://www.semanticscholar.org/paper/9ded38d29a6f4dfa5357cdb061b3772823ecf322,"With the increasing adoption of Big Data technologies as basic tools for the ongoing Digital Transformation, there is a high demand for data-intensive applications. In order to efficiently execute such applications, it is vital that cloud providers change the way hardware infrastructure resources are managed to improve their performance. However, the increasing use of virtualization technologies to achieve an efficient usage of infrastructure resources continuously widens the gap between applications and the underlying hardware, thus decreasing resource efficiency for the end user. Moreover, this scenario is especially troublesome for Big Data applications, as storage resources are one of the most heavily virtualized, thus imposing a significant overhead for large-scale data processing. This paper proposes a novel PaaS architecture specifically oriented for Big Data where the scheduler offers disks as resources alongside the more common CPU and memory resources, looking forward to provide a better storage solution for the user. Furthermore, virtualization overheads are reduced to the bare minimum by replacing heavy hypervisor-based technologies with operating-system-level virtualization based on light software containers. This architecture has been deployed on a Big Data infrastructure at the CESGA supercomputing center, used as a testbed to compare its performance with OpenStack, a popular private cloud platform. Results have shown significant performance improvements, reducing the execution time of representative Big Data workloads by up to 4.5×.",data oriented architecture,157,included
78de7a5498144cae54ab3024654507c5b1ece5ac,to_check,semantic_scholar,Int. J. Electron. Bus. Manag.,2016-01-01,semantic_scholar,big data collections and services for building intelligent transport applications,https://www.semanticscholar.org/paper/78de7a5498144cae54ab3024654507c5b1ece5ac,This paper presents an approach for building data collections and cloud services required for building intelligent transport applications. Services implement Big Data analytics functions that can bring new insights and useful correlations of large data collections and provide knowledge for managing transport issues. Applying data analytics to transport systems brings better understanding to the transport networks revealing unexpected choking points in cities. This facility is still largely inaccessible to small companies and citizens due to their limited access to computational resources. A cloud service oriented architecture opens new perspectives for democratizing the use of efficient and personalized big data management and analytics.,data oriented architecture,158,not included
70b81a624fc4732e03a427e3b1936afcad7ca1c9,to_check,semantic_scholar,16th International Conference on Advanced Communication Technology,2014-01-01,semantic_scholar,"balancing scalability, performance and fault tolerance for structured data (bspf)",https://www.semanticscholar.org/paper/70b81a624fc4732e03a427e3b1936afcad7ca1c9,"Analytical business applications generate reports that give a trend predicting insight into the organization's future, estimating the financial graphs and risk factors. These applications work on huge amounts of data, which comprises of decades of market and company records, and decision logs of an organization. Today, limit of big data is touching zeta-bytes and the structured data makes only 20% of today's data. 20% of a giga-byte can be ignorable in comparison to big data but 20% of big data itself cannot be neglected. Traditional data management tools are like step-dads when it comes to running cross table analytical queries on structured data in distributed processing environment; response time to these data management tools are high because of the ill-aligned data sets and complex hierarchy of distributed computing environment. Data alignment requires a complete shift in data deployment paradigm from row oriented storage layout to column oriented storage layout, and complex hierarchy of distributed computing environment can be handled by keeping metadata of entire data set. Paper proposes an approach to ease the deployment of structured data into the distributed processing environment by arranging data into column-wise combinational entities. Response time to analytical queries can be lowered with the support of two concepts; Shared architecture and Multi path query execution. Highly scalable systems are Shared Nothing architecture based but degradation in performance and fault tolerance are the side effects that came with high scalability. Proposed method is an effort to balance the equation between scalability, performance and fault tolerance. And due to the limited scope of this paper we concentrate on issues and solutions for structured data only. Shared architecture and active backup helps improving the system's performance by sharing the work-load-per-node. BSPF's clustering methodology sheds the data pressure points to minimize the data loss per node crash.",data oriented architecture,159,not included
3f8636f8685944cc4b6b88d568e50ee9e524099a,to_check,semantic_scholar,International Journal of Innovative Technology and Exploring Engineering,2019-01-01,semantic_scholar,big data architectures: a detailed and application oriented analysis,https://www.semanticscholar.org/paper/3f8636f8685944cc4b6b88d568e50ee9e524099a,"Big Data refers to huge amounts of heterogeneous data from both traditional and new sources, growing at a higher rate than ever. Due to their high heterogeneity, it is a challenge to build systems to centrally process and analyze efficiently such data which are internal and external to organizations. A Big data architecture describes the blueprint of a system handling massive volume of data during its storage, processing, analysis and visualization. Several architectures belonging to different categories have been proposed by academia and industry but the field is still lacking benchmarks. Therefore, a detailed analysis of the characteristics of the existing architectures is required in order to ease the choice between architectures for specific use cases or industry requirements. The types of data sources, the hardware requirements, the maximum tolerable latency, the fitment to industry, the amount of data to be handled are some of the factors that need to be considered carefully before making the choice of an architecture of a Big Data system. However, the wrong choice of architecture can result in huge decline for a company reputation and business. This paper reviews the most prominent existing Big Data architectures, their advantages and shortcomings, their hardware requirements, their open source and proprietary software requirements and some of their realworld use cases catering to each industry. The purpose of this body of work is to equip Big Data architects with the necessary resources to make better informed choices to design optimal Big Data systems.",data oriented architecture,160,not included
7f3cd3fe2c75c3816f5fca0ac61caca5122c06cc,to_check,semantic_scholar,2016 5th International Conference on Multimedia Computing and Systems (ICMCS),2016-01-01,semantic_scholar,a multi-agent based on ant colony model for urban traffic management,https://www.semanticscholar.org/paper/7f3cd3fe2c75c3816f5fca0ac61caca5122c06cc,"This paper presents a conception model of a distributed algorithm as a heuristic (meta-heuristic) method inspired from the ant colony system which consists on exploiting pheromone information to find the shortest path from the food source to the nest, in order to optimize the urban traffic through a graph by orienting vehicles to make the best decision to choose the optimal road and to favor the fluency of the urban traffic. For this purpose, multi-agent system architecture will be proposed using embedded agents which aim to interconnect the various objects influencing the urban traffic. This interaction comprises an exchange of many informations and big data coming from many different devices existing in the real world. For this reason, the place of internet of things (IoT) technology is assured in our paper therefore will be discussed.",data oriented architecture,161,not included
abe96d6250409eaa4906436143dd90b32e426ce2,to_check,semantic_scholar,,2017-01-01,semantic_scholar,proposed architecture of mongodb-hive integration,https://www.semanticscholar.org/paper/abe96d6250409eaa4906436143dd90b32e426ce2,"There is tremendous growth in heterogeneous and unstructured data in last few years. Various NoSQL databases have been developed to store and query this humongous data. MongoDB is prevailing document oriented database among NoSQL databases. MongoDB has been chosen among other technologies because of its ability to work with variety of latest as well as conventional technologies. It provides drivers for almost every development language. This paper summarizes work of various authors who have compared and integrated MongoDB with other big data technologies. In most cases, MongoDB gives better performance in terms of various parameters. Further, after carrying out critical analysis , an architecture is being proposed to integrate MongoDB with Hive. It utilizes the SQL like features of Hive for SQL familiar users.",data oriented architecture,162,not included
56f2a6aceb199553ce4bc1d4d5b98594c6fe044f,to_check,semantic_scholar,2017 IEEE International Congress on Big Data (BigData Congress),2017-01-01,semantic_scholar,scmat: a mechanism presuming scms to efficiently enable both olap and oltp,https://www.semanticscholar.org/paper/56f2a6aceb199553ce4bc1d4d5b98594c6fe044f,"Many commercial DBMSs based on a column-oriented storage method have been used to analyze large-scale data. However, the column-oriented DBMS is difficult to use for processing big-data analysis updated in real time, because the column-oriented storage performs inefficient OLTP when processing row-oriented updates. Therefore, we attempted to enable the column-oriented DBMS to efficiently process OLTP for performing big data analysis. In this paper, we propose a DBMS architecture by focusing on storage class memory (SCM) such as STT-MRAM, PRAM, and ReRAM of new storage devices used in future computing. Our approach assumed that SCMs have not yet been considered, we propose a TiD-based update index for modifying the column data using SCMs in real time. Moreover, the DBMS mechanism we consider is able to identify a row of the column data such that we efficiently use a materialization method for aggregation in OLAP in which users perform a similar OLAP query for data analysis.",data oriented architecture,163,not included
0dda959d8e17115a71a0c0c1d6a31c3d0715207b,to_check,semantic_scholar,2014 International Symposium on Computer Architecture and High Performance Computing Workshop,2014-01-01,semantic_scholar,watershed reengineering: making streams programmable,https://www.semanticscholar.org/paper/0dda959d8e17115a71a0c0c1d6a31c3d0715207b,"Most high-performance data processing (aka big-data) systems allow users to express their computation using abstractions (like map-reduce) that simplify the extraction of parallelism from applications. Most frameworks, however, do not allow users to specify how communication must take place: that element is deeply embedded into the run-time system (RTS), making changes hard to implement. In this work we describe our reengineering of the Watershed system, a framework based on the filter-stream paradigm and focused on continuous stream processing. Like other big-data environments, watershed provided object-oriented abstractions to express computation (filters), but the implementation of streams was an RTS element. By isolating stream functionality into appropriate classes, combination of communication patterns and reuse of common message handling functions (like compression and blocking) become possible. The new architecture even allow the design of new communication patterns, for example, allowing users to choose MPI, TCP or shared memory implementations of communication channels as their problem demand. Applications designed for the new interface showed reductions in code size on the order of 50%and above in some cases, with no significant performance penalty.",data oriented architecture,164,not included
5c4da82d61b08e94a26d39ed43820e35fa10b871,to_check,semantic_scholar,,2016-01-01,semantic_scholar,týr: efficient transactional storage for data-intensive applications,https://www.semanticscholar.org/paper/5c4da82d61b08e94a26d39ed43820e35fa10b871,"As the computational power used by large-scale applications increases, the amount of data they need to manipulate tends to increase as well. A wide range of such applications requires robust and flexible storage support for atomic, durable and concurrent transactions. Historically, databases have provided the de facto solution to transactional data management, but they have forced applications to drop control over data layout and access mechanisms, while remaining unable to meet the scale requirements of Big Data. More recently, key-value stores have been introduced to address these issues. However, this solution does not provide transactions, or only restricted transaction support, compelling users to carefully coordinate access to data in order to avoid race conditions, partial writes, overwrites, and other hard problems that cause erratic behaviour. We argue there is a gap between existing storage solutions and application requirements that limits the design of transaction-oriented data-intensive applications. In this paper we introduce Tyr, a massively parallel distributed transactional blob storage system. A key feature behind Tyr is its novel multi-versioning management designed to keep the metadata overhead as low as possible while still allowing fast queries or updates and preserving transaction semantics. Its share-nothing architecture ensures minimal contention and provides low latency for large numbers of concurrent requests. Tyr is the first blob storage system to provide sequential consistency and high throughput, while enabling unforeseen transaction support. Experiments with a real-life application from the CERN LHC show Tyr throughput outperforming state-of-the-art solutions by more than 100%.",data oriented architecture,165,not included
1711c2c6a8e476b124c6c25cd83b87650e4e9e81,to_check,semantic_scholar,,2016-01-01,semantic_scholar,systems theory based architecture framework for complex system governance,https://www.semanticscholar.org/paper/1711c2c6a8e476b124c6c25cd83b87650e4e9e81,"SYSTEMS THEORY BASED ARCHITECTURE FRAMEWORK FOR COMPLEX SYSTEM GOVERNANCE Bry Carter Old Dominion University, 2016 Director: Dr. Charles B. Keating The purpose of this research was to develop a systems theory based framework for complex system governance using grounded theory approach. Motivation for this research includes: 1) the lack of research that identifies modeling characteristics for complex system governance, 2) the lack of a framework rooted in systems theory to support performance of complex system governance functions for maintaining system viability. This research focused on answering: What systems theoretic framework can be developed to inform complex system governance and enable articulation of governance function performance? The grounded theory research approach utilized three phases. First, the literature in systems theory, management cybernetics, governance and enterprise architecture was synthesized and open-coded to generalize main themes using broad analysis in NVivo software, researcher note taking in EndNote, and cataloging in Excel spreadsheets. Second, the literature underwent axial-coding to identify interconnections and relevance to systems theory and complex system governance, primarily using Excel spreadsheets. Finally, selective coding and interrelationships were identified and the complex system governance architecture framework was shaped, reviewed, and validated by qualified experts. This research examined a grounded theory approach not traditionally used in systems theory research. It produced a useful systems theory based framework for practical application, bridging the gap between theory and practice in the emerging field of complex system governance. Theoretical implications of this research include identifying the state of knowledge in each literature domain and the production of a unique framework for performing metasystem governance functions that is analytically generalizable. Management cybernetics, governance, and systems theory are expanded through a testable tool for meta-level organizational and system governance theories. Enterprise architecture is advanced with a multi-disciplinary framework that coherently presents and facilitates new use for architecture at the metasystem level. Methodological implications of this research include using grounded theory approach for systems theory research, where it is atypical. Although a non-traditional method, it provides an example for conducting fruitful research that can contribute knowledge. Practical implications of this research include a useable framework for complex system governance which has never before existed and a living structure adaptable to evolutionary change coming from any related domain or future practical application feedback. Copyright, 2016, by Bry Carter, All Rights Reserved. iv This dissertation is dedicated to Esmeralda and Alexandra. -Together Foreverv ACKNOWLEDGMENTS I am most grateful to Dr. Charles B. Keating, my Advisor, for opening the aperture of my worldview in systems thinking and inspiring me to be part of a Learning Community on the leading edges of complex system governance. Thank you Dr. Mamadou D. Seck, Dr. Teddy Cotter, and Dr. James C. Pyne for your academic partnership and oversight as research committee members. Thank you Dr. Kim Sibson for your time and effort conducting editing review. Thank you Learning Community members for your professional partnership and critical peer reviews of this research and related briefings, journal articles, and book chapter material. I look forward to continuing the journey with you. Many cast doubt on the potential for return on investment in time and resources required to pursue this endeavor of independent scholarly research, but never once was there a shred of doubt expressed by my devoted wife or loving daughter despite the many competing challenges we faced together along the way. Esmeralda and Alexandra, thank you. vi NOMENCLATURE ADP Architecture Development Process AF-EAF Air Force Enterprise Architecture Framework AFIoT IEEE P2413 – Architecture Framework for the Internet of Things AGA Australian Government Architecture Reference Models AGATE Atelier de Gestion de l’ArchiTecturE des Systèmes d’Information et de Communication AM Avancier Methods ARCHI ArchiMate AUSDAF Australian Defence Architecture Framework AAF Automotive Architecture Framework ATO Australian Taxation Office BCA Business Capability Architecture BDAF Big Data Architecture Framework BEAM Business Enterprise Architecture Modeling BPEAM Best Practice Enterprise Architecture Management CAFCR Customer Objectives, Application, Functional, Conceptual, and Realisation Model CAFEA Common Approach to Federal Enterprise Architecture CBDI-SAE CBDI Service Architecture & Engineering (CBDI-SAETM) for SOA CEA CEA Framework: A Service Oriented Enterprise Architecture Framework CEAF Commission Enterprise IT Architecture Framework CIAF Capgemini Integrated Architecture Framework vii CSG Complex System Governance CSGAF Complex System Governance Architecture Framework DoDAF Department of Defense Architecture Framework DND/CF Canadian Department of National Defense and the Canadian Forces DNDAF DN/CF Architecture Framework DRA1 Dragon 1 DYA Dynamic Architecture EA Enterprise Architecture EAB Enterprise Architecture Blueprinting E2AF Extended Enterprise Architecture Framework EAM-PC EAM Pattern Catalog EAP Enterprise Architecture Design Principles EEAF US OMB Enterprise Architecture Assessment Framework EES Extended Enterprise Systems EPCAF EPC Global Architecture Framework ESAAF European Space Agency Architecture Framework ESG Enterprise Systems Governance ESSAF Essential Architecture Framework eTOM Business Process Framework EXAF Extreme Architecture Framework FEAF Federal Enterprise Architecture Framework FESS Framework of Enterprise Systems and Structures viii FFLV+GODS Functions-Flows-Layers-Views + Governance-OperationsDevelopment-Support FMLS-ADF FMLS Architecture Description Framework 3.0 FSAM Federal Segment Architecture Methodology GA Garland and Anthony GEAF Gartner’s Enterprise Architecture Framework GERA ISO 15704 Generic Enterprise Reference Architecture HEAF Health Enterprise Architecture Framework HV Human View (NATO) IADS IBM Architecture Description Standard IAF Index Architecture Framework ICODE iCode Security Architecture Framework IFW IBM Information Framework 3D EAF 3-Dimensional Enterprise Architecture Framework 4+1 Kruchten’s 4+1 View Model LEAD Leading Enterprise Architecture Development Practice LST Living Systems Theory MACCIS An Architecture Description Framework for Technical Infostructures and their Enterprise Environment MCS Minimal Critical Specifications MBSA Model Based System Architecture MEGAF Mega-modeling Architecture Framework MODAF Ministry of Defense Architecture Framework ix MP Metasystem Pathology MV Metasystem Viewpoint NAF NATO Architecture Framework NIST-EAM NIST Enterprise Architecture Model OIO OIO Enterprise Architecture Method PEAF Pragmatic Enterprise Architecture PPOOA Processes Pipeline in Object Oriented Architectures PRINCE2 Projects In Controlled Environments PRISM Partnership for Research in Information Systems Management QGEA Queensland Government Enterprise Architecture RASDS Reference Architecture for Space Data Systems RM-ODP ISO Reference Model for Open Distributed Processing RWSSA Rozanski and Woods S4V Siemens 4 Views SABSA Sherwood Applied Business Security Architecture SASSY Self-Architecting Software Systems SDLC System Development Life Cycle SGCAF Smart Grid Conceptual Architecture Framework SoS System of Systems ST Systems Theory TEAF (US) Treasury Enterprise Architecture Framework TOGAF The Open Group Architecture Framework TRAK The Rail Architecture Framework x UADF Universal Architecture Description Framework VCD Value Chain Diagram VSM Viable System Model WFM Work Flow Model xAF Extensible Architecture Framework ZAF Zachman Framework xi TABLE OF CONTENTS LIST OF TABLES ...................................................................................................................... xiii LIST OF FIGURES ....................................................................................................................... xv Chapter I INTRODUCTION ...................................................................................................................... 1 Problem Statement and Background ............................................................................................ 1 Research Question ....................................................................................................................... 9 Research Purpose ......................................................................................................................... 9 Research Delimitations .............................................................................................................. 10 Research Significance ................................................................................................................ 11 Research Limitations ................................................................................................................. 12 Dissertation Structure ................................................................................................................ 14 Chapter Summary ...................................................................................................................... 15 II LITERATURE REVIEW ........................................................................................................ 16 Literature Domain Reviews and Critique .................................................................................. 17 Chapter Summary ...................................................................................................................... 45 III RESEARCH PERSPECTIVE ..................................................................",data oriented architecture,166,not included
0e58e4214353fe3721a849a2eed593c4e4ec0a33,to_check,semantic_scholar,ICCBR,2017-01-01,semantic_scholar,building an integrated cbr-big data oriented architecture for case-based reasoning systems,https://www.semanticscholar.org/paper/0e58e4214353fe3721a849a2eed593c4e4ec0a33,"The growth of intensive data-driven decision-making is now being recognized broadly. Big data systems are mainstream and the demand for building systems that able to process data streams is growing. Yet many decision support systems act like ”black boxes”, providing little or no transparency in the rationale of their processes [1]. The ”black box” methodologies are not acceptable in crucial domains like health care, aviation, and maintenance. Experts prefer to reason the decisions. Current big data strategies tend to process in-motion data and o↵er many potential scenarios to work with. The big data term refers to dynamic, large, structured and unstructured volumes of data generated from di↵erent sources with di↵erent formats [2]. Therefore, it is a must for CBR systems that tends to process the in-motion data to manage their sub-tasks, such as collecting and formatting data, case base maintenance, cases retrieval, cases adaptation and retaining new cases [3]. In my research I will describe the idea of spanning the gap between CBR and Big Data based on the SEASALT architecture [4] [5]. SEASALT is an application independent architecture to work with heterogeneous data repositories and modularizing knowledge. It was proposed based on the CoMES approach to develop collaborative multi-expert systems and provides an application-independent architecture that features knowledge acquisition from a Web community, knowledge modularization, and agent-based knowledge maintenance. Its first research prototype was developed for the travel medicine application [4]. SEASALT aims to provide a coherent multi-agent CBR architecture that can define the outlines and interactions to develop multi-agent CBR systems.",data oriented architecture,167,included
7f31ef32e8dcff0e41b5bc6a4c54039e3e690c04,to_check,semantic_scholar,"2018 Fifth International Conference on Parallel, Distributed and Grid Computing (PDGC)",2018-01-01,semantic_scholar,big data analytics: performance evaluation for high availability and fault tolerance using mapreduce framework with hdfs,https://www.semanticscholar.org/paper/7f31ef32e8dcff0e41b5bc6a4c54039e3e690c04,"Big data analytics helps in analyzing structured data transaction and analytics programs that contain semi-structured and unstructured data. Internet clickstream data, mobile-phone call details, server logs are examples of big data. Relational database-oriented dataset doesn't fit in traditional data warehouse since big data set is updated frequently and large amount of data are generated in real time. Many open source solutions are available for handling this large scale data. The Hadoop Distributed File System (HDFS) is one of the solutions which helps in storing, managing, and analyzing big data. Hadoop has become a standard for distributed storage and computing in Big Data Analytic applications. It has the capability to manage distributed nodes for data storage and processing in distributed manner. Hadoop architecture is also known as Store everything now and decide how to process later. Challenges and issues of multi-node Hadoop cluster setup and configuration are discussed in this paper. The troubleshooting for high availability of nodes in different scenarios for Hadoop cluster failure are experimented with different sizes of datasets. Experimental analysis carried out in this paper helps to improve uses of Hadoop cluster effectively for research and analysis. It also provides suggestions for selecting size of Hadoop cluster as per data size and generation speed.",data oriented architecture,168,not included
6782131a02bc88c3a5a3a39c5d3f579da059c241,to_check,semantic_scholar,SoICT 2018,2018-01-01,semantic_scholar,overall structural system solution for supporting services and tourists management oriented on smart city in viet nam,https://www.semanticscholar.org/paper/6782131a02bc88c3a5a3a39c5d3f579da059c241,"Recently, ""Smart tourism"" has appeared as a new term to describe the application of the technological advancements that rely on sensors, big data processing technique, open data, open API, new way of connecting and exchanging between humans and machines and multi-device (such as IoT, RFID, and NFC) in tourism. When these technologies are utilized, the digital data become practical and valuable products. Besides, the mobile revolution, and specifically the role of the smartphone and its many opportunities to support travel experiences, is especially worth mentioning in this context. In addition, new management tool for the government, new business opportunities for travel agencies, as well as new experiences for tourists are created. Therefore, in this paper, a model for developing sustainable and intelligent tourism is studied and then an overall architecture model of the information system that can provide supporting services and tools for visitor management (Smart Tourism Service Centre -- STSC) is proposed for fostering the smart cities in Vietnam, in general, and Danang, in particular.",data oriented architecture,169,not included
31dc692d87881f935918f83c44892e6dc9ee15de,to_check,semantic_scholar,Wirel. Pers. Commun.,2020-01-01,semantic_scholar,µbigmsa-microservice-based model for big data knowledge discovery: thinking beyond the monoliths,https://www.semanticscholar.org/paper/31dc692d87881f935918f83c44892e6dc9ee15de,"Enterprise thrives on software applications that are built to fulfil the core business requirements. A single business application can offer a cluster of capabilities to generate value from processing huge amount of data often termed as Big Data. The time-based requirements of these applications are satisfied frequently by applying monolithic approaches with increased complexity and less scalability. Traditional approaches for Big Data Analytics suffer from overpriced, excessive and irrelevant data transfer owing to the constricted coupling amongst computing resources and data processing logic. Service-oriented approach came into existence as a new paradigm to enable applications to be rendered as service for better flexibility and scalability. Service orientation architecture avoids monolithic style but web services, one of its major implementation encourages monolith development of software application. Thus building a scalable, robust, resilient, cost-effective and optimum solution is one of the major requirements for outsized data. New software development style Microservices offer low degree of coupling and smaller size. This work reviews the existing and prevalent approaches like monolithic architecture in this area along with their drawbacks. This work also proposes a generic microservice model µBIGMSA for handling Knowledge Discovery in Big Data. Reference applications are implemented using proposed model. The effectiveness of the proposed model is evaluated by comparing the reference application with the monolithic application using various software metrics.",data oriented architecture,170,not included
c70d482f449d192b7be3f207488b37a3706d5623,to_check,semantic_scholar,Computing,2019-01-01,semantic_scholar,bringing sql databases to key-based nosql databases: a canonical approach,https://www.semanticscholar.org/paper/c70d482f449d192b7be3f207488b37a3706d5623,"Big Data management has brought several challenges to data-centric applications, like the support to data heterogeneity, rapid data growth and huge data volume. NoSQL databases have been proposed to tackle Big Data challenges by offering horizontal scalability, schemaless data storage and high availability, among others. However, NoSQL databases do not have a standard query language, which bring on a steep learning curve for developers. On the other hand, traditional relational databases and SQL are very popular standards for storing and manipulating critical data, but they are not suitable to Big Data management. One solution for relational-based applications to move to NoSQL databases is to offer a way to access NoSQL databases through SQL instructions. Several approaches have been proposed for translating relational database schemata and operations to equivalent ones in NoSQL databases in order to improve scalability and availability. However, these approaches map relational databases only to a single NoSQL data model and, sometimes, to a specific NoSQL database product. This paper presents a canonical approach, called SQLToKeyNoSQL , that translates relational schemata as well as SQL instructions to equivalent schemata and access methods of any key-oriented NoSQL database. We present the architecture of our layer focusing on the mapping strategies as well as experiments that evaluate the benefits of our approach against some state-of-art baselines.",data oriented architecture,171,not included
fa5de23db381ee6c9719050cd3ab6fd53a8cb2ff,to_check,semantic_scholar,Conf. Computing Frontiers,2017-01-01,semantic_scholar,selective off-loading to memory: task partitioning and mapping for pim-enabled heterogeneous systems,https://www.semanticscholar.org/paper/fa5de23db381ee6c9719050cd3ab6fd53a8cb2ff,"Processing-in-Memory (PIM) is returning as a promising solution to address the issue of memory wall as computing systems gradually step into the big data era. Researchers continually proposed various PIM architecture combined with novel memory device or 3D integration technology, but it is still a lack of universal task scheduling method in terms of the new heterogeneous platform. In this paper, we propose a formalized model to quantify the performance and energy of the PIM+CPU heterogeneous parallel system. In addition, we are the first to build a task partitioning and mapping framework to exploit different PIM engines. In this framework, an application is divided into subtasks and mapped onto appropriate execution units based on the proposed PIM-oriented Earliest-Finish-Time (PEFT) algorithm to maximize the performance gains brought by PIM. Experimental evaluations show our PIM-aware framework significantly improves the system performance compared to conventional processor architectures.",data oriented architecture,172,not included
6fa5379cb8dacbba39db3cc2aee9df709bce0645,to_check,semantic_scholar,,2020-01-01,semantic_scholar,a comprehensive overview of fog data processing and analytics for healthcare 4.0,https://www.semanticscholar.org/paper/6fa5379cb8dacbba39db3cc2aee9df709bce0645,"In recent technological era, the healthcare industry has been gaining momentum toward service-oriented facilities to the customers. The primary aim of the Healthcare 4.0 is to provide healthcare services anytime and anywhere. This is possible, as Healthcare 4.0 targets integration with current technologies like Internet of Things (IoT), Cloud Computing, Big Data, and Machine Learning. However, the integration of Healthcare 4.0, with IoT and cloud computing through Internet has several challenges in handling real-time applications such as access latency, cost, and lack of service availability. On the other hand, the fog computing (FC) is able to overcome these challenges using fog devices, that are capable of optimizing the delay in information gathering and processing. The primary advantage of the fog computing system is the geographical location of fog devices within proximity of patient and IoT healthcare systems. This enables fog computing system to perform computation, storage and networking services with lesser delay and jitter. However, the major issue in fog computing is to handle the voluminous healthcare data generate from different IoT healthcare edge systems. Hence, this chapter targets to present on various fog-based data processing and data analysis (FDPA) mechanisms in fog computing solutions toward achieving the objectives of Healthcare 4.0. This chapter is divided into five major sections namely architecture of fog data processing and analytics, applications of FDPA, data processing algorithms in fog computing and data compression mechanisms and data analysis mechanisms in Fog computing toward Healthcare 4.0. The fog data architecture discusses various layers namely sensing layer, fog gateway layer, fog-based data processing and data analysis layer, cloud layer, and service layer. Here, the process of sensing of healthcare data, maintenance of data, and various methods to analyze healthcare data are discussed. Further, the healthcare data gathered from sensor devices are raw and redundant in data, hence they are needed for various data processing algorithms for fog-based healthcare systems. Hence, various data processing techniques such as Dynamic Time Warping, Clinical Speech Processing are discussed. Next, in fog computing, the data compression techniques are required for optimizing the bandwidth consumption and energy efficiency are presented. Next, data analytics mechanism such as real-time decisive analysis, real-time control and context analysis, and real-time data analysis are presented.",data oriented architecture,173,not included
c21a315dd1e6a7853e9f25aed34c5c0e6cba2d77,to_check,semantic_scholar,MATEC Web of Conferences,2020-01-01,semantic_scholar,a referenced cyber physical system for compressor manufacturing,https://www.semanticscholar.org/paper/c21a315dd1e6a7853e9f25aed34c5c0e6cba2d77,"Compressor is a typical high-end discrete product，with the shortening of product life cycle and the enhancement of the degree of product customization, the traditional compressor manufacturing system architecture cannot meet the requirements of comprehensive digital management of compressor from body scheme design to parts production line, logistics management, operation and maintenance monitoring and evaluation. This paper presents a compressor manufacturing system architecture based on digital twinning, and establishes an Internet platform for compressor industry oriented to remote coordination from three aspects of compressor design, production, operation and maintenance. The platform includes industrial Internet infrastructure layer, physical space entity model layer, virtual space multidimensional model layer, physical space and virtual space multidimensional model correlation and mapping layer, big data intelligent analysis decision-making layer, and digital twin application layer. Through the establishment of the compressor product design and simulation model of digital twin, compressor production process digital twin model, compressor fault diagnosis and remote operations digital twin model, implementation is based on the number of compressor collaboration in manufacturing industrial Internet platform twin system, leading the transformation and upgrading of intelligent manufacturing industry, compressor industry sustainable development ability and international competitiveness.",data oriented architecture,174,not included
8be57d73db4c10d9c0a41fdfc2e6d4f868689315,to_check,semantic_scholar,2018 IEEE 4th International Conference on Computer and Communications (ICCC),2018-01-01,semantic_scholar,design of manufacturing big data access platform based on soa,https://www.semanticscholar.org/paper/8be57d73db4c10d9c0a41fdfc2e6d4f868689315,"In view of the lack of big data access platform in current manufacturing industry, the big data access platform was studied based on SOA. With the analysis of big data characteristics and the big data access business in manufacturing industry, the overall architecture of the service oriented manufacturing big data access platform was built. The whole technical scheme of the platform was introduced and the platform functional design was the elaborated. The platform has functions of the data access management, data processing management, log management, database management and the distributed storage management. These provide good foundation for manufacturing big data service.",data oriented architecture,175,not included
cd876a703abbef14161ea8f1707909db6591a224,to_check,semantic_scholar,2016 International Conference on Robots & Intelligent System (ICRIS),2016-01-01,semantic_scholar,a high-performance retrieval method of mass data oriented to cloud computing,https://www.semanticscholar.org/paper/cd876a703abbef14161ea8f1707909db6591a224,"With the acceleration development of the Internet of Things and big data, the importance of high-performance mass data retrieval is gradually highlighted. Cloud computing is the distributed data calculation model that is suitable for big data, and has been widely used. In this paper, firstly, the technology of cloud computing is introduced. Secondly, retrieval technology of mass data is analyzed, finally a high-performance retrieval method of mass data based on Hadoop is proposed. The architecture of this method is composed of HDFS, MapReduce, and Hive, and is divided into four layers from bottom to top: access layer, interface layer, management layer and storage layer.",data oriented architecture,176,included
bb4fafc7412de2f4ea12aeaecadb2fbb8dd57c0b,to_check,semantic_scholar,Sci. Program.,2021-01-01,semantic_scholar,research on the design of government affairs platform in the context of big data,https://www.semanticscholar.org/paper/bb4fafc7412de2f4ea12aeaecadb2fbb8dd57c0b,"Big data is a massive and diverse form of unstructured data, which needs proper analysis and management. It is another great technological revolution after the Internet, the Internet of Things, and cloud computing. This paper firstly studies the related concepts and basic theories as the origin of research. Secondly, it analyzes in depth the problems and challenges faced by Chinese government management under the impact of big data. Again, we explore the opportunities that big data brings to government management in terms of management efficiency, administrative capacity, and public services and believe that governments should seize opportunities to make changes. Brainlike computing attempts to simulate the structure and information processing process of biological neural network. This paper firstly analyzes the development status of e-government at home and abroad, studies the service-oriented architecture (SOA) and web services technology, deeply studies the e-government and SOA theory, and discusses this based on the development status of e-government in a certain region. Then, the deep learning algorithm is used to construct the monitoring platform to monitor the government behavior in real time, and the deep learning algorithm is used to conduct in-depth mining to analyze the government's intention behavior.",data oriented architecture,177,not included
5db86e5d1bf2647d020ec6cd736e39d30766b850,to_check,semantic_scholar,,2020-01-01,semantic_scholar,background and research challenges for fc for healthcare 4.0,https://www.semanticscholar.org/paper/5db86e5d1bf2647d020ec6cd736e39d30766b850,"The revolution in the healthcare domain was originated with the emergence of modular IT system in healthcare (Health 1.0) to the healthcare extension of Industry 4.0 (Health 4.0) integrated with Internet of Things (IoT), Cyber Physical Systems, Artificial Intelligence (AI), Cloud Computing, Big Data, Bioinformatics, Robotics, Precision Medicine, to cite a few. Applying IoT in healthcare 4.0, massive amount of patients’ data is generated by the sensors and this data is accessible to the doctors at any time and at any place for analysis and for appropriate line of treatment. The sensors in the healthcare domain of IoT need to be wearable and wireless to monitor the patients on large scale. In addition, the analysis of data and decision of treatment should be done and communicated in as little amount of time as possible. Thus, the aggregation, storage, analysis, and maintenance of data should be such that the data is continuously available, portable, consistent, accurate, scalable, secure, and quickly transferable. These challenges constraint the energy, memory, communication, and processing capacity of the end devices (sensors) used. Hence, instead of relying entirely on remote data centers using Cloud computing, the gap is bridged by means of fog computing (near the healthcare premises). The factors affecting the architecture of fog computing in healthcare domain are location of patient, latency requirements, geographic distribution, heterogeneous data, scalability, real-time vs batch processing, mobility of end devices, etc. On the other side, use of fog computing in the healthcare has substantial challenges for researchers and organizations including application-oriented architecture prototype, modeling and deployment, infrastructure and network management, resource management, mobility of patients and hence data mobility, security and privacy of patients’ data, scalability, easy incorporation of various healthcare professionals’ proficiency with intelligent devices and sensors, and minimum latency time in case of life threatening situations. This chapter discusses background and research challenges of fog computing in Healthcare 4.0 with an aim to guide the researchers and stakeholders for the overall improvement in the functioning of the healthcare domain.",data oriented architecture,178,not included
7bc1dd8a4d0735f49ffe64e91e2a1f1f376118be,to_check,semantic_scholar,,2019-01-01,semantic_scholar,проблема анализа больших веб-данных и использование технологии data mining для обработки и поиска закономерностей в большом массиве веб-данных на практическом примере,https://www.semanticscholar.org/paper/7bc1dd8a4d0735f49ffe64e91e2a1f1f376118be,"The purpose of the work is to study the current problems and prospects of the solution for processing big data received or stored in the Internet (web data), as well as the possibility of practical realization of Data Mining technology for big web data on practical example. Materials and methods. The study included a review of bibliographic sources on big data analysis problems. Data Mining technology was used to analyze large web data, as well as computer modeling of a practical problem using the C # programming language and creating a DDL database structure for accumulating web data. Results. In the course of the work, the specifics of big data were described, the main characteristics of big data were highlighted, and modern approaches to processing big data were analyzed. A brief description of the horizontal-scalable architecture and the BI-solution architecture for big data processing is given. The problems of processing large web data are formulated: limiting the speed of access to data, providing access via network protocols through general-purpose networks. An example showing the approach to processing large web data was also implemented. Based on the idea of big data, the described complexities of web data processing and the methods of Data Mining, techniques were proposed for effectively solving the practical problem of processing and searching patterns in a large data array. The following classes have been developed in the C # programming language: Class of receiving web data via the Internet; Data conversion class; Intelligent data processing class; Created DDL script that creates a structure for the accumulation of web data. A single UML class diagram has been developed. The constructed system of data and classes allows to solve the main part of the problems of processing large web data and perform intelligent processing using Data Mining technology in order to solve the problem posed of identifying certain records in a large array. The combination of object-oriented approach, neural networks and BI-analysis to filter data will speed up the process of data processing and obtaining the result of the study Conclusion. According to the results of the study, it can be argued that the current state of technology for analyzing large web data allows you to efficiently process data objects, identify patterns, get hidden data and get full-fledged statistical data. The obtained results can be used both for the purpose of the initial study of big data processing technologies, and as a basis for developing an already real application for analyzing web data. The use of neural networks and the created universal classes-handlers makes the created architecture flexible and self-learning, and the class declarations and the base DDL structure will greatly simplify the development of program code.",data oriented architecture,179,not included
35aa6df81a8eaf3992658dba4b49f1d18f10094a,to_check,semantic_scholar,,2015-01-01,semantic_scholar,community-oriented networking technology,https://www.semanticscholar.org/paper/35aa6df81a8eaf3992658dba4b49f1d18f10094a,"The Internet Protocol (IP) communication technology used on the Internet has evolved and developed as a versatile communication technology that enables humans to communicate with each other. Nowadays, low-cost sensors, radio frequency identification (RFID), and scalable and high-speed wireless communication technology have made progress and have been applied to the field of “Internet of Things (IoT)” where all kinds of physical objects and things are able to connect to the Internet or the field of “cyberphysical systems” (CPS) which enables interaction between the Internet-connected physical world and cyberspace. IoT and CPS require a system for managing the vast amount of data (i.e. big data) generated by sensors, actuators and other devices, processing such data within the network, and sharing among the interested parties, but a communication model that manages all of the big data on a server or cloud has limits in terms of the communication speed and energy efficiency. Based on a recent white paper from Cisco, there will be 50 billion devices connected to Internet by 2020. Therefore, there is a need for a communication protocol with even higher scalability and real-time capabilities (immediate responsiveness) than the current IP communication. In many IoT systems and CPSs, the main communication will be the sharing of data within a community of objects, such as humans and things. However, the use of traditional IP communication based on a host-centric, end-to-end communication model for communication within a community with numerous objects will lead to an enormous number of communication paths or a significant increase in unnecessary communication traffic, resulting in overall degradation of communication performance and quality. Against such a backdrop, we propose a CommunityORiented IcN (CORIN), a community-oriented communication architecture using the concept of information-centric networking (ICN) which has been studied as a new paradigm for future network technologies. The ICN enables communication centered on information (content) rather than the host-centric communication premised by IP communication. Specifically, information (content) is acquired from a nearby router or node that stores (or caches) the content, through communication using the name of the content, without designating the location (IP address) of a server or the information provider. In CORIN, a “community name” is designated instead of the content name used in ICN to perform communication based on communities. A community used in CORIN is a group of users with common interests in information or content or network-connected users with some kind of",data oriented architecture,180,not included
badfe56ebd7348a8654365aacb162ec4c84368af,to_check,semantic_scholar,J. Intell. Fuzzy Syst.,2021-01-01,semantic_scholar,intelligent platform for real-time page view statistics using educational big data digital resource sharing,https://www.semanticscholar.org/paper/badfe56ebd7348a8654365aacb162ec4c84368af,"In order to meet the rapid growth of educational data, to automate the processing of educational data business, improve operational efficiency and scientific decision-making, a statistical analysis platform for educational data is designed, and Hadoop-based education is designed from the conceptual model, logical model, and physical model. Data warehouse; designed and researched the storage of educational multidimensional data model; and then compared and tested the query efficiency and storage space of HBase and Hive in the Hadoop ecosystem based on educational big data, and used HBase+Hive integrated architecture to complete the education data The statistical analysis tasks and the function of the educational data statistical analysis platform are transplanted to the educational big data platform based on Hadoop; the performance test of the conversion efficiency of educational big data in the ETL link is performed, which illustrates the effectiveness of the educational big data platform based on Hadoop. An object-oriented analysis and design method used to analyze and design the business requirements of teaching resource sharing services. From the perspective of managers and teachers, use case diagrams and use case description tables to define system business requirements. The role of teachers is further refined as the theme of teaching and research. Participants, participants in the subject teaching and research, initiators of simulation teaching research and development, participants, famous teachers, high-quality course judges and experts. The recording, accumulation, statistics and analysis of students’ learning behaviors will provide more valuable applications for school education.",data oriented architecture,181,not included
96bb8913c38529e8c2b935eb164744fdef61f100,to_check,semantic_scholar,,2020-01-01,semantic_scholar,research on garment mass customization architecture for intelligent manufacturing cloud,https://www.semanticscholar.org/paper/96bb8913c38529e8c2b935eb164744fdef61f100,"The deep integration of Internet, intelligent manufacturing and big data technology has promoted the development of products to be networked, digital, intelligent and personalized. The rapid iteration and differential segmentation of consumer demand has spawned new personalized consumer demand, transforming the traditional manufacturing model into a service-oriented manufacturing model. This paper analyses the large-scale customized operation mode of domestic and foreign clothing custom brands. In view of the transformation of traditional clothing industry, this paper proposes a solution to establish a large-scale custom clothing architecture under the vision of intelligent manufacturing cloud platform technology. This paper uses data mining and cloud computing and other methods to build an “Internet + manufacturing” innovation model with rapid collaboration under the umbrella of big data, and propose an architecture for mass customization of clothing, providing effective solutions and strategy recommendations for the transformation and upgrading of the traditional apparel industry.",data oriented architecture,182,not included
acb50d8487af3d4066b078d69d8301644e599046,to_check,semantic_scholar,OTM Workshops,2014-01-01,semantic_scholar,enterprise networks integration in a sensing environment: a case study,https://www.semanticscholar.org/paper/acb50d8487af3d4066b078d69d8301644e599046,"Internet of things, mobile Internet, cloud computing and big data technologies build a sensing environment for all kinds of businesses. Inter enterprise collaboration is meeting new challenges of omni-channel marketing, closed-loop supply chain and enterprise networks integration. A data convergence oriented enterprise networks integration architecture is developed in the paper. How to use the developed technologies to solve problems of product lifecycle management and omni-channel marketing management are discussed in detailed cases studies.",data oriented architecture,183,not included
00bffa682b9231e66460e7386efa9d2d80d1503e,to_check,semantic_scholar,,2016-01-01,semantic_scholar,optimized management of big data produced in brain disorder rehabilitation,https://www.semanticscholar.org/paper/00bffa682b9231e66460e7386efa9d2d80d1503e,"Brain disorders resulting from injury, disease, or health conditions can influence function of most parts of human body. Necessary medical care and rehabilitation is often impossible without close cooperation of several diverse medical specialists who must work jointly to choose methods that improve and support healing processes as well as to discover underlying principles. The key to their decisions are data resulting from careful observation or examination of the patient. We introduce the concept of scientific dataspace that involves and stores numerous and often complex types of data, e.g., the primary data captured from the application, data derived by curation and analytic processes, background data including ontology and workflow specifications, semantic relationships between dataspace items based on ontologies, and available published data. Our contribution applies big data and cloud technologies to ensure efficient exploitation of this dataspace, namely, novel software architectures, algorithms and methodology for its optimized management and utilization. We present its service-oriented architecture using a running case study and results of its data processing that involves mining and visualization of selected patterns optimized towards big and complex data we are dealing with.",data oriented architecture,184,not included
5d3162d9fa543922b88c53403ecfc883cddb7f6b,to_check,semantic_scholar,,2016-01-01,semantic_scholar,disrupting the chinese state: new actors and new factors,https://www.semanticscholar.org/paper/5d3162d9fa543922b88c53403ecfc883cddb7f6b,"How do the development of digital technology influence the architecture of China’s governance structure? This paper will focus on two elements that, it argues, are radically transforming the modus operandi of the Chinese state. First, it will discuss the rapid emergence of the huge private corporations that have come to dominate China’s Internet, and the increasing symbiosis between them and political processes. This paper will argue that a strategic public-private nexus is forming at the centre of China’s political architecture, where the particular properties of private Internet corporations are used to counter some of the perennial problems that plague the Party-State. Second, it will discuss the leadership’s perception of how new forms of data, data gathering, processing and analysis (generally referred to as “big data” (da shuju) may enhance its governing capabilities (zhizheng nengli). Prior e-governance efforts were largely dedicated at digitization of existing data, generally held by state bodies. However, in China as elsewhere, private corporations have rapidly developed new profit modes based on the exploitation of hitherto unmined data. Unsurprisingly, China’s control-oriented government sees this as a great opportunity to enhance its ability to monitor the activities of its citizens, businesses and government officials. One particular manifestation of this approach is the social credit system (shehui xinyong tixi) that is currently under development. This paper will argue that the data-empowered agenda has the potential to radically disrupt China’s information order. From the central point of view, it will erode the separation between the centre and the periphery, as encapsulated in the well-known proverb “the mountains are high, and the emperor far away” (shan gao, huangdi yuan). Nevertheless, as Internet-based approaches become institutionalized, it is equally likely that current governance pathologies will reproduce themselves in the online sphere. Please note: this is the working version of this paper. The published version can be found through the Brill database.",data oriented architecture,185,not included
3edf359def63c38a109ae4eda9b4d0fa5dbd2f66,to_check,semantic_scholar,"2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)",2016-01-01,semantic_scholar,bussola: a cloud collaborative platform of oriented services to passengers,https://www.semanticscholar.org/paper/3edf359def63c38a109ae4eda9b4d0fa5dbd2f66,"BUS Services Mobilizing Living Lab, namely BUSSOLA, focuses on means of transport for people to make a living lab on the move upon which to design, implement and test innovative services that uses and feeds platform SmartDataNet. In particular, thanks to several sensors and devices, the system pays attention on three main macro-areas: air quality monitoring, passengers monitoring and safety on board the vehicles. A distributed and modular architecture has been adopted, to communicate and manage heterogeneous information. The solution is based on cloud technology for a better flexibility and scalability system and an easier adaptation at future requirements in term of computational resource and storage. It allows to experiment and adopt paradigms typical of the world of the Internet of Things and the Internet of Services, it made available by the platform SmartDataNet starting from the processing of big data and open-data.",data oriented architecture,186,not included
10.1109/asru.2007.4430168,to_check,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),IEEE,2007-12-13 00:00:00,ieeexplore,a data-centric architecture for data-driven spoken dialog systems,https://ieeexplore.ieee.org/document/4430168/,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",data centric architecture,187,included
10.1109/icdcsw.2003.1203556,to_check,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",IEEE,2003-05-22 00:00:00,ieeexplore,"""data-centric to the max"", the splice architecture experience",https://ieeexplore.ieee.org/document/1203556/,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",data centric architecture,188,included
10.1109/cluster.2012.80,to_check,2012 IEEE International Conference on Cluster Computing,IEEE,2012-09-28 00:00:00,ieeexplore,a decoupled execution paradigm for data-intensive high-end computing,https://ieeexplore.ieee.org/document/6337781/,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",data centric architecture,189,included
10.1109/siot.2016.007,to_check,2016 International Workshop on Secure Internet of Things (SIoT),IEEE,2016-09-30 00:00:00,ieeexplore,addressing data-centric security requirements for iot-based systems,https://ieeexplore.ieee.org/document/7913560/,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",data centric architecture,190,included
10.1109/icce-china.2017.7991141,to_check,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),IEEE,2017-06-14 00:00:00,ieeexplore,an iot framework for intelligent roadside assistance system,https://ieeexplore.ieee.org/document/7991141/,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",data centric architecture,191,not included
10.1109/issnip.2005.1595552,to_check,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",IEEE,2005-12-08 00:00:00,ieeexplore,architectures for wireless sensor networks,https://ieeexplore.ieee.org/document/1595552/,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,data centric architecture,192,included
10.1109/bigdata.2015.7363971,to_check,2015 IEEE International Conference on Big Data (Big Data),IEEE,2015-11-01 00:00:00,ieeexplore,component based dataflow processing framework,https://ieeexplore.ieee.org/document/7363971/,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",data centric architecture,193,included
10.1109/icsea.2010.30,to_check,2010 Fifth International Conference on Software Engineering Advances,IEEE,2010-08-27 00:00:00,ieeexplore,content server architecture pattern for evolvability and scalability,https://ieeexplore.ieee.org/document/5615125/,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",data centric architecture,194,included
10.1109/aero.2005.1559422,to_check,2005 IEEE Aerospace Conference,IEEE,2005-03-12 00:00:00,ieeexplore,"data centric, position-based routing in space networks",https://ieeexplore.ieee.org/document/1559422/,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",data centric architecture,195,included
10.1109/icccn.2019.8847129,to_check,2019 28th International Conference on Computer Communication and Networks (ICCCN),IEEE,2019-08-01 00:00:00,ieeexplore,data-centric video for mixed reality,https://ieeexplore.ieee.org/document/8847129/,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",data centric architecture,196,included
10.1109/netsys.2019.8854515,to_check,2019 International Conference on Networked Systems (NetSys),IEEE,2019-03-21 00:00:00,ieeexplore,information-centric iot middleware overlay: vsl,https://ieeexplore.ieee.org/document/8854515/,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",data centric architecture,197,included
10.1109/aero.2017.7943816,to_check,2017 IEEE Aerospace Conference,IEEE,2017-03-11 00:00:00,ieeexplore,software architecture and design of the kontur-2 mission,https://ieeexplore.ieee.org/document/7943816/,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",data centric architecture,198,not included
10.1109/ciot.2018.8627124,to_check,2018 3rd Cloudification of the Internet of Things (CIoT),IEEE,2018-07-04 00:00:00,ieeexplore,"fogø5: unifying the computing, networking and storage fabrics end-to-end",https://ieeexplore.ieee.org/document/8627124/,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",data centric architecture,199,included
10.1049/cp.2012.1116,to_check,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),IET,2012-03-05 00:00:00,ieeexplore,design of real-time distributed system using dds,https://ieeexplore.ieee.org/document/6492723/,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,data centric architecture,200,included
10.1109/bigdata47090.2019.9006235,to_check,2019 IEEE International Conference on Big Data (Big Data),IEEE,2019-12-12 00:00:00,ieeexplore,hybrid 2d and 3d visual analytics of network simulation data,https://ieeexplore.ieee.org/document/9006235/,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,201,included
10.1109/iccworkshops49005.2020.9145301,to_check,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,supporting delay tolerant networking: a comparative study of epidemic routing and ndn,https://ieeexplore.ieee.org/document/9145301/,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",data centric architecture,202,not included
10.1016/j.future.2021.06.020,to_check,core,'Elsevier BV',2023-06-19 00:00:00,core,a big data-centric architecture metamodel for industry 4.0,,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",data centric architecture,203,included
10.2514/6.2012-549,to_check,core,,2012-01-01 00:00:00,core,towards a unified framework using cpacs for geometry management in aircraft design,,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",data centric architecture,204,included
10.1002/dac.2964,to_check,core,"John Wiley & Sons, Inc.",2017-01-01 00:00:00,core,push applications and dynamic content generation over content-centric networking,,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",data centric architecture,205,included
,to_check,core,,2012-01-01 00:00:00,core,measurements in opportunistic networks,,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",data centric architecture,206,included
,to_check,core,,2013-09-24 00:00:00,core,s.: persistent information state in a data-centric architecture,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,207,included
,to_check,core,,2001-01-01 00:00:00,core,adaptive collaboration for wired and wireless platforms - a data-centric architecture for collaboration environments uses xml to adapt shared data dynamically between devices with widely disparate capabilities.,,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",data centric architecture,208,included
,to_check,core,,2011-01-01 00:00:00,core,data serving climate simulation science at the nasa center for climate simulation,https://core.ac.uk/download/pdf/10560731.pdf,"The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",data centric architecture,209,included
,to_check,core,,2004-01-01 00:00:00,core,wireless sensor networks dynamic runtime configuration,,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",data centric architecture,210,included
,to_check,core,,2017-05-01 00:00:00,core,resource management in sensing services with audio applications,https://core.ac.uk/download/158321560.pdf,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",data centric architecture,212,included
,to_check,core,,2012-05-19 00:00:00,core,1 social-driven internet of connected objects,,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",data centric architecture,213,not included
,to_check,core,,2007-01-01 00:00:00,core,gestion de l'évolution des applications web,,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",data centric architecture,214,not included
,to_check,core,,2015-08-26 00:00:00,core,adaptive collaboration for wired and wireless platforms,,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",data centric architecture,215,included
,to_check,core,,2009-08-31 00:00:00,core,a context-oriented synchronization approach,,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",data centric architecture,216,included
,to_check,core,HAL CCSD,2017-03-27 00:00:00,core,towards blockchain-based auditable storage and sharing of iot data,https://core.ac.uk/download/145154055.pdf,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",data centric architecture,217,included
,to_check,core,,2018-01-01 00:00:00,core,collaborative systems engineering in the ascent abort-2 crew module/separation ring project,https://core.ac.uk/download/pdf/161999682.pdf,"Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",data centric architecture,218,not included
a6777903dbfc256b551043f93ebbb13fa923d2d1,to_check,semantic_scholar,Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003),2003-01-01,semantic_scholar,mobishare: sharing context-dependent data & services from mobile sources,https://www.semanticscholar.org/paper/a6777903dbfc256b551043f93ebbb13fa923d2d1,"The rapid advances in wireless communications technology and mobile computing have enabled personal mobile devices that we use in everyday life to become information and service providers by complementing or replacing fixed-location hosts connected to the wireline network. Such mobile resources is highly important for other moving users, creating significant opportunities for many interesting and novel applications. The MobiShare architecture provides the infrastructure for ubiquitous mobile access and mechanisms for publishing, discovering and accessing heterogeneous mobile resources in a large area, taking into account the context of both sources and requestors. Any wireless communication technology could be used between a device and the system. Furthermore, the use of XML-related languages and protocols for describing and exchanging metadata gives the system a uniform and easily adaptable interface, allowing a variety of devices to use it. The overall approach is data-centric and service-oriented, implying that all devices are treated as producers or requestors of data wrapped as information services.",data oriented architecture,219,not included
fc98ec63ffb5811fc6828dfea5b6e7423d3e186e,to_check,semantic_scholar,2010 IEEE International Conference on Web Services,2010-01-01,semantic_scholar,formal specification and verification of data-centric service composition,https://www.semanticscholar.org/paper/fc98ec63ffb5811fc6828dfea5b6e7423d3e186e,Service-oriented architecture (SOA) promotes a paradigm where ad-hoc applications are built by dynamically linking service-based software capabilities. Service providers follow specification standards to advertise their services’ capabilities and to enable loosely coupled integration between their services and other businesses over the Web. A major challenge in this domain is interpreting the data that must be marshaled between consumer and producer systems. We propose a framework to support formal modeling and contracts for data-centric Web services. We demonstrate how this framework can be used to verify correctness properties for composition of services.,data oriented architecture,220,included
1b7febba27b45a71123ac45717a1ad98bff0786f,to_check,semantic_scholar,SPLASH '12,2012-01-01,semantic_scholar,"the data, context and interaction paradigm",https://www.semanticscholar.org/paper/1b7febba27b45a71123ac45717a1ad98bff0786f,"This is a design track overview tutorial that provides a foundation for exploring and applying the DCI (Data, Context and Interaction) paradigm. DCI is a means to supporting full object orientation that restores much of the original object vision that has been lost by class-based design and programming. DCI focuses on objects and their relationships to the roles of human mental models by which end users and programmers reason about them generally. DCI leads to an architecture that extends contemporary object-oriented programming from its data-centric structure to focus more on the business value of system-level operations.",data oriented architecture,221,not included
eac74f4ee61fd9e69163b96c0b64710b9ed13a04,to_check,semantic_scholar,,2009-01-01,semantic_scholar,beautiful architecture: leading thinkers reveal the hidden beauty in software design,https://www.semanticscholar.org/paper/eac74f4ee61fd9e69163b96c0b64710b9ed13a04,"What are the ingredients of robust, elegant, flexible, and maintainable software architecture? Beautiful Architecture answers this question through a collection of intriguing essays from more than a dozen of today's leading software designers and architects. In each essay, contributors present a notable software architecture, and analyze what makes it innovative and ideal for its purpose. Some of the engineers in this book reveal how they developed a specific project, including decisions they faced and tradeoffs they made. Others take a step back to investigate how certain architectural aspects have influenced computing as a whole. With this book, you'll discover: How Facebook's architecture is the basis for a data-centric application ecosystem The effect of Xen's well-designed architecture on the way operating systems evolve How community processes within the KDE project help software architectures evolve from rough sketches to beautiful systems How creeping featurism has helped GNU Emacs gain unanticipated functionality The magic behind the Jikes RVM self-optimizable, self-hosting runtime Design choices and building blocks that made Tandem the choice platform in high-availability environments for over two decades Differences and similarities between object-oriented and functional architectural views How architectures can affect the software's evolution and the developers' engagement Go behind the scenes to learn what it takes to design elegant software architecture, and how it can shape the way you approach your own projects, with Beautiful Architecture.",data oriented architecture,222,not included
a50ab8ce1165aa9d17ad623707d9e1bc661ca80e,to_check,semantic_scholar,2012 IEEE International Conference on Information Science and Technology,2012-01-01,semantic_scholar,an object-oriented system for dynamics-based 3d cloth simulation,https://www.semanticscholar.org/paper/a50ab8ce1165aa9d17ad623707d9e1bc661ca80e,"The dynamics-based 3D cloth simulation has very broad applications. Generally, it involves mathematical modeling, collision detection between objects, self-collision detection for deformable object, and numerical solution of differential equations. As a result, the final simulation software system is usually complex. On the other hand, currently no suitable open-source software systems are publicly available for one to easily use so that his/her idea can be quickly tested. In this paper we first present a data-centric paradigm for dynamics-based simulation, and then propose an object oriented architecture for cloth simulation. In this architecture, we design a common abstract base class for all objects and bounding-box based collision detection, from which we can easily simulate a given type of object by creating a new inherited object class. The inherited class can easily reuse the existing modules in its base class, and hence decrease the number of code lines significantly, thus reducing the complexity and coupling between modules. In particular, when a new algorithm is designed, we can expediently test and verify its effectiveness by directly reuse the other modules without having to reprogram them. The clothing simulation system that we have implemented has fully demonstrated the reusability of the proposed architecture. This architecture also has the potential to be easily used for other types of dynamics-based 3D simulations.",data oriented architecture,223,not included
3ca01f112f3cade2d8a2957a49d4bc5e312be870,to_check,semantic_scholar,,2002-01-01,semantic_scholar,xmach-1: a multi-user benchmark for xml data management,https://www.semanticscholar.org/paper/3ca01f112f3cade2d8a2957a49d4bc5e312be870,"The specification of XMach-1 (XML Data Management benchmark, Version 1) was developed at the University of Leipzig in 2000 and published at the beginning of 2001 [BoRa01]. It was the first XML database benchmark. The benchmark defines a database of XML documents and a set of operations covering important characteristics of XML processing and querying. Key features of XMach-1 are scalability, multi-user simulation and the evaluation of the entire data management system. It has been sucessfully implemented for a variety of native XML database systems and XML-enabled relational and object-relational DBMS. The benchmark is based on a web application in order to model a typical use case of a XML data management system. The system architecture consists of four parts: the XML database, application servers, loaders to populate the database and browser clients. The application servers run a web (HTTP) server and other middleware components to support processing of the XML documents and to interact with the backend database. The XML database contains both document-centric and data-centric XML documents. The largest part is document-centric consisting of semi-structured documents with larger text portions such as books or essays. These documents are synthetically produced by a parameterizable generator. In order to achieve close-to-reality results when storing and querying text contents, text is generated from the 10,000 most frequent English words, using a distribution corresponding to natural language text. The documents varies in size (2-100 kB) as well as in structure (flat and deep element hierarchy). The second part of the database is a data-centric directory containing the metadata of the other documents such as document URL, name, insertand update time. All data in this document is stored in attributes (no mixed content) and the order of element siblings is free. Compared to stuctured data in relational databases it shows some semi-structured properties such as variable path length using recursive elements or optional attributes. The database can be scaled by increasing the number of documents, e.g. from 1000 text-oriented documents to 10 million documents. The metadata document scales proportionally with the number of text documents. A distinctive feature of XMach-1 is that documents may be schema-less or schema-based and that we increase the number schemas with the number of documents. This allows us to test a database system’s ability to cope with an increasing number of different element types and to test query execution across multiple schemas. Additionally the benchmark supports evaluating schema-less and schema-based document storage. The XMach-1 workload mix consists of 8 query operations and 3 update operations. They cover a wide range of processing features such as complete reconstruction of complex documents, full text retrieval, navigational queries, queries using sorting and grouping operators etc. In addition to the textual specification there exists a XQuery formulation of the queries [XM02]. Update operations cover inserting and deleting of documents as well as changing attribute values. Having update operations defined is unique across the XML benchmarks. Despite the missing data manipulation language for update operations it is insightful to test this functionality. Since XMach-1 is a multi-user benchmark the primary performance metric is throughput measured in Xqps (XML queries per second). This value is calculated from the workload mix which defines firm ratios for each operation. According to its simulated domain this mix emphasizes the retrieval of complete documents whereas update operations have only a minor share. Nevertheless the latter one can have a significant impact on the execution of the query operations since cache and transaction management have to provide current data. Of course, the benchmark can also be applied in single-user mode, e.g. to determine the response times of the various queries as a reference point.",data oriented architecture,224,not included
af5f816e2d00d9190f7b1ed7635c2f5360f8949b,to_check,semantic_scholar,2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI),2017-01-01,semantic_scholar,poster abstract: data-centric iot services provisioning in fog-cloud computing systems,https://www.semanticscholar.org/paper/af5f816e2d00d9190f7b1ed7635c2f5360f8949b,"Fog computing is mainly proposed for IoT applications that are geospatially distributed, large-scale, and latency sensitive. This poses new research challenges in real-time and scalable provisioning of IoT services distributed across Fog-Cloud computing platforms. Data-centric IoT services, as a dominant type of IoT services in large-scale deployments, require design solutions to speed up data processing and notification, and scale up with the data volume. In this paper, we propose a service-oriented design architecture which is particularly focused on provisioning and processing data-centric IoT services over Fog-Cloud systems. In the proposed architecture, data-centric IoT services are organized in a service integrating tree structure, adhering to the hierarchical fog-based IoT computing models. A service node in the tree is empowered with features for real-time service data notification, local data processing and multi-level IoT data access. The initial results show that, along the design advantages of the proposed model, it does not impose any additional overhead as compared to state-of-the-art solutions.",data oriented architecture,225,included
2d2385f99fa1fcefd4dbda103375b0c3aa5074fe,to_check,semantic_scholar,,2006-01-01,semantic_scholar,microsoft visual studio 2012 unleashed,https://www.semanticscholar.org/paper/2d2385f99fa1fcefd4dbda103375b0c3aa5074fe,"Normal 0 false false false MicrosoftInternetExplorer4 Normal 0 false false false MicrosoftInternetExplorer4 Microsoft Visual Studio 2012 significantly improves developer productivity across virtually all application lifecycle management tasks, while providing first-class support for Windows 8, Windows Phone, WindowsRT, and Windows Azure cloud development. This end-to-end deep dive will help working developers squeeze maximum productivity out of Microsofts powerful new toolbox. The authors combine authoritative and detailed information about Microsofts latest IDE, with extensive insights and best practices drawn from decades of development experience. Developers will quickly get comfortable with Visual Studio 2012s revamped interface and discover multiple opportunities to leverage the updated .NET 4.5 platform it supports. By focusing entirely on Visual Studio 2012 Professional, the authors have gone deeper into Microsofts core product than ever before. Youll find expert coverage of everything from debugging through refactoring, automation through enterprise-class development. Throughout, this books focus is relentlessly practical: how to apply Microsofts tools to build better software, faster. Detailed information on how to... Use Visual Studio 2012s new interface to significantly improve your productivity Make the most of VS 2012s new WPF-based code editor Work with solutions, projects, browsers, explorers, and designers Create modern Windows Store applications for Windows 8 and Windows RT apps with VS 2012 and Windows Runtime Library Develop websites with ASP.NET, ASP.NET MVC, and the Razor View Engine Create richer, smarter user interfaces for software of all types Build robust service oriented architecture (SOA)-based systems Construct data-centric applications with LINQ and Entity Framework Develop SharePoint and other Microsoft Office business applications Write Windows Azure applications that live in the cloud Instrument, analyze, and test your software Refactor code for greater robustness, maintainability, and performance Leverage brand-new improvements to Windows Workflow and Windows Communication Foundation Use VS 2012s one-click web deployment capabilities Extend VS 2012 with Managed Extensibility Framework (MEF) and Automation Object Model",data oriented architecture,227,not included
7466dc46407029fec36e896f1fb1019ba6e41418,to_check,semantic_scholar,Enterp. Inf. Syst.,2017-01-01,semantic_scholar,a method of demand-driven and data-centric web service configuration for flexible business process implementation,https://www.semanticscholar.org/paper/7466dc46407029fec36e896f1fb1019ba6e41418,"ABSTRACT Facing the rapidly changing business environments, implementation of flexible business process is crucial, but difficult especially in data-intensive application areas. This study aims to provide scalable and easily accessible information resources to leverage business process management. In this article, with a resource-oriented approach, enterprise data resources are represented as data-centric Web services, grouped on-demand of business requirement and configured dynamically to adapt to changing business processes. First, a configurable architecture CIRPA involving information resource pool is proposed to act as a scalable and dynamic platform to virtualise enterprise information resources as data-centric Web services. By exposing data-centric resources as REST services in larger granularities, tenant-isolated information resources could be accessed in business process execution. Second, dynamic information resource pool is designed to fulfil configurable and on-demand data accessing in business process execution. CIRPA also isolates transaction data from business process while supporting diverse business processes composition. Finally, a case study of using our method in logistics application shows that CIRPA provides an enhanced performance both in static service encapsulation and dynamic service execution in cloud computing environment.",data oriented architecture,228,included
d2494bdd4b5aed00296f83fd28086857048f4503,to_check,semantic_scholar,PCI '13,2013-01-01,semantic_scholar,wsmeta: a meta-model for web services to compare service interfaces,https://www.semanticscholar.org/paper/d2494bdd4b5aed00296f83fd28086857048f4503,"With the increasing adoption of the web-services stack of standards, service-oriented architecture has attracted substantial interest from the research community which has produced several languages and methods for describing and reasoning about services. These languages cover many concepts ranging from individual services and their code generation from specifications, service semantics, service compositions and networks, economics and business aspects around service ecosystems etc. However, this abundance of specification languages has also resulted in communication difficulties between stakeholders and hinders tasks such as service composition, discovery and maintenance. The presented work is a step towards the unification of the specifications and different aspects of service systems using Model-Driven Engineering. We propose a generic and abstract web service meta-model called WSMeta, which has the ability to describe both operation-centric web services (WS-*) and data-centric web services (REST) and can be used in tasks such as service evolution analysis and service systems maintenance.",data oriented architecture,229,not included
3ac5a76ab14cb422f93132ab78e810da02d684f9,to_check,semantic_scholar,BIS,2011-01-01,semantic_scholar,an approach to the semantization of erp systems,https://www.semanticscholar.org/paper/3ac5a76ab14cb422f93132ab78e810da02d684f9,"The paper promotes a methodology and application model for extending traditional, data-centric Enterprise Resource Planning Systems with semantics-oriented data models, in order to enrich interaction and reporting capabilities. The proposal includes a method of automating data semantization using a mix of semantic modeling and formal concept analysis, and an extended ERP architecture which integrates legacy systems in a Semantic Web wrapper system, providing new dimensions to traditional interaction and reports in a business environment, with specific examples regarding human resources management.",data oriented architecture,230,not included
548f78f3d4deb45578654fcb47f405e6a7cca4c0,to_check,semantic_scholar,2006 IEEE Sarnoff Symposium,2006-01-01,semantic_scholar,peer-to-peer wireless sensor network data acquisition system with pipelined time division scheduling,https://www.semanticscholar.org/paper/548f78f3d4deb45578654fcb47f405e6a7cca4c0,"this paper, we introduce a peer-to-peer sensor network (P2PWSNDAS) architecture with pipelined time division scheduling for sensor data acquisition from an ad hoc wireless sensor network (WSN). P2PWSNDAS takes a service-oriented, data-centric view of the deployed WSN. The wireless sensors that constitute the WSN measure physical attributes of the environment they are deployed in such as temperature, pressure, vibration, toxic chemical, biological agents, etc. In our architecture, we assume that the entire WSN can be divided into sets of 'sensor-clusters'. Each cluster has a gateway or base station that aggregates data from its sensor cluster. The gateways themselves which constitute the middleware layer between the WSN and end point clients are designed to form an IP-based distributed peer-to-peer (P2P) overlay network. Clients query the gateways for real-time sensor data via a publish/subscribe/notify paradigm implemented at the gateways, and they can also concurrently receive notifications on alarms/events of interest. Another contribution we report in this paper is a Pipelined Time- division Model (PTM) scheduling for continuous energy-aware MAC-layer communication between a gateway and its sensors. Our PTM scheduling algorithm is particularly targeted towards wireless sensors such as the MICA2 series [4] that have multichannel radio transceivers.",data oriented architecture,231,included
2e28595f5c783d7cffd3987bc5c430aee68bd3f0,to_check,semantic_scholar,,2013-01-01,semantic_scholar,clara: clas12 reconstruction and analysis framework,https://www.semanticscholar.org/paper/2e28595f5c783d7cffd3987bc5c430aee68bd3f0,"In this paper we present SOA based CLAS12 event Reconstruction and Analyses (CLARA) framework. CLARA design focus is on two main traits: real-time data stream processing, and service-oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions capable of processing large volumes of data interactively and substantially faster than batch systems.",data oriented architecture,232,included
5eab79c9a418325c3646209f77be91e45c156b0a,to_check,semantic_scholar,,2000-01-01,semantic_scholar,evaluating module systems for crosscutting concerns,https://www.semanticscholar.org/paper/5eab79c9a418325c3646209f77be91e45c156b0a,"Although object-oriented programming techniques support modular decomposition of data types well, there are a number of programming concerns that cannot be cleanly modularized using conventional language mechanisms. This paper classifies these concerns into several categories, and describes examples and a prototypical challenge problem from each category. It then describes several recent techniques designed to improve program modularity in the face of these concerns. The strengths and weaknesses of each technique are evaluated with respect to the challenge problems. The paper concludes with a discussion of future research directions. 1. Object-Oriented Modularity A module, as used in this paper, is a programming environment mechanism for decomposing a large software program into smaller pieces, which the environment can automatically compose into a complete program later. Modules yield a number of programming benefits [P72]. The most important benefit is the intellectual leverage gained by separating the different concerns (programming issues) within a large program into smaller modules. Effective separation of concerns makes a program easier to understand, change, and debug. A second benefit comes from information hiding, which reduces dependencies between modules, supporting program evolution and independent development of different parts of a program. Other benefits of modules include separate compilation, incremental development, easier unit testing, improved re-use, and intellectual property protection. Object-oriented programming separates data representation concerns very well using the concept of an abstract data type. Since data representations are very likely to change over the course of program evolution, object-oriented systems separate a particular data representation choice from other parts of a program by putting it together with related code in a source file and hiding the representation choice behind an interface. When the data representation changes, these mechanisms often limit the effect of that change to the particular object involved. Object-oriented inheritance also enables a related group of objects to reuse a data representation scheme. Although object-oriented programming effectively separates data representation concerns, there are other kinds of concerns that are difficult to separate into modules using conventional object-oriented language technology. In the next section, we describe and classify a number of challenging modularity problems. Section 3 describes several techniques designed to address these concerns, and section 4 evaluates the techniques against selected challenge problems. Section 5 discusses future research directions in modularity, and section 6 concludes. 2. Modularity Challenges This section classifies programming concerns (that is, the problem domain for modularity) into a number of categories. For each category, we provide a brief description, relate it to other categories, give a number of example modularity problems, and choose a representative challenge problem that captures the essence of the category. 2.1. Data Representation Data representation concerns deal with how program data should be organized; this paper assumes the reader is familiar with this concern. Existing object-oriented languages, especially those with parameterized types, modularize many data representation concerns well. Parnas [P72] proposed the KWIC index system as a challenge problem to evaluate different modularizations of a data-centric program. 2.2. Functional Concerns A functional concern is a piece of functionality, such as a requirement or use case, provided for a client, such as the user, another program, or another component. While a single object is the unit of modularity in mainstream object-oriented languages, the implementation of a functional concern may cross object boundaries or may only be part of an object’s implementation. Thus, it is difficult to isolate the functional concern’s code in a single module. A challenge problem for modularizing functional concerns is separating operations on a program representation [TOHS99]. In typical program representations, there are many different kinds of nodes like assignment and function call nodes, and operations like typechecking, various optimization passes, and code generation can be applied to the different nodes. A good modularization would separate the typechecking operations for each node into one module, the code generation operations in another module, etc, effectively separating the functional concerns implemented by the different operations. Tools might even support both an object-oriented view and a functional view (Figure 1). Other example problems include the various actions of a bottle deposit machine like depositing and printing a receipt [AR92], composable pieces of data structure functionality such as searching and allocation [SB98], user interaction concerns such as directory listings and error messages in an FTP server [LM99], adding an operation to a shape hierarchy [FF98], functional testing of a use case scenario, and many others. 2.3. Program Organization Program organization concerns address the large-scale structure of the program: how do modules, each composed of many objects, interact on a high level? Large-scale program structure (as opposed to small-scale functional and data representation concerns) is an important concern for program understanding and modular analysis, yet most languages do not support modular structure beyond the size of a single object, obscuring their high-level structure [MN97]. Work on software architecture description languages [MT00] does address this concern, but is not tightly integrated with conventional programming languages. For lack of space, this paper does not survey the area. Effective support for program organization includes specifying relationships between program components separate from the components’ code, and clarifying the relationship between components using optional restrictions on the kinds of inter-component communication. A challenge problem, inspired by an urban simulation program [NBW00], is to specify a blackboard software architecture [GS94] as in Figure 2, with an explicit connection diagram showing how a set of simulation modules interacts with a shared data store. The system should enforce the application constraint that the modules do not directly communicate, but only make modifications to the shared data. It should be easy to make changes like Object-oriented Functional Figure 1. Object-oriented and Functional Decompositions of a Program Representation Figure 2. A Blackboard Software Architecture Module 4 Blackboard Module 3 Module 2 Module 1 Statement Core Data Structs Expression Function Call Typechecking",data oriented architecture,233,not included
441b6a2ecfea590592dddb01ef056c87766a9916,to_check,semantic_scholar,,2003-01-01,semantic_scholar,mobishare : sharing context-dependent data and services among mobile devices ♣,https://www.semanticscholar.org/paper/441b6a2ecfea590592dddb01ef056c87766a9916,"Initiative on Global Computing for the cooperation of autonomous and mobile entities in dynamic environments. Abstract Rapid advances in wireless and mobile communications and computing technologies have enabled handy personal mobile devices to be used in everyday life. Such small mobile devices can now become not only information browsers and service clients, but also information and service providers, complementing or replacing fixed hosts connected to the wireline network. Such mobile resources can be very important for other moving users and mobile devices, creating significant opportunities for many interesting and novel applications. The MobiShare architecture outlined in this paper provides a scalable infrastructure for ubiquitous mobile access to dynamic information and mechanisms for publishing, discovering and accessing heterogeneous mobile resources in a large area, taking into account the context of both providers and requestors. Any wireless communication technology could be employed between a device and the system. In addition, the use of XML-related languages and protocols for describing and exchanging metadata gives the system a uniform, easily adaptable and platform-independent interface, allowing a variety of devices to use it. The overall approach is data-centric and service-oriented, implying that all the devices are treated both as potential providers or requestors of data wrapped as information m-services.",data oriented architecture,234,included
45e79d391bb8b352cc959206f3ddaeca40ad4599,to_check,semantic_scholar,IET Softw.,2019-01-01,semantic_scholar,e2sm: a security tool for adaptive cloud-based service-oriented applications,https://www.semanticscholar.org/paper/45e79d391bb8b352cc959206f3ddaeca40ad4599,"The issue of security in the distributed system landscape of a service-oriented architecture (SOA) is a challenging one. No longer is it limited to a local application or an application domain, security must now work across a range of applications and business processes interacting with each other. This is even more true when SOA-based applications are provisioned in the cloud. Firstly, cloud applications components, and the data they might handle, that were once silos, are now being exposed as services by distinct and distrusted tenants. Secondly, such applications are often adaptive when they are provisioned in cloud environments. This study proposes an end-to-end security model (E2SM) that aims to protect data confidentiality in adaptive cloud-based SOA applications. E2SM allows the setting of data-centric security policies that go beyond services boundaries. First, security configuration is automatically calculated starting from a few intuitive business-oriented security settings. Then, the configuration is updated with minimal overhead if security policies are dynamically modified and/or SOA architecture is reconfigured. A security tool is implemented according to the proposed model. As for validation, the tool was used to secure a healthcare business process.",data oriented architecture,235,not included
f150f7f3521184317830bb7f96b94aece9925c74,to_check,semantic_scholar,Int. J. Online Biomed. Eng.,2019-01-01,semantic_scholar,wireless sensor networks suitable for large-scale heterogeneous networking,https://www.semanticscholar.org/paper/f150f7f3521184317830bb7f96b94aece9925c74,"In order to optimize the network architecture, addressing mechanism, heterogeneous nodes and other functions of wireless sensor networks, this study begins with the issue of networking of large-scale heterogeneous networks. A layered distributed network architecture is proposed, which provides a powerful reference for the future architecture of wireless sensor networks. Based on this architecture, the resource addressing of the corresponding hierarchical network, and the scale and location deployment of heterogeneous nodes such as sink nodes are discussed separately, and corresponding strategies and algorithms are proposed. The research results show that the core idea of the addressing mechanism is data-centric, address-oriented addressing is transformed into service-oriented addressing. Therefore, the proposed LBA addressing algorithm is suitable for other hierarchically structured networks. In addition, although the sink node is taken as an example for research, it is also suitable for the deployment of other heterogeneous nodes such as sink nodes, relay nodes, and base stations. In summary, regardless of the number of nodes or the location of the deployment, energy-saving factors need to be considered. Energy-saving is also an indispensable technology in wireless sensor network technology.",data oriented architecture,236,not included
10.1109/i-span.2009.67,to_check,"2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks",IEEE,2009-12-16 00:00:00,ieeexplore,a data-driven architecture for remote control of sensors over a wireless sensor network and the internet,https://ieeexplore.ieee.org/document/5381871/,"This study revealed an applicable architecture in which a data-driven mechanism was designed to bridge a wireless sensor network (WSN) and the Internet. The system was divided into two independent parts. The first part is the data communication between the sensor network and the database. The other part is the data communication between the database and the user interface (UI). These two parts are connected by the database server. Asynchronous interoperation was introduced while exchanging data between these two parts. Users were not allowed to control the sensors through direct connection to the sensors and can only use the Web service to update the sensor profile built in the database. The sensors were triggered to start the action through a data-update event from the database. A sensor profile built in the database collected all sensor information and all user control command. For the information to be centralized and triggered by the database, regardless of whether sensors were measured in a periodic sampling or an event-driven environment, all sensor actions were triggered through a data-update event in the database. For the sake of improving user experience, a Web-based UI was implemented using scalable vector graphics (SVG) and Ajax technologies. All operations by users were conducted through the Hypertext Transfer Protocol (HTTP) standard method. Therefore, this system can be used via a browser and easily deployed. The proposed architecture is suitable for a healthcare system, a personal body area network, and the Infranet for control.",data driven architecture,237,included
10.1109/nssmic.1998.775181,to_check,1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255),IEEE,1998-11-14 00:00:00,ieeexplore,a 16-channel digital tdc chip,https://ieeexplore.ieee.org/document/775181/,"A 16-channel digital TDC chip has been built for the DIRC Cerenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns and the full-scale 32 microseconds. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The linearity is better than 80 ps rms on 90% of the production parts.",data driven architecture,238,not included
10.1109/emwrts.1996.557821,to_check,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,IEEE,1996-06-14 00:00:00,ieeexplore,an embedded accelerator for real-time image processing,https://ieeexplore.ieee.org/document/557821/,"The paper presents an embedded reconfigurable accelerator called Xputer, comprising a novel kind of sequencer hardware (data sequencer). For many real-time signal processing, multimedia, and other high-performance applications this new data-driven architecture increases the performance of a single processor system enormously by integrating it as a co-processor for accelerating computation-intensive parts of an application. The reconfigurable architecture and programming environment is described. Its use is illustrated with an automotive application requiring real-time image processing.",data driven architecture,239,not included
10.1109/geoinformatics.2010.5567735,to_check,2010 18th International Conference on Geoinformatics,IEEE,2010-06-20 00:00:00,ieeexplore,an integrated spatio-temporal modeling and analysis framework for climate change research,https://ieeexplore.ieee.org/document/5567735/,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It's brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.",data driven architecture,240,not included
10.1109/fpt.2010.5681493,to_check,2010 International Conference on Field-Programmable Technology,IEEE,2010-12-10 00:00:00,ieeexplore,automatic synthesis of processor arrays with local memories on fpgas,https://ieeexplore.ieee.org/document/5681493/,"In this paper, we present an automatic synthesis framework to map loop nests to processor arrays with local memories on FPGAs. An affine transformation approach is firstly proposed to address space-time mapping problem. Then a data-driven architecture model is introduced to enable automatic generation of processor arrays by extracting this data-driven architecture model from transformed loop nests. Some techniques including memory allocation, communication generation and control generation are presented. Synthesizable RTL codes can be easily generated from the architecture model built by these techniques. A preliminary synthesis tool is implemented based on PLUTO, an automatic polyhedral source-to-source transformation and parallelization framework.",data driven architecture,241,not included
10.1109/icws.2008.147,to_check,2008 IEEE International Conference on Web Services,IEEE,2008-09-26 00:00:00,ieeexplore,common business components and services toward more agile and flexible industry solutions and assets,https://ieeexplore.ieee.org/document/4670150/,"In many decades, many organizations, especially large consulting companies, have been designing, implementing and managing business solutions for every industry around the globe. But due to numerous limitations in process, tooling and skills, most of those solutions were made very specific to individual industry and client needs at its early design stage. Therefore, reuse and more importantly, managing the ever changing business requirements, become almost impossible. Service-orientation and architecture, model-driven business development provides us a new and powerful approach to facilitate asset based industry solution design and development. To further accelerate this, this tutorial will discuss an innovative approach that take advantage of many proven best software engineering practices, from object/component based technology, meta-data driven architecture types (archetypes) that are used to model the common structural and in some cases non-structural business entities such as customer, product, payment, etc. In order to address the consequences introduced by abstracting those common elements out of the specific industry model and be able to enable easy and meta-data based transformation, we properly decompose business components/services into a multi-layered business architecture. Therefore, process/components/services can be decomposed accordingly to facilitate the decomposition and abstraction, while maintaining certain level of necessary traceability across various artifacts. In the realization phase, existing assets/operational systems will be mapped and transformed to the required business components and services to best leverage those existing valuable industry/client investments. To support such a SOA based, model and business driven development process, existing tooling, especially the necessary transformation and integration capability, needs to be significantly enhanced. This tutorial will also present some recommendation based on some recent design and implementation, and they could be used to guide future tooling alignment and integration effort across software modeling, implementation and solution products. In addition, we will present how to leverage existing internal or external assets or product offerings and the open industry reference models and standards (such as ACCORD, ebXML, ARTS/IxRetail). This work is based on authors' collective experience in leading the large end-to-end client engagements across many industries, while promoting various industry leading software engineering best practices.",data driven architecture,242,not included
10.1109/tina.1997.660723,to_check,Proceedings TINA '97 - Global Convergence of Telecommunications and Distributed Object Computing,IEEE,1997-11-20 00:00:00,ieeexplore,data-driven implementation of tina kernel transport network,https://ieeexplore.ieee.org/document/660723/,"To realize the actual TINA-based telecommunications network, the performance of the kernel Transport Network (kTN) such as availability, reliability, throughput and load tolerance becomes more crucial than for existing computer networks. The authors have been studying and developing a super-integrated data-driven processor to be applied to the TINA kTN nodes and network interfaces in CUE (Coordinating Users' requirements and Engineering constraints) project. Since the processor is primarily designed to be a scalable VLSI component, it is easily interconnected to form a super-integrated chip and multi-chip system for achieving the performance and reliability demanded in a TINA environment. We first examine the requirements for kTN. A stream-oriented data-driven architecture is then proposed with special emphasis on effective multiprocessing capability with overload tolerance. After that, we demonstrate that autonomous load balancing among super-integrated data-driven processors without adding any runtime overhead to achieve effective and reliable multiprocessing is possible by utilizing the overload tolerance of the processor. Finally, this paper shows preliminary performance estimations of the super-integrated data-driven processor being developed to perform efficient multiprocessing in protocol handling such as TCP/IP.",data driven architecture,243,included
10.1109/sam48682.2020.9104367,to_check,2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,2020-06-11 00:00:00,ieeexplore,deep radar waveform design for efficient automotive radar sensing,https://ieeexplore.ieee.org/document/9104367/,"In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a wellknown unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.",data driven architecture,244,not included
10.1109/nssmic.2004.1466709,to_check,IEEE Symposium Conference Record Nuclear Science 2004.,IEEE,2004-10-22 00:00:00,ieeexplore,design and evaluation of the clear-pem detector for positron emission mammography,https://ieeexplore.ieee.org/document/1466709/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with adequate field-of-view dimensions for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,245,included
10.1109/cac.2017.8244168,to_check,2017 Chinese Automation Congress (CAC),IEEE,2017-10-22 00:00:00,ieeexplore,design and implementation of data-driven based universal data editing framework,https://ieeexplore.ieee.org/document/8244168/,"Apply Integrated Logistics Support (ILS) to weapon equipment can efficiently improve equipment's automation and digital level. ILS needs support of various integrated support systems, which have demands for data editing. Nowadays, most of data editing software used in these systems are customized and provide a form-based editing approach, which becomes an obstacle to carry out ILS. This paper brings forward to design a data-driven based universal data editing framework. In this framework, data models are taken as input and only corresponding data models need to be modified when data change. Firstly, the whole development process of data editing software that adopt form-based development mode is analyzed in detail to find out problems exists in this development mode. Then the data-driven based universal data editing framework is designed. New idea of data-driven architecture is proposed. Data-driven architecture takes data models as input and processes all data models in a universal way. Finally, key technology for framework realization is given.",data driven architecture,246,included
10.1109/nssmic.2000.949945,to_check,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,2000-10-20 00:00:00,ieeexplore,error handling for the cdf silicon vertex tracker,https://ieeexplore.ieee.org/document/949945/,"The SVT online tracker for the CDF upgrade reconstructs two-dimensional tracks using information from the Silicon Vertex detector (SVXII) and the Central Outer Tracker (COT). The SVT has an event rate of 100 kHz and a latency time of 10 /spl mu/s. The system is composed of 104 VME 9U digital boards (of 8 different types) and it is implemented as a data driven architecture. Each board runs on its own 30 MHz clock. Since the data output from the SVT (few Mbytes/sec) are a small fraction of the input data (200 Mbytes/sec), it is extremely difficult to track possible internal errors by using only the output stream. For this reason several diagnostic tools have been implemented: local error registers, error bits propagated through the data streams and the Spy Buffer system. Data flowing through each input and output stream of every board are continuously copied to memory banks named Spy Buffers which act as built in logic state analyzers hooked continuously to internal data streams. The contents of all buffers can be frozen at any time (e.g. on error detection) to take a snapshot of all data flowing through each SVT board. The Spy Buffers are coordinated at system level by the Spy Control Board. The architecture, design and implementation of this system are described.",data driven architecture,247,included
10.1109/isit45174.2021.9517812,to_check,2021 IEEE International Symposium on Information Theory (ISIT),IEEE,2021-07-20 00:00:00,ieeexplore,model-inspired deep detection with low-resolution receivers,https://ieeexplore.ieee.org/document/9517812/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector network, called LoRD-Net, for signal recovering from one-bit measurements. Our approach relies on a model-aware data-driven architecture, based on a deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely ~ 500 samples, for training.",data driven architecture,248,not included
10.1109/icc42927.2021.9500961,to_check,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,removing channel estimation by location-only based deep learning for ris aided mobile edge computing,https://ieeexplore.ieee.org/document/9500961/,"In this paper, we investigate a deep learning architecture for lightweight online implementation of a reconfigurable intelligent surface (RIS)-aided multi-user mobile edge computing (MEC) system, where the optimized performance can be achieved based on user equipment’s (UEs’) location-only information. Assuming that each UE is endowed with a limited energy budget, we aim at maximizing the total completed task-input bits (TCTB) of all UEs within a given time slot, through jointly optimizing the RIS reflecting coefficients, the receive beamforming vectors, and UEs’ energy partition strategies for local computing and computation offloading. Due to the coupled optimization variables, a three-step block coordinate descending (BCD) algorithm is first proposed to effectively solve the formulated TCTB maximization problem iteratively with guaranteed convergence. The location-only deep learning architecture is then constructed to emulate the proposed BCD optimization algorithm, through which the pilot channel estimation and feedback can be removed for online implementation with low complexity. The simulation results reveal a close match between the performance of the BCD optimization algorithm and the location-only data-driven architecture, all with superior performance to existing benchmarks.",data driven architecture,249,not included
10.1109/30.982782,to_check,IEEE Transactions on Consumer Electronics,IEEE,2001-11-01 00:00:00,ieeexplore,a novel hdtv video decoder and decentralized control scheme,https://ieeexplore.ieee.org/document/982782/,"A novel dedicated architecture for an HDTV video decoding chip is developed. Each task is mapped to a highly optimized hardware unit by classifying the video processing tasks into three levels. On the function level, a data driven architecture is adopted to make each processing unit operate once the processing data and buffer are available. Therefore the high computing efficiency of each unit is exploited, hardware is saved, and the computing capability is maximized compared with conventional pipeline decoder. On the system level, a decentralized control scheme is designed to provide high efficient communication between all the processing units to yield the best overall performance. Moreover it features simple control logic and minimum size of the connecting buffers.",data driven architecture,250,included
10.1109/tns.2006.870173,to_check,IEEE Transactions on Nuclear Science,IEEE,2006-02-01 00:00:00,ieeexplore,design and evaluation of the clear-pem scanner for positron emission mammography,https://ieeexplore.ieee.org/document/1610954/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities, and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with dimensions 16.5/spl times/14.5 cm/sup 2/ for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,251,included
10.1109/access.2021.3071274,to_check,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,graph neural network: a comprehensive review on non-euclidean space,https://ieeexplore.ieee.org/document/9395439/,"This review provides a comprehensive overview of the state-of-the-art methods of graph-based networks from a deep learning perspective. Graph networks provide a generalized form to exploit non-euclidean space data. A graph can be visualized as an aggregation of nodes and edges without having any order. Data-driven architecture tends to follow a fixed neural network trying to find the pattern in feature space. These strategies have successfully been applied to many applications for euclidean space data. Since graph data in a non-euclidean space does not follow any kind of order, these solutions can be applied to exploit the node relationships. Graph Neural Networks (GNNs) solve this problem by exploiting the relationships among graph data. Recent developments in computational hardware and optimization allow graph networks possible to learn the complex graph relationships. Graph networks are therefore being actively used to solve many problems including protein interface, classification, and learning representations of fingerprints. To encapsulate the importance of graph models, in this paper, we formulate a systematic categorization of GNN models according to their applications from theory to real-life problems and provide a direction of the future scope for the applications of graph models as well as highlight the limitations of existing graph networks.",data driven architecture,252,not included
10.1109/tsp.2021.3117503,to_check,IEEE Transactions on Signal Processing,IEEE,2021-01-01 00:00:00,ieeexplore,lord-net: unfolded deep detection network with low-resolution receivers,https://ieeexplore.ieee.org/document/9557819/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector entitled LoRD-Net for recovering information symbols from one-bit measurements. Our method is a model-aware data-driven architecture based on deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. LoRD-Net operates in a blind fashion, which requires addressing both the non-linear nature of the data-acquisition system as well as identifying a proper optimization objective for signal recovery. Accordingly, we propose a two-stage training method for LoRD-Net, in which the first stage is dedicated to identifying the proper form of the optimization process to unfold, while the latter trains the resulting model in an end-to-end manner. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely <inline-formula><tex-math notation=""LaTeX"">$\sim 500$</tex-math></inline-formula> samples, for training.",data driven architecture,253,not included
10.1109/access.2021.3091716,to_check,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,modeling and key technologies of a data-driven smart city system,https://ieeexplore.ieee.org/document/9462829/,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a `two-dimension, three-layer, and six-goal' top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated.",data driven architecture,254,included
10.1109/acc.2013.6580528,to_check,2013 American Control Conference,IEEE,2013-06-19 00:00:00,ieeexplore,data-driven design of kpi-related fault-tolerant control system for wind turbines,https://ieeexplore.ieee.org/document/6580528/,"In this paper, a scheme for an integrated design of fault-tolerant control (FTC) systems for a wind turbine benchmark is proposed, with focus on the overall performance of the system. For that a key performance indicator (KPI) which reflects the economic performance of the system is defined, and the objective of the proposed FTC scheme is to maintain the system KPI in the admissible range in faulty conditions. The basic idea behind this scheme is data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilizing controllers with an embedded residual generator for fault detection (FD) purpose. The performance and effectiveness of the proposed scheme are demonstrated through the wind turbine benchmark model proposed in [1].",data driven architecture,255,not included
10.23919/acc50511.2021.9482806,to_check,2021 American Control Conference (ACC),IEEE,2021-05-28 00:00:00,ieeexplore,direct data-driven design of switching controllers for constrained systems,https://ieeexplore.ieee.org/document/9482806/,"This paper presents a hierarchical structure to directly design controllers for (possibly nonlinear) constrained systems. The proposed architecture combines the advantages of an inner data-driven switching controller designed to achieve a predefined closed-loop behavior and an outer model predictive controller, which is used as a reference governor. These design choices enable us to avoid the identification step typical of model-based approaches while exploiting the ability of model predictive controllers to handle constraints and optimize the closed-loop performance. As a proof of concept, a benchmark simulation example is used to demonstrate the effectiveness of the proposed strategy.",data driven architecture,256,not included
10.1109/tii.2018.2843124,to_check,IEEE Transactions on Industrial Informatics,IEEE,2018-10-01 00:00:00,ieeexplore,data-driven design of fog-computing-aided process monitoring system for large-scale industrial processes,https://ieeexplore.ieee.org/document/8370742/,"Stimulated by the recent development of fog computing technology, in this paper, a fog-computing-aided process monitoring and control architecture is proposed for large-scale industrial processes, which enables reliable and efficient online performance optimization in each fog computing node without modifying predesigned control subsystems. Moreover, a closed-loop data-driven method is developed for the process monitoring system design and an adaptive configuration approach is proposed to deal with the problems caused by the changes of process parameters and operating points. The feasibility and effectiveness of the proposed design approaches are verified and demonstrated through the case study on the Tennessee Eastman benchmark system.",data driven architecture,257,not included
10.1109/spawc51858.2021.9593131,to_check,2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),IEEE,2021-09-30 00:00:00,ieeexplore,fast power control adaptation via meta-learning for random edge graph neural networks,https://ieeexplore.ieee.org/document/9593131/,"Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,258,not included
10.1109/tie.2013.2273477,to_check,IEEE Transactions on Industrial Electronics,IEEE,2014-05-01 00:00:00,ieeexplore,real-time implementation of fault-tolerant control systems with performance optimization,https://ieeexplore.ieee.org/document/6560360/,"In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.",data driven architecture,259,not included
10.1007/s10845-018-1430-y,to_check,Journal of Intelligent Manufacturing,Springer,2020-01-01 00:00:00,springer,"a data-driven cyber-physical approach for personalised smart, connected product co-development in a cloud-based environment",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-018-1430-y,"The rapid development of information and communication technology enables a promising market of information densely product, i.e. smart, connected product (SCP), and also changes the way of user–designer interaction in the product development process. For SCP, massive data generated by users drives its design innovation and somehow determines its final success. Nevertheless, most existing works only look at the new functionalities or values that are derived in the one-way communication by introducing novel data analytics methods. Few work discusses about an effective and systematic approach to enable individual user innovation in such context, i.e. co-development process, which sets the fundamental basis of the prevailing concept of data-driven design. Aiming to fill this gap, this paper proposes a generic data-driven cyber-physical approach for personalised SCP co-development in a cloud-based environment. A novel concept of smart, connected, open architecture product is hence introduced with a generic cyber-physical model established in a cloud-based environment, of which the interaction processes are enabled by co-development toolkits with smartness and connectedness. Both the personalized SCP modelling method and the establishment of its cyber-physical product model are described in details. To further demonstrate the proposed approach, a case study of a smart wearable device (i.e. i-BRE respiratory mask) development process is given with general discussions.",data driven architecture,260,included
10.1007/978-3-642-39200-9_5,to_check,Web Engineering,Springer,2013-01-01 00:00:00,springer,semantic data driven interfaces for web applications,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39200-9_5,"Modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. These conditions require interfaces that can adapt to the changes in the <user, platform, environment> triad. The Model-Based User Interface approach has been proposed as a way to deal with these requirements. In this paper we present a data-driven, rule-based interface definition model capable of taking into account the semantics of the data it is manipulating, especially in the case of Linked Data. An implementation architecture based on the Synth environment supporting this model is presented.",data driven architecture,261,included
10.1007/978-3-642-23333-3_4,to_check,Electronic Participation,Springer,2011-01-01 00:00:00,springer,combining social and government open data for participatory decision-making,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23333-3_4,"In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making.",data driven architecture,262,not included
10.1007/978-3-642-04492-2_21,to_check,Management Enabling the Future Internet for Changing Business and New Computing Services,Springer,2009-01-01 00:00:00,springer,the proposal of service delivery platform built on distributed data driven architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04492-2_21,"SDP (Service Delivery Platform) is a recommended system platform for NGN (Next Generation Network) that is expected to resolve two common system running problems: one is functional aspects such as high availability and providing effective maintenance methods, the other is cost aspects such as simplifying development method of a service. However, SDP is still on the way to be standardized, and its architecture has two problems: the congestion of service requests and flexibility of enabler, a service component of SDP. This paper explains how to build a SDP by adopting Distributed Data Driven Architecture and how our system resolves the problems by evaluating the prototype.",data driven architecture,263,included
http://arxiv.org/abs/2202.07448v1,to_check,arxiv,arxiv,2022-02-04 00:00:00,arxiv,"towards a unified pandemic management architecture: survey, challenges
  and future directions",http://arxiv.org/abs/2202.07448v1,"The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,
economy and society worldwide. Emerging strains are making pandemic management
increasingly challenging. There is an urge to collect epidemiological,
clinical, and physiological data to make an informed decision on mitigation
measures. Advances in the Internet of Things (IoT) and edge computing provide
solutions for pandemic management through data collection and intelligent
computation. While existing data-driven architectures attempt to automate
decision-making, they do not capture the multifaceted interaction among
computational models, communication infrastructure, and the generated data. In
this paper, we perform a survey of the existing approaches for pandemic
management, including online data repositories and contact-tracing
applications. We then envision a unified pandemic management architecture that
leverages the IoT and edge computing to automate recommendations on vaccine
distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We
elucidate the flow of data among the layers of the architecture, namely, cloud,
edge and end device layers. Moreover, we address the privacy implications,
threats, regulations, and existing solutions that may be adapted to optimize
the utility of health data with security guarantees. The paper ends with a
lowdown on the limitations of the architecture and research directions to
enhance its practicality.",data driven architecture,264,included
http://arxiv.org/abs/2110.09005v1,to_check,arxiv,arxiv,2021-10-18 00:00:00,arxiv,unsupervised learned kalman filtering,http://arxiv.org/abs/2110.09005v1,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.",data driven architecture,265,not included
http://arxiv.org/abs/2108.13178v1,to_check,arxiv,arxiv,2021-08-04 00:00:00,arxiv,"black-box and modular meta-learning for power control via random edge
  graph neural networks",http://arxiv.org/abs/2108.13178v1,"In this paper, we consider the problem of power control for a wireless
network with an arbitrarily time-varying topology, including the possible
addition or removal of nodes. A data-driven design methodology that leverages
graph neural networks (GNNs) is adopted in order to efficiently parametrize the
power control policy mapping the channel state information (CSI) to transmit
powers. The specific GNN architecture, known as random edge GNN (REGNN),
defines a non-linear graph convolutional filter whose spatial weights are tied
to the channel coefficients. While prior work assumed a joint training approach
whereby the REGNN-based policy is shared across all topologies, this paper
targets adaptation of the power control policy based on limited CSI data
regarding the current topology. To this end, we propose both black-box and
modular meta-learning techniques. Black-box meta-learning optimizes a
general-purpose adaptation procedure via (stochastic) gradient descent, while
modular meta-learning finds a set of reusable modules that can form components
of a solution for any new network topology. Numerical results validate the
benefits of meta-learning for power control problems over joint training
schemes, and demonstrate the advantages of modular meta-learning when data
availability is extremely limited.",data driven architecture,266,not included
http://arxiv.org/abs/2105.00459v1,to_check,arxiv,arxiv,2021-05-02 00:00:00,arxiv,"fast power control adaptation via meta-learning for random edge graph
  neural networks",http://arxiv.org/abs/2105.00459v1,"Power control in decentralized wireless networks poses a complex stochastic
optimization problem when formulated as the maximization of the average sum
rate for arbitrary interference graphs. Recent work has introduced data-driven
design methods that leverage graph neural network (GNN) to efficiently
parametrize the power control policy mapping channel state information (CSI) to
the power vector. The specific GNN architecture, known as random edge GNN
(REGNN), defines a non-linear graph convolutional architecture whose spatial
weights are tied to the channel coefficients, enabling a direct adaption to
channel conditions. This paper studies the higher-level problem of enabling
fast adaption of the power control policy to time-varying topologies. To this
end, we apply first-order meta-learning on data from multiple topologies with
the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,267,not included
http://arxiv.org/abs/1910.06115v1,to_check,arxiv,arxiv,2019-10-11 00:00:00,arxiv,"microservices based linked data quality model for buildings energy
  management services",http://arxiv.org/abs/1910.06115v1,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality.",data driven architecture,268,not included
http://arxiv.org/abs/1807.06699v5,to_check,arxiv,arxiv,2018-07-17 00:00:00,arxiv,adaptive neural trees,http://arxiv.org/abs/1807.06699v5,"Deep neural networks and decision trees operate on largely separate
paradigms; typically, the former performs representation learning with
pre-specified architectures, while the latter is characterised by learning
hierarchies over pre-specified features with data-driven architectures. We
unite the two via adaptive neural trees (ANTs) that incorporates representation
learning into edges, routing functions and leaf nodes of a decision tree, along
with a backpropagation-based training algorithm that adaptively grows the
architecture from primitive modules (e.g., convolutional layers). We
demonstrate that, whilst achieving competitive performance on classification
and regression datasets, ANTs benefit from (i) lightweight inference via
conditional computation, (ii) hierarchical separation of features useful to the
task e.g. learning meaningful class associations, such as separating natural
vs. man-made objects, and (iii) a mechanism to adapt the architecture to the
size and complexity of the training dataset.",data driven architecture,269,not included
10.14627/537690036,to_check,core,Wichmann Verlag im VDE Verlag GmbH,2020-01-01 00:00:00,core,bridging tangible and virtual realities : computational procedures for data-informed participatory processes,,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe",data driven architecture,270,not included
'elsevier bv',to_check,core,https://core.ac.uk/download/146492122.pdf,2013-01-01 00:00:00,core,10.1016/j.procs.2013.05.357,,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",data driven architecture,271,included
10.5075/epfl-thesis-3545,to_check,core,A multitasking and data-driven architecture for multi-agents simulations,2006-04-24 00:00:00,core,https://core.ac.uk/download/147916631.pdf,,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach",data driven architecture,272,not included
,to_check,core,,2019-10-11 00:00:00,core,http://arxiv.org/abs/1910.06115,,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality",data driven architecture,273,not included
,to_check,core,,2010-01-01 00:00:00,core,10.1109/geoinformatics.2010.5567735,,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",data driven architecture,274,not included
,to_check,core,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",2008-01-01 00:00:00,core,https://core.ac.uk/download/pdf/195383281.pdf,,"This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",data driven architecture,275,included
bd566b88df8a3a045962f78ddb2d64d541845a39,to_check,semantic_scholar,IEEE Communications Magazine,2019-01-01,semantic_scholar,a hierarchical architecture for the future internet of vehicles,https://www.semanticscholar.org/paper/bd566b88df8a3a045962f78ddb2d64d541845a39,"Recent advances in wireless communication, sensing, computation and control technologies have paved the way for the development of a new era of Internet of Vehicles (IoV). Demanded by the requirements of information-centric and data-driven intelligent transportation systems (ITS), it is of great significance to explore new paradigms of IoV in supporting large-scale, real-time, and reliable information services. In this article, we propose a hierarchical system architecture, which aims at synthesizing the paradigms of software defined networking and fog computing in IoV and best exploiting their synergistic effects on information services. Specifically, a four-layer architecture is designed, comprising the application layer, the control layer, the virtualization layer, and the data layer, with objectives of enabling logically centralized control via the separation of the control plane and the data plane; facilitating adaptive resource allocation and QoS oriented services based on network functions virtualization and network slicing, and enhancing system scalability, responsiveness, and reliability by exploiting the networking, computation, communication, and storage capacities of fog-based services. On this basis, we further analyze newly arising challenges and discuss future research directions by presenting a cross-layer protocol stack. Finally, for the proof of concept, we implement the system prototype and give two case studies in real-world IoV environments. The results of field tests not only demonstrate the great potential of the new architecture, but also give insight into the development of future ITS.",data oriented architecture,276,not included
1eb7ae4f9700717ed5f1b9de2d85928125745d8b,to_check,semantic_scholar,TMI,2007-01-01,semantic_scholar,towards hybrid quality-oriented machine translation – on linguistics and probabilities in mt,https://www.semanticscholar.org/paper/1eb7ae4f9700717ed5f1b9de2d85928125745d8b,"We present a hybrid MT architecture, combining state-of-the-art linguistic processing with advanced stochastic techniques. Grounded in a theoretical reflection on the division of labor between rule-based and probabilistic elements in the MT task, we summarize per-component approaches to ranking, including empirical results when evaluated in isolation. Combining component-internal scores and a number of additional sources of (probabilistic) information, we explore discriminative re-ranking of n-best lists of candidate translations through an eclectic combination of knowledge sources, and provide evaluation results for various configurations. 1 Background—Motivation Machine Translation is back in fashion, with data-driven approaches and specifically Statistical MT (SMT) as the predominant paradigm— both in terms of scientific interest and evaluation results inMT competitions. But (fullyautomated) machine translation remains a hard— if not ultimately impossible—challenge. The task encompasses not only all strata of linguistic description—phonology to discourse—but in the general case requires potentially unlimited knowledge about the actual world and situated language use (Kay, 1980, 1997). Although the majority of commercialMT systems still have large sets of hand-crafted rules at their core (often using techniques first invented in the 1960s and 1970s),MT research in the once mainstream linguistic tradition has become the privilege of a small, faithful minority. Like a growing number of colleagues, we question the long-term value of purely statistical (or data-driven) approaches, both practically and scientifically. Large (parallel) training corpora remain scarce for most languages, and wordand phrase-level alignment continue to be active research topics. Assuming sufficient training material, statistical translation quality still leaves much to be desired; and probabilistic NLP experience in general suggests that one must expect ‘ceiling’ effects on system evolution. Statistical MT research has yet to find a satisfactory role for linguistic analysis; on its own, it does not further our understanding of language. Progress on combining rule-based and datadriven approaches toMT will depend on a sustained stream of state-of-the-art, MT-oriented linguistics research. The NorwegianLOGON initiative capitalizes on linguistic precision for high-quality translation and, accordingly, puts scalable, general-purpose linguistic resources—complemented with advanced stochastic components—at its core. Despite frequent cycles of overly high hopes and subsequent disillusionment,MT in our view is the type of application that may demand knowledge-heavy, ‘deep’ approaches toNLP for its ultimate, longterm success. Much like Riezler & Maxwell III (2006) and Llitjós & Vogel (2007)—being faithful minority members ourselves—we approach a hybrid MT architecture with a semantic transfer backbone as our vantage point. Plurality of approaches to grammatical description, reusability of component parts, and the interplay of linguistic and stochastic processes are among the strong points of theLOGON system. In the following, we provide a brief overview of theLOGON architecture ( §2) and a bit of theoretical reflection on the role of probability theory",data oriented architecture,277,not included
b9894d01eb14834220ac6133a600f2070ed9c41d,to_check,semantic_scholar,Proceedings of IEEE Workshop on FPGA's for Custom Computing Machines,1994-01-01,semantic_scholar,a reconfigurable data-driven alu for xputers,https://www.semanticscholar.org/paper/b9894d01eb14834220ac6133a600f2070ed9c41d,"A reconfigurable data-driven datapath architecture for ALUs is presented which may be used for custom computing machines (CCMs), Xputers (a class of CCMs) and other adaptable computer systems as well as for rapid prototyping of high speed datapaths. Fine grained parallelism is achieved by using simple reconfigurable processing elements which are called datapath units (DPUs). The word-oriented datapath simplifies the mapping of applications onto the architecture. Pipelining is supported by the architecture. The programming environment allows automatic mapping of the operators from high level descriptions. Two implementations, one by FPGAs and one with standard cells are shown.<<ETX>>",data oriented architecture,278,not included
973bf397826261e3d1add7a57a78cd62f057442e,to_check,semantic_scholar,IEICE Trans. Electron.,2006-01-01,semantic_scholar,design philosophy of a networking-oriented data-driven processor: cue,https://www.semanticscholar.org/paper/973bf397826261e3d1add7a57a78cd62f057442e,"To realize a secure networking infrastructure, the author is carrying out CUE (Coordinating Users' requirements and Engineering constraints) project with a network carrier and a VLSI manufacture. Since CUE-series data-driven processors developed in the project were specifically designed to be an embedded programmable component as well as a multi-processor element, particular design considerations were taken to achieve real-time multiprocessing capabilities essentially needed in multimedia communication environment. A novel data-driven paradigm is first introduced with special emphasis on VLSI-oriented parallel processing architectures. Data-driven protocol handlings on CUE-p and CUE-vl are then discussed for their real-time multiprocessing capability without any runtime overheads. The emulation facility RESCUE (Real-time Execution System for CUE-series data-driven processors) was also built to develop scalable chip multi-processors in self-evolutional manner. Based on emulation results, the latest version named CUE-v2 was realized as a hybrid processor enabling simultaneous processing of data-driven and control-driven threads to achieve higher performance for inline processing and to avoid any bottlenecks in sequential parts of real-time programs frequently encountered in actual time-sensitive applications. Effectiveness of the data-driven chip multi-processor architecture will finally be addressed for lower power consumption and scalability to realize future VLSI processors in the sub-100 nm era.",data oriented architecture,279,not included
758ef1269c1cf2b5f2be5479fde9dfc610226eed,to_check,semantic_scholar,International Journal of Parallel Programming,2011-01-01,semantic_scholar,acotes project: advanced compiler technologies for embedded streaming,https://www.semanticscholar.org/paper/758ef1269c1cf2b5f2be5479fde9dfc610226eed,"Streaming applications are built of data-driven, computational components, consuming and producing unbounded data streams. Streaming oriented systems have become dominant in a wide range of domains, including embedded applications and DSPs. However, programming efficiently for streaming architectures is a challenging task, having to carefully partition the computation and map it to processes in a way that best matches the underlying streaming architecture, taking into account the distributed resources (memory, processing, real-time requirements) and communication overheads (processing and delay). These challenges have led to a number of suggested solutions, whose goal is to improve the programmer’s productivity in developing applications that process massive streams of data on programmable, parallel embedded architectures. StreamIt is one such example. Another more recent approach is that developed by the ACOTES project (Advanced Compiler Technologies for Embedded Streaming). The ACOTES approach for streaming applications consists of compiler-assisted mapping of streaming tasks to highly parallel systems in order to maximize cost-effectiveness, both in terms of energy and in terms of design effort. The analysis and transformation techniques automate large parts of the partitioning and mapping process, based on the properties of the application domain, on the quantitative information about the target systems, and on programmer directives. This paper presents the outcomes of the ACOTES project, a 3-year collaborative work of industrial (NXP, ST, IBM, Silicon Hive, NOKIA) and academic (UPC, INRIA, MINES ParisTech) partners, and advocates the use of Advanced Compiler Technologies that we developed to support Embedded Streaming.",data oriented architecture,280,not included
29e04a9a210cda16656ef4cf8ee1efa619c4b408,to_check,semantic_scholar,,2020-01-01,semantic_scholar,information sharing for manufacturing supply chain management based on blockchain technology,https://www.semanticscholar.org/paper/29e04a9a210cda16656ef4cf8ee1efa619c4b408,"Internet of Things (IoT) and blockchain technology-based information system (IS) can be used to improve tracking of goods and services in offering and build a collaborative operating environment among the business-partners of the manufacturing industry. In this process IS architecture plays an important role in storing, processing, and distributing data. Despite contributing to the rapid development of IoT applications, the current IoT-centric architecture has led to a myriad of isolated data silos that hinder the full potential of holistic data-driven decision-support applications with the IoT because of technical issues (e.g., standalone IoT applications suffer from security and privacy-related problems). This chapter presents a proof of concept of a hybrid enterprise information system architecture, which consists of IoT-based applications and a blockchain-oriented distributed-ledger system to support-transaction services within a multiparty global manufacturing (e.g., textile and clothing business) network.",data oriented architecture,281,not included
651d0f1bfc127119ad3fc92df2510fff525ec668,to_check,semantic_scholar,Proceedings of IEEE International Workshop on Research Issues in Data Engineering: Active Databases Systems,1994-01-01,semantic_scholar,an alternative paradigm for active databases,https://www.semanticscholar.org/paper/651d0f1bfc127119ad3fc92df2510fff525ec668,Most active database models adopted an event-driven approach in which whenever a given event occurs the database triggers some actions. This paper presents a reflective paradigm implemented in a dependency-oriented fashion. According to this paradigm data driven rules are specified as invariants. The invariants are translated to a dependency graph and the execution logic is self-determined at run-time using this dependency graph. This architecture is presented and discussed as a solution both for data driven rules and for event driven rules.<<ETX>>,data oriented architecture,282,not included
428c581e43a2459971d6b76d53567f387decf531,to_check,semantic_scholar,2006 Second IEEE International Symposium on Service-Oriented System Engineering (SOSE'06),2006-01-01,semantic_scholar,a tuple-space-based coordination architecture for test agents in the mast framework,https://www.semanticscholar.org/paper/428c581e43a2459971d6b76d53567f387decf531,"Service-oriented architecture (SOA) is becoming the mainstream of distributed system integration. Trustworthiness is critical for cross-domain service interaction, and testing is necessary to build the trust among the different parties involved in SOA. MAST, a multi-agent-based service testing framework, was proposed for testing service-based applications in our previous work. This paper further explores the agent coordination issues in the MAST framework to address the challenge of effective agent communication and interaction. A hybrid coordination architecture is presented which combines data-driven and control-driven models based on the reactive tuple space technique. Different tuple spaces are introduced to facilitate data sharing and asynchronous coordination among test agents. A subscription mechanism is introduced to associate programmable reactions to the events occurred and state changes on the tuple space. The mobile agent technique is also introduced to implement the test agents, which are created on line carrying the tasks, and migrate to the host computers to execute various tasks. A prototype system is designed and implemented to illustrate the proposed approach",data oriented architecture,283,not included
c452896d0ba5c7f36b7ba500dc6869c2b522ebcd,to_check,semantic_scholar,IEEE Transactions on Visualization and Computer Graphics,2015-01-01,semantic_scholar,munin: a peer-to-peer middleware for ubiquitous analytics and visualization spaces,https://www.semanticscholar.org/paper/c452896d0ba5c7f36b7ba500dc6869c2b522ebcd,"We present Munin, a software framework for building ubiquitous analytics environments consisting of multiple input and output surfaces, such as tabletop displays, wall-mounted displays, and mobile devices. Munin utilizes a service-based model where each device provides one or more dynamically loaded services for input, display, or computation. Using a peer-to-peer model for communication, it leverages IP multicast to replicate the shared state among the peers. Input is handled through a shared event channel that lets input and output devices be fully decoupled. It also provides a data-driven scene graph to delegate rendering to peers, thus creating a robust, fault-tolerant, decentralized system. In this paper, we describe Munin's general design and architecture, provide several examples of how we are using the framework for ubiquitous analytics and visualization, and present a case study on building a Munin assembly for multidimensional visualization. We also present performance results and anecdotal user feedback for the framework that suggests that combining a service-oriented, data-driven model with middleware support for data sharing and event handling eases the design and execution of high performance distributed visualizations.",data oriented architecture,284,not included
6d1411047ee7f89b38620f095c670958833675d5,to_check,semantic_scholar,2007 IEEE International Conference on Information Reuse and Integration,2007-01-01,semantic_scholar,defining dependable dynamic data-driven software architectures,https://www.semanticscholar.org/paper/6d1411047ee7f89b38620f095c670958833675d5,"The thesis of this vision paper is that the dynamic data driven applications systems (DDDAS) is a promising paradigm to adopt for assisting architectures to self-maintain their dependability properties, as the software architecture tends to evolve in response to changes in the operating environment, changes in contexts, and dynamic usages of the application. In this perspective, the architecture becomes an integrated computational and measurement artifact aimed at measuring, simulating, and controlling the runtime evolution of dependable software systems. This perspective is novel and has the promise to form a built-in support for the runtime dependability analyses, reasoning, and evaluation for many architecture-centric approaches such as product-line, service oriented, and model-driven paradigms. The contribution of this position paper is a definition of Dependable Dynamic Data-Driven Software Architectures (DSA), inspired by this paradigm. We describe the major components which can ""orchestrate "" to realize DSA. We highlight some challenges and opportunities.",data oriented architecture,285,included
b895ee008741a82194abd8f99ed2baa2dedf0731,to_check,semantic_scholar,Int. J. Cooperative Inf. Syst.,1993-01-01,semantic_scholar,a reflective approach for data-driven rules,https://www.semanticscholar.org/paper/b895ee008741a82194abd8f99ed2baa2dedf0731,"This paper presents an alternative to the E-C-A approach adopted by most active database models, in which, whenever a given event occurs the database triggers some actions. A reflective paradigm is implemented in a dependency-oriented fashion. According to this paradigm, data driven rules are specified as invariants. The invariants are translated to a dependency graph and the execution logic is being self-determined at run-time using this dependency graph. This architecture is presented and discussed as a solution for data-driven rules with an extension to support event-driven rules.",data oriented architecture,286,not included
61b2ead1ebc64c3abfc99965fb2c2f7b8484988f,to_check,semantic_scholar,ICSOC,2008-01-01,semantic_scholar,towards automated wsdl-based testing of web services,https://www.semanticscholar.org/paper/61b2ead1ebc64c3abfc99965fb2c2f7b8484988f,"With the emergence of service-oriented computing, proper approaches are needed to validate a Web Service (WS) behaviour. In the last years several tools automating WS testing have been released. However, generally the selection of which and how many test cases should be run, and the instantiation of the input data into each test case, is still left to the human tester. 
 
In this paper we introduce a proposal to automate WSDL-based testing, which combines the coverage of WS operations with data-driven test case generation. We sketch the general architecture of a test environment that basically integrates two existing tools: soapUI, which is a popular tool for WS testing, and TAXI, which is a tool we have previously developed for the automated derivation of XML instances from a XML Schema. 
 
The test suite generation can be driven by basic coverage criteria and by the application of some heuristics, aimed in particular at systematically combining the generated instance elements in different ways, and at opportunely varying the cardinalities and the data values used for the generated instances.",data oriented architecture,287,not included
c9cce66b351a09343012ca1940289ab63e993649,to_check,semantic_scholar,2008 International Symposium on Intelligent Information Technology Application Workshops,2008-01-01,semantic_scholar,toward domain-driven data mining,https://www.semanticscholar.org/paper/c9cce66b351a09343012ca1940289ab63e993649,"Traditional data mining is a data-driven trial-an-error process. It stops at discovered pattern/rule, either views data mining as an autonomous process, or only analyzes the issues in an isolated and case-by-case manner. As a result, the knowledge discovered is not interesting and actionable to constrained business. However, in many real world data mining tasks, for instance financial data mining in capital markets are highly constraint-based and domain- oriented. This paper proposes a new methodology named domain-driven data mining (DDDM), aims to discovery interesting and actionable knowledge for real user needs, overcome the gap between academia and business. DDDM integrates domain knowledge, expert experience, user interestingness, rule action ability and data into mining system. In this paper, A few basic concepts and methodologies are introduced firstly, after that the architecture is proposed and working detail is addressed. Finally, we specify issues that are either not addressed or insufficiently suited yet.",data oriented architecture,288,not included
68c94cae2b9478f0cefd4b264bff4142767c5429,to_check,semantic_scholar,5th Working IEEE/IFIP Conference on Software Architecture (WICSA'05),2005-01-01,semantic_scholar,dmda - a dynamic service architecture for scientific computing,https://www.semanticscholar.org/paper/68c94cae2b9478f0cefd4b264bff4142767c5429,"The objective of this paper is to address the design of an architecture for scientific applications utilizing sensor data. The proposed architecture models applications as services in a service-oriented architecture. This architecture is, mapped to a heterogeneous architecture that contains highperformance, data-driven components and SOA-style components, and a superimposed on a service architecture that provides dynamism.",data oriented architecture,289,not included
5a6a599e9895d621bddd7c9ffe714112f6d5c58d,to_check,semantic_scholar,2008 Tenth IEEE International Symposium on Multimedia,2008-01-01,semantic_scholar,a semantics- and data-driven soa for biomedical multimedia systems,https://www.semanticscholar.org/paper/5a6a599e9895d621bddd7c9ffe714112f6d5c58d,"Due to the problems of heterogeneous data and platforms, abundant functional and QoS requirements, high data size, and tangling correlation between data/contents and software functionalities, developing large-scale biomedical multimedia database systems is a challenging task. This paper presents a semantics- and data-driven service-oriented architecture (SOA) to take the interoperability and scalability advantages of conventional SOA and solve the aforementioned problems. By establishing data ontology with respect to data properties, contents, QoS, and biomedical regulations and expanding service ontology to describe more functional and QoS specifications supported by services, appropriate services for processing biomedical multimedia data may be discovered, performed, tuned up or replaced as needed. Additionally, six transmission services are introduced to support dynamic adaptation under specific requirements.",data oriented architecture,290,not included
b50b7b84df434ae9ef4f7f0c57cbb43916dfc6a7,to_check,semantic_scholar,IEEE Transactions on Industrial Informatics,2021-01-01,semantic_scholar,an overview of recent advances in coordinated control of multiple autonomous surface vehicles,https://www.semanticscholar.org/paper/b50b7b84df434ae9ef4f7f0c57cbb43916dfc6a7,"Autonomous surface vehicles (ASVs) are marine vessels capable of performing various marine operations without a crew in a variety of cluttered and hostile water/ocean environments. For complex missions, there are increasing needs for deploying a fleet of ASVs instead of a single one to complete difficult tasks. Cooperative operations with a fleet of ASVs offer great advantages with enhanced capability and efficacy. Despite various application potentials, coordinated motion control of ASVs pose great challenges due to the multiplicity of ASVs, complexity of intravehicle interactions and fleet formation with collision avoidance requirements, and scarcity of communication bandwidths in sea environments. Coordinated control of multiple ASVs has received considerable attention in the last decade. This article provides an overview of recent advances in coordinated control of multiple ASVs. First, some challenging issues and scenarios in motion control of ASVs are presented. Next, coordinated control architecture and methods of multiple ASVs are briefly discussed. Then, recent results on trajectory-guided, path-guided, and target-guided coordinated control of multiple ASVs are reviewed in detail. Finally, several theoretical and technical issues are suggested to direct future investigations including network-based coordination, event-triggered coordination, collision-free coordination, optimization-based coordination, data-driven coordination of ASVs, and task-region-oriented coordination of multiple ASVs and autonomous underwater vehicles.",data oriented architecture,291,not included
9884653e7a961a602858884858e821ece17e0e13,to_check,semantic_scholar,ICSOFT,2010-01-01,semantic_scholar,an approach to data-driven adaptable service processes,https://www.semanticscholar.org/paper/9884653e7a961a602858884858e821ece17e0e13,"Within the currently forming pervasive computing environment, services and information sources thrive. Instantiations of the service oriented computing paradigm, e.g. Web, Peer-to-Peer (P2P) and Grid services, are continuously emerging, whilst information can be collected from several information sources, e.g. materializations of the Web 2.0 and Web 3.0 trends, Social Networking apps and Sensor Networks. Within this context the development of adaptable service oriented processes utilizing heterogeneous services, in addition to available information, is an emerging trend. This paper presents an approach and an enabling architecture that leverage the provision of data-driven, adaptable, heterogeneous service processes. Core within the proposed architecture is a set of interacting components that accommodate the acquisition of information, the execution of service chains and their adaptation, based on collected information.",data oriented architecture,292,not included
10a1b9d832fec5a034054b6248be5206ac0199ac,to_check,semantic_scholar,,2007-01-01,semantic_scholar,rationale for and design of a generic tiled hierarchical phased array beamforming architecture,https://www.semanticscholar.org/paper/10a1b9d832fec5a034054b6248be5206ac0199ac,"The purpose of the phased array beamforming project is to develop a generic flexible efficient phased array receiver platform, using a mixed signal hardware/software-codesign approach. The results will be applicable to any radio (RF) system, but we will focus on satellite receiver (DVB-S) and radar applications. We will present a preliminary mapping of beamforming processing on a tiled architecture and determine its scalability.

The functionality, size and cost constraints imply an integrated mixed signal CMOS solution. For a generic flexible multi-standard solution, a software defined radio approach is taken. Because a scalable and dependable solution is needed, a tiled hierarchical architecture is proposed with reconfigurable hardware to regain flexibility. A mapping is provided of beamforming on the proposed architecture. The advantages and disadvantages of each solution are discussed with respect to applicability and scalability.

Different beamforming processing solutions can be mapped on the same proposed tiled hierarchical architecture. This provides a flexible, scalable and reconfigurable solution for a wide application domain. Beamforming is a data-driven streaming process which lends itself well for a regular scalable architecture. Beamsteering on the other hand is much more control-oriented and future work will focus on how to support beamsteering on the proposed architecture as well.",data oriented architecture,293,not included
c05d30af61f3442c6d333a018b961695ef7bb04b,to_check,semantic_scholar,SAG,2005-01-01,semantic_scholar,"scientific applications of grid computing, first international workshop, sag 2004, beijing, china, september 20-24, 2004, revised selected and invited papers",https://www.semanticscholar.org/paper/c05d30af61f3442c6d333a018b961695ef7bb04b,"Data-Based Applications.- to OGSA-DAI Services.- Using OGSA-DQP to Support Scientific Applications for the Grid.- Mobile Agent-Based Service Provision in Distributed Data Archives.- A Proxy Service for the xrootd Data Server.- A Flexible Two-Level I/O Architecture for Grids.- Data Driven Infrastructure and Policy Selection to Enhance Scientific Applications in Grid.- BioApplications.- Modelling a Protein Structure Comparison Application on the Grid Using PROTEUS.- Grid Services Complemented by Domain Ontology Supporting Biomedical Community.- Applications Architecture, Frameworks and Models.- A Generic Architecture for Sensor Data Integration with the Grid.- Embarrassingly Distributed and Master-Worker Paradigms on the Grid.- A Framework for the Design and Reuse of Grid Workflows.- Towards Peer-to-Peer Access Grid.- A Service Oriented Architecture for Integration of Fault Diagnostics.- GAM: A Grid Awareness Model for Grid Environments.- Accounting and Market-Based Architecture.- Grid Accounting Service Infrastructure for Service-Oriented Grid Computing Systems.- Mercatus: A Toolkit for the Simulation of Market-Based Resource Allocation Protocols in Grids.- Resource and Information Management in Grid.- A Resource Monitoring and Management Middleware Infrastructure for Semantic Resource Grid.- A Service-Oriented Framework for Traffic Information Grid.",data oriented architecture,294,not included
8e60928342ee18517ac7221c841173a2d91c0bb7,to_check,semantic_scholar,VDM Europe,1987-01-01,semantic_scholar,a formal description of object-oriented programming using vdm,https://www.semanticscholar.org/paper/8e60928342ee18517ac7221c841173a2d91c0bb7,"In this paper we present a formal definition of an object-oriented environment using the specification language VDM [1]. Object-oriented architectures have been of considerable importance in the Artificial InteIligence community [2,3,4] and are of increasing importance in a wider software engineering context [5]. The principal concepts to be defined are those of inheritance and message passing. Smalltalk [5] has a particular architecture which has gained immense popularity. Here we present an environment derived from the Smalltalk architecture, which is simpler but sufficiently powerful to support real applications and has the merit of having been given a concise formal specification. We begin by giving an example of using an object-oriented class hierarchy to describe a simple network of nodes containing data. Then we present a VDM specification of a class hierarchy with a particular model of inheritance. We discuss the facility of passing messages between objects in the class hierarchy as a means of maintaining constraints on the data in our example network. Equipped with the full power of inheritance and message passing, we give examples of propagating constraints through the network in the styles of demand and data driven programming. When presenting the specifications we will assume that the reader has prior knowledge of VDM. Finally, we discuss how the use of formal specification has allowed us to iterate upon the design of this particular object-oriented facility and how we have validated the design by turning the specification into a prototype using the me too method [6,7]. The software specified in this paper has eventually been implemented in LISP and is being used for the development of some business applications. We comment briefly on these matters.",data oriented architecture,295,not included
e40705fe62e4989e9e37be2c33e3913873b2defe,to_check,semantic_scholar,Proceedings Fifth IEEE International Workshop on Computer Architectures for Machine Perception,2000-01-01,semantic_scholar,active computer vision system,https://www.semanticscholar.org/paper/e40705fe62e4989e9e37be2c33e3913873b2defe,"We present a modular architecture for image understanding and active computer vision which consists of the following major components: sensor and actor interfaces required for data-driven active vision are encapsulated to hide machine-dependent parts; image segmentation is implemented in object-oriented programming as a hierarchy of image operator classes, guaranteeing simple and uniform interfaces. We apply this architecture to appearance-based object recognition. This is used for an autonomous mobile service robot which has to locate objects using visual sensors.",data oriented architecture,296,not included
2780780d866ea58b79c5526f3f1d20c56d4d4268,to_check,semantic_scholar,ICVS,1999-01-01,semantic_scholar,active knowledge-based scene analysis,https://www.semanticscholar.org/paper/2780780d866ea58b79c5526f3f1d20c56d4d4268,"We present a modular architecture for image understanding and active computer vision which consists of three major components: Sensor and actor interfaces required for data-driven active vision are encapsulated to hide machine-dependent parts; image segmentation is implemented in object-oriented programming as a hierarchy of image operator classes, guaranteeing simple and uniform interfaces; knowledge about the environment is represented either as a semantic network or as statistical object models or as a combination of both; the semantic network formalism is used to represent actions which are needed in explorative vision. 
 
We apply these modules to create two application systems. The emphasis here is object localization and recognition in an office room: an active purposive camera control is applied to recover depth information and to focus on interesting objects; color segmentation is used to compute object features which are relatively insensitive to small aspect changes. Object hypotheses are verified by an A*-based search using the knowledge base.",data oriented architecture,297,not included
6f8157d52d07286c18c4d72dcd15bf035683a4b6,to_check,semantic_scholar,Sensors,2018-01-01,semantic_scholar,a robust predicted performance analysis approach for data-driven product development in the industrial internet of things,https://www.semanticscholar.org/paper/6f8157d52d07286c18c4d72dcd15bf035683a4b6,"Industrial Internet of Things (IoT) is a ubiquitous network integrating various sensing technologies and communication technologies to provide intelligent information processing and smart control abilities for the manufacturing enterprises. The aim of applying industrial IoT is to assist manufacturers manage and optimize the entire product manufacturing process to improve product quality and production efficiency. Data-driven product development is considered as one of the critical application scenarios of industrial IoT, which is used to acquire the satisfied and robust design solution according to customer demands. Performance analysis is an effective tool to identify whether the key performance have reached the requirements in data-driven product development. The existing performance analysis approaches mainly focus on the metamodel construction, however, the uncertainty and complexity in product development process are rarely considered. In response, this paper investigates a robust performance analysis approach in industrial IoT environment to help product developers forecast the performance parameters accurately. The service-oriented layered architecture of industrial IoT for product development is first described. Then a dimension reduction approach based on mutual information (MI) and outlier detection is proposed. A metamodel based on least squares support vector regression (LSSVR) is established to conduct performance prediction process. Furthermore, the predicted performance analysis method based on confidence interval estimation is developed to deal with the uncertainty to improve the robustness of the forecasting results. Finally, a case study is given to show the feasibility and effectiveness of the proposed approach.",data oriented architecture,298,not included
30b93606b582f22abee447947ca9255420ab07e2,to_check,semantic_scholar,,2001-01-01,semantic_scholar,high performance mass storage and parallel i/o: technologies and applications,https://www.semanticscholar.org/paper/30b93606b582f22abee447947ca9255420ab07e2,"From the Publisher: 
The definitive roadmap through the complex and fast-growing field of high performance I/O architecture 
Todays data-driven high performance computer technologies demand reliable delivery systems that combine high-level computing, storage, I/O, and network communication performance. Due to the growth of Internet-driven applications like digital libraries, virtual laboratories, video on demand, e-commerce, web services, and collaborative systems, issues such as storage capacity and access speed have become critical in the design of todays computer systems. 
High Performance Mass Storage and Parallel I/O fills the need for a readily accessible single reference source on the subject of high performance, large-scale storage and delivery systems, specifically the use of Redundant Arrays of Inexpensive Disks (RAID) that are accessed using parallel input/output (I/O) architecture. The authors, all internationally recognized experts in the field, have combined the best of the current literature on the subject with important information on emerging technologies and future trends. 
Topics covered include: 
Redundant disk array Architecture 
Fault Tolerance Issues in Disk Arrays 
Caching and Prefetching 
Parallel File and I/O Systems 
Emerging Technologies and Future Trends 
 
 
A valuable resource for both students of computer technology and professionals in the field, High Performance Mass Storage and Parallel I/O delivers state-of-the-art information that will help todays system designers and application developers meet the increasing demand for high-performance, large-scale storage systems. 
Author Biography: HAI JIN is a professor of computer science at Huazhong University of Science and Technology, Wuhan, China. He holds both a B.A. and M.S. degree in computer science, and a Ph.D. in electrical and electronics engineering from the same University. He is currently a postdoctoral fellow in the Department of Electrical and Electronics Engineering at the University of Hong Kong in addition to being a visiting scholar at the Internet and Cluster Computing Laboratory at the University of Southern California. Dr. Jin has coauthored three books and published more than 50 papers in international journals and conferences. 
TONI CORTES is an associate professor at Universitat Politecnica de Catalunya, Barcelona, Spain. He obtained his M.S. and Ph.D. degrees in computer science at the same university, and is currently the coordinator of the single-system image technical area in the IEEE Task Force on Cluster Computing (TFCC). Dr. Cortes has also been working on several European industrial projects and has published more than 15 papers in international journals and conferences. RAJKUMAR BUYYA is Co-Chair of the IEEE Task Force on Cluster Computing and an international speaker in the IEEE Computer Society Chapter Tutorials Program. Currently at Monash University, Melbourne, Australia, he is conducting R&D on the use of an economics paradigm for peer-to-peer and grid-based service-oriented computing. He has co-authored Microprocessor x86 Programming and Mastering C++, and edited a popular two-volume book on high performance cluster computing. He has published over 50 research articles in major international journals and conferences.",data oriented architecture,299,not included
b50d46088bfa144b3542acc60919500680e7cc53,to_check,semantic_scholar,,2000-01-01,semantic_scholar,information extraction from the web,https://www.semanticscholar.org/paper/b50d46088bfa144b3542acc60919500680e7cc53,The goal of information extraction from the Web is to provide an integrated view on data from autonomous heterogeneous information sources The main problem with current wrap per mediator approaches is that they rely on very di erent formalisms and tools for wrappers and mediators thus leading to an impedance mismatch between the wrapper and mediator level Additionally most approaches nowadays are restricted to access information only from a xed set of sources On the other hand generic Web querying approaches are restricted to pure syntactical and structural queries and do not deal with semantical issues In this paper we discuss an integrated architecture for Web exploration wrapping media tion and querying Our system is based on a uni ed framework i e data model and language in which all tasks are performed We regard the Web and its contents as a unit represented in an object oriented data model the Web structure given by its hyperlinks the parse trees of Web pages and its contents are all included in the internal world model of the system The advantage of this uni ed view is that the same data manipulation and querying language can be used for the Web structure and the application level model The model is complemented by a rule based object oriented language which is extended by Web access capabilities and structured document analysis Thus accessing Web pages wrapping mediating and querying information can be done using the same language This integration also allows for data driven Web exploration which is independent from a given network of individual prede ned wrappers and mediators Thus in addition to the classical wrapper and mediator functionality a system with this architecture can be equipped with Web navigation and exploration functionality Queries to existing Web indexing and searching engines can also be integrated In particular we present a methodology for reusing generic rule patterns for typical extrac tion integration and restructuring tasks using this framework In an abstract sense the system contains a universal wrapper which can be applied to arbitrary Web pages that the system learns about during information processing Equipped with suitably intelligent rules the sys tem can potentially explore initially unknown parts of the Web thus coping with the steady growth of the Web We show the practicability of our approach by using the Florid system HKL The approach is illustrated by two case studies,data oriented architecture,300,not included
484b9dbbf1425957589aed3d42ff9f9c461caa11,to_check,semantic_scholar,2017 IEEE Symposium on Service-Oriented System Engineering (SOSE),2017-01-01,semantic_scholar,soa based integrated software to develop fault diagnosis models using machine learning in rotating machinery,https://www.semanticscholar.org/paper/484b9dbbf1425957589aed3d42ff9f9c461caa11,"Fault detection and diagnostic software (FDDS) supports technicians and engineers to deal with operational matters, in major cases related to complicated systems and advanced technology that require higher performance expectation. Information and communication technologies play an importantrole for implementing efficient maintenance software, therefore, the development of FDDS is posed as an industrial necessity. In case of industrial rotating machinery, data-driven FDDS using available vibration signals, or other related signals monitored from sensors, is currently viewed as an industrial informatics requirement. This paper proposes the application of a Service Oriented Architecture (SOA) to implement an integrated tool for automatically developing and testing machine learning based fault diagnosis models in rotating machinery. As a result, a generic architecture is obtained which is able to build and implement diagnosis models in similar devices or processes. A condition monitoring software application, using the proposed SOA, was implemented in Java and deployed on a computational environment to test its performance in a experimental test bed, under realistic fault mechanical conditions in a gearbox.",data oriented architecture,301,not included
db2623c46b81f6010dcfc97a2f31cc4b3b0541d7,to_check,semantic_scholar,,2005-01-01,semantic_scholar,towards dynamic model driven architectures,https://www.semanticscholar.org/paper/db2623c46b81f6010dcfc97a2f31cc4b3b0541d7,"Scientific applications using data from networks of sensors must be both highly flexible and high performing. A service-oriented architecture makes sense for modelling such applications, but not for implementing them, due to performance issues and architectural mismatch. In this paper we present an architecture that aims at solving these problems. Applications are modelled as services in a service-oriented architecture, mapped to high-performance, data-driven architectures. Each component is a parallel application. This mapping is done using a MDA approach and is changeable at runtime due to a dynamic Architecture Pattern.",data oriented architecture,302,not included
037d455efb951ce03d0fcd73f7dc7a1265691727,to_check,semantic_scholar,2018 Sixth International Conference on Enterprise Systems (ES),2018-01-01,semantic_scholar,specification of a software architecture for an industry 4.0 environment,https://www.semanticscholar.org/paper/037d455efb951ce03d0fcd73f7dc7a1265691727,"Data-driven decision making is at the core of Industry 4.0. This paper describes the specification of a conceptual architecture of a smart system for supporting decision making in the context of disruptive events in manufacturing operations. Following a viewpoint-oriented approach, the proposed architecture identifies the functional components that facilitate decision making and establishes the interfaces between them, demonstrates the information flow within the manufacturing ecosystem for vertical / horizontal integration and establishes the mapping of the functional components to different software containers, execution environments and physical devices.",data oriented architecture,303,not included
147cc4d3e3364bdc525b28138c2da5e8e4a3d017,to_check,semantic_scholar,IEEE Transactions on Information Forensics and Security,2019-01-01,semantic_scholar,calpa-net: channel-pruning-assisted deep residual network for steganalysis of digital images,https://www.semanticscholar.org/paper/147cc4d3e3364bdc525b28138c2da5e8e4a3d017,"Over the past few years, detection performance improvements of deep-learning based steganalyzers have been usually achieved through structure expansion. However, excessive expanded structure results in huge computational cost, storage overheads, and consequently difficulty in training and deployment. In this paper we propose CALPA-NET, a ChAnneL-Pruning-Assisted deep residual network architecture search approach to shrink the network structure of existing vast, over-parameterized deep-learning based steganalyzers. We observe that the broad inverted-pyramid structure of existing deep-learning based steganalyzers might contradict the well-established model diversity oriented philosophy, and therefore is not suitable for steganalysis. Then a hybrid criterion combined with two network pruning schemes is introduced to adaptively shrink every involved convolutional layer in a data-driven manner. The resulting network architecture presents a slender bottleneck-like structure. We have conducted extensive experiments on BOSSBase + BOWS2 dataset, more diverse ALASKA dataset and even a large-scale subset extracted from ImageNet CLS-LOC dataset. The experimental results show that the model structure generated by our proposed CALPA-NET can achieve comparative performance with less than two percent of parameters and about one third FLOPs compared to the original steganalytic model. The new model possesses even better adaptivity, transferability, and scalability.",data oriented architecture,304,not included
15bfc2f3da21963c5bdf6e859d66a182ae59f32f,to_check,semantic_scholar,Bell Labs Technical Journal,2003-01-01,semantic_scholar,data-driven fault management within a distributed object-oriented oam&p framework,https://www.semanticscholar.org/paper/15bfc2f3da21963c5bdf6e859d66a182ae59f32f,"The design of the Universal Mobile Telecommunications System (UMTS) terrestrial radio access network (UTRAN) radio network controller (RNC) required the integration of hardware and software from multiple vendors and development organizations across a multinational project. The RNC architects, drawing on their experience with previous object-oriented projects, designed an abstract, distributed, object-oriented operations, administration, maintenance, and provisioning (OAM&P) system. A key component is the innovative data-driven fault management (FM) design. It is not just integrated with the devices being controlled; it is integrated into the entire system. FM data is a central project resource used to drive internal error and fault handling, operational state changes, external alarms, and generation of customer documentation. The design takes advantage of well-known commonality and variability design concepts for easy implementation and maintenance. The FM architecture makes the definition of an error, fault, alarm, and fault-handling behavior as simple as adding a row of data. © 2003 Lucent Technologies Inc.",data oriented architecture,305,not included
8ae309e268c677d0d222fbac70d2c8b0c7959ba3,to_check,semantic_scholar,,2008-01-01,semantic_scholar,a network of metadata and web services for integrated coastal zone management,https://www.semanticscholar.org/paper/8ae309e268c677d0d222fbac70d2c8b0c7959ba3,"ABSTRACT Web based tools facilitate intersectoral views of resources by providing for technological solutions of networking and distributed data management in a service oriented architecture, which relies on the ISO standards 19115 for metadata and 19117 for web services. Key features of the described infor-mation infrastructure are a metadata authoring tool, a web portal with detailed discovery interface, where distinct information spaces can be combined for search operations, and workflow embedded mechanisms for metadata production and use. 1. INTRODUCTION The documentation of public geographic and scientific data with standardized metadata is turning into common practice as Spatial Data Infrastructures are being set up on local, regional, national and in-ternational levels to support vertical information flow. PORTER, D.E. et al. (2004), e.g., describe the elements of an estuarine monitoring program as part of a regional coastal observation system that supports the US integrated ocean observing system IOOS. In Europe, the national SDI’s ultimately feed into INSPIRE, the Infrastructure for Spatial InfoRmation in Europe. As outlined by the EURO-PEAN PARLIAMENT AND COUNCIL (2007) this network aims at transparency of information and public access to resources maintained by national spatial data infrastructures. A WORKING GROUP ARCHITECTURE SDI-GERMANY (2007) has put forward the technological concepts and a master plan to implement an appropriate infrastructure in Germany. In addition, several research and devel-opment projects have already been funded to establish a metadata driven information infrastructure for the coastal zone. LEHFELDT, R. et al. (2002) give details on the North Sea and Baltic Sea Coastal Information System NOKIS, which provides a working environment to create metadata appropriate for documentation and data discovery purposes, www.nokis.org. The key issue of this paper is to discuss the basic elements for a network of metadata and web services to disseminate and use coastal infor-mation.",data oriented architecture,306,not included
2705c0ebccb40a11f2d8aec0f5c8e0667741e26f,to_check,semantic_scholar,,2008-01-01,semantic_scholar,acoustic models for posterior features in speech recognition,https://www.semanticscholar.org/paper/2705c0ebccb40a11f2d8aec0f5c8e0667741e26f,"In this thesis, we investigate the use of posterior probabilities of sub-word units directly as input features for automatic speech recognition (ASR). These posteriors, estimated from data-driven methods, display some favourable properties such as increased speaker invariance, but unlike conventional speech features also hold some peculiarities, such that their components are non-negative and sum up to one. State-of-the-art acoustic models for ASR rely on general-purpose similarity measures like Euclidean-based distances or likelihoods computed from Gaussian mixture models (GMMs), hence, they do not explicitly take into account the particular properties of posterior-based speech features. We explore here the use of the Kullback-Leibler (KL) divergence as similarity measure in both non-parametric methods using templates and parametric models that rely on an architecture based on hidden Markov models (HMMs). Traditionally, template matching (TM)-based ASR uses cepstral features and requires a large number of templates to capture the natural variability of spoken language. Thus, TM-based approaches are generally oriented to speaker-dependent and small vocabulary recognition tasks. In our work, we use posterior features to represent the templates and test utterances. Given the discriminative nature of posterior features, we show that a limited number of templates can accurately characterize a word. Experiments on different databases show that using KL divergence as local similarity measure yields significantly better performance than traditional TM-based approaches. The entropy of posterior features can also be used to further improve the results. In the context of HMMs, we propose a novel acoustic model where each state is parameterized by a reference multinomial distribution and the state score is based on the KL divergence between the reference distribution and the posterior features. Besides the fact that the KL divergence is a natural dissimilarity measure between posterior distributions, we further motivate the use of the KL divergence by showing that the proposed model can be interpreted in terms of maximum likelihood and information theoretic clustering. Furthermore, the KL-based acoustic model can be seen as a general case of other known acoustic models for posterior features such as hybrid HMM/MLP and discrete HMM. The presented approach has been extended to large vocabulary recognition tasks. When compared to state-of-the-art HMM/GMM, the KL-based acoustic model yields comparable results while using significantly fewer parameters.",data oriented architecture,307,not included
ce6141a89812338095003cde4f837e252c703b10,to_check,semantic_scholar,,,semantic_scholar,a first-order formalization of knowl- edge and action for a multi-agent planning system. in,https://www.semanticscholar.org/paper/ce6141a89812338095003cde4f837e252c703b10,"(1988). MANDIS/Amoeba: A widely dispersed object-oriented operating system. The contract-net protocol: high-level communication and control in a distributed problem solver. ent cooperation is a considered to be a difficult task (Lesser and Corkill, 1981; Davis and Smith, 1983). CONCLUSIONS Research in cooperation and coordination among independent nodes involves both distributed artificial intelligence, distributed operating systems and studies of cooperation in natural systems. In this paper, we have mainly focused on concepts within DAI. StormCast is a distributed artificial intelligence application for severe storm forecasting (Hartvig-sen and Johansen, 1989) which has functioned as a means of gaining real experience with DAI. In the StormCast project, our main strategy in the design and implementation of the system have been simplification – to keep the design and the source code as simple as possible without main losses in the functionality. The major motivation for this has been the transparency requirements. A modular design together with the utilization of de facto industrial standards has appeared to be sufficient in the task of weather forecasting in a distributed artificial intelligence concept. In addition, through the use of our simplifying approach, we have avoided problems with global state detections, synchronization , etc., which in term influences the transparent view the users have of the application. One of the main problems to face in distributed artificial intelligence applications is the coordination of cooperating nodes. A lot of effort has been spent on the coordination problem, and several approaches to improving coordination among cooperating nodes have been presented. A common denominator for the approach presented seems to be real-time computing, which in our experience is a very resource intensive solution. Therefore, we have used a non real-time approach in order to reduce the complexity, but maintain the functionality. However, even if our choice of system architecture, a data-driven forward-chaining expert system module together with the simple blackboard system (the knowledge layer), has shown some of the possibilities with this kind of application, still much work remain to be done to obtain a commercial application. Further research might include the study of a more complex rule-based expert system that includes both forward and backward chaining, certainty factors, possibly frame-based reasoning, etc., and the diversification of the blackboard in small specialized parts, each guarded by its own monitor. This may in turn increase both the qualitative and the quantitative system performance.",data oriented architecture,308,not included
90fb729b8f2ea9cd1043098fa229cb6269219c2e,to_check,semantic_scholar,2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2),2021-01-01,semantic_scholar,a survey of deep neural network in acoustic direction finding,https://www.semanticscholar.org/paper/90fb729b8f2ea9cd1043098fa229cb6269219c2e,"Direction of Arrival (DoA) estimation has importance in many industries such as speech enhancement, spatial audio coding, radio frequency and radio telescope. Deep Neural Network (DNN) has find its way into DoA applications along with the well-known methods such as subspace-based or time difference of arrival methods, which opens-up the data-driven approach towards estimating the DoA. This paper first surveys different DNN architectures and their supporting methods and datasets that are used for estimating DoA in different scenarios. Then a promising architecture based on convolutional recurrent neural network (CRNN) is re-presented on the Spatially Oriented Format for Acoustics (SOFA) dataset, where the average error rate of 9.68° has been achieved.",data oriented architecture,309,not included
92b889406beb784a7a9f98750612648c51b33f58,to_check,semantic_scholar,2019 Winter Simulation Conference (WSC),2019-01-01,semantic_scholar,a study of lightweight dddas architecture for real-time public safety applications through hybrid simulation,https://www.semanticscholar.org/paper/92b889406beb784a7a9f98750612648c51b33f58,"Utilizing the Dynamic Data Driven Applications Systems (DDDAS) framework for Smart Cities, a Smart Public Safety (SPS) system has become feasible by integrating heterogeneous computing devices to collaboratively provide public safety services. However, a service oriented architecture (SOA) is difficult to provide scalable and extensible services in a city-wide distributed Internet of Things (IoT)-based SPS system. Furthermore, traditional management and security solutions rely on a centralized authority, which can be the performance bottleneck or single point of failure. Inspired by the microservices architecture and blockchain technology, a Lightweight IoT based Smart Public Safety (LISPS) framework is proposed on top of a permissioned blockchain network. Through decoupling a monolithic complex system into independent sub-tasks, the LISPS system possesses high flexibility in the design process and online maintenance. The experimental results demonstrate the feasibility of the approach to provide a secured data sharing and access control mechanism.",data oriented architecture,310,not included
3f769b65303541f8e27e43a550110b3f1ad311aa,to_check,semantic_scholar,ARCS,2013-01-01,semantic_scholar,gals-cmp: chip-multiprocessor for gals embedded systems,https://www.semanticscholar.org/paper/3f769b65303541f8e27e43a550110b3f1ad311aa,"In this paper we present a novel multi-processor architecture for concurrent execution of programs that follow the Globally Asynchronous Locally Synchronous (GALS) formal model of computation. Programs are specified using the SystemJ concurrent programming language, suitable for modeling heterogeneous embedded applications that contain reactive and control driven parts and interact with the external environment. The proposed architecture is based on separating the control-driven and data-driven operations and executing them on distinct cores that support both types of operations, implemented as two modes within the single processor core. Each core can switch between two modes without any overhead. The core as the basic building block of the multiprocessor extends Java Optimized Processor (JOP), suitable for data-driven transformational operations, with control-oriented constructs that implement concurrency, reactivity, and control flow in SystemJ. Experimental evaluation over a range of benchmarks shows significant performance improvements over the existing platforms developed for the execution of the SystemJ program.",data oriented architecture,311,not included
b2076d15e86a5bd8e2dd3e8240e0c08254865c94,to_check,semantic_scholar,ArXiv,2019-01-01,semantic_scholar,accelerating pde-constrained inverse solutions with deep learning and reduced order models,https://www.semanticscholar.org/paper/b2076d15e86a5bd8e2dd3e8240e0c08254865c94,"Inverse problems are pervasive mathematical methods in inferring knowledge from observational and experimental data by leveraging simulations and models. Unlike direct inference methods, inverse problem approaches typically require many forward model solves usually governed by Partial Differential Equations (PDEs). This a crucial bottleneck in determining the feasibility of such methods. While machine learning (ML) methods, such as deep neural networks (DNNs), can be employed to learn nonlinear forward models, designing a network architecture that preserves accuracy while generalizing to new parameter regimes is a daunting task. Furthermore, due to the computation-expensive nature of forward models, state-of-the-art black-box ML methods would require an unrealistic amount of work in order to obtain an accurate surrogate model. On the other hand, standard Reduced-Order Models (ROMs) accurately capture supposedly important physics of the forward model in the reduced subspaces, but otherwise could be inaccurate elsewhere. In this paper, we propose to enlarge the validity of ROMs and hence improve the accuracy outside the reduced subspaces by incorporating a data-driven ML technique. In particular, we focus on a goal-oriented approach that substantially improves the accuracy of reduced models by learning the error between the forward model and the ROM outputs. Once an ML-enhanced ROM is constructed it can accelerate the performance of solving many-query problems in parametrized forward and inverse problems. Numerical results for inverse problems governed by elliptic PDEs and parametrized neutron transport equations will be presented to support our approach.",data oriented architecture,312,not included
c92b7a5a26e81fb0a6080b3a1572b287d1f2fcb5,to_check,semantic_scholar,Proceedings. Second Euromicro Workshop on Parallel and Distributed Processing,1994-01-01,semantic_scholar,wavefront scheduling in logflow,https://www.semanticscholar.org/paper/c92b7a5a26e81fb0a6080b3a1572b287d1f2fcb5,"Recently inrensive research h,as been started on investigaring the possibility of implementing logic programming languages on distributed memiry computers [KaWi92]. The LOGFLOW project belongs to this class of projects and is unique in the sense that is based on a data driven execution model which is highly optimised towards the execution on neighborhoodo~ented~~geneous processor spaces. The main contribution of the current paper is the description of a dynamic scheduling scheme thal is able to adaptively control the distribution of Prolog work in the processor space based on the a c t d workbad of processors. 1: Introduction Parallel implementation of Prolog on different kinds of parallel computers has intensively been investigated since the mid eighties. The variety of parallel computers entailed a large number of proposals and experimental work on parallel Prolog, but most of these research efforts have been concentrated on implementing Prolog or a F’rolog variant on shared memory multiprocessors [GuJS], [HeCir90], [AlKaW], [CoWY91], [Dove%]. Recently intensive research has been started on investigating the possibility of implementing logic programming languages on distributed memory computers as well [KaWi92]. Many research projects aimed at parallelizing logic programs based on a dataflow execution model, but except for [BaCR92], the others consideired real dataflow machines as target architecture for a possible implementation @aAm84], [ItO8s], [Hali86], [BiLe87], [SiswSS]. The LOGFLOW project is also based on a data driven execution model but this model is highly optimised towards the execution on neighborhood oriented homogeneous processor spaces. Prolog programs are compiled into the Dataflow Search Graph and the computahion is based on this graph. An early version of the underlying abstract parallel execution model was described in [KacsW]. A revised version and its interpreted implementatioin on distributed memory multicomputers like multi-Transputers has been shown in [Kacs9l]. Based on the revised execution model a distributed data driven Prolog abstract machine, called the 3DPAh4 was designed and described in detail in mcs921. The implementation of the 3DPAM in a two-layer multi-transputer based machine, called the LOGFLOW machine is shown in Dcs931. In the present paper we give a detailed explanation of how to schedule parallel activities in the LOGFLOW machine based on a dynamic mapping and scheduling scheme that is able to adaptively control the distribution of Prolog work in the processor space based on the actual workload of processors. The scheduling of processes in parallel Prolog systems has been thoroughly investigated for shared memory systems [Herm87], [But188], [AlKa91], [Beau911 and recently for distributed memory systems, mainly for multi-transputers [Bria92] . The work described in [Can11921 has many similarities with our scheduling approach. 2: LOGFLOW The objective of the LOGFLour project is to implement CPA-Prolog (a slight modification of Prolog) on tightly-coupled distributed memory parallel computers where the communication cost between neighboring processors is significantly less than between remote processors. In CPA-Prolog everything is parallel by default, and therefore database oriented sideeffect * The current paper is part of the project titled “Highly Parallel Implementation of :Prolog on Distributed Memory Computers” supported by the National Scientific Research Foundation (Hungary) under the Grant Number T4045. 0-8186-5370-1/94 $3.00",data oriented architecture,313,not included
10fc71551cc0cae6430d695c2f2c739f2a8a9f36,to_check,semantic_scholar,SBP-BRiMS,2018-01-01,semantic_scholar,digilego: a standardized analytics-driven consumer-oriented connected health framework,https://www.semanticscholar.org/paper/10fc71551cc0cae6430d695c2f2c739f2a8a9f36,"Connected health solutions provide novel pathways to provide integrated and affordable care. Emerging research suggests these connected tools can result improved health outcomes and sustainable self-health management. However, current health technology frameworks limit flexibility, engagement, and reusability of underlying connected health components. The objective of this paper is to develop a data-driven consumer engagement framework, which we call Digilego, to facilitate development of connected health solutions that are targeted, modular, extensible, and engaging. The major components include social media analysis, patient engagement features, and behavioral intervention technologies. We propose implementation of these Digilego components using FHIR specification such that the resulting technology is compliant to industry standards. We apply and evaluate the proposed framework to characterize four individual building blocks (DigiMe, DigiSocial, DigiConnect, DigiEHR) for a connected health solution that is responsive to cancer survivor needs. Results indicate that the framework (a) allows identification of survivor needs (e.g. social integration, treatment side effects) through semi-automated social media analysis, (b) facilitates infusion of engagement elements (e.g. smart health trackers, integrated electronic health records), and (c) integrates behavior change constructs into the design architecture of survivorship applications (e.g. goal setting, emotional coping). End user evaluation with 16 cancer survivors indicated general user acceptance and enthusiasm to adopt the solution for self-care management. Implications for design of patient-engaging chronic disease management solutions are discussed.",data oriented architecture,314,not included
eb902eddbc65d568eec589af7c3b015359b93622,to_check,semantic_scholar,IF&GIS,2007-01-01,semantic_scholar,architecture types of the bit permutation instruction for general purpose processors,https://www.semanticscholar.org/paper/eb902eddbc65d568eec589af7c3b015359b93622,"In large information systems different data transform algorithms including the bit permutation operations requiring an execution of great number of cycles are used. To increase significantly the software performance of such algorithm a controlled bit permutation instruction (BPI) is desirable. Here a question of justification of embedding a new command, controlled BPI, into the standard set of instructions of general-purpose processor for increasing the efficiency of different types algorithms implemented in software is studied. In a variety of applications two different types of bit permutation operations are required: arbitrary fixed permutations and variable permutations. The last are used in a new fast cipher designs based on data-dependent permutations. Accounting for an expediency of embedding the controlled permutation command into the set of elementary processor operations the cryptographic applications form only one of the motivation elements. Another strong motivation is BPI’s use for solving variety of non-cryptographic problems. The multipurpose architecture of the BPI operation oriented to the efficient execution of both the cryptographic functions based on data-driven permutations and the algorithms including arbitrary bit permutations is proposed.",data oriented architecture,315,not included
bbcfc2fd448de0e144c931768e2feb706e50844b,to_check,semantic_scholar,,2007-01-01,semantic_scholar,error awareness and recovery in conversational spoken language interfaces,https://www.semanticscholar.org/paper/bbcfc2fd448de0e144c931768e2feb706e50844b,"One of the most important and persistent problems in the development of conversational spoken language interfaces is their lack of robustness when confronted with understanding-errors. Most of these errors stem from limitations in current speech recognition technology, and, as a result, appear across all domains and interaction types. There are two approaches towards increased robustness: prevent the errors from happening, or recover from them through conversation, by interacting with the users. 
In this dissertation we have engaged in a research program centered on the second approach. We argue that three capabilities are needed in order to seamlessly and efficiently recover from errors: (1) systems must be able to detect the errors, preferably as soon as they happen, (2) systems must be equipped with a rich repertoire of error recovery strategies that can be used to set the conversation back on track, and (3) systems must know how to choose optimally between different recovery strategies at run-time, i.e. they must have good error recovery policies . This work makes a number of contributions in each of these areas. 
First, to provide a real-world experimental platform this error handling research program, we developed RavenClaw, a plan-based dialog management framework for task-oriented domains. The framework has a modular architecture that decouples the error handling mechanisms from the do main-specific dialog control logic; in the process, it lessens system authoring effort, promotes portability and reusability, and ensures consistency in error handling behaviors both within and across domains. To date, RavenClaw has been used to develop and successfully deploy a number of spoken dialog systems spanning different domains an interaction types. Together with these systems, RavenClaw provides the infrastructure for the error handling work described in this dissertation. 
To detect errors, spoken language interfaces typically rely on confidence scores. In this work we investigated in depth current supervised learning techniques for building error detection models. In addition, we proposed a novel, implicitly-supervised approach for this task. No developer supervision is required in this case; rather, the system obtains the supervision signal online, from naturally-occurring patterns in the interaction. We believe this learning paradigm represents an important step towards constructing autonomously self-improving systems. Furthermore, we developed a scalable, data-driven approach that allows a system to continuously monitor and update beliefs throughout the conversation; the proposed approach leads to significant improvements in both the overall effectiveness and efficiency of the interaction. 
We developed and empirically investigated a large set of recovery strategies, targeting two types of understanding-errors that commonly occur in these systems: misunderstandings and nonunderstandings. Our results add to an existing body of knowledge about the advantages and disadvantages of these strategies, and highlight the importance of good recovery policies. 
In the last part of this work, we proposed and evaluated a novel online-learning based approach for developing recovery policies. The system constructs runtime estimates for the likelihood of success of each recovery strategy, together with confidence bounds for those estimates. These estimates are then used to construct a policy online, while balancing the system's exploration and exploitation goals. Experiments with a deployed spoken dialog system showed that the system was able to learn a more effective recovery policy in a relatively short time period.",data oriented architecture,316,not included
3af19665f88f5b4a5782deec8909b41173319c3b,to_check,semantic_scholar,EC-Web,2009-01-01,semantic_scholar,metadata-driven soa-based application for facilitation of real-time data warehousing,https://www.semanticscholar.org/paper/3af19665f88f5b4a5782deec8909b41173319c3b,"Service-oriented architecture (SOA) has already been widely recognized as an effective paradigm for achieving integration of diverse information systems. SOA-based applications can cross boundaries of platforms, operation systems and proprietary data standards, commonly through the usage of Web Services technology. On the other side, metadata is also commonly referred to as a potential integration tool given the fact that standardized metadata objects can provide useful information about specifics of unknown information systems with which one has interest in communicating with, using an approach commonly called ""model-based integration"". This paper presents the result of research regarding possible synergy between those two integration facilitators. This is accomplished with a vertical example of a metadata-driven SOA-based business process that provides ETL (Extraction, Transformation and Loading) and metadata services to a data warehousing system in need of a real-time ETL support.",data oriented architecture,317,not included
56ec57f9db38a8467b1cf5672dda307661f635fc,to_check,semantic_scholar,,2010-01-01,semantic_scholar,modeling and simulation technology oriented to machining-assembly combined production system,https://www.semanticscholar.org/paper/56ec57f9db38a8467b1cf5672dda307661f635fc,"In view of the problem of collaborative production relationship between machining or assembly isolated by the separately modeling and simulation for each production system,the modeling and simulation technology oriented to machine-assembly combined production system,which supports the JIT (just-in-time) production pattern,is put forward.By importing the concept of the integrity assembly work station,the unified process description data structure for the combined production system is proposed and the collaborative production relationship between the machining and assembly is defined.Based on the hierarchical and interaction architecture of the workshop-work station-equipment,the modular modeling library embodied as the logic controller,corresponding with each level of the architecture,is constructed,and the lot-sizing process logic controller is also derived in order to reflect practice of the portfolio production.By utilizing the separation strategy between the physical model and control blocks,the layout and process data-driven rapid modeling methodology is brought forward on the basis of the mapping between the layout element and logic controllers.The task data-driven,hierarchical and modular simulation control mechanism is presented under the guidance of mapping methodology between the practical operation of the production system and the collaborating interaction among logic controller.The statistics of the equipment,queue and product driven by the simulation event is gathered and can support the optimization decision based on simulation.The optimization planning case of the task's production release time based on comparative analysis with such practical combined production system in a research institution shows that data-driven modeling and simulation technology can effectively be used for lean production decision.",data oriented architecture,318,not included
4fabe5ce8ea799f834282266affdec97711c1a60,to_check,semantic_scholar,SBSI,2019-01-01,semantic_scholar,polyflow: a soa for analyzing workflow heterogeneous provenance data in distributed environments,https://www.semanticscholar.org/paper/4fabe5ce8ea799f834282266affdec97711c1a60,"In the last decade the (big) data-driven science paradigm became a wide-spread reality. However, this approach has some limitations such as a performance dependency on the quality of the data and the lack of reproducibility of the results. In order to enable this reproducibility, many tools such as Workflow Management Systems were developed to formalize process pipelines and capture execution traces. However, interoperating data generated by these solutions became a problem, since most systems adopted proprietary data models. To support interoperability across heterogeneous provenance data, we propose a Service Oriented Architecture with a polystore storage design in which provenance is conceptually represented utilizing the ProvONE model. A wrapper layer is responsible for transforming data described by heterogeneous formats into ProvONE-compliant. Moreover, we propose a query layer that provides location and access transparency to users. Furthermore, we conduct two feasibility studies, showcasing real usecase scenarios. Firstly, we illustrate how two research groups can compare their processes and results. Secondly, we show how our architecture can be used as a queriable provenance repository. We show Polyflow's viability for both scenarios using the Goal-Question-Metric methodology. Finally, we show our solution usability and extensibility appeal by comparing it to similar approaches.",data oriented architecture,319,not included
bdf614547e22ef85f5c6c8377935d678b0c2fe59,to_check,semantic_scholar,,2002-01-01,semantic_scholar,sumatratt: towards a universal data preprocessor,https://www.semanticscholar.org/paper/bdf614547e22ef85f5c6c8377935d678b0c2fe59,"In the practice of data mining (DM) and data warehousing (DWH), real-life data arrive in various different formats, and without putting them into an acceptable shape, even the most intelligent DM/DWH tool would be useless. SumatraTT (Transformation Tool) is an original universal data pre-processing tool allowing to access and transform data stored in various types of datasources (e.g. plain text, SQL etc.). We briefly review the concept of the system and summarize its recent developments. The paper briefly overviews the connectivity with inductive logic programming (ILP) systems and then informs on more recently added features consisting of new data interfaces, scripting features, and templates. The usage of Sumatra TT on an example application is shortly demonstratied. After a brief touch upon near-future plans, we finally discuss some questions typically arising at the first usage of SumatraTT. 1 OUR MOTIVATION AND GOALS DM algorithms [6] are being designed by researchers and SW houses all over the world. There are many of them and their offer is continuously growing. Their different available implementations differ in principles as well as in tiny details such as the format used for the input data. Moreover, most often the data subjected to DM have not been collected for DM purposes primarily; on the contrary they serve e.g. as a company archive. Consequently, the format of such data cannot meet the requirements of a specific DM algorithm most often. The challenge of a DM task is in finding the algorithm which will reveal interesting observations in the considered data. But to reach this goal many experiments have to be done. One cannot decide in advance which set of DM tools or which derived attributes will prove most useful for the given problem. Thus original data have to be processed or transformed in different ways to make them usable by the chosen DM algorithms. Format of data has to be changed, data has to be cleaned, filtered, aggregated, etc. This is the purpose of data transformation systems which have recently appeared as independent SW tools supporting DM process itself [14]. This is an important step simplifying data preparation processes and supporting experiments with real life data. The common pain of state-of-art data transformation systems is their insufficient generality. Our goal is to overcome this problem by designing a developing a system • that allows for virtually any customization with respect to different data standards and requirements on the transformation, • but at the same time provides ultimate ease-of-use in cases where only standard procedures are required. The former goal can be achieved by providing a dataprocessing oriented scripting language, and the latter goal by providing templates of the common procedures and standard interfaces to many kinds of datasources. These ideas form the design principles of the data preprocessing tool SumatraTT described briefly in the next section. Most industries benefit from appropriate standardization. Positive reaction of the research community to the activity of the PMML group proves this is the case of the research field concerned with decision support systems, too. Prediction Model Mark-up Language is being developed to simplify exchange or sharing the results „between compliant vendorś applications ... so that proprietary issues and incompababilities are no longer a barrier“ ( http://www.dmg.org/pmmlspecs_v2/ ). Similar view can be taken towards data-transformations. We hope that our study of data transfomations using SumatraTT will complemet to development of a standard for data transfomation, namely to the Data Transformation Markup Language (DTML) supporting e.g. reuse of the same data by different algorithms through seemless import, rapid development of derived attributes, etc. 2 THE CONCEPT OF SUMATRA SumatraTT (Transformation Tool) is a metadata-driven, platform independent, extensible, and universal data processing tool [3]. The mentioned features have been achieved by building the tool as an interpreter of the transformation-oriented scripting language called Sumatra [2]. The Sumatra language is a fully interpreted Java-like language combining data access, metadata access, and common programming constructions. Furthermore, it supports the RAD (Rapid Application Development) technology by means of the library of reusable transformation templates. The principal scheme of SumatraTT is shown in Figure 1. As can be seen in the figure, the central part of SumatraTT is the Metadata repository module. Basically, the repository plays two roles. It is the central storage consisting of descriptions of all data sources and data transformations to be used. Moreover, the repository contains data objects interconnecting the abstract data access level in the Sumatra interpreter with real-life data sources. This intermediated connection helps to unify data access to very different data sources (e.g. SQL-based data sources, plain text files, etc). Such unification makes the process of transformation script development easier and data source independent. Moreover it separates the transformation ""logic"" from the data connection problems. In the case of very complicated data pre-processing task, the development of a data transformation script can be rather time consuming. SumatraTT allows to speed up this process by using reapplicable transformation templates. The idea of reusable templates is based on the library of solved types of tasks. E.g. there is a data set containing time series and we need to calculate a statistical characterization of the data. If this is carried out for the first time, a new template has to be developed. But the next time, the statistical transformation script can be developed via a parametric modification of the existing template within a fraction of the time required before. Every pre-processing task realized using SumatraTT consists of design and run-time phases. It corresponds to a client-server architecture where the design phase consists of the definition of all data sources and the development of transformation scripts on the client side. Regarding a typical user who is an expert in data mining or data warehousing but who is not a programmer, the design phase can be carried out using graphical user interface. The GUI allows to interactively realize both the data definition and script development by simple clicking on wizards. On the other hand, the run-time phase corresponds to a script execution on the server side. From the user's perspective, the execution can be invoked immediately or scheduled for a later run.",data oriented architecture,320,not included
faf427a862e3eff614e78eb5bd870c595cff9766,to_check,semantic_scholar,,1994-01-01,semantic_scholar,a reconfigurable arithmetic datapath architecture,https://www.semanticscholar.org/paper/faf427a862e3eff614e78eb5bd870c595cff9766,"A reconfigurable data-driven arithmetic datapath architecture for ALUs is presented which may be used for custom computing machines, Xputers and other adaptable computer systems as well as for rapid prototyping of high speed datapaths. Fine grained parallelism is achieved by using simple reconfigurable processing elements which are called datapath units (DPUs). The word-oriented datapath simplifies the mapping of applications onto the architecture. Pipelining is supported by the architecture. The programming environment allows automatic mapping of the operators from high level descriptions. Two implementations, one by FPGAs and one with standard cells are shown.",data oriented architecture,321,not included
d81e8b60fd2cc9f14412a45ac9243431ebd0ad7c,to_check,semantic_scholar,2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops),2011-01-01,semantic_scholar,decoupling context-aware services,https://www.semanticscholar.org/paper/d81e8b60fd2cc9f14412a45ac9243431ebd0ad7c,"We present a novel software architecture for context-aware applications based on a distributed, non-monolithic, simple and extensible relational model for representing context; a service-oriented architecture for computing these relations in a decoupled, flexible fashion; and with data driven, event based communication providing the kind of fine grained dynamic service composition required in mobile and volatile environments. A prototype implementation is running a Bluetooth-sensor-based active map of users at our home university.",data oriented architecture,322,not included
062a5b4fbc9e2decd5d38151531ec78c72980ea2,to_check,semantic_scholar,2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS),2020-01-01,semantic_scholar,improving data quality in medical research: a monitoring architecture for clinical and translational data warehouses,https://www.semanticscholar.org/paper/062a5b4fbc9e2decd5d38151531ec78c72980ea2,"Clinical and translational data warehouses are important infrastructure building blocks for modern data-driven approaches in medical research. These analytics-oriented databases have been designed to integrate heterogeneous biomedical datasets from different sources and to support use cases such as cohort selection and ad-hoc data analyses. However, the lack of clear definitions of source data and controlled data collection procedures often raises concerns about the quality of data provided in such environments and, consequently, about the evidence level of related findings. To address these problems, we present an architecture that helps to monitor data quality issues when importing data into warehousing solutions using ETL (Extraction, Transformation, Load) processes. Our approach provides software developers with an API (Application Programming Interface) for logging detailed and structured information about data quality issues encountered. This information can then be displayed in dynamic dashboards, the evolution of data quality can be monitored over time, and quality issues can be traced back to their source. Our architecture supports several well-known data quality dimensions, addressing conformance, completeness, and plausibility. We present an open-source implementation, which is compatible with common clinical and translational data warehousing platforms, such as i2b2 and tranSMART, and which can be used in conjunction with many ETL environments.",data oriented architecture,323,not included
8bf515f6bca6c76ff30988bb410b6aa29587cdd0,to_check,semantic_scholar,ArXiv,2017-01-01,semantic_scholar,joint auto-encoders: a flexible multi-task learning framework,https://www.semanticscholar.org/paper/8bf515f6bca6c76ff30988bb410b6aa29587cdd0,"The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples. Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest. Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion. We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task. Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations. The method deals with domain adaptation and multi-task learning in a unified fashion, and can easily deal with data arising from different types of sources. Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network.",data oriented architecture,324,not included
c6e097227b1c37abec6fc9d593fe4df6c5c6924b,to_check,semantic_scholar,,2012-01-01,semantic_scholar,cloud computing for mission design and operations,https://www.semanticscholar.org/paper/c6e097227b1c37abec6fc9d593fe4df6c5c6924b,"The space mission design and operations community already recognizes the value of cloud computing and virtualization. However, natural and valid concerns, like security, privacy, up-time, and vendor lock-in, have prevented a more widespread and expedited adoption into official workflows. In the interest of alleviating these concerns, we propose a series of guidelines for internally deploying a resource-oriented hub of data and algorithms. These guidelines provide a roadmap for implementing an architecture inspired in the cloud computing model: associative, elastic, semantical, interconnected, and adaptive. The architecture can be summarized as exposing data and algorithms as resource-oriented Web services, coordinated via messaging, and running on virtual machines; it is simple, and based on widely adopted standards, protocols, and tools. The architecture may help reduce common sources of complexity intrinsic to data-driven, collaborative interactions and, most importantly, it may provide the means for teams and agencies to evaluate the cloud computing model in their specific context, with minimal infrastructure changes, and before committing to a specific cloud services provider.",data oriented architecture,325,not included
b026efb31ee0ad78eef8a9c6ae667f73eecc9a73,to_check,semantic_scholar,,2013-01-01,semantic_scholar,goal-driven automated dynamic retraining for space weather abnormality detection,https://www.semanticscholar.org/paper/b026efb31ee0ad78eef8a9c6ae667f73eecc9a73,"This paper addresses the application of automatically adaptive data-driven and goal-driven software tools for the detection and environment caused characterization of abnormal space system behavior with a priori unknown signatures. Goal-driven abnormality detection determines when retraining is needed, what data to train on, what data to test on, how to test, whether additional training is needed, and whether to promote the updated software. We discuss the design of automated space weather (SpWx) attribution tools and show sample results on real data. The space weather attribution, context assessment, and visualization tools described in this paper are extendable for characterization of fused multiple source abnormal event tracks from new sources using the Smoking Gun (SG) and the Bayesian Fusion Node (BFN). SG identifies correlation relationships such as between space weather and satellite system abnormal events. The BFN is runtime configurable with regard to input formats, taxonomy specification, decision logic, and processing. BACKGROUND Situational Awareness forms the framework for operations, planning, and decision making. Space Situational Awareness (SSA) brings knowledge of the operational space environment, its supporting ground elements and links and the projection of its future status. To achieve effective space situational awareness, the SSA system architecture must provide the decision maker and user the right data, information, tools, and decision aids at the right time. Using a net-centric service-oriented data fusion approach will allow a rapid assessment of the situation, capitalize on many available data sources, and adapt to situations in a timely manner. Information will need to be gathered across a broad range of DOD, civil, and commercial sources. Once this data is identified, it will need to be developed into actionable information for the decision maker. Space assets are susceptible to numerous anomalous conditions including: space weather events, radio frequency interference (RFI), satellite payload jamming, dazzling, proximity operations, breakup, bus failures, and other satellite anomalies. Given this variety of problematic situations, decision makers need a distributed satellite resource management system to effectively accomplish their space access mission. Near real-time integrated Space Situational Awareness (SSA) methods are needed to: detect & distinguish between environmental, man-made, and unintentional acts; predict actor intent; and provide real-time response recommendations to evolving scenarios. Distributed satellite resource management promises continued access to space capabilities so as to maintain mission-critical information after space-based asset degradation. Currently, in the event that space-based assets suffer an outage or abnormality, the responsibility falls to the human-in-the-loop to follow checklist procedures to restore operations. Unfortunately, these procedural checklists are time-consuming and are not always optimized with consideration of the need to maintain SSA. Also, systems used to compensate for satellites suffering outages may not achieve the restoration of service with sufficient time to adequately support ongoing missions. A semi-automated satellite mission re-planning system capable of confirming and characterizing abnormalities and then recommending space-based asset responses will be integral to the future improved use of US space order of battle assets. This system will run continuously, monitoring the relationships between space asset events, the potential for satellite system outages, and the ongoing missions relying on space-based assets. The system will provide immediate input to the human-in-the-loop in the form of a series of satellite mission re-planning and response options based on the current SSA that will balance support to ongoing operations with the need to ensure US space missions. There are five functional levels of SSA. Namely, incident detection/ causality, event tracking/characterization, event relationship assessment, mission impact prediction, and process & context assessments) and five dual response management levels within which the automated response decision aids of interest reside. These five levels have been described based upon the Data Fusion & Resource Management (DF&RM) Dual Node Network (DNN) technical architecture which is an extension of the JDL fusion model [1 and 2]. Activities include development of space weather attribution technologies, performance assessments, and services that utilize real sources of space systems data (e.g., State of Health (SOH), Signal to Noise Ratio (SNR), signal strength, etc.) and authoritative space weather sources. Scope and Relationships of This Work The DF&RM DNN technical architecture has been applied to guide the system architecture development for numerous DF&RM capabilities developed for SSA. The divide & conquer techniques in the DF&RM DNN technical architecture begin with guidance to functionally partition by layer and at the applications layer by “DF&RM functional levels” that are extensions and duals of the Joint Director’s Lab (JDL) data fusion model from the 1980’s [1]. The five fusion levels are summarized as follows:  Signal/Feature Assessment -Level 0: estimation of entity feature states  Entity Assessment -Level 1: estimation of entity states  Situation Assessment -Level 2: estimation of entity relationship states  Impact Assessment -Level 3: estimation of the mission impact of fused states  Process Assessment -Level 4: estimation of the DF&RM system performance, context conformity, and distributed DF&RM consistency measures both internal and external to the baseline DF&RM system. At each fusion level the DF node is designed to perform: data preparation, data association, and state estimation. This decomposition of the data driven decision support problem into fusion levels and corresponding nodes allows relatively constrained and low-risk development of each processing step in a loosely coupled manner, where many of the nodes in the fusion node network can be used and tested independently. The DNN technical architecture engineering guidelines provide for building the SSA capability as process flows of fusion and management node networks. These process flows cleanly map onto services composing a Service Oriented Architecture (SOA) as described in the STP quoted above. At the output side, modular visualization UDOP components can provide graphical user interfaces. These modular services and components will provide reusable building blocks for supporting a more agile enterprise for rapid, cost-effective development of SSA mission capabilities. The SOA building-block approach to constructing mission-specific applications is conducive to the spiral development approach providing iterative, agile, incremental development to achieve SSA objective prototype systems. This work aimed to develop and demonstrate a data fusion application that could be used across multiple domains for higher level data fusion (primarily multiple source levels 1-3) to increase SSA and provide timely and highly summarized data driven decision support to analysts and operators.",data oriented architecture,326,not included
80fe80f3d7814239530ef2ce10428fb692f7e311,to_check,semantic_scholar,ECIS,2019-01-01,semantic_scholar,what is smart about services? breaking the bond between the smart product and the service,https://www.semanticscholar.org/paper/80fe80f3d7814239530ef2ce10428fb692f7e311,"While the conceptual delineation between conventional and smart products is rather conspicuous, the distinction between conventional services and their smart counterparts remains elusive. This study develops a conceptual framework for understanding the distinctive attributes of smart services and their relationship to smart products. In a systematic literature review of publications from top information systems outlets, 30 contributions holding relevant information on smart services are identified and subjected to content analysis. The analysis reveals a variety of different definitions and characterizations of smart services and relations to concepts like data-driven services and services associated to smart products and smart objects. These findings are used to examine artifacts developed in rather design-oriented papers to derive five dimensions that impact the level of smartness of services: richness of the data, the knowledge intensiveness of the engine for decision support, the level of sophistication of the outcome delivered to the service user(s), the architecture of the stakeholders, and the automation level of the service processes. Within this scope, the product can have four roles: sensor, computer, interface, or integrator. The paper concludes by identifying some gaps in the overall research landscape and provides directions for future research.",data oriented architecture,327,not included
1fd708d6427cb36ed304d964833d089cc3df7764,to_check,semantic_scholar,,1996-01-01,semantic_scholar,"foundations of intelligent systems : 9th international symposium, ismis '96, zakopane, poland, june 9-13, 1996 : proceedings",https://www.semanticscholar.org/paper/1fd708d6427cb36ed304d964833d089cc3df7764,"Putting objects to work on a massive scale.- Approximate and commonsense reasoning: From theory to practice.- Cooperative information systems engineering.- Towards a Worldwide Knowledge base extended abstract.- Data mining and knowledge discovery in business databases.- Learning composite concepts in description logics: A first step.- Comparison of conceptual graphs for modelling knowledge of multiple experts.- Semantical considerations for knowledge base updates.- Partial evaluation in Constraint Logic Programming.- The AQ17-DCI system for data-driven constructive induction and its application to the analysis of world economics.- Induction of classification rules from imperfect data.- Induction of expert system rules from databases based on rough set theory and Resampling methods.- Mining patterns at each scale in massive data.- On evolving intelligence.- Intelligent mutation rate control in canonical genetic algorithms.- A fine-grained parallel evolutionary program for concept induction.- Evolutionary exploration of search spaces.- Evolutionary computation: One project, many directions.- Signed formula logic programming: Operational semantics and applications (extended abstract).- Automating proofs of integrity constraints in situation calculus.- Towards programming in default logic.- A sound and complete fuzzy logic system using Zadeh's implication operator.- Meeting the deadline: On the formal specification of temporal deontic constraints.- Validity queries and completeness queries.- Explanation for Cooperative Information Systems.- Toward intelligent representation of database content.- Reducing information systems with uncertain attributes.- Object and dependency oriented programming in FLO.- Knowledge simplification.- A model-based approach to consistency-checking.- Resource-based vs. task-based approaches for scheduling problems.- A Fuzzy Behaviorist Approach to sensor-based robot control.- Knowledge-based fuzzy neural networks.- Coevolutionary game theoretic multi-agent systems.- Searching for features defined by hyperplanes.- Inductive database design.- Enhancing query processing of information systems.- Structuring and retrieval of the complex predicate arguments proper to the NKRL conceptual language.- On the handling of imperfect data in relational database systems from null values to possibility distributions.- Modified component valuations in Valuation Based systems as a way to optimize query processing.- Learning for decision making: The FRD approach and a comparative study.- The application of rough sets-based data mining technique to differential diagnosis of meningoenchepahlitis.- A rough set framework for data mining of prepositional default rules.- An empirical study on the incompetence of attribute selection criteria.- Locally finite, proper and complete operators for refining Datalog programs.- Forest fire management with Negoplan.- An architecture for a deductive Fuzzy Relational Database.- A multi-step process for discovering, managing and refining strong functional relations hidden in databases.- An architecture and methodology for the design and development of Technical Information Systems.- Explaining explanation closure.- PAC-learning logic programs under the closed-world assumption.- Planning, truth criteria and the systematic approach to action and change.- Automated inductive reasoning as a support of deductive reasoning in a user-independent automation of inductive theorem proving.- Semantic query optimization for bottom-up evaluation.- Dynamically changing behavior: An agent-oriented view to modeling intelligent information systems.- A multi-layer architecture for knowledge-based system synthesis.- MuRaLi: An architecture for multiple reasoning.- Heterogeneous view integration via sketches and equations.- DLAB: A declarative language bias formalism.- Knowledge discovery in databases and data mining.- Learning with noise in engineering domains.- Hierarchical conceptual clustering in a first order representation.- Rule discovery from databases with decision matrices.",data oriented architecture,328,not included
6cd96cedac9b77bebb3f5e8dbf5d76d1ac906971,to_check,semantic_scholar,,1990-01-01,semantic_scholar,"conpar 90 - vapp iv: joint international conference on vector and parallel processing, zurich, switzerland, september 10-13, 1990. proceedings",https://www.semanticscholar.org/paper/6cd96cedac9b77bebb3f5e8dbf5d76d1ac906971,"Digital electronics for 50 years: No limits to growth?.- Parallel computing : An Indian perspective.- POOMA, POOL and parallel symbolic computing: An assessment.- A decoupled data-driven architecture with vectors and macro actors.- A novel paradigm of parallel computation and its use to implement simple high performance hardware.- Presto: A bus-connected multiprocessor for a rete-based production system.- A model for performance prediction of message passing multiprocessors achieving concurrency by domain decomposition.- Workloads, observables, benchmarks and instrumentation.- A method for performance prediction of parallel programs.- Divide and conquer: A new parallel algorithm for the solution of a tridiagonal linear system of equations.- Sparse matrix algorithms for SUPRENUM.- Parallel givens factorization on a shared memory multiprocessor.- Study of a parallel inference machine for parallel execution of logic programs.- Parallel implementation of logic languages.- Prolog implementations on parallel computers.- Performance evaluation of parallel programs in parallel and distributed systems.- The ELAN performance analysis environment.- Monitoring and debugging Transputer-networks with NETMON-II.- An adaptive blocking strategy for matrix factorizations.- Factorizations of band matrices using level 3 BLAS.- On the computation of breeding values.- Code parallelization for the LGDG large-grain dataflow computation.- Development of portable parallel programs with large-grain data flow 2.- ADAM: a coarse-grain dataflow architecture that addresses the load balancing and throttling problems.- A latency tolerant code generation algorithm for a coarse grain dataflow machine.- Cedar Fortrand its compiler.- Optimizing communication in SUPERB.- A design of performance-optimized control-based synchronization.- Interprocess analysis and optimization in the equational language compiler.- Transputer based distributed cartographic image processing.- MPS-an experimental multi-microprocessor based parallel system.- Parallel implementation of the convolution method in image reconstruction.- SYDAMA II: A heterogeneous multiprocessor system for real time image processing.- Analysis and design of circuit switching interconnection networks using 4x4 nodes.- Design and simulation of a multistage interconnection network.- A reconfigurable interconnection network for flexible pipelining.- A fast distributed mapping algorithm.- A note on the load balancing problem for coarse grained hypercube dictionary machines.- Hierarchical wiring in multigrids.- Optimal data structures for an efficient vectorized finite element code.- FFTVPLIB, a collection of Fast Fourier transforms for vectorprocessors.- Improving the vector performance via algorithmic domain decomposition.- Implementation of parallel numerical routines using broadcast communication schemes.- A process and memory model for a parallel distributed-memory machine.- A deadlock free routing algorithm with network size independent buffering space.- From object-oriented programming to automatic load distribution.- Partitioning programs into processes.- An MIMD execution environment with a fixed number of processes.- Sorting large data files on POOMA.- Parallelizing divide-and-conquer algorithms - Microtasking versus autotasking.- The performance of linear algebra subprograms on the siemens S series.- A family of highly parallel computers.- A distributed shared memory multiprocessor kit with scalable local complexity.- Scalable cache coherence for large shared memory multiprocessors.- Design and implementation of an exception handling mechanism for communicating sequential processes.- Creating and controlling concurrency in object oriented systems - A case study -.- A distributed algorithm for dynamic task scheduling.- TeNOR++: A dynamic configurer for SuperNode machines.- Parallel modelling of electromagnetic field scattering: A new approach using the Edinburgh concurrent supercomputer facility.- 3D multigrid correction methods for Transputer networks.- A comparative study of two wavefront implementations of a LU solver algorithm.- Systolic array architecture for two-dimensional discrete Fourier transform.- Design and implementation of M1 Cellprocessor.- A comparison of microtasking implementations of the applicative language SISAL.- An efficient scheme for fine-grain software pipelining.- Sisal on a message passing architecture.- The TOPSYS architecture.- MMK - A distributed operating system kernel with integrated dynamic loadbalancing.- The distributed monitor system of TOPSYS.- Hybrid algorithms for the elgensolution of large sparse symmetric matrices on the AMT DAP 510.- Virtual systems architecture on the AMT DAP.- Numerical simulation of thermal convection on SIMD computers.- Massively parallel realization of logical operations in distributed parallel systems.- High-performance computer system ""Siberia"".- EDS hardware architecture.- Visualizing and analysing the runtime behavior of parallel programs.- PATOP for performance tuning of parallel programs.- Real-time visualization of concurrent processes.- Achieving superlinear speedups for the multiple polynomial quadratic sieve factoring algorithm on a distributed memory multiprocessor.- A performance analysis of network topologies in finding the roots of a polynomial.- Parallel multigrid algorithms for some specialized computer systems.- Computation race at CONPAR 90, VAPP IV ETH Zurich, Sep 10-13, 1990.",data oriented architecture,329,not included
