doi,type,publication,publisher,publication_date,database,title,url,abstract,domain,id
10.1109/iccda.2010.5540715,filtered,2010 International Conference On Computer Design and Applications,IEEE,2010-06-27 00:00:00,ieeexplore,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://ieeexplore.ieee.org/document/5540715/,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,1
10.1109/icacc.2010.5487131,filtered,2010 2nd International Conference on Advanced Computer Control,IEEE,2010-03-29 00:00:00,ieeexplore,data-oriented architecture of ln function,https://ieeexplore.ieee.org/document/5487131/,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,2
10.1109/icetc.2010.5529337,filtered,2010 2nd International Conference on Education Technology and Computer,IEEE,2010-06-24 00:00:00,ieeexplore,data-oriented architecture of sine,https://ieeexplore.ieee.org/document/5529337/,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,3
10.1109/icacte.2010.5579358,filtered,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),IEEE,2010-08-22 00:00:00,ieeexplore,data-oriented architecture of sine and cosine functions,https://ieeexplore.ieee.org/document/5579358/,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,4
10.1109/icepe.2014.6970070,filtered,2014 International Conference and Exposition on Electrical and Power Engineering (EPE),IEEE,2014-10-18 00:00:00,ieeexplore,domain specific languages in power systems engineering,https://ieeexplore.ieee.org/document/6970070/,"This paper proposes an information system for data mining that allows the specification of ad-hoc queries on a data warehouse, which contain historical information relative to exceptions (i.e., operating faults) recorded by a SCADA system in a power distribution network. The proposed application can be used by the power system engineers to explore the existent historical data, with no need for any “low level” programming expertise. The data-oriented architecture of the system provides important advantages related to application development and system maintainability.",data oriented architecture,5
10.1109/cse.2014.128,filtered,2014 IEEE 17th International Conference on Computational Science and Engineering,IEEE,2014-12-21 00:00:00,ieeexplore,exploring the benefits of introducing network coding into named data networking,https://ieeexplore.ieee.org/document/7023638/,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,6
10.1109/icmss.2010.5577074,filtered,2010 International Conference on Management and Service Science,IEEE,2010-08-26 00:00:00,ieeexplore,research of soa-based crm in telecommunications industry,https://ieeexplore.ieee.org/document/5577074/,"This paper first analyzes the architecture of the existing CRM in operators and its disadvantages. When operators integrate the 3G services into their business, it is necessary to propel their business support system shift from DOA (data-oriented architecture) to SOA (service-oriented architecture).Then an architecture of the CRM system based on SOA is presented. The paper finally takes an example of how to integrate the CRM and SFS based on SOA.",data oriented architecture,7
10.1109/lcomm.2016.2645768,filtered,IEEE Communications Letters,IEEE,2017-04-01 00:00:00,ieeexplore,broadcast-based content delivery in information-centric hybrid multihop wireless networks,https://ieeexplore.ieee.org/document/7801039/,"Information-centric networking is a “data-oriented” architecture for Future Internet. Since unicast routing cannot exploit the natural broadcast property of wireless networks and unicast paths may be broken down frequently due to node mobility, broadcast transmission is applied for content delivery in information-centric multihop wireless networks. It will face two key challenges: which nodes that receive the broadcasted packet should forward it, and how to avoid multiple nodes simultaneously transmitting it. In this letter, we solve these two issues by taking node mobility and available link capacity into account. A mobility-based forward node selection algorithm is proposed, which tends to select the less mobility nodes as the forward ones. An available link capacity-based forwarding scheme is proposed, which tends to select forward nodes with larger available link capacities to forward packets. Simulation results demonstrate the effectiveness of the proposed mechanism.",data oriented architecture,8
10.1007/978-981-15-5859-7_51,filtered,Proceedings of Fifth International Congress on Information and Communication Technology,Springer,2021-01-01 00:00:00,springer,preliminary study and implementation of chiang mai tourism platform based on dosa,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5859-7_51,"To cope with data complication systematically, a tourism platform is proposed through a newly-defined concept named Data Oriented Security Architecture or DOSA. The framework of DOSA shifts an attention from “Application” in a conventional method to “Data”. The main idea is to neutralize the numerously different sources of data into single entity called Data Register Center and strengthen the security of data by utilizing the public- and private-key encryption. Thus it could be simply adaptable to the varieties of applications and easily extensible to sustainable development. The advantages of DOSA include (1) maintainability of data ownership, (2) improvement in security and privacy, and (3) reduction in storage that, as a result, are suitable to modern application development. The application prototype is implemented in web application and piloted by a set of tourist destination in Chiang Mai. This work contains the implementation from Data Register Center in DOSA through the Tourism Service Platform. Although the sample does not include all features of the DOSA, the results are comprehensive and ready for the future extension and improvement.",data oriented architecture,9
http://arxiv.org/abs/1706.03968v2,filtered,arxiv,arxiv,2017-06-13 00:00:00,arxiv,asynchronous graph pattern matching on multiprocessor systems,http://arxiv.org/abs/1706.03968v2,"Pattern matching on large graphs is the foundation for a variety of
application domains. Strict latency requirements and continuously increasing
graph sizes demand the usage of highly parallel in-memory graph processing
engines that need to consider non-uniform memory access (NUMA) and concurrency
issues to scale up on modern multiprocessor systems. To tackle these aspects,
graph partitioning becomes increasingly important. Hence, we present a
technique to process graph pattern matching on NUMA systems in this paper. As a
scalable pattern matching processing infrastructure, we leverage a
data-oriented architecture that preserves data locality and minimizes
concurrency-related bottlenecks on NUMA systems. We show in detail, how graph
pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,10
,filtered,core,International Foundation for Telemetering,2008-10-01 00:00:00,core,a data-oriented software architecture for telemetry,,"ITC/USA 2008 Conference Proceedings / The Forty-Fourth Annual International Telemetering Conference and Technical Exhibition / October 27-30, 2008 / Town and Country Resort & Convention Center, San Diego, CaliforniaBuilding modern telemetry systems is fraught with challenges involving subsystem integration, the role and management of data, scalability issues, disparate technologies, concerns about cost-effectiveness and more. This article addresses today's challenges with a solution based on adopting a data-oriented architecture and relying on a standards-based, integrated high-performance middleware platform with standards-based programmable components. Key to the solution is integrating around the system information model instead of the application or technology infrastructure. A standards-based middleware infrastructure that breaks away from traditional assumptions is at the core of this approach. The article also presents successful applications of data-oriented architecture using standards-based middleware.International Foundation for TelemeteringProceedings from the International Telemetering Conference are made available by the International Foundation for Telemetering and the University of Arizona Libraries. Visit http://www.telemetry.org/index.php/contact-us if you have questions about items in this collection",data oriented architecture,11
10.15598/aeee.v19i4.4183,filtered,core,"'VSB Technical University of Ostrava, Faculty of Electrical Engineering and Computer Sciences'",2021-01-01 00:00:00,core,intelligent bearing fault diagnosis method based on hnr envelope and classification using supervised machine learning algorithms,https://core.ac.uk/download/490710719.pdf,"Research on data-driven bearing fault diagnosis techniques has recently drawn more and more attention due to the availability of massive condition monitoring data. The research work presented in this paper aims to develop an architecture for the detection and diagnosis of bearing faults in the induction machines. The developed data-oriented architecture uses vibration signals collected by sensors placed on the machine, which is based, in the first place, on the extraction of fault indicators based on the harmonics-to-noise ratio envelope. Normalisation is then applied to the extracted indicators to create a well-processed data set. The evolution of these indicators will be studied afterwards according to the type and severity of defects using sequential backward selection technique. Supervised machine learning classification methods are developed to classify the measurements described by the feature vector with respect to the known modes of operation. In the last phase concerning decision making, ten classifiers are tested and applied based on the selected and combined indicators. The developed classification methods allow classifying the observations, with respect to the different modes of bearing condition (outer race, inner race fault or healthy condition). The proposed method is validated on data collected using an experimental bearing test bench. The experimental results indicate that the proposed architecture achieves high accuracy in bearing fault detection under all operational conditions. The results show that, compared to some proposed approaches, our proposed architecture can achieve better performance overall in terms of the number of optimal features and the accuracy of the tests",data oriented architecture,12
10.3390/electronics10151810,filtered,core,'MDPI AG',2021-07-01 00:00:00,core,on-board data management layer: connected vehicle as data platform,,"For connected vehicles, as well as generally for the transportation sector, data are now seen as a precious resource. They can be used to make right decisions, improve road safety, reduce CO2 emissions, or optimize processes. However, analyzing these data is not so much a question of which technologies to use, but rather about where these data are analyzed. Thereby, the emerging vehicle architecture has to become a data-oriented architecture based on embedded computing platforms and take into account new applications, artificial intelligence elements, advanced analytics, and operating systems. Accordingly, in this paper, we introduce the concept of data management to the vehicle by proposing an on-board data management layer, so that the vehicle can play the role of data platform capable of storing, processing, and diffusing data. Our proposed layer supports analytics and data science to deliver additional value from the connected vehicle data and stimulate the development of new services. In addition, our data platform can also form or contribute to shaping the backbone of data-driven transport. An on-board platform was built where the dataset size was reduced 80% and a rate of 99% accuracy was achieved in a 5 min traffic flow prediction using artificial neural networks (ANNs)",data oriented architecture,13
10.3844/jcssp.2014.469.476,filtered,core,Science Publications,2014-01-01 00:00:00,core,a novel architectural framework for aggregated subscriber profile,https://core.ac.uk/download/pdf/25810838.pdf,"Subscriber/User&rsquo;s data in a Communication Service Provider&rsquo;s (CSP) Environment spread across different &ldquo;silo type&rdquo; Network Elements (subscriber data sources) and systems such as Customer Relationship Management System (CRM), Home Location Register/Visitor Location Register (HLR/VLR), Home Subscriber Server (HSS), Policy Charging Rules Function (PCRF), Business Support System/Operation Support System (BSS/OSS). The proliferation of convergent telecom applications and value added services necessitates CSPs to be equipped with unified subscriber data management systems to enable Application Service Providers and Enterprises to build and offer subscriber oriented applications and services. Rapid service development warrants the need for general inter-faces for subscriber data access rather than multiple traditional data access interfaces and associated complexities. The Proposed Aggregated Subscriber Profile Architectural Framework abstracts the Network Elements and integration complexities by providing aggregated profile to 3rd party applications. The proposed Architectural Framework is based on Data Oriented Architecture (DOA), Service Oriented Architecture principles. Proof of concept implementation details along with performance results for a typical aggregated data model defined based on previous experiences, discussed",data oriented architecture,14
10.1007/978-3-642-45249-9_36,filtered,core,'Springer Science and Business Media LLC',2014-01-04 00:00:00,core,towards a new internetworking architecture: a new deployment approach for information centric networks,,"International audienceNew research efforts are trying to evolve the current Inter-net. With satisfying communication hardware, the intent is to switch to data oriented networks. In this new vision, data will be the heart of the architecture and protocols have to be changed to dial with this concept. Promising ideas are proposed up in order to develop clean slate design solutions. However, these propositions encounter many deployment problems. In this paper, we propose new approach based on Bloom Filter to cope with storage space problem in data oriented architecture DONA",data oriented architecture,15
10.1109/hoticn50779.2020.9350821,filtered,2020 3rd International Conference on Hot Information-Centric Networking (HotICN),IEEE,2020-12-14 00:00:00,ieeexplore,hierarchical identity-based security mechanism using blockchain in named data networking,https://ieeexplore.ieee.org/document/9350821/,"Named Data Networking (NDN) with the data-centric design has been viewed as a promising future Internet architecture. It requires a new security model orienting data but not host. In this paper, a Hierarchical Identity-based Security Mechanism by Blockchain (HISM-B) is to be proposed for NDN networks. It could satisfy the two assumptions specified in the NDN testbed to maintain the data-oriented authentication. At one hand, the hierarchical identity-based cryptology is used to bind the data name with the public key and then two signatures are encapsulated in the data packet so that the data source authentication and the integrity of data packet can be supported. At the other hand, a blockchain is employed to manage public keys for different domains to avoid catastrophes due to a single node failure. The validation result shows that the proposed HISM-B is safe.",data centric architecture,16
0d54509265f99423027d6348b106ff0fe58b64b6,filtered,semantic_scholar,SCREAM@HPDC,2015-01-01,semantic_scholar,data centric discovery with a data-oriented architecture,https://www.semanticscholar.org/paper/0d54509265f99423027d6348b106ff0fe58b64b6,"Increasingly, scientific discovery is driven by the analysis, manipulation, organization, annotation, sharing, and reuse of high-value scientific data. While great attention has been given to the specifics of analyzing and mining data, we find that there are almost no tools nor systematic infrastructure to facilitate the process of discovery from data. We argue that a more systematic perspective is required, and in particular, propose a data-centric approach in which discovery stands on a foundation of data and data collections, rather than on fleeting transformations and operations. To address the challenges of data-centric discovery, we introduce a Data-Oriented Architecture and contrast it with the prevalent Service-Oriented Architecture. We describe an instance of the Data-Oriented Architecture and describe how it has been used in a variety of use cases.",data oriented architecture,17
987f1feddb599eac1c924ce5dc39f9c57e93d5e0,filtered,semantic_scholar,,2012-01-01,semantic_scholar,data-oriented architecture for system integration,https://www.semanticscholar.org/paper/987f1feddb599eac1c924ce5dc39f9c57e93d5e0,"According to the problem that,in the process of integrating large-scale distributed system,the subsystems are difficult to manage,extend,and maintenance,which caused by their different implementation technologies and tightly-coupled design.A pattern of data-oriented design is introduced,and the principle based on the pattern and the related middleware technology were discussed.A data-oriented architecture for system integration was proposed.Finally,based on the example of a real-time package tracking system-of-systems,the architecture of data-oriented integration was discussed in detail.",data oriented architecture,18
b671e6b6ad4b5cb346f19414c709f78e862da379,filtered,semantic_scholar,2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),2019-01-01,semantic_scholar,uav-gcs centralized data-oriented communication architecture for crowd surveillance applications,https://www.semanticscholar.org/paper/b671e6b6ad4b5cb346f19414c709f78e862da379,"In recent years, a large number of researchers investigate the conception of systems that use a unique Unmanned Ariel Vehicles (UAV) or multiple independent UAVs to conduct civil or military missions, with minimal human intervention. In this paper we focus on using multiple UAVs to cooperatively monitor a crowded area. Communication in such UAVs network is an ongoing project. Due to the lack of proper communication standards and rules, designing a reliable communication model is essential for: (i) multi-UAV coordination, (ii) efficient bandwidth sharing according to data priority and urgency and (iii) avoiding useless transmission of the same data by multiple UAVs. To address the above challenges, we propose a centralized data-oriented communication architecture for crowd surveillance allocations using an UAV fleet. The Ground Control Station (GCS) is used as a central coordinator to manage bandwidth usage for the UAV fleet in its coverage area. To allow UAVs to send priority messages urgently to the GCS, we define two classes of urgent messages: critical state and important result. The class of the data as well as other relevant information about the detected event will be used by the GCS to authorize or not UAV data transmission and hence to optimize the bandwidth usage efficiency.",data oriented architecture,19
6d5165205564bc98c1afcf20a1652a21f1e3e61e,filtered,semantic_scholar,,2007-01-01,semantic_scholar,data-oriented architecture: a loosely-coupled real-time soa,https://www.semanticscholar.org/paper/6d5165205564bc98c1afcf20a1652a21f1e3e61e,"2007 August "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,20
9fc03132540aa5d53f50b875bb4ccb620dee09ea,filtered,semantic_scholar,,2007-01-01,semantic_scholar,data-oriented architecture,https://www.semanticscholar.org/paper/9fc03132540aa5d53f50b875bb4ccb620dee09ea,"2007 January "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,21
f7946ea31a3da644fd59303be9fff721579987fd,filtered,semantic_scholar,IEEE Internet of Things Journal,2017-01-01,semantic_scholar,a data-oriented m2m messaging mechanism for industrial iot applications,https://www.semanticscholar.org/paper/f7946ea31a3da644fd59303be9fff721579987fd,"Machine-to-machine (M2M) communication is a key enabling technology for the future industrial Internet of Things applications. It plays an important role in the connectivity and integration of computerized machines, such as sensors, actuators, controllers, and robots. The requirements in flexibility, efficiency, and cross-platform compatibility of the intermodule communication between the connected machines raise challenges for the M2M messaging mechanism toward ubiquitous data access and events notification. This investigation determines the challenges facing the M2M communication of industrial systems and presents a data-oriented M2M messaging mechanism based on ZeroMQ for the ubiquitous data access in rich sensing pervasive industrial applications. To prove the feasibility of the proposed solution, the EU funded PickNPack production line with a reference industrial network architecture is presented, and the communication between a microwave sensor device and the quality assessment and sensing module controller of the PickNPack line is illustrated as a case study. The evaluation is carried out through qualitative analysis and experimental studies, and the results demonstrate the feasibility of the proposed messaging mechanism. Due to the flexibility in dealing with hierarchical system architecture and cross-platform heterogeneity of industrial applications, this messaging mechanism deserves extensive investigations and further evaluations.",data oriented architecture,22
86cd3e57dd5d31c025543d96dc271da365d61a90,filtered,semantic_scholar,SIGCOMM,2007-01-01,semantic_scholar,a data-oriented (and beyond) network architecture,https://www.semanticscholar.org/paper/86cd3e57dd5d31c025543d96dc271da365d61a90,"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, we propose the Data-Oriented Network Architecture (DONA), which involves a clean-slate redesign of Internet naming and name resolution.",data oriented architecture,23
d0bdc150887cfca9e8ee50db6e2f17d7c08520bc,filtered,semantic_scholar,ReArch '09,2009-01-01,semantic_scholar,lanes: an inter-domain data-oriented routing architecture,https://www.semanticscholar.org/paper/d0bdc150887cfca9e8ee50db6e2f17d7c08520bc,"Data-oriented networking has attracted research recently, but the efficiency of the state-of-the-art solutions can still be improved. Our work towards this goal is set in a clean-slate architecture consisting of modular rendezvous, routing, and forwarding functions. In this paper we present the interdomain routing layer and its interplay with the other components of the system. The proposed system is built around two types of nodes: forwarding nodes and branching nodes. The forwarding nodes are optimized for throughput with no per-subscription state and no need to change passing packets, while branching nodes contain a large memory for caching and can make complex routing decisions. The amount of storage space and bandwidth can be independently scaled to suit the needs of each network. In the background, topology nodes perform load-balancing and configure routes in each domain using a two-dimensional addressing mechanism. The paths taken by packets adapt to the number of active subscribers to keep the amount of in-network state and latency low. A new data-oriented congestion control scheme is introduced, which takes into account the use of storage resources on-path and is fair to multicast flows.",data oriented architecture,24
b0e0e1172296a6da7de25aa40f51cce9614ae8fc,filtered,semantic_scholar,,2015-01-01,semantic_scholar,allocation strategies for data-oriented architectures,https://www.semanticscholar.org/paper/b0e0e1172296a6da7de25aa40f51cce9614ae8fc,"Data orientation is a common design principle in distributed data management systems. In contrast to process-oriented or transaction-oriented system designs, dataoriented architectures are based on data locality and function shipping. The tight coupling of data and processing thereon is implemented in different systems in a variety of application scenarios such as data analysis, database-as-a-service, and data management on multiprocessor systems. Data-oriented systems, i.e., systems that implement a data-oriented architecture, bundle data and operations together in tasks which are processed locally on the nodes of the distributed system. Allocation strategies, i.e., methods that decide the mapping from tasks to nodes, are core components in data-oriented systems. Good allocation strategies can lead to balanced systems while bad allocation strategies cause skew in the load and therefore suboptimal application performance and infrastructure utilization. Optimal allocation strategies are hard to find given the complexity of the systems, the complicated interactions of tasks, and the huge solution space. To ensure the scalability of dataoriented systems and to keep them manageable with hundreds of thousands of tasks, thousands of nodes, and dynamic workloads, fast and reliable allocation strategies are mandatory. In this thesis, we develop novel allocation strategies for data-oriented systems based on graph partitioning algorithms. Therefore, we show that systems from different application scenarios with different abstraction levels can be generalized to generic infrastructure and workload descriptions. We use weighted graph representations to model infrastructures with bounded and unbounded, i.e., overcommited, resources and possibly non-linear performance characteristics. Based on our generalized infrastructure and workload model, we formalize the allocation problem, which seeks valid and balanced allocations that minimize communication. Our allocation strategies partition the workload graph using solution heuristics that work with single and multiple vertex weights. Novel extensions to these solution heuristics can be used to balance penalized and secondary graph partition weights. These extensions enable the allocation strategies to handle infrastructures with non-linear performance behavior. On top of the basic algorithms, we propose methods to incorporate heterogeneous infrastructures and to react to changing workloads and infrastructures by incrementally updating the partitioning. We evaluate all components of our allocation strategy algorithms and show their applicability and scalability with synthetic workload graphs. In end-to-end– performance experiments in two actual data-oriented systems, a database-as-aservice system and a database management system for multiprocessor systems, we prove that our allocation strategies outperform alternative state-of-the-art methods.",data oriented architecture,25
d202d37f5d90cb7fbb7dff2d454fcad944a3176e,filtered,semantic_scholar,GeoInfo,2005-01-01,semantic_scholar,local spatial data infrastructures based on a service-oriented architecture,https://www.semanticscholar.org/paper/d202d37f5d90cb7fbb7dff2d454fcad944a3176e,"Sharing geographic information is an essential activity which has been sought since the early days of GIS, mostly due to the cost of information collection and maintenance. Having once depended on the establishment of data transfer standards, sharing initiatives gradually evolved towards the creation of clearinghouses, Web resources that centralize links to various GI sources, but are still data-oriented. The current focus on spatial data infrastructures changes that, by establishing a service-oriented view, thus allowing for the creation of shared, distributed, and interoperable environments through Web services. This paper explores, in a preliminary fashion, such an architecture as applied to distributed geographic applications, focusing on the potential for local services and local uses, and proposing specialized services deemed essential for urban-scale applications.",data oriented architecture,26
b51a5d61dc40f45443ae3995490679d4f96a1383,filtered,semantic_scholar,SIGMOD '11,2011-01-01,semantic_scholar,a data-oriented transaction execution engine and supporting tools,https://www.semanticscholar.org/paper/b51a5d61dc40f45443ae3995490679d4f96a1383,"Conventional OLTP systems assign each transaction to a worker thread and that thread accesses data, depending on what the transaction dictates. This thread-to-transaction work assignment policy leads to unpredictable accesses. The unpredictability forces each thread to enter a large number of critical sections for the completion of even the simplest of the transactions; leading to poor performance and scalability on modern manycore hardware.
 This demonstration highlights the chaotic access patterns of conventional OLTP designs which are the source of scalability problems. Then, it presents a working prototype of a transaction processing engine that follows a non-conventional architecture, called data-oriented or DORA. DORA is designed around the thread-to-data work assignment policy. It distributes the transaction execution to multiple threads and offers predictable accesses. By design, DORA can decentralize the lock management service, and thereby eliminate the critical sections executed inside the lock manager. We explain the design of the system and show that it more efficiently utilizes the abundant processing power of modern hardware, always contrasting it against the conventional execution. In addition, we present different components of the system, such as a dynamic load balancer. Finally, we present a set of tools that enable the development of applications that use DORA.",data oriented architecture,27
bd6d3585fea44c2812e16047fcb28d38ae438682,filtered,semantic_scholar,IEEE Communications Surveys & Tutorials,2016-01-01,semantic_scholar,control-data separation architecture for cellular radio access networks: a survey and outlook,https://www.semanticscholar.org/paper/bd6d3585fea44c2812e16047fcb28d38ae438682,"Conventional cellular systems are designed to ensure ubiquitous coverage with an always present wireless channel irrespective of the spatial and temporal demand of service. This approach raises several problems due to the tight coupling between network and data access points, as well as the paradigm shift towards data-oriented services, heterogeneous deployments and network densification. A logical separation between control and data planes is seen as a promising solution that could overcome these issues, by providing data services under the umbrella of a coverage layer. This article presents a holistic survey of existing literature on the control-data separation architecture (CDSA) for cellular radio access networks. As a starting point, we discuss the fundamentals, concepts, and general structure of the CDSA. Then, we point out limitations of the conventional architecture in futuristic deployment scenarios. In addition, we present and critically discuss the work that has been done to investigate potential benefits of the CDSA, as well as its technical challenges and enabling technologies. Finally, an overview of standardisation proposals related to this research vision is provided.",data oriented architecture,28
bd5fafd1cb584bdfbd39a6f768b5c8c1954e4474,filtered,semantic_scholar,,2004-01-01,semantic_scholar,data-oriented belief revision : towards a unified theory of epistemic processing,https://www.semanticscholar.org/paper/bd5fafd1cb584bdfbd39a6f768b5c8c1954e4474,"Building on a long research tradition (cf. 1), this paper proposes to apply the distinction between data (information stored in the agent’s mind) and beliefs (information accepted as reliable) to belief revision modeling (cf. 2), in order to integrate belief change in the overall epistemic processing of the agent. As a result, a more comprehensive and complex model of epistemic dynamics is formally described, christened as Data-oriented Belief Revision (DBR), and compared on the ground of expressive power with the underlying conceptual architecture of standard models of belief change (cf. 3). Some computational features of DBR are further discussed in 4, with special reference to information update, data structures, the assessment of data properties, and belief selection. Finally, preliminary results and future developments of DBR are assessed in 5.",data oriented architecture,29
0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,filtered,semantic_scholar,J. Database Manag.,2001-01-01,semantic_scholar,a metadata oriented architecture for building datawarehouse,https://www.semanticscholar.org/paper/0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,"Data warehouse is an intelligent store of data that can aggregate vast amounts of information. A metadata is critical for implementing data warehouse. Therefore, integrating data warehouse with its metadata offers a new opportunity to create a more adaptive information system. This paper proposes a metadata-oriented data warehouse architecture that consists of seven components: legacy system, extracting software, operational data store, data warehouse, data mart, application, and metadata. A taxonomy for dataflow and metaflow is proposed for better understanding of the architecture. In addition, a metadata schema is built within the framework of the seven components. The architecture with its metadata component is applied to a real-life data warehouse for a large medical center in order to illustrate its practical usefulness.",data oriented architecture,30
a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,filtered,semantic_scholar,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019-01-01,semantic_scholar,auto-fpn: automatic network architecture adaptation for object detection beyond classification,https://www.semanticscholar.org/paper/a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,"Abstract Neural architecture search (NAS) has shown great potential in automating the manual process of designing a good CNN architecture for image classification. In this paper, we study NAS for object detection, a core computer vision task that classifies and localizes object instances in an image. Existing works focus on transferring the searched architecture from classification task (ImageNet) to the detector backbone, while the rest of the architecture of the detector remains unchanged. However, this pipeline is not task-specific or data-oriented network search which cannot guarantee optimal adaptation to any dataset. Therefore, we propose an architecture search framework named Auto-FPN specifically designed for detection beyond simply searching a classification backbone. Specifically, we propose two auto search modules for detection: Auto-fusion to search a better fusion of the multi-level features; Auto-head to search a better structure for classification and bounding-box(bbox) regression. Instead of searching for one repeatable cell structure, we relax the constraint and allow different cells. The search space of both modules covers many popular designs of detectors and allows efficient gradient-based architecture search with resource constraint (2 days for COCO on 8 GPU cards). Extensive experiments on Pascal VOC, COCO, BDD, VisualGenome and ADE demonstrate the effectiveness of the proposed method, e.g. achieving around 5% improvement than FPN in terms of mAP while requiring around 50% fewer parameters on the searched modules.",data oriented architecture,31
a323992739aaa0e477c206fdcad9f7cb87139360,filtered,semantic_scholar,IEEE Transactions on Nanotechnology,2015-01-01,semantic_scholar,an energy-efficient nonvolatile in-memory computing architecture for extreme learning machine by domain-wall nanowire devices,https://www.semanticscholar.org/paper/a323992739aaa0e477c206fdcad9f7cb87139360,"The data-oriented applications have introduced increased demands on memory capacity and bandwidth, which raises the need to rethink the architecture of the current computing platforms. The logic-in-memory architecture is highly promising as future logic-memory integration paradigm for high throughput data-driven applications. From memory technology aspect, as one recently introduced nonvolatile memory device, domain-wall nanowire (or race-track) not only shows potential as future power efficient memory, but also computing capacity by its unique physics of spintronics. This paper explores a novel distributed in-memory computing architecture where most logic functions are executed within the memory, which significantly alleviates the bandwidth congestion issue and improves the energy efficiency. The proposed distributed in-memory computing architecture is purely built by domain-wall nanowire, i.e., both memory and logic are implemented by domain-wall nanowire devices. As a case study, neural network-based image resolution enhancement algorithm, called DW-NN, is examined within the proposed architecture. We show that all operations involved in machine learning on neural network can be mapped to a logic-in-memory architecture by nonvolatile domain-wall nanowire. Domain-wall nanowire-based logic is customized for in machine learning within image data storage. As such, both neural network training and processing can be performed locally within the memory. The experimental results show that the domain-wall memory can reduce 92% leakage power and 16% dynamic power compared to main memory implemented by DRAM; and domain-wall logic can reduce 31% both dynamic and 65% leakage power under the similar performance compared to CMOS transistor-based logic. And system throughput in DW-NN is improved by 11.6x and the energy efficiency is improved by 56x when compared to conventional image processing system.",data oriented architecture,32
e7eacfd126dfe09f26fbac0f52cd290bb6684c43,filtered,semantic_scholar,MidSens '12,2012-01-01,semantic_scholar,enabling the usage of sensor networks with service-oriented architectures,https://www.semanticscholar.org/paper/e7eacfd126dfe09f26fbac0f52cd290bb6684c43,"Closing the gap between device-oriented sensor networks and data-oriented applications is a serious challenge. We present a novel platform which enables the seamless integration of sensor networks with a Service-Oriented Architecture approach. The platform hides the device-specific details from the applications and transforms data into a device-independent format. Thereby the system provides a mechanism to create a variety of end-user applications on top of the platform, which are independent from the device-specific details. We present an in-depth description of the architecture of our platform, and a full implementation and evaluation of it in a residential energy management setting.",data oriented architecture,33
e0b54bc395fccf323645a4839d04b646431eb369,filtered,semantic_scholar,IEEE Transactions on Circuits and Systems II: Express Briefs,2015-01-01,semantic_scholar,a fast integral image computing hardware architecture with high power and area efficiency,https://www.semanticscholar.org/paper/e0b54bc395fccf323645a4839d04b646431eb369,"Integral image computing is an important part of many vision applications and is characterized by intensive computation and frequent memory accessing. This brief proposes an approach for fast integral image computing with high area and power efficiency. For the data flow of the integral image computation a dual-direction data-oriented integral image computing mechanism is proposed to improve the processing efficiency, and then a pipelined parallel architecture is designed to support this mechanism. The parallelism and time complexity of the approach are analyzed and the hardware implementation cost of the proposed architecture is also presented. Compared with the state-of-the-art methods this architecture achieves the highest processing speed with comparatively low logic resources and power consumption.",data oriented architecture,34
a312fd2a6feffb5bd907a08548a359f071b1e2fe,filtered,semantic_scholar,SIGCOMM '09,2009-01-01,semantic_scholar,lipsin: line speed publish/subscribe inter-networking,https://www.semanticscholar.org/paper/a312fd2a6feffb5bd907a08548a359f071b1e2fe,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.
 In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.",data oriented architecture,35
501c680ea3bf5e809dd8f23fd5dc17d3f8ec0ac0,filtered,semantic_scholar,NDM '15,2015-01-01,semantic_scholar,managing scientific data with named data networking,https://www.semanticscholar.org/paper/501c680ea3bf5e809dd8f23fd5dc17d3f8ec0ac0,"Many scientific domains, such as climate science and High Energy Physics (HEP), have data management requirements that are not well supported by the IP network architecture. Named Data Networking (NDN) is a new network architecture whose service model is better aligned with the needs of data-oriented applications. NDN provides features such as best-location retrieval, caching, load sharing, and transparent failover that would otherwise be painstakingly (re-)implemented by each application using point-to-point semantics in an IP network.
 We present the first scientific data management application designed and implemented on top of NDN. We use this application to manage climate and HEP data over a dedicated, high-performance, testbed. Our application has two main components: a UI for dataset discovery queries and a federation of synchronized name catalogs. We show how NDN primitives can be used to implement common data management operations such as publishing, search, efficient retrieval, and publication access control.",data oriented architecture,36
d0a79dba16d373cf34550ded37f624f0c0615b47,filtered,semantic_scholar,Int. J. Data Warehous. Min.,2016-01-01,semantic_scholar,modeling and evaluating the effects of big data storage resource allocation in global scale cloud architectures,https://www.semanticscholar.org/paper/d0a79dba16d373cf34550ded37f624f0c0615b47,"The availability of powerful, worldwide span computing facilities offering application scalability by means of cloud infrastructures perfectly matches the needs for resources that characterize Big Data applications. Elasticity of resources in the cloud enables application providers to achieve results in terms of complexity, performance and availability that were considered beyond affordability, by means of proper resource management techniques and a savvy design of the underlying architecture and of communication facilities. This paper presents an evaluation technique for the combined effects of cloud elasticity and Big Data oriented data management layer on global scale cloud applications, by modeling the behavior of both typical in memory and in storage data management.",data oriented architecture,37
70e6fa53b806b17d603bdc7d47a7d615d7834670,filtered,semantic_scholar,2011 IEEE Third International Conference on Cloud Computing Technology and Science,2011-01-01,semantic_scholar,a cloud environment for data-intensive storage services,https://www.semanticscholar.org/paper/70e6fa53b806b17d603bdc7d47a7d615d7834670,"The emergence of cloud environments has made feasible the delivery of Internet-scale services by addressing a number of challenges such as live migration, fault tolerance and quality of service. However, current approaches do not tackle key issues related to cloud storage, which are of increasing importance given the enormous amount of data being produced in today's rich digital environment (e.g. by smart phones, social networks, sensors, user generated content). In this paper we present the architecture of a scalable and flexible cloud environment addressing the challenge of providing data-intensive storage cloud services through raising the abstraction level of storage, enabling data mobility across providers, allowing computational and content-centric access to storage and deploying new data-oriented mechanisms for QoS and security guarantees. We also demonstrate the added value and effectiveness of the proposed architecture through two real-life application scenarios from the healthcare and media domains.",data oriented architecture,38
c7f42b0f6dc0e7f593035327822dafe6c5605e4a,filtered,semantic_scholar,CoNEXT '08,2008-01-01,semantic_scholar,towards a new generation of information-oriented internetworking architectures,https://www.semanticscholar.org/paper/c7f42b0f6dc0e7f593035327822dafe6c5605e4a,"In response to the limitations of the Internet architecture when used for applications for which it was not originally designed, a series of clean slate efforts have emerged to shape the so-called future Internet. Recently, visionary voices have advised a shift in the networking problem under research, moving from seamless host-reachability to internetworking of information. We contribute to the healthy debate on future Internet design and discuss ongoing information oriented efforts. Inspired by recent works in Bloom-filterlike data structures, we propose the SPSwitch as a novel switching engine to make wire speed forwarding decisions on flat information labels. We address part of the scalability issues in a data-oriented forwarding layer by trading overdeliveries for state reduction and line speed operations.",data oriented architecture,39
bb4b9316c514860dbfd54bbd50baec757e37b83d,filtered,semantic_scholar,,2012-01-01,semantic_scholar,data as a service (daas) in cloud computing,https://www.semanticscholar.org/paper/bb4b9316c514860dbfd54bbd50baec757e37b83d,"Data has become the enabling technology for many of the recent innovations. ""More data trumps smarter algorithms"" has been the mantra behind this revolution in computing. Given the rate at which the data is produced, there is need for scalable solutions to extract information out of them. Allowing the data to be stored in the cloud and be accessed without geographical and scalability limitations will remove many bottlenecks in bringing data-oriented innovations. Current cloud architecture solves the issues of accessibility and scalability, but poses several new challenges such as automatic management of the service, pricing the data, and security of the data. This talk will include several techniques to address these challenges using automatic physical design, servicebased pricing, and cryptographic mechanisms. Data Information Knowledge Intelligence.",data oriented architecture,40
6c4fca03bf42a507fcf0ef437d89a6e9f9c12b90,filtered,semantic_scholar,The IEEE symposium on Computers and Communications,2010-01-01,semantic_scholar,roles and security in a publish/subscribe network architecture,https://www.semanticscholar.org/paper/6c4fca03bf42a507fcf0ef437d89a6e9f9c12b90,"Several publish/subscribe (pub/sub) and data-oriented networking proposals have been presented to overcome limitations of the current message- and host-centric Internet. However, security issues of these solutions have not been addressed comprehensively. In this paper we examine roles of actors comprising an inter-domain pub/sub network, together with security requirements and minimal required trust associations arising from this setting. We then introduce and analyze a security design for a clean-slate pub/sub network architecture that secures both the control and data planes. The solution addresses availability and data integrity while remaining scalable and usable.",data oriented architecture,41
78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,filtered,semantic_scholar,IEEE Communications Magazine,2013-01-01,semantic_scholar,on functionality separation for green mobile networks: concept study over lte,https://www.semanticscholar.org/paper/78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,"Traditional wireless networks are designed for ubiquitous network access provision with low-rate voice services, which thus preserve the homogeneous architecture and tight coupling for infrastructures such as base stations. With the traffic explosion and the paradigm shift from voice-oriented services to data-oriented services, traditional homogeneous architecture no longer maintains its optimality, and heterogeneous deployment with flexible network control capability becomes a promising evolution direction. To achieve this goal, in this article, we propose a two-layer network functionality separation scheme, targeting at low control signaling overhead and flexible network reconfiguration for future mobile networks. The proposed scheme is shown to support all kinds of user activities defined in current networks. Moreover, we give two examples to illustrate how the proposed scheme can be applied to multicarrier networks and suggest two important design principles for future green networks. Numerical results show that the proposed scheme achieves significant energy reduction over traditional LTE networks, and can be recommended as a candidate solution for future green mobile networks.",data oriented architecture,42
4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,filtered,semantic_scholar,IEEE Transactions on Industrial Electronics,2015-01-01,semantic_scholar,design and optimization of multiclocked embedded systems using formal techniques,https://www.semanticscholar.org/paper/4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,"Today's system-on-chip and distributed systems are commonly equipped with multiple clocks. The key challenge in designing such systems is that two situations have to be captured and evaluated in a single framework. The first is the heterogeneous control-oriented and data-oriented behaviors within one clock domain, and the second is the asynchronous communications between two clock domains. In this paper, we propose to use timed automata and synchronous dataflow to model the dynamic behaviors of the multiclock train-control system, and a multiprocessor architecture for the implementation from our model to the real system. Data-oriented behaviors are captured by synchronous dataflow, control-oriented behaviors are captured by timed automata, and asynchronous communications of the interclock domain can be modeled as an interface timed automaton or a synchronous dataflow module. The behaviors of synchronous dataflow are interpreted by some equivalent timed automata to maintain the semantic consistency of the mixed model. Then, various functional properties that are important to guarantee the correctness of the system can be simulated and verified within the framework. We apply the framework to the design of a control system described in the standard IEC 61 375 and several bugs are detected. The bugs in the standard have been fixed, and the new version has been implemented and used in the real-world subway communication control system.",data oriented architecture,43
ec02fc78f7ec0d9cbef609f4386143eaa84d4ae5,filtered,semantic_scholar,ADMS@VLDB,2014-01-01,semantic_scholar,eris: a numa-aware in-memory storage engine for analytical workload,https://www.semanticscholar.org/paper/ec02fc78f7ec0d9cbef609f4386143eaa84d4ae5,"The ever-growing demand for more computing power forces hardware vendors to put an increasing number of multiprocessors into a single server system, which usually exhibits a non-uniform memory access (NUMA). In-memory database systems running on NUMA platforms face several issues such as the increased latency and the decreased bandwidth when accessing remote main memory. To cope with these NUMA-related issues, NUMA-awareness has to be considered as a major design principle for the fundamental architecture of a database system. In this paper we present ERIS, a NUMA-aware inmemory storage engine that is based on a data-oriented architecture. In contrast to existing approaches that focus on transactional workloads on a disk-based DBMS, ERIS aims at tera-scale analytical workloads that are executed entirely in main memory. ERIS uses an adaptive partitioning approach that exploits the topology of the underlying NUMA platform and significantly reduces NUMA-related issues. We evaluate ERIS on widespread standard server systems as well as on a system consisting of 64 multiprocessors and 512 cores. On these platforms, we achieve a more than linear speedup for index lookups and scalable parallel scan operations that are only limited by the available local bandwidth of the multiprocessor. Moreover, we measured a performance gain of up to 200% (index lookups) respectively 660% (column scans) in the memory-bound case compared to a NUMA-agnostic storage subsystem.",data oriented architecture,44
14fb54b6e2515274d82df8a3f15c77904ad66ddf,filtered,semantic_scholar,,1994-01-01,semantic_scholar,real-time communication in packet-switched networks,https://www.semanticscholar.org/paper/14fb54b6e2515274d82df8a3f15c77904ad66ddf,"The dramatically increased bandwidths and processing capabilities of future high-speed networks make possible many distributed real-time applications, such as sensor-based applications and multimedia services. Since these applications will have traffic characteristics and performance requirements that differ dramatically from those of current data-oriented applications, new communication network architectures, and protocols will be required. In this paper we discuss the performance requirements and traffic characteristics of various real-time applications, survey recent developments in the areas of network architecture and protocols for supporting real-time services, and develop frameworks in which these, and future, research efforts can be considered. >",data oriented architecture,45
9ea9411fa553275a9f3bc5b1467cebedd5c554a4,filtered,semantic_scholar,IEEE Commun. Mag.,1998-01-01,semantic_scholar,a programmable transport architecture with qos guarantees,https://www.semanticscholar.org/paper/9ea9411fa553275a9f3bc5b1467cebedd5c554a4,"The emergence of distributed multimedia applications exhibiting significantly more stringent quality of service requirements than conventional data-oriented applications calls for new transport protocols with different characteristics to coexist and be integrated within single applications. The different delivery requirements posed by these diverse multimedia applications often imply the need for highly customized protocol implementations. Hence, application developers are faced with the threat of code obsolescence caused by the development of even newer delivery techniques. We present an object-oriented transport architecture that allows for dynamically binding a variety of protocol stacks on a per-call basis. By binding protocol stacks together, the special needs of the application can be met without the need to rewrite the code. This differs significantly from the traditional transport architecture which assumes preinstalled transport protocol stacks that cannot be customized. To illustrate some of the advantages provided by the architecture, we describe the transport component of the first reference implementation of the 150 MPEG-4 Delivery Multimedia Integration Framework and demonstrate how quickly it was implemented in our framework.",data oriented architecture,46
5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,filtered,semantic_scholar,Information-Centric Networking,2010-01-01,semantic_scholar,a survey of information-centric networking (draft),https://www.semanticscholar.org/paper/5c7d2cc547427274d3d8bc60d56e0e1e80921cf6,"In this paper we compare and discuss some of the features and design choices 
of the 4WARD Networking of Information architecture (NetInf), PARC's Content Centric Networking(CCN), the Publish-Subscribe Internet Routing Paradigm (PSIRP), and the Data Oriented Network Architecture (DONA). All four projects take an information-centric approach to designing a future network architecture, where the information objects themselves are the primary focus rather than the network nodes.",data oriented architecture,47
1112c1cd0e7b0c96a1f5231bd1767603466d4300,filtered,semantic_scholar,CIDR,2006-01-01,semantic_scholar,turning cluster management into data management; a system overview,https://www.semanticscholar.org/paper/1112c1cd0e7b0c96a1f5231bd1767603466d4300,"This paper introduces the CondorJ2 cluster management system. Traditionally, cluster management systems such as Condor employ a process-oriented approach with little or no use of modern database system technology. In contrast, CondorJ2 employs a data-centric, 3-tier web-application architecture for all system functions (e.g., job submission, monitoring and scheduling; node configuration, monitoring and management, etc.) except for job execution. Employing a data-oriented approach allows the core challenge (i.e., managing and coordinating a large set of distributed computing resources) to be transformed from a relatively low-level systems problem into a more abstract, higher-level data management problem. Preliminary results suggest that CondorJ2’s use of standard 3-tier software represents a significant step forward to the design and implementation of large clusters (1,000 to 10,000 nodes).",data oriented architecture,48
f1d7ddb9bc63fee86bfece409732bd977899b254,filtered,semantic_scholar,CFI,2012-01-01,semantic_scholar,on adapting http protocol to content centric networking,https://www.semanticscholar.org/paper/f1d7ddb9bc63fee86bfece409732bd977899b254,"Designed around host-reachability, today's Internet architecture faces many limitations while serving content-oriented applications which generate most traffic load to the Internet. CCN (Content Centric Networking) [1] is one of the most important proposals for future Internet architecture, which aims to build a content/data oriented network to solve these limitations. On the other hand, HTTP is the most important protocol to deploy new services and applications on current TCP/IP-based Internet. In this paper, we attempt to run HTTP protocol on CCN and combine the two by stitching them semantically on their content-oriented features, such as content caching. We expect that this combination can be leveraged to build CCN testbed with real HTTP traffic which is vital to validation and redesigning of specific mechanisms of CCN and to finding a transition way of CCN in which great incentive is provided for service providers in the economic ecosystem of content distribution. We designed and implemented a HTTP-CCN gateway to transform HTTP request and HTTP response into CCN Interest and Data respectively. We illustrate how to semantically map HTTP caching to CCN caching, which is one of the most attractive properties of CCN. We also discuss how to achieve transparent caching with CCN and find out that it is nontrivial to achieve complete transparency of caching with CCN given no cooperation with CDNs and content providers.",data oriented architecture,49
96be97fc6ec58a35601ada2e353e17b1afa09335,filtered,semantic_scholar,IEEE J. Sel. Areas Commun.,2003-01-01,semantic_scholar,a summary of the hornet project: a next-generation metropolitan area network,https://www.semanticscholar.org/paper/96be97fc6ec58a35601ada2e353e17b1afa09335,"Metropolitan area networks are currently undergoing an evolution aimed at more efficiently transport of data-oriented traffic. However, the incoming generation of metro networks is based on conventional technology, which prevents them scaling cost-effectively to ultrahigh capacities. We have developed a new architecture and set of protocols for the next generation of metro networks. The architecture, named HORNET (hybrid optoelectronic ring network), is a packet-over-wavelength-division multiplexing ring network that utilizes fast-tunable packet transmitters and wavelength routing to enable it to scale cost-effectively to ultrahigh capacities. A control-channel-based media access control (MAC) protocol enables the network nodes to share the bandwidth of the network while preventing collisions. The MAC protocol is designed to transport variable-sized packets and to provide fairness control to all network end users. The efficiency and the fairness of the MAC protocol is demonstrated with custom-designed simulations. The implementation of the MAC protocol and the survivability of the network have been demonstrated in a laboratory experimental testbed. The article summarizes the accomplishments of the HORNET project, including the design, analysis, and demonstration of a metro architecture and a set of protocols. The HORNET architecture is an excellent candidate for next-generation high-capacity metro networks.",data oriented architecture,50
4587979e037cce59feb86f54411c25e949ec555d,filtered,semantic_scholar,2010 IEEE Second International Conference on Cloud Computing Technology and Science,2010-01-01,semantic_scholar,dynamic request allocation and scheduling for context aware applications subject to a percentile response time sla in a distributed cloud,https://www.semanticscholar.org/paper/4587979e037cce59feb86f54411c25e949ec555d,"We consider geographically distributed data centers forming a collectively managed cloud computing system, hosting multiple Service Oriented Architecture (SOA) based context aware applications, each subject to Service Level Agreements (SLA). The Service Level Agreements for each context aware application require the response time of a certain percentile of the input requests to be less than a specified value for a profit to be charged by the cloud provider. We present a novel approach of data-oriented dynamic service-request allocation with gi-FIFO scheduling, in each of the geographically distributed data centers, to globally increase the profit charged by the cloud computing system. Our evaluation shows that our dynamic scheme far outperforms the commonly deployed static allocation with either First in First Out (FIFO) or Weighted Round Robin (WRR) scheduling.",data oriented architecture,51
c3c4454f395c64144cb68ab310e0ef0d735f0abe,filtered,semantic_scholar,,2005-01-01,semantic_scholar,"bulletproof wireless security: gsm, umts, 802.11, and ad hoc security (communications engineering)",https://www.semanticscholar.org/paper/c3c4454f395c64144cb68ab310e0ef0d735f0abe,CH 1: Security and Cryptography CH 2: Network Security Protocols CH 3: Security and the Layered Architecture CH 4: Voice-Oriented Wireless Networks CH 5: Data-Oriented Wireless Networks CH 6: Security in Traditional Wireless Networks CH 7: Security in Wireless Local Area Networks CH 8: Security in Wireless Ad Hoc Networks,data oriented architecture,52
8cc03eadb1c418dd2b927fcb5a3717fad8982033,filtered,semantic_scholar,MIS Q.,2011-01-01,semantic_scholar,design and implementation of decision support systems in the public sector,https://www.semanticscholar.org/paper/8cc03eadb1c418dd2b927fcb5a3717fad8982033,"This article examines the implications of utilizing decision support systems (DSS) in the public sector based on a DSS developed and implemented for a community mental health system. The DSS includes a multiple objective (goal programming) allocation model and encompasses a multiple party decision process. The experiences and insights acquired during the development and implementation of this DSS are relevant to public sector decision support in general. The importance of a DSS as a process-support aid rather than a product-oriented aid (i.e., simply providing answers) and the interaction of system architecture and the chosen design strategy are key insights. In particular, the distinction between model-oriented and data-oriented DSS does not appear to be appropriate. The public sector decision maker's concern with issues of equity requires the ability to operate in a higher dimensional framework than the typical spreadsheet model and there is a critical need for communication support.",data oriented architecture,53
ea835ee626baa1d719a54206f4af3f5e6349173e,filtered,semantic_scholar,Third IEEE International Conference on Data Mining,2003-01-01,semantic_scholar,a dynamic adaptive self-organising hybrid model for text clustering,https://www.semanticscholar.org/paper/ea835ee626baa1d719a54206f4af3f5e6349173e,"Clustering by document concepts is a powerful way of retrieving information from a large number of documents. This task in general does not make any assumption on the data distribution. For this task we propose a new competitive self-organising (SOM) model, namely the dynamic adaptive self-organising hybrid model (DASH). The features of DASH are a dynamic structure, hierarchical clustering, nonstationary data learning and parameter self-adjustment. All features are data-oriented: DASH adjusts its behaviour not only by modifying its parameters but also by an adaptive structure. The hierarchical growing architecture is a useful facility for such a competitive neural model which is designed for text clustering. We have presented a new type of self-organising dynamic growing neural network which can deal with the nonuniform data distribution and the nonstationary data sets and represent the inner data structure by a hierarchical view.",data oriented architecture,54
9a441988271473b1a5d3205331cbd6dff3502f95,filtered,semantic_scholar,,2017-01-01,semantic_scholar,"wireless sensor network based smart grid communications: cyber attacks, intrusion detection system and topology control",https://www.semanticscholar.org/paper/9a441988271473b1a5d3205331cbd6dff3502f95,"The existing power grid is going through a massive transformation. Smart grid technology is a radical approach for improvisation in prevailing power grid. Integration of electrical and communication infrastructure is inevitable for the deployment of Smart grid network. Smart grid technology is characterized by full duplex communication, automatic metering infrastructure, renewable energy integration, distribution automation and complete monitoring and control of entire power grid. Wireless sensor networks (WSNs) are small micro electrical mechanical systems that are deployed to collect and communicate the data from surroundings. WSNs can be used for monitoring and control of smart grid assets. Security of wireless sensor based communication network is a major concern for researchers and developers. The limited processing capabilities of wireless sensor networks make them more vulnerable to cyber-attacks. The countermeasures against cyber-attacks must be less complex with an ability to offer confidentiality, data readiness and integrity. The address oriented design and development approach for usual communication network requires a paradigm shift to design data oriented WSN architecture. WSN security is an inevitable part of smart grid cyber security. This paper is expected to serve as a comprehensive assessment and analysis of communication standards, cyber security issues and solutions for WSN based smart grid infrastructure.",data oriented architecture,55
3217ddafee28cd2a7db9cff8aa69051e56373da6,filtered,semantic_scholar,,1995-01-01,semantic_scholar,coordination approaches for cim,https://www.semanticscholar.org/paper/3217ddafee28cd2a7db9cff8aa69051e56373da6,"We propose a general architecture for Computer Integrated Manufacturing (CIM) based on the coordination, rather than integration, of component systems. The coordination process is achieved through inter-system dependencies controlled by a central, global coordinator. Coordination, like integration, may be either data- or application-oriented. In the case of data-oriented coordination, multidatabase technologies may be exploited to maintain global data consistency. For application-oriented coordination, the global coordinator uses operational dependencies as a basis for the invocation of methods in remote systems. We examine each of these orientations in detail and then provide a comparison of approaches. Specifically, we describe two prototype systems developed in the context of the CIM/Z project.",data oriented architecture,56
fd5324394d82b42bc33c10725d41ca36d2ef06dd,filtered,semantic_scholar,ESSoS,2013-01-01,semantic_scholar,a fully homomorphic crypto-processor design,https://www.semanticscholar.org/paper/fd5324394d82b42bc33c10725d41ca36d2ef06dd,"A KPU is a replacement for a standard CPU that natively runs encrypted machine code on encrypted data in registers and memory --- a 'crypto-processor unit', in other words. Its computations are opaque to an observer with physical access to the processor but remain meaningful to the owner of the computation. In theory, a KPU can be run in simulation and remain as secure (or otherwise) as in hardware. Any block cipher with a block-size of about a word is compatible with this developing technology, the long-term aim of which is to make it safe to entrust data-oriented computation to a remote environment. 
 
Hardware is arranged in a KPU to make the chosen cipher behave as a mathematical homomorphism with respect to computer arithmetic. We describe the architecture formally here and show that 'type-safe' programs run correctly when encrypted.",data oriented architecture,57
cf99bc5412e2513b97cf6d4cbbb0e427a973c528,filtered,semantic_scholar,Proc. VLDB Endow.,2017-01-01,semantic_scholar,analyzing the impact of system architecture on the scalability of oltp engines for high-contention workloads,https://www.semanticscholar.org/paper/cf99bc5412e2513b97cf6d4cbbb0e427a973c528,"Main-memory OLTP engines are being increasingly deployed on multicore servers that provide abundant thread-level parallelism. However, recent research has shown that even the state-of-the-art OLTP engines are unable to exploit available parallelism for high contention workloads. While previous studies have shown the lack of scalability of all popular concurrency control protocols, they consider only one system architecture---a non-partitioned, shared everything one where transactions can be scheduled to run on any core and can access any data or metadata stored in shared memory.In this paper, we perform a thorough analysis of the impact of other architectural alternatives (Data-oriented transaction execution, Partitioned Serial Execution, and Delegation) on scalability under high contention scenarios. In doing so, we present Trireme, a main-memory OLTP engine testbed that implements four system architectures and several popular concurrency control protocols in a single code base. Using Trireme, we present an extensive experimental study to understand i) the impact of each system architecture on overall scalability, ii) the interaction between system architecture and concurrency control protocols, and iii) the pros and cons of new architectures that have been proposed recently to explicitly deal with high-contention workloads.",data oriented architecture,58
ac3df9cff34e5b9331a114c70d5e308f03370bfd,filtered,semantic_scholar,"2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems",2015-01-01,semantic_scholar,a data-oriented method for scheduling dependent tasks on high-density multi-gpu systems,https://www.semanticscholar.org/paper/ac3df9cff34e5b9331a114c70d5e308f03370bfd,"The rapidly-changing computer architectures, though improving the performance of computers, have been challenging the programming environments for efficiently harnessing the potential of novel architectures. In this area, though the high-density multi-GPU architecture enabled unparalleled performance advantage of dense GPUs in a single server, it has increased the difficulty for scheduling diversified and dependent tasks. We therefore propose a data-oriented method for scheduling dependent tasks for this architecture while providing its implementation. In our method, we model a parallel program as a collection of data-dependent tasks for which data dependencies are managed by an expressive matrix. Accordingly, we develop a hierarchical scheduler infrastructure for our model. In this, a top scheduler is built for querying the data-dependency matrix; three downstream schedulers for queuing computation tasks that are exclusively assigned to processor, accelerator or either; and a multitude of bottom schedulers each for providing a processing element with assigned tasks. We experiment our scheduler for examples of Strassen matrix multiplication and Cholesky matrix inversion algorithms on a computer that has 8 Tesla K40 GPUs. The results show that our method is capable of offering the efficient task parallelism while fulfilling the complex task dependencies. When advanced task-oriented schedulers have been widely designed for distributed systems, a lightweight data-driven scheduler could be an alternative and handy approach that can handle the dependent yet diversified tasks of data-intensive applications for the novel high-density multi-accelerator system.",data oriented architecture,59
f66df4762da27773e3a6ed820665aa74d4db0e76,filtered,semantic_scholar,2018 IEEE European Symposium on Security and Privacy (EuroS&P),2018-01-01,semantic_scholar,security risks in asynchronous web servers: when performance optimizations amplify the impact of data-oriented attacks,https://www.semanticscholar.org/paper/f66df4762da27773e3a6ed820665aa74d4db0e76,"Over the past decade, many innovations have been achieved with respect to improving the responsiveness of highly-trafficked servers. These innovations are fueled by a desire to support complex and data-rich web applications while consuming minimal resources. One of the chief advancements has been the emergence of the asynchronous web server architecture, which is built from the ground up for scalability. While this architecture can offer a significant boost in performance over classic forking servers, it does so at the cost of abandoning memory space isolation between client interactions. This shift in design, that delegates the handling of many unrelated requests within the same process, enables powerful and covert data-oriented attacks that rival complete web server takeover — without ever hijacking the control flow of the server application. To demonstrate the severity of this threat, we present a technique for identifying security-critical web server data by tracing memory accesses committed by the program in generating responses to client requests. We further develop a framework for performing live memory analysis of a running server in order to understand how low-level memory structures can be corrupted for malicious intent. A fundamental goal of our work is to assess the realism of such data-oriented attacks in terms of the types of memory errors that can be leveraged to perform them, and to understand the prominence of these errors in real-world web servers. Our case study on a leading asynchronous architecture, namely Nginx, shows how dataoriented attacks allow an adversary to re-configure an Nginx instance on the fly in order to degrade or disable services (e.g., error reporting, security headers like HSTS, access control), steal sensitive information, as well as distribute arbitrary web content to unsuspecting clients — all by manipulating only a few bytes in memory. Our empirical findings on the susceptibility of modern asynchronous web servers to two wellknown CVEs show that the damage could be severe. To address this threat, we also discuss several potential mitigations. Taken as a whole, our work tells a cautionary tale regarding the risks of blindly pushing forward with performance optimizations.",data oriented architecture,60
85d191b722bf7e0724cb431d7bef69d1cad8b54a,filtered,semantic_scholar,China Communications,2017-01-01,semantic_scholar,"digital rights management: model, technology and application",https://www.semanticscholar.org/paper/85d191b722bf7e0724cb431d7bef69d1cad8b54a,"with rapid achievement of current information technology and computing ability and applications, much more digital content such as films, cartoons, design drawings, office documents and software source codes are produced in daily work, however to protect the content being copying, shared or deliberately stolen by inside or outside, digital rights management (DRM) became more and more important for digital content protection. In this paper, we studied various DRM model, technology and application, and first proposed DRM Security Infrastructure (DSI), in which we defined encryption, hash, signature algorithm, watermarking algorithms, authentication, usage control, trusted counter, conditional trace, secure payment, and based on the DSI we then proposed a whole classification approach and architecture of all kinds of DRMs, in which we proposed 6 typical classes of copyrights and content protection DRMs architecture: (1) Software-oriented DRM,(2) eBook-oriented DRM, (3) Video-oriented DRM, (4)Image-Oriented DRM (5) Unstructured data oriented DRM, (6) Text-oriented DRM. Based on the above DSI, we then proposed a dynamic DRM model selection method for various DRM application, which can be adapted dynamically for different technology of different applications, which can provide a whole solution for variant DRM development in a rapid and customized mode. The proposed DRM method, technology and application in this paper provided a common, flexible and extendable solution for variant DRM scenes, and can support rapid and customized development. Moreover, we proposed an opinion that the future life will enter into a new era that the content usage and consumption will not again adopt DRM technology rather than with law, liberty and morality.",data oriented architecture,61
302962ecbd4d9c6d307d99837fee147a530106d9,filtered,semantic_scholar,"2014 Design, Automation & Test in Europe Conference & Exhibition (DATE)",2014-01-01,semantic_scholar,energy efficient in-memory aes encryption based on nonvolatile domain-wall nanowire,https://www.semanticscholar.org/paper/302962ecbd4d9c6d307d99837fee147a530106d9,"The widely applied Advanced Encryption Standard (AES) encryption algorithm is critical in secure big-data storage. Data oriented applications have imposed high throughput and low power, i.e., energy efficiency (J/bit), requirements when applying AES encryption. This paper explores an in-memory AES encryption using the newly introduced domain-wall nanowire. We show that all AES operations can be fully mapped to a logic-in-memory architecture by non-volatile domain-wall nanowire, called DW-AES. The experimental results show that DW-AES can achieve the best energy efficiency of 24 pJ/bit, which is 9X and 6.5X times better than CMOS ASIC and memristive CMOL implementations, respectively. Under the same area budget, the proposed DW-AES exhibits 6.4X higher throughput and 29% power saving compared to a CMOS ASIC implementation; 1.7X higher throughput and 74% power reduction compared to a memristive CMOL implementation.",data oriented architecture,62
0790af19ce0f479f822b890388791cfd3ebfe276,filtered,semantic_scholar,,1998-01-01,semantic_scholar,the wasa approach to workflow management for scientific applications,https://www.semanticscholar.org/paper/0790af19ce0f479f822b890388791cfd3ebfe276,"Workflow management has gained increasing attention recently, since it allows one to combine a data-oriented view on applications, which is the traditional one for an information system, with a process-oriented one in which activities and their occurrences over time are modeled and supported properly. While workflow management has mostly been considered in business applications so far, the focus of the WASA project is on scientific applications such as geoprocessing, molecular biology, or laboratory environments. In particular, WASA aims at flexible and platform-independent workflow support, with respect to both specification and execution of workflows. It turns out that the modeling and execution of workflows in traditional and in scientific applications exhibit significant differences. In particular, the need for dynamic modifications of workflow models while workflows are running is an important feature in scientific applications. Observations like these have resulted in a generic WASA architecture, which can be tailored towards various specific application domains. The conceptual design and functionality of a WASA prototype is outlined, in particular that of its core workflow engine, and it is shown how the requirements of flexibility in modeling and executing workflows, imposed by scientific applications, are met by this prototype.",data oriented architecture,63
522f493d89ff29bde79d6b5ec87e09983f9a1573,filtered,semantic_scholar,,2003-01-01,semantic_scholar,an abstract modeling approach towards system-level design-space exploration,https://www.semanticscholar.org/paper/522f493d89ff29bde79d6b5ec87e09983f9a1573,"Integration of increasingly complex systems on a chip augments the need of system-level methods for specification and design. In the earliest phases of the design process important design decisions can be taken on the basis of a fast exploration of the design space. This paper describes an abstract modeling approach towards system-level design-space exploration, which is formal and flexible. It uses a uniform system model that contains both functional and architectural information. Disjunct, parameterizable resources represent the real-time behavior of the target architecture. Due to the expressiveness of the modeling language (POOSL), control as well as data oriented behavior can be specified in the functional part of the system model. Well-founded design decisions can be taken as a result of performance estimations that are based on Markov theory.",data oriented architecture,64
3c43e848a6cf8f90c17298d6298ce0b58007881e,filtered,semantic_scholar,,2012-01-01,semantic_scholar,generic adaptation framework for unifying adaptive web-based systems,https://www.semanticscholar.org/paper/3c43e848a6cf8f90c17298d6298ce0b58007881e,"The Generic Adaptation Framework (GAF) research project first and foremost creates a common formal framework for describing current and future adaptive hypermedia (AHS) and adaptive webbased systems in general. It provides a commonly agreed upon taxonomy and a reference model that encompasses the most general architectures of the present and future, including conventional AHS, and different types of personalization-enabling systems and applications such as recommender systems (RS) personalized web search, semantic web enabled applications used in personalized information delivery, adaptive e-Learning applications and many more. At the same time GAF is trying to bring together two (seemingly not intersecting) views on the adaptation: a classical pre-authored type, with conventional domain and overlay user models and data-driven adaptation which includes a set of data mining, machine learning and information retrieval tools. To bring these research fields together we conducted a number GAF compliance studies including RS, AHS, and other applications combining adaptation, recommendation and search. We also performed a number of real systems’ case-studies to prove the point and perform a detailed analysis and evaluation of the framework. Secondly it introduces a number of new ideas in the field of AH, such as the Generic Adaptation Process (GAP) which aligns with a layered (data-oriented) architecture and serves as a reference adaptation process. This also helps to understand the compliance features mentioned earlier. Besides that GAF deals with important and novel aspects of adaptation enabling and leveraging technologies such as provenance and versioning. The existence of such a reference basis should stimulate AHS research and enable researchers to demonstrate ideas for new adaptation methods much more quickly than if they had to start from scratch. GAF will thus help bootstrap any adaptive web-based system research, design, analysis and evaluation.",data oriented architecture,65
63c7863fcba665bb8b87ee7f204ec79dcd60ba9a,filtered,semantic_scholar,2020 IEEE Symposium on Security and Privacy (SP),2020-01-01,semantic_scholar,xmp: selective memory protection for kernel and user space,https://www.semanticscholar.org/paper/63c7863fcba665bb8b87ee7f204ec79dcd60ba9a,"Attackers leverage memory corruption vulnerabilities to establish primitives for reading from or writing to the address space of a vulnerable process. These primitives form the foundation for code-reuse and data-oriented attacks. While various defenses against the former class of attacks have proven effective, mitigation of the latter remains an open problem. In this paper, we identify various shortcomings of the x86 architecture regarding memory isolation, and leverage virtualization to build an effective defense against data-oriented attacks. Our approach, called xMP, provides (in-guest) selective memory protection primitives that allow VMs to isolate sensitive data in user or kernel space in disjoint xMP domains. We interface the Xen altp2m subsystem with the Linux memory management system, lending VMs the flexibility to define custom policies. Contrary to conventional approaches, xMP takes advantage of virtualization extensions, but after initialization, it does not require any hypervisor intervention. To ensure the integrity of in-kernel management information and pointers to sensitive data within isolated domains, xMP protects pointers with HMACs bound to an immutable context, so that integrity validation succeeds only in the right context. We have applied xMP to protect the page tables and process credentials of the Linux kernel, as well as sensitive data in various user-space applications. Overall, our evaluation shows that xMP introduces minimal overhead for real-world workloads and applications, and offers effective protection against data-oriented attacks.",data oriented architecture,66
bdd38349d22ab12ddd44a500d5720853ee17286b,filtered,semantic_scholar,2012 IEEE International Conference on Communications (ICC),2012-01-01,semantic_scholar,traffic engineering for information-centric networks,https://www.semanticscholar.org/paper/bdd38349d22ab12ddd44a500d5720853ee17286b,"Information-centric networking (ICN) proposes a networking architecture that uses methodologies such as publish-subscribe to achieve a data-oriented approach as opposed to a destination based approach found in the current Internet. This new architecture brings both new problems to be solved and also natural solutions to existing problems. This paper investigates an intra-domain traffic engineering (TE) problem for an information-centric networking (ICN) architecture where a form of source routing is used as the forwarding mechanism. The TE goal is to maximise the residual capacity in the network so that the load is spread evenly. A network flow approach is used and it is shown that the source routing mechanism allows the traffic to be split across multiple paths in a manner that is difficult to achieve using existing IP or IP/MPLS networks. Allowing splittable flows means that a fully polynomial-time approximation scheme can be used that has superior results when compared to existing constraint based routing schemes for flows that cannot be split. Consequently, this work demonstrates that the ICN architecture can simplify the given TE problem in a natural manner.",data oriented architecture,67
536ab937378e5965f8687b5bf29af2e360aac3bb,filtered,semantic_scholar,2006 ieee/aiaa 25TH Digital Avionics Systems Conference,2006-01-01,semantic_scholar,system-wide information management (swim) demonstration security architecture,https://www.semanticscholar.org/paper/536ab937378e5965f8687b5bf29af2e360aac3bb,"System-wide information management (SWIM) is a Federal Aviation Administration (FAA) network-centric environment that facilitates software application integration in the National Airspace System (NAS). Built on a set of five core service types - interfaces, registries, message brokers, information assurance and system management - SWIM accelerates NAS evolution by defining a secure common infrastructure for application integration and a framework for information modeling and exchange. Providing information security in this distributed network-centric environment is a significant challenge. System users must be confident that their critical data is protected. Competing requirements, the transportation of sensitive data and air-to-ground bandwidth constraints mean that a network layer-based approach to security is no longer sufficient. Trusted security at every layer of a network-centric architecture - combined with strong identity management and a data-oriented approach to information assurance - is the key to success. This paper introduces the FAA SWIM demonstration security architecture, and explores some of the methods and mechanisms used to provide end-to-end security, confidentiality, integrity, availability and privacy for NAS applications and their users",data oriented architecture,68
b728578e4b46a145a24cf02a2f5b70c01eb9b78a,filtered,semantic_scholar,FM,2005-01-01,semantic_scholar,verification of a signature architecture with hol-z,https://www.semanticscholar.org/paper/b728578e4b46a145a24cf02a2f5b70c01eb9b78a,"We report on a case study in using HOL-Z, an embedding of Z in higher-order logic, to specify and verify a security architecture for administering digital signatures. We have used HOL-Z to formalize and combine both data-oriented and process-oriented architectural views. Afterwards, we formalized temporal requirements in Z and carried out verification in higher-order logic. 
 
The same architecture has been previously verified using the SPIN model checker. Based on this, we provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with rich data. Moreover, our comparison highlights the advantages of this approach and provides evidence that, in the hands of experienced users, theorem proving is neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,69
f0c611b788794234c65bb32b4f748a17bd6cebbd,filtered,semantic_scholar,,2017-01-01,semantic_scholar,digital economy: conceptual architecture of a digital economic sector ecosystem,https://www.semanticscholar.org/paper/f0c611b788794234c65bb32b4f748a17bd6cebbd,"Yury M. Akatkin - Head of Laboratory of Social-Demographic Statistics, Plekhanov Russian University of EconomicsAddress: 36, Stremyanny Lane, Moscow, 117997, Russian FederationE-mail: u.akatkin@semanticpro.orgOleg E. Karpov - Corresponding Member, Russian Academy of Sciences; General Director of Pirogov National Medical-Surgical CenterAddress: 70, Nizhnyaya Pervomaiskaya Street, Moscow, 105203, Russian FederationE-mail: nmhc@mail.ruValery A. Konyavskiy - Head of Information Security Department, Moscow Institute of Physics and TechnologyAddress: 1A, Kerchenskaya Street, Moscow, 117303, Russian FederationE-mail: konyavskiy@gospochta.ruElena D. Yasinovskaya - Senior Researcher, Laboratory of Social-Demographic Statistics, Plekhanov Russian University of EconomicsAddress: 36, Stremyanny Lane, Moscow, 117997, Russian FederationE-mail: elena@semanticpro.org The main objective of digital transformation is to fulfill the needs of a “new digital generation customer” for on-demand delivery, quality and personalization. ”Anything as a service” has become the key principle of the digital paradigm. This is about a data-oriented service which relies on sharing information resources (including public ones) and the requirements for interoperability, security and trust. This paper presents the main approaches to digital transformation based on the example of the most innovatively active sectors such as banking and healthcare. We compare the proprietary development of digital services (products) to the building of a digital sector ecosystem aimed at attracting an unlimited number of participants. We defined the purpose of creating an ecosystem that is to provide the population with digital services formed on demand, in real time, in compliance with legislation and regulations, as well as in the context of maximum trust. We emphasize the role of openness for uniting the efforts of the community interested in the development of a digital industry, extension of public-private partnerships and building a competitive environment in order to ensure the rapid growth of available digital services, as well as to improve their quality. Since the knowledge economy is the basis for the digital economy, the authors consider it especially important to form a semantic core which acts as the carrier of knowledge in a digital sector ecosystem. We confirmed the necessity to implement the semantic core by a brief analysis of modern semantic approaches to standardization of information sharing in the above-mentioned industries, such as FIBO, BIAN (banking), HL7 and UMLS (health). The research carried out allowed the authors to design the conceptual architecture of the ecosystem and to suggest several proposals for digital transformation of an industry. The proposals express the necessity of state support for innovation and providing the conditions for the entry of new digital products based on the following principles: accessibility, timeliness, personalization, adaptability and security.",data oriented architecture,70
cb4fb34f4c165913a98692dea22a0eb965cefb12,filtered,semantic_scholar,SIGMOD Conference,2010-01-01,semantic_scholar,docqs: a prototype system for supporting data-oriented content query,https://www.semanticscholar.org/paper/cb4fb34f4c165913a98692dea22a0eb965cefb12,"Witnessing the richness of data in document content and many ad-hoc efforts for finding such data, we propose a Data-oriented Content Query System(DoCQS), which is oriented towards fine granularity data of all types by searching directly into document content. DoCQS uses the relational model as the underlying data model, and offers a powerful and flexible Content Query Language(CQL) to adapt to diverse query demands. In this demonstration, we show how to model various search tasks by CQL statements, and how the system architecture efficiently supports the CQL execution. Our online demo of the system is available at http://wisdm.cs.uiuc.edu/demos/docqs/.",data oriented architecture,71
449b756485d77d452b0cc0805b1a7a6767d8f525,filtered,semantic_scholar,IEEE Transactions on Industrial Informatics,2017-01-01,semantic_scholar,iot-based techniques for online m2m-interactive itemized data registration and offline information traceability in a digital manufacturing system,https://www.semanticscholar.org/paper/449b756485d77d452b0cc0805b1a7a6767d8f525,"The integration of internet-of-things (IoT) technologies in the industry benefits digital manufacturing applications by allowing ubiquitous interaction and collaborative automation between machines. Online data collection and data interaction are critical for real-time decision making and machine collaborations. However, due to the specificity of digital manufacturing applications, the technical gap between IoT techniques and practical machine operation could hinder the efficient data interactions, collaborations between machines, and the effectiveness as well as the accuracy of itemized data collection. This investigation, therefore, identifies some major technical problems and challenges that current IoT-based digital manufacturing is facing, and proposes a method to bridge the technical gap for itemized product management. The highlights of this investigation are: 1) a data-oriented system architecture toward flexible data interaction between machines, 2) a customized machine-to-machine protocol for machine discovery, presence, and messaging, (3) flexible data structure and data presentation for interoperability, and (4) versatile information tracing approaches for product management. The proposed solutions have been implemented in PicknPack digital food manufacturing line, and achieved ubiquitous data interaction, online data collection, and versatile product information tracing methods have shown the feasibility and significance of the presented methods.",data oriented architecture,72
63f8e385951558e9c6b49cb4c83098b09ed704e3,filtered,semantic_scholar,2013 International Conference on Advanced Cloud and Big Data,2013-01-01,semantic_scholar,a mechanism of information-centric networking based on data centers,https://www.semanticscholar.org/paper/63f8e385951558e9c6b49cb4c83098b09ed704e3,"Information-centric networking (ICN) aims to make the Internet more data-oriented or content-centric, thus name-based routing and universal caching are used to change the way users requesting and fetching content, as well as to improve network performance. However, current implementation mechanisms define some kinds of ""clean-slate"" architecture and certain brand new technologies need to be designed and implemented. In this paper, some requisites reflecting ICN's essential ingredients are generalized, and based on the OpenFlow and the data center technologies, a mechanism called odICN, which can satisfy those aforementioned requisites, is proposed together with its algorithmic framework. Finally, a prototype of odICN is built to verify its feasibility.",data oriented architecture,73
e4313c807b2de4d0d1c4078cb2bebdd6a4576022,filtered,semantic_scholar,Wirel. Pers. Commun.,2005-01-01,semantic_scholar,analysis of sub-carrier multiplexed radio over fiber link for the simultaneous support of wlan and wcdma systems,https://www.semanticscholar.org/paper/e4313c807b2de4d0d1c4078cb2bebdd6a4576022,"The present third generation (3G) wireless technology can provide data oriented applications. However, the bit rate is limited to around 2 Mbps with limited mobility. Today, more applications demand high data rate and reasonable mobility. Therefore, by integrating 3G cellular system and wireless local area network (WLAN), there is a potential to push the data rate higher. This integration means 3G cellular users can enjoy high data rate at a location that is within WLAN coverage area. Similarly, WLAN users also can have data services as long as they are under the coverage of the 3G cellular system. The 3G cellular system has a much larger coverage than the WLAN. In this paper, we present the first step toward an integration of the two systems. This paper presents a fiber-wireless architecture that simultaneously supports the wideband code division multiple access (WCDMA) system and the IEEE 802.11b WLAN. Our approach uses sub-carrier multiplexed (SCM) architecture to combine and transmit 2.4 GHz WLAN and 1.9 GHz WCDMA signals through an optical fiber from a central base station (CBS) to a radio access point (RAP, single antenna unit). After the fiber, the signals continue to propagate through the air interface to respective mobile stations. The WLAN access point is also located at the CBS. For the SCM architecture, we investigate three areas: i) the signal to noise ratio of the uplink and the downlink, ii) the cell coverage area for the WCDMA and WLAN systems, and iii) the throughput of the IEEE 802.11b WLAN. Our results show that with up to 2.5 km cell radius, better than 18 dB SNR is possible with 5 km fiber link for WLAN system. Simultaneously, the WCDMA system has at least 18 dB SNR for a cell coverage radius of 8 km. These numbers depend on the relative RF power of each system in the fiber.",data oriented architecture,74
9703eec800ca2f2cbbcdb8edc565da15ba15af8c,filtered,semantic_scholar,Formal Aspects of Computing,2007-01-01,semantic_scholar,verifying a signature architecture: a comparative case study,https://www.semanticscholar.org/paper/9703eec800ca2f2cbbcdb8edc565da15ba15af8c,"We report on a case study in applying different formal methods to model and verify an architecture for administrating digital signatures. The architecture comprises several concurrently executing systems that authenticate users and generate and store digital signatures by passing security relevant data through a tightly controlled interface. The architecture is interesting from a formal-methods perspective as it involves complex operations on data as well as process coordination and hence is a candidate for both data-oriented and process-oriented formal methods.We have built and verified two models of the signature architecture using two representative formal methods. In the first, we specify a data model of the architecture in Z that we extend to a trace model and interactively verify by theorem proving. In the second, we model the architecture as a system of communicating processes that we verify by finite-state model checking. We provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with complex operations on data. Moreover, our comparison highlights the advantages of proving theorems about such models and provides evidence that, in the hands of an experienced user, theorem proving may be neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,75
62bdf319dcb9743d8abe61d5ba3f4e2180092a2e,filtered,semantic_scholar,IEEE Wireless Communications,2015-01-01,semantic_scholar,video delivery in heterogenous crans: architectures and strategies,https://www.semanticscholar.org/paper/62bdf319dcb9743d8abe61d5ba3f4e2180092a2e,"Video traffic has become a major part of mobile data traffic, and will keep growing in the coming years. The performance of video delivery is fundamentally constrained by the structure of the underlying wireless networks. The recently proposed heterogeneous cloud access networks have been widely recognized as an inevitable evolution trend of the current cellular system toward the future 5G system, where multiple hybrid radio access technologies coexist to provide flexible access for mobile users. As a key enabling functional block for high-performance video delivery, a powerful centralized baseband processing unit pool is adopted to control all the radio access technologies, and possibly facilitate the video encoding and transmission, which opens up the potential to achieve higher throughput, lower traffic delay, and greater robustness compared to its basic baseband processing unit counterpart without central control functions. However, such a centralized control framework also raises many new research challenges to be addressed. In this article, we provide an overview of the state-of-the-art video delivery architectures and video packet transmission strategies in heterogeneous cloud radio access networks, with highlights on the networking architectures, transmission strategies, performance analysis, and design challenges. This article also sheds some light on the design principles for future big-data-oriented wireless networks.",data oriented architecture,76
38450d945f8ca0fd66a088bb042ed30ed3b3ee84,filtered,semantic_scholar,Int. J. Distributed Sens. Networks,2013-01-01,semantic_scholar,integrating sensor networks for energy monitoring with service-oriented architectures,https://www.semanticscholar.org/paper/38450d945f8ca0fd66a088bb042ed30ed3b3ee84,"More accurate predictions of energy consumption are a strong motivator for utility providers to deploy a smart grid infrastructure. However, measurements which only reflect the consumption of a household lose the details associated with the behaviour of individual devices. Finding a flexible and efficient way to process these readings is essential. Using standard application techniques to integrate device-oriented sensor networks and data-oriented applications is a serious challenge due to the architectural gap between the different approaches. Additionally, this device-level information should be shared with the end-users in a trusted manner to increase their energy awareness. We propose a novel platform for the smart grid which enables the seamless integration of sensor networks with a service-oriented architecture approach. The platform hides the device-specific details from the applications and transforms data into a device-independent format. Specifically, we present an in-depth description of the architecture of our platform and a full implementation and evaluation of it in a live residential energy management deployment.",data oriented architecture,77
3fa248cfa1491c657bb5f32f237fac4a6a882bfe,filtered,semantic_scholar,,1994-01-01,semantic_scholar,communications architecture: towards a more robust understanding of information flows and emergent patterns of communication in organizations,https://www.semanticscholar.org/paper/3fa248cfa1491c657bb5f32f237fac4a6a882bfe,"With the proliferation of telecommunications technologies, the information-based communication infrastructure is becoming an increasingly critical organization resource. In order effectively to channel limited resources (skills, capital, technology) to the most strategically critical communication needs of the organization, the development of business driven planning methodologies which result in a well-defined architecture (blueprint) of organizational communication processes are needed. Unfortunately, while architectural issues are of utmost importance today, researchers have focused almost exclusively on data oriented models. This study attempts to expand this view and provide a holistic representation of information architecture. With the perspective provided by this definitional framework, two methods for development of communications architecture are discussed and evaluated: (1) a flow based approach; and (2) network analysis. Network analysis in particular shows great promise in constructing robust representations of organizational communication processes.",data oriented architecture,78
cdb52713b40d7864cbe48af444db56af8f3201dd,filtered,semantic_scholar,International Conference on Internet Computing,2003-01-01,semantic_scholar,"an architecture for efficient, flexible enterprise system integration",https://www.semanticscholar.org/paper/cdb52713b40d7864cbe48af444db56af8f3201dd,"Integrating complex enterprise systems is challenging and reliability and performance of the integrated systems can be problematic when using typical solutions of distributed transactions or on-demand message-based querying. We describe a data-oriented approach for enterprise system integration that uses information brokering. A broker application isolates the interactions between a local enterprise application server and a wide variety of remote systems, performing data acquisition, storage, transformation, update and status management. We describe a prototype book brokering system developed using Java 2 Enterprise Edition, CORBA, Java Messaging Service and Web Services and using our integration strategy. We outline the architecture, design and implementation of this prototype and summarise our experiences with this information integration technique.",data oriented architecture,79
8c4150135d16aaba51db505d8281171a7a20f42e,filtered,semantic_scholar,Enterp. Inf. Syst.,2016-01-01,semantic_scholar,a new practice-driven approach to develop software in a cyber-physical system environment,https://www.semanticscholar.org/paper/8c4150135d16aaba51db505d8281171a7a20f42e,"Cyber-physical system (CPS) is an emerging area, which cannot work efficiently without proper software handling of the data and business logic. Software and middleware is the soul of the CPS. The software development of CPS is a critical issue because of its complicity in a large scale realistic system. Furthermore, object-oriented approach (OOA) is often used to develop CPS software, which needs some improvements according to the characteristics of CPS. To develop software in a CPS environment, a new systematic approach is proposed in this paper. It comes from practice, and has been evolved from software companies. It consists of (A) Requirement analysis in event-oriented way, (B) architecture design in data-oriented way, (C) detailed design and coding in object-oriented way and (D) testing in event-oriented way. It is a new approach based on OOA; the difference when compared with OOA is that the proposed approach has different emphases and measures in every stage. It is more accord with the characteristics of event-driven CPS. In CPS software development, one should focus on the events more than the functions or objects. A case study of a smart home system is designed to reveal the effectiveness of the approach. It shows that the approach is also easy to be operated in the practice owing to some simplifications. The running result illustrates the validity of this approach.",data oriented architecture,80
0e3bd3672a1964062c528fea878f9771c850f2b9,filtered,semantic_scholar,,2010-01-01,semantic_scholar,design and implementation of an efficient data stream processing system,https://www.semanticscholar.org/paper/0e3bd3672a1964062c528fea878f9771c850f2b9,"In standard database scenarios, an end-user assumes that all data (e.g., sensor readings) is stored in a database. Therefore, one can simply submit any arbitrary complex processing in the form of SQL queries or stored procedures to a database server. Data stream oriented applications are typically dealing with huge volumes of data. Storing data and performing off-line processing on this huge dataset can be costly, time consuming and impractical. This work describes our research results while designing and implementing an efficient data management system for online and off-line processing of data streams in the field of environmental monitoring. Our target data sources are wireless sensor networks. Although our focus is on a specific application domain, the results of this thesis are designed in a generic way, so that they can be applied to wide variety of data stream oriented applications. This thesis starts by first presenting the state-of-the-art in data stream processing research specifically window processing concepts, continuous queries, stream filtering query languages and in-network data processing (particular focus on TinyOS-based approaches). We present key existing data stream processing engines, their internal architecture and how they are compared to our platform, namely Global Sensor Network (GSN) middleware. GSN middleware enables fast and flexible deployment and interconnection of sensor networks. It provides simple and uniform access to a comprehensive set of heterogeneous technologies. Additionally, GSN offers zero-programming deployment and data-oriented integration of sensor networks and supports dynamic re-configuration and adaptation at runtime. We present the virtual sensor concept, which offers a high-level view of arbitrary stream data sources, its powerful declarative specification and query tools. Furthermore, we describe design, conceptual, architectural and optimization decisions of GSN platform in detail. In order to achieve high efficiency while processing large volumes of streaming data using window-based continuous queries, we present a set of optimization algorithms and techniques to intelligently group and process different types of continuous queries. While adapting GSN to large scale sensor network deployments, we have encountered several performance bottlenecks. One of the challenges we faced was related to scalable delivery of streaming data for high data rate streams. We found out that we could dramatically improve the performance of a query processor by performing simple grouping of user queries hence sharing both the processing and memory costs among similar queries. Moreover, we encountered a similar performance issue while scheduling continuous queries. Problem of efficiently scheduling the execution of continuous queries with window and sliding parameters is not addressed in depth in literature. This problem becomes severe when one considers large volumes of high data rate streams. In these cases, an efficient query scheduler not only increases the performance at least by an order of magnitude but also, decreases the response time and memory requirements. Finally, we present how our GSN platform can get integrated with an external data sharing and visualization framework namely Microsoft's SenseWeb platform. Microsoft's SenseWeb platform, provides a sensor network data gathering and visualization infrastructure which is globally accessible to the end users. This integration (which is initiated by the Swiss Experiment project and demanded by GSN users) not only shows the scalability of GSN platform when combined with optimized algorithms, but also demonstrates its flexibility.",data oriented architecture,81
072c3011c75630fb4a49aa6171533f631747fe0b,filtered,semantic_scholar,,1992-01-01,semantic_scholar,a mathematical model of cpu,https://www.semanticscholar.org/paper/072c3011c75630fb4a49aa6171533f631747fe0b,"This paper is based on a previous work of the first author [12] in which a mathematical model of the computer has been presented. The model deals with random access memory, such as RASP of C. C. Elgot and A. Robinson [11], however, it allows for a more realistic modeling of real computers. This new model of computers has been named by the author (Y. Nakamura, [12]) Architecture Model for Instructions (AMI). It is more developed than previous models, both in the description of hardware (e.g., the concept of the program counter, the structure of memory) as well as in the description of instructions (instruction codes, addresses). The structure of AMI over an arbitrary collection of mathematical domains N consists of: a non-empty set of objects, the instruction counter, a non-empty set of objects called instruction locations, a non-empty set of instruction codes, an instruction code for halting, a set of instructions that are ordered pairs with the first element being an instruction code and the second a finite sequence in which members are either objects of the AMI or elements of one of the domains included in N, a function that assigns to every object of AMI its kind that is either an instruction or an instruction location or an element of N, a function that assigns to every instruction its execution that is again a function mapping states of AMI into the set of states. By a state of AMI we mean a function that assigns to every object of AMI an element of the same kind. In this paper we develop the theory of AMI. Some properties of AMI are introduced ensuring it to have some properties of real computers: a von Neumann AMI, in which only addresses to instruction locations are stored in the program counter, data oriented, those in which instructions cannot be stored in data locations, halting, in which the execution of the halt instruction is the identity mapping of the states of an AMI, steady programmed, the condition in which the contents of the instruction locations do not change during execution,",data oriented architecture,82
5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,filtered,semantic_scholar,ICON 2012,2012-01-01,semantic_scholar,application design over named data networking with its features in mind,https://www.semanticscholar.org/paper/5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,"Designed around host-reachability, today’s Internet architecture faces many limitations while serving data-oriented applications, which produce most traffic load to the Internet. Many clean-slate designs of the content/data oriented network have emerged to adapt to these needs. Named Data Networking (also known as CCN) is one of these designs to address these limitations from the fundamental level by building network architecture around named data. In this paper, we identify five key features crucial to application design over Named Data Networking and take the voice conference system as an example to show how this features impact the application design significantly in detail. We identify three major challenges facing current voice conference system and illustrate how NDN could help to solve these challenges. A NDN-based design of voice conference system is presented along with discussing its reliability and congestion control. Keywords-Named Data Networking; Application Design;",data oriented architecture,83
b43f67bc15fd25112aaa9d7378f4952af41206a3,filtered,semantic_scholar,ISPRS Int. J. Geo Inf.,2019-01-01,semantic_scholar,interactive and online buffer-overlay analytics of large-scale spatial data,https://www.semanticscholar.org/paper/b43f67bc15fd25112aaa9d7378f4952af41206a3,"Buffer and overlay analysis are fundamental operations which are widely used in Geographic Information Systems (GIS) for resource allocation, land planning, and other relevant fields. Real-time buffer and overlay analysis for large-scale spatial data remains a challenging problem because the computational scales of conventional data-oriented methods expand rapidly with data volumes. In this paper, we present HiBO, a visualization-oriented buffer-overlay analysis model which is less sensitive to data volumes. In HiBO, the core task is to determine the value of pixels for display. Therefore, we introduce an efficient spatial-index-based buffer generation method and an effective set-transformation-based overlay optimization method. Moreover, we propose a fully optimized hybrid-parallel processing architecture to ensure the real-time capability of HiBO. Experiments on real-world datasets show that our approach is capable of handling ten-million-scale spatial data in real time. An online demonstration of HiBO is provided (http://www.higis.org.cn: 8080/hibo).",data oriented architecture,84
7da24e5d96d353e9fcb32247006bf2a9b468ba8e,filtered,semantic_scholar,Inf. Syst. E Bus. Manag.,2013-01-01,semantic_scholar,an integrated e-service model for electronic medical records,https://www.semanticscholar.org/paper/7da24e5d96d353e9fcb32247006bf2a9b468ba8e,"In this paper, we discuss the critical issues with the implementation of electronic medical records and argue that the emerging e-services will not fully resolve the issues if they do not work together. To meet the challenge, we propose an integrated e-service model consisting of both process- and data-oriented grids that glue together distributed electronic medical services, records, and application services. We also provide an implementation architecture and prototype that validates the model.",data oriented architecture,85
08eeaab633644ab8d362d57563443bd671963c0c,filtered,semantic_scholar,"2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)",2018-01-01,semantic_scholar,tmdfi: tagged memory assisted for fine-grained data-flow integrity towards embedded systems against software exploitation,https://www.semanticscholar.org/paper/08eeaab633644ab8d362d57563443bd671963c0c,"Memory corruption vulnerabilities are main causes of quite a few modern software attacks. Classical Data-flow integrity, which is originally implemented purely on soft-ware platforms, can perform a good security effect against memory corruption attacks, particularly the newly proposed data-oriented programming attacks. However, it introduces high space and time overheads. To tackle these limitations of DFI, in this paper we present tagged memory supported data-flow integrity, TMDFI, a hardware data-flow integrity implementation to enable fine-grained DFI checks with reduced time and space overheads. Our hardware DFI proposal is based on lowRISC, an existing open-source tagged memory architecture targeting a RISC-V core. The tag fields are enlarged and adopted to keep the identifiers for run-time DFI enforcement. We modified the low-RISC architecture by adding a new instruction that performs multiple tags checking simultaneously and changing some native tag manipulation features. We tested our prototype on an RTL emulator. The result shows that the reduction of run-time overhead of a full inter-procedural DFI enforcement is from 104% to 39% and the space overhead shrinks from 50% to 12.5%.",data oriented architecture,86
102b85595c9d0ffddf74517124ad3e9dca61b271,filtered,semantic_scholar,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),2020-01-01,semantic_scholar,making iot data ready for smart city applications,https://www.semanticscholar.org/paper/102b85595c9d0ffddf74517124ad3e9dca61b271,"Modern smart city projects are evolving to the next level of data-centric situation awareness and decision makings, thereby requiring much intensive data integration over various data sources made from city space. In order to satisfy a variety of data demands for diverse smart city applications, we have been developing an integrated IoT data service, IoTDA, to provide essential data-oriented services from data collecting to deep learning based data analysis. In this paper, we introduce the overall architecture and functions of the service platform and explain how the platform will be used with a case study of road surface analysis. In particular, we examine how our data service can be connected to public smart city applications and present the common direction that these types of urban data services should provide for advanced city services.",data oriented architecture,87
e699c5433777fc8a0fcad58410061ec9b6d8afa5,filtered,semantic_scholar,Int. J. Netw. Manag.,2017-01-01,semantic_scholar,on efficient data storage service for iot,https://www.semanticscholar.org/paper/e699c5433777fc8a0fcad58410061ec9b6d8afa5,"SUMMARY 
 
The increasing popularity of Internet of Things (IoT) services causes tremendous growth of the amount of produced data. These data must be effectively stored and retrieved by the IoT service providers. The solution is to access the data through application programming interfaces. The paper focuses on the problem of designing an effective data storage service for IoT, which will be available through the universal application programming interface. We propose and analyze eight variants of the distributed data storage service that differ in the database structure, that is, the hierarchical structure based on Data-Oriented Network Architecture or the flat structure based on distributed hash table, the type of stored records, and the memory management algorithm that decides about using cache or base memory. The proposed solutions have been evaluated in the comprehensive simulation studies. The obtained results confirmed the effectiveness of the preferred solution with Dynamic Routing Records stored in the cache memory. Copyright © 2016 John Wiley & Sons, Ltd.",data oriented architecture,88
407ebbe7b9a024c71d459a370deaf614455e3c8e,filtered,semantic_scholar,,2017-01-01,semantic_scholar,named data networking in vanet: a survey,https://www.semanticscholar.org/paper/407ebbe7b9a024c71d459a370deaf614455e3c8e,"Named Data Networking is futuristic data oriented communication model, currently applied to different area of networking. VANET is one area of networking, that named data networking applied on it, to overcome the problem of classically TCP/IP based architecture. As VANET has become a likely area in wireless communication, which can provide a lot of service: traffic efficiency, road safety, and driving comfort. So, Named data networking architecture provide a lot purpose for VANET such as in network caching, security and efficient data distribution between vehicles due to caching capabilities in NDN, this feature make VANET more efficient than TCP/IP network. In existing IP based internet architecture the end points identified by IP addresses but in NDN contents are named with human readable names that provide VANET to retrieve data by sending content name without knowing the location of the provider. This paper also present some research challenge in the VANET via NDN. Keywords— NDN, VANET, Caching, ICN.",data oriented architecture,89
007351f71380494eefea410bacbe4fc5cfbc8d85,filtered,semantic_scholar,,2011-01-01,semantic_scholar,poor man's content centric networking (with tcp),https://www.semanticscholar.org/paper/007351f71380494eefea410bacbe4fc5cfbc8d85,"A number of different architectures have been proposed in support of data-oriented or information-centric networking. Besides a similar visions, they share the need for designing a new networking architecture. We present an incrementally deployable approach to content-centric networking based upon TCP. Content-aware senders cooperate with probabilistically operating routers for scalable content delivery (to unmodified clients), effectively supporting opportunistic caching for time-shifted access as well as de-facto synchronous multicast delivery. Our approach is application protocol-independent and provides support beyond HTTP caching or managed CDNs. We present our protocol design along with a Linux-based implementation and some initial feasibility checks.",data oriented architecture,90
328fb04c4cfe6a90de32041c31810c6d8908e439,filtered,semantic_scholar,IEEE Transactions on Circuits and Systems for Video Technology,2011-01-01,semantic_scholar,communication mechanisms and middleware for distributed video surveillance,https://www.semanticscholar.org/paper/328fb04c4cfe6a90de32041c31810c6d8908e439,"A new generation of advanced surveillance systems is being conceived as a collection of multisensor components such as video, audio, and mobile robots interacting in a cooperating manner to enhance situation awareness capabilities to assist surveillance personnel. The prominent issues that these systems face are the improvement of existing intelligent video surveillance systems, the inclusion of wireless networks, the use of low power sensors, the design architecture, the communication between different components, the fusion of data emerging from different type of sensors, the location of personnel (providers and consumers), and the scalability of the system. This paper focuses on the aspects pertaining to real-time distributed architecture and scalability. For example, to meet real-time requirements, these systems need to process data streams in concurrent environments, designed by taking into account scheduling and synchronization. This paper proposes a framework for the design of visual surveillance systems based on components derived from the principles of real-time networks/data-oriented requirements implementation scheme. It also proposes the implementation of these components using the well-known middleware technology common object request broker architecture. Results using this architecture for video surveillance are presented through an implemented prototype.",data oriented architecture,91
72ce5e9265b4b5c3b4be020cea8ee70b2541526d,filtered,semantic_scholar,CCS,2016-01-01,semantic_scholar,"""the web/local"" boundary is fuzzy: a security study of chrome's process-based sandboxing",https://www.semanticscholar.org/paper/72ce5e9265b4b5c3b4be020cea8ee70b2541526d,"Process-based isolation, suggested by several research prototypes, is a cornerstone of modern browser security architectures. Google Chrome is the first commercial browser that adopts this architecture. Unlike several research prototypes, Chrome's process-based design does not isolate different web origins, but primarily promises to protect ""the local system"" from ""the web"". However, as billions of users now use web-based cloud services (e.g., Dropbox and Google Drive), which are integrated into the local system, the premise that browsers can effectively isolate the web from the local system has become questionable. In this paper, we argue that, if the process-based isolation disregards the same-origin policy as one of its goals, then its promise of maintaining the ""web/local system (local)"" separation is doubtful. Specifically, we show that existing memory vulnerabilities in Chrome's renderer can be used as a stepping-stone to drop executables/scripts in the local file system, install unwanted applications and misuse system sensors. These attacks are purely data-oriented and do not alter any control flow or import foreign code. Thus, such attacks bypass binary-level protection mechanisms, including ASLR and in-memory partitioning. Finally, we discuss various full defenses and present a possible way to mitigate the attacks presented.",data oriented architecture,92
4da301bdd08146959f5939f76ba0e189e6d6e300,filtered,semantic_scholar,,2014-01-01,semantic_scholar,blaze: building a foundation for array-oriented computing in python,https://www.semanticscholar.org/paper/4da301bdd08146959f5939f76ba0e189e6d6e300,"We present the motivation and architecture of Blaze, a library for cross-backend data-oriented computation. Blaze provides a standard interface to connect users familiar with NumPy and Pandas to other data analytics libraries like SQLAlchemy and Spark. We motivate the use of these projects through Blaze and discuss the benefits of standard interfaces on top of an increasingly varied software ecosystem. We give an overview of the Blaze architecture and then demonstrate its use on a typical problem. We use the abstract nature of Blaze to quickly benchmark and compare the performance ofnature of Blaze to quickly benchmark and compare the performance of a variety of backends on a standard problem.",data oriented architecture,93
633e38c9b0b59ce507edda0ea8c44b4177f32844,filtered,semantic_scholar,2013 22nd International Conference on Computer Communication and Networks (ICCCN),2013-01-01,semantic_scholar,architectural blueprints of a unified sensing platform for the internet of things,https://www.semanticscholar.org/paper/633e38c9b0b59ce507edda0ea8c44b4177f32844,"The Internet of Things (IoT) is understood as a major embodiment of the convergence between device-oriented sensor networks and data-oriented applications that is facilitated through the Internet portfolio of technologies. From an architecture perspective, the wide range of operational parameters entailed by multiple application domains myriads of combinations of sensors and applications is the most significant challenge brought on by the IoT vision. To this end, the design blueprint of a platform that enables the seamless integration of multiple dissimilar devices and their efficient use by independently contributed applications is an essential architecture concern. Herein we address this concern by introducing a Unified Sensing Platform (USP) designed to accommodate an open set of sensor types and to expose their functional capabilities to applications in an efficient, reusable and context-aware way.",data oriented architecture,94
48d9424e505f7be05ff74d68229fcf96c00929e0,filtered,semantic_scholar,Bell Labs Technical Journal,2000-01-01,semantic_scholar,the enhanced service manager: a service management system for next-generation networks,https://www.semanticscholar.org/paper/48d9424e505f7be05ff74d68229fcf96c00929e0,"In this paper, we describe a service management product, the Enhanced Service Manager (eSM), that provides not only fast service development and easy maintenance but also performance, reliability, and Web-enabled provisioning. Competition is fierce in the business world, especially in telecommunications. Being first to offer a service is typically a key decision-making factor for service providers in selecting an operations support system product to manage their services. Furthermore, we have seen the operations network landscape evolving from switch-based to intelligent network-oriented services and from circuit-based to more data-oriented networks. This paper illustrates how open architecture elements such as Common Object Request Broker Architecture (CORBA∗), Extensible Markup Language (XML), and Java∗/JavaServer Pages∗ (JSP∗) technology have been woven with off-the-shelf components into a product designed to meet current business needs. We discuss our architectural approach as well as a future direction.",data oriented architecture,95
98dd6400d25ba55c5de74689bfd7056300155b76,filtered,semantic_scholar,"2014 IEEE 10th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",2014-01-01,semantic_scholar,integration between terrestrial and satellite networks: the ppdr-tc vision,https://www.semanticscholar.org/paper/98dd6400d25ba55c5de74689bfd7056300155b76,"Wireless communication technologies are critical for public protection and disaster relief (PPDR) professionals during the emergency operations that follow natural or man-made disasters, scenarios in which commercial terrestrial networks often fail to provide the necessary support. The reason is threefold: they simply get disrupted by the disaster, they cannot sustain the sudden surge of network demand or they fail to deliver the necessary bandwidth and/or other QoS guarantees. In every PPDR operation reliable voice communications are critical, especially in the very early stages of the response; nevertheless, there is an increasing demand from the PPDR community for a wider range of data-centric services. While current technologies used for PPDR operations provide a rich set of voice-centric services, they are unable to sustain high-bandwidth data-oriented applications. As the PPDR-TC EU consortium, we propose a hybrid approach to tackle the question of determining the future architecture for Pan-European PPDR networks based on the integration of Terrestrial and Satellite technologies, presenting our first simulation results on the integration of LTE and Satellite Networks.",data oriented architecture,96
eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,filtered,semantic_scholar,2009 Seventh Annual Communication Networks and Services Research Conference,2009-01-01,semantic_scholar,optical access-metro network architecture based on passive access and burst-mode transmission,https://www.semanticscholar.org/paper/eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,"A network architecture that integrates several WDM PON access segments in a metropolitan area network and uses optical circuit/burst switching is presented here. This architecture targets the delivery of very high speed end to end optical communications between the edge nodes connecting the end users. The combination of circuit switching and burst transmission allows the simultaneous delivery of real-time applications (VoIP, Video) and other data-oriented applications (Internet, peer-to-peer). In the proposed architecture there is a clear separation of the functions in data plane and a control plane. A centralized control entity manages the overall architecture. A dedicated aggregation node acts as a gateway to external networks. After a presentation of the proposed network architecture, this paper focuses on the performance evaluation of the control plane using simulation. Our results show that the queuing delay remains acceptable even under heavy traffic loads.",data oriented architecture,97
fbc77d8f579858a0c92a8843e175f825229f3cca,filtered,semantic_scholar,2012 Second Symposium on Network Cloud Computing and Applications,2012-01-01,semantic_scholar,cloud computing for global name-resolution in information-centric networks,https://www.semanticscholar.org/paper/fbc77d8f579858a0c92a8843e175f825229f3cca,"Information-Centric Networking (ICN) is a novel paradigm for future Internet architectures. It exploits the current trend in Internet usage which mostly involves information dissemination. ICN architectures based on the publish/subscribe model use names for information in order to route requests and data, as well as to facilitate in-network caching, anycasting and multicasting for efficient content delivery. However, the number of named information objects is expected to be huge in the future Internet, raising serious concerns with respect to a global-scale deployment of ICN. Routing and forwarding will require vast amounts of state, which pushes storage, maintenance and processing demands to the limit. In this paper we discuss the feasibility of deploying the Data Oriented Networking Architecture (DONA) by leveraging cloud computing facilities. We identify the exact scalability concerns for DONA based on simulations over a realistic model of the current Internet topology and find that registrations for information objects lead to a state explosion. For this reason, we then discuss how cloud facilities can assist DONA deployment, focusing on various options for deploying DONA in the cloud and their suitability for different areas of the inter-network.",data oriented architecture,98
f925f3d29d9161514719651dd16a7310e051d56b,filtered,semantic_scholar,2005 Asia-Pacific Conference on Communications,2005-01-01,semantic_scholar,a conceptual architecture for adaptation in remote desktop systems driven by the user perception of multimedia,https://www.semanticscholar.org/paper/f925f3d29d9161514719651dd16a7310e051d56b,Current thin-client remote desktop systems were designed for data-oriented applications over low-quality LAN links and they do not provide satisfactory end-user performance in enterprise environment for more and more popular graphical and multimedia applications. To improve perception of those applications in thin-client environment we propose architecture of a server-side quality of service (QoS) management component responsible for mapping application QoS requirements into network QoS. We analyze how service differentiation and traffic management techniques combined with user perception monitoring can be used in order to adjust network level resource allocation when performance of multimedia applications in remote desktop environment is not meeting user requirements. Our objective is to provide QoS-aware remote desktop systems which will be able to manage available resources in intelligent manner and meet end-user performance expectations,data oriented architecture,99
13acc27d419769500af8c3b0d04ad065402f816e,filtered,semantic_scholar,ISPRS Int. J. Geo Inf.,2018-01-01,semantic_scholar,hibuffer: buffer analysis of 10-million-scale spatial data in real time,https://www.semanticscholar.org/paper/13acc27d419769500af8c3b0d04ad065402f816e,"Buffer analysis, a fundamental function in a geographic information system (GIS), identifies areas by the surrounding geographic features within a given distance. Real-time buffer analysis for large-scale spatial data remains a challenging problem since the computational scales of conventional data-oriented methods expand rapidly with increasing data volume. In this paper, we introduce HiBuffer, a visualization-oriented model for real-time buffer analysis. An efficient buffer generation method is proposed which introduces spatial indexes and a corresponding query strategy. Buffer results are organized into a tile-pyramid structure to enable stepless zooming. Moreover, a fully optimized hybrid parallel processing architecture is proposed for the real-time buffer analysis of large-scale spatial data. Experiments using real-world datasets show that our approach can reduce computation time by up to several orders of magnitude while preserving superior visualization effects. Additional experiments were conducted to analyze the influence of spatial data density, buffer radius, and request rate on HiBuffer performance, and the results demonstrate the adaptability and stability of HiBuffer. The parallel scalability of HiBuffer was also tested, showing that HiBuffer achieves high performance of parallel acceleration. Experimental results verify that HiBuffer is capable of handling 10-million-scale data.",data oriented architecture,100
dc9df4822e7e894c8da4b936599be6cffb17ea29,filtered,semantic_scholar,,1998-01-01,semantic_scholar,hoss: an environment to support structural computing,https://www.semanticscholar.org/paper/dc9df4822e7e894c8da4b936599be6cffb17ea29,"There have been two distinct trends in hypermedia work over the last decade. One has concerned the construction of increasingly more powerful infrastructure for the support of open hypermedia navigation systems, while the other has concerned the application of hypermedia technologies and concepts to increasingly diverse domains. This dissertation addresses how these trends can be merged, resulting in a framework for design of powerful, general infrastructure. 
An examination of the domains to which hypermedia concepts have been applied yields to the conclusion that all rely on general structure and general structural computation. A philosophy of computation is presented called structural computing that stresses the primacy of these concepts. Without such a philosophy, structure is seen as an ad hoc functionality to be added over data-oriented programs. Different structure-oriented domains are seen as special cases of navigational hypertext, with a corresponding confusion of basic terminologies. 
An analysis of the historical development of hypermedia systems leads to the conclusion that current open hypermedia systems can be modified in a straightforward way to support structural computing by opening the link server layer in traditional hypermedia architectures. The resultant generalized link server is called a structure processor (Sproc). Different Sprocs encapsulate tailoring and extension of the structure and structural computation models provided by the structure store of the system. 
A conceptual architecture for an environment to support structural computing (named HOSS) is presented. This architecture is divided into two parts. The operating system layer describes the basic services available to all HOSS programs. The computing environment layer consists of an open set of programs that run address specific structural computing domains. A prototypic implementation of the operating system layer and several example computing environment layer programs is described, which provides a proof of concept of the structural computing environment architecture presented. The sample programs substantiate the claims that such an environment can support the design and implementation of a wide variety of structural computing programs. 
The dissertation concludes with an evaluation of the philosophy of structural computing and the design and implementation of HOSS, a description of directions for possible future work, and conclusions.",data oriented architecture,101
71486129fd8ca17e9ae2fbdef984f82dac85d1c3,filtered,semantic_scholar,,1994-01-01,semantic_scholar,analyzing and tuning memory performance in sequential and parallel programs,https://www.semanticscholar.org/paper/71486129fd8ca17e9ae2fbdef984f82dac85d1c3,"Recent architecture and technology trends have led to a significant gap between processor and main memory speeds. Responding to this gap, architects have introduced cache memories that are placed between processors and memories to mask high latencies. If cache misses are common, however, memory stalls can still significantly degrade execution time. To help identify and fix such memory bottlenecks, this work presents techniques to efficiently collect detailed information about program memory performance and effectively organize the data collected. These techniques help guide programmers or compilers to memory bottlenecks. They apply to both sequential and parallel applications and are embodied in the MemSpy performance monitoring system. 
Experiences performance tuning several programs have driven this research, leading to the following conclusions. First, this thesis contends that the natural interrelationship between program memory bottlenecks and program data structures mandates the use of data oriented statistics, a novel approach that associates program performance information with application data structures. Data oriented statistics, viewed alone or paired with traditional code oriented statistics, offer a powerful, new dimension for performance analysis. The dissertation develops techniques for aggregating statistics on similarly-used data structures and for extracting intuitive source-code names for statistics. 
Second, this thesis also argues that detailed statistics on the frequency and causes of cache misses are crucial in understanding memory bottlenecks. Common memory performance bugs are most easily distinguished by noting the causes of their resulting cache misses. Offering such information, MemSpy's performance profiles have been invaluable in analyzing memory bottlenecks in several applications. 
Third, since collecting such detailed information seems, at first glance, to require large execution time slowdowns, this dissertation also evaluates techniques to improve the performance of MemSpy's simulation-based monitoring. The first optimization, hit bypassing, improves simulation performance by specializing processing of cache hits. The second optimization, reference trace sampling, improves performance by simulating only sampled portions out of the full reference trace. Together, these optimizations reduce simulation time by nearly an order of magnitude. Overall, having used MemSpy to tune several applications, these experiences demonstrate that MemSpy generates effective memory performance profiles, at speeds competitive with previous, less detailed approaches.",data oriented architecture,102
6de34e4976ac5e1382d41a5e2f05b13eac8c4ec0,filtered,semantic_scholar,Applied Sciences,2018-01-01,semantic_scholar,a big data and time series analysis technology-based multi-agent system for smart tourism,https://www.semanticscholar.org/paper/6de34e4976ac5e1382d41a5e2f05b13eac8c4ec0,"This study focuses on presenting a development trend from the perspective of data-oriented evidence, especially open data and technologies, as those numbers can verify and prove current technology trends and user information requirements. According to the practical progress of Dr. What-Info I and II, this paper continues to develop Dr. What-Info III. Moreover, big data technology, the MapReduce paralleled decrement mechanism of the cloud information agent CEOntoIAS, which is supported by a Hadoop-like framework, Software R, and time series analysis are adopted to enhance the precision, reliability, and integrity of cloud information. Furthermore, the proposed system app receives a collective satisfaction score of 80% in terms of Quesenbery’s 5Es and Nielsen ratings. In addition, the verification results of the interface design show that the human-machine interface of our proposed system can meet important design preferences and provide approximately optimal balance. The top-n experiment shows that the top-5 recommendations would be better for solving the traditional tradeoff between output quality and processing time. Finally, the system effectiveness experiments indicate that the proposed system receives an overall up-to-standard function rate of 87.5%, and such recommendations provide this system with high information correctness and user satisfaction. Although there is plenty of room for improvement in experience, the feasibility of this service architecture has been proven.",data oriented architecture,103
3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,filtered,semantic_scholar,EMISA,2006-01-01,semantic_scholar,challenges and solutions in planning information systems for networked value constellations,https://www.semanticscholar.org/paper/3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,"Nowadays businesses often decide to form networked value constellations in order to satisfy complex customer needs. To fulfill the value-based requirements of an e-Business idea and to realize the coordination of such a multi-actor network an adequate underlying information systems architecture has to be conceptualized. This paper discusses the applicability of classical information system planning approaches, such as Information Engineering to cross-organizational settings expressed
through value-based requirements. On the basis of this analysis several requirements for the enhancement and adaptation of Information Engineering-like methodologies
for e-Business ideas are defined for the purpose of enabling alignment between a value-based business context and the information systems architecture in a networked environment.
The paper proposes a way to derive data-orientation from value-orientation,
i.e. an enterprise model from a value model. This in turn enables afterwards the
straightforward use of traditional data-oriented techniques for value-based business
models.",data oriented architecture,104
3e40b11fef094fde5e02abfad618797658e2d867,filtered,semantic_scholar,DATA,2015-01-01,semantic_scholar,decision support system for implementing data quality projects,https://www.semanticscholar.org/paper/3e40b11fef094fde5e02abfad618797658e2d867,"The new data-oriented shape of organizations inevitably imposes the need for the improvement of their data quality (DQ). In fact, growing data quality initiatives are offering increased monetary and non-monetary benefits for organizations. These benefits include increased customer satisfaction, reduced operating costs and increased revenues. However, regardless of the numerous initiatives, there is still no globally accepted approach for evaluating data quality projects in order to build the optimal business cases taking into account the benefits and the costs. This paper presents a model to clearly identify the opportunities for increased monetary and non-monetary benefits from improved data quality within an Enterprise Architecture context. The aim of this paper is to measure, in a quantitative manner, how key business processes help to execute an organization’s strategy and then to qualify the benefits as well as the complexity of improving data, that are consumed and produced by these processes. These findings will allow to select data quality improvement projects, based on the latter’s benefits to the organization and their costs of implementation. To facilitate the understanding of this approach, a Java EE Web application is developed and presented here.",data oriented architecture,105
b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,filtered,semantic_scholar,Defense + Security,2016-01-01,semantic_scholar,icrowd: agent-based behavior modeling and crowd simulator,https://www.semanticscholar.org/paper/b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,"Initially designed in the context of the TASS (Total Airport Security System) FP-7 project, the Crowd Simulation platform developed by the Integrated Systems Lab of the Institute of Informatics and Telecommunications at N.C.S.R. Demokritos, has evolved into a complete domain-independent agent-based behavior simulator with an emphasis on crowd behavior and building evacuation simulation. Under continuous development, it reﬂects an eﬀort to implement a modern, multithreaded, data-oriented simulation engine employing latest state-of-the-art programming technologies and paradigms. It is based on an extensible architecture that separates core services from the individual layers of agent behavior, oﬀering a concrete simulation kernel designed for high-performance and stability. Its primary goal is to deliver an abstract platform to facilitate implementation of several Agent-Based Simulation solutions with applicability in several domains of knowledge, such as: (i) Crowd behavior simulation during [in/out] door evacuation. (ii) Non-Player Character AI for Game-oriented applications and Gamiﬁcation activities. (iii) Vessel traﬃc modeling and simulation for Maritime Security and Surveillance applications. (iv) Urban and Highway Traﬃc and Transportation Simulations. (v) Social Behavior Simulation and Modeling.",data oriented architecture,106
54aea761600684eea98b8d38c1ce972ba1f38888,filtered,semantic_scholar,Euro-Par,2017-01-01,semantic_scholar,partitioning strategy selection for in-memory graph pattern matching on multiprocessor systems,https://www.semanticscholar.org/paper/54aea761600684eea98b8d38c1ce972ba1f38888,"Pattern matching on large graphs is the foundation for a variety of application domains. The continuously increasing size of the underlying graphs requires highly parallel in-memory graph processing engines that need to consider non-uniform memory access (NUMA) and concurrency issues to scale up on modern multiprocessor systems. To tackle these aspects, a fine-grained graph partitioning becomes increasingly important. Hence, we present a classification of graph partitioning strategies and evaluate representative algorithms on medium and large-scale NUMA systems in this paper. As a scalable pattern matching processing infrastructure, we leverage a data-oriented architecture that preserves data locality and minimizes concurrency-related bottlenecks on NUMA systems. Our in-depth evaluation reveals that the optimal partitioning strategy depends on a variety of factors and consequently, we derive a set of indicators for selecting the optimal partitioning strategy suitable for a given graph and workload.",data oriented architecture,107
d20ee34db8deda89ad3c93786a3bcf780d67d608,filtered,semantic_scholar,,2005-01-01,semantic_scholar,specifying and verifying hysteresis signature system with hol-z,https://www.semanticscholar.org/paper/d20ee34db8deda89ad3c93786a3bcf780d67d608,"We report on a case-study in using the data-oriented modeling language Z to formalize a security architecture for administering digital signatures and its architectural security requirements. Within an embedding of Z in the higher-order logic Isabelle/HOL, we provide formal machine-checked proofs of the correctness of the architecture with respect to its requirements. A formalization and verification of the same architecture has been previously carried out using the process-oriented modeling language PROMELA and the SPIN model checker. We use this as a basis for comparing these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking).",data oriented architecture,108
2cfdabf9a66841e368c45e15d9f65e1f576bb7c1,filtered,semantic_scholar,,2002-01-01,semantic_scholar,formal reasoning about real-time components on a data-oriented architecture,https://www.semanticscholar.org/paper/2cfdabf9a66841e368c45e15d9f65e1f576bb7c1,"We investigate an approach towards formal reasoning about component-based software architecture. In this paper we develop specification schemes for real-time applications which interact via the data-oriented software architecture SPLICE. Composition of these applications requires not only knowledge about the component specifications, but also information about key parameters of the underlying communication mechanism. We formulate a proof scheme for the interaction of data-oriented components, and illustrate its use with an example of a flight-tracking-anddisplay system.",data oriented architecture,109
92229332f42836d60c1977fd26dfff630853d401,filtered,semantic_scholar,,1998-01-01,semantic_scholar,"requirement capture, formal description and verification of an invoicing system",https://www.semanticscholar.org/paper/92229332f42836d60c1977fd26dfff630853d401,"The Invoicing case study is a typical business system proposed by Henri Habrias as a common example for a contest on the capacity of particular formal methods to capture requirements from the client. For this, the case study is informally described by half a page of English text. In this report, we use the formal description technique LOTOS for requirement capture, formal description and verification of the Invoicing case study. First, we analyse and interpret the informal requirements of the case study using the LOTOS approach for description of systems. This leads to a set of twenty questions about the informal description. By answering to these questions, we obtain a high-level specification architecture that can be formalised. Then, we present the formal description of the case study in LOTOS and, for comparison, in E-LOTOS, the new version of LOTOS currently being standardized. Since LOTOS allows a balance to be struck between process-oriented and data-oriented modeling, descriptions in both styles are given. After that, we verify the LOTOS descriptions by model-checking using the CADP (CAESAR/ALDEBARAN) toolbox. The underlying Labelled Transition System (LTS) models corresponding to various scenarios are generated using the CAESAR compiler. We push further the analysis of the case study by formalizing in temporal logic six properties of the system. We verify these properties on the LTS models using the XTL model-checker. Finally, we study the equivalence of the process-oriented and data-oriented descriptions using the ALDEBARAN tool.",data oriented architecture,110
060477ed830f344a2e012aff637bb21b33e492c5,filtered,semantic_scholar,,2007-01-01,semantic_scholar,closer to the edge,https://www.semanticscholar.org/paper/060477ed830f344a2e012aff637bb21b33e492c5,"The next generation of distributed systems will be loosely-coupled systems that: support incremental and independent development, and are tolerant of interface changes; can systematically deal with impedance mismatches; and work well in dynamically changing realtime situations; and can scale in complexity while delivering the required real-time performance. Popular architectural styles, including data flow architecture, event driven architecture and service-oriented architecture, can be regarded as special cases, by the appropriate assignment of roles and choice of quality of service in the interfaces between components. Data-oriented application architecture coupled with an appropriate standards based messaging software bus such as DDS can cut down the complexity of the integration problem from O(N*N) to O(N), while preserving loose-coupling and ensuring scalability. Having readily available middleware infrastructure bridges for popular application platform components can greatly boost productivity and the pace of integration.",data oriented architecture,111
7261028c80d1ac82828f26c46318557a50c42176,filtered,semantic_scholar,,2007-01-01,semantic_scholar,biofederator: a data federation system for bioinformatics on the web,https://www.semanticscholar.org/paper/7261028c80d1ac82828f26c46318557a50c42176,"A problem facing many bioinformatics researchers today is the aggregation and analysis of vast amounts of data produced by large scale projects from various laboratories around the world. Depositing such data into centralized web-based repositories (e.g. NCBI, UCSCGenome Browser) is the common approach. However, the distributed nature of the data, its growth rate, and increased collaborative needs represent real challenges calling for novel decentralized web architectures. The BioFederator is a web services-based data federation architecture for bioinformatics applications. Based on collaborations with bioinformatics researchers, several domainspecific data federation challenges and needs are identified. The BioFederator addresses such challenges and provides an architecture that incorporates a series of utility services. These address issues like automatic workflow composition, domain semantics, and the distributed nature of the data. It also incorporates a series of data-oriented services that facilitate the actual integration of data. The BioFederator is deployed on a grid environment over the web. The proposed design, services, and usage scenarios are discussed in detail. We demonstrate how our architecture can be leveraged for a real-world bioinformatics problem involving tissue specificity of gene expression.",data oriented architecture,112
52c5ec6acd2dfb2194ec655bd695474f76876754,filtered,semantic_scholar,,2003-01-01,semantic_scholar,when theory meets practice: building traffic control systems made easy,https://www.semanticscholar.org/paper/52c5ec6acd2dfb2194ec655bd695474f76876754,"Two separate road developments in traffic management in the Netherlands have been the Motorway Traffic Control Architecture (MTCA) and the implementation of data-oriented middleware by Trinite in the first Traffic Management Centre in the Netherlands. The move towards integration in different systems at the traffic management level is described. The principles behind the MTCA are outlined. The architecture had to offer a framework for existing and future traffic control (TC) measures, to adopt an infrastruture-oriented approach and the different parts had to be integrated. Measures are controlled by so-called Traffic Controls, software components that are based on the composite design pattern. The programmable distributed architecture developed by Trinite is the platform on which Traffic Controls are realised in the software. The implementation of an infrastructural system with Traffic Controls involves determining the information needs, adding information elements and adding functionality.",data oriented architecture,113
44f46dbb8eec8fb695e7008b1e3d4f5ef467305f,filtered,semantic_scholar,ICCSP,2019-01-01,semantic_scholar,the study of data-oriented and ownership-based security architecture in open internet environment,https://www.semanticscholar.org/paper/44f46dbb8eec8fb695e7008b1e3d4f5ef467305f,"DOSA (Data-Oriented Security Architecture, or Data Ownership-based Security Architecture) is an architecture for data protection and application in an open Internet environment. DOSA combines data with ownership by using digital certification authentication (CA) and public key infrastructure (PKI). The DOSA is simply described as one body with two wings. The one body is that the data must be combined with ownership. The one wing is that the data should be innately registered. Another wing is that the data should be innately encrypted with the data owner's public key. To share data and make data applicable, DOSA also establishes the authorization of data ownership for data sharing, the recording of data operation for data history tracing, the data behaviour analysis for the discovery of illegal use of data, and the data usage statistics for the assessment of data value, etc. Therefore, data can be securely shared and used in an open environment with ownership authorization. At the same time, data ownership is clarified; the interests of the data owner can be guaranteed.",data oriented architecture,114
c641fb970edff6345974c540394e94e2e58e6f67,filtered,semantic_scholar,,2014-01-01,semantic_scholar,high-performance big data management across cloud data centers,https://www.semanticscholar.org/paper/c641fb970edff6345974c540394e94e2e58e6f67,"The easily-accessible computation power offered by cloud infrastructures coupled with the revolution of Big Data are expanding the scale and speed at which data analysis is performed. The cloud resources for computation and storage are spread among globally distributed data centers. Enabling fast data transfers in such scenarios becomes particularly important for scientific applications for which moving the processing close to data is rather expensive or not feasible (e.g. genome mapping, high-energy physics simulations, large sensors network). Analyzing how clouds can become “Big Data - friendly”, and what are the best options to provide data-oriented cloud services to address applications needs are the key goals of this thesis. In this talk, we present our contributions for providing high performance data management for applications running across multiple cloud data centers. We start by focusing on the scalability aspects of single-site processing and show how the MapReduce model can be extended across multi-sites. Next, we present a transfer service architecture that enables configurable cost-performance optimizations for inter-site transfers. This transfer scheme is then leveraged in the context of real-time streaming across cloud data centers. Finally, we investigate the viability of leveraging this data movement solution as a cloud-provided service, following a Transfer-as-a-Service paradigm based on a flexible pricing scheme.",data oriented architecture,115
354cc746560319b71c63ef2d994a095e72ddc5da,filtered,semantic_scholar,,2012-01-01,semantic_scholar,development a prototype of academic performance among university students,https://www.semanticscholar.org/paper/354cc746560319b71c63ef2d994a095e72ddc5da,"In the modern world the power of communication through internet has been dramatically increased. New technology with new concept is well envisioned to effect the end users in the form of providing data oriented services. Through an effective management of information the accuracy of the information would be increased which will increase the academic performance of the university students. Usually the new WAP technology is very popularly used by the architecture students to make the work effective. Two surveys were conducted to know the students limitations for the performance and to know the system usability which could improve academic performance. The development of the project is based on the SDLC in Object-Oriented approaches and takes UML as the modeling system while the development of the system uses WAPTOR and mobile explorer language. Due to the time constraint, this project does not fully complete its functionality as shown in the prototype. Therefore, it is recommended that future research to be carried out in order to enhance and expand the service of the application by taking this prototype as a starting point of the development.",data oriented architecture,116
26c3b18f7a5ee7adee14245654e887d728a8570b,filtered,semantic_scholar,,2018-01-01,semantic_scholar,on efficient data exchange in multicore architectures,https://www.semanticscholar.org/paper/26c3b18f7a5ee7adee14245654e887d728a8570b,"In contemporary multicore architectures, three trends can be observed: (i) A growing number of cores, (ii) shared memory as the primary means of communication and data exchange and (iii) high diversity between platform architectures. Still, these platforms are typically programmed manually on a core-by-core basis; the most helpful tool that is widely accepted are library implementations of frequently used algorithms. This complicated task of multicore programming will grow further in complexity with the increasing numbers of cores. In addition, the constant change in architecture designs and thus in platform-specific programming demands will continue to make it laborious to migrate existing code to new platforms. State-of-the-art methods of automatic multicore code generation only partially meet the requirements of modern multicore platforms. They typically have a high overhead for different threads when growing numbers of cores and thus shrinking thread granularities demand the opposite. Also, they typically use message passing models for implementing data exchange when memory sharing should be the natural mode of data exchange. As a result, they often fail to produce efficient code, especially when large data throughput is required. This thesis proposes a data-oriented approach to multicore programming. It shows how dividing a program into discrete tasks with clearly specified inputs and outputs helps to formalise the problem of optimising high data throughput applications for a large range of multicore architectures, at the same time enabling an efficient, low-overhead implementation. In detail, its contributions are as follows. • Inefficiencies in existing programming models are demonstrated for the cases of the CAL actor language and Kahn process networks. Methods are shown to reduce these inefficiencies. • Ladybirds, a specificationmodel and language for parallel programs is presented. A Ladybirds program consists of a tasks with clearly defined inputs and outputs and of dependencies between them. It is explained how Ladybirds aims at execution efficiency also in the domains of data placement and transport and what steps are necessary to get from a Ladybirds specification to executable program code.The examples of comfortable debugging and ofminimising state retention overhead for transient systems underline the usability and versatility of Ladybirds. • An optimisation method for Ladybirds programs on the Kalray MPPA platform is presented. It tries to place data on different memory banks such as to avoid access conflicts. Afterwards, the Ladybirds optimisation problem for",data oriented architecture,117
09d08d03be2e49b58e2888b5d5b0e3a38cfb1305,filtered,semantic_scholar,IEEE Communications Magazine,2010-01-01,semantic_scholar,end-to-end flexible transport service provisioning in inter-csp environments [next-generation telco it architectures],https://www.semanticscholar.org/paper/09d08d03be2e49b58e2888b5d5b0e3a38cfb1305,"Communication service providers deliver value-added services to customers based on their available network transport services. Some services extend beyond the boundaries of a single CSP and require the collaboration of several CSPs to provide inter-CSP services. Transport services for next-generation value-added services are currently based on expensive connection oriented technologies such as synchronous digital hierarchy and optical transport networks. Data-oriented technologies have recently been considered for transport networks (e.g., Ethernet and MPLS variants) due to their efficiency, simplicity, and better suitability for data traffic, which dominates the transport networks. Currently, CSP transport networks are isolated and inter-CSP transport service provisioning involves human-to-human negotiations and manual setup of network devices. Next-generation CSPs must provide QoS intra-service-to-customer, inter-CSP, and customer-to-customer transport services that are generic, automatically provisioned, and based on business logic that can be expressed easily and uniformly. A transport service layer architecture for automatic provisioning of inter-CSP transport services is suggested here, based on standard Ethernet technology. This transport service layer architecture is part of the Ethernet transport network architecture that takes into account business relations among carriers. It enables various class-of-service transport services based on multi-constraint matching and optimizations. The resulting transport service provisioning is automated and optimized, and significantly decreases the involved inter-CSP service setup operations.",data oriented architecture,118
d4d7701d4fdebddccef04ba1a2715820fffdfb10,filtered,semantic_scholar,Workshop on Information Integration on the Web,2001-01-01,semantic_scholar,"data-driven, xml-based web management in highly personalized environments",https://www.semanticscholar.org/paper/d4d7701d4fdebddccef04ba1a2715820fffdfb10,"In the domain of XML-based Web applications, sets of XML documents derived from heterogeneous data sources are to be managed. The deployment o XML offers a single and common data model which allows these sets to consider under a data-oriented perspective and to compose their elements to a single, logica XML document. The introduction of a logical representation of the underlying data by a so-called unified view enables comprehensive personalization and customization, because the document structure as well as its graphical presentation can be changed and adapted independently. The intention of this paper is to discuss the idea of building the unified view. Therefore, an overview of the corresponding architecture is given and basic strategies for the building process are presented.",data oriented architecture,119
d61555ba40f6c5a3f7bf36333534c1e28f8f62d9,filtered,semantic_scholar,ICA3PP,2009-01-01,semantic_scholar,a software transactional memory service for grids,https://www.semanticscholar.org/paper/d61555ba40f6c5a3f7bf36333534c1e28f8f62d9,"In-memory data sharing for grids allow location-transparent access to data stored in volatile memory. Existing Grid middlewares typ- ically support only explicit data transfer between Grid nodes. We be- lieve that Grid systems benefit from complementing traditional message- passing techniques with a data-oriented sharing technique. The latter includes automatic replica management, data consistency, and location- transparent access. As a proof of concept, we are implementing a POSIX- compatible object sharing service as part of the EU-funded XtreemOS project, which builds a Linux-based Grid operating system. In this paper we describe the software architecture of the object sharing service and design decisions including transactional consistency and peer-to-peer net- work structure. We also present preliminary evaluation results analyzing lower-bound transaction-overhead using a parallel raytracing application.",data oriented architecture,120
612b052ac49aefad99cb3153de691ba3a6c41057,filtered,semantic_scholar,Australian Conference on Artificial Intelligence,2004-01-01,semantic_scholar,"ai 2004: advances in artificial intelligence, 17th australian joint conference on artificial intelligence, cairns, australia, december 4-6, 2004, proceedings",https://www.semanticscholar.org/paper/612b052ac49aefad99cb3153de691ba3a6c41057,"Full Papers.- Agent-Based Evolutionary Labor Market Model with Strategic Coalition.- A Multiagent Architecture for Privacy-Preserving ID-Based Service in Ubiquitous Computing Environment.- Critical Damage Reporting in Intelligent Sensor Networks.- Landscape Dynamics in Multi-agent Simulation Combat Systems.- Safe Agents in Space: Lessons from the Autonomous Sciencecraft Experiment.- Bio-Discretization: Biometrics Authentication Featuring Face Data and Tokenised Random Number.- Cochlea Modelling: Clinical Challenges and Tubular Extraction.- Combining Bayesian Networks, k Nearest Neighbours Algorithm and Attribute Selection for Gene Expression Data Analysis.- Medical Image Vector Quantizer Using Wavelet Transform and Enhanced SOM Algorithm.- SVM Classification for Discriminating Cardiovascular Disease Patients from Non-cardiovascular Disease Controls Using Pulse Waveform Variability Analysis.- Adaptive Enhancing of Fingerprint Image with Image Characteristics Analysis.- Adaptive Image Classification for Aerial Photo Image Retrieval.- An Investigation into Applying Support Vector Machines to Pixel Classification in Image Processing.- Applying Image Pre-processing Techniques for Appearance-Based Human Posture Recognition: An Experimental Analysis.- A Stochastic Approach to Tracking Objects Across Multiple Cameras.- Caption Detection and Removal in a TV Scene.- Enhanced Importance Sampling: Unscented Auxiliary Particle Filtering for Visual Tracking.- Face Recognition Using Wavelet Transform and Non-negative Matrix Factorization.- Modelling-Alignment for Non-random Sequences.- Moments and Wavelets for Classification of Human Gestures Represented by Spatio-Temporal Templates.- Personal Authenticator on the Basis of Two-Factors: Palmprint Features and Tokenized Random Data.- Practical Gaze Point Computing Method by 3D Position Estimation of Facial and Eye Features.- A Classification of Ontology Modification.- Concept Type Hierarchy as Ontology: An Example Historical Knowledge Base.- A Dynamic Allocation Method of Basis Functions in Reinforcement Learning.- A Hybrid Classification Approach to Ultrasonic Shaft Signals.- A Landmarker Selection Algorithm Based on Correlation and Efficiency Criteria.- A Learning-Based Algorithm Selection Meta-Reasoner for the Real-Time MPE Problem.- A Novel Clustering Algorithm Based on Immune Network with Limited Resource.- A Novel Modeling and Recognition Method for Underwater Sound Based on HMT in Wavelet Domain.- BayesTH-MCRDR Algorithm for Automatic Classification of Web Document.- Classification Rule Mining with an Improved Ant Colony Algorithm.- Clustering Large Datasets Using Cobweb and K-Means in Tandem.- Cost-Sensitive Decision Trees with Multiple Cost Scales.- Effective Sampling for Mining Association Rules.- Improving the Centered CUSUMS Statistic for Structural Break Detection in Time Series.- Investigating ID3-Induced Rules from Low-Dimensional Data Cleaned by Complete Case Analysis.- Investigating Learning Parameters in a Standard 2-D SOM Model to Select Good Maps and Avoid Poor Ones.- Key Element Summarisation: Extracting Information from Company Announcements.- Knowledge Discovery Using Concept-Class Taxonomies.- Learning the Grammar of Distant Change in the World-Wide Web.- Mining Maximal Frequent ItemSets Using Combined FP-Tree.- Multinomial Naive Bayes for Text Categorization Revisited.- The Effect of Attribute Scaling on the Performance of Support Vector Machines.- Towards Efficient Imputation by Nearest-Neighbors: A Clustering-Based Approach.- Univariate and Multivariate Linear Regression Methods to Predict Interval-Valued Features.- Using Classification to Evaluate the Output of Confidence-Based Association Rule Mining.- Analyzing the Effect of Query Class on Document Retrieval Performance.- Combined Word-Spacing Method for Disambiguating Korean Texts.- Extraction of Shallow Language Patterns: An Approximation of Data Oriented Parsing.- Improving the Presentation of Argument Interpretations Based on User Trials.- Reliable Unseen Model Prediction for Vocabulary-Independent Speech Recognition.- Voice Code Verification Algorithm Using Competing Models for User Entrance Authentication.- A Logic Based Approach for Dynamic Access Control.- A New Neighborhood Based on Improvement Graph for Robust Graph Coloring Problem.- An Extension of the H-Search Algorithm for Artificial Hex Players.- Applying Constraint Satisfaction Techniques to 3D Camera Control.- Constraints from STRIPS - Preliminary Report.- Embedding Memoization to the Semantic Tree Search for Deciding QBFs.- On Possibilistic Case-Based Reasoning for Selecting Partners in Multi-agent Negotiation.- Set Bounds and (Split) Set Domain Propagation Using ROBDDs.- User Friendly Decision Support Techniques in a Case-Based Reasoning System.- Longer-Term Memory in Clause Weighting Local Search for SAT.- Natural Landmark Based Navigation.- A Novel Approach for Simplifying Neural Networks by Identifying Decoupling Inputs.- Aggregation of Foraging Swarms.- An ACO Algorithm for the Most Probable Explanation Problem.- Designing a Morphogenetic System for Evolvable Hardware.- Evaluation of Evolutionary Algorithms for Multi-objective Train Schedule Optimization.- Fuzzy Modeling Incorporated with Fuzzy D-S Theory and Fuzzy Naive Bayes.- Genetic Algorithm Based K-Means Fast Learning Artificial Neural Network.- Immune Clonal Selection Network.- Performance Improvement of RBF Network Using ART2 Algorithm and Fuzzy Logic System.- Solving Rotated Multi-objective Optimization Problems Using Differential Evolution.- Sub-structural Niching in Non-stationary Environments.- Suitability of Two Associative Memory Neural Networks to Character Recognition.- Using Loops in Genetic Programming for a Two Class Binary Image Classification Problem.- Short Papers.- A Negotiation Agent.- Agent Services-Driven Plug-and-Play in F-TRADE.- Applying Multi-medians Location and Steiner Tree Methods into Agents Distributed Blackboard Architecture Construction.- Meta-game Equilibrium for Multi-agent Reinforcement Learning.- A Fast Visual Search and Recognition Mechanism for Real-Time Robotics Applications.- Adaptive Object Recognition with Image Feature Interpolation.- Effective Approach for Detecting Digital Image Watermarking via Independent Component Analysis.- Extended Locally Linear Embedding with Gabor Wavelets for Face Recognition.- Image Processing of Finite Size Rat Retinal Ganglion Cells Using Multifractal and Local Connected Fractal Analysis.- The DSC Algorithm for Edge Detection.- A Novel Statistical Method on Decision Table Analysis.- An Interaction Model for Affect Monitoring.- Ontology Transformation in Multiple Domains.- A Bayesian Metric for Evaluating Machine Learning Algorithms.- A Comparison of Text-Categorization Methods Applied to N-Gram Frequency Statistics.- A Global Search Algorithm for Attributes Reduction.- A Symbolic Hybrid Approach to Face the New User Problem in Recommender Systems.- A Toolbox for Learning from Relational Data with Propositional and Multi-instance Learners.- An Improvement to Unscented Transformation.- Automatic Wrapper Generation for Metasearch Using Ordered Tree Structured Patterns.- Building a More Accurate Classifier Based on Strong Frequent Patterns.- Color Texture Analysis Using Wavelet-Based Hidden Markov Model.- Contributions of Domain Knowledge and Stacked Generalization in AI-Based Classification Models.- Discovering Interesting Association Rules by Clustering.- Exploiting Maximal Emerging Patterns for Classification.- Feature Extraction for Learning to Classify Questions.- Mining Exceptions in Databases.- MML Inference of Oblique Decision Trees.- Naive Bayes Classifiers That Perform Well with Continuous Variables.- On Enhancing the Performance of Spam Mail Filtering System Using Semantic Enrichment.- Parameterising Bayesian Networks.- Radar Emitter Signal Recognition Based on Feature Selection Algorithm.- Selecting Subspace Dimensions for Kernel-Based Nonlinear Subspace Classifiers Using Intelligent Search Methods.- Using Machine Learning Techniques to Combine Forecasting Methods.- Web Data Mining and Reasoning Model.- A Framework for Disambiguation in Ambiguous Iconic Environments.- An Intelligent Grading System for Descriptive Examination Papers Based on Probabilistic Latent Semantic Analysis.- Domain-Adaptive Conversational Agent with Two-Stage Dialogue Management.- Feature Extraction Based on Wavelet Domain Hidden Markov Tree Model for Robust Speech Recognition.- Feature Unification and Constraint Satisfaction in Parsing Korean Case Phenomena.- A Comparison of BDI Based Real-Time Reasoning and HTN Based Planning.- A Formal Method Toward Reasoning About Continuous Change.- A Time and Energy Optimal Controller for Mobile Robots.- Inheritance of Multiple Identity Conditions in Order-Sorted Logic.- A Comparative Analysis of Fuzzy System Modelling Approaches: A Case in Mining Medical Diagnostic Rules.- A Parallel Learning Approach for Neural Network Ensemble.- An Intelligent Gas Concentration Estimation System Using Neural Network Implemented Microcontroller.- Ant Colonies Discover Knight's Tours.- Immune Clonal Selection Algorithm for Multiuser Detection in DS-CDMA Systems.- Intrusion Detection Based on Immune Clonal Selection Algorithms.- Mapping Dryland Salinity Using Neural Networks.- Normalized RBF Neural Network for Real-Time Detection of Signal in the Noise.- Statistical Exploratory Analysis of Genetic Algorithms: The Influence of Gray Codes upon the Difficulty of a Problem.- The Semipublic Encryption for Visual Cryptography Using Q'tron Neural Networks.- The T-Detectors Maturation Algorithm Based on Genetic Algorithm.",data oriented architecture,121
60881ba191ac396c88bf081b940b547c51d1b5b0,filtered,semantic_scholar,,1999-01-01,semantic_scholar,a scalable service architecture for computer-telephony integration,https://www.semanticscholar.org/paper/60881ba191ac396c88bf081b940b547c51d1b5b0,"The convergence of traditional voice-oriented telecommunications networks and data-oriented computer communications networks is yielding new challenges for building systems equally adept at handling voice and data applications. While there is much discussion about packetized voice over IP networks, a little explored opportunity is the ability to more easily deploy innovative new services based on the Internet’s client-server paradigm and the ease with which software agents can be introduced and migrated around the network. We discuss our new architecture for middleware services that more effectively enables the integration of telephone and data application. This horizontally-integrated architecture supports competition between interchangeable service implementations, based upon features, cost, etc. It is characterized by pervasive and seamless access across multiple cascaded networks. We describe our experiences in integrating an Internet-based core with cellular and other access networks, and our analysis of IP performance in this testbed using a graphical multi-layer protocol analysis tool. Based on our architecture, we have developed prototype converged applications for voice-actuated room control and personal “universal in-box” information management.",data oriented architecture,122
c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,filtered,semantic_scholar,"2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools",2009-01-01,semantic_scholar,run-time reconfigurable array using magnetic ram,https://www.semanticscholar.org/paper/c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,"This paper presents the implementation of a coarse-grained Magnetic RAM based Reconfigurable Array. The Reconfigurable Array architecture is organized as a one- dimensional array of programmable ALU, with the configura- tion bits stored in magnetic random-access memories. The use of MRAM technology to implement run-time reconfigurable hardware devices is a very promising technological solution because MRAM can provide non-volatility with cell areas and access speeds comparable to those of SRAM, and with lower process complexity than flash memory. This type of coarse- grained array, where each reconfigurable element computes on 4-bit or larger input words, is more suitable to execute data-oriented algorithms and is more able to exploit larger amounts of operation-level parallelism than common fine- grained architectures. By substantially reducing the overhead for configurability, this coarse-grain architecture is also more apt to efficiently exploit run-time reconfiguration and therefore to take advantage of multi-context MRAM-based configuration memories. Keywords-reconfigurable array; MRAM; programmable fab- rics;",data oriented architecture,123
826ac2113812ee288da45f585759f81318ce4c85,filtered,semantic_scholar,,2017-01-01,semantic_scholar,information management for enabling systems medicine,https://www.semanticscholar.org/paper/826ac2113812ee288da45f585759f81318ce4c85,"Abstract Systems medicine is a data-oriented approach in research and clinical practice to support study and treatment of complex diseases. It relies on well-defined information management processes providing comprehensive and up to date information as basis for electronic decision support. The authors suggest a three-layer information technology (IT) architecture for systems medicine and a cyclic data management approach including a knowledge base that is dynamically updated by extract, transform, and load (ETL) procedures. Decision support is suggested as case-based and rule-based components. Results are presented via a user interface to acknowledging clinical requirements in terms of time and complexity. The systems medicine application was implemented as a prototype.",data oriented architecture,124
61f0f98f644912b1c71d137a829db60782eebd63,filtered,semantic_scholar,IEEE Access,2020-01-01,semantic_scholar,cyber physical and social networks in iov (cpsn-iov): a multimodal architecture in edge-based networks for optimal route selection using 5g technologies,https://www.semanticscholar.org/paper/61f0f98f644912b1c71d137a829db60782eebd63,"Humans are blessed with the intelligence to create links, develop semantic metaphors and models for reasoning; construct rules for decision making; and to form bounded loops for interaction, socialization and knowledge sharing. But machines are inadequate with these extraordinary abilities rather, numerous algorithms and mathematical models can be used to connect physical resources with cyberspaces to control objects and, develop cognitive learning for optimal decision making. Connected users and devices in closed virtual and physical proximity give direction towards the plethora of real-world applications for physical, social and, cyber computing. Because of the increase in social media networking and 5G communication links offer real-time crowdsourcing and sensing as a complementary base for information. Proceeding this idea, in this study we have proposed Cyber-Physical and Social Networks (CPSN) for two fundamental operations in IoV (Internet of Vehicles) as CPSN-IoV; (1) to define conceptual architecture of CPSN-IoV for data-oriented network for smart infrastructure and, (2) to create the significant virtual space where the instances of smart vehicles, devices, and things will have meaningful links with the real world objects where, CPSN-IoV will evolve, emerge, compete, and collaborate with all connected objects to strengthen the decision making process. To investigate the potential impact of our proposed study, we have simulated the taxicab trajectory data of the urban city of Portugal in OMNeT++ for the in-depth understanding of road topology, connected vehicles and things, and their traffic trends; and users’ social media streams in respective edge for efficient route planning. The results of simulation demonstrate that our proposed framework has the ability to achieve human-machine intellectual association for managing the smart environment.",data oriented architecture,125
01d8df8f4964dc0dc8cbcb7d559459cce29010ea,filtered,semantic_scholar,Open Distributed Processing,1994-01-01,semantic_scholar,"open distributed processing, ii: proceedings of the ifip tc6/wg6.1 international conference on open distributed processing, berlin, germany, 13-16 september 1993",https://www.semanticscholar.org/paper/01d8df8f4964dc0dc8cbcb7d559459cce29010ea,"Opening of the ICODP'93 conference welcome speech of the president of the Technical University of Berlin message from the Berlin senate of economics and technology message from the German institute for standards. Part 1 Tutorials: reference model of open distributed processing - a tutorial, K.A. Raymond an ODP-oriented framework for European services in telemedicine, D. Lutzeback and B. Mahr. Part 2 Invited presentation: ODP-trader, M.Y. Bearman does midware provide an adequate distributed application environment?, J. Slonim et al medical applications of ODP, H. Hansen and R.D. Kutsche data oriented approach to business information modelling, R. Hotaka and M. Bjorn service engineering in RACE and its relation to ODP, M. Campolargo the challenges of CSCW for open distributed processing, G.S. Blair and T. Rodden. Part 3 Reviewed papers - session on trader: object trading in open systems, A. Goscinski and Y. Ni broadening the user environment with implicit trading, L. Kutvonen and P. Kutvonen a type management system for an ODP trader, J. Indulska et al contexts, views and rules - an integrated approach to trader contexts, K.A. Raymond and M.Y. Bearman. Part 4 Session on distributed systems: HARNESS - an evolving standard for distributed processing, A. Balis et al a distributed object-oriented platform based on DCE and C(++), P.G. Bosco et al is DCE a support environment for ODP?, A.D. Beitz et al. Part 5 Session on multimedia and quality of service: distributed application performance metrics and management, J.A. Rolia a language for the specification of interactive and distributed multimedia applications, P.F. Pinto and P.F. Linington distributed multimedia systems quality of service in ODP framework of abstraction - a first study, L. Fedaoui et al. Part 6 Session on distributed applications: home automation systems - ODP in the kitchen?, A. Munro federating expert systems in an ODP environment, N. Sharma ODP - a framework for defining service management reference configurations, L. Strick et al. Part 7 Session on design and modelling: new economic-driven aspects of the ODP enterprise specification and related quality of service issues, Z. Milosevic et al co-operation support for an open service market, M. Merz and W. Lamersdorf an object-oriented approach to the formal specification of ODP trader, J.S. Dong and R. Duke an improved model for transactional operations in RM-ODP, A. Berry and K.A. Raymond. Part 8 Workshops: architectural semantics in ODP, chair - C.A. Vissers the role of ODP in medical applications, chair - M. Gerenth and B. Mahr object management architecture, chair - J. Slitz.",data oriented architecture,126
141ac67c51134b03e993dca1a4e038266c6a45aa,filtered,semantic_scholar,WABBWUAS@UMAP,2010-01-01,semantic_scholar,generic adaptation process,https://www.semanticscholar.org/paper/141ac67c51134b03e993dca1a4e038266c6a45aa,Adaptive Hypermedia Systems (AHS) have long been mainly represented by domain- or application-specific systems. Few reference models exist and they provide only a brief overview of how to describe and organize the ‘adaptation process’ in a generic way. In this paper we consider the process aspects of AHS from the very first classical ‘user modelling-adaptation’ loop to a generic detailed flowchart of the adaptation in AHS.We introduce a Generic Adaptation Process and by aligning it with a layered (data-oriented) AHS architecture we show that it can serve as the process part of a new reference model for AHS.,data oriented architecture,127
b1ba63a67004633da7f3a7b635324f0eba90afdc,filtered,semantic_scholar,,2011-01-01,semantic_scholar,research on service-oriented geospatial information sharing mechanism and technical architecture,https://www.semanticscholar.org/paper/b1ba63a67004633da7f3a7b635324f0eba90afdc,"SOA is providing conceptual design pattern for service-oriented distributed systems, and Web service is one of standards-based implementation of SOA technologies, deployed on the Web as an object or component. Survey the whole paper, get two points. First of all, it compares the spatial data oriented sharing with the spatial information service oriented sharing on technology and feature, and analysis of the service-oriented spatial information sharing mechanism and the implementation of ideas; Secondly, it frames a service-based geospatial information sharing platform, expounding the key technology and organizing way of spatial information based on Web Service. Offer solutions for GIS data integration and spatial information sharing that platform-crossed and sector-crossed.",data oriented architecture,128
74a462a4e6426679aa9f2f0c172e28c0bb064258,filtered,semantic_scholar,ACM Multimedia,2020-01-01,semantic_scholar,pose-native network architecture search for multi-person human pose estimation,https://www.semanticscholar.org/paper/74a462a4e6426679aa9f2f0c172e28c0bb064258,"Multi-person pose estimation has achieved great progress in recent years, even though, the precise prediction for occluded and invisible hard keypoints remains challenging. Most of the human pose estimation networks are equipped with an image classification-based pose encoder for feature extraction and a handcrafted pose decoder for high-resolution representations. However, the pose encoder might be sub-optimal because of the gap between image classification and pose estimation. The widely used multi-scale feature fusion in pose decoder is still coarse and cannot provide sufficient high-resolution details for hard keypoints. Neural Architecture Search (NAS) has shown great potential in many visual tasks to automatically search efficient networks. In this work, we present the Pose-native Network Architecture Search (PoseNAS) to simultaneously design a better pose encoder and pose decoder for pose estimation. Specifically, we directly search a data-oriented pose encoder with stacked searchable cells, which can provide an optimum feature extractor for the pose specific task. In the pose decoder, we exploit scale-adaptive fusion cells to promote rich information exchange across the multi-scale feature maps. Meanwhile, the pose decoder adopts a Fusion-and-Enhancement manner to progressively boost the high-resolution representations that are non-trivial for the precious prediction of hard keypoints. With the exquisitely designed search space and search strategy, PoseNAS can simultaneously search all modules in an end-to-end manner. PoseNAS achieves state-of-the-art performance on three public datasets, MPII, COCO, and PoseTrack, with small-scale parameters compared with the existing methods. Our best model obtains 76.7% mAP and 75.9% mAP on the COCO validation set and test set with only 33.6M parameters. Code and implementation are available at https://github.com/for-code0216/PoseNAS.",data oriented architecture,129
f4dda7d65b3b3c21beb58483c712911945649b33,filtered,semantic_scholar,ICN,2020-01-01,semantic_scholar,toward a restful information-centric web of things: a deeper look at data orientation in coap,https://www.semanticscholar.org/paper/f4dda7d65b3b3c21beb58483c712911945649b33,"The information-centric networking (ICN) paradigm offers replication of autonomously verifiable content throughout a network, in which content is bound to names instead of hosts. This has proven beneficial in particular for the constrained IoT. Several approaches, the most prominent of which being Named Data Networking, propose access to named content directly on the network layer. Independently, the IETF CoAP protocol group started to develop mechanisms that support autonomous content processing and in-network storage. In this paper, we explore the emerging CoAP protocol building blocks and how they contribute to an information-centric network architecture for a data-oriented RESTful Web of Things. We discuss design options and measure characteristic performances of different network configurations, which deploy CoAP proxies and OSCORE content object security, and compare with NDN. Our findings indicate an almost continuous design space ranging from plain CoAP at the one end to NDN on the other. On both ends---ICN and CoAP---we identify protocol features and aspects whose mutual transfer potentially improves design and operation of the other.",data oriented architecture,130
2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,filtered,semantic_scholar,,2005-01-01,semantic_scholar,model checking circus,https://www.semanticscholar.org/paper/2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,"As software complexity increases, so does the need for precision. For some areas, such as high-integrity and safety-critical domains, this precision is imperative rather than optional. To address this issue, both academia and industry have been applying formal methods and formal verification techniques, where model checking and theorem proving are the most successful. Model checking is a verification technique that exhaustively searches the state space of a system represented by some formal notation. It became a successful technique applied by both academia and industry, due to its high level of automation and the ability to provide counter-examples as a debugging device in the case of failure. The difficulty of applying this technique is the state explosion problem that often happens in software verification, hence making such technique unsuitable for representation by computer. In order to finitely represent infinite state systems to be analysed by computer, one needs to resort to the more powerful technique of theorem proving. It allows precise description with less compromise on the state representation, as it uses symbols and quantifiers rather than actual values. The problem is that the higher the expressiveness of a notation, the lower the level of automation that it supports and greater the demand for user expertise and interactivity. The maturity of these techniques, as well as the wide availability of tools, pushed the demand for more expressive techniques with powerful automation tool support. Thus, combination of formalisms and their tools have become a topic of great interest in current research in formal methods. The combination of formalisms usually involve blending mature techniques that cover different aspects of software development in a common semantical framework. For instance, combining data oriented languages, such as Z and B, with behaviour oriented languages, such as CCS and CSP has been the focus of considerable research. The next step in this direction is to provide tool support for these combined languages. The combination of model checking and theorem proving have become the state-of-the-art in terms of tool development for formal verification techniques, as it combines expressiveness with high levels of automation. In this thesis, our main goal is to provide model checking support with integrated theorem proving for Circus, a concurrent language for refinement that combines Z, CSP, and the refinement calculus. Its semantic model is based on Hoare and He’s Unifying Theories of Programming (UTP), which provides an integrated theoretical framework for development and extension of different programming paradigms. From the partnership of our research group with QinetiQ Malvern, it is clear that there is demand for integrated formalisms and respective tool support. Our aim is to provide tool support for Circus, in order to allow its use in real applications, where we are able to formally specify different aspects of systems including, but not limited to, data and behaviour. As Circus is based in UTP, it is possible to integrate other aspects, such as mobility, and real-time, and research in these fronts is well advanced. To fulfill our goal, we provided an operational semantics for model checking Circus, which enables the representation of Circus programs as automata, as well as a search algorithm enabling us to establish refinement between two programs. Throughout the development process, we have decided to take our own medicine and use formal specification and verification, in order to increase the levels of integrity of our tools and techniques. The semantics and the underlying automata theory has been formally defined and mechanised in the Z/Eves theorem prover. Next, we proposed a model checking architecture, which integrates theorem proving facilities, and is implemented as a model checker prototype in Java. This architecture has been formally defined in Circus itself, and we augmented the Java code with JML annotations and assertions representing our findings from the formal specification. Finally, from the abstract Circus specification of the model checker architecture, we calculated a sequential refinement search algorithm using Circus refinement laws, where generated proof obligations have been discharged using Z/Eves again. This effort gave rise to a prototype model checking tool for Circus, which integrates refinement model checking with theorem proving in an extensible framework compliant with the Z Standard.",data oriented architecture,131
5bebd0d71a010e6a9b1b1de6cbcac9a59483aa35,filtered,semantic_scholar,,1996-01-01,semantic_scholar,a data model for architecture independent parallel programming,https://www.semanticscholar.org/paper/5bebd0d71a010e6a9b1b1de6cbcac9a59483aa35,"This paper presents a common data model for both shared and distributed parallel programming. Our model aims at parallel application programming, especially in th e field of data parallelism. We introduce coordinators shared objects which automatically perform synchronization in shared memory programming and remote communication in distributed programming. Programming with coordinators allows a static definition of dynamic access properties (shared access patterns) in a declarative manner. Thus, there is no need for explicit use of synchronization or communication primitiv es in order to get well defined and efficient parallel programs. In contrast, declarativity allows to think in abstract coor dination categories. Our paradigm is named Declarative Imperative Parallel Programming due to this fact and due to our commitment to imperative applications, mainly from the field of scientific computing, image processing, simulation and optimization. 1. The DIPP programming model Ideally, explicit parallel programming should be uniform for shared and distributed platforms. One way to achieve this is to give the programmer the illusion of shared memory even on distributed platforms[18]. While we think that this might be exactly what a programmer wants we must acknowledge that this goal is not reached yet. The performance issue implies some sort of discrimination of local from non-local data for distributed platforms. We believe that the process model can be uniform without any impact on performance. We propose such a model (a workpool model) in [13]. The aim of this paper is to show that even the data model can benefit from an uniform approach allowing architecture invariant programmin g without too much loss of performance. The relationship between our data model and the workpool is described in [14]. The main property of the approach presented in this paper is a paradigm which makes explicit synchronization or remote communication obsolete without performance degradation1. We introducecoordinators, a means for declaratively specifying the dynamic access properties of objects to be used by more than one process. The access properties directly correspond to algorithmic patterns typically found i data parallel algorithms such as fan-in or fan-out. In the context of message passing we have the related term broadcast. These all are specific cases of access patterns which can be defined by coordinators. The automatic coordination behavior of a system that implements coordinators can be derived from the specified patterns. Since coordinators are a declarative means to be used in imperative programming the programming model is named Declarative Imperative Parallel Programming. Imperativity is one of the properties which make coordinators different from other implicit synchronization paradigms such as futures [10]. See the discussion of related work for details. Coordinators are objects that may be accessed by more than one process in a coordinated fashion. In shared memory programming they might be named selfsynchronized objects. In distributed programming the term self-distributing might be in order. Accesses to coordinators may trigger synchronization or remote communication actions. We discriminate writing accesses (producers) from reading accesses (consumers). Note, that we do not support general producer-consumer aspects like buffering. In contras t, coordinators are a means for synchronized control allowing a tight coupling between producer and consumer. We 1Notice that we are concerned with application programming; we do not claim that our model does away with explicit synchroniza tion or coordination for parallel system programming such as operati ng systems or databases. specify access properties in a declarative manner: Access patterns are declared separately for reading and writing. The parallel semantics is defined by switching between a writableand areadablestate of a coordinator. The patterns statically describe the conditions which trigger the state switches. These conditions are defined in terms of “who reads or writes an object how many times”. Inappropriate (premature) accesses are delayed until the state switches. This behavior is implemented by implicit synchronization or communication, depending on the underlying architecture. 1.1. Dynamic behavior of coordinators The basic assumption about accesses to coordinators is that writing accesses are distinguished from reading accesses. In imperative programs, switches between writable and readabletypically occur repeatedly inside loops. In functional programs there is exactly one switch from writable to readable. 2 In the following, we informally describe the dynamic behavior of coordinators. Two state semantics Coordinators exhibit a two state semantics: A coordinator is initially in thewritablestate. After construction of the first value it switches to the readable state. After the last read access the coordinator switches t o thewritable state again, thus allowing multiple updates of objects. Depending on the access patterns defined for each state (see section 1.2), the switches may be triggered by dif ferent actions. Blocking If a coordinator is accessed and its state does not correspond to the access kind (i.e. a read access while the coordinator is writable and vice versa) the access is automatically blocked. Blocking lasts at least until the stat e has switched (e.g. by completion of some other accesses). By defining the switch conditions between the two states, the access patterns also determine blocking conditions. Computational steps Our focus is on iteratively writing and reading objects inside some loop or recursion. All such activities within one iteration are referred to as a computational step. More accurately, we define a computational stepwith respect to a coordinator as (dynamically) starting in the writable state and ending when this state is reached again, i.e. a computational step consists of a write phase and aread phase .3 2Readers familiar withfuturesor I-structuresmight see some relationship to these. 3In the functional world, the whole lifetime of a variable is a computational step. The semantics of coordinators is defined by their behavior during one computational step. In general, different co ordinators will carry out different computational steps. 1.2. De ning access patterns Every coordinator reveals a specific access pattern with respect to both phases of a computational step. The access patterns must be specified by the user separately for both phases. Access patterns correspond to algorithmic pat terns as they typically occur in “data-oriented” parallel a lgorithms (e.g. in numerical computation). We have defined the following patterns: each(<process group >,<no of accesses >) each(<process group >) arbitrary(<no of accesses >) arbitrary() The main patternseach and arbitrary differ in the mode of cooperation between the involved processes while their shapes denote the events that trigger a state change. Theeach pattern is used for a homogeneous group of processes <process group >, when the overall task within the write or read phase of a computational step can be defined by specifying the task of every single process within the phase. The intended standard way to specify such a task is to declare how many times the process will access the coordinator within the phase. To do so the each pattern is used with a<no of accesses > specification ( <no of accesses > will be 1 in many cases). This pattern fits for most algorithms that work on regular data (like arrays) in a regular fashion. If the number of accesses cannot be given, each process has to state explicitly that its task within a phase is finished by invoking the coordinator method procReady(<phase>). This method is parameterized with the phase, since it must be synchronized with concurrent accesses. Thus, a call to procReady is a further potential blocking situation. The state change is triggered as soon as each process has finished its task. In order to get a proper definition of this switch condition we require an invariable line-up of the pro cess group (except for an initial phase, see [13]). In contrast, thearbitrary pattern is used if an arbitrary, possibly varying number of possibly inhomogeneous processes share the coordinator. Within this cooperation mode, we can provide only global switch conditions: In the arbitrary pattern a<no of accesses > specification refers to the overall number of accesses, i.e. the state of the coordinator switches after exactly <no of accesses > accesses, no matter which processes were involved. Again, if the number of accesses cannot be given the state switch has to be triggered explicitly. In contrast to theeach pattern this is done by only one process, using the coordinator method switch(<phase>). It can be concluded that this pattern is appropriate e.g. for a farm work model where a centralized master controls the work of several slave processes. 1.3. A short example We illustrate the use of coordinators in a small example, using aC++ like notation enhanced with simple syntactic extensions. Our example implements a producer-consumer scenario where an integer variable sharedInt is repeatedly written by a single producer and subsequently read by nProcs different consumers. We ensure that each value written by the producer is read exactly once by each consumer, by simply definingsharedInt as a coordinator:",data oriented architecture,132
44c75858494b9aecb62b9c50fe4cea48a7e045d1,filtered,semantic_scholar,"CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.",2003-01-01,semantic_scholar,a method to find unique sequences on distributed genomic databases,https://www.semanticscholar.org/paper/44c75858494b9aecb62b9c50fe4cea48a7e045d1,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled. Hence, it becomes feasible to analyze the entire genomic information all at once. On the other hand, the quantity of the genomic information stocked on databases is increasing day after day. In order to process the whole information, we have to develop an effective method to deal with lots of data. Therefore, it is indispensable not only to make an effective and rapid algorithm but also to use high-speed computer resource so as to analyze the biological information. For this purpose, as one of the most promised computing environments, the grid computing architecture has appeared recently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11]. In the field of bioinformatics, it is important to find unique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found they can be useful for target specific probes/primers design, gene sequence comparison and so on. In this paper, we propose a method to discover unique sequences from among genomic databases located in a distributed environment. Next, we implement this method upon the European Data Grid and show the calculation results for E. coli genomes.",data oriented architecture,133
59bb50285c3e3807a03617b98aac00233cc5ce28,filtered,semantic_scholar,2010 IFIP Wireless Days,2010-01-01,semantic_scholar,a software radio architecture for the baseband level of the multi-standard user terminal: design methodology and computational assessment,https://www.semanticscholar.org/paper/59bb50285c3e3807a03617b98aac00233cc5ce28,In this paper we present a design methodology and system prototyping for the baseband level of the Software Defined Radio (SDR)-based portable multi-standard terminal. The SDR-based architecture consists of three main layers denoted as: i) Upper Layer to provide communication with an end user and a network; ii) Middle Layer to establish the required protocol configuration; and iii) Bottom Layer to execute the protocol algorithm. Main concern was based on the examination of the SDR-based module behavior in the heterogeneous environment. As a case study we have chosen two different wireless communication standards: data-oriented WiMAX (IEEE 802.16d) and voice-oriented UMTS (release 1999). The simulation of the digital signal processing for both standards was performed in the MATLAB environment. The goal is to achieve and to verify the given system configuration depending on the environment characteristics. For this reason we show that SDR-based module can recognize the required protocol configuration and tune the system accordingly.,data oriented architecture,134
b27747686819c89faa029ac1b4dc483797211406,filtered,semantic_scholar,Proceedings of the 1994 IEEE International Conference on Robotics and Automation,1994-01-01,semantic_scholar,a parallel simulation of multiple mobile robots using the doris design method,https://www.semanticscholar.org/paper/b27747686819c89faa029ac1b4dc483797211406,"This paper introduces the data oriented requirements implementation scheme (DORIS) design strategy and the data interaction architecture demonstrator (DIADEM), by describing their use for a multiple-robot workspace simulation. The design process, the hardware and the software for the DIADEM are outlined, followed by a discussion of the design used for the simulation.<<ETX>>",data oriented architecture,135
85c91ea5de453ba5bfb10ec4c895a775422358df,filtered,semantic_scholar,"5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007)",2007-01-01,semantic_scholar,requirements specification: what strategy under what conditions,https://www.semanticscholar.org/paper/85c91ea5de453ba5bfb10ec4c895a775422358df,"There are several strategies/philosophies of IS development (structured, data-oriented, object-oriented, service- oriented, and agile programming). Their application was to a high degree implied by technological conditions. The strategies have been determining the information systems architecture and the tools and methods of requirement specification. Due the success of new strategies the older ones are improperly considered to be obsolete. There are discussed the conditions under which the application of a particular strategy is not only feasible but optimal and when and how different strategies are to be combined. All the strategies except the service-oriented one are suited to the development of application more or less from scratch. The application has a programmed number of threads. The current largest information systems like the systems supporting e-government or global enterprises must have service- oriented architecture of a specific form - software confederations. Confederation-oriented strategy is different from the other strategies but it can (should) be combined with them. The main differences are in the use of legacy systems and software standards.",data oriented architecture,136
dea31cbcf29a62120d437208a754455acb8bc82b,filtered,semantic_scholar,PeerJ Comput. Sci.,2021-01-01,semantic_scholar,distributed in-memory data management for workflow executions,https://www.semanticscholar.org/paper/dea31cbcf29a62120d437208a754455acb8bc82b,"Complex scientific experiments from various domains are typically modeled as workflows and executed on large-scale machines using a Parallel Workflow Management System (WMS). Since such executions usually last for hours or days, some WMSs provide user steering support, i.e., they allow users to run data analyses and, depending on the results, adapt the workflows at runtime. A challenge in the parallel execution control design is to manage workflow data for efficient executions while enabling user steering support. Data access for high scalability is typically transaction-oriented, while for data analysis, it is online analytical-oriented so that managing such hybrid workloads makes the challenge even harder. In this work, we present SchalaDB, an architecture with a set of design principles and techniques based on distributed in-memory data management for efficient workflow execution control and user steering. We propose a distributed data design for scalable workflow task scheduling and high availability driven by a parallel and distributed in-memory DBMS. To evaluate our proposal, we develop d-Chiron, a WMS designed according to SchalaDB’s principles. We carry out an extensive experimental evaluation on an HPC cluster with up to 960 computing cores. Among other analyses, we show that even when running data analyses for user steering, SchalaDB’s overhead is negligible for workloads composed of hundreds of concurrent tasks on shared data. Our results encourage workflow engine developers to follow a parallel and distributed data-oriented approach not only for scheduling and monitoring but also for user steering.",data oriented architecture,137
4545c290e77387c305da61557ada3f512dfedbb1,filtered,semantic_scholar,,2007-01-01,semantic_scholar,study on application of pdm technology in reliability design and analysis of mechanisms,https://www.semanticscholar.org/paper/4545c290e77387c305da61557ada3f512dfedbb1,"The multidisciplinary tools integration is one of the key technical problems in the Virtual Prototyping design and simulation of the complex product. In this paper,a service-oriented,better opening,standard-based and plug-and-play multidisciplinary tools integration platform for mechanism reliability design and analysis is presented,and the architectures of design and analysis of mechanism reliability based on PDM technology are given. What is discussed is the model data-oriented integration of management to realize the integration of CAD/CAE and PDM both in design and collaborative simulation periods. At last,an application example in space rendezvous mechanism is briefly introduced to indicate methods of integration design and analysis of mechanism reliability and how to realize PDM based collaborative modeling and analysis of mechanism reliability by using application packaging.",data oriented architecture,138
f1782bbad00979a37b68b55388e82f3dbc0a6edf,filtered,semantic_scholar,2008 IEEE Aerospace Conference,2008-01-01,semantic_scholar,iknow mission: payload design for in orbit test of w band technology,https://www.semanticscholar.org/paper/f1782bbad00979a37b68b55388e82f3dbc0a6edf,"This paper presents the payload design for an in orbit test of W band technology called IKNOW mission (In orbit Key-test and validatioN Of W band). The increasing demand for frequency bands with large bandwidth availability to satisfy satellite communications applications requirements renders mandatory the need to explore higher and higher frequency ranges. W band (75-110 GHz) could represent the answer to these needs due to the large bandwidth availability, allowing to propose many innovative services that need high-volume transfers. Therefore, the exploitation of W band is foreseen in order to meet the high-quality data transmission for a large number of end users and data-oriented services. The IKNOW mission is a demonstrative experiment foreseen within the phase A2 of the WAVE (W band analysis and verification) project, a study funded by the Italian Space Agency (ASI), which aims at designing and developing W band payloads for telecommunication applications. This paper will be focused on the characterization of the IKNOW mission within the WAVE project devoted to carry out a preliminary channel propagation assessment. Specifically, special attention will be paid to the payload design, particularly critical from the technological point of view at these high frequencies. The basic idea is to develop the receiving/transmitting chain using MMIC devices, in order to fit cost, power and weight constraints, typically limited for a spacecraft. Technological critical items will be highlighted, focusing on the present state of the art and presenting some architectural choices. Moreover, some simulations based on ADS software will be reported in order to simulate the performance of the identified payload configuration.",data oriented architecture,139
00a97b3ca5c924b9350a6199f67bcf76c21bbdbd,filtered,semantic_scholar,2007 International Conference on Service Systems and Service Management,2007-01-01,semantic_scholar,electronic medical records: a vision for medical data and service grids,https://www.semanticscholar.org/paper/00a97b3ca5c924b9350a6199f67bcf76c21bbdbd,"In this paper, we propose an integrated e-service model for implementing electronic medical records (EMR). We discuss technical and economic issues associated with EMR and argue that the emerging e-services will not fully resolve the issues if they do not work together. To meet the challenge, we propose an integrated e-service framework consisting of both process-and data-oriented grids that glue together distributed electronic medical services and records, and application services that provide readily available solutions. We suggest an implementation architecture that extends the open systems interconnectivity model and improves existing e-service architectures. The proposed e-services framework would help deliver e-health applications effectively at a time when such applications are being considered as an effective means of delivering healthcare information, products, and services.",data oriented architecture,140
c35363cb270b737e8f41dc87974d001c39858299,filtered,semantic_scholar,[1988] Proceedings of the Twenty-First Annual Hawaii International Conference on System Sciences. Volume II: Software track,1988-01-01,semantic_scholar,language level persistence for an object-oriented application programming platform,https://www.semanticscholar.org/paper/c35363cb270b737e8f41dc87974d001c39858299,"A description is given of a prototype persistent-object system, called DOOM, (Data-Oriented Object Manager), which was designed to explore issues in language-level persistence for object-oriented application platforms. In its first iteration, the language aspects of persistence were investigated, and a design which allowed the exchange of persistent objects between Common Objects (Common Lisp extension) and Objective-C/sup 2/ (C extension) was implemented. The system features a tight coupling between the languages; run-time support and a relational storage manager. In a second iteration, the coupling between the database and the language was loosened, and more characteristics of the database were exposed to the applications programmer. The language extensions introduced into CommonObject and Objective-C/sup 2/ to support persistence are discussed, and the architectures of DOOM-I and DOOM-II are described. Some persistent-object systems similar to DOOM that have appeared in the recent literature are briefly reviewed, and DOOM is examined in the light of two of the other systems.<<ETX>>",data oriented architecture,141
4679087942b944a1463b6305dd355d0b2322c78e,filtered,semantic_scholar,2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA),2020-01-01,semantic_scholar,big data oriented light-load embedded performance modeling,https://www.semanticscholar.org/paper/4679087942b944a1463b6305dd355d0b2322c78e,"With increasing development of big data, the performance assessment and optimization face with a big challenge. The traditional methods widely use delivery-testinganalysis-solving (DTAS) ring. In big data area, big data environment is necessary for the testing phase in DTAS, which results in the big cost in both time and hardware. This paper proposes the big data oriented light-load embedded performance modeling. It ascertains the performance criteria to set the Capacity and Performance (C&P) factors. These factors will be embedded into the software with an on-off switch during the architecture, design and developing phases before DTAS phase. After the software coding done with embedded C&P factors, a small traffic load is run to collect the C&P data. The collected data will be used for the performance bottleneck finding, performance optimization, and forecasting the capacity and performance for various customers’ scenarios. Since the data easily help locate the issue, the required running traffic is small, and the problem solving is done before the traditional DTAS, this study is more suitable for the big data application. It can save more than 50% of time, decrease the software development efforts, and reduce the lab resources occupation. Finally, the proposed method is employed in the real prototype of an Internet of Things application, obtains the better capacity and performance, and the experiment data verify its effectiveness.",data oriented architecture,142
96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,filtered,semantic_scholar,Proceedings 11th International Workshop on Database and Expert Systems Applications,2000-01-01,semantic_scholar,an object-based architecture for wap-compliant applications,https://www.semanticscholar.org/paper/96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,"The Wireless Application Protocol (WAP) is an emerging standard for the deployment of data oriented applications in wireless environments. Although some components of the WAP suite have been developed, it lacks a complete general architecture integrating software components of both the Internet and wireless contexts in a transparent way. The paper presents a general architectural framework to develop and deploy portable applications and services accessible by WAP-compliant mobile terminals, extending end-to-end services between terminal and business applications. Moreover, a technique to handle client disconnection is presented.",data oriented architecture,143
9ac1afce90ae30e267a928f4a203c0f3e0972edb,filtered,semantic_scholar,,2004-01-01,semantic_scholar,compound data oriented processing in usagi ipv6 stack,https://www.semanticscholar.org/paper/9ac1afce90ae30e267a928f4a203c0f3e0972edb,"IPv6 has been attracting much attention as a drastic countermeasure for severe shortage of addresses on the Internet. Linux, one of operating systems, also supports IPv6. However, the quality of the protocol stack was not so good. In this study, we worked out an architectural design for this basic software in Linux. Specifically, we introduce compound data oriented processing in network stack, which simplifies data object management and relationship between object. We show the quantitative research shows that the quality of protocol stack of IPv6 has been greatly improved. key words: IPv6, Linux, Compound Data Oriented Processing",data oriented architecture,144
a96539c753dd3b547cd5a3f390b6678b63c0d648,filtered,semantic_scholar,2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS),2021-01-01,semantic_scholar,iot microservice architecture for iotaas device users,https://www.semanticscholar.org/paper/a96539c753dd3b547cd5a3f390b6678b63c0d648,"Scaling up the Internet of Things (IoT) as a service (IoTaaS) is still facing many challenges including the demand of IoTass users to gain a more privilege access on IoT device to configure necessary parameters such as data rate and actuator rotation speed for custom object tracking methods. To address this challenge, this paper aims to propose a micro service architecture of IoT, particularly to provide configurable IoT device platform. Compared to previous works focusing on data-oriented high-level architecture of IoT solution, the proposed architecture provides a solution for IoT device users and, hence, this study is critical to extend the capabilities of IoTaaS.",data oriented architecture,145
00c4a804484051d385c992e2221bc406a54aa598,filtered,semantic_scholar,Int. J. Digit. Libr. Syst.,2011-01-01,semantic_scholar,a presentation-preserved compositional approach for integrating heterogeneous systems: using e-learning as an example,https://www.semanticscholar.org/paper/00c4a804484051d385c992e2221bc406a54aa598,"In traditional SCW environments, related web services are integrated into business processes. Web service still brings less than expected benefits to small corporations and end-users for two reasons: 1 the web service only focuses on data level and is difficult to implement the presentation-centric business contexts. 2 The small corporations and end-users usually do not have enough IT competences to write a client or user interface to interact with web services. In order to solve these problems, the author proposes a presentation-preserved compositional approach for service-oriented architecture PCSOA, which extends the existing data-oriented compositional approaches for web services to provide a more flexible methodology to orchestrate both data level and presentation level services during the workflow integration. A prototype is also built to validate the feasibility of the approach.",data oriented architecture,146
fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,filtered,semantic_scholar,,2018-01-01,semantic_scholar,a research on the security of wisdom campus based on geospatial big data,https://www.semanticscholar.org/paper/fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,"Wang Haiying School of Land and Resource China West Normal University Nanchong, China e-mail: wanghaiying8228@163.com Abstract— There are some difficulties in wisdom campus, such as geospatial big data sharing, function expansion, data management, analysis and mining geospatial big data for a characteristic, especially the problem of data security can't guarantee cause prominent attention increasingly. In this article we put forward a data-oriented software architecture which is designed by the ideology of orienting data and data as kernel, solve the problem of traditional software architecture broaden the campus space data research, develop the application of wisdom campus.",data oriented architecture,147
442567e7d47373f6d305a249b7ae05b81d15782e,filtered,semantic_scholar,"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",2019-01-01,semantic_scholar,consideration and research on data architecture for the future cyber society,https://www.semanticscholar.org/paper/442567e7d47373f6d305a249b7ae05b81d15782e,"The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.",data oriented architecture,148
98412aed33ea771756e73d8fb9a3b1b13c96a5c5,filtered,semantic_scholar,,2010-01-01,semantic_scholar,construction of fishery scientific data sharing platform,https://www.semanticscholar.org/paper/98412aed33ea771756e73d8fb9a3b1b13c96a5c5,"According to the national requirement for scientific data sharing buildings,we presents a comprehensive exposition of the design concept and key technologies research methods of the sharing platform of fishery scientific data which have base on the results of the fishery scientific data features and user requirements analysis.The research includes the architecture of fishery scientific data standard,metadata design,database design,network sharing platform development and the architecture of personalized service.The study has put forward constructive ideas about platform building which of data mining and data oriented services,also has importance signification for enhancing the fisheries information service.",data oriented architecture,149
7f7553beefdf3579a6759b97ef41948c1fc79c57,filtered,semantic_scholar,iiWAS,2017-01-01,semantic_scholar,a data-oriented architecture for loosely coupled real-time information systems,https://www.semanticscholar.org/paper/7f7553beefdf3579a6759b97ef41948c1fc79c57,"In this paper, we present an architectural pattern called Data Oriented Architecture (DOA). Motivation is the fact that on the one hand we face a shift to the usage of more and more mobile devices but on the other hand most services in the Internet still use a classic client-server-approach. Data is mainly produced at private devices today and put on centralized servers afterwards. This situation reflects the actual reality better: data is shared directly among users without the need of centralized sources. Three key facts distinguish DOA from existing approaches: First, DOA does not bind data to a specific location. Data is defined by the application which produced it and not an address of a location where it is currently stored. Second, DOA is a holistic approach that comprises a suitable data structure, data access methods and a message exchange protocol. Thus, DOA can be easily implemented and used right away. Third, in DOA, users can decide which data they want to keep private and which data they want to share. Shared data becomes a ""public good"" that is not owned by a specific entity but belongs to the community.",data oriented architecture,150
2378a6fe57d15f89a526eeb91c46b6cc231b729b,filtered,semantic_scholar,2015 7th Conference on Information and Knowledge Technology (IKT),2015-01-01,semantic_scholar,otanes: a live tv simulator for content-centric networking,https://www.semanticscholar.org/paper/2378a6fe57d15f89a526eeb91c46b6cc231b729b,"The tremendous growth of the Internet traffic and the rapid changes that have occurred in the way people using it to access massive contents, instruct the research community to data oriented networks. Over the last few years, various data oriented network architectures have emerged to fulfill the demand for a more scalable content distribution. Content-Centric Networking (CCN) is an architecture that has attracted a good consideration. A significant portion of Internet traffic growth relates to diverse types of multimedia applications, including live TV. In fact, delivering television services over the existing Internet protocol (IPTV) has been commercialized for more than a decade. Emigrating to the new network generation requires well analysis of the current applications. Nevertheless, CCN still suffers from the shortage of suitable simulators. We have developed a new modular, component based CCN simulator specifically optimized for live TV modeling. We have published it as an open source utility. In this paper, we present our simulator and evaluate its capabilities on the simulation of live video streaming over CCN.",data oriented architecture,151
21e1af9f96fa81391e3accec650e1e4de0851916,filtered,semantic_scholar,International Symposium on Multispectral Image Processing and Pattern Recognition,2015-01-01,semantic_scholar,an on-demand provision model for geospatial multisource information with active self-adaption services,https://www.semanticscholar.org/paper/21e1af9f96fa81391e3accec650e1e4de0851916,"Location-related data are playing an increasingly irreplaceable role in business, government and scientific research. At the same time, the amount and types of data are rapidly increasing. It is a challenge how to quickly find required information from this rapidly growing volume of data, as well as how to efficiently provide different levels of geospatial data to users. This paper puts forward a data-oriented access model for geographic information science data. First, we analyze the features of GIS data including traditional types such as vector and raster data and new types such as Volunteered Geographic Information (VGI). Taking into account these analyses, a classification scheme for geographic data is proposed and TRAFIE is introduced to describe the establishment of a multi-level model for geographic data. Based on this model, a multi-level, scalable access system for geospatial information is put forward. Users can select different levels of data according to their concrete application needs. Pull-based and push-based data access mechanisms based on this model are presented. A Service Oriented Architecture (SOA) was chosen for the data processing. The model of this study has been described by providing decision-making process of government departments with a simulation of fire disaster data collection. The use case shows this data model and the data provision system is flexible and has good adaptability.",data oriented architecture,152
d907ba410e13d3d5c31bbbcb4f192275dce295ec,filtered,semantic_scholar,2019 2nd International Conference on Hot Information-Centric Networking (HotICN),2019-01-01,semantic_scholar,cdac: a collaborative data access control scheme in named data networking,https://www.semanticscholar.org/paper/d907ba410e13d3d5c31bbbcb4f192275dce295ec,"Named Data Networking (NDN) shifts networking paradigm from host-oriented to data-oriented and supports in-network caching. However, in-network caching brings about some new security issues (e.g., the separation of ownership and management of data). In native NDN architecture, consumers' requests are usually authenticated by a content producer, which results in highly computation overhead and unnecessary network delay. Moreover, in such a scenario where the connection between content producer and network is intermittent, encrypted contents cached in routers fail to be accessed by consumers due to lacking of content producer's permission. In this paper, we propose a collaborative data access control scheme for NDN, called CDAC, in which data access control is performed at cached-enabled routers rather than single content producer. In addition, enhanced secret sharing method is applied to achieve data access control in the situation where the connection between content producer and network is intermittent. We also use two-variable one-way function to reduce the computation overhead caused by consumer's revocation. Through reasonable security analysis and the comparison with preliminary works, the CDAC scheme achieves the expected design goals. The experimental results demonstrate that our scheme is efficient for N DN architecture, and introduces slight delay for contents securely retrieval.",data oriented architecture,153
4b85ebe746b3a66663af789f9eda8ec3b2016741,filtered,semantic_scholar,SCOPES,2019-01-01,semantic_scholar,towards efficient code generation for exposed datapath architectures,https://www.semanticscholar.org/paper/4b85ebe746b3a66663af789f9eda8ec3b2016741,Coarse-grained reconfigurable architectures and other exposed datapath architectures such as transport-triggered architectures come with a high energy efficiency promise for accelerating data oriented workloads. Their main drawback results from the push of complexity from the architecture to the programmer; compiler techniques that allow starting from a higher-level programming language and generate code efficiently to such architectures robustly is still an open research area. In this article we survey the known main sources of challenges and outline a generic processor architecture template that covers the most common architecture variations along with a proposal for a common code generation framework for such challenging architectures.,data oriented architecture,154
92eca9bc0df78e4e3d4daef20c7219e4b01e0c74,filtered,semantic_scholar,,1994-01-01,semantic_scholar,"database issues for data visualization: ieee visualization '93 workshop, san jose, california, usa, october 26, 1993 : proceedings",https://www.semanticscholar.org/paper/92eca9bc0df78e4e3d4daef20c7219e4b01e0c74,"Workshop description.- Workshop participants.- Database issues for data visualization: Developing a data model.- Database issues for data visualization: System integration issues.- Database issues for data visualization: Interaction, user interfaces, and presentation.- The VIS-AD data model: Integrating metadata and polymorphic display with a scientific programming language.- An extended schema model for scientific data.- Data integration for visualization systems.- Inherent logical structure of computational data: Its role in storage and retrieval strategies to support user queries.- Database management for data visualization.- Data exploration interactions and the ExBase system.- Database requirements for supporting end-user visualizations.- A system architecture for data-oriented visualization.- A Hyperspectral Image Data Exploration Workbench for environmental science applications.- Design of a 3D user interface to a database.- Visualizing reference databases.- A 3D based user interface for information retrieval systems.- Using visualization to support data mining of large existing databases.",data oriented architecture,155
01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,filtered,semantic_scholar,,2018-01-01,semantic_scholar,research on digital power grid information integration solution,https://www.semanticscholar.org/paper/01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,"Information integration is an important part of the digital grid architecture. The purpose is to solve the information interaction obstacles between heterogeneous systems on the basis of making full use of the old system. This paper analyzes the development stage of digital power grid information integration from the perspective of information integration, and points out that the information integration of current digital power grid is mainly data-oriented integration. Based on the characteristics of digital power grid information integration, this paper puts forward a digital power grid information Integration solution combining horizontal information integration and vertical information integration, designs the overall architecture of digital power grid information integration, and elaborates the horizontal integration and vertical integration respectively.",data oriented architecture,156
de54590c4894018552b7d8f99a092ea2150a200a,filtered,semantic_scholar,,2013-01-01,semantic_scholar,research status and prospect of condition-based maintenance decision-making,https://www.semanticscholar.org/paper/de54590c4894018552b7d8f99a092ea2150a200a,"Research status about three key contents of condition-based maintenance decision-making is analyzed based on open architecture of CBM(Condition Based Maintenance).The application methodologies of weights for multi-attributed features are analyzed when it's referred to condition evaluation.When it comes to condition prediction,predicting methods are analyzed separately according to varied descriptions of condition.Optimal modeling methods for CBM decision-making are analyzed based on their theoretical foundations.It is put forward that dynamic decision-making for CBM,condition description modeling based on multi information and data oriented decision making should be further researched based on results from analysis of current research status.",data oriented architecture,157
5420d66a752c1eb434633e1e96f9f2c9743a5c69,filtered,semantic_scholar,Proceedings of NOMS '94 - IEEE Network Operations and Management Symposium,1994-01-01,semantic_scholar,information engineering architecture for strategic network operations and management platforms,https://www.semanticscholar.org/paper/5420d66a752c1eb434633e1e96f9f2c9743a5c69,"Today's telecommunications industry in Japan is not merely a business for an equipment infrastructure. Service providers are fiercely competing to improve customer satisfaction: providing services more quickly, notifying customers of exact recovery times, and supplying advanced new services. To improve customer satisfaction, all network operations and management (O&M) activities from customer services to administration have to flow smoothly and in cooperation with each other. A major factor in achieving this is an efficient information flow. An important aspect in this flow is that information must be readily available at any time and any place. To achieve global availability, the meaning, representation, and structure of the information must be systematized and standardized at an enterprise level and represented specifically at the local processing level. It is therefore necessary to construct O&M systems by using methodologies based on an information(data-) oriented perspective. An O&M system so constructed can be characterized as a strategic information system (SIS). Traditionally, O&M systems have been based on a process-oriented perspective and have been isolated from the flow of information. This paper describes the information engineering architecture we have developed for constructing a strategic network operation platform as an SIS. We have designed part of an information model based on this architecture and are studying the operation platform construction. 268 0-7803-181 1-0/94$04.00019941EEE Operation Systems: Present and Future Basic Structure of Process1 Qriented Operation Systems-df I .~.~..""-.,"""".~~.~.. .. .. ~ ......~... (Information L ,-.-.. ... .. ...-.. .. .""........"".. . .......-... . .."".....-,. Basic Structure of Data-oriente>j Platforms Application Platforms Presentation I [Data Communication Network) In&ormutton Resources Encupsuluted wtdh Merhods 1 Information Resource Platforms Traditional O&M systems focus on operating and managing the equipment and the network; they are developed by using methodologies based on a process-oriented perspective. Their data modeling and standardization are therefore done independently, so their data naming and data coding are not consistent. Information flows among these systems by means of paper and floppy disks, leading to duplicate data input, data transformation, and data inconsistency. The O&Ms are becoming strategic, advanced, and commercialized. For example, customers will be able to control their own networks, or they can let the service provider do it for them. To achieve strategic and advanced O&M, several O&M systems are needed and information must flow among them. In traditional vertically-structured systems, it is difficult to simplify data flow management, maintain data quality, and reduce data transformation costs. It is necessary to construct an information infrastructure which does not limit processing and managing data flows. The information needed by any O&M system must be immediately available, so information must be able to easily and quickly flow to all related O&M systems. From the view that ""Information is a final product which is gained by processing data"", it is necessary to construct O&M systems by using methodologies based on an information(data-) oriented perspective. We have developed a horizontally-structured O&M systems environment based on a data-oriented perspective. We call it an operation platform.",data oriented architecture,158
41869028b49ed2aac17ae9aede4f482ce7c6372c,filtered,semantic_scholar,,1998-01-01,semantic_scholar,evaluation results nlp components ovis2,https://www.semanticscholar.org/paper/41869028b49ed2aac17ae9aede4f482ce7c6372c,"The NWO Priority Programme Language and Speech Technology is a research programme aiming at the development of spoken language information systems. Its immediate goal is to develop a demonstrator of a public transport information system, which operates over ordinary telephone lines. This demonstrator is called OVIS, Openbaar Vervoer Informatie Systeem (Public Transport Information System). The language of the system is Dutch. In this Programme, two alternative natural language processing modules are developed in parallel: a ‘grammar-based’ (conventional, rule-based) module and a ‘data-oriented’ (statistical, probabilistic, DOP) module. Both of these modules fit into the system architecture of OVIS. For detailed descriptions of these modules, the reader is refered to (van Noord et al., 1996), (van Noord et al., 1996) and (van Noord et al., 1997) for the grammar-based NLP module. The DOP approach is documented in (Scha et al., 1996), (Sima’an, 1997b), (Bod and Scha, 1997). In order to compare both NLP modules, a formal evaluation has been carried out. This evaluation was planned originally for the beginning of 1997. Because the design of the update language (the interface between NLP and the pragmatic component and dialog manager) took more time than foreseen, and because the (semantic) annotation of corpus material has been available only since May 1997, this formal evaluation could only start in february 1998. The evaluation procedure is described in (van Noord, 1997), and summarized here in section 2. The methods implemented in Groningen and Amsterdam are described in somewhat more detail in section 3. Some characteristics of the test set are provided in section 4. The results of the evaluation are presented in section 5.",data oriented architecture,159
1dc736e04e41a1651fe35751300dda1dd069017f,filtered,semantic_scholar,I3E,2007-01-01,semantic_scholar,"integration and innovation orient to e-society, volume 1, seventh ifip international conference on e-business, e-services, and e-society (i3e2007), october 10-12, wuhan, china",https://www.semanticscholar.org/paper/1dc736e04e41a1651fe35751300dda1dd069017f,"e-Service Track.- Measuring the performance of G2G services in Iran.- The Study on the Architecture of Public knowledge Service Platform Based on Collaborative Innovation.- Wiki-based Knowledge Sharing in A Knowledge-Intensive Organization.- Web 2.0 Applications in China.- On the Standardization of Semantic Web Services-based Network Monitoring Operations.- Antecedents for Building Trust in Professional e-Services.- Service-Oriented Software Testing Platform.- A Research Study on Externalization of Tacit Knowledge Based on Web2.0.- Application of Electronic Business in Safe Accident Prevention and Control on Coalface.- Fulfillment of HTTP Authentication Based on Alcatel OmniSwitch 9700.- On the Potential of Web Services in Network Management.- A conceptual model of public medical service system based-on cell phone mobile platform.- An Integrated Model in E-Government Based on Semantic Web, Web Service and Intelligent Agent.- Electronic Commerce in Tourism in China: B2B or B2C?.- Customer's Perceptions and Intentions on Online Travel Service Delivery: An Empirical Study in China.- Research on the Impetus Mechanism of Institutional Repositories.- Study on Influencing Factor Analysis and Application of Consumer Mobile Commerce Acceptance.- The role of post-adoption phase trust in B2C e-service loyalty: towards a more comprehensive picture.- Open Access: How Is Scholarly Information Service System Going?.- Analysis and Modelling of Willingness to Receive Reward for Relay in Ad Hoc Networks.- A Keyword Extraction Based Model for Web Advertisement.- Study on Personalized Recommendation Model of Internet Advertisement.- An Analysis on Modes of Scientific and TechnologicaInformation Integration Services in the E- environment.- QoE: Quality of Experience: A Conceptual Essay.- Inter-organization Cooperation for Care of the Elderly.- An Investigation and Analysis of e-Services in Major Subject Based Information Gateways in the World.- Design of Web-based Management Information System for Academic Degree & Graduate Education.- A Process Model of Partnership Evolution Around New IT Initiatives.- Design of a Web2.0-based Knowledge Management Platform.- An Access Control Model of Workflow System Integrating RBAC and TBAC.- Study on Technological Innovation Risk of China's e-Services.- Research of Default Rules Mining Model Based on Reduced Lattice.- WSDRI-based Semantic Web Service Discovery Framework.- Virtual Team Governance: Addressing the Governance Mechanisms and Virtual Team Performance.- Government Information Access: A decisive Factor for E-Government.- An Algorithm for Semantic Web Services Composition Based on Output and Input Matching.- Ecological Analysis on Evolution of Information Systems.- Humanized Mandarin E-Learning Based on Pervasive Computing.- The Agent of extracting Internet Information with Lead Order.- Governmental Information Resources Management Base on metadata.- Web Services Composition based on Domain Ontology and Discrete Particle Swarm Optimization.- e-Society Track.- Personal knowledge management based on social software.- The Design And Implementing Of Collaborative Learning On Internet Curriculum Development.- eGovGrid: A Service-Grid-Based Framework for E-Government Interoperability.- Information Specificity Vulnerability: Comparison of Medication Information Flows in Different Health Care Units.- Service quality of Early Childhood Education web portals in Finnish municipalities.- Exploring the Intelligent and Collaborative control for E-Government System.- Evaluating the E-government Based on BSC.- A New Multi-Agent Approach to Adaptive E-Education.- A Research on Issues Related to RFID Security and Privacy.- Business Models of E-Government: Research on Dynamic E-Government Based on Web Services.- Education for Digitization: A Case Studyon Sharing E-Information Resources in University Library.- Role-based Administration of User-role Assignment and Its Oracle Implementation.- An Empirical Analysis of the Determinants of International Digital Divide.- Integration of E-education and Knowledge Management.- Spontaneous Group Learning in Ambient Learning Environments.- Roadmapping Future E-Government Research.- An E-education Framework Based on Semantic Web Agents.- A Framework for Web Usage Mining in Electronic Government.- A Theoretical Approach to Information Needs Across Different Healthcare Stakeholders.- The Moderating Effect of Leader-member Exchange on the Job Insecurity-Organizational Commitment Relationship.- Trust-based Access Control in Virtual Learning Community.- One Continuous Auditing Practice in China: Data-oriented Online Auditing(DOOA).- Research on the Status Quo and System Architecture of the Web Information Resource Evaluation.- Citizen Engagement: Driving Force of E-Society Development.- The Personal Digital Library (PDL)-based e-learning: Using the PDL as an e-learning support tool.- Research on Methods of Processing Transit IC Card Information and Constructing Transit OD Matrix.- Research on Implementation of E-Government Integrated Information Services.- The E-learning system used in the civil servants' job-training.- Evaluate E-loyalty of sales website: a Fuzzy mathematics method.- CSPMS supported by information technology.- An Exploratory Discuss of New Ways for Competitive Intelligence on WEB2.0.",data oriented architecture,160
fd4cbfabe49082a784e60ea60359c9483af8c216,filtered,semantic_scholar,22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC),2017-01-01,semantic_scholar,identity-based proxy signature multiple-file pdp for mobile cloud computing,https://www.semanticscholar.org/paper/fd4cbfabe49082a784e60ea60359c9483af8c216,"Provable Data Possession (PDP) schemes which are vital to data-oriented mobile cloud computing security architecture enable users to check the integrity of their data in the cloud efficiently. Due to the limitation of storage space and computing power of the mobile terminals, a new identity-based proxy signature multiple-file data integrity verification scheme called Identity-Based Proxy Signature Multiple-File PDP(IBPS-MPDP) for mobile cloud computing is proposed. In this paper, by using identity-based proxy signature, the system does not need to take the additional overhead to manage the public key certifications and the mobile users do not need to take additional cost to authenticate others' certificates yet. Allotting the heavy proxy signature tasks to the proxy sign party to implement to reduce the mobile terminal users' computing pressures. Adopting the aggregate signature to diminish the communication overhead of cloud and mobile users. The security of the scheme is proved in the random oracle model.",data oriented architecture,161
9b0cb4dcad5b0f2ec385af15a030dbbf97e86c4c,filtered,semantic_scholar,,2006-01-01,semantic_scholar,a study on the distribution of massive image data for mobile gis,https://www.semanticscholar.org/paper/9b0cb4dcad5b0f2ec385af15a030dbbf97e86c4c,"This paper studies and implements the architecture and key technologies of the distribution of massive image data oriented to the mobile GIS in low-bandwidth.According to the characteristics of massive image data and mobile internet,the paper studies several technologies,such as index of massive image data,multi-cache strategy and multi-server cluster technology.At last,it realizes the distribution of massive image data for mobile GIS.",data oriented architecture,162
cddb42247b854abce14ee1e059f332f42be54c5d,filtered,semantic_scholar,2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP),2015-01-01,semantic_scholar,rapid customization of image processors using halide,https://www.semanticscholar.org/paper/cddb42247b854abce14ee1e059f332f42be54c5d,"Image processing applications typically involve data-oriented kernels with limited control divergence. In order to efficiently exploit the data level parallelism, image processors include SIMD instructions and other parallel computation resources. Generic processors that can be purchased off-the-shelf are adequate for most of the use scenarios of image processing. However, especially with embedded mobile devices, they might not be optimal for the algorithm, the environment, or the energy budget at hand. Such cases call for programmable customized architectures with just enough hardware resources to ensure the high priority applications reach their real time goals with minimal overheads. In order to maintain high engineer productivity, implementing image algorithms for customized processors should be as easy as with standard processors. This is emphasized at the processor co-design time; because the program is used to drive the processor design space exploration towards an optimized architecture, assembly programming is not feasible due to the required porting effort whenever the architecture is modified. In this paper we propose an image processor customization flow that exploits the domain-specific Halide language as an input to a processor co-design environment. In addition to efficiently exploiting standard resources in the customized processors, the flow provides an easy way to invoke special instructions from Halide programs. We validate the performance benefits of custom operations using example filters described with the Halide language.",data oriented architecture,163
de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,filtered,semantic_scholar,2017 International Carnahan Conference on Security Technology (ICCST),2017-01-01,semantic_scholar,"encrypted computing: speed, security and provable obfuscation against insiders",https://www.semanticscholar.org/paper/de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,"Over the past few years we have articulated theory that describes ‘encrypted computing’, in which data remains in encrypted form while being worked on inside a processor, by virtue of a modified arithmetic. The last two years have seen research and development on a standards-compliant processor that shows that near-conventional speeds are attainable via this approach. Benchmark performance with the US AES-128 flagship encryption and a 1GHz clock is now equivalent to a 433MHz classic Pentium, and most block encryptions fit in AES's place. This summary article details how user data is protected by a system based on the processor from being read or interfered with by the computer operator, for those computing paradigms that entail trust in data-oriented computation in remote locations where it may be accessible to powerful and dishonest insiders. We combine: (i) the processor that runs encrypted; (ii) a slightly modified conventional machine code instruction set architecture with which security is achievable; (iii) an ‘obfuscating’ compiler that takes advantage of its possibilities, forming a three-point system that provably provides cryptographic ‘semantic security’ for user data against the operator and system insiders.",data oriented architecture,164
1ee9b2571008acac45a7f27b205df71b6cbf756a,filtered,semantic_scholar,2019 IEEE Global Communications Conference (GLOBECOM),2019-01-01,semantic_scholar,mc-track: a cloud based data oriented vehicular tracking system with adaptive security,https://www.semanticscholar.org/paper/1ee9b2571008acac45a7f27b205df71b6cbf756a,"In this paper, we propose Mc-Track, a new secure data oriented Cloud based vehicular tracking system. We introduced in Mc-Track an adaptive approach which consists in selection of security level according to data kinds. The architecture of the Mc-Track is composed of three levels: the vehicular network, the Cloud service, and proxies called Tracking Authorities, in charge of performing Attribute Based Encryption (ABE). We provided selective encryption and adaptive security in the Tracking Authority (TA), using the machine learning classifier k-Nearest Neighbours (k-NN). We conducted experimental study to evaluate the efficiency of the proposed k-NN classifier in selective encryption and adaptive security. So we compared the accuracy of the predictions of k-NN classifier to the accuracy of predictions using Support Vector Machine (SVM) classifier. Experimental results, has shown that the k-NN classifier is more accurate than SVM classifier.",data oriented architecture,165
bf25baf2eac5677cad335addbfab8b1c51ee360e,filtered,semantic_scholar,,2003-01-01,semantic_scholar,a method to find uniq e sequences on distrib ted genomic databases,https://www.semanticscholar.org/paper/bf25baf2eac5677cad335addbfab8b1c51ee360e,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled.Hence, it becomes feasible to analyze the entire genomicinformation all at once. On the other hand, the quantity ofthe genomic information stocked on databases is increasingday after day. In order to process the whole information, wehave to develop an effective method to deal with lots of data.Therefore, it is indis ensable not only to make an effectiveand rapid algorithm but also to use high-speed computerresource so as to analyze the biological information. Forthis purpose, as one of the most promised computing environments, the grid computing architecture has appearedrecently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11].In the field of bioinformatics, it is important to findunique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found, theycan be useful for target specific probes/primers design, genesequence comparison and so on. In this paper, we propose amethod to discover unique sequences from among genomicdatabases located in a distributed environment. Next, weimplement this method upon the European Data Grid andshow the calculation results for E. coli genomes.",data oriented architecture,166
88af34df634edebdfe39871f82166e61ad0a4835,filtered,semantic_scholar,,2010-01-01,semantic_scholar,electronic communications of the easst volume 28 ( 2010 ) proceedings of the third international discotec workshop on context-aware adaptation mechanisms for pervasive and ubiquitous services ( campus 2010 ) modelling feedback control loops for self-adaptive systems,https://www.semanticscholar.org/paper/88af34df634edebdfe39871f82166e61ad0a4835,"Feedback Control Loops (FCLs) are the heart of any self-adaptive system. Existing engineering approaches for building self-ad aptive systems mask FCL by providing abstraction layers that hide the application c mplexity. In this paper, we investigate a model-driven approach for the engineering of FCLs whose architecture is based on the Service Component Architecture (SCA) model. Our proposal consists in exploiting the data streaming model, to specify the characteristics of the control policies, and to generate FCLs of self-adaptive sys tem deployed in largescale environment. We argue that the use of a data-oriented m odel for designing self-adaptive systems significantly increases FCL visibil ity.",data oriented architecture,167
05fbbfb5cdab641e15c49690064b9aa1728bd2c3,filtered,semantic_scholar,,2015-01-01,semantic_scholar,non-volatile in-memory computing,https://www.semanticscholar.org/paper/05fbbfb5cdab641e15c49690064b9aa1728bd2c3,"The analysis of big-data at exa-scale (1018 bytes or flops) has called for an urgent need to re-examine the existing hardware platform that can support intensive data-oriented computing. A big-data-driven application requires huge bandwidth and yet able to ensure low-power density. For example, web-searching application involves crawling, comparing, ranking, and paging of billions of web-pages with extensive memory access. The existing memory technologies have critical challenges of scaling at nano-scale due to process variation, leakage current and I/O access limitations. Recently, the emerging non-volatile memory (NVM) technologies such as resistive-RAM (ReRAM), spintransfer torque RAM (STT-RAM), domain-wall nanowire racetrack memory etc., have all shown significantly reduced standby power and increased integration density, not forgetting the close-to DRAM/SRAM access speed. Therefore, they are considered as promising candidates of universal memory for future big-data applications. The primary challenge to validate a hybrid design with both CMOS and nonvolatile devices is the lack of design platform that can validate the large-scale NVM circuit and system design accurately and efficiently. In addition, due to the use of non-electrical states of emerging NVM devices, new cells structures and their agreeing circuits for both read and write operations are needed to harness non-volatile memory with unique operations. For example, the transistor-free crossbar array that associates with NVM is different from conventional access transistor based memory structure. What is more, leveraging the NVM for computing, one also needs to examine the potential logic-inmemory computing architecture with significantly improved bandwidth and reduced power. In order to tackle above challenges ranging from device to system levels, this PhD thesis has explored the development of NVM design platform to support designs of non-volatile memories, readout and logic circuit designs, as well as the in-memory computing architecture. For the NVM design platform, the target is to perform accurate yet efficient circuit level simulation. The previous approaches either ignore dynamic effect without considering non-volatile states for dynamic behavior, or need equivalent circuits with high complexity to curve-fit non-linearity of those devices. We proposed a SPICE simulaiii tor named NVM-SPICE. This tool takes advantages of its new modified nodal analysis (MNA) framework, which can effectively support the non-electrical state variables of emerging non-volatile devices, such as ReRAM and spintronics devices. Due to the physics based modeling approach, NVM-SPICE is able to perform hybrid NVM/CMOS circuits efficiently and accurately. Compared to the equivalent circuit model based approach, the NVM-SPICE simulator exhibits more than 117x faster simulation speed for spintronics category devices and 40x faster speed for RRAM category devices. For NVM in-memory architecture, both memory elements and logic elements are implemented by emerging spintronics devices, which leads to a system purely composed of non-volatile devices. The detailed non-volatile memory and logic circuits are explored within the NVM-SPICE platform. In addition, logic is built inside the memory so that the I/O workload can be alleviated. Applications such as data retention, encryption, machine learning that play critical roles for big-data computing are explored within the non-volatile in-memory architecture. The evaluation results show that the purely non-volatile memory based platforms with in-memory architecture greatly contribute to power efficiency and throughput improvement for big-data oriented applications, and thus are potential candidates to be next generation information and communication technology.",data oriented architecture,168
04887833a763e3025714350a9ec3b547be731214,filtered,semantic_scholar,Wirel. Pers. Commun.,2017-01-01,semantic_scholar,trends in the evolution of voice services: a comprehensive survey,https://www.semanticscholar.org/paper/04887833a763e3025714350a9ec3b547be731214,"Mobile network operators are increasingly striving to substitute legacy telecommunication technologies in their networks with the contemporary ones. Modern, future-proof architecture that provides better service quality, requires easier and cheaper maintenance, and consequently brings greater financial benefits is the main driving force for that action. In this moment, Long Term Evolution (LTE) deployment is a goal most mobile network operators are aspiring to. This paper describes presently ongoing changes in the mobile communication networks from the perspective of voice services they provide. Namely, LTE network is, so far, mainly recognized as a “data oriented” network. Having in mind enormous mobile data traffic increase, deployment of that kind of network is fully understandable and justified. However, voice services are still important part of telecommunications’ market offer. So, the above mentioned changes are leading not only toward satisfaction of growing needs regarding mobile data traffic, but also toward utilization of LTE network attributes for the purposes of voice communication. Complete transformation of mobile networks architecture and evolution of traditional voice communication will occur in the process. So far, that evolution has resulted with development of a mechanism know as voice over LTE. However, the mentioned changes are coming gradually and will take a certain time to be fully accomplished. In the meantime, some transition solutions are defined and deployed, in order to enable uninterrupted provisioning of voice services. Their description is included in the paper as well. At the end, relevant forecasts of several network parameters have been discussed.",data oriented architecture,169
c78864537e89a1cfb3d1c0c86d1c0798f06957c3,filtered,semantic_scholar,Euro-Par Workshops,2017-01-01,semantic_scholar,on the effects of data-aware allocation on fully distributed storage systems for exascale,https://www.semanticscholar.org/paper/c78864537e89a1cfb3d1c0c86d1c0798f06957c3,"The convergence between computing- and data-centric workloads and platforms is imposing new challenges on how to best use the resources of modern computing systems. In this paper we show the need of enhancing system schedulers to differentiate between compute- and data-oriented applications to minimise interferences between storage and application traffic. These interferences can be especially harmful in systems featuring fully distributed storage systems together with unified interconnects, such as our custom-made architecture ExaNeSt. We analyse several data-aware allocation strategies, and found that such strategies are essential to maintain performance in distributed storage systems.",data oriented architecture,170
c456b6d3246ae83dd76d50bcdbf8b12364e06df1,filtered,semantic_scholar,2019 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS),2019-01-01,semantic_scholar,an efficient routing strategy for information centric networks,https://www.semanticscholar.org/paper/c456b6d3246ae83dd76d50bcdbf8b12364e06df1,"Information Centric Network (ICN) focuses on shifting the current architecture of internet from host oriented to data oriented. It emphasizes on the location of contents rather than producer of the same. ICN accomplishes it's objectives by supporting caching of content at internal nodes in the network. It also focuses on proper routing of content requests towards a suitable data source for efficient and timely delivery. Hence, routing and caching are two prominent areas of research in ICN. In this paper, a dynamic routing mechanism is proposed that utilizes the concept of likelihood time and betweenness centrality. In order to improve content retrieval latency, the content requests are routed to the nearest content locations, determined by the likelihood time of requested content and betweenness centrality of a node in the network. The routing strategy of the proposed scheme extends native Dijkstra's algorithm and works with the available caching mechanism. The performance of the proposed strategy is evaluated through exhaustive simulations in ndnSIM-2.0, which is a ns-3 driven NDN simulator. The observed simulation results depict that in realistically simulated network topology, the new protocol shows 5-8% of performance improvement over existing ICN routing strategy in terms of cache hit ratio, latency and packet overhead.",data oriented architecture,171
43b318139f17bf010e68d56d098bec9dc74f18ad,filtered,semantic_scholar,,1986-01-01,semantic_scholar,"advanced programming environments : proceedings of an international workshop, trondheim, norway, june 16-18, 1986",https://www.semanticscholar.org/paper/43b318139f17bf010e68d56d098bec9dc74f18ad,"Source level debuggers: Experience from the design and implementation of chillscope.- Data-oriented incremental programming environments.- Context-sensitive editing with PSG environments.- Editing large programs using a structure-oriented text editor.- On the usefulness of syntax directed editors.- PegaSys and the role of logic in programming environments.- GARDEN tools: Support for graphical programming.- Discussion.- SunPro engineering a practical program development environment.- Information structuring for software environments.- An architecture for tool integration.- Software development in a distributed environment: The XMS system.- The SAGA approach to automated project management.- A process-object centered view of software environment architecture.- Software development environments: Research to practice.- Discussion.- A model of software manufacture.- Protection and cooperation in a software engineering environment.- The integration of version control into programming languages.- Discussion.- IDL: Past experience and new ideas.- Supporting flexible and efficient tool integration.- Views for tools in integrated environments.- Discussion.- Damokles - A database system for software engineering environments.- Toward a persistent object base.- Choosing an environment data model.- Version management in an object-oriented database.- Discussion.- Abstract data types, specialization, and program reuse.- Towards advanced programming environments based on algebraic concepts.- Program development by transformation and refinement.- Discussion.- Creating a software engineering knowledge base.- The unified programming environment: Unobtrusive support.- Beyond programming-in-the-large: The next challenges for software engineering.- Reuse of cliches in the knowledge-based editor.- Organizing programming knowledge into syntax-directed experts.- Framework for a knowledge-based programming environment.- Discussion.- Summing up.",data oriented architecture,172
03f78f06314280cfc53ccf241cc52a92c1483ca9,filtered,semantic_scholar,,1999-01-01,semantic_scholar,frame relay: technology and practice,https://www.semanticscholar.org/paper/03f78f06314280cfc53ccf241cc52a92c1483ca9,"Preface. Acknowledgments. 1. Introduction. Driving Forces for Frame Relay. The Need for Frame Relay. Accelerators for the Growth of Frame Relay. Frame Relay Network Basics. Benefits and Limitations of Frame Relay. Limitations. Frame Relay and Other Networking Technologies. Dial-Up Modem Lines. ISDN and Other Switched Digital Facilities. Leased Lines. X.25 Packet-Switching Services. Asynchronous Transfer Mode. Data-Oriented Virtual Private Networks. Switched Multimegabit Data Service. 2. Who's Who in Frame Relay. Standards Organizations. The American National Standards Institute. The Frame Relay Forum. The Internet Engineering Task Force. Other Standards Organization. Commercial Organizations. Frame Relay Service Providers. Frame Relay Vendors. 3. Frame Relay Architecture. Frame Relay Layers. Frame Relay and X.25 Packet Switching. Network Interfaces. User-Network Interface. Network-to-Network Interface. Local Management Interface. Frame Relay Layer 2 Formats. Frame Format. Header Format. Data Link Connection Identifiers. How DLCIs Identify Visual Circuits. Mapping DLCIs within a Network. Globally Significant DLCIs. Exercises. 4. Connecting to the Network. Access Circuits. Leased Access Circuits. Local Frame Relay Services. Dial-Up Access. Physical Connections to the Access Circuit. Physical Interfaces. Data Service Units/Channel Service Units. Port Connections. Network-to-Network Interfaces. Access Devices. Routers for Frame Relay Networks. Frame Relay Access Devices. Other Interfaces for Frame Relay Access. Recovery from Physical Circuit Failures. Failure of the Access Circuits. Failure of the Backbone Trunks. 5. Frame Relay Virtual Circuits. Virtual Circuits. Switches. Differences between PVCs and SVCs. Permanent Virtual Circuits. Switched Virtual Circuits. More on SVCs. SVC Signaling Specifications. Advantages and Disadvantages of SVCs. Switched Physical Access and SVCs. Recovery from Virtual Circuit Failures. 6. Traffic Management. Committed Information Rate. The User View of CIR. The Standards View of CIR. Capacity Allocation. Bursting. Dynamic Allocation. Oversubscription of Port Connections. Asymmetric PVCs. Congestion Management and Flow Control. Frame Discarding and the Discard-Eligible Bit. Explicit Congestion Notification Using the FECN and BECN Bits. Implicit Congestion Notification. Where Congestion Can Occur. Congestion across the Local Access Circuit. Congestion across the Provider's Network. Congestion across the Network-to-Network Interface. Congestion across the Remote Access Circuit. Limitations of Congestion Management. Proprietary Implementations of CIR and the DE, FECN, and BECN Bits. The Customer's Inability to Respond to the FECN and BECN Bits. Use and Misuse of the DE Bit. 7. Engineering of Frame Relay Networks. Frame Relay Switch Families. Public Service Provider Switches. The Non-CIR Approach. PVC Services and Bursting. Capacity Planning. Traffic Handling. Congestion Management. Summary. The Flow-Controlled Approach. PVC Services. Capacity Planning. Traffic and Burst Handling. Congestion Management. Summary. Comparison of Non-CIR and Flow-Controlled Approaches. Advantages of Non-CIR. Advantages of Flow-Controlled Networks. Second-Generation Frame Relay Switches. Quality of Service Support. Greater Speeds and Scalability. Improved Traffic Routing. The Zero CIR Controversy. 8. Network Management. Network Management System Functions. Management Data Sources. Data from Switches. Data from Routers. Data from Protocol Analzyers. Data from Enhanced DSU/CSUs. Frame Relay Standards versus Proprietary Network Management Systems. Frame Relay Standards in Network Management. The Local Management Interface. Consolidated Link Layer Management. Review of the Simple Network Management Protocol. The Management Information Base for Frame Relay Service. Frame Relay Management Approaches. User-Based Monitoring. Carrier-Based Monitoring. Managed Network Services. Open Network Management Systems. Frame Relay Network Management Functions. Configuration Management. Fault Management. Performance Management. Accounting Management. Security Management. Managed Network Services. 9. Frame Relay Pricing. Pricing Structures. PVC Pricing. Access Circuit Charges. Port Connection Charges. Permanent Virtual Circuit Changes. Variations in PVC Pricing. SVC Pricing. International Issues. Ancillary Carrier Services. 10. Procurement of Frame Relay Services. The RFP Process. Objectives. Evaluation Criteria. The RFP. Contract Negotiations. Monitoring the Contract. 11. Design of Frame Relay Networks. Overview. Physical Network Design. Backbone Network Design. Access Network Design. Virtual Circuit Network Design. The Access Network Design Process. Set Objectives. Inventory the Sites. Collect Traffic Statistics. Sketch the PVC Map. Consider Asymmetric PVCs. Determine CIR. Determine Port Connection Speed. Determine Access Circuit Speed. Decide on Backup Options. Plan for Implementation. Implement and Fine-Tune. Case Study: Redesigning a Private Line Network. Solution 1: Star Topology Frame Relay Network. Solution 2: Hybrid Frame Relay Network. Solution 3: Partial Mesh Topology Frame Relay Network. Other Design Issues. Designing for Performance. Designing for Switched Virtual Circuits. Designing for Disaster Recovery. Exercise. 12. Voice over Frame Relay. Advantages. Challenges. Measuring Voice Quality. Improving Voice Performance. Voice Compression. Silence Suppression. Voice-Engineering Techniques. Small Voice Frames. Fragmentation of Data Frames. Priority of Voice Frames. QoS in the Frame Relay Network. Fax over Frame Relay. Voice-Band Modem Data over Frame Relay. Video over Frame Relay. Considerations. Performance and Quality Issues. Technical Issues. Management and Administrative Issues. Perception Issues. Standards. FRF.11 Voice over Frame Relay Implementation Agreement. FRF.12 Frame Relay Fragmentation Implementation Agreement. 13. Internetworking with Frame Relay. Routing over Frame Relay Networks. Routing Protocols. Improved Routing Protocols. Frame Relay Interfaces for Routers. TCP and Congestion Control. Routers and Congestion. Prioritizing Traffic within Routers. Effects of Frame Relay on Router Interconnectivity. RFC 1490/2427 Multiprotocol Encapsulation. RFC 1490 Encapsulation Formats. Address Resolution with RFC 1490. Encapsulation of X.25. RFC 1490 Misunderstandings. Routable Protocols over Frame Relay. TCP/IP over Frame Relay. IPX over Frame Relay. IBM's SNA over Frame Relay. SNA Background. SNA over Frame Relay. IBM Hardware/Software Support for Frame Relay. SNA Gateways. Router-Based RFC 1490 Multiprotocol Encapsulation. Data Link Switching. Sending SNA over Frame Relay. Nonroutable Protocols over Frame Relay. 14. Frame Relay and ATM. Comparison. Network Interworking. Service Interworking. The ATM Frame User-Network Interface. Migration Path. Conclusion. Appendix A - Frame Relay Information Sources. Web Sites. Internet Newsgroups (Usenet). Books. Magazines (monthly). Periodicals (weekly). Newsletters, Mailing Lists. Frame Relay Vendors and Carriers. Appendix B - Answers to Exercises. Chapter 3 Exercises. Chapter 11 Exercises. Glossary. References. Index. 0201485249T04062001",data oriented architecture,173
f16778cf55577077edc2105942cfd1f3107b27e6,filtered,semantic_scholar,MobiSys 2007,2007-01-01,semantic_scholar,programming and securing service-oriented wireless sensor networks,https://www.semanticscholar.org/paper/f16778cf55577077edc2105942cfd1f3107b27e6,"Our demonstrator shows the implementation of a Serviceoriented Architecture (SoA) for wireless sensor-actuator networks (WSAN). It demonstrates the feasibility of our serviceoriented system in a real-world, resource-restricted WSAN based on off-the-shelf MICAz motes running the operation system TinyOS. In contrast to data-oriented approaches our service-oriented system does not only provide ”traditional” uni-directional data transfer (from sensor nodes to a base station), but also enables autonomous collaboration of sensor nodes. The nodes collaborate in the sense that the input of several sensors is used to trigger actuators, which in turn affect the sensor readings etc. For demonstration purposes we built an intelligent greenhouse that autonomously adapts its ambience in order to cultivate plants according to their individual and collective needs (see Figure 1). E.g., the lighting of the greenhouse is adapted considering all plants’ needs and the sunlight. For visualization we constructed a miniature version of the greenhouse with several plants. The greenhouse itself as well as the plants within are all equipped with various sensors and actuators in order to measure and modify the plants’ ecosystem (i.e. light and soil humidity). We also simulate external influence on the ecosystem, such as the influence of the sun on the greenhouse’s light control. Protocol details of our service-oriented system can be observed via a couple of PDAs connected to the sensor nodes. These PDAs allow for inspecting and changing the internal state of sensor nodes. Hence, attendees of the demonstration can use these PDAs to interact with the WSAN. We show two fundamental aspects of our Service-oriented Architecture in the demonstration: • Service description and execution: The intelligent greenhouse application is composed of services. The services are described and executed by Talassa (Tasking Language for Service-oriented Sensor-Actuator Networks [1]). • Secure lookup of available services: Services are stored in a distributed service directory, SCAN (Secure Content Addressable Network [2]). As this is a security critical component of our architecture, SCAN has been designed to provide secure service discovery. Talassa is a description language for distributed WSAN applications based on services. An application consists of a number of atomic services, which perform either basic hardware interaction or influence the control flow of other services. A virtual machine on each sensor node executes any of the above mentioned service types and provides inter-service new plant “sun”",data oriented architecture,174
47963243de795b321fe10edb46a3a9d1931960ec,filtered,semantic_scholar,,1998-01-01,semantic_scholar,toward an exemplar-based computational model for cognitive grammar,https://www.semanticscholar.org/paper/47963243de795b321fe10edb46a3a9d1931960ec,"An exemplar-based computational framework is presented which is compatible with Cognitive Grammar. In an exemplar-based approach, language acquisition is modeled as the incremental, data-oriented storage of experiential patterns, and language performance as the extrapolation of information from those stored patterns on the basis of a language-independent information-theoretic similarity metric. We show that this simple architecture works for many aspects of phonological, morphological, and morphosyntactic acquisition and processing. Furthermore, we sketch how the approach may also work for syntactic processing. A central insight of the approach, based on the results of computational modeling experiments, is that abstraction of representations is not only unnecessary to achieve generalization (i.e. to make the system productive, and to make it gòbeyond' the learned patterns), but even harmful, and that useful language-independent metrics can be found for deening similarity in the context of language processing. In the generative tradition, generality is achieved by means of abstraction, and the representations of choice to describe these abstractions are rules. This implies that redundancy and the storage of individual instances are to be avoided, except for exceptions to the generalizations expressed in rules. In Langacker, 1991 (Chapter 10), this methodology is critically examined, and cognitive grammar is described as an alternative usage-based model of language structure. In the latter, bottom-up, approach, patterns (rules, generalizations) and (redundant) instantiations of those rules are assumed to co-exist in the grammar, describing phenomena at all levels of generality, from exceptionless regularities to idiosyncratic exceptions. Rules are presumed to be necessary for the computation of novel instantiations. In the remainder of this paper we will introduce an exemplar-based approach to language acquisition and processing. The approach is in large part compatible with Lan-gacker's usage-based model, but is more radical in its ""maximalism"": language knowledge is supposed to consist only of ""instantiations"" (exemplars); there is no role for explicit abstractions corresponding to (sub)regularities. We will argue on the basis of computational modeling experiments that the adoption of abstractions (rules, patterns), taken as necessary for explaining generalization and productivity in both the generative and the cognitive grammar approach, is misguided. Furthermore, the exemplar-based approach contributes to making cognitive grammar ideas more concrete by providing computational operationalisations of both acquisition and processing in such a framework.",data oriented architecture,175
5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,filtered,semantic_scholar,,2010-01-01,semantic_scholar,software design and class diagrams,https://www.semanticscholar.org/paper/5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,"ion • ignoring detail to get the high level structure right Decomposition and Modularization • big systems are composed from small components Encapsulation/information hiding • the ability to hide detail (linked to abstraction) Defined interfaces • separable from implementation Evaluation of structure • Coupling: How interlinked a component is • Cohesion: How coherent a component is © 2004-2007 SEOC Lecture Note 04 5 Architecture and Structure Architectural structures and viewpoints Architectural styles Design patterns • small-scale patterns to guide the designer Families and frameworks • component sets and ways of plugging them together • software product lines Architectural design Architectural structures and viewpoints deal with system facets (e.g., physical view, functional or logical view, security view, etc.) separately. Depending on the architectural emphasis, there are different styles, for example, Three-tier architecture for a distributed system (interface, middleware, back-end database), Blackboard, Layered architectures, Model-View-Controller, Time-triggered and so forth. Architectural Design supports stakeholder communication, system analysis and large-scale reuse. It is possible to distinguish diverse design strategies: function oriented (sees the design of the functions as primary), data oriented (sees the data as the primary structured element and drives design from there), object oriented (sees objects as the primary element of design). There is no clear distinction between Sub-systems and modules. Intuitively, sub-systems are independent and composed of modules, have defined interfaces for communication with other sub-systems. Modules are system components and provide/make use of service(s) to/provided by other modules. The system architecture affects the quality attributes (e.g., performance, security, availability, modifiability, portability, reusability, testability, maintainability, etc.) of a system. It supports quality analysis (e.g., reviewing techniques, static analysis, simulation, performance analysis, prototyping, etc.). It allows to define (predictive) measures (i.e., metrics) on the design, but they are usually very dependent on the process in use. The software architecture is the fundamental framework for structuring the system. Different architectural models (e.g., system organizational models, modular decomposition models and control models) may be developed. Design decisions enhance system attributes like, for instance, performance (e.g., localize operations to minimize sub-system communication), security (e.g., use a layered architecture with critical assets in inner layers), safety (e.g., isolate safety-critical components), availability (e.g., include redundant components in the architecture) and maintainability (e.g., use fine-grain self-contained components). Readings • P. Kruchten, H. Obbink, J. Stafford. The Past, Present and Future of Software Architecture. IEEE Software, March/April 2006. © 2004-2007 SEOC Lecture Note 04 6 Architecture Models A static structural model that shows the subsystems or components that are to be developed as separate units. A dynamic process model that shows how the system is organized into processes at run-time. This may be different from the static model. An interface model that defines the services offered by each sub-system through their public interface. A relationship model that shows relationships such as data flow between the sub-systems. Comparing Architecture Design Notations • Modeling Components: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Connectors: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Configurations: Understandable Specifications, Compositionality (and Conposability), Refinement and Traceability, Heterogeneity, Scalability, Evolvability, Dynamism, Constraints, Non-functional Properties UML Design Notations • Static Notations: Class and object diagrams, Component diagrams, Deployment diagrams, CRC Cards • Dynamic Notations: Activity diagrams, Communication diagrams, Statecharts, Sequence diagrams What are the Architect’s Duties? • Get it Defined, documented and communicated, Act as the emissary of the architecture, Maintain morale • Make sure everyone is using it (correctly), management understands it, the software and system architectures are in synchronization, the right modeling is being done, to know that quality attributes are going to be met, the architecture is not only the right one for operations, but also for deployment and maintenance • Identify architecture timely stages that support the overall organization progress, suitable tools and design environments, (and interact) with stakeholders • Resolve disputes and make tradeoffs, technical problems • Manage risk identification and risk mitigation strategies associated with the architecture, understand and plan for evolution © 2004-2007 SEOC Lecture Note 04 7 Class Diagrams Support architectural design • Provide a structural view of systems Represent the basics of Object-Oriented systems • identify what classes there are, how they interrelate and how they interact • Capture the static structure of Object-Oriented systems how systems are structured rather than how they behave Constrain interactions and collaborations that support functional requirements • Link to Requirements",data oriented architecture,176
e6937bb8e048376916a77a5ee6aa7d52ab568c6a,filtered,semantic_scholar,International Journal of Trend in Scientific Research and Development,2019-01-01,semantic_scholar,smart grid communication protocols,https://www.semanticscholar.org/paper/e6937bb8e048376916a77a5ee6aa7d52ab568c6a,"Present power grids are getting replaced by smart grids, mainly for improving performance of existing power grid. Integration of electrical, electronics and computer science have led this technology more popular. Smart grid technology is characterized by full duplex communication, automatic metering infrastructure, renewable energy integration, distribution automation and complete monitoring and control of entire power grid. Wireless sensor networks (WSNs) are small micro electrical mechanical systems that are deployed to collect and communicate the data from surroundings. Security of wireless sensor based communication network is a major concern for researchers and developers. The address oriented design and development approach for usual communication network requires a paradigm shift to design data oriented WSN architecture. This paper is presents different communication protocols used in smart grid technology.",data oriented architecture,177
8e572fed5fc239d796dcb44633897ebf6fb40887,filtered,semantic_scholar,2005 IEEE International Conference on Cluster Computing,2005-01-01,semantic_scholar,ibrix file system: architecture and design,https://www.semanticscholar.org/paper/8e572fed5fc239d796dcb44633897ebf6fb40887,"Summary form only given. Recently, there have been significant advances in file system technology in the form of cluster, distributed and/or parallel file systems in an attempt to break the I/O bottleneck plaguing the effective utilization of clusters of commodity computers. Successes have been achieved in scaling performance when defined as bandwidth, as typified by sequential access of large files using large I/O sizes. Applications with such access patterns does not represent all application classes to which cluster computing is being applied as a potential solution, the balance being those that access small and medium sized files in a random or sequential manner using small I/O sizes. Specifically, these access patterns perform as many and often more ""metadata"" operations on the file system as data reads or writes. Since metadata operations are at the heart of a file system and impact its integrity, scaling throughput or metadata performance through concurrency across many servers poses the most difficult technical challenge in file system design. This poster will present details about the fundamentally new architecture for constructing parallel file systems called segmented file system that scales linearly for both data and metadata oriented applications. Performance results will be presented with the IBRIX Fusion product (http:Wwww.ibrix.com) based on this architecture using micro benchmarks as well as real applications demonstrating the general-purpose scalability of this architecture. The poster will also show typical I/O cluster offerings from Dell that use IBRIX, using large cluster installations at universities and research labs as an example",data oriented architecture,178
f323b4f434bdfc48836d8eebd5cf267c9258aa09,filtered,semantic_scholar,BDCA'17,2017-01-01,semantic_scholar,exploiting open data to improve the business intelligence & business discovery experience,https://www.semanticscholar.org/paper/f323b4f434bdfc48836d8eebd5cf267c9258aa09,"The extent to which data mining tools are able to make efficient use of an open data oriented strategy in a smart city is limited. In a sense that it is not fully automated, incompatible or has to be supervised. These sets of tools may offer the possibility to import a dataset in a certain predefined standardized format, still, they do not make it a part of their workflow and algorithms in a fully unsupervised manner (i.e without ongoing human guidance). In a departure from previous research works, in this paper, we present a middleware architecture that exploits open data as background knowledge by acting as a bridge between data mining tools and open data resources.",data oriented architecture,179
10.1007/978-3-030-88207-5_17,filtered,"Cooperative Design, Visualization, and Engineering",Springer,2021-01-01 00:00:00,springer,building a big data oriented architecture for enterprise integration,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88207-5_17,"Digital transformation is happening across all industries and affecting all facets of our daily life. However, in many corporations, this important process is fragmented and is undertaken without a farsighted plan to take advantage of an invaluable resource: data. This can be due to a variety of reasons, for example, lack of funding, poor business vision, inappropriate consulting or deployment. Digital transformation is a considerable investment since it will determine the system’s ability to grow and adapt to the company’s changing requirements. To achieve that end, the architecture must be flexible both in development and deployment and must also be able to harness the ever-increasing data of the corporation. Among the widely used information system architectures being used in the world, Micro-service is a standout with many advantages. The adaptation of this architecture to work with Big Data, as well as to tackle different aspects of a data system such as load-balancing, file handling and storage, etc. is a very practical area of research. This paper presents such an enterprise integration solution for a mega-corporation client in Vietnam, the An Pha Petrol Group Joint Stock Company, including the architecture and technologies used to build a comprehensive system that brings novel experiences to its 2,000 internal users. It consists of building the information infrastructure and system, super applications for both desktop and mobile devices to enhance the work performance and quality. The approaches and results of this paper are applicable to similar large enterprise solutions.",data oriented architecture,180
10.1109/cast.2016.7914932,filtered,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",IEEE,2016-12-21 00:00:00,ieeexplore,big data architecture with mobile cloud in cdroid operating system for storing huge data,https://ieeexplore.ieee.org/document/7914932/,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,data centric architecture,181
10.1109/innovate-data.2017.14,filtered,2017 International Conference on Big Data Innovations and Applications (Innovate-Data),IEEE,2017-08-23 00:00:00,ieeexplore,bringing big data into the car: does it scale?,https://ieeexplore.ieee.org/document/8316294/,"The increasing velocity of big data captured by various sensors and processed in real-time offers support for a range of new application domains. For car information systems (CIS), data from different sources including IoT needs to be combined to offer an adequate service to the user. In this paper, we introduce a novel CIS big data-centric architecture based on a smart streaming infrastructure integrating data source in and outside of the car. We have created a prototype implementation of this architecture and run several experiments to validate the quality of our solution. Especially, we have examined the fault tolerance of the architecture by systematically introducing failures and evaluating their effects on the car information system. The experimental results show that our solution for a smart data based car information system is both scalable and fault tolerant.",data centric architecture,182
10.1109/cts.2014.6867550,filtered,2014 International Conference on Collaboration Technologies and Systems (CTS),IEEE,2014-05-23 00:00:00,ieeexplore,defining architecture components of the big data ecosystem,https://ieeexplore.ieee.org/document/6867550/,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a socalled Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.",data centric architecture,183
10.1109/trustcom.2016.0248,filtered,2016 IEEE Trustcom/BigDataSE/ISPA,IEEE,2016-08-26 00:00:00,ieeexplore,rethinking high performance computing system architecture for scientific big data applications,https://ieeexplore.ieee.org/document/7847131/,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",data centric architecture,184
10.1109/tcc.2015.2474385,filtered,IEEE Transactions on Cloud Computing,IEEE,2020-06-01 00:00:00,ieeexplore,cross-cloud mapreduce for big data,https://ieeexplore.ieee.org/document/7229313/,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",data centric architecture,185
10.1007/978-3-319-28031-8_11,filtered,Innovations in Bio-Inspired Computing and Applications,Springer,2016-01-01 00:00:00,springer,data centric text processing using mapreduce,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-28031-8_11,"Processing huge volume of data opened new opportunities in ecommerce, engineering, business and large computing applications. MapReduce programming model is a parallel data processing approach for execution on computer clusters. This model provides an abstraction to design scalable computing algorithm for big data processing. For batch processing types of data processing, MapReduce model provides faster computation. The key/value pair generation of MapReduce program creates memory overhead and deserialization overhead due to data redundancy. Redundancy of data is one of the most important factors that consumes space and affect system performance while using large set of data. This overhead can be avoided considerably by using a novel approach that we developed named Data Triggered Multithreaded Programming (DTMP) model. In this paper, we demonstrate the use of DTMP model using a large dataset with author details and his publications. The Data Triggered Multithreaded Programming can dynamically allocate the resources and can identify the data repetition occurring during computation. DTMP model when applied to the MapReduce programming model brings performance improvement to the system. The major contributions of this work are a simple, scalable and powerful processing of text data that enables automatic parallelization and distribution of large-scale computations.",data centric architecture,186
http://arxiv.org/abs/1705.04958v1,filtered,arxiv,arxiv,2017-05-14 00:00:00,arxiv,a proposed architecture for big data driven supply chain analytics,http://arxiv.org/abs/1705.04958v1,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.",data centric architecture,187
10.23919/date51398.2021.9473940,filtered,"2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)",IEEE,2021-02-05 00:00:00,ieeexplore,everest: a design environment for extreme-scale big data analytics on heterogeneous platforms,https://ieeexplore.ieee.org/document/9473940/,"High-Performance Big Data Analytics (HPDA) applications are characterized by huge volumes of distributed and heterogeneous data that require efficient computation for knowledge extraction and decision making. Designers are moving towards a tight integration of computing systems combining HPC, Cloud, and IoT solutions with artificial intelligence (AI). Matching the application and data requirements with the characteristics of the underlying hardware is a key element to improve the predictions thanks to high performance and better use of resources. We present EVEREST, a novel H2020 project started on October 1, 2020, that aims at developing a holistic environment for the co-design of HPDA applications on heterogeneous, distributed, and secure platforms. EVEREST focuses on programmability issues through a data-driven design approach, the use of hardware-accelerated AI, and an efficient runtime monitoring with virtualization support. In the different stages, EVEREST combines state-of-the-art programming models, emerging communication standards, and novel domain-specific extensions. We describe the EVEREST approach and the use cases that drive our research.",data driven architecture,188
10.1007/978-3-030-87571-8_64,filtered,Web Information Systems and Applications,Springer,2021-01-01 00:00:00,springer,a big data driven design method of helicopter health management system,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87571-8_64,"This article briefly describes the development process of aircraft health management, and discusses the basic principles of helicopter health and use monitoring systems. Then proposed a big data-driven helicopter health management system architecture, analyzed the relationship between the components of the helicopter health management system, and analyzed the sources of the helicopter health management big data, and finally proposed Big data and knowledge-driven helicopter health management system Program. This paper explores the design method of the helicopter health management system driven by big data, and reserves the theoretical basis for the practical research of the future system.",data driven architecture,189
10.1007/978-981-10-6611-5_37,filtered,Humanizing Digital Reality,Springer,2018-01-01 00:00:00,springer,navigating the intangible spatial-data-driven design modelling in architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-6611-5_37,"Over the past few decades, digital technologies have played an increasingly substantial role in how we relate to our environment. Through mobile devices, sensors, big data and ubiquitous computing amongst other technologies, our physical surroundings can be augmented with intangible data, suggesting that architects of the future could start to view the increasingly digitally saturated world around them as an information-rich environment (McCullough in Ambient commons: attention in the age of embodied information, The MIT Press, Cambridge, 2013 ). The adoption of computational design and digital fabrication processes in has given architects and designers the opportunity to design and fabricate architecture with unseen material performance and precision. However, attempts to combine these tools with methods for navigating and integrating the vast amount of available data into the design process have appeared slow and complicated. This research proposes a method for data capture and visualization which, despite its infancy, displays potentials for use in projects ranging in scale from the urban to the interior evaluation of existing buildings. The working research question is as follows: “How can we develop a near real-time data capture and visualization method, which can be used across multiple scales in various architectural design processes?”",data driven architecture,190
10.1007/978-3-319-75429-1_18,filtered,Integrated Uncertainty in Knowledge Modelling and Decision Making,Springer,2018-01-01 00:00:00,springer,big data driven architecture for medical knowledge management systems in intracranial hemorrhage diagnosis,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75429-1_18,"Stroke is the most common and dangerous cerebrovascular disease. According to the statistics from World Health Organization (WHO), only following heart attack, stroke is one of the two leading causes of human deaths. In addition, in Vietnam, a shortage of specialized equipment and qualified professionals is becoming a significant problem for not only accurate diagnosis but also timely and effective treatment of stroke, especially intracranial hemorrhage (ICH), an acute case of stroke. This research will analyze challenges and show solutions for constructing an effective knowledge system in ICH diagnosis and treatment that helps to shorten professional gap among hospitals and regions. We suggest a service-oriented architecture for the big data driven knowledge system based on medical imaging of ICH. The architecture ensures the development of knowledge obeying a systematic and complete process including the exploration and exploitation of knowledge from medical imaging. Besides, the architecture adapts to modern trends in knowledge service modeling.",data driven architecture,191
10.1007/978-3-319-07863-2_21,filtered,Human Interface and the Management of Information. Information and Knowledge in Applications and Services,Springer,2014-01-01 00:00:00,springer,data driven enterprise ux: a case study of enterprise management systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07863-2_21,"This paper describes and makes a case for a data driven user experience design process for Enterprise IT. The method described employs an approach that focuses on defining the key modules (objects) in an enterprise IT software and the data sets used by these modules very early in the design process. We discuss how mapping parent child relationships between key entities in the software and the linked data helps create a holistic view of the product ecosystem which in turn allows the designer to create an uncluttered information architecture and user journey that maps closely to mental construct of the system in the user’s mind. We further argue that in the present age of big data, working with well-defined data sets and visible data relationships creates a valuable information repository for the designer to take decisions regarding task optimization and building business intelligence in the system itself. We also discuss the urgent need, advantages and methods of ‘consumerizing’ the Enterprise UI to increase users productivity and reduce the learning curve. Lastly, these ideas are exemplified through a real life case study for an enterprise server management system.",data driven architecture,192
http://arxiv.org/abs/2106.15356v2,filtered,arxiv,arxiv,2021-06-26 00:00:00,arxiv,"scalable gaussian processes for data-driven design using big data with
  categorical factors",http://arxiv.org/abs/2106.15356v2,"Scientific and engineering problems often require the use of artificial
intelligence to aid understanding and the search for promising designs. While
Gaussian processes (GP) stand out as easy-to-use and interpretable learners,
they have difficulties in accommodating big datasets, categorical inputs, and
multiple responses, which has become a common challenge for a growing number of
data-driven design applications. In this paper, we propose a GP model that
utilizes latent variables and functions obtained through variational inference
to address the aforementioned challenges simultaneously. The method is built
upon the latent variable Gaussian process (LVGP) model where categorical
factors are mapped into a continuous latent space to enable GP modeling of
mixed-variable datasets. By extending variational inference to LVGP models, the
large training dataset is replaced by a small set of inducing points to address
the scalability issue. Output response vectors are represented by a linear
combination of independent latent functions, forming a flexible kernel
structure to handle multiple responses that might have distinct behaviors.
Comparative studies demonstrate that the proposed method scales well for large
datasets with over 10^4 data points, while outperforming state-of-the-art
machine learning methods without requiring much hyperparameter tuning. In
addition, an interpretable latent space is obtained to draw insights into the
effect of categorical factors, such as those associated with building blocks of
architectures and element choices in metamaterial and materials design. Our
approach is demonstrated for machine learning of ternary oxide materials and
topology optimization of a multiscale compliant mechanism with aperiodic
microstructures and multiple materials.",data driven architecture,193
http://arxiv.org/abs/2103.04185v1,filtered,arxiv,arxiv,2021-03-06 00:00:00,arxiv,"everest: a design environment for extreme-scale big data analytics on
  heterogeneous platforms",http://arxiv.org/abs/2103.04185v1,"High-Performance Big Data Analytics (HPDA) applications are characterized by
huge volumes of distributed and heterogeneous data that require efficient
computation for knowledge extraction and decision making. Designers are moving
towards a tight integration of computing systems combining HPC, Cloud, and IoT
solutions with artificial intelligence (AI). Matching the application and data
requirements with the characteristics of the underlying hardware is a key
element to improve the predictions thanks to high performance and better use of
resources.
  We present EVEREST, a novel H2020 project started on October 1st, 2020 that
aims at developing a holistic environment for the co-design of HPDA
applications on heterogeneous, distributed, and secure platforms. EVEREST
focuses on programmability issues through a data-driven design approach, the
use of hardware-accelerated AI, and an efficient runtime monitoring with
virtualization support. In the different stages, EVEREST combines
state-of-the-art programming models, emerging communication standards, and
novel domain-specific extensions. We describe the EVEREST approach and the use
cases that drive our research.",data driven architecture,194
http://arxiv.org/abs/2008.00442v2,filtered,arxiv,arxiv,2020-08-02 00:00:00,arxiv,"identifying the elastic isotropy of architectured materials based on
  deep learning method",http://arxiv.org/abs/2008.00442v2,"With the achievement on the additive manufacturing, the mechanical properties
of architectured materials can be precisely designed by tailoring
microstructures. As one of the primary design objectives, the elastic isotropy
is of great significance for many engineering applications. However, the
prevailing experimental and numerical methods are normally too costly and
time-consuming to determine the elastic isotropy of architectured materials
with tens of thousands of possible microstructures in design space. The quick
mechanical characterization is thus desired for the advanced design of
architectured materials. Here, a deep learning-based approach is developed as a
portable and efficient tool to identify the elastic isotropy of architectured
materials directly from the images of their representative microstructures with
arbitrary component distributions. The measure of elastic isotropy for
architectured materials is derived firstly in this paper to construct a
database with associated images of microstructures. Then a convolutional neural
network is trained with the database. It is found that the convolutional neural
network shows good performance on the isotropy identification. Meanwhile, it
exhibits enough robustness to maintain the performance under fluctuated
material properties in practical fabrications. Moreover, the well-trained
convolutional neural network can be successfully transferred among different
types of architectured materials, including two-phase composites and porous
materials, which greatly enhance the efficiency of the deep learning-based
approach. This study can give new inspirations on the fast mechanical
characterization for the big-data driven design of architectured materials.",data driven architecture,195
10.3390/books978-3-03943-135-9,filtered,core,'MDPI AG',2021-05-01 00:00:00,core,computer-aided manufacturing and design,,"Recent advancements in computer technology have allowed for designers to have direct control over the production process through the help of computer-based tools, creating the possibility of a completely integrated design and manufacturing process. Over the last few decades, ""artificial intelligence"" (AI) techniques, such as machine learing and deep learning, have been topics of interest in computer-based design and manufacturing research fields. However, efforts to develop computer-based AI to handle big data in design and manufacturing have not yet been successful. This Special Issue aims to collect novel articles covering artificial intelligence-based design, manufacturing, and data-driven design. It will comprise academics, researchers, mechanical, manufacturing, production and industrial engineers and professionals related to engineering design and manufacturing",data driven architecture,196
10.1016/j.jii.2019.04.003,filtered,core,'Elsevier BV',2019-09-01 00:00:00,core,a data-driven scheduling approach to smart manufacturing,https://core.ac.uk/download/286208185.pdf,"Traditional methods of scheduling are mostly based on the use of pieces of information directly related to the performance of schedules, as for instance processing times, delivery dates, etc., assuming that the production system is operating normally. In the case of malfunctions, the literature concentrates on the ensuing corrective operations, like scheduling with machine breakdowns or under remanufacturing considerations. These event-driven approaches are mainly used in dynamic scheduling or rescheduling systems. Unlike those, Smart Manufacturing and Industry 4.0 production environments integrate the physical and decision-making aspects of manufacturing processes in order to achieve their decentralization and autonomy. On these grounds we propose a data-driven architecture for scheduling, in which the system has real time access to data. Then, scheduling decisions can be made ahead of time, on the basis of more information. This promising approach is based on the architecture of cyber-physical systems, with a data-driven engine that uses, in particular, Big Data techniques to extract vital information for Industry 4.0 systems.Fil: Rossit, Daniel Alejandro. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Tohmé, Fernando Abel. Universidad Nacional del Sur. Departamento de Economía; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Frutos, Mariano. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Investigaciones Económicas y Sociales del Sur. Universidad Nacional del Sur. Departamento de Economía. Instituto de Investigaciones Económicas y Sociales del Sur; Argentin",data driven architecture,197
10.3846/cs.2021.12933,filtered,core,'Vilnius Gediminas Technical University',2021-02-25 00:00:00,core,creativity forward: a framework that integrates data analysis techniques to foster creativity within the creative process in user experience contexts,https://core.ac.uk/download/481324485.pdf,"The latest technological advancements allow users to generate a large volume of data related to their experiences and needs. However, the absence of an advanced methodology that links the big data and the creative process prevents the effective use of the data and extracting all its potential and knowledge in this context, which is crucial in offering user-centred solutions. Incorporating data creatively and critically as design material can help us learn and understand user needs better. Therefore, design can bring deeper meaning to data, just as data can enhance design practice. Accordingly, this work raises a reflection on whether designers could appropriate the workflow of data science in order to integrate it into the research process in the creative process within a framework of user experience analysis. The proposed model: data-driven design model, enhances the exploratory design of problem space and assists in the creation of ideas during the conceptual design phase. In this way, this work offers an integrated vision, enhancing creativity in industrial design as an instrument for the achievement of the proper and necessary balance between intuition and reason, design, and science",data driven architecture,198
cern,filtered,core,10.23726/cij.2018.736,2018-12-01 00:00:00,core,https://core.ac.uk/download/201170889.pdf,"[{'title': None, 'identifiers': ['2413-9505', 'issn:2413-9505']}]","Today, interest in the analysis of cognitive activities related to creativity has become a critical interdisciplinary topic. The need for effective means for the use of data management and analysis in design is growing. As a tool to assist designers in the early stages of design, there have been discussed the effects of considering the integration of big data via the data-driven design model within the creative process of new product development. In this way, new perspectives are studied about how data and creativity science will involve the development of both design and creativity models",data driven architecture,199
,filtered,core,,2013-01-01 00:00:00,core,architecture framework and components for the big data ecosystem draft version 0.2,,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a so-called Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties ( also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Dat",data centric architecture,200
,filtered,core,,2010-01-01 00:00:00,core,"boom analytics: exploring data-centric, declarative programming for the cloud",,"Building and debugging distributed software remains ex-tremely difficult. We conjecture that by adopting a data-centric approach to system design and by employing declar-ative programming languages, a broad range of distributed software can be recast naturally in a data-parallel program-ming model. Our hope is that this model can significantly raise the level of abstraction for programmers, improving code simplicity, speed of development, ease of software evo-lution, and program correctness. This paper presents our experience with an initial large-scale experiment in this direction. First, we used the Overlog language to implement a “Big Data ” analytics stack that is API-compatible with Hadoop and HDFS and provides com-parable performance. Second, we extended the system with complex distributed features not yet available in Hadoop, including high availability, scalability, and unique monitor-ing and debugging facilities. We present both quantitative and anecdotal results from our experience, providing some concrete evidence that both data-centric design and declara-tive languages can substantially simplify distributed systems programming",data centric architecture,201
,filtered,core,"eScholarship, University of California",2011-01-01 00:00:00,core,declarative systems,,"Building system software is a notoriously complex and arduous endeavor.Developing tools and methodologies for practical system software engineeringhas long been an active area of research.  This thesis explores system softwaredevelopment through the lens of a declarative, data-centric programminglanguage that can succinctly express high-level system specifications and bedirectly compiled to executable code.  By unifying specification andimplementation, our approach avoids the common problem of implementationsdiverging from specifications over time.  In addition, we show that using adeclarative language often results in drastic reductions in code size (100× andmore) relative to procedural languages like Java and C++.  We demonstrate theseadvantages by implementing a host of functionalities at various levels of thesystem hierarchy, including network protocols, query optimizers, and schedulingpolicies.  In addition to providing a compact and optimized implementation, wedemonstrate that our declarative implementations often map very naturally totraditional specifications: in many cases they are line-by-line translations ofpublished pseudcode.We started this work with the hypothesis that declarative languages --originally developed for the purposes of data management and querying -- couldbe fruitfully adapted to the specification and implementation of core systeminfrastructure.  A similar argument had been made for networking protocols afew years earlier [61].  However, our goals were quite different: we wanted toexplore a broader range of algorithms and functionalities (dynamic programming,scheduling, program rewriting, and system auditing) that were part of complex,real-world software systems.  We identified two existing system components --query optimizers in a DBMS and task schedulers in a cloud computing system --that we felt would be better specified via a declarative language.  Given ourinterest in delivering real-world software, a key challenge was identifying theright system boundary that would permit meaningful declarative implementationsto coexist within existing imperative system architectures.  We found thatrelations were a natural boundary for maintaining the ongoing system state onwhich the imperative and declarative code was based, and provided an elegantway to model system architectures.This thesis explores the boundaries of declarative systems via two projects.We begin with Evita Raced; an extensible compiler for the Overlog language usedin our declarative networking system, P2.  Evita Raced is a metacompiler -- anOverlog compiler written in Overlog -- that integrates seamlessly with the P2dataflow architecture.  We first describe the minimalist design of Evita Raced,including its extensibility interfaces and its reuse of the P2 data model andruntime engine.  We then demonstrate that a declarative language like Overlogis well-suited to expressing traditional and novel query optimizations as wellas other program manipulations, in a compact and natural fashion.  FollowingEvita Raced, we describe the initial work in BOOM Analytics, which began as alarge-scale experiment at building ""cloud"" software in a declarative language.Specifically, we used the Overlog language to implement a ""Big Data"" analyticsstack that is API-compatible with the Hadoop MapReduce architecture andprovides comparable performance.  We extended our declarative version of Hadoopwith complex distributed features that remain absent in the stock Hadoop Javaimplementation, including alternative scheduling policies, online aggregation,continuous queries, and unique monitoring and debugging facilities.  We presentquantitative and anecdotal results from our experience, providing concreteevidence that both data-centric design and declarative languages cansubstantially simplify systems programming",data centric architecture,202
,filtered,core,,2010-01-01 00:00:00,core,"analytics: exploring data-centric, declarative programming for the cloud",,"Building and debugging distributed software remains extremely difficult. We conjecture that by adopting a datacentric approach to system design and by employing declarative programming languages, a broad range of distributed software can be recast naturally in a data-parallel programming model. Our hope is that this model can significantly raise the level of abstraction for programmers, improving code simplicity, speed of development, ease of software evolution, and program correctness. This paper presents our experience with an initial largescale experiment in this direction. First, we used the Overlog language to implement a “Big Data ” analytics stack that is API-compatible with Hadoop and HDFS and provides comparable performance. Second, we extended the system with complex distributed features not yet available in Hadoop, including high availability, scalability, and unique monitoring and debugging facilities. We present both quantitative and anecdotal results from our experience, providing some concrete evidence that both data-centric design and declarative languages can substantially simplify distributed systems programming",data centric architecture,203
,filtered,core,,2016-09-26 00:00:00,core,analysis of the big data based on mapreduce,,"Abstract. Big Data are becoming a popular technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. Big Data is bringing a positive change in the decision making process of various business organizations.In this paper, MapReduce big data analysis methods, and with SQL server performance comparison, the experimental results show that, compared to SQL server, MapReduce method loads a small time, as the data set increases, the performance MapReduce approach is better. So MapReduce method has better scalability and speedup for large data processing applications. ",data centric architecture,204
,filtered,core,,2021-01-01 00:00:00,core,data-driven design orientado ao comportamento sustentável : diretrizes para briefing metaprojetual,https://core.ac.uk/download/482192986.pdf,"Orientador: Prof. Dr. Aguinaldo dos SantosDissertação (mestrado) - Universidade Federal do Paraná, Setor de Artes, Comunicação e
Design, Programa de Pós-Graduação em Design. Defesa : Curitiba, 28/05/2021Inclui referências: p. 138-153Resumo: A presente dissertação apresenta um estudo com característica exploratória, de natureza aplicada, por meio de uma abordagem fenomenológica e qualitativa, sobre o uso do Data- Driven Design em um briefing metaprojetual para promover comportamentos mais sustentáveis. Ao longo das últimas décadas, as inovações em tecnologias da informação e comunicação vêm proporcionando diversas transformações no mercado de consumo e alterando o comportamento dos usuários. Essas modificações ocorrem nos diferentes pontos da jornada de consumo, seja no modo como os usuários pesquisam, adquirem, utilizam, avaliam ou descartam produtos e serviços. Consequentemente, o aumento da quantidade de dados digitais (big data) e do volume de tráfego on-line tem sido exponencial. Por meio da análise de big data é possível obter novo e/ou melhor entendimento acerca do comportamento humano de modo a influenciá-lo. Entretanto, muitas dessas análises estão sendo utilizadas como instrumentos para estimular o consumo. Neste cenário, os comportamentos de consumo dos últimos 50 anos têm contribuído para os impactos negativos na sustentabilidade, como por exemplo, para o aumento da temperatura do planeta. Por outro lado, as investigações de big data também podem apresentar oportunidades para o Data-Driven Design para o Comportamento Sustentável, como a elaboração de briefings metaprojetuais de: produto; serviço; Sistemas de Produto+Serviço (PSS); políticas públicas. Diante disso, este estudo teve como objetivo propor Diretrizes para Briefing Metaprojetual de Data-Driven Design para o Comportamento Sustentável. Como estratégia para a condução da pesquisa utilizou-se um conjunto de métodos, distribuídos ao longo de cinco fases, contemplando: 1. Revisões Bibliográficas (Assistemática e Sistemática); 2. Estudo de Caso ex-post-facto; 3. e 4. Action Design Research (Design Science Research e Pesquisa-Ação); 5. Análise Cruzada. O desenvolvimento da dissertação contou com o apoio de variados parceiros, dentre eles: uma agência de business intelligence, uma empresa de tecnologia médica, um órgão da ONU, pesquisadores de Design e pesquisadores de Ciência de Dados. Através das quatro fases iniciais, foi possível apurar, compreender e analisar os conceitos, para posteriormente propor diretrizes. Na última fase, todas as diretrizes foram avaliadas, refinadas e formalizadas em Diretrizes Finais. As diretrizes visam oferecer a designers um referencial que viabilize a elaboração de briefings metaprojetuais, que por meio do big data possibilite a compreensão do perfil dos usuários e aponte a estratégia de Design para Comportamento Sustentável mais adequada.Abstract: This dissertation presents an exploratory study, of an applied nature, through a phenomenological and qualitative approach, on the use of Data-Driven Design in a briefing of meta-projects to promote more sustainable behaviors. In recent decades, innovations in information and communication technologies have brought about several transformations in the costumers market and changed the users' behavior. These changes occur at different points in the customer journey, whether in the way users search, buy, use, evaluate or discard products and services. Consequently, the amount of digital data (big data) and the volume of online traffic has been increasing exponentially. Through big data analytics, it is possible to gain a new and/or better understanding of human behavior to influence it. However, many of these analyzes are being used as instruments to encourage consumption. In this scenario, the consumption behavior of the last 50 years contributed to negative impacts on sustainability, such as the increase in the planet's temperature. On the other hand, big data investigations can also present opportunities for Data-Driven Design for Sustainable Behaviour, such as developing meta-project briefings for a product; service; Product+Service Systems (PSS); public policies. Therefore, this study aimed to propose Data-Driven Design for Sustainable Behaviour Meta-Project Briefing Guidelines. As a strategy for conducting the research, a set of methods was used, distributed in five phases: 1.?? Literature Reviews (Unsystematic and Systematic); 2. Ex post-facto case study; 3. and 4.?? Action Design Research (Design Science Research and Action Research); 5. Cross analysis.?? The dissertation development was supported by several partners, including a business?? intelligence agency, a medical technology company, a UN agency, design researchers, and?? data science researchers. Through the four initial phases, it was possible to know,?? understand and analyze the concepts, to later propose guidelines. In the last phase, all?? guidelines were evaluated, refined, and formalized in the Final Guidelines. The guidelines?? aim to offer designers a framework that enables the preparation of briefings for metaprojects, which, through big data, make it possible to understand the profile of users and?? point out the most appropriate Design for Sustainable Behaviour strategy",data driven architecture,205
7ee214c411ca42c323af6e6cdc96058d5140aefe,filtered,semantic_scholar,"2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)",2018-01-01,semantic_scholar,service-oriented architecture for big data analytics in smart cities,https://www.semanticscholar.org/paper/7ee214c411ca42c323af6e6cdc96058d5140aefe,"A smart city has recently become an aspiration for many cities around the world. These cities are looking to apply the smart city concept to improve sustainability, quality of life for residents, and economic development. The smart city concept depends on employing a wide range of advanced technologies to improve the performance of various services and activities such as transportation, energy, healthcare, and education, while at the same time improve the city's resources utilization and initiate new business opportunities. One of the promising technologies to support such efforts is the big data technology. Effective and intelligent use of big data accumulated over time in various sectors can offer many advantages to enhance decision making in smart cities. In this paper we identify the different types of decision making processes involved in smart cities. Then we propose a service-oriented architecture to support big data analytics for decision making in smart cities. This architecture allows for integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations needed to effectively utilize available big data. It provides different functions and capabilities to use big data and provide smart capabilities as services that the architecture supports. As a result, different big data applications will be able to access and use these services for varying proposes within the smart city.",data oriented architecture,206
af225b810dfc8a90eb07c8f225dbf530fbb7c1dd,filtered,semantic_scholar,Big Data Cogn. Comput.,2020-01-01,semantic_scholar,mobda: microservice-oriented big data architecture for smart city transport systems,https://www.semanticscholar.org/paper/af225b810dfc8a90eb07c8f225dbf530fbb7c1dd,"Highly populated cities depend highly on intelligent transportation systems (ITSs) for reliable and efficient resource utilization and traffic management. Current transportation systems struggle to meet different stakeholder expectations while trying their best to optimize resources in providing various transport services. This paper proposes a Microservice-Oriented Big Data Architecture (MOBDA) incorporating data processing techniques, such as predictive modelling for achieving smart transportation and analytics microservices required towards smart cities of the future. We postulate key transportation metrics applied on various sources of transportation data to serve this objective. A novel hybrid architecture is proposed to combine stream processing and batch processing of big data for a smart computation of microservice-oriented transportation metrics that can serve the different needs of stakeholders. Development of such an architecture for smart transportation and analytics will improve the predictability of transport supply for transport providers and transport authority as well as enhance consumer satisfaction during peak periods.",data oriented architecture,207
16684e61c9ad5a61571de2e719dee4b2788ee31f,filtered,semantic_scholar,iiWAS,2014-01-01,semantic_scholar,analytics service oriented architecture for enterprise information systems,https://www.semanticscholar.org/paper/16684e61c9ad5a61571de2e719dee4b2788ee31f,"Big data analytics and business analytics are disruptive technology and innovative solution for enterprise development. However, what is the relationship between big data analytics and business analytics? What is the relationship between business analytics and enterprise information systems (EIS)? How can business analytics enhance the development of EIS? These are still big issues for EIS development. This paper addresses these three issues by proposing an ontology of business analytics, presenting an analytics service-oriented architecture (ASOA) and applying ASOA to EIS, where our surveyed data analysis showed that the proposed ASOA can enhance to develop EIS. This paper also discusses the interrelationship between data analysis and business analytics, and between data analytics and big data analytics. The proposed approaches in this paper will facilitate research and development of EIS, business analytics, big data analytics, and business intelligence.",data oriented architecture,208
f64c7a9a3be492f749dfe7ac3c2c8111ed5d0139,filtered,semantic_scholar,IEEE Network,2016-01-01,semantic_scholar,big data in mobile social networks: a qoe-oriented framework,https://www.semanticscholar.org/paper/f64c7a9a3be492f749dfe7ac3c2c8111ed5d0139,"Due to the rapid development of mobile social networks, mobile big data play an important role in providing mobile social users with various mobile services. However, as mobile big data have inherent properties, current MSNs face a challenge to provide mobile social user with a satisfactory quality of experience. Therefore, in this article, we propose a novel framework to deliver mobile big data over content- centric mobile social networks. At first, the characteristics and challenges of mobile big data are studied. Then the content-centric network architecture to deliver mobile big data in MSNs is presented, where each datum consists of interest packets and data packets, respectively. Next, how to select the agent node to forward interest packets and the relay node to transmit data packets are given by defining priorities of interest packets and data packets. Finally, simulation results show the performance of our framework with varied parameters.",data oriented architecture,209
b727a990d5a408542afe1bba8bbaca8a53b0fc5f,filtered,semantic_scholar,Softw. Pract. Exp.,2018-01-01,semantic_scholar,towards a data‐driven iot software architecture for smart city utilities,https://www.semanticscholar.org/paper/b727a990d5a408542afe1bba8bbaca8a53b0fc5f,"The Internet of things (IoT) is emerging as the next big wave of digital presence for billions of devices on the Internet. Smart cities are a practical manifestation of IoT, with the goal of efficient, reliable, and safe delivery of city utilities like water, power, and transport to residents, through their intelligent management. A data‐driven IoT software platform is essential for realizing manageable and sustainable smart utilities and for novel applications to be developed upon them. Here, we propose such service‐oriented software architecture to address 2 key operational activities in a smart utility: the IoT fabric for resource management and the data and application platform for decision‐making. Our design uses Open Web standards and evolving network protocols, cloud and edge resources, and streaming big data platforms. We motivate our design requirements using the smart water management domain; some of these requirements are unique to developing nations. We also validate the architecture within a campus‐scale IoT testbed at the Indian Institute of Science, Bangalore and present our experiences. Our architecture is scalable to a township or city while also generalizable to other smart utility domains. Our experiences serve as a template for other similar efforts, particularly in emerging markets and highlight the gaps and opportunities for a data‐driven IoT software architecture for smart cities.",data oriented architecture,210
a4146945c83ff6bd6fab6d0e43e655790a4e52ef,filtered,semantic_scholar,WEA 2013,2013-01-01,semantic_scholar,towards an integrated service-oriented reference enterprise architecture,https://www.semanticscholar.org/paper/a4146945c83ff6bd6fab6d0e43e655790a4e52ef,"New business information systems are integrating emerging cloud infrastructures with service-oriented platforms and intelligent user-centered mobile systems. Both architecture engineering and management of service-oriented enterprise architectures is complex and has to integrate synergistic disciplines like EAM - Enterprise Architecture and Management for Services & Cloud Computing, Semantic-based Decision Support through Ontologies and Knowledge-based Systems, Big Data Management, as well as Mobility and Collaboration Systems. It is necessary to identify affected decisions by runtime changes of a service-oriented runtime environment and architecture. We have to make transparent the impact of these changes over the integral landscape of affected EAM-capabilities, like directly and transitively impacted business categories, processes, applications, services, platforms and infrastructures. The paper describes a new Metamodel-based integration approach for Service-oriented Reference Enterprise Architectures.",data oriented architecture,211
051f1e01908ecf02735910828cbdf6d74b1e79b8,filtered,semantic_scholar,2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops,2013-01-01,semantic_scholar,towards service-oriented enterprise architectures for big data applications in the cloud,https://www.semanticscholar.org/paper/051f1e01908ecf02735910828cbdf6d74b1e79b8,"Applications with Service-oriented Enterprise Architectures in the Cloud are emerging and will shape future trends in technology and communication. The development of such applications integrates Enterprise Architecture and Management with Architectures for Services & Cloud Computing, Web Services, Semantics and Knowledge-based Systems, Big Data Management, among other Architecture Frameworks and Software Engineering Methods. In the present work in progress research, we explore Service-oriented Enterprise Architectures and application systems in the context of Big Data applications in cloud settings. Using a Big Data scenario, we investigate the integration of Services and Cloud Computing architectures with new capabilities of Enterprise Architectures and Management. The underlying architecture reference model can be used to support semantic analysis and program comprehension of service-oriented Big Data Applications. Enterprise Services Computing is the current trend for powerful large-scale information systems, which increasingly converge with Cloud Computing environments. In this paper we combine architectures for services with cloud computing. We propose a new integration model for service-oriented Enterprise Architectures on basis of ESARC - Enterprise Services Architecture Reference Cube, which is our previous developed service-oriented enterprise architecture classification framework, with MFESA - Method Framework for Engineering System Architectures - for the design of service-oriented enterprise architectures, and the systematic development, diagnostics and optimization of architecture artifacts of service-oriented cloud-based enterprise systems for Big Data applications.",data oriented architecture,212
bf38e0240dea95acec1915de14692edf4b9fcd65,filtered,semantic_scholar,2013 15th IEEE International Conference on Communication Technology,2013-01-01,semantic_scholar,big data-as-a-service: definition and architecture,https://www.semanticscholar.org/paper/bf38e0240dea95acec1915de14692edf4b9fcd65,"Big Data-as-a-Service (BDaaS) is a core direction in the age of big data to help companies gain intrinsic value from big data and innovative their business strategies. Based on analyzing technological challenges that BDaaS faces, firstly, a clear definition of BDaaS was given. After that a User Experience-oriented BDaaS Architecture was constructed. In addition, service processes of processing, analysis and visualization requests were described in detail. Contrast with conventional data services architectures, UE-BDaaSA supports for unstructured data, and provides a wide variety of service, such as analysis and visualization services, and it can better meet the needs of big data era.",data oriented architecture,213
83aa94353bb6b870e9f57a2567358b29fcb83507,filtered,semantic_scholar,J. Comput. Inf. Syst.,2018-01-01,semantic_scholar,big data analytics services for enhancing business intelligence,https://www.semanticscholar.org/paper/83aa94353bb6b870e9f57a2567358b29fcb83507,"ABSTRACT This article examines how to use big data analytics services to enhance business intelligence (BI). More specifically, this article proposes an ontology of big data analytics and presents a big data analytics service-oriented architecture (BASOA), and then applies BASOA to BI, where our surveyed data analysis shows that the proposed BASOA is viable for enhancing BI and enterprise information systems. This article also explores temporality, expectability, and relativity as the characteristics of intelligence in BI. These characteristics are what customers and decision makers expect from BI in terms of systems, products, and services of organizations. The proposed approach in this article might facilitate the research and development of business analytics, big data analytics, and BI as well as big data science and big data computing.",data oriented architecture,214
418250f45c5fc5a7e21305e75fe8ad50af9df91c,filtered,semantic_scholar,2018 IEEE 22nd International Enterprise Distributed Object Computing Workshop (EDOCW),2018-01-01,semantic_scholar,evolution of enterprise architecture for digital transformation,https://www.semanticscholar.org/paper/418250f45c5fc5a7e21305e75fe8ad50af9df91c,"The digital transformation of our life changes the way we work, learn, communicate, and collaborate. Enterprises are presently transforming their strategy, culture, processes, and their information systems to become digital. The digital transformation deeply disrupts existing enterprises and economies. Digitization fosters the development of IT systems with many rather small and distributed structures, like Internet of Things, Microservices and mobile services. Since years a lot of new business opportunities appear using the potential of services computing, Internet of Things, mobile systems, big data with analytics, cloud computing, collaboration networks, and decision support. Biological metaphors of living and adaptable ecosystems provide the logical foundation for self-optimizing and resilient run-time environments for intelligent business services and adaptable distributed information systems with service-oriented enterprise architectures. This has a strong impact for architecting digital services and products following both a value-oriented and a service perspective. The change from a closed-world modeling world to a more flexible open-world composition and evolution of enterprise architectures defines the moving context for adaptable and high distributed systems, which are essential to enable the digital transformation. The present research paper investigates the evolution of Enterprise Architecture considering new defined value-oriented mappings between digital strategies, digital business models and an improved digital enterprise architecture.",data oriented architecture,215
812550cee7ddf225f282d5086a7fb2759cf806fc,filtered,semantic_scholar,Emerging Trends in the Evolution of Service-Oriented and Enterprise Architectures,2016-01-01,semantic_scholar,emerging trends in the evolution of service-oriented and enterprise architectures,https://www.semanticscholar.org/paper/812550cee7ddf225f282d5086a7fb2759cf806fc,"This book presents emerging trends in the evolution of service-oriented and enterprise architectures. New architectures and methods of both business and IT are integrating services to support mobility systems, Internet of Things, Ubiquitous Computing, collaborative and adaptive business processes, Big Data, and Cloud ecosystems. They inspire current and future digital strategies and create new opportunities for the digital transformation of next digital products and services. Services Oriented Architectures (SOA) and Enterprise Architectures (EA) have emerged as a useful framework for developing interoperable, large-scale systems, typically implementing various standards, like Web Services, REST, and Microservices. Managing the adaptation and evolution of such systems presents a great challenge. Service-Oriented Architecture enables flexibility through loose coupling, both between the services themselves and between the IT organizations that manage them. Enterprises evolve continuously by transforming and extending their services, processes and information systems. Enterprise Architectures provide a holistic blueprint to help define the structure and operation of an organization with the goal of determining how an organization can most effectively achieve its objectives. The book proposes several approaches to address the challenges of the service-oriented evolution of digital enterprise and software architectures.",data oriented architecture,216
dfd468bd962a7c6edeeeb1fb3e8250a853608189,filtered,semantic_scholar,ASE BD&SI,2015-01-01,semantic_scholar,fog data: enhancing telehealth big data through fog computing,https://www.semanticscholar.org/paper/dfd468bd962a7c6edeeeb1fb3e8250a853608189,"The size of multi-modal, heterogeneous data collected through various sensors is growing exponentially. It demands intelligent data reduction, data mining and analytics at edge devices. Data compression can reduce the network bandwidth and transmission power consumed by edge devices. This paper proposes, validates and evaluates Fog Data, a service-oriented architecture for Fog computing. The center piece of the proposed architecture is a low power embedded computer that carries out data mining and data analytics on raw data collected from various wearable sensors used for telehealth applications. The embedded computer collects the sensed data as time series, analyzes it, and finds similar patterns present. Patterns are stored, and unique patterns are transmited. Also, the embedded computer extracts clinically relevant information that is sent to the cloud. A working prototype of the proposed architecture was built and used to carry out case studies on telehealth big data applications. Specifically, our case studies used the data from the sensors worn by patients with either speech motor disorders or cardiovascular problems. We implemented and evaluated both generic and application specific data mining techniques to show orders of magnitude data reduction and hence transmission power savings. Quantitative evaluations were conducted for comparing various data mining techniques and standard data compression techniques. The obtained results showed substantial improvement in system efficiency using the Fog Data architecture.",data oriented architecture,217
a4584baccf772622e5dfd57db4f19290ac5f0d73,filtered,semantic_scholar,,2017-01-01,semantic_scholar,a survey of big data architectures and machine learning algorithms in healthcare,https://www.semanticscholar.org/paper/a4584baccf772622e5dfd57db4f19290ac5f0d73,"Big Data has gained much attention from researchers in healthcare, bioinformatics, and information sciences. As a result, data production at this stage will be 44 times greater than that in 2009. Hence, the volume, velocity, and variety of data rapidly increase. Hence, it is difficult to store, process and visualise this huge data using traditional technologies. Many organisations such as Twitter, LinkedIn, and Facebook are used big data for different use cases in the social networking domain. Also, implementations of such architectures of the use cases have been published worldwide. However, a conceptual architecture for specific big data application has been limited. The intention of this paper is application-oriented architecture for big data systems, which is based on a study of published big data architectures for specific use cases. This paper also provides an overview of the state-of-the-art machine learning algorithms for processing big data in healthcare and other applications.",data oriented architecture,218
143b9249206804e083f6326f0a3ad7bb412a136c,filtered,semantic_scholar,ESOCC Workshops,2015-01-01,semantic_scholar,adaptive enterprise architecture for digital transformation,https://www.semanticscholar.org/paper/143b9249206804e083f6326f0a3ad7bb412a136c,"The Internet of Things, Enterprise Social Networks, Adaptive Case Management, Mobility systems, Analytics for Big Data, and Cloud services environments are emerging to support smart connected products and services and the digital transformation. Biological metaphors of living and adaptable ecosystems provide the logical foundation for self-optimizing and resilient run-time environments for intelligent business services and related distributed information systems with service-oriented enterprise architectures. We are investigating mechanisms for flexible adaptation and evolution for the next digital enterprise architecture systems in the context of the digital transformation. Our aim is to support flexibility and agile transformation for both business and related enterprise systems through adaptation and dynamical evolution of digital enterprise architectures. The present research paper investigates digital transformations of business and IT and integrates fundamental mappings between adaptable digital enterprise architectures and service-oriented information systems. We are putting a spotlight with the example domain – Internet of Things.",data oriented architecture,219
6c401ae38727e2b6ccc168a7d519a5ca871c7540,filtered,semantic_scholar,Int. J. Syst. Serv. Oriented Eng.,2015-01-01,semantic_scholar,a scalable big stream cloud architecture for the internet of things,https://www.semanticscholar.org/paper/6c401ae38727e2b6ccc168a7d519a5ca871c7540,"The Internet of Things IoT will consist of billions 50 billions by 2020 of interconnected heterogeneous devices denoted as ""Smart Objects:"" tiny, constrained devices which are going to be pervasively deployed in several contexts. To meet low-latency requirements, IoT applications must rely on specific architectures designed to handle the gigantic stream of data coming from Smart Objects. This paper propose a novel Cloud architecture for Big Stream applications that can efficiently handle data coming from Smart Objects through a Graph-based processing platform and deliver processed data to consumer applications with low latency. The authors reverse the traditional ""Big Data"" paradigm, where real-time constraints are not considered, and introduce the new ""Big Stream"" paradigm, which better fits IoT scenarios. The paper provides a performance evaluation of a practical open-source implementation of the proposed architecture. Other practical aspects, such as security considerations, and possible business oriented exploitation plans are presented.",data oriented architecture,220
4a67be4b1b0546c60f90fa5fc9c058cb7f3e1fe0,filtered,semantic_scholar,I3E,2015-01-01,semantic_scholar,big data analytics as a service for business intelligence,https://www.semanticscholar.org/paper/4a67be4b1b0546c60f90fa5fc9c058cb7f3e1fe0,"This paper proposes an ontology of big data analytics and examines how to enhance business intelligence through big data analytics as a service by presenting a big data analytics services-oriented architecture (BASOA), and applying BASOA to business intelligence, where our surveyed data analysis showed that the proposed BASOA is viable for developing business intelligence and enterprise information systems. This paper also discusses the interrelationship between business intelligence and big data analytics. The proposed approach in this paper might facilitate the research and development of business analytics, big data analytics, and business intelligence as well as intelligent agents.",data oriented architecture,221
5d93748040f20eb0cf76c417ef96ef39699af610,filtered,semantic_scholar,,2012-01-01,semantic_scholar,editorial: big services era: global trends of cloud computing and big data,https://www.semanticscholar.org/paper/5d93748040f20eb0cf76c417ef96ef39699af610,"N the hot topics on novel information technology include cloud computing, social networking, mobile Internet, and big data. The major goal of cloud computing is to share resources, which consist of infrastructure, platform, software, and business process. When those resources are provisioned as services, the value of cloud computing is realized. From a cloud offering perspective, Infrastructure As A Service (IaaS), Platform As A Service (PaaS), Software As A Service (SaaS), and Business Process As A Service (BPaaS) are typical service delivery types in cloud computing. “Servicelization” is the way of defi ning interfaces for resource sharing. Servicelization is also the way of offering social networking services, big data analytics, and mobile Internet services. In short, “everything as a service” is creating a Big Services era due to the foundational architecture (i.e., Service-Oriented Architecture) of services computing. Those new technologies are creating differentiating business models, application innovations, and computing patterns. In order to illustrate the global trends of cloud computing and associated technologies, I would like to use enterprise architecture as a base to articulate the innovations created and consumed by enterprises. The most popular enterprise architecture standard is The Open Group Architectural Framework (TOGAF), which covers business architecture, application architecture, data architecture, and technology architecture. From a business architecture perspective, cloud computing is creating brand new business models. For example, Instagram leverages cloud computing as a platform to offer photo sharing services integrated with popular social networking sites. After 19 months in operation, it only had 12 employees when it was acquired by Facebook at $1.1 billion. EdX online education service is also built on Amazon’s cloud computing platform to offer courses for students worldwide. A course has been offered to more than 120,000 students in a virtual classroom over the Internet. As for innovations in application architectures, cloud computing speeds up the servicelization of application software. Software has been componentized for reuse and recomposition for creating value-added services. Building APIs-based platforms has become a mainstream approach to focus on extensibility and scalability. Domain-specifi c applications such as human resource management and customer relationship management have dominated the SaaS market. Social networking aspects have been integrated as core enablers of enterprise applications to facilitate effective communications. Large application software vendors are transforming their packaged applications to cloud-based, social-network-enabled, analytics-intensive, and mobile-reachable SaaS offerings. In terms of innovations in data architecture, cloud computing is driven by killer applications. The more applications there are, the more data there is. Moreover, big data needs more computing power and storage provided by cloud computing platforms. Data architecture needs to be redesigned to elaborate on massive domain and industry-specifi c data. Hadoop type of infrastructure has been offered as a service for researchers, data analysts, and developers to process big data in a cost-effective manner. In addition, cloud database is another direction to leverage data and fi les as a base and offer identity management and fi ne-grained APIs. New applications can be built on those APIs and run on mobile devices, web browsers, and other programming tools and environments. The next innovations are around technology architecture. There are three major trends. The fi rst innovation trend is to integrate hardware, software, and service into one box. This type of innovation can hide the complexity of the enterprises’ IT systems and make them cloud ready. Most importantly, the services aspect of the box can capture best practices of operations in various scenarios. Meanwhile, the box provides a development toolkit to enable developers to import knowledge and experiences into the integrated black box. The second innovation trend is to provide open cloud platforms by leading Internet service providers. Application engines, big data analyzing algorithms, cloud storage APIs, and prediction and translation APIs are gradually becoming important tools and assets for open innovations. The third technology architecture innovation comes from mobile Internet and social networking services. Technology architecture is used to realize application architecture and data architecture, which further supports business architecture. The last innovation is around architecture governance for cloud computing. It includes the standardization of individual architectural building blocks within business architecture, application architecture, data architecture, and technology architecture. For each of the four architectures, we need to create unifi ed interfaces and protocols to exchange information. The semantics of the exchanged information and data structure also needs to be standardized to build an interoperable ecosystem for cloud computing. For example, the Distributed Management Task Force (DMTF)",data oriented architecture,222
687735e9ee544c12b100845e8e605fd7b1366315,filtered,semantic_scholar,2013 IEEE International Conference on Big Data,2013-01-01,semantic_scholar,big data analytics on high velocity streams: a case study,https://www.semanticscholar.org/paper/687735e9ee544c12b100845e8e605fd7b1366315,"Big data management is often characterized by three Vs: Volume, Velocity and Variety. While traditional batch-oriented systems such as MapReduce are able to scale-out and process very large volumes of data in parallel, they also introduce some significant latency. In this paper, we focus on the second V (Velocity) of the Big Data triad; We present a case-study where we use a popular open-source stream processing engine (Storm) to perform real-time integration and trend detection on Twitter and Bitly streams. We describe our trend detection solution below and experimentally demonstrate that our architecture can effectively process data in real-time - even for high-velocity streams.",data oriented architecture,223
6cbec639e12c882f75f6b6c1d82d7576a3cd3aca,filtered,semantic_scholar,J. Comput. Inf. Syst.,2017-01-01,semantic_scholar,business analytics-based enterprise information systems,https://www.semanticscholar.org/paper/6cbec639e12c882f75f6b6c1d82d7576a3cd3aca,"ABSTRACT Big data analytics and business analytics are a disruptive technology and innovative solution for enterprise development. However, what is the relationship between business analytics, big data analytics, and enterprise information systems (EIS)? How can business analytics enhance the development of EIS? How can analytics be incorporated into EIS? These are still big issues. This article addresses these three issues by proposing ontology of business analytics, presenting an analytics service-oriented architecture (ASOA) and applying ASOA to EIS, where our surveyed data analysis showed that the proposed ASOA is viable for developing EIS. This article then examines incorporation of business analytics into EIS through proposing a model for business analytics service-based EIS, or ASEIS for short. The proposed approach in this article might facilitate the research and development of EIS, business analytics, big data analytics, and business intelligence.",data oriented architecture,224
8d8882ab46e6bf34280d9d66119e05e10f253dc9,filtered,semantic_scholar,IEEE Software,2016-01-01,semantic_scholar,a deep-intelligence framework for online video processing,https://www.semanticscholar.org/paper/8d8882ab46e6bf34280d9d66119e05e10f253dc9,"Video data has become the largest source of big data. Owing to video data's complexities, velocity, and volume, public security and other surveillance applications require efficient, intelligent runtime video processing. To address these challenges, a proposed framework combines two cloud-computing technologies: Storm stream processing and Hadoop batch processing. It uses deep learning to realize deep intelligence that can help reveal knowledge hidden in video data. An implementation of this framework combines five architecture styles: service-oriented architecture, publish-subscribe, the Shared Data pattern, MapReduce, and a layered architecture. Evaluations of performance, scalability, and fault tolerance showed the framework's effectiveness. This article is part of a special issue on Software Engineering for Big Data Systems.",data oriented architecture,225
c5d4b26fdffc52042c9df0e88ba6d480c778c152,filtered,semantic_scholar,DEC,2015-01-01,semantic_scholar,evolving enterprise architectures for digital transformations,https://www.semanticscholar.org/paper/c5d4b26fdffc52042c9df0e88ba6d480c778c152,"The digital transformation of our society changes the way we live, work, learn, communicate, and collaborate. This disruptive change interacts with all information processes and systems that are important business enablers for the digital transformation since years. The Internet of Things, Social Collaboration Systems for Adaptive Case Management, Mobility Systems and Services for Big Data in Cloud Services environments are emerging to support intelligent usercentered and social community systems. They will shape future trends of business innovation and the next wave of information and communication technology. Biological metaphors of living and adaptable ecosystems provide the logical foundation for self-optimizing and resilient run-time environments for intelligent business services and related distributed information systems with service-oriented enterprise architectures. The present research investigates mechanisms for flexible adaptation and evolution of Digital Enterprise Architectures in the context of integrated synergistic disciplines like distributed service-oriented Architectures and Information Systems, EAM Enterprise Architecture and Management, Metamodeling, Semantic Technologies, Web Services, Cloud Computing and Big Data technology. Our aim is to support flexibility and agile transformations for both business domains and related enterprise systems through adaptation and evolution of digital enterprise architectures. The present research paper investigates digital transformations of business and IT and integrates fundamental mappings between adaptable digital enterprise architectures and service-oriented information systems.",data oriented architecture,226
796d48dd013668369d29840675405cdcc044a477,filtered,semantic_scholar,2014 IEEE 18th International Enterprise Distributed Object Computing Conference Workshops and Demonstrations,2014-01-01,semantic_scholar,adaptable enterprise architectures for software evolution of smartlife ecosystems,https://www.semanticscholar.org/paper/796d48dd013668369d29840675405cdcc044a477,"SmartLife ecosystems are emerging as intelligent user-centered systems that will shape future trends in technology and communication. Biological metaphors of living adaptable ecosystems provide the logical foundation for self-optimizing and self-healing run-time environments for intelligent adaptable business services and related information systems with service-oriented enterprise architectures. The present research in progress work investigates mechanisms for adaptable enterprise architectures for the development of service-oriented ecosystems with integrated technologies like Semantic Technologies, Web Services, Cloud Computing and Big Data Management. With a large and diverse set of ecosystem services with different owners, our scenario of service-based SmartLife ecosystems can pose challenges in their development, and more importantly, for maintenance and software evolution. Our research explores the use of knowledge modeling using ontologies and flexible metamodels for adaptable enterprise architectures to support program comprehension for software engineers during maintenance and evolution tasks of service-based applications. Our previous reference enterprise architecture model ESARC -- Enterprise Services Architecture Reference Cube -- and the Open Group SOA Ontology was extended to support agile semantic analysis, program comprehension and software evolution for a SmartLife applications scenario. The Semantic Browser is a semantic search tool that was developed to provide knowledge-enhanced investigation capabilities for service-oriented applications and their architectures.",data oriented architecture,227
3c95cebb6eeef8b3b57f8b8c6b92dfb98c23bf6f,filtered,semantic_scholar,2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC),2018-01-01,semantic_scholar,service-oriented big data analytics for improving buildings energy management in smart cities,https://www.semanticscholar.org/paper/3c95cebb6eeef8b3b57f8b8c6b92dfb98c23bf6f,"This paper proposes a service-oriented architecture to support big data analytics for buildings energy management in smart cities. This architecture allows for seamlessly integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations. These operations are needed to effectively utilize available big data for optimizing energy consumption for residential, industrial, and commercial buildings in smart cities. The paper also recognizes the different kinds of decision making processes required by a smart city to effectively manage energy efficiency for its buildings. These decision-making processes can be implemented and deployed as services in the proposed architecture.",data oriented architecture,228
b593c420984bf49c3b8e17f081b42679cedd67db,filtered,semantic_scholar,Mobile Big Data,2018-01-01,semantic_scholar,levering mobile cloud computing for mobile big data analytics,https://www.semanticscholar.org/paper/b593c420984bf49c3b8e17f081b42679cedd67db,"Mobile devices are becoming an indispensable tool for daily life and a considerable number of services are delivered via mobile devices. However, the capacity of mobile devices is constrained for complex interactive and computationally intensive applications (such as Siri on iOS), and therefore, cloud computing is needed to improve user experience. This results in mobile cloud computing. In this chapter, we first review the architectures of popular cloud computing platforms used in enterprise level application scenarios, then we present the requirements and challenges of cloud computing enabled service oriented intelligent mobile applications. After analyzing those challenges on both client side and cloud architecture, we propose the cloud computing architecture for mobile big data analytics and present several application cases.",data oriented architecture,229
9fcedc58a28937e2fabafde45c711b0801cadc3f,filtered,semantic_scholar,Journal of Management Inquiry,2018-01-01,semantic_scholar,gamification in management: between choice architecture and humanistic design,https://www.semanticscholar.org/paper/9fcedc58a28937e2fabafde45c711b0801cadc3f,"Gamification in management is currently informed by two contradicting framings or rhetorics: the rhetoric of choice architecture casts humans as rational actors and games as perfect information and incentive dispensers, giving managers fine-grained control over people’s behavior. It aligns with basic tenets of neoclassical economics, scientific management, operations research/management science, and current big data-driven decision making. In contrast, the rhetoric of humanistic design casts humans as growth-oriented and games as environments optimally designed to afford positive, meaningful experiences. This view, fitting humanistic management ideas and the rise of design and customer experience, casts managers as “second order” designers. While both rhetorics highlight important aspects of games and management, the former is more likely to be adopted and absorbed into business as usual, whereas the latter holds more uncertainty, but also transformative potential.",data oriented architecture,230
b0647805b29395239aaada60a3911812433610ef,filtered,semantic_scholar,Grid 2012,2012-01-01,semantic_scholar,distributed and big data storage management in grid computing,https://www.semanticscholar.org/paper/b0647805b29395239aaada60a3911812433610ef,"Big data storage management is one of the most challenging issues for Grid computing environments, since large amount of data intensive applications frequently involve a high degree of data access locality. Grid applications typically deal with large amounts of data. In traditional approaches high-performance computing consists dedicated servers that are used to data storage and data replication. In this paper we present a new mechanism for distributed and big data storage and resource discovery services. Here we proposed an architecture named Dynamic and Scalable Storage Management (DSSM) architecture in grid environments. This allows in grid computing not only sharing the computational cycles, but also share the storage space. The storage can be transparently accessed from any grid machine, allowing easy data sharing among grid users and applications. The concept of virtual ids that, allows the creation of virtual spaces has been introduced and used. The DSSM divides all Grid Oriented Storage devices (nodes) into multiple geographically distributed domains and to facilitate the locality and simplify the intra-domain storage management. Grid service based storage resources are adopted to stack simple modular service piece by piece as demand grows. To this end, we propose four axes that define: DSSM architecture and algorithms description, Storage resources and resource discovery into Grid service, Evaluate purpose prototype system, dynamically, scalability, and bandwidth, and Discuss results. Algorithms at bottom and upper level for standardization dynamic and scalable storage management, along with higher bandwidths have been designed.",data oriented architecture,231
b54cffcb00f5da83126e5003fd4e451dd12cbd50,filtered,semantic_scholar,2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),2017-01-01,semantic_scholar,udp: a programmable accelerator for extract-transform-load workloads and more,https://www.semanticscholar.org/paper/b54cffcb00f5da83126e5003fd4e451dd12cbd50,"Big data analytic applications give rise to large-scale extract-transformload (ETL) as a fundamental step to transform new data into a native representation. ETL workloads pose significant performance challenges on conventional architectures, so we propose the design of the unstructured data processor (UDP), a software programmable accelerator that includes multi-way dispatch, variable-size symbol support, flexible-source dispatch (stream buffer and scalar registers), and memory addressing to accelerate ETL kernels both for current and novel future encoding and compression. Specifically, UDP excels at branch-intensive and symbol and pattern-oriented workloads, and can offload them from CPUs. To evaluate UDP, we use a broad set of data processing workloads inspired by ETL, but broad enough to also apply to query execution, stream processing, and intrusion detection/monitoring. A single UDP accelerates these data processing tasks 20-fold (geometric mean, largest increase from 0.4 GB/s to 40 GB/s) and performance per watt by a geomean of 1,900-fold. UDP ASIC implementation in 28nm CMOS shows UDP logic area of 3.82mm2 (8.69mm2 with 1MB local memory), and logic power of 0.149W (0.864W with 1MB local memory); both much smaller than a single core. CCS CONCEPTS • Information systems → Extraction, transformation and loading; • Computer systems organization → Parallel architectures; • Hardware → Application specific processors; • Theory of computation → Pattern matching;",data oriented architecture,232
90700d4b034f0714d32e000c002a24b8fec38252,filtered,semantic_scholar,IEEE Transactions on Industrial Informatics,2017-01-01,semantic_scholar,interoperability for industrial cyber-physical systems: an approach for legacy systems,https://www.semanticscholar.org/paper/90700d4b034f0714d32e000c002a24b8fec38252,"Contemporary industrial systems are challenged by fast-growing requirements for agile and effective reactivity to rapidly changing market demands. To achieve this set of requirements, new technologies and paradigms like Internet-of-Things (IoT), Big Data Analytics, Internet-of-Services (IoS), and service-oriented architecture (SOA) are being introduced into the industrial environments. These advances result in the confluence of two dissimilar, but complementary domains: the physical operational technologies (OT) and the cyber information technologies (IT) domains. Convergence of these two domains in a cross-layer fashion implies a new set of two major requirements of components and systems: 1) structural connectivity and 2) functional interoperability. However, the wide variety and heterogeneity of industrial systems—especially in the factory floor—entails integration complexity, which is in contrast with the mentioned requirements. In this paper, we focus on how legacy industrial systems can migrate in a cost-effective manner to the new paradigm of integrated IT–OT levels. We propose an interoperability layer requiring no changes on the legacy device that maps field device data into an ISA95-based information model. The performance of our contributed open-source implementation is evaluated in several deployment configurations.",data oriented architecture,233
213b5f30cd84c80c1f53e46553fa221fdcc226dd,filtered,semantic_scholar,2017 IEEE International Conference on Big Data (Big Data),2017-01-01,semantic_scholar,towards a unified storage and ingestion architecture for stream processing,https://www.semanticscholar.org/paper/213b5f30cd84c80c1f53e46553fa221fdcc226dd,"Big Data applications are rapidly moving from a batch-oriented execution model to a streaming execution model in order to extract value from the data in real-time. However, processing live data alone is often not enough: in many cases, such applications need to combine the live data with previously archived data to increase the quality of the extracted insights. Current streaming-oriented runtimes and middlewares are not flexible enough to deal with this trend, as they address ingestion (collection and pre-processing of data streams) and persistent storage (archival of intermediate results) using separate services. This separation often leads to I/O redundancy (e.g., write data twice to disk or transfer data twice over the network) and interference (e.g., I/O bottlenecks when collecting data streams and writing archival data simultaneously). In this position paper, we argue for a unified ingestion and storage architecture for streaming data that addresses the aforementioned challenge. We identify a set of constraints and benefits for such a unified model, while highlighting the important architectural aspects required to implement it in real life. Based on these aspects, we briefly sketch our plan for future work that develops the position defended in this paper.",data oriented architecture,234
d87e1322c34fd7e9e6a53fe9a7b19c4e084e3133,filtered,semantic_scholar,"2019 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)",2019-01-01,semantic_scholar,service-oriented distributed energy data management using big data technologies,https://www.semanticscholar.org/paper/d87e1322c34fd7e9e6a53fe9a7b19c4e084e3133,"Nowadays, the smart grid becomes a new electrical grid system instead of the traditional grid. It can provide the efficiency and reliability of energy resources. A smart meter possesses the sen-sors which collect information about energy consumption and production at a defined time. A vast amount of data needs to be aggregated, stored and transformed in near realtime for intelligent response and decision support in the smart grid. There are many technologies, which can provide the storing, aggregation and processing of the data. Each technology is more suitable for specific tasks. The devices generate a massive amount of data. Therefore, all this data belong to the Big Data area. Grid management includes the prediction of load and consumer usage behaviours. In order to effectively analyze and storage, this data should use the Big Data technologies. It can provide fast methods of transmitting. In this article the authors considered the architecture of the smart grid and evaluated this system in the real region.",data oriented architecture,235
fd06f0726db674e1afee85e69b001dff5e370874,filtered,semantic_scholar,2015 IEEE International Congress on Big Data,2015-01-01,semantic_scholar,h-drive: a big health data analytics platform for evidence-informed decision making,https://www.semanticscholar.org/paper/fd06f0726db674e1afee85e69b001dff5e370874,"Healthcare operations generates large volumes of data. Big data analytics methods are needed to derive actionable and decision-quality 'intelligence' from 'big' healthcare data in order to improve patient care. Given the technical challenges to big health data analytics, in this paper we present a specialized health analytics platform -- H-DRIVE (Health Data Reconciliation Inferencing and Visualization Environment). H-DRIVE is an integrated, end-to-end health data analytics service-oriented workbench designed to empower data analysts and researchers to design analytical experiments and then perform complex analytics on their health data. We present the high-level functional and technical architecture of H-DRIVE. As a case study, we demonstrate the application of H-DRIVE in the context of optimizing the operations of a provincial pathology lab, where we analyze province-wide lab orders to prepare scorecards outlining physician lab testing performance and offer an operational dashboard to provide an overview of lab utilization.",data oriented architecture,236
fa1a329f59595d88d3cd7c5f3a7a73f615fb7d03,filtered,semantic_scholar,Softw. Pract. Exp.,2015-01-01,semantic_scholar,breeze graph grammar: a graph grammar approach for modeling the software architecture of big data‐oriented software systems,https://www.semanticscholar.org/paper/fa1a329f59595d88d3cd7c5f3a7a73f615fb7d03,"Various technologies have been proposed to support the processing of big data. However, such technologies require software architectures not only to adapt to the changes and achieve dynamic evolution but also to be reliable. Most of the architecture description techniques are not able to directly capture the dynamic changes in the definition of the software architecture and cannot analyze or evaluate the system reliability. In this paper, we provide a breeze graph grammar (BGG) to model the software architecture in both static and dynamic aspects and give a BGG reliability model to help supporting software system reliability modeling and evaluation. Our work expands this idea in three directions. We first present the definition of BGG to specify the software architecture and map the system dynamic evolution to BGG transformation rules. Second, a BGG reliability model is proposed in which we add error attributes to the BGG graph for capturing the system error information, and the system error state transition is performed through BGG graph rewriting rules. Then, we study the rules to map the BGG reliability model to a generalized stochastic Petri net (GSPN) model, which can be used for reliability evaluation. Throughout this paper, we use a big data‐based centralized system to demonstrate our approach. The BGG graph rewriting characteristic supports the dynamic change requirements, and the architecture is statically checked through the BGG productions. Moreover, system reliability modeling and evaluation can be achieved through the BGG reliability model by combining GSPN. Copyright © 2014 John Wiley & Sons, Ltd.",data oriented architecture,237
f14a05ad1ce441a580b839efd82bcb468505906f,filtered,semantic_scholar,,2013-01-01,semantic_scholar,tassonomy and review of big data solutions navigation,https://www.semanticscholar.org/paper/f14a05ad1ce441a580b839efd82bcb468505906f,"In recent years more and more often, we hear about Big Data and issues related to the management of these huge volume of data, and considering that there is no definitive solution for their storage, querying, analysis. This discipline is in great evolution, multidisciplinary and very complex to be dominated for the several aspects to be addressed: architectural, data structure, data management, data analytics, protection and security, computational as parallel and distributed processing, etc. To cope with these problems a basic survey of main tips, which would allow the developer to orient themselves in the choice of the best solution, for the development of an architecture for the management of Big Data, in each specific case could be of great support and help. In fact a large number of fields, from industry to scientific research, are inquiring information and hints about what can be obtained through the analysis of Big Data and how these infrastructures can be created, by using what, etc. And, therefore, more powerful solutions are needed to cope with increasing complexity and variety of problems, for their better management and exploitation of the open accessible, produced and integrated data. In this paper, starting from the analysis of the existing solutions, particularly interesting and well documented use cases, we identified a group of main differentiating features which can mainly influence the choice of the solution to be set up; then we looked at different types of existing solutions and products to see how they are handled the identified features. Lastly, the results obtained with the analysis of the desirable features for each main domain and then the identification of the most suitable and/or adopted products for the application domains. The work cannot be exhaustive, and in many cases we had to decide to include and to exclude aspects and tools. The obtained results can be regarded as a model and main guidelines for big data solution navigation.",data oriented architecture,238
1fc5dc2fe308c9eadd15f1a1d18ed298d4d343ff,filtered,semantic_scholar,Proc. VLDB Endow.,2014-01-01,semantic_scholar,large-scale graph analytics in aster 6: bringing context to big data discovery,https://www.semanticscholar.org/paper/1fc5dc2fe308c9eadd15f1a1d18ed298d4d343ff,"Graph analytics is an important big data discovery technique. Applications include identifying influential employees for retention, detecting fraud in a complex interaction network, and determining product affinities by exploiting community buying patterns. Specialized platforms have emerged to satisfy the unique processing requirements of large-scale graph analytics; however, these platforms do not enable graph analytics to be combined with other analytics techniques, nor do they work well with the vast ecosystem of SQL-based business applications. 
 
Teradata Aster 6.0 adds support for large-scale graph analytics to its repertoire of analytics capabilities. The solution extends the multi-engine processing architecture with support for bulk synchronous parallel execution, and a specialized graph engine that enables iterative analysis of graph structures. Graph analytics functions written to the vertex-oriented API exposed by the graph engine can be invoked from the context of an SQL query and composed with existing SQL-MR functions, thereby enabling data scientists and business applications to express computations that combine large-scale graph analytics with techniques better suited to a different style of processing. The solution includes a suite of pre-built graph analytic functions adapted for parallel execution.",data oriented architecture,239
b69f53ce7255b69128b8094fe9877a3be3bbb4f1,filtered,semantic_scholar,International Journal of Data Mining & Knowledge Management Process,2019-01-01,semantic_scholar,a business intelligence platform implemented in a big data system embedding data mining: a case of study,https://www.semanticscholar.org/paper/b69f53ce7255b69128b8094fe9877a3be3bbb4f1,"In this work is discussed a case study of a business intelligence –BI- platform developed within the framework of an industry project by following research and development –R&D- guidelines of ‘Frascati’. The proposed results are a part of the output of different jointed projects enabling the BI of the industry ACI Global working mainly in roadside assistance services. The main project goal is to upgrade the information system, the knowledge base –KB- and industry processes activating data mining algorithms and big data systems able to provide gain of knowledge. The proposed work concerns the development of the highly performing Cassandra big data system collecting data of two industry location. Data are processed by data mining algorithms in order to formulate a decision making system oriented on call center human resources optimization and on customer service improvement. Correlation Matrix, Decision Tree and Random Forest Decision Tree algorithms have been applied for the testing of the prototype system by finding a good accuracy of the output solutions. The Rapid Miner tool has been adopted for the data processing. The work describes all the system architectures adopted for the design and for the testing phases, providing information about Cassandra performance and showing some results of data mining processes matching with industry BI strategies.",data oriented architecture,240
4ea53f634ae78d1fc5533551b67236e0b6dab74f,filtered,semantic_scholar,"Proceedings of 2013 IEEE International Conference on Service Operations and Logistics, and Informatics",2013-01-01,semantic_scholar,a system for green personal integrated mobility: a research in progress,https://www.semanticscholar.org/paper/4ea53f634ae78d1fc5533551b67236e0b6dab74f,"We present an ongoing research on an Integrated Real-time Mobility Assistant (IRMA). IRMA is a software system that targets the personal mobility in a near future scenario, based on green, shared and public transports. IRMA handles end-to-end itineraries that may involve multiple transport systems, and encompasses both commuter mobility and visitor mobility. The objective of IRMA is to make practically feasible a mobility that balances efficiency of time, energy/pollution and cost. Therefore, IRMA supports users in plotting the itinerary and also when en-route. IRMA architecture includes a smartphone application and a set of web services to gather and interpret any relevant source of information, that includes open data, crowd data and big data. The technology is SOA/EDA (Service Oriented Architecture / Event Driven Architecture) and uses GTFS format to access open data. IRMA, after being proved on test cases, shall be tested by the students of University of Pavia. IRMA concept is a step ahead current personal mobility systems that simply suggest and track itineraries.",data oriented architecture,241
a761198f4df06973a68cfd70e96877abe9c4f5e9,filtered,semantic_scholar,International Symposium on Low Power Electronics and Design (ISLPED),2013-01-01,semantic_scholar,an ultralow-power memory-based big-data computing platform by nonvolatile domain-wall nanowire devices,https://www.semanticscholar.org/paper/a761198f4df06973a68cfd70e96877abe9c4f5e9,"As one recently introduced non-volatile memory (NVM) device, domain-wall nanowire (or race-track) has shown potential for main memory storage but also computing capability. In this paper, the domain-wall nanowire is studied for a memory-based computing platform towards ultra-low-power big-data processing. One domain-wall nanowire based logic-in-memory architecture is proposed for big-data processing, where the domain-wall nanowire memory is deployed as main memory for data storage as well as XOR-logic for comparison and addition operations. The domain-wall nanowire based logic-in-memory circuits are evaluated by SPICE-level verifications. Further evaluated by applications of general-purpose SPEC2006 benchmark and also web-searching oriented Phoenix benchmark, the proposed computing platform can exhibit a significant power saving on both main memory and ALU under the similar performance when compared to CMOS based designs.",data oriented architecture,242
c8c71ee0b7f12592f6928eaa4c5dc48c5e3361ad,filtered,semantic_scholar,IEEE Access,2018-01-01,semantic_scholar,an ontology-oriented architecture for dealing with heterogeneous data applied to telemedicine systems,https://www.semanticscholar.org/paper/c8c71ee0b7f12592f6928eaa4c5dc48c5e3361ad,"Current trends in medicine regarding issues of accessibility to and the quantity and quality of information and quality of service are very different compared to former decades. The current state requires new methods for addressing the challenge of dealing with enormous amounts of data present and growing on the Web and other heterogeneous data sources such as sensors and social networks and unstructured data, normally referred to as big data. Traditional approaches are not enough, at least on their own, although they were frequently used in hybrid architectures in the past. In this paper, we propose an architecture to process big data, including heterogeneous sources of information. We have defined an ontology-oriented architecture, where a core ontology has been used as a knowledge base and allows data integration of different heterogeneous sources. We have used natural language processing and artificial intelligence methods to process and mine data in the health sector to uncover the knowledge hidden in diverse data sources. Our approach has been applied to the field of personalized medicine (study, diagnosis, and treatment of diseases customized for each patient) and it has been used in a telemedicine system. A case study focused on diabetes is presented to prove the validity of the proposed model.",data oriented architecture,243
4d1b8d46560d08b59d41b24ebedd8aa018d6b0a0,filtered,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,a survey of distributed data stream processing frameworks,https://www.semanticscholar.org/paper/4d1b8d46560d08b59d41b24ebedd8aa018d6b0a0,"Big data processing systems are evolving to be more stream oriented where each data record is processed as it arrives by distributed and low-latency computational frameworks on a continuous basis. As the stream processing technology matures and more organizations invest in digital transformations, new applications of stream analytics will be identified and implemented across a wide spectrum of industries. One of the challenges in developing a streaming analytics infrastructure is the difficulty in selecting the right stream processing framework for the different use cases. With a view to addressing this issue, in this paper we present a taxonomy, a comparative study of distributed data stream processing and analytics frameworks, and a critical review of representative open source (Storm, Spark Streaming, Flink, Kafka Streams) and commercial (IBM Streams) distributed data stream processing frameworks. The study also reports our ongoing study on a multilevel streaming analytics architecture that can serve as a guide for organizations and individuals planning to implement a real-time data stream processing and analytics framework.",data oriented architecture,244
064f532b6b67817988a60bcb7a28de1803665e5f,filtered,semantic_scholar,iiWAS,2015-01-01,semantic_scholar,sqltokeynosql: a layer for relational to key-based nosql database mapping,https://www.semanticscholar.org/paper/064f532b6b67817988a60bcb7a28de1803665e5f,"Today, many applications produce and manipulate a large volume of data, the so-called Big Data. Traditional databases (DB), like relational databases, are not suitable to Big Data management. In order to solve this problem, a new category of DB has been proposed, the so-called NoSQL DB. NoSQL DB have different data models, as well as different access methods which are not usually compatible with the SQL language. In this context, approaches have been proposed for providing mapping of relational DB schemata and operations to equivalent ones in NoSQL DB to deal with large relational data sets in the cloud, focusing on scalability and availability. However, these approaches map relational DB only to a single NoSQL data model and, sometimes, to a specific NoSQL DB product. This paper presents SQLtoKeyNoSQL, a layer able to translate relational schemata as well as SQL commands to equivalent schemata and access methods to any key-oriented NoSQL DB (document-oriented, key-value and column-oriented). We present the architecture of our layer focusing on our mapping strategies, as well as some preliminary experiments that evaluate the impact of SQLtoKeyNoSQL as a solution for transparent mapping of relational DB to key-based NoSQL DB.",data oriented architecture,245
0030dd50c55ded2ee5b388dee26697890c25be36,filtered,semantic_scholar,,2016-01-01,semantic_scholar,fpgas for software programmers,https://www.semanticscholar.org/paper/0030dd50c55ded2ee5b388dee26697890c25be36,"This book makes powerful Field Programmable Gate Array (FPGA) and reconfigurable technology accessible to software engineers by covering different state-of-the-art high-level synthesis approaches (e.g., OpenCL and several C-to-gates compilers). It introduces FPGA technology, its programming model, and how various applications can be implemented on FPGAs without going through low-level hardware design phases. Readers will get a realistic sense for problems that are suited for FPGAs and how to implement them from a software designers point of view. The authors demonstrate that FPGAs and their programming model reflect the needs of stream processing problems much better than traditional CPU or GPU architectures, making them well-suited for a wide variety of systems, from embedded systems performing sensor processing to large setups for Big Data number crunching. This book serves as an invaluable tool for software designers and FPGA design engineers who are interested in high design productivity through behavioural synthesis, domain-specific compilation, and FPGA overlays. Introduces FPGA technology to software developers by giving an overview of FPGA programming models and design tools, as well as various application examples;Provides a holistic analysis of the topic and enables developers to tackle the architectural needs for Big Data processing with FPGAs; Explains the reasons for the energy efficiency and performance benefits of FPGA processing;Provides a user-oriented approach and a sense for where and how to apply FPGA technology.",data oriented architecture,246
bb5d26da72bfe7030dbc6650b686b210ae661f2c,filtered,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,a new data processing architecture for multi-scenario applications in aviation manufacturing,https://www.semanticscholar.org/paper/bb5d26da72bfe7030dbc6650b686b210ae661f2c,"The development of industry 4.0 has spurred the transformation of traditional manufacturing into modern industrial Internet-of-Things. The most notable feature during this transition is the improvement of digitization and intelligence based on the massive data drives. In such a data-driven environment, the processing, storage, and utilization of the industry data get more and more important. Usually, the traditional data processing architecture runs as a one-way streamline, which cannot adapt to the different requirements of the multi-scenario application. This paper proposed a new industrial big data processing architecture called Phi architecture, which can realize many functions such as batch data processing and stream data processing, distributed storage and access, and real-time control. Compared with other data processing architecture, the Phi architecture combined with edge computing and feedback control has the ability to deal with the different demands in aviation manufacturing. Next, the new architecture is designed for microservices pattern, which improves the flexibility and stability of the architecture, and makes it independent operated in multi-scenarios, such as state monitoring of workshop, adaptive data acquisition, feedback control, and user-oriented information classification. As a proof of concept, the architecture has been tested in a simulation digital manufacturing workshop. The results verify the improved effectiveness of the Phi architecture on the data feedback control and real-time processing. And, the development of microservices architecture greatly improves the efficiency, adaptability, and extensibility of the manufacturing process.",data oriented architecture,247
d2b24d3e7f57b45ea502adc2fe0d03803de9bf5d,filtered,semantic_scholar,Int. J. Interact. Multim. Artif. Intell.,2019-01-01,semantic_scholar,data and artificial intelligence strategy: a conceptual enterprise big data cloud architecture to enable market-oriented organisations,https://www.semanticscholar.org/paper/d2b24d3e7f57b45ea502adc2fe0d03803de9bf5d,"Market-Oriented companies are committed to understanding both the needs of their customers, and the 
capabilities and plans of their competitors through the processes of acquiring and evaluating market information 
in a systematic and anticipatory manner. On the other hand, most companies in the last years have defined that 
one of their main strategic objectives for the next years is to become a truly data-driven organisation in the 
current Big Data context. They are willing to invest heavily in Data and Artificial Intelligence Strategy and build 
enterprise data platforms that will enable this Market-Oriented vision. In this paper, it is presented an Artificial 
Intelligence Cloud Architecture capable to help global companies to move from the use of data from descriptive 
to prescriptive and leveraging existing cloud services to deliver true Market-Oriented in a much shorter time 
(compared with traditional approaches).",data oriented architecture,248
d500cf270be481235be7655818ec80e65cdc8070,filtered,semantic_scholar,,2016-01-01,semantic_scholar,big data analytics with apache hadoop mapreduce framework,https://www.semanticscholar.org/paper/d500cf270be481235be7655818ec80e65cdc8070,"Huge amount of data cannot be handled by conventional database management system. For storing, processing and accessing massive volume of data, which is possible with help of Big data. In this paper we discussed the Hadoop Distributed File System and MapReduce architecture for storing and retrieving information from massive volume of datasets. In this paper we proposed a WordCount application of MapReduce object oriented programming paradigm. It divides input file into splits or tokens that is done with help of java.util.StingTokenizer class. Output file is represented in the form of , value>. The experimental results are conducted on Hadoop framework by loading large number of input files and evaluating the performance of Hadoop framework with respect to MapReduce object oriented programming paradigm. In this paper we have examined the performance of the map task and the reduce task by loading more number of files and read-write operations that are achieved by these jobs.",data oriented architecture,249
d9347d02a6642030b4d30db956103a9cae02078c,filtered,semantic_scholar,IEEE Access,2019-01-01,semantic_scholar,real-time context-aware microservice architecture for predictive analytics and smart decision-making,https://www.semanticscholar.org/paper/d9347d02a6642030b4d30db956103a9cae02078c,"The impressive evolution of the Internet of Things and the great amount of data flowing through the systems provide us with an inspiring scenario for Big Data analytics and advantageous real-time context-aware predictions and smart decision-making. However, this requires a scalable system for constant streaming processing, also provided with the ability of decision-making and action taking based on the performed predictions. This paper aims at proposing a scalable architecture to provide real-time context-aware actions based on predictive streaming processing of data as an evolution of a previously provided event-driven service-oriented architecture which already permitted the context-aware detection and notification of relevant data. For this purpose, we have defined and implemented a microservice-based architecture which provides real-time context-aware actions based on predictive streaming processing of data. As a result, our architecture has been enhanced twofold: on the one hand, the architecture has been supplied with reliable predictions through the use of predictive analytics and complex event processing techniques, which permit the notification of relevant context-aware information ahead of time. On the other, it has been refactored towards a microservice architecture pattern, highly improving its maintenance and evolution. The architecture performance has been evaluated with an air quality case study.",data oriented architecture,250
ed497f674af7d9c729f06bba3639d612c4bc019d,filtered,semantic_scholar,GvD,2016-01-01,semantic_scholar,the gobia method: fusing data warehouses and big data in a goal-oriented bi architecture,https://www.semanticscholar.org/paper/ed497f674af7d9c729f06bba3639d612c4bc019d,"Traditional Data Warehouse (DWH) architectures are challenged by numerous novel Big Data products. These tools are typically presented as alternatives or extensions for one or more of the layers of a typical DWH reference architecture. Still, there is no established joint reference architecture for both DWH and Big Data that is inherently aligned with business goals as implied by Business Intelligence (BI) projects. In this paper, the current iteration of a work-inprogress approach towards such custom BI architectures, the GOBIA method, is presented to address this gap, combining a BI reference architecture and a development process. A use case example is presented to illustrate the proposed method.",data oriented architecture,251
e641f72738bea9c196eaf0a6fca2663a57192589,filtered,semantic_scholar,AMCIS,2016-01-01,semantic_scholar,towards an architecture for big data-driven knowledge management systems,https://www.semanticscholar.org/paper/e641f72738bea9c196eaf0a6fca2663a57192589,"Nowadays, knowledge management systems are confronted with a variety and unprecedented amount of data, resulting from big data sources. A new generation of knowledge management systems for exploring and exploiting big data becomes a major need for organizations. For this reason, the paper proposes a novel service-oriented architecture for big data-driven knowledge management systems. The purpose of this research is to support organizations to leverage their knowledge-based assets for improving decisionmaking and facilitating organizational learning. The proposed architecture is based on the principles of design science research, including a set of constructs, a model and a method. The design evaluation is presented based on the analytical evaluation method. By applying the architecture, an organization can manage and govern business and digital transformation, setting them apart from their competitors.",data oriented architecture,252
574bf669d6d26df693023588492b40a9dd4917e9,filtered,semantic_scholar,The Journal of Supercomputing,2014-01-01,semantic_scholar,cloud computing in e-science: research challenges and opportunities,https://www.semanticscholar.org/paper/574bf669d6d26df693023588492b40a9dd4917e9,"Service-oriented architecture (SOA), workflow, the Semantic Web, and Grid computing are key enabling information technologies in the development of increasingly sophisticated e-Science infrastructures and application platforms. While the emergence of Cloud computing as a new computing paradigm has provided new directions and opportunities for e-Science infrastructure development, it also presents some challenges. Scientific research is increasingly finding that it is difficult to handle “big data” using traditional data processing techniques. Such challenges demonstrate the need for a comprehensive analysis on using the above-mentioned informatics techniques to develop appropriate e-Science infrastructure and platforms in the context of Cloud computing. This survey paper describes recent research advances in applying informatics techniques to facilitate scientific research particularly from the Cloud computing perspective. Our particular contributions include identifying associated research challenges and opportunities, presenting lessons learned, and describing our future vision for applying Cloud computing to e-Science. We believe our research findings can help indicate the future trend of e-Science, and can inform funding and research directions in how to more appropriately employ computing technologies in scientific research. We point out the open research issues hoping to spark new development and innovation in the e-Science field.",data oriented architecture,253
0f1d4f233d8a29c3c55d899027b3618533f366e7,filtered,semantic_scholar,Briefings Bioinform.,2016-01-01,semantic_scholar,how computer science can help in understanding the 3d genome architecture,https://www.semanticscholar.org/paper/0f1d4f233d8a29c3c55d899027b3618533f366e7,"Chromosome conformation capture techniques are producing a huge amount of data about the architecture of our genome. These data can provide us with a better understanding of the events that induce critical regulations of the cellular function from small changes in the three-dimensional genome architecture. Generating a unified view of spatial, temporal, genetic and epigenetic properties poses various challenges of data analysis, visualization, integration and mining, as well as of high performance computing and big data management. Here, we describe the critical issues of this new branch of bioinformatics, oriented at the comprehension of the three-dimensional genome architecture, which we call 'Nucleome Bioinformatics', looking beyond the currently available tools and methods, and highlight yet unaddressed challenges and the potential approaches that could be applied for tackling them. Our review provides a map for researchers interested in using computer science for studying 'Nucleome Bioinformatics', to achieve a better understanding of the biological processes that occur inside the nucleus.",data oriented architecture,254
ed917706e95581348579d0abdd34ad687e0a9a31,filtered,semantic_scholar,Int. J. Softw. Sci. Comput. Intell.,2019-01-01,semantic_scholar,using vehicles as fog infrastructures for transportation cyber-physical systems (t-cps): fog computing for vehicular networks,https://www.semanticscholar.org/paper/ed917706e95581348579d0abdd34ad687e0a9a31,"The advent of intelligent vehicular applications and IoT technologies gives rise to data-intensive challenges across different architectural layers of an intelligent transportation system (ITS). Without powerful communication and computational infrastructure, various vehicular applications and services will still stay in the concept phase and cannot be put into practice in daily life. The current cloud computing and cellular set-ups are far from perfect because they are highly dependent on, and bear the cost of additional infrastructure deployment. Thus, the geo-distributed ITS components require a paradigm shift from centralized cloud-scale processing to edge centered fog computing (FC) paradigms. FC outspreads the computing facilities into the edge of a network, offering location-awareness, latency-sensitive monitoring, and intelligent control. In this article, the authors identify the mission-critical computing needs of the next generation ITS applications and highlight the scopes of FC based solutions towards addressing them. Then, the authors discuss the scenarios where the underutilized communication and computational resources available in connected vehicles can be brought in to perform the role of FC infrastructures. Then the authors present a service-oriented software architecture (SOA) for FC-based Big Data Analytics in ITS applications. The authors also provide a detailed analysis of the potential challenges of using connected vehicles as FC infrastructures along with future research directions.",data oriented architecture,255
f87e659ff4c522fdfbb64a8486090f0440126664,filtered,semantic_scholar,"2015 International Conference on Event-based Control, Communication, and Signal Processing (EBCCSP)",2015-01-01,semantic_scholar,event-based hybrid metering feeding ami and scada,https://www.semanticscholar.org/paper/f87e659ff4c522fdfbb64a8486090f0440126664,"This article presents an industrial application in which event-based smart meters supplies datasets feeding the Advanced Metering Infrastructure, legacy billing procedures, and Supervisory Control and Data Acquisition systems of smart grid. New generation hybrid meters interoperate by using the FI-WARE architectural framework personalized by FINESCE team in the context of Cloud-based Service-Oriented Architecture made available by the Future Internet Public-Private-Partnership. Authors illustrate an opportunity to make observable each node of the Low Voltage energy distribution topology by using new event-based real time toolkit. In this industrial use case, event-based meters fed billing subsystem at regular time intervals, and supplies statefull events in real-time to the control system. This way, both event-based and timer-based datasets are conveyed to the FI-WARE cloud first, that directs them to the respective recipients by using publish-subscribe features and Big Data tools.",data oriented architecture,256
19793c5d3f8e6f346cfdac6477926f38111d0d93,filtered,semantic_scholar,Computer,2016-01-01,semantic_scholar,modern computer arithmetic,https://www.semanticscholar.org/paper/19793c5d3f8e6f346cfdac6477926f38111d0d93,"A 2009 IEEE Transactions on Computers (TC) guest editorial called computer arithmetic “the mother of all computer research and application topics.” Today, one might question what computer arithmetic still o ers in terms of advancing scienti c research; after all, multiplication and addition haven’t changed. The answer is surprisingly easy: new architectures, processors, problems, application domains, and so forth all require computations and are open to new challenges for computer arithmetic. Big data crunching, exascale computing, low-power constraints, and decimal precision are just a few domains in which advances are implicitly pushing for rapid, deep reshaping of the traditional computer-arithmetic framework. TC (www.computer.org/web/tc) has long published regular submissions as well as special sections on this topic, including one scheduled for 2017. Here, we focus on three recently published papers. In “Parallel Reproducible Summation,” James Demmel and Hong Diep Nguyen (IEEE Trans. Computers, vol. 64, no. 7, 2015, pp. 2060–2070) address result reproducibility in cases where it’s a requirement. They present a technique for floating-point reproducible addition that doesn’t depend on the order in which operations are performed, which makes it appropriate for massively parallel environments. Mioara Joldeş and her colleagues deal with manipulation of oatingpoint expansions in “Arithmetic Algorithms for Extended Precision Using Floating-Point Expansions” (IEEE Trans. Computers, vol. 65, no. 4, 2016, pp. 1197–1210). Such expansions, which are unevaluated sums of a few oatingpoint numbers, might be used when one temporarily needs to represent numerical values with a higher precision than that o ered by the available oating-point format. The authors introduce and prove new algorithms for dividing and square-rooting oating-point expansions, as well as for “normalizing” such expansions. In “On the Design of Approximate Restoring Dividers for Error-Tolerant Applications” (IEEE Trans. Computers, vol. 65, no. 8, 2016, pp. 2522–2533), Linbin Chen and his colleagues propose several approximate restoringdivider designs. Their simulation results show that, compared with nonrestoring division schemes, their designs had superior delay, power dissipation, circuit complexity, and error tolerance. Most striking, the approximate designs o er better error tolerance “for quotient-oriented applications (image processing) than remainder-oriented applications (modulo operations).”",data oriented architecture,257
33469f86bc7ef904c1f4664d1cadf22227e3462a,filtered,semantic_scholar,KES-HCIS,2020-01-01,semantic_scholar,"iot in smart farming analytics, big data based architecture",https://www.semanticscholar.org/paper/33469f86bc7ef904c1f4664d1cadf22227e3462a,"The concern over Smart Farming is growing, where Internet of Things (IoT) technologies are highlighted in the farm management cycle. Also a large amount of data is generated via different channels such as sensors, Information Systems (IS), and human experiences. A timely right decision-making by monitoring, analyzing, and creating value from these Big Data is a key element to manage and operate the farms smartly, and is also bound to technical and socio-economic constraints. Given the fact, in this research, we work on the implication of Big Data technologies, IoT, and Data Analysis in agriculture. And we propose a Smart Farming Oriented Big Data Architecture (SFOBA).",data oriented architecture,258
b0bf8eff2eb6465ff170219272c0bd84156a395b,filtered,semantic_scholar,,2015-01-01,semantic_scholar,intelligent cities: enabling tools and technology,https://www.semanticscholar.org/paper/b0bf8eff2eb6465ff170219272c0bd84156a395b,"The emergence of highly promising and potent technologies has enabled the transition of ordinary objects into smart artifactsproviding wider connectivity of digitized entities that can facilitate the building of connected cities. This book provides readers with a solid foundation on the latest technologies and tools required to develop and enhance smart cities around the world.The book begins by examining the rise of the cloud as the fundamental technology for establishing and sustaining smart cities and enterprises. Explaining the principal technologies and platform solutions for implementing intelligent cities, the book details the role of various technologies, standards, protocols, and tools in establishing flexible homes and the buildings of the future. Examines IT platforms and tools from various product vendors Considers service-oriented architecture and event-driven architecture for smart city applications Explains how to leverage big data analytics for smart city enhancement and improved decision making Includes case studies of intelligent cities, smart homes, buildings, transports, healthcare systems, and airports The authors explore the convergence of cloud computing and enterprise architecture and present valuable information on next-generation cloud computing. They also cover the various architectural types, including enterprise-scale integration, security, management, and governance.The book concludes by explaining the various security requirements of intelligent cities as well as the threats and vulnerabilities of the various components that form the basis of the intelligent city framework, including cloud, big data, Internet of Things, and mobile technologies.",data oriented architecture,259
481eb088af92e3865f21c9bd293bf9cb6cab4a19,filtered,semantic_scholar,IEEE Transactions on Services Computing,2018-01-01,semantic_scholar,data-driven and feedback-enhanced trust computing pattern for large-scale multi-cloud collaborative services,https://www.semanticscholar.org/paper/481eb088af92e3865f21c9bd293bf9cb6cab4a19,"Multi-cloud collaborative environment consists of multiple data centers, which is a typical processing platform for big data. This paper focuses on the trust computing requirement of multi-cloud collaborative services and develops a Data-driven and Feedback-Enhanced Trust (DFET) computing pattern across multiple data centers with several innovative mechanisms. First, a trust-aware service monitoring architecture is proposed based on distributed soft agents to serve as middleware for multi-cloud trust computing and task scheduling. A data-driven trust computation scheme based on multi-indicator monitoring data is then proposed. The integration of several key service indicators into trust computing makes this scheme suitable for service-oriented cloud applications. More importantly, according to the intrinsic relationship among users, monitors, and service providers, we propose an enhanced and hierarchical feedback mechanism that can effectively reduce networking risk while improving system dependability. Theoretical analysis shows that DFET pattern is highly dependable against garnished and bad-mouthing attacks. We also build a prototype system to verify the feasibility of DFET pattern and the experiments yield meaningful observations that can facilitate the effective utilization of DFET in the large-scale multi-cloud collaborative environment.",data oriented architecture,260
3f2f299796b6eaa9eaaa314b3f1e35a27717597a,filtered,semantic_scholar,2016 16th International Symposium on Communications and Information Technologies (ISCIT),2016-01-01,semantic_scholar,mining target users for mobile advertising based on telecom big data,https://www.semanticscholar.org/paper/3f2f299796b6eaa9eaaa314b3f1e35a27717597a,"The mobile advertising industry in China has developed rapidly in recent years. Many companies and brands tend to employ mobile advertising in order to reach the target customers accurately. However, the conversion rates associated with the advertising campaigns are usually quite low due to the low quality of the datasets and impropriate predictive model. In this paper, we propose a novel mobile advertising system architecture based on telecom big data analytics. The defined multi-dimensional user portrait is introduced for user label oriented ad display strategy or as the basic database for the further user classification algorithm. We also adopt the widely used logistic regression algorithm in this paper to improve the target accuracy. The result of use case, which is calculated from the real-time collected cellular network data, also shows the superior performance of the proposed mobile advertising system.",data oriented architecture,261
aac1d360dcb6b9f296f9195b9d07cb33527d11d9,filtered,semantic_scholar,2016 IEEE 2nd International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow (RTSI),2016-01-01,semantic_scholar,towards better scalability for iot-cloud interactions via combined exploitation of mqtt and coap,https://www.semanticscholar.org/paper/aac1d360dcb6b9f296f9195b9d07cb33527d11d9,"It is manifest the growing research and industrial interest in scalable solutions for the efficient integration of large amounts of deployed sensors and actuators (Internet of Things - IoT-devices) and cloud-hosted virtualized resources for elastic storage and processing (including big data online stream processing). Such relevant attention is also demonstrated by the emergence of interesting IoT-cloud platforms from industry and open-source communities, as well as by the flourishing research area of fog/edge computing, where decentralized virtual resources at edge nodes can support enhanced scalability and reduced latency via locality-based optimizations. In this perspective, this paper proposes an innovative distributed architecture combining machine-to-machine industry-mature protocols (i.e., MQTT and CoAP) in an original way to enhance the scalability of gateways for the efficient IoT-cloud integration. In addition, the paper presents how we have applied the approach in the practical experience of efficiently and effectively extending the implementation of the open-source gateway that is available in the industry-oriented Kura framework for IoT.",data oriented architecture,262
2d0e36ae78978b829e7ba544fbaa67043bc87938,filtered,semantic_scholar,,2015-01-01,semantic_scholar,agent-based manufacturing service discovery method for cloud manufacturing,https://www.semanticscholar.org/paper/2d0e36ae78978b829e7ba544fbaa67043bc87938,"The development of new generation information technology has brought opportunities for industrial production model innovation. Especially, the cloud computing, Internet of Things, and big data technology are widespread applied in industrial fields. Based on this tendency, a service-oriented networked manufacturing model called cloud manufacturing (CM) was proposed in 2010. In order to realize this manufacturing model, one of the key technologies is how to achieve the discovery of manufacturing service which has not found a suitable solution. In this paper, a manufacturing service discovery framework based on agent is provided. The architecture consists of two parts: one is that manufacturing task agent and manufacturing service agent based on the expansion of the object model, and the other one is task and service matching process knowledge base. Furthermore, a structural matching method is proposed to implement the static parameters matching of task agent and service agent, and a multi-agent system bid mechanism is built to accomplish the dynamic parameters matching of the two agents. A simulation environment based on JADE has been properly developed. The simulation shows that the discovery method can effectively achieve the manufacturing service discovery in CM environment, which provides technical support for the cloud manufacturing service platform development.",data oriented architecture,263
9b716916628ab9003f87bf5841350a847ff09c38,filtered,semantic_scholar,TheScientificWorldJournal,2014-01-01,semantic_scholar,cloud computing based systems for healthcare,https://www.semanticscholar.org/paper/9b716916628ab9003f87bf5841350a847ff09c38,"The emergence of cloud computing leads to new developments for diverse application domains. This is particularly true for healthcare with its tremendous importance in today's society, thus making it worth to investigate the relevant perspectives and insights. In this special issue, readers will find the foundations together with cutting-edge developments in the state-of-the-art of cloud computing based systems for healthcare. 
 
Cloud computing is getting increasing attention and represents nowadays one of the most important research topics in computing science and information systems. Cloud computing refers to both the applications delivered as services over the Internet and the hardware and software systems within the data centers which provide those services. Cloud is now seen as a valid strategy and specific applications based on these technologies have become widespread. 
 
Healthcare, as with any other service operation, has been impacted by the cloud computing phenomenon with the literature reporting both benefits and challenges of cloud computing in the area. However, the evolving nature of science and technology creates new scenarios that must be studied using interdisciplinary and holistic means. 
 
The aim of this special issue was to collect innovative and high-quality research contributions regarding the advances in the healthcare domain that are enabled by the use of cloud computing architectures and techniques. The focus is intended to be integral for cloud computing in healthcare, but emphasizing not only the IT side of the phenomenon but also the managerial and the health practitioner side. 
 
Editors received a considerable amount of submissions that were peer-reviewed by top experts in the field. Based on the reviews and our reading of the papers, editors selected seven high-quality ones to be published. Contributions of these papers are summarized as follows. 
 
Two contributions deal with scenarios where cloud computing can serve as an enabler for improved decision making and contribute to systemic improvements in healthcare domain. In “Usalpharma: a cloud-based architecture to support Quality Assurance training processes in health area using Virtual Worlds” by F. J. Garcia-Penalvo et al., the authors discuss ways cloud-based architectures can extend and enhance the functionality of training environments based on Virtual Worlds with focus on training processes in Quality Assurance for pharmaceutical laboratories. In “Cloud based meta-learning system for predictive modeling of biomedical data” by M. Vukicevic et al., the authors propose a cloud-based system that integrates a meta-learning framework for ranking and selection of the best predictive algorithms for data at hand and open-source big data technologies for analysis of biomedical data. 
 
Two contributions focus on the topics of risk and security as management issues in cloud computing based systems for healthcare. In “Proposal for a security management in cloud computing for health care” K. by Haufe et al., the authors propose a framework that aims to cover the most important security processes related to cloud computing in the healthcare sector. The approach considers both the standards of the ISO 27000 family, as well as specific aspects of healthcare organizations using cloud computing. In “Risks and crises for healthcare providers: the impact of cloud computing” by R. Glasberg et al., the multidisciplinary team of authors analyze risks and crises for healthcare providers and discuss the impact of cloud computing in such scenarios. 
 
Three contributions deal with specific healthcare-related use cases of cloud computing in diverse application scenarios. In “SAMuS: service-oriented architecture for multisensor surveillance in smart homes,” S. Van Hoecke et al. present the design of a service-oriented architecture (SOA) for multisensor surveillance in smart homes. The solution is evaluated by building a smart Kinect sensor that is able to dynamically switch between IR and RGB and improves person detection by incorporating feedback from pressure sensors within the SOA. In “A cloud-based X73 ubiquitous mobile healthcare system: design and implementation” by Z. Ji et al., a ubiquitous mobile healthcare uHealth system is presented. It is based on the ISO/IEEE11073 personal health data (PHD) standards (X73) and cloud computing techniques. In “An expert fitness diagnosis system based on elastic cloud computing,” K. C. Tseng et al. describe an expert diagnosis system based on cloud computing that is able to classify a user's fitness level based on supervised machine learning techniques. This system uses parameters such as user's physiological data, age, gender, and body mass index (BMI) and utilizes an elastic algorithm based on Poisson distribution to allocate computation resources dynamically. 
 
The special issue editors would like to take this opportunity to thank the authors for their papers and the reviewers for their valuable comments and suggestions. Special thanks also to the editorial team for its help and also for providing us an opportunity to edit this special issue.",data oriented architecture,264
f6c20e3ff831be79d2d99e36cd63db157eb644db,filtered,semantic_scholar,2015 50th International Universities Power Engineering Conference (UPEC),2015-01-01,semantic_scholar,cim oriented graph database for network topology processing and applications integration,https://www.semanticscholar.org/paper/f6c20e3ff831be79d2d99e36cd63db157eb644db,"Though CIM brings an integration of proprietary software applications of a utility, managing a sheer volume of data between the software application systems is still challenging for utility operators. With the advent of high performance database technologies and real-time big-data processing tools available, CIM oriented database can play important role in the operation and processing of the power system data. As the power system resembles connected-data, the choice of the database technology has to be based on the performance measures such as high-speed data retrieval of the connected-data and efficient storage. This paper presents a CIM oriented graph database (CIMGDB) by the object-graph mapping methodology. The integration of the CIMGDB with power system applications is discussed by the developed implementation architecture. The network topology processing (NTP) application is implemented on the CIMGDB. The NTP is tested on the six IEEE test systems and on one practical power system network. The six IEEE test systems are considered in evaluating and comparing the time complexity of CIMGDB with the CIM oriented relational database framework. The practical power system network is considered to demonstrate the implementation architecture and the CIMGDB integration with power system applications.",data oriented architecture,265
ef2e868a21567e2dc2ff655291ecb057a81b5e2a,filtered,semantic_scholar,,2016-01-01,semantic_scholar,"resource management for big data platforms: algorithms, modelling, and high-performance computing techniques",https://www.semanticscholar.org/paper/ef2e868a21567e2dc2ff655291ecb057a81b5e2a,"Serving as a flagship driver towards advance research in the area of Big Data platforms and applications, this book provides a platform for the dissemination of advanced topics of theory, research efforts and analysis, and implementation oriented on methods, techniques and performance evaluation. In 23 chapters, several important formulations of the architecture design, optimization techniques, advanced analytics methods, biological, medical and social media applications are presented. These chapters discuss the research of members from the ICT COST Action IC1406 High-Performance Modelling and Simulation for Big Data Applications (cHiPSet). This volume is ideal as a reference for students, researchers and industry practitioners working in or interested in joining interdisciplinary works in the areas of intelligent decision systems using emergent distributed computing paradigms. It will also allow newcomers to grasp the key concerns and their potential solutions.",data oriented architecture,266
291b3c452df36eef8578ebb02e80879df86cb390,filtered,semantic_scholar,Int. J. Intell. Inf. Technol.,2018-01-01,semantic_scholar,towards a service-oriented architecture for knowledge management in big data era,https://www.semanticscholar.org/paper/291b3c452df36eef8578ebb02e80879df86cb390,"Nowadays, big data is a revolution that transforms conventional enterprises into data-driven organizations in which knowledge discovered from big data will be integrated into traditional knowledge to improve decision-making and to facilitate organizational learning. Consequently, a major concern is how to evolve current knowledge management systems, which are confronted with a various and unprecedented amount of data, resulting from different data sources. Therefore, a new generation of knowledge management systems is required for exploring and exploiting big data as well as for facilitating the knowledge co-creation between the society and its business environment to foster innovation. This article proposes a service-oriented architecture for elaborating a new generation of big data-driven knowledge management systems to help enterprises to promote knowledge co-creation and to obtain more business value from big data. The proposed architecture is presented based on the principles of design science research and its evaluation uses the analytical evaluation method.",data oriented architecture,267
874ea834b5150072a90079ac4fba1e78999d8ed0,filtered,semantic_scholar,International Journal of Advanced Computer Science and Applications,2019-01-01,semantic_scholar,towards an architecture for handling big data in oil and gas industries: service-oriented approach,https://www.semanticscholar.org/paper/874ea834b5150072a90079ac4fba1e78999d8ed0,"Existing architectures to handle big data in Oil & gas industry are based on industry-specific platforms and hence limited to specific tools and technologies. With these architectures, we are confined to big data single-provider solutions. The idea of multi-provider big data solutions is essential. When building up big data solutions, organizations should embrace the best-in-class technologies and tools that different providers offer. In this article, we hypothesize that the limitations of the proposed big-data architectures for oil and gas industries can be addressed by a Service Oriented Architecture approach. In this article, we are proposing the idea of breaking complex systems to simple separate yet reliable distributed services. It should be noted that loose coupling exists between the interacting services. Thus, our proposed architecture enables petroleum industries to select the necessary services from the SOA-based ecosystem and create viable big data solutions.",data oriented architecture,268
8986ae83e7f4dea878066b69f42737d9b2d03a70,filtered,semantic_scholar,2013 Second International Conference on Informatics & Applications (ICIA),2013-01-01,semantic_scholar,"using of cloud computing, clustering and document-oriented database for enterprise content management",https://www.semanticscholar.org/paper/8986ae83e7f4dea878066b69f42737d9b2d03a70,"The paper deals with NoSQL Document-oriented database technology and its implementation in Enterprise Content Management area. The results of performance tests of the SQL and NoSQL solutions and suggestions on the conceptual architecture of the ECM system based on NoSQL Document-oriented database are provided. Using of cloud computing, clustering, data ranking and other Big Data related technologies is discussed.",data oriented architecture,269
eb5b680e81cf9cc71607f3567ce6350f95465a31,filtered,semantic_scholar,,2015-01-01,semantic_scholar,critical success factors ( csfs ) of service-oriented architecture ( soa ) in big data systems *,https://www.semanticscholar.org/paper/eb5b680e81cf9cc71607f3567ce6350f95465a31,"The objective of this study is to find out the critical success factors that are needed to implement Service-Oriented Architecture (SOA) in BIGDATA systems such as Cloud Enterprise Resource Planning (CERP) in India. A survey has conducted and data has been collected through online blog from India, particularly cities such as Chennai, Mumbai and New Delhi. The data is analysed using partial least square (smartPLS) statistical package and results are discussed. The analysed results would be very useful for academicians and researchers who would like to write articles in terms of implementing SOA with BIG DATA",data oriented architecture,270
fd64738c9015e8fa6643359b1cad007c806f6368,filtered,semantic_scholar,LWA,2015-01-01,semantic_scholar,the gobia method: towards goal-oriented business intelligence architectures,https://www.semanticscholar.org/paper/fd64738c9015e8fa6643359b1cad007c806f6368,"Traditional Data Warehouse (DWH) architectures are chal- lenged by numerous novel Big Data products. These tools are typically presented as alternatives or extensions for one or more of the layers of a typical DWH reference architecture. Still, there is no established joint reference architecture for both DWH and Big Data that is inher- ently aligned with business goals as implied by Business Intelligence (BI) projects. In this paper, a work-in-progress approach towards such cus- tom BI architectures, the GOBIA method, is presented to address this gap, combining a BI reference architecture and a development process.",data oriented architecture,271
5b6069aacf586b51364218ca76dd7b764088eb17,filtered,semantic_scholar,ISPRS Int. J. Geo Inf.,2018-01-01,semantic_scholar,an efficient graph-based spatio-temporal indexing method for task-oriented multi-modal scene data organization,https://www.semanticscholar.org/paper/5b6069aacf586b51364218ca76dd7b764088eb17,"Task-oriented scene data in big data and cloud environments of a smart city that must be time-critically processed are dynamic and associated with increasing complexities and heterogeneities. Existing hybrid tree-based external indexing methods are input/output (I/O)-intensive, query schema-fixed, and difficult when representing the complex relationships of real-time multi-modal scene data; specifically, queries are limited to a certain spatio-temporal range or a small number of selected attributes. This paper proposes a new spatio-temporal indexing method for task-oriented multi-modal scene data organization. First, a hybrid spatio-temporal index architecture is proposed based on the analysis of the characteristics of scene data and the driving forces behind the scene tasks. Second, a graph-based spatio-temporal relation indexing approach, named the spatio-temporal relation graph (STR-graph), is constructed for this architecture. The global graph-based index, internal and external operation mechanisms, and optimization strategy of the STR-graph index are introduced in detail. Finally, index efficiency comparison experiments are conducted, and the results show that the STR-graph performs excellently in index generation and can efficiently address the diverse requirements of different visualization tasks for data scheduling; specifically, the STR-graph is more efficient when addressing complex and uncertain spatio-temporal relation queries.",data oriented architecture,272
aa282e85218d0842fb7774cbf50b15da9925060a,filtered,semantic_scholar,2014 IEEE 10th International Conference on e-Science,2014-01-01,semantic_scholar,a scalable planetary science information architecture for big science data,https://www.semanticscholar.org/paper/aa282e85218d0842fb7774cbf50b15da9925060a,"Research has shown that the amount of data now available often overwhelms key functions of an information system. This situation necessitates the design of information architectures that scale to meet the challenges. The Planetary Data System, a NASA funded project, has developed an information architecture for the planetary science community that addresses this and other big science data issues noted in a National Research Council report regarding architectures for big data management and analysis and end-to-end data lifecycle management across diverse disciplines. The report identified enabling technology trends including distributed systems, service-oriented architectures, ontologies, models and information representation, scalable database systems, federated data security mechanisms, and technologies for moving big data. This paper will present the PDS4 information architecture, its successful implementation in a multi-discipline big-data environment.",data oriented architecture,273
4f5029c1bac6ef100c375bea3e3c9637b511e891,filtered,semantic_scholar,KMIS,2016-01-01,semantic_scholar,big data and knowledge management: how to implement conceptual models in nosql systems?,https://www.semanticscholar.org/paper/4f5029c1bac6ef100c375bea3e3c9637b511e891,"In 2014, Big Data has passed the top of the Gartner Hype Cycle, proving that Big Data technologies and 
 
application start to be mature, becoming more realistic about how Big Data can be useful for organizations. 
 
NoSQL data stores are becoming widely used to handle Big Data; these databases operate on schema-less 
 
data model enabling users to incorporate new data into their applications without using a predefined 
 
schema. But, there is still a need for a conceptual model to define how data will be structured in the 
 
database. In this paper, we show how to store Big Data within NoSQL systems. For this, we use the Model 
 
Driven Architecture (MDA) that provides a framework for models automatic transformation. Starting from 
 
a conceptual model that describes a set of complex objects, we propose transformation rules formalized with 
 
QVT to generate a column-oriented NoSQL model. To ensure efficient automatic transformation, we use a 
 
logical model that limits the impacts related to technical aspects of column-oriented platforms. We provide 
 
experiments of our approach using a case study example taken from the health care domain. The results of 
 
our experiments show that the proposed logical model can be effectively implemented in different columnoriented 
 
systems independently of their specific technical details.",data oriented architecture,274
537819f9d8561791bfd308942fe399bb95e8c20d,filtered,semantic_scholar,,2017-01-01,semantic_scholar,investigating an architectural framework for small data platforms,https://www.semanticscholar.org/paper/537819f9d8561791bfd308942fe399bb95e8c20d,"The potential of data to support solutions to some of the global grand challenges is uncontested. This potential is recognized and confirmed through the articulation of technology as an explicit Means of Implementation for the Sustainable Development Goals. In particular the advent of big data has introduced not only new data sources and data providers, but also new data analytics and processing algorithms that are having an impact across national and global data ecosystems. The major investments to harness this potential for data are being made in the private sector, to provide insights to inform better decision making for business; and also in the public sector where governments are exploring the use of data for better governance and service delivery. The role of data to make an impact on societal challenges, especially in the context of challenges related to social wellbeing and the Sustainable Development Goals, is typically considered from the macro and meso levels where the trends about national or state/district level phenomenon are observed. This macro level (also called ecological level) perspective, with its associated instruments of analysis, techniques of visualization, is in contrast to another growing perspective which is encapsulated in the small data approach. The small data approach seeks to connect individuals with ‘timely, meaningful insights, organized to be accessible, understandable, and actionable for everyday tasks’. Thus within this approach the unit of sampling (which is usually an individual or a household) is maintained as the same unit at which data analysis is undertaken. Consequently the target of consumption of the derived insights and knowledge is the individual, which implies the use of reporting and visualization techniques that are similarly geared at the individuals. This paper revisits an architectural framework for knowledge-oriented, context-sensitive platforms, and evaluates this architecture for the realization of systems and platforms that embody the small data approach. Through a layered and modular separation of data, access, social networking, interaction and presentation components, this architecture seeks to achieve the interaction and presentation personalization for individuals while ensuring not only improved data provenance preservation but also the security of the underlying data.",data oriented architecture,275
558c41804da624b4255e1191e7d0f71c44a73f54,filtered,semantic_scholar,Big Data 2017,2017-01-01,semantic_scholar,towards a unified ingestion-and-storage architecture for stream processing,https://www.semanticscholar.org/paper/558c41804da624b4255e1191e7d0f71c44a73f54,"Big Data applications are rapidly moving from a batch-oriented execution model to a streaming execution model in order to extract value from the data in real-time. However, processing live data alone is often not enough: in many cases, such applications need to combine the live data with previously archived data to increase the quality of the extracted insights. Current streaming-oriented runtimes and middlewares are not flexible enough to deal with this trend, as they address ingestion (collection and pre-processing of data streams) and persistent storage (archival of intermediate results) using separate services. This separation often leads to I/O redundancy (e.g., write data twice to disk or transfer data twice over the network) and interference (e.g., I/O bottlenecks when collecting data streams and writing archival data simultaneously). In this position paper, we argue for a unified ingestion and storage architecture for streaming data that addresses the aforementioned challenge. We identify a set of constraints and benefits for such a unified model, while highlighting the important architectural aspects required to implement it in real life. Based on these aspects, we briefly sketch our plan for future work that develops the position defended in this paper.",data oriented architecture,276
5f75b018f9f19dbc737146551fa0fda91d3d8a5d,filtered,semantic_scholar,,2014-01-01,semantic_scholar,guide to cloud computing for business and technology managers: from distributed computing to cloudware applications,https://www.semanticscholar.org/paper/5f75b018f9f19dbc737146551fa0fda91d3d8a5d,"Preface Acknowledgments Increasing Functional Specificity over Increasingly Commoditized Hardware Google's Vision of Utility Computing Drivers for Cloud Computing in Enterprises Modern On-Demand Computing Grid Computing Server Virtualization Computer Hardware Types of Computer Systems Parallel Processing Multiprogramming Vector Processing Symmetric Multiprocessing Systems Massively Parallel Processing Enterprise Systems Evolution of ES Extended Enterprise Systems (EES) Autonomic Computing Summary Section I: Genesis of Cloudware Networking and Internetworking ARPANET Ethernet TCP/IP Protocol Computer Networks Network Principles Types of Network Network Models Internet Internet Services World Wide Web Origin of the World Wide Web Browser Applications of the World Wide Web Semantic Web Internet of Things Summary Distributed Systems Distributed Applications N-Tier Application Architecture Enterprise Component Architecture Enterprise Component Model Distributed Application Requirements Component-Based Technologies Advent of Component-Based Technologies Distributed Computing in the Enterprise Summary Enterprise Application Integration (EAI) Enterprise Applications Management of Enterprise Applications Systems Heterogeneity in Enterprises Integration of Enterprise Applications Basics of Integration Models of Integration Patterns of Integration Summary Integration Technologies Middleware Database Access Technologies Microsoft Open Database Connectivity (ODBC) Java Database Connectivity (JDBC) Asynchronous Middleware Store and Forward Messaging Publish/Subscribe Messaging Point-to-Point Messaging Event-Driven Processing Mechanism Synchronous Middleware Remote Procedural Call (RPC) Remote Method Invocation (RMI) Messaging-Oriented Middleware (MOM) Integration Brokers Java Message Service (JMS) Request/Reply Messaging Middleware Transaction Processing Monitors Object Request Brokers Application Servers Web Services Enterprise Service Bus (ESB) Enterprise Systems Replacing a Point-to-Point Integration Architecture with a Broker Enterprise Systems with an Enterprise Model Summary J2EE for Enterprise Integration Choosing an Enterprise Application Integration Platform CORBA DCOM J2EE .NET Enterprise Application Integration (EAI) Using J2EE Reference Architecture Realization of the Reference Architecture in J2EE Model-View-Controller Architecture Overview of J2EE Platform Technologies Summary Section II: Road to Cloudware Service-Oriented Architecture Defining SOA Services SOA Benefits Characteristics of SOA Dynamic, Discoverable, Metadata Driven Designed for Multiple Invocation Styles Loosely Coupled Well-Defined Service Contracts Standard Based Granularity of Services and Service Contracts Stateless Predictable Service-Level Agreements (SLAs) Design Services with Performance in Mind SOA Ingredients Objects, Services, and Resources SOA and Web Services SOA and RESTful Web Services SOA Applications Rapid Application Integration Multichannel Access Business Process Management Summary Web Services Web Service Standards XML WSDL SOAP and Messaging UDDI Security, Transactions, and Reliability Semantic Web Services Summary Enterprise Service Bus (ESB) Defining Enterprise Service Bus (ESB) Evolution of ESB Elements of an ESB Solution Integration Brokers Application Servers Business Process Management ESB Transport-Level Choices Connectivity and Translation Infrastructure ESB Scalability Event-Driven Nature of ESB Key Capabilities of an ESB Leveraging Legacy Assets Summary Service Composition Process Workflow Business Process Management (BPM) Business Processes via Web Services Service Composition Business Process Execution Language (BPEL) Background of WSDL BPEL4WS BPEL Process Model Summary Application Service Providers (ASPs) Enterprise Application Service Providers (ASPs) Fundamentals of ASP ASP Business Model Service Level Agreements (SLAs) ASP Value Drivers ASP Benefits, Risks, and Challenges Oracle SAP CRM On Demand Private ASPs What Does a Private ASP Offer? Summary Grid Computing Background to Grid Computing Introduction to Grid Computing Virtualization Cluster Web Services P2P Network Comparison with Other Approaches Characteristics of a Grid Types of Grids Grid Technologies Grid Computing Standards Globus Summary Section III: Cloudware Cloudware Basics Cloud Definition Cloud Characteristics Cloud Delivery Models Infrastructure as a Service (IaaS) Platform as a Service (PaaS) Software as a Service (SaaS) Cloud Deployment Models Private Clouds Public Clouds Hybrid Clouds Community Clouds Cloud Benefits Flexibility and Resiliency Reduced Costs Centralized Data Storage Reduced Time to Deployment Scalability Cloud Challenges Scalability Multitenancy Availability Summary Cloudware Economics Drivers for Cloud Computing in Enterprises Total Cost of Ownership (TCO) Capital Budgeting Models Provisioning Configurations Traditional Internal IT Colocation Managed Service IaaS Cloud Model Quality of Service (QoS) Service-Level Agreement (SLA) Summary Cloudware Technologies Virtualization Characteristics of Virtualized Environment Layering and Virtualization Virtual Machines Types of Virtualization Operating System Virtualization Platform Virtualization Storage Virtualization Network Virtualization Service-Oriented Architecture (SOA) Operations in the SOA Roles in SOA Layers in an SOA Web Services Quality of Service (QoS) Summary Cloudware Vendors Solutions Infrastructure as a Service (IaaS) Solutions Amazon Platform as a Service (PaaS) Solutions Amazon Relational Database Service Google App Engine (GAE) Google Cloud Print Windows Azure Software as a Service (SaaS) Solutions Google Salesforce.com Open Source Cloud Solutions Nimbus OpenNebula Eucalyptus CloudStack Apache Hadoop Summary Cloudware Application Development Reliability Conundrum Functional Programming Paradigm Google MapReduce Google File System (GFS) Google's BigTable Hadoop Hadoop Distributed File System (HDFS) HBase Hive Pig Summary Cloudware Operations and Management Characteristics of Cloud Operations Core Services Discovery and Replication Load Balancing Resource Management Data Governance Management Services Fault Tolerance Core Portfolio of Functionality Metrics for Interfacing to Cloud Service Providers Selection Criteria for Service Provider(s) Service-Level Agreements (SLAs) Quality of Service (QoS) Pricing Models for Cloud Systems Software Licensing Summary Cloudware Security Governance IT Governance Security Privacy Trust Security Risks Dimensions of Security Identity Management Network Security Data Security Instance Security Application Architecture Patch Management Cloud Security Concerns Cloud Security Solutions Aspects of Cloud Security Solutions Cloudware Security, Governance, Risk, and Compliance Assessing a Cloud Service Provider Requisite Certifications Summary Migrating to Cloudware Cloud Computing Planning for Migration Deployment Model Scenarios Public Cloud Private Cloud Hybrid Cloud Cloud Adoption Plan As-Is (Baseline/Current State) Analysis To-Be (Target/Future State) Analysis Realization Go Live Summary Section IV: Cloudware Applications Big Data Computing Applications Big Data What Is Big Data? Common Characteristics of Big Data Computing Systems Big Data Appliances Tools, Techniques, and Technologies of Big Data Big Data Architecture Row versus Column-Oriented Data Layouts NoSQL Data Management In-Memory Computing Developing Big Data Applications Additional Details on Big Data Technologies Processing Approach Big Data System Architecture Row Partitioning or Sharding NoSQL Databases Column-Oriented Stores or Databases Key-Value Stores (K-V Store) or Databases Document-Oriented Databases Graph Stores or Databases Comparison of NoSQL Databases Summary Mobile Applications Agile Enterprises Stability versus Agility Aspects of Agility Principles of Built-for-Change Systems Framework for Change Proficiency Enhancing Enterprise Agility Network Enterprises Process-Oriented Enterprise Value-Add Driven Enterprise Business Process Management (BPM) Business Process Reengineering (BPR) Methodology Mobile-Enabling Business Processes Mobile Enterprise Mobile Business Processes Mobile Enterprise Systems Redesigning for Mobility Mobile Web Services Mobile Field Cloud Services Summary Context-Aware Applications Decision Patterns as Context Concept of Patterns Domain-Specific Decision Patterns CRM Decision Patterns Context-Aware Applications Context-Aware Mobile Applications Ontology-Based Context Model Context Support for User Interaction Location-Based Service (LBS) Applications LBS System Components LBS System Challenges Summary Appendix: Future of Moore's Law Cloudware and Moore's Law References Index",data oriented architecture,277
f0de9750a851ee6c88ca1e64b1fa95cf6af537a3,filtered,semantic_scholar,BIS,2016-01-01,semantic_scholar,multi-perspective digitization architecture for the internet of things,https://www.semanticscholar.org/paper/f0de9750a851ee6c88ca1e64b1fa95cf6af537a3,"Social networks, smart portable devices, Internet of Things (IoT) on base of technologies like analytics for big data and cloud services are emerging to support flexible connected products and agile services as the new wave of digital transformation. Biological metaphors of living and adaptable ecosystems with service-oriented enterprise architectures provide the foundation for self-optimizing and resilient run-time environments for intelligent business services and related distributed information systems. We are extending Enterprise Architecture (EA) with mechanisms for flexible adaptation and evolution of information systems having distributed IoT and other micro-granular digital architecture to support next digitization products, services, and processes. Our aim is to support flexibility and agile transformation for both IT and business capabilities through adaptive digital enterprise architectures. The present research paper investigates additionally decision mechanisms in the context of multi-perspective explorations of enterprise services and Internet of Things architectures by extending original enterprise architecture reference models with state of art elements for architectural engineering and digitization.",data oriented architecture,278
7101e554b086cdb8a7b3e58d202fbf472f8a105d,filtered,semantic_scholar,,2017-01-01,semantic_scholar,big data analytics with service-oriented architecture,https://www.semanticscholar.org/paper/7101e554b086cdb8a7b3e58d202fbf472f8a105d,"This chapter focuses on Big Data and its relation with Service-Oriented Architecture. We start with the introduction to Big Data Trends in recent times, how data explosion is not only faced by web and retail networks but also the enterprises. The notorious “V’s” – Variety, volume, velocity and value can cause a lot of trouble. We emphasize on the fact that Big Data is much more than just size, the problem that we face today is neither the amount of data that is created nor its consumption, but the analysis of all those data. In our next step, we describe what service-oriented architecture is and how SOA can efficiently handle the increasingly massive amount of transactions. Next, we focus on the main purpose of SOA here is to meaningfully interoperate, trade, and reuse data between IT systems and trading partners. Using this Big Data scenario, we investigate the integration of Services with new capabilities of Enterprise Architectures and Management. This has had varying success but it remains the dominant mode for data integration as data can be managed with higher flexibility.",data oriented architecture,279
be1d99414e1aa806a89229e8175ceb5d0a51b4fa,filtered,semantic_scholar,Electronics,2019-01-01,semantic_scholar,"intelligent micro energy grid in 5g era: platforms, business cases, testbeds, and next generation applications",https://www.semanticscholar.org/paper/be1d99414e1aa806a89229e8175ceb5d0a51b4fa,"As fifth-generation mobile communication systems give rise to new smart grid technologies, such as distributed energy resources, advanced communication systems, the Internet of Things, and big data analytics, the development of novel platforms and business models that ensure reliability and profitability of microgrid operations become increasingly important. In this study, we introduce an open micro energy grid platform to operate the widely distributed microgrids in Korea. Subsequently, we present commercial microgrid business models supported by the open micro energy grid platform equipped with an artificial intelligence engine and provide test results from testbeds connected to the platform. In contrast to the existing microgrid business models in the market, we propose a universal architecture and business model of the future microgrid, comprising (i) an energy robot-management operation business model, (ii) electric vehicle-based demand response, (iii) blockchain technology for energy trading, and (iv) a service-oriented business model. Finally, we propose a new business model for an intelligent virtual power plant (VPP) operator along with the architecture of the VPP and its proof of concept (PoC). We expect the proposed business model to provide energy solution providers with guidelines to develop various VPP services.",data oriented architecture,280
c5edac75cf94c6fb1f7f332ce37328803a67fe44,filtered,semantic_scholar,2016 IEEE/PES Transmission and Distribution Conference and Exposition (T&D),2016-01-01,semantic_scholar,the design and implementation of the enterprise level data platform and big data driven applications and analytics,https://www.semanticscholar.org/paper/c5edac75cf94c6fb1f7f332ce37328803a67fe44,"In order to improve the capability of utilizing big data and business intelligence in the power industry, this paper presents a comprehensive solution through building an enterprise-level data platform based on the OSIsoft PI system to support big data driven applications and analytics. The platform has the features of scalability, real time, service-oriented architecture and high reliability. Compared to traditional platforms in the power industry, the significant benefit of the innovative platform is that end users can use the data with the global model to drive the self-customized services rather than depend on IT professionals to deploy the service. The paper also describes how to implement data integration, global model construction and big data driven analytics, which are difficult to achieve with traditional solutions. Meanwhile, the paper exhibits preliminary visualization results through data analysis in real scenarios.",data oriented architecture,281
cc6f299a33009d6bd13ac69fd742f1a0504ffba3,filtered,semantic_scholar,IEEE Access,2018-01-01,semantic_scholar,a secured data management scheme for smart societies in industrial internet of things environment,https://www.semanticscholar.org/paper/cc6f299a33009d6bd13ac69fd742f1a0504ffba3,"Smart societies have an increasing demand for quality-oriented services and infrastructure in an industrial Internet of Things (IIoT) paradigm. Smart urbanization faces numerous challenges. Among them, secured energy demand-side management (DSM) is of particular concern. The IIoT renders the industrial systems to malware, cyberattacks, and other security risks. The IIoT with the amalgamation of big data analytics can provide efficient solutions to such challenges. This paper proposes a secured and trusted multi-layered DSM engine for a smart social society using IIoT-based big data analytics. The major objective is to provide a generic secured solution for smart societies in IIoT environment. The proposed engine uses a centralized approach to achieve optimum DSM over a home area network. To enhance the security of this engine, a payload-based authentication scheme is utilized that relies on a lightweight handshake mechanism. Our proposed method utilizes the lightweight features of the constrained application protocol to facilitate the clients in monitoring various resources residing over the server in an energy-efficient manner. In addition, data streams are processed using big data analytics with MapReduce parallel processing. The proposed authentication approach is evaluated using NetDuino Plus 2 boards that yield a lower connection overhead, memory consumption, response time, and a robust defense against various malicious attacks. On the other hand, our data processing approach is tested on reliable datasets using Apache Hadoop with Apache Spark to verify the proposed DMS engine. The test results reveal that the proposed architecture offers valuable insights into the smart social societies in the context of IIoT.",data oriented architecture,282
b5ae81662c03b7caa9649f35138307f2a3e30c03,filtered,semantic_scholar,,2016-01-01,semantic_scholar,smart citizen sensing: a proposed computational system with visual sentiment analysis and big data architecture,https://www.semanticscholar.org/paper/b5ae81662c03b7caa9649f35138307f2a3e30c03,"A city‘s ―smartness‖ depends greatly on citizens‘ participation in smart city services. Furthermore, citizens are becoming technology-oriented in every aspect concerning their convenience, comfort and safety. Thus, they become sensing nodes—or citizen sensors—within smart-cities with both static information and a constantly emitting activity system. This paper presents a novel approach to perform visual sentiment analysis of big visual data shared on social networks (such as Facebook, Twitter, LinkedIn, and Pinterest) using transfer learning. The proposed approach aims at contributing to smart citizens sensing area of smart cities. This work explores deep features of photos shared by users in Twitter via convolutional neural networks and transfer learning to predict sentiments. Moreover, we propose big data architecture to extract, save and transform raw Twitter image posts into useful insights. We obtained an overall prediction accuracy of 83.35%, which indicates that neural networks are indeed capable of predicting sentiments. Therefore, revealing interesting research opportunities and applications in the domain of smart sensing.",data oriented architecture,283
6a90c8a94a22c983ca0d7e8b131a3d223680fc67,filtered,semantic_scholar,Advances in Aeronautical Informatics,2018-01-01,semantic_scholar,flight 4.0: the changing technology landscape of aeronautics,https://www.semanticscholar.org/paper/6a90c8a94a22c983ca0d7e8b131a3d223680fc67,"This chapter draws the readers into a comprehensive discussion about the advances in Information and Communication Technologies (ICT) and their influence on the technology landscape of aeronautics. It gives a rough overview of the advances in technical systems from the industrial revolution up until Industry 4.0 and elaborates the reflection of these advancements in aeronautics from the pioneers era toward Flight 4.0. It briefly describes various recent fields of research in ICT such as Cyber-Physical Systems (CPS), Internet of Things (IoT) , wireless networks, multi-core architectures, Service-Oriented Architecture (SOA), cloud computing, big data, and modern software engineering methodologies as the parts of future aeronautical engineering body of knowledge. Thereafter, it describes aeronautical informatics as an establishing interdisciplinary field of study of applied informatics and aeronautics.",data oriented architecture,284
7a47b24b713fa9e920c97764edfcb703d2a8c42e,filtered,semantic_scholar,,2014-01-01,semantic_scholar,"service computing: concept, method and technology",https://www.semanticscholar.org/paper/7a47b24b713fa9e920c97764edfcb703d2a8c42e,"Service computing is a cross-disciplinary field that covers science and technology, and represents a promising direction for distributed computing and software development methodologies. It aims to bridge the gap between business services and IT services by supporting the whole lifecycle of services innovation. Over the last ten years applications in industry and academic research have produced considerable progress and success 
 
Service Computing: Concept, Method and Technology presents the concept of service computing and a proposed reference architecture for service computing research before proceeding to introduce two underlying technologies: Web services and service-oriented architecture. It also presents the authors' latest research findings on hot topics such as service discovery, recommendation, composition, verification, service trust, dynamic configuration and big data service. Some new models and methods are proposed including three service discovery methods based on semantics and skyline technologies, two service recommendation methods using graph mining and QoS prediction, two service composition methods with graph planning and one service verification method using π calculus and so on. Moreover, this book introduces JTang, an underlying platform supporting service computing, which is a product of the authors' last ten years of research and development. 
 
 
 
Systematically reviews all the research on service computing 
Introduces state-of-art research works on service computing and provides a road map for future directions 
Bridges the gap between service computing theory and practice 
Provides guidance for both industry and academia 
 
 
 
Table of Contents 
 
 
Introduction 
 
Service-Oriented Architecture and Web Services 
 
Service Discovery 
 
Service Recommendation 
 
Service Composition 
 
Service Verification 
 
Service Adaption 
 
Service Trustworthiness 
 
Dynamic Configuration for Complex Services 
 
Jtang Middleware Platform",data oriented architecture,285
5045fb290a1ab454ef18d1ab3ae1444712739529,filtered,semantic_scholar,IEEE Access,2021-01-01,semantic_scholar,towards a service-oriented architecture for the energy efficiency of buildings: a systematic review,https://www.semanticscholar.org/paper/5045fb290a1ab454ef18d1ab3ae1444712739529,"Currently, smart buildings generate large amounts of data due to the many devices and equipment available. Hence, buildings implement building management systems (BMSs), which monitor, control, manage and analyze each of these components. However, current BMSs are incapable of managing a massive amount of data (big data) and therefore cannot extract knowledge or make intelligent decisions in quasi real time. In addition, there are serious limitations to integrating BMSs with other services since they generally use proprietary software. In this sense, service-oriented architecture (SOA) is an architectural style that allows one to build distributed systems and provide functionalities such as services to end users or other types of services. Therefore, an SOA has the great advantage of allowing the expansion of the functionalities of BMSs. In fact, there are several studies that address SOAs for building management. However, we have not found any description or systematic analysis in the literature that allows the development of a versatile and interoperable SOA focused on the energy efficiency of buildings and that can integrate massive data analysis features. For these reasons, this study seeks to fill this knowledge gap and, more specifically, to identify and analyze the various software requirements proposed in the literature and the characteristics of big data that allow for improving the energy efficiency of buildings. To this end, we performed an in-depth review of the literature according to the methodology proposed by Kitchenham. As a result of this review, we provide researchers with a specific vision of the requirements and characteristics to consider for software development aimed at the energy efficiency of unique or historic buildings.",data oriented architecture,286
7d0e285df3b7b4f3df7acfc9468623e72c96436e,filtered,semantic_scholar,2015 IEEE International Conference on Cloud Engineering,2015-01-01,semantic_scholar,how to enhance cloud architectures to enable cross-federation: towards interoperable storage providers,https://www.semanticscholar.org/paper/7d0e285df3b7b4f3df7acfc9468623e72c96436e,"Small/medium cloud storage providers can hardly compete with the biggest cloud players such as Google, Amazon, Dropbox, etc. As a consequence, the cloud storage market depends on such mega-providers and each small/medium provider cannot face alone the challenge of Big Data storage. A possible solution consists in establishing stronger partnerships among small-medium providers where they can borrow/lend resources each other, according to the rules of the federated cloud ecosystem they belong to. According to such an approach, the challenge consists in creating federated cloud ecosystems able to compete with mega-provides and one of the major problems for the achievement of such an ecosystem is the management of inter-domain communications. In this paper, we propose an architecture addressing such an issue. In particular, we present and test a solution integrating the CLEVER Message Oriented Middleware (MOM) with the Hadoop Distribute File System (HDFS), i.e., one of the major massive storage solutions currently available on the market.",data oriented architecture,287
238f10e047f5a6064bce3c3fa627c82019d80840,filtered,semantic_scholar,,2016-01-01,semantic_scholar,decision case management for digital enterprise architectures with the internet of things,https://www.semanticscholar.org/paper/238f10e047f5a6064bce3c3fa627c82019d80840,"The Internet of Things (IoT), Enterprise Social Networks, Adaptive Case Management, Mobility systems, Analytics for Big Data, and Cloud services environments are emerging to support smart connected products and services and the digital transformation. Biological metaphors of living and adaptable ecosystems with service-oriented enterprise architectures provide the foundation for self-optimizing and resilient run-time environments for intelligent business services and related distributed information systems. We are investigating mechanisms for flexible adaptation and evolution for the next digital enterprise architecture systems in the context of the digital transformation. Our aim is to support flexibility and agile transformation for both business and related enterprise systems through adaptation and dynamical evolution of digital enterprise architectures. The present research paper investigates mechanisms for decision case management in the context of multi-perspective explorations of enterprise services and Internet of Things architectures by extending original enterprise architecture reference models with state of art elements for architectural engineering for the digitization and architectural decision support.",data oriented architecture,288
0e52e261c51d8d5d78e263249a4fa134c4fb018c,filtered,semantic_scholar,,2016-01-01,semantic_scholar,data-driven cyber-physical systems via real-time stream analytics and machine learning,https://www.semanticscholar.org/paper/0e52e261c51d8d5d78e263249a4fa134c4fb018c,"Emerging distributed cyber-physical systems (CPSs) integrate a wide range of heterogeneous components that need to be orchestrated in a dynamic environment. While model-based techniques are commonly used in CPS design, they be- come inadequate in capturing the complexity as systems become larger and extremely dynamic. The adaptive nature of the systems makes data-driven approaches highly desirable, if not necessary.Traditionally, data-driven systems utilize large volumes of static data sets to extract models and predictions of physical processes. However, in emerging CPS, networked sensors provide continually streaming data, creating an essentially infinite source of information. Processing data in batches is no longer a viable option: streams are most valuable when processed on-line, allowing actionable information to be gathered just as the data becomes available. This fundamental shift from big data to infinite data, while having great potential to enable smarter systems, also poses unique challenges. Computation models that capture the integration of streaming data into CPS design become a key requirement for systems to learn, adapt, and evolve in real-time.This thesis explores methodologies for developing data-driven CPSs that integrate model-based design and real-time stream analytics in a modular way. The key modeling framework to be introduced is the aspect-oriented modeling (AOM) paradigm, which leverages the principle of separation-of-concerns in actor-oriented de- sign. Aspects are useful for representing cross-cutting concerns in complex system architectures, as first introduced by the aspect-oriented programming paradigm in object-oriented design. AOM applies this idea to actor-oriented design, creating aspects that enable representation of modular concerns in a complex system model. In data-driven CPS, the introduced aspects can be leveraged to process streaming data, extract actionable information, and incorporate these into the system workflow in a way that preserves model semantics and modularity. To address information extraction from streaming data, we propose the use of aspects that implement Dynamic Bayesian Network based algorithms for machine learning and optimization. Specifically, we introduce an actor-oriented toolkit that enables dynamics and sensing models to be composed with inference, Bayesian learning, and optimization algorithms, and present comprehensive case studies on cooperative mobile robot control. We additionally study the use of streaming data for control of dynamic networked CPS in the context of home automation, and present an overview of the use cases of aspects in actor-oriented CPS development.",data oriented architecture,289
77e8d4bc65511f97d4bc1576ffb7da1a4b07af42,filtered,semantic_scholar,Int. J. Online Biomed. Eng.,2019-01-01,semantic_scholar,toward automatic generation of column-oriented nosql databases in big data context,https://www.semanticscholar.org/paper/77e8d4bc65511f97d4bc1576ffb7da1a4b07af42,"The growth of application architectures in all areas (e.g. Astrology, Meteorology, E-commerce, social network, etc.) has resulted in an exponential increase in data volumes, now measured in Petabytes. Managing these volumes of data has become a problem that relational databases are no longer able to handle because of the acidity properties. In response to this scaling up, new concepts have emerged such as NoSQL. In this paper, we show how to design and apply transformation rules to migrate from an SQL relational database to a Big Data solution within NoSQL. For this, we use the Model Driven Architecture (MDA) and the transformation languages like as MOF 2.0 QVT (Meta-Object Facility 2.0 Query-View-Transformation) and Acceleo which define the meta-models for the development of transformation model. The transformation rules defined in this work can generate, from the class diagram, a CQL code for creation column-oriented NoSQL database.",data oriented architecture,290
40b113a5169addf442905ff2e2245ba00b840c1b,filtered,semantic_scholar,,2013-01-01,semantic_scholar,scalable data-management systems for big data,https://www.semanticscholar.org/paper/40b113a5169addf442905ff2e2245ba00b840c1b,"Big Data can be characterized by 3 V’s. •Big Volume refers to the unprecedented growth in the amount of data. •Big Velocity refers to the growth in the speed of moving data in and out management systems. •Big Variety refers to the growth in the number of different data formats. Managing Big Data requires fundamental changes in the architecture of data management systems. Data storage should continue being innovated in order to adapt to the growth of data. They need to be scalable while maintaining high performance regarding data accesses. This thesis focuses on building scalable data management systems for Big Data. Our first and second contributions address the challenge of providing efficient support for Big Volume of data in data-intensive high performance computing (HPC) environments. Particularly, we address the shortcoming of existing approaches to handle atomic, non-contiguous I/O operations in a scalable fashion. We propose and implement a versioning-based mechanism that can be leveraged to offer isolation for non-contiguous I/O without the need to perform expensive synchronizations. In the context of parallel array processing in HPC, we introduce Pyramid, a large-scale, array-oriented storage system. It revisits the physical organization of data in distributed storage systems for scalable performance. Pyramid favors multidimensional-aware data chunking, that closely matches the access patterns generated by applications. Pyramid also favors a distributed metadata management and a versioning concurrency control to eliminate synchronizations in concurrency. Our third contribution addresses Big Volume at the scale of the geographically distributed environments. We consider BlobSeer, a distributed versioning-oriented data management service, and we propose BlobSeer-WAN, an extension of BlobSeer optimized for such geographically distributed environments. BlobSeer-WAN takes into account the latency hierarchy by favoring locally metadata accesses. BlobSeer-WAN features asynchronous metadata replication and a vector-clock implementation for collision resolution. To cope with the Big Velocity characteristic of Big Data, our last contribution feautures DStore, an in-memory document-oriented store that scale vertically by leveraging large memory capability in multicore machines. DStore demonstrates fast and atomic complex transaction processing in data writing, while maintaining high throughput read access. DStore follows a single-threaded execution model to execute update transactions sequentially, while relying on a versioning concurrency control to enable a large number of simultaneous readers.",data oriented architecture,291
73b3a42ed53bb7072d5366fd114f337c061b4d71,filtered,semantic_scholar,2018 4th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP),2018-01-01,semantic_scholar,a framework for big data driven product traceability system,https://www.semanticscholar.org/paper/73b3a42ed53bb7072d5366fd114f337c061b4d71,"In recent years, the safety of consumer goods such as food products, drugs, etc. has become one of the major research challenge. This was due to the several food and drugs scandals and incidents that occurs during the 21st century (horse meat, mad cow disease, counterfeit drucs, etc.). To respond to this problem, multiple sectors of industry are becoming more client-oriented and needs faster response to deal with such issues. Product Traceability Systems (PTS) can ensure product authenticity over its whole lifecycle, thereby reducing the potential for bad publicity, minimising recall costs and stoping the distribution of unsafe products. However, current traceability systems are not adapted for all industries, they still deal with specific domain segment (food industry). This paper presents a comparative study between several works done on product traceability and proposes based on this study a standardized traceability system architecture based on Big Data technology.",data oriented architecture,292
184c3915fe0aefc21aecc8d0fcb3db0b45348240,filtered,semantic_scholar,,2016-01-01,semantic_scholar,cloud big data application for transport,https://www.semanticscholar.org/paper/184c3915fe0aefc21aecc8d0fcb3db0b45348240,This paper presents a cloud service oriented approach for managing and analysing big data required by transport applications. Big data analytics brings new insights and useful correlations of large data collections providing undiscovered knowledge. Applying it to transport systems brings better understanding to the transport networks revealing unexpected choking points in cities. This facility is still largely inaccessible to small companies due to their limited access to computational resources. A cloud-oriented architecture opens new perspectives for providing efficient and personalised big data management and analytics services to (small) companies.,data oriented architecture,293
ba44d5ca40bc4f5b3e8df83c0aefdc7d6a5d09c6,filtered,semantic_scholar,2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC),2017-01-01,semantic_scholar,an iot architecture for personalized recommendations over big data oriented applications,https://www.semanticscholar.org/paper/ba44d5ca40bc4f5b3e8df83c0aefdc7d6a5d09c6,"The paper presents an innovative Internet of Things architecture for building personalized services in the smart city context. The main blocks of the presented implementation comprise data flows implemented through Node-Red, Neo4j data store for handling the smart city big data and a recommendation service which is applied in order to offer personalized recommendations to the users. The current work studies integration of the various components, the modelling approach for user generated data combined with open big data and proceeds with the appropriate reference implementation and experimentation to validate the personalized recommendation services for innovative citizen-centric applications and use cases. Moreover, we study and validate performance issues of this Neo4j based recommendation service and evaluate it as a useful appliance for real-time big data application.",data oriented architecture,294
ad3e23bbac51d2c053305aedd9864676c88210ae,filtered,semantic_scholar,"2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)",2016-01-01,semantic_scholar,i-hastream: density-based hierarchical clustering of big data streams and its application to big graph analytics tools,https://www.semanticscholar.org/paper/ad3e23bbac51d2c053305aedd9864676c88210ae,"Big Data Streams are very popular at now, as stirred-up by a plethora of modern applications such as sensor networks, scientific computing tools, Web intelligence, social network analysis and mining tools, and so forth. Here, the main research issue consists in how to effectively and efficiently extract useful knowledge from (streaming) big data, in order to support innovative big data analytics platforms. To this end, clustering analysis is a well-known tool for extracting knowledge from big data streams, as also confirmed by recent trends in active literature. A special applicative case is represented by so-called graph-shaped data (big) streams, which are produced by graph sources providing both structure-and content-oriented knowledge. On top of such sources, big graph analytics is a leading scientific area to be considered. At the convergence of these emerging topics, in this paper we provide the following contributions: (i) I-HASTREAM, a novel density-based hierarchical clustering algorithm for evolving big data streams that founds on it predecessor, namely HASTREAM, (ii) the architecture of a big graph analytics engine that embeds I-HASTREAM in its core layer.",data oriented architecture,295
3b04fd35b2671e4f6546dc2f64f050d607db1c05,filtered,semantic_scholar,2015 IEEE/ACM 7th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems,2015-01-01,semantic_scholar,cloud and multi-cloud computing: current challenges and future applications,https://www.semanticscholar.org/paper/3b04fd35b2671e4f6546dc2f64f050d607db1c05,"Computing systems are becoming increasingly virtual. We come from a world where applications were entirely developed by organizations for their own use, possibly exploiting components and/or platforms developed by third parties, but mainly deployed and executed on the organizations own IT facilities. With Service Oriented systems, we moved into a world in which a software application may delegate part of its functionality to already existing software services run by external organizations. Recent advances in Cloud computing are pushing virtuality even further: users can access third party software components, hardware physical resources or full application stacks that support execution and automatic management of Cloud based applications, and pay only for the resources they use. Cloud computing is growing daily, providing a vibrant technical environment where innovative solutions and services can be created. The Cloud promises the capability for cheap and flexible services for end-users and allows small organizations and individuals to host and offer world-scale services, themselves. However, while there has been substantial research in the field already, there still remain open challenges. Specifically, Cloud business models and technologies introduce critical issues, such as proprietary APIs and lack of interoperability [1]. The choice of the application architecture matching and fully exploiting the characteristics of the underlying Cloud environments is also critical [2], [3]. At the infrastructural layer, resource contentions lead to unpredictable performance [4] and additional work for resource management [5], automated VM and service migration [6] is still needed. Also networks are frequently the Cloud bottleneck and data center energy management is very critical [7]. To cope with such challenges the adoption of multi-Clouds [8], has been advocated by many researchers, since deploying software on multiple Clouds overcomes single provider unavailability and allows to build cost efficient follow the sun applications. Moreover, Cloud computing is also becoming a mainstream solution to provide very large clusters in a pay per use basis to support Big data applications [9]. Many cloud providers already include in their offering MapReduce based platforms (i.e., one of the most adopted framework to support large volume unstructured information processing) such as Google MapReduce framework, Microsoft HDinsight, and Amazon Elastic Compute Cloud. IDC estimates that by 2020, nearly 40% of Big Data analyses will be supported by public cloud. To support such challenges a Model-Driven Development (MDD) approach developed within the MODAClouds (www. modaclouds.eu) and DICE (dice-h2020.eu) European projects will be presented. MDD allows shifting the paradigm from code-centric to model-centric. Models are thus the main artefacts of the development process and enable developers to work at a high level of abstraction by focusing on Cloud concerns rather than implementation details [10]. Model transformations help automating the work of going from abstract concepts to implementation. Moreover, models can also be used to reason about the QoS properties of an application [2] and to support design-time exploration in order to identify the Cloud deployment configuration of minimum cost, while satisfying QoS constraints [3]. Finally, models can be kept alive also at runtime to trigger dynamic adaptation [10], [5], providing QoS guarantees even under workload fluctuations, virtualized systems performance degradations, or failures.",data oriented architecture,296
a6a457a80114a57b7857568227daf95806656770,filtered,semantic_scholar,2018 13th Iberian Conference on Information Systems and Technologies (CISTI),2018-01-01,semantic_scholar,integration through mapping — an openehr based approach for research oriented integration of health information systems,https://www.semanticscholar.org/paper/a6a457a80114a57b7857568227daf95806656770,"The growing need for Healthcare Information Systems that meets standards of rigor and demand, as well as the need to provide health researchers with the best quality data, has created a major challenge with regard to interoperability in information systems. Nowadays it is common patient data to be dispersed by various systems. Modern systems are tending to adopt standards for modelling and communicating information, but this is not true for legacy systems, where the precision in terms of medical concepts are not standardized. Many times these systems are developed solutions to a specific needs of a medical service, without care for the terminology of clinical concepts representation or how it is structured in terms of semantic. Research relies heavily on the available data, and in context of Big Data analysis, the possibility of aggregating data from multiple, different and distributed sources in a meaningful and straightforward way is relevant. The main objective of this work is to propose an integration architecture that enables access to clinical data from different heterogeneous sources for research purposes. This paper presents an architecture based on the openEHR standard and a proof of concept of the mapping component that provides a tool for matching the attributes of openEHR Archetypes/Templates and fields of databases. With this approach all the data distributed in various repositories, legacy or openEHR are potentially available to the researcher, through the creation of AQL queries in order to get aggregated results for additional research activities.",data oriented architecture,297
7c5624ace5eefe7c2f49fd95a05496c1907b3242,filtered,semantic_scholar,2017 36th Chinese Control Conference (CCC),2017-01-01,semantic_scholar,storage and parallel topology processing of the power network based on neo4j,https://www.semanticscholar.org/paper/7c5624ace5eefe7c2f49fd95a05496c1907b3242,"With the rapid development of the information technology and the smart grid technology, the Energy Internet as the core of the third industrial revolution is on the rise. The EI is a complete set of future energy system from energy production, transportation, distribution, transformation and consumption and so on. The traditional model of data storage and processing have been unable to meet the requirements of high availability and real-time of the Energy Internet. In view of this, this paper proposes Graph-CIM model based on the Hadoop architecture, and build a service oriented architecture of processing the big data of the Energy Internet. This paper designs the interface based on the Graph-CIM model of the power network data management, and develops the application of power network topology processing. Finally, the data of the power network in Shandong is tested, which verifies the robustness of the distributed storage and the performance of parallel topology analysis.",data oriented architecture,298
468e9ddd010c1ce16a281df9c05da9a9cd89402a,filtered,semantic_scholar,,2017-01-01,semantic_scholar,big data analytics : understanding its capabilities and potential bene fi ts for healthcare organizations,https://www.semanticscholar.org/paper/468e9ddd010c1ce16a281df9c05da9a9cd89402a,"Article history: Received 17 June 2015 Received in revised form 11 November 2015 Accepted 12 December 2015 Available online 26 February 2016 To date, health care industry has not fully grasped the potential benefits to be gained from big data analytics. While the constantly growing body of academic research on big data analytics is mostly technology oriented, a better understanding of the strategic implications of big data is urgently needed. To address this lack, this study examines the historical development, architectural design and component functionalities of big data analytics. From content analysis of 26 big data implementation cases in healthcare, we were able to identify five big data analytics capabilities: analytical capability for patterns of care, unstructured data analytical capability, decision support capability, predictive capability, and traceability.We alsomapped the benefits driven by big data analytics in terms of information technology (IT) infrastructure, operational, organizational, managerial and strategic areas. In addition, we recommend five strategies for healthcare organizations that are considering to adopt big data analytics technologies. Our findingswill help healthcare organizations understand the big data analytics capabilities and potential benefits and support them seeking to formulate more effective data-driven analytics strategies. © 2016 Elsevier Inc. All rights reserved.",data oriented architecture,299
db241ef09e26a296664e872f9ddb6ae122770b1c,filtered,semantic_scholar,2016 IEEE 20th International Enterprise Distributed Object Computing Workshop (EDOCW),2016-01-01,semantic_scholar,multi-perspective decision management for digitization architecture and governance,https://www.semanticscholar.org/paper/db241ef09e26a296664e872f9ddb6ae122770b1c,"The Internet of Things, Enterprise Social Networks, Adaptive Case Management, Mobility S ystems, Analytics for Big Data, and Cloudenvironments are emerging to support smart connected i.e. digital products and services and the digital transformation. Biological metaphors of living and adaptable ecosystems provide the logical foundation for self- optimizing and resilient run-time environments for intelligent business services and related distributed information systems with service-oriented digitization architectures. We are investigatingmechanismsforflexibleadaptationandevolution of information systems with digital architecture in the context of the ongoing digital transformation. Our aim is to support flexibility and agile transformation for both business and related information systems through adaptation and dynamical evolution of their digital architectures. The present research paper investigates mechanisms of decision analytics for digitization architectures, putting a spotlight to Internet of Things architectures, by extending original enterprise architecture reference models with digitization architectures andtheirmulti- perspective architectural decision management.",data oriented architecture,300
206595baad102edad8e3262563ee07fb4987ff23,filtered,semantic_scholar,2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom),2015-01-01,semantic_scholar,secure authentication using biometric templates in kerberos,https://www.semanticscholar.org/paper/206595baad102edad8e3262563ee07fb4987ff23,"The paper suggests the use of biometric templates for achieving the authentication in distributed systems and networks using Kerberos. The most important advantage in using the biometric templates is implying biologically inspired passwords such as pupil, fingerprints, face, iris, hand geometry, voice, palm print, handwritten signatures and gait. Using biometric templates in Kerberos gives more reliability to client server architectures for analysis in distributed platform while dealing with sensitive and confidential information. Even today the companies face challenge of security of confidential data. Although the main focus of the development of hadoop, CDBMS like technologies was primarily oriented towards the big data analysis, data management and further conversion of huge chunks of raw data into useful information. Hence, implementing biometric templates in Kerberos makes various frameworks on master slave architecture to be more reliable providing an added security advantage.",data oriented architecture,301
e73438185bce358ddaf0eb330cb216970d79df63,filtered,semantic_scholar,,2021-01-01,semantic_scholar,secured big data analytics for decision-oriented medical system using internet of things,https://www.semanticscholar.org/paper/e73438185bce358ddaf0eb330cb216970d79df63,"The Internet of Medical Things (IoMT) has shown incredible development with the growth of medical systems using wireless information technologies. Medical devices are biosensors that can integrate with physical things to make smarter healthcare applications that are collaborated on the Internet. In recent decades, many applications have been designed to monitor the physical health of patients and support expert teams for appropriate treatment. The medical devices are attached to patients’ bodies and connected with a cloud computing system for obtaining and analyzing healthcare data. However, such medical devices operate on battery powered sensors with limiting constraints in terms of memory, transmission, and processing resources. Many healthcare solutions are helping the community with the efficient monitoring of patients’ conditions using cloud computing, however, mostly incur latency in data collection and storage. Therefore, this paper presents a model for the Secured Big Data analytics using Edge–Cloud architecture (SBD-EC), which aims to provide distributed and timely computation of a decision-oriented medical system. Moreover, the mobile edges cooperate with the cloud level to present a secure algorithm, achieving reliable availability of medical data with privacy and security against malicious actions. The performance of the proposed model is evaluated in simulations and the results obtained demonstrate significant improvement over other solutions.",data oriented architecture,302
a6ae7ad3b0fb61846ea3b3b397e6b186284dc2f4,filtered,semantic_scholar,Ann. des Télécommunications,2017-01-01,semantic_scholar,cloudification of the internet of things,https://www.semanticscholar.org/paper/a6ae7ad3b0fb61846ea3b3b397e6b186284dc2f4,"The focus of this special issue is on the Internet of Things (IoT) with particular emphasis on the use of the Cloud as a central component of the IoTarchitecture and a key infrastructural support for IoT applications. With its virtualized infrastructure and software-defined networking substrate, the Cloud is in a good position to provide a flexible and scalable hosting environment for the plethora of emerging IoT applications in health, transportation, smart cities, and many other application areas. The shared infrastructure as service-oriented architecture of the Cloud can be indeed leveraged in support of IoT-generated data and control flows, Machine-to-Machine (M2M) communication, Big-data analytics, IoT management systems, security solutions, Network Function Virtualization (NFV), and SDN-based data forwarding to name a few. This special issue addresses a wide spectrum of research issues pertaining to the use of Cloud infrastructures in support of IoT systems from the sensors and machines to the end users and applications hosted in the Cloud. It comprises selected papers that provide an overview of and in-depth research, development, and deployment efforts on the Cloudification of IoT, specifically IoT infrastructure, IoT gateways, and IoT cloud environments. Hereafter, a summary of each paper accepted in this special issue is described.",data oriented architecture,303
5acd17eabd994cf851ff9ee8e4b30317eda1e2a4,filtered,semantic_scholar,2015 IEEE/ACIS 14th International Conference on Computer and Information Science (ICIS),2015-01-01,semantic_scholar,a big data approach to enhance the integration of access control policies for web services,https://www.semanticscholar.org/paper/5acd17eabd994cf851ff9ee8e4b30317eda1e2a4,"Service-oriented Architecture (SoA) is a layered architecture used to organize software resources as services that can be deployed, discovered and combined to produce new services. The interactions between services can be affected in situations where a destination service becomes unavailable. Herein, the Protocol service is introduced as a solution to coordinate interactions between services. The method is then extended to consider the automatic assignment of access control policies by the generation of a new service, called the Access Control Policies (AC_Policies) service, which is linked to the Protocol service. In this context, the Protocol service manages a large amount of data. The analysis of such data sets may help improving the Protocol service performance. Dealing with such a large data sets is referred recently as “Big Data”, is a term related to large set of data that is complicated to be analyzed using traditional applications. One of the most successful implementations of Big Data is the Hadoop Framework. This paper proposes an extension to automate the integration of the Hadoop platform. This aims to breaks individual problems down into multiple subtasks, using a simple programming model (MapReduce). After the analysis is computed, the result is submitted to a Score table linked with the Protocol service. The approach harnesses the capability of Model-Driven Architecture (MDA) to automate the creation, and integration of the architecture. As a proof of concept, the approach is then implemented as a tool.",data oriented architecture,304
334496d101957a8ae488c58f355aa052e990c775,filtered,semantic_scholar,Acta informatica medica : AIM : journal of the Society for Medical Informatics of Bosnia & Herzegovina : casopis Drustva za medicinsku informatiku BiH,2019-01-01,semantic_scholar,generating and knowledge framework: design and open specification,https://www.semanticscholar.org/paper/334496d101957a8ae488c58f355aa052e990c775,"Introduction: The Information Aggregation (IA) component manages streaming and batch data deriving from a multitude sources in a scalable, efficient and reliable way to create Holistic Health Records (HHRs).Within this context, the IA component combines a number of diverse data sources into a common format and stores information in an available form to be used for analytics, simulations and decision making. Aim: The purpose of this paper is to provide an overview of the CrowdHEALTH project and the technical architecture of the CrowdHEALTH platform in order to put the aforementioned IA mechanism in context. This is followed by the design details and initial specifications of the first prototype of the IA component as well as its relationship with other components. Methods: The micro-service approach can be used to perform information aggregation and to update HHRs in the CrowdHEALTH platform. Micro-services are a variant of the service-oriented architecture (SOA) where applications are structured as a collection of loosely coupled services with defined interfaces. Results: Within the CrowdHEALTH architecture, the Information Aggregation component is situated between the Interoperability Layer and the CrowdHEALTH Datastore. The Information Aggregation component processes and aggregates interoperable data, before data aggregation in the HHRs and storage in the big datastore of CrowdHEALTH platform. The aggregation functions use big data management techniques and enhance the state of the art in specific areas such as the use of micro-services to perform synchronous aggregation operations on heterogeneous datasets. Conclusions: Although an initial version of the IA component was presented, the specifications and implementation level details will be further updated during the project’s course.",data oriented architecture,305
623b2bd810131197d133fe8a1b5b358b6dc0c815,filtered,semantic_scholar,2014 IEEE International Congress on Big Data,2014-01-01,semantic_scholar,a key-value based application platform for enterprise big data,https://www.semanticscholar.org/paper/623b2bd810131197d133fe8a1b5b358b6dc0c815,"Big data poses big challenges to modern enterprises. Traditional data-intensive business applications begin to fall behind the times, because of insufficient capabilities to process large data volumes, ever-changing streaming data and unstructured information. Furthermore, large, complex and all-in-one enterprise applications are no longer popular, whereas lightweight and fragmentary applications become welcome for the sake of the bursts of cloud computing and mobile internet. Below this kind of situation, this paper proposed a big data application platform for enterprises to simply develop and operate personalized data retrieval, data analysis, business intelligence and other data-intensive services. Unlike current related products, it is distinguished for the design of key-value based hybrid data storage and a service-oriented outsourcing architecture. The former is used to resolve the frequently-encountered issue of diversified and massive data storage, and the latter enables an open environment for third-party vendors, which promotes a self-increasing services ecosystem for big data application development. In order to validate the feasibility of our platform, the paper also developed a sentiment analysis application for Kingdee popular products based on the services provided by the platform. The result of our experiment proves that the platform shows enough potential to effectively facilitate data-intensive application development.",data oriented architecture,306
716a313d921b30b4e5e05b428733b68fd0257f28,filtered,semantic_scholar,Innovations in Systems and Software Engineering,2019-01-01,semantic_scholar,performance analysis of an efficient object-based schema oriented data storage system handling health data,https://www.semanticscholar.org/paper/716a313d921b30b4e5e05b428733b68fd0257f28,"Object-based cloud storage system has an important role in handling big data. All available cloud storage systems deal with scalability, reliability or durability issues. However, there is lack of work addressing data variety. In a previous paper, a basic architecture of an object-based schema oriented data storage system has been proposed which stores data in an encapsulated way. The system comprises account layer, container layer, object layer, database layer and schema layer. In this paper, the architecture proposed in our previous paper has been elaborated. For example, the communication protocols of the proposed system are explained. Moreover, this architecture is realized to test its effectiveness on health data in terms of query execution performance and flexibility on the basis of four different queries of database computation (e.g., append, read, aggregate and delete). The result set are collected on three types of datasets (table, document, file) taken from healthcare scenario. Each type of dataset consists of four different sets of data records. The performance is compared with Amazon S3 (i.e., bucket oriented object-based data storage system) and Microsoft Azure (i.e., account-container oriented object-based data storage system). Flexibility property is also analyzed with respect to these three database operations (i.e., READ, WRITE and DELETE) on three types of experimental datasets (table, document, file) with Amazon S3.",data oriented architecture,307
cd022843689dc7a55c0da5fb046fd81990dd7d9a,filtered,semantic_scholar,APMS,2017-01-01,semantic_scholar,advances in internet of things (iot) in manufacturing,https://www.semanticscholar.org/paper/cd022843689dc7a55c0da5fb046fd81990dd7d9a,"As a promising technology with increased adoption in recent years, Internet of Things (IoT) realizes ubiquitous interconnection of physical devices through internet, opening doors for building powerful industrial applications by leveraging the advances in sensor technology and wireless networks. IoT technologies can be viewed as enablers for smart manufacturing and Industry 4.0. This review paper focuses on applications of IoT in manufacturing, which is also known as Industrial Internet of Things IIoT. To that end, technologies relevant to the application of IoT in manufacturing, such as wireless sensor networks (WSNs), smart sensors, big data analytics, and cloud computing are discussed. A service oriented architecture (SOA) based four-layer model for realizing IoT applications in manufacturing is proposed. Finally, a review of the state of art of IoT applications in manufacturing including shop floor automation, predictive maintenance, energy aware manufacturing, and smart workers is presented with relevant industry use cases.",data oriented architecture,308
5b0d7887a4e47b7c4fba7eee5dd8eef6d82bda53,filtered,semantic_scholar,IEEE Access,2018-01-01,semantic_scholar,job allocation mechanism for battery consumption minimization of cyber-physical-social big data processing based on mobile cloud computing,https://www.semanticscholar.org/paper/5b0d7887a4e47b7c4fba7eee5dd8eef6d82bda53,"The rapid development of information & communication technology has led to the wide popularity of mobile devices, which have helped to improve business efficiency and enabled simple mobility as small and light devices and convenience of being available anytime, anywhere for cyber-physical-social big data. There are many ongoing studies on mobile cloud computing (MCC) to overcome the limited computing capability and storage capacity and internal battery limitation by taking advantage of the popularity of mobile devices for the processing cyber-physical-social big data. MCC consists of service-oriented architecture, agent-client architecture, and collaborative architecture, with job splitting and allocation as the critical factor. As such, job allocation techniques considering the performance resources of mobile devices have been studied. Note, however, that there is a problem of job reallocation due to continuous battery consumption, since the studies consider only the performance resources of mobile devices at the time of job allocation or take into account the performance resources and remaining battery power only. This paper proposes the job allocation mechanism (JAM) for battery consumption minimization of cyber-physical-social big data processing in MCC, which continuously reflects the battery consumption rate to process jobs with mobile devices only without an external cloud server in a collaborative architecture-based MCC environment. JAM allocates jobs considering the periodic measurement of battery consumption and surplus resource to minimize the problem of job reallocation due to battery rundown of the mobile devices. This paper designs and implements a system for verifying JAM and demonstrated that the job processing speed increased in an MCC environment for cyber-physical-social big data.",data oriented architecture,309
6904341803304d39eaa86f7634e1a3501a02139b,filtered,semantic_scholar,,2018-01-01,semantic_scholar,architecture for the strategy-planning techniques using big data analytics,https://www.semanticscholar.org/paper/6904341803304d39eaa86f7634e1a3501a02139b,"The rapid growth in technology and market has posed a throat-cut competition among the service providers. Retaining of existing customers in place of catching new one is 90% cheaper, but it needs to know the customer very well, which is possible by analyzing the customer data. To analyze customer data and provide customer-oriented services, this paper recommends an architecture for the development of techniques which would further be able to design strategies, such as tariff plan, on the basis of available information from the customer relationship management system of any service-based company, which is finally known as customer-oriented data product. This architecture has five phases with data source, data collection, data refinement, analysis of collected data, and generation of data product. This paper summarizes the requirement of data sets and systems to develop strategy-planning techniques with the study of available architectures in the big data and CRM environment.",data oriented architecture,310
5dcda12a9c710f1c2c9af617208d40f2b2812cd0,filtered,semantic_scholar,,2017-01-01,semantic_scholar,big data in building information modeling research survey and exploratory text mining,https://www.semanticscholar.org/paper/5dcda12a9c710f1c2c9af617208d40f2b2812cd0,It has been argued that Building Information Modeling BIM can transform the landscape of Architecture Engineering and Construction AEC and Facility Management FM industries with its potential to reduce cost project delivery time and increase productivity Going beyond traditional Computer Aided Design CAD BIM has emerged as a data rich object oriented shared digital representation of a facility that can serve as a reliable basis for decision making across the entire life cycle of a construction project Simultaneous advancements in big data analytics storage as well as information visualization seem to hold the potential to enable truly n dimensional BIMs integrated with other data intensive sources such as Geographic Information Systems GIS Building Automation Systems BAS Energy Management Systems EMS etc A number of recently published articles in the literature seem to indicate that the AEC industry can significantly benefit from big data analytics and architecture and make data driven decisions considering the volume and variety of information resulting from BIM integration approaches This paper presents a concise survey of recently published articles highlighting the big data based BIM challenges as well as some exploratory text analysis using bag of words text mining a Natural Language Processing NLP technique,data oriented architecture,311
36c42a044f4946c3004ac9e853b9f0976cc95607,filtered,semantic_scholar,WorldCIST,2017-01-01,semantic_scholar,a service-oriented architecture for bioinformatics: an application in cell image analysis,https://www.semanticscholar.org/paper/36c42a044f4946c3004ac9e853b9f0976cc95607,"The advance technology in microscopy and computing has allowed the development of cell image analysis. Cloud Computing offers services, software and computing infrastructure to manage cell images’ big data. However the usability of these platforms is adequate to expert users only. Many software tools are oriented to expert users in image processing, likewise the use of bioinformatics require a basic knowledge in programming. In this paper we present a framework to develop a software solution with a Service-Oriented Architecture (SOA) applied to the analysis of cell images using cloud computing.",data oriented architecture,312
0a21d179c04a6cb6e1d6a4144c651b3009e9ae8f,filtered,semantic_scholar,IEEE Vehicular Technology Magazine,2020-01-01,semantic_scholar,beyond 5g: big data processing for better spectrum utilization,https://www.semanticscholar.org/paper/0a21d179c04a6cb6e1d6a4144c651b3009e9ae8f,"This article emphasizes the great potential of big data processing for advanced user- and situationoriented, context-aware resource utilization in future wireless networks. In particular, we consider the application of dedicated, detailed, and rich-in-content maps and records called radio-service maps (RSMs) for unlocking the spectrum opportunities in 6G networks. Due to the characteristics of 5G, in the future, there will be a need for high convergence of various types of wireless networks, such as cellular and Internet of Things (IoT) networks, which are steadily growing and consequently considered as the studied use case in this article. We show that the 6G network significantly benefits from effective dynamic spectrum management (DSM) based on RSMs that provide rich and accurate knowledge of the radio context, a knowledge that is stored and processed within database-oriented subsystems designed to support wireless networks for improving spectral efficiency. In this article, we discuss contextaware RSM subsystem architecture and operation for DSM in convergent 6G radio and IoT networks. By providing various use cases, we demonstrate that accurate definition of and access to the rich context information leads to a significant improvement of system performance. As a consequence, we also claim that efficient big data processing algorithms will be necessary in future applications.",data oriented architecture,313
a4628a0a05e84b4a4358d60c748663f9e369c9de,filtered,semantic_scholar,ER,2019-01-01,semantic_scholar,requirements-driven visualizations for big data analytics: a model-driven approach,https://www.semanticscholar.org/paper/a4628a0a05e84b4a4358d60c748663f9e369c9de,"Choosing the right Visualization techniques is critical in Big Data Analytics. However, decision makers are not experts on visualization and they face up with enormous difficulties in doing so. There are currently many different (i) Big Data sources and also (ii) many different visual analytics to be chosen. Every visualization technique is not valid for every Big Data source and is not adequate for every context. In order to tackle this problem, we propose an approach, based on the Model Driven Architecture (MDA) to facilitate the selection of the right visual analytics to non-expert users. The approach is based on three different models: (i) a requirements model based on goal-oriented modeling for representing information requirements, (ii) a data representation model for representing data which will be connected to visualizations and, (iii) a visualization model for representing visualization details regardless of their implementation technology. Together with these models, a set of transformations allow us to semi-automatically obtain the corresponding implementation avoiding the intervention of the non-expert users. In this way, the great advantage of our proposal is that users no longer need to focus on the characteristics of the visualization, but rather, they focus on their information requirements and obtain the visualization that is better suited for their needs. We show the applicability of our proposal through a case study focused on a tax collection organization from a real project developed by the Spin-off company Lucentia Lab.",data oriented architecture,314
b88ca237521336c26e42521005a1d36b50a3d38f,filtered,semantic_scholar,ENASE,2019-01-01,semantic_scholar,multiple perspectives of digital enterprise architecture,https://www.semanticscholar.org/paper/b88ca237521336c26e42521005a1d36b50a3d38f,"Enterprises are transforming their strategy, culture, processes, and their information systems to enlarge their Digitalization efforts or to approach for digital leadership. The Digital Transformation profoundly disrupts existing enterprises and economies. In current times, a lot of new business opportunities appeared using the potential of the Internet and related digital technologies: The Internet of Things, Services Computing, Cloud Computing, Artificial Intelligence, Big Data with Analytics, Mobile Systems, Collaboration Networks, and Cyber-Physical Systems. Digitization fosters the development of IT environments with many rather small and distributed structures, like the Internet of Things, Microservices, or other micro-granular elements. Architecting micro-granular structures have a substantial impact on architecting digital services and products. The change from a closed-world modeling perspective to more flexible Open World of living software and system architectures defines the context for flexible and evolutionary software approaches, which are essential to enable the Digital Transformation. In this paper, we are revealing multiple perspectives of digital enterprise architecture and decisions to effectively support value and service-oriented software systems for intelligent digital services and products.",data oriented architecture,315
d05656b8bca0c50e0866f912eef237313271f7f7,filtered,semantic_scholar,2015 IEEE International Conference on Big Data (Big Data),2015-01-01,semantic_scholar,earth science data fusion with event building approach,https://www.semanticscholar.org/paper/d05656b8bca0c50e0866f912eef237313271f7f7,"Objectives of the NASA Information And Data System (NAIADS) project are to develop a prototype of a conceptually new middleware framework to modernize and significantly improve efficiency of the Earth Science data fusion, big data processing and analytics. The key components of the NAIADS include: Service Oriented Architecture (SOA) multi-lingual framework, multi-sensor coincident data Predictor, fast into-memory data Staging, multi-sensor data-Event Builder, complete data-Event streaming (a workflow with minimized IO), on-line data processing control and analytics services. The NAIADS project is leveraging CLARA framework, developed in Jefferson Lab, and integrated with the ZeroMQ messaging library. The science services are prototyped and incorporated into the system. Merging the SCIAMACHY Level-1 observations and MODIS/Terra Level-2 (Clouds and Aerosols) data products, and ECMWF re-analysis will be used for NAIADS demonstration and performance tests in compute Cloud and Cluster environments.",data oriented architecture,316
4c9c01fd4e1a65e17df74925ad9cc324f7843e9f,filtered,semantic_scholar,J. Intell. Manuf.,2017-01-01,semantic_scholar,holonic and multi-agent technologies for service and computing oriented manufacturing,https://www.semanticscholar.org/paper/4c9c01fd4e1a65e17df74925ad9cc324f7843e9f,"This special feature aims at shedding light on new emerging holonic and multi-agent systems operating in a service-and computing oriented manufacturing environment, using the latest ICT technologies such as service-orientation, mobile agents, Web-and Cloud services, virtualization, big data and analytics to name a few. Industrials are seeking for models and solutions that are not only able to provide efficient overall production performance, but also to face reactively a growing set of unpredicted events. The demand for large scale industrial systems running in complex and even chaotic environments requires the consideration of new paradigms and technologies that provide flexibility, robustness, agility and responsiveness. Holonic systems are, actually by definition, targeting challenges that include coping with the heterogeneous nature of manufacturing systems and their on-line interactive nature in combination with competitive pressures. Multi-agent systems is a suitable implementing approach to address these challenge by offering an alternative way to design control systems, based on the decentralization of control functions over distributed autonomous and cooperative entities. Moreover, virtualization of manufacturing execution system workloads offers a set of design and operational advantages to enterprises, the most visible being improved resource utilization and flexibility of the overall solution. At the manufacturing execution system level, cloud computing adoption refers mainly to virtualization of MES workloads. While MES implementations are different and usually depend directly on the actual physical shop floor layout, the general MES functions are aligned with the set of functions defined by ISA-95.03 specification. To achieve high levels of productivity growth and agility to market changes, manufacturers will need to leverage Big Data sets to drive efficiency across the networked enterprise. There is need for a framework allowing the development of manufacturing cyber physical systems that include capabilities for complex event processing and Big Data analytics, which are expected to move the manufacturing domain closer to digital transformation and cloud services within the contextual enterprise. On the other hand, service orientation is emerging at multiple organizational levels in enterprise business, and leverages technology in response to the growing need for greater business integration, flexibility and agility of manufacturing enterprises. Close related to IT infrastructures of Web Services, the Service Oriented Enterprise Architecture represents a technical architecture, a business modelling concept, an integration source and a new way of viewing units of control within the enterprise. Business and process information systems integration and interoperability are feasible by considering the customized product as ""active controller"" of the enterprise resources – thus providing consistency between material and informational flows. The areas of Service Oriented Computing and Multi-agent Systems are getting closer, both trying to deal with the same kind of environments formed by loose-coupled, flexible, persistent and distributed tasks. An example is the new approach of Service Oriented Multi-agent Systems (SoMAS).",data oriented architecture,317
64c5a749ff57f35356d1066661c34ba68785a172,filtered,semantic_scholar,Communications in Computer and Information Science,2018-01-01,semantic_scholar,multi-domain and sub-role oriented software architecture for managing scientific big data,https://www.semanticscholar.org/paper/64c5a749ff57f35356d1066661c34ba68785a172,"The existing Scientific Data Management Systems (SDMSs) usually focus on a single domain and the interaction pattern of each subsystem is complex. What’s more, the heterogeneity and multi-source of Scientific Big Data (SBD), resulting in a wide variety of databases, scientific devices and functional areas, make the incompatibility and conflict between system modules inevitable. In this context, the paper focuses on the design and technology requirements of a multi-domain and sub-role oriented software architecture. Through integrating multiple databases, third-party systems and related tools, this architecture realizes both the storage and the sharing of multi-domain and multi-type SBD. Particularly, this architecture is divided into four independent functional areas and corresponding roles are designed, which enhances the decoupling and extensibility of the architecture. In addition, this paper has a formal description of the partition design from the perspective of role. On this basis, this paper also shows the typical application scenarios under different roles. The rationality and comprehensiveness of the proposed architecture are proved by describing the architectures design and technology.",data oriented architecture,318
88bb6767030f6f72760211db08a269138278ce24,filtered,semantic_scholar,2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA),2017-01-01,semantic_scholar,prospects and potential application of cloud drilling,https://www.semanticscholar.org/paper/88bb6767030f6f72760211db08a269138278ce24,"Cloud computing technology changes the world, and creates new solutions and opportunities to the enterprises, including petroleum engineering companies. In order to solve more complex drilling problems and optimize oil-field services process control system, the impediments to existing drilling system were analyzed. New technologies, such as cloud computing, cloud manufacturing, internet of things (IoT), big data have been used to solve the complex problems. We propose a unique service-oriented drilling system called Cloud Drilling for petroleum engineering and oil-field services, based on these new technologies. This paper will present the concept of Cloud Drilling and the characteristics of Cloud Drilling system. The architecture and key technology points will be also presented. Finally, we will discuss future prospects of Cloud Drilling and its application potential.",data oriented architecture,319
9c4e430a843a0c30a1184803d690f7ed21bfd228,filtered,semantic_scholar,2015 International Conference and Workshop on Computing and Communication (IEMCON),2015-01-01,semantic_scholar,"formalizing big data processing lifecycles: acquisition, serialization, aggregation, analysis, mining, knowledge representation, and information dissemination",https://www.semanticscholar.org/paper/9c4e430a843a0c30a1184803d690f7ed21bfd228,"In today's e-Business environment, ERP, CRM, collaboration tools, and networked sensors may be characterized as data generators resources. Business Intelligence (BI) is a term that incorporates a range of analytical and decision support applications in business including data mining, decision support systems, knowledge management systems, and online analytical processing; processing data within these systems produce new data that are characterized to grow rapidly causing limitation problem of data management if handled by a Relational Database Management System (RDBMS) or statistical tools. Collectively these structured and unstructured data are referred to as Big Data. Successful and efficient handling of Big Data requires deployment of specific IT infrastructure components as well as adopting an emerging service model. In this research we introduce a conceptual model that abstracts the processing scheme of big data processing lifecycle. The model addresses the main phases of the lifecycle: data acquisition, data serialization, data aggregation, data analysis, data mining, knowledge representation, and information dissemination. The model is driven by projecting Service Oriented Architecture attributes to the building block of the lifecycle and adhering to the Lifecycle Modeling Language specification.",data oriented architecture,320
8f5f4802080c838ec1bcf395f0e5480d1d327a50,filtered,semantic_scholar,,2015-01-01,semantic_scholar,soa enabled elta: approach in designing business intelligence solutions in era of big data,https://www.semanticscholar.org/paper/8f5f4802080c838ec1bcf395f0e5480d1d327a50,"The current work presents a new approach for designing business intelligence solutions. In the Era of Big Data, former and robust analytical concepts and utilities need to adapt themselves to the changed market circumstances. The main focus of this work is to address the acceleration of building process of a ""data-centric"" Business Intelligence (BI) solution besides preparing BI solutions for Big Data utilization. This research addresses the following goals: reducing the time spent during business intelligence solution's design phase; achieving flexibility of BI solution by adding new data sources; and preparing BI solution for utilizing Big Data concepts. This research proposes an extension of the existing Extract, Load and Transform (ELT) approach to the new one Extract, Load, Transform and Analyze (ELTA) supported by service-orientation concept. Additionally, the proposed model incorporates Service-Oriented Architecture concept as a mediator for the transformation phase. On one side, such incorporation brings flexibility to the BI solution and on the other side; it reduces the complexity of the whole system by moving some responsibilities to external authorities.",data oriented architecture,321
28b0a6c933e33f5cba484c43e09210fe8f8b7d09,filtered,semantic_scholar,I-ESA,2018-01-01,semantic_scholar,toward information system architecture to support predictive maintenance approach,https://www.semanticscholar.org/paper/28b0a6c933e33f5cba484c43e09210fe8f8b7d09,"The prognostic and health management (PHM) approach aims at supporting maintenance operations in order to ensure the functionality of a system. In order to achieve this objective, a PHM approach is composed of a prognostic component, able to send a prognostic of failure, and a component able to give the health status of the system. Nowadays, this approach suffers from a lack of exploitation of the emerging technologies. This article presents a novel architecture for PHM approach able to extract added value from data. This lambda architecture embeds two layers: a speed layer and a storage layer. Thanks to the storage layer, maintenance rules can be applied as well as the result of machine learning algorithms to the speed layer in order to realize the prognostic aspect of the PHM. In addition, the system has to deal with heterogeneous data, which comes with the necessity to handle the big data issues as well as making it interoperable. This is achieved thanks to a service-oriented architecture approach and the use of complex event processing.",data oriented architecture,322
8ee544932422fab1774db86f60a4840843ae0ffb,filtered,semantic_scholar,2013 IEEE Seventh International Symposium on Service-Oriented System Engineering,2013-01-01,semantic_scholar,performance and reliability effects of multi-tier bidding on mapreduce in auction-based clouds,https://www.semanticscholar.org/paper/8ee544932422fab1774db86f60a4840843ae0ffb,"Hadoop has become a central big data processing framework in today's cloud environments. Ensuring the good performance and cost effectiveness of Hadoop is crucial for the numerous applications that rely on it. In this paper we analyze Hadoop's performance in a multi-tier market-oriented cloud infrastructure known as Spot Instances. Amazon Spot Instances (SIs) are designed to deliver a cheap but transient alternative to fixed cost On-Demand (ODIs) instances. Recently, AWS introduced SIs in their managed Elastic Map Reduce offering. This managed framework lets the users design a multi-tier Hadoop architecture using fine grained controls to define the instance types both in terms of capacity, i.e. compute/storage/network, but also in terms of costs, i.e. ODI vs SI. The performance effects of such fine grained configurations are not yet well understood. First, we analyze a set of cluster configurations that can lead to important performance effects that can affect both the running time and the cost of such cloud Hadoop clusters. Second, we examine Hadoop's fault tolerance mechanisms and show the inadequacy of these mechanisms for multi-tier bidding architectures. Third, we discuss directions for making the Hadoop framework more market-aware without losing its focus on extreme scalability.",data oriented architecture,323
f723b71864734944abefeb2775b3fc3baf179a90,filtered,semantic_scholar,,2012-01-01,semantic_scholar,my cray can do that ? supporting diverse workloads on the cray xe-6,https://www.semanticscholar.org/paper/f723b71864734944abefeb2775b3fc3baf179a90,"The Cray XE architecture has been optimized to support tightly coupled MPI applications, but there is an increasing need to run more diverse workloads in the scientific and technical computing domains. These needs are being driven by trends such as the increasing need to process “Big Data”. In the scientific arena, this is exemplified by the need to analyze data from instruments ranging from sequencers, telescopes, and X-ray light sources. These workloads are typically throughput oriented and often involve complex task dependencies. Can platforms like the Cray XE line play a role here? In this paper, we will describe tools we have developed to support high-throughput workloads and data intensive applications on NERSC’s Hopper system. These tools include a custom task farmer framework, tools to create virtual private clusters on the Cray, and using Cray’s Cluster Compatibility Mode (CCM) to support more diverse workloads. In addition, we will describe our experience with running Hadoop, a popular open-source implementation of MapReduce, on Cray systems. We will present our experiences with this work including successes and challenges. Finally, we will discuss future directions and how the Cray platforms could be further enhanced to support these class of workloads.",data oriented architecture,324
06c6044e1a36b767142c846b3cf264b3faf810de,filtered,semantic_scholar,ACM Trans. Internet Techn.,2019-01-01,semantic_scholar,bpms-ra,https://www.semanticscholar.org/paper/06c6044e1a36b767142c846b3cf264b3faf810de,"A growing number of business process management systems is under development both in academia and in practice. These systems typically are based on modern system engineering principles, such as service-oriented architecture. At the same time, the advent of big data analytics has changed the scope of these systems, including functionality such as data mining. However, existing reference architectures for business process management systems date back 20 years and, consequently, are not up-to-date with these modern developments. To fill the gap, this article proposes an up-to-date reference architecture, called BPMS-RA, for modern business process management systems. BPMS-RA is based on analysis of recent literature and of existing commercial implementations. This reference architecture aims to provide a guideline template for the development of modern-day business process management systems by specifying functions and interfaces that need to be provided by these systems as well as a set of quality criteria that they need to meet.",data oriented architecture,325
759923f35e855fd8ba7214bd67cb07cf4cae6baa,filtered,semantic_scholar,IEEE Transactions on Network Science and Engineering,2020-01-01,semantic_scholar,cognitive popularity based ai service sharing for software-defined information-centric networks,https://www.semanticscholar.org/paper/759923f35e855fd8ba7214bd67cb07cf4cae6baa,"As an important architecture of next-generation network, Software-Defined Information-Centric Networking (SD-ICN) enables flexible and fast content sharing in beyond the fifth-generation (B5G). The clear advantages of SD-ICN in fast and efficient content distribution and flexible control make it a perfect platform for solving the rapid sharing and cognitive caching of AI services, including data samples sharing and pre-trained models transferring. With the explosive growth of decentralized artificial intelligence (AI) services, the training and sharing efficiency of edge AI is affected. Various applications usually request the same AI samples and training models, but the efficient and cognitive sharing of AI services remain unsolved. To address these issues, we propose a cognitive popularity-based AI service distribution architecture based on SD-ICN. First, an SD-ICN enabled edge training scheme is proposed to generate accurate AI service models over decentralized big data samples. Second, Pure Birth Process (PBP) and error correction-based AI service caching and distribution schemes are proposed, which provides user request-oriented cognitive popularity model for caching and distribution optimization. Simulation results indicate the superiority of the proposed architecture, and the proposed cognitive SD-ICN scheme has 62.11% improved to the conventional methods.",data oriented architecture,326
4cfc5046350211da9e0781d9a0778611b311d6de,filtered,semantic_scholar,ICFNDS,2017-01-01,semantic_scholar,iot mashups: from iot big data to iot big service,https://www.semanticscholar.org/paper/4cfc5046350211da9e0781d9a0778611b311d6de,"Internet of Things (IoT) addresses the challenge to provide a transparent access to a huge number of IoT resources that can be either physical devices or just data resources. Moreover, because of the large number of resource-constrained devices and the dynamic nature of IoT environments, integrating the resulted data becomes a non trivial task. We believe that the use of mashups, a way to compose new services from existing ones, can be a solution to the above challenge if each resource exposes its functionalities as a Web service. In the IoT environment, this will constitute a Web of Things where mashups development will take advantage of the connected physical world. The huge amounts of IoT-generated data from physical devices and data sources, called IoT Big Data, requires new design solutions to speed up data processing, scale up with the data volume and improve data adaptability. Besides existing techniques for IoT data collection, filtering, and analytics, we present in this article a mashup oriented model, called IoT Big Services, for provisioning data-centric IoT services in the context of IOT mashups. These IoT services are organized in tree structure where each node, called an IoT Big Service, acts as an integrator that collects data from lower level, processes them and delivers the results to higher level in the architecture.",data oriented architecture,327
972a4df01203f246b7c28a031a69ab1eff70887e,filtered,semantic_scholar,2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC),2016-01-01,semantic_scholar,using object-oriented big data analytics to reveal server performance dead zone,https://www.semanticscholar.org/paper/972a4df01203f246b7c28a031a69ab1eff70887e,"So far, big data analytics have proved worth by reaping fruitful achievements in business intelligence, health care and so on, which aims to reveal efficiently hidden and unique information from pre-existing large datasets. Therefore, big data analytics are sprouting in almost all areas, expecting to find new values from musty archives or continuous wave of newly generated data. This paper introduces how we utilize big data technologies to establish an object-oriented analytic architecture for IT operations, which evolves from traditional and coarse statistics into fine-grained and in-depth analysis. Moreover, this paper demonstrates applying the architecture to peek inside practical problem of the server performance dead zone. The peering process consists of applying various analysis models iteratively on large set of server logs. Our work can be considered as an attempt to exploit how object-oriented big data analytic benefits IT system operations and optimization.",data oriented architecture,328
400a9c04bca46f0355d6b88b451ccbf05e0ae0f7,filtered,semantic_scholar,HEART,2017-01-01,semantic_scholar,dataflow based near data computing achieves excellent energy efficiency,https://www.semanticscholar.org/paper/400a9c04bca46f0355d6b88b451ccbf05e0ae0f7,"The emergence of 3D-DRAM has rekindled interest in near data computing (NDC) research. This article introduces dataflow processing in memory (DFPIM) which melds near data computing, dataflow architecture, coarse-grained reconfigurable logic (CGRL), and 3D-DRAM technologies to provide high performance and very high energy efficiency for stream oriented and big data application kernels. The application of dataflow architecture with a CGRL implementation provides a flexible, energy efficient computing platform. The initial evaluation presented in this paper shows an average speedup of 5.5 is achieved with an energy efficiency factor of 460.",data oriented architecture,329
45f717f571bc1d477191e107264db33cf9dde7c7,filtered,semantic_scholar,WAIM Workshops,2013-01-01,semantic_scholar,a cloud computation architecture for unconventional emergency management,https://www.semanticscholar.org/paper/45f717f571bc1d477191e107264db33cf9dde7c7,"With the development of technologies and the deterioration of natural environment, unconventional emergencies outbreak more unexpectedly and diffuse more quickly and broadly. Secondary and derived disasters increase, and the impacts tend to be indirect and tremendous. Emergency management decisions are facing great challenges, and have attracted great concerns from government departments, academia and industries. In recent years, as a service-oriented computing mode, the cloud computing technology brings advantage in information sharing, resource allocating, and distributed high-performance computing, which makes it a feasible solution to unconventional emergency management, research, quick response and decision support. In this paper, we propose a cloud computation architecture for unconventional emergency management, which involves the key technologies including computation resource pooling, scalable extension of computation resource and services and user-centroid service management. The proposed architecture supports multilevel demand in computation and storage resource by providing services such as virtual machine, big data storage, web information detection and spatio-temporal data visualization. Three experimental scenarios are designed to validate the improvement of decision support capabilities and emergency response speed.",data oriented architecture,330
3a25bab8c44fdd12fd921657df4d051e85ca9217,filtered,semantic_scholar,Sustainability,2021-01-01,semantic_scholar,sustainable smart cities: convergence of artificial intelligence and blockchain,https://www.semanticscholar.org/paper/3a25bab8c44fdd12fd921657df4d051e85ca9217,"Recently, 6G-enabled Internet of Things (IoT) is gaining attention and addressing various challenges of real time application. The artificial intelligence plays a significant role for big data analytics and presents accurate data analysis in real time. However, designing big data analysis through artificial intelligence faces some issues in terms of security, privacy, training data, and centralized architecture. In this article, blockchain-based IoT framework with artificial intelligence is proposed which presents the integration of artificial intelligence and blockchain for IoT applications. The performance of the proposed architecture is evaluated in terms of qualitative and quantitative measurement. For qualitative measurement, how the integration of blockchain and artificial intelligence addresses various issues are described with the description of AI oriented BC and BC oriented AI. The performance evaluation of proposed AI-BC architecture is evaluated and compared with existing techniques in qualitative measurement. The experimental analysis shows that the proposed framework performs better in comparison with the existing state of art techniques.",data oriented architecture,331
886c398deebeaaa148ff227b9f8aa5cfcdc52241,filtered,semantic_scholar,J. Intell. Manuf.,2021-01-01,semantic_scholar,designing and developing smart production planning and control systems in the industry 4.0 era: a methodology and case study,https://www.semanticscholar.org/paper/886c398deebeaaa148ff227b9f8aa5cfcdc52241,"In furtherance of emerging research within smart production planning and control (PPC), this paper prescribes a methodology for the design and development of a smart PPC system. A smart PPC system uses emerging technologies such as the internet of things, big-data analytics tools and machine learning running on the cloud or on edge devices to enhance performance of PPC processes. It achieves this by using a wider range of data sources from the production system, capturing and utilizing the experience of production planners, using analytics and machine learning to harness insights from the data and allowing dynamic and near real-time action to the continuously changing production system. The proposed methodology is illustrated with a case study in a sweets and snacks manufacturing company, to highlight the key considerations and challenges production managers might face during its application. The case further demonstrates considerations for scalability and flexibility via a loosely coupled, service-oriented architecture and the selection of fitting algorithms respectively to address a business requirement for a short-term, multi-criteria and event-driven production planning and control solution. Finally, the paper further discusses the challenges of PPC in smart manufacturing and the importance of fitting smart technologies to planning environment characteristics.",data oriented architecture,332
5ddb53a44fc9dc2cfd018e4478c31353f5b1aaff,filtered,semantic_scholar,,2015-01-01,semantic_scholar,novel dynamic and scalable storage management architecture,https://www.semanticscholar.org/paper/5ddb53a44fc9dc2cfd018e4478c31353f5b1aaff,"In the current scenario, storage management of Big Data is imposing concern for Grid Computing environments, as a large scale distributed computation System which can resolve the problem of resource sharing. In traditional approach there is high-performance computing machine consisting of dedicated servers that are used to store data storage and resource discovery. In this paper, It is proposed to be an architecture Novel Dynamic and Scalable Storage Management Architecture for Big Data Management. This allows the grid oriented storage machine to share the resource and storage space. It has a retention period to resource discovery whenever data is communicating with the virtual storage.",data oriented architecture,333
9ded38d29a6f4dfa5357cdb061b3772823ecf322,filtered,semantic_scholar,Journal of Grid Computing,2018-01-01,semantic_scholar,big data-oriented paas architecture with disk-as-a-resource capability and container-based virtualization,https://www.semanticscholar.org/paper/9ded38d29a6f4dfa5357cdb061b3772823ecf322,"With the increasing adoption of Big Data technologies as basic tools for the ongoing Digital Transformation, there is a high demand for data-intensive applications. In order to efficiently execute such applications, it is vital that cloud providers change the way hardware infrastructure resources are managed to improve their performance. However, the increasing use of virtualization technologies to achieve an efficient usage of infrastructure resources continuously widens the gap between applications and the underlying hardware, thus decreasing resource efficiency for the end user. Moreover, this scenario is especially troublesome for Big Data applications, as storage resources are one of the most heavily virtualized, thus imposing a significant overhead for large-scale data processing. This paper proposes a novel PaaS architecture specifically oriented for Big Data where the scheduler offers disks as resources alongside the more common CPU and memory resources, looking forward to provide a better storage solution for the user. Furthermore, virtualization overheads are reduced to the bare minimum by replacing heavy hypervisor-based technologies with operating-system-level virtualization based on light software containers. This architecture has been deployed on a Big Data infrastructure at the CESGA supercomputing center, used as a testbed to compare its performance with OpenStack, a popular private cloud platform. Results have shown significant performance improvements, reducing the execution time of representative Big Data workloads by up to 4.5×.",data oriented architecture,334
ffecead4be7deb3b7fbe82488c77a9e89a51b117,filtered,semantic_scholar,2015 IEEE 11th International Conference on e-Science,2015-01-01,semantic_scholar,enhanced usability of managing workflows in an industrial data gateway,https://www.semanticscholar.org/paper/ffecead4be7deb3b7fbe82488c77a9e89a51b117,"The Grid and Cloud User Support Environment (gUSE) enables users convenient and easy access to grid and cloud infrastructures by providing a general purpose, workflow-oriented graphical user interface to create and run workflows on various Distributed Computing Infrastructures (DCIs). Its arrangements for creating and modifying existing workflows are, however, non-intuitive and cumbersome due to the technologies and architecture employed by gUSE. In this paper, we outline the first integrated web-based workflow editor for gUSE with the aim of improving the user experience for those with industrial data workflows and the wider gUSE community. We report initial assessments of the editor's utility based on users' feedback. We argue that combining access to diverse scalable resources with improved workflow creation tools is important for all big data applications and research infrastructures.",data oriented architecture,335
78de7a5498144cae54ab3024654507c5b1ece5ac,filtered,semantic_scholar,Int. J. Electron. Bus. Manag.,2016-01-01,semantic_scholar,big data collections and services for building intelligent transport applications,https://www.semanticscholar.org/paper/78de7a5498144cae54ab3024654507c5b1ece5ac,This paper presents an approach for building data collections and cloud services required for building intelligent transport applications. Services implement Big Data analytics functions that can bring new insights and useful correlations of large data collections and provide knowledge for managing transport issues. Applying data analytics to transport systems brings better understanding to the transport networks revealing unexpected choking points in cities. This facility is still largely inaccessible to small companies and citizens due to their limited access to computational resources. A cloud service oriented architecture opens new perspectives for democratizing the use of efficient and personalized big data management and analytics.,data oriented architecture,336
cb863b418911f1025d798a9de5bacfc4a5ea384b,filtered,semantic_scholar,,2015-01-01,semantic_scholar,caemon: cloud access execution and monitoring for big data analytics of sensor system,https://www.semanticscholar.org/paper/cb863b418911f1025d798a9de5bacfc4a5ea384b,"This paper aims to implement an intelligent architectural system to analyze and access the sensor data using Big Data analytics. As cloud resources enable the Wireless Sensor Networks to store and analyze their vast amount of data, Sensor Cloud is designed using Service Oriented Sensor Architecture. Sensor Cloud acts as an enabler for big sensor Data analytics. In the current application these three become the compelling combination. It is proposed to use the Hadoop Distributed File Systems (HDFS) concept to store the streaming sensor data on to sensor cloud for further analysis using MapReduce technique. This paper describes a public sensor cloud delivery model through cloud data analytics for sensor services. The proposed architecture acts as a Cloud Access Execution and Monitoring environment for sensor systems and is able to respond to the requested sensor client applications with greater intelligence.",data oriented architecture,337
70b81a624fc4732e03a427e3b1936afcad7ca1c9,filtered,semantic_scholar,16th International Conference on Advanced Communication Technology,2014-01-01,semantic_scholar,"balancing scalability, performance and fault tolerance for structured data (bspf)",https://www.semanticscholar.org/paper/70b81a624fc4732e03a427e3b1936afcad7ca1c9,"Analytical business applications generate reports that give a trend predicting insight into the organization's future, estimating the financial graphs and risk factors. These applications work on huge amounts of data, which comprises of decades of market and company records, and decision logs of an organization. Today, limit of big data is touching zeta-bytes and the structured data makes only 20% of today's data. 20% of a giga-byte can be ignorable in comparison to big data but 20% of big data itself cannot be neglected. Traditional data management tools are like step-dads when it comes to running cross table analytical queries on structured data in distributed processing environment; response time to these data management tools are high because of the ill-aligned data sets and complex hierarchy of distributed computing environment. Data alignment requires a complete shift in data deployment paradigm from row oriented storage layout to column oriented storage layout, and complex hierarchy of distributed computing environment can be handled by keeping metadata of entire data set. Paper proposes an approach to ease the deployment of structured data into the distributed processing environment by arranging data into column-wise combinational entities. Response time to analytical queries can be lowered with the support of two concepts; Shared architecture and Multi path query execution. Highly scalable systems are Shared Nothing architecture based but degradation in performance and fault tolerance are the side effects that came with high scalability. Proposed method is an effort to balance the equation between scalability, performance and fault tolerance. And due to the limited scope of this paper we concentrate on issues and solutions for structured data only. Shared architecture and active backup helps improving the system's performance by sharing the work-load-per-node. BSPF's clustering methodology sheds the data pressure points to minimize the data loss per node crash.",data oriented architecture,338
3f8636f8685944cc4b6b88d568e50ee9e524099a,filtered,semantic_scholar,International Journal of Innovative Technology and Exploring Engineering,2019-01-01,semantic_scholar,big data architectures: a detailed and application oriented analysis,https://www.semanticscholar.org/paper/3f8636f8685944cc4b6b88d568e50ee9e524099a,"Big Data refers to huge amounts of heterogeneous data from both traditional and new sources, growing at a higher rate than ever. Due to their high heterogeneity, it is a challenge to build systems to centrally process and analyze efficiently such data which are internal and external to organizations. A Big data architecture describes the blueprint of a system handling massive volume of data during its storage, processing, analysis and visualization. Several architectures belonging to different categories have been proposed by academia and industry but the field is still lacking benchmarks. Therefore, a detailed analysis of the characteristics of the existing architectures is required in order to ease the choice between architectures for specific use cases or industry requirements. The types of data sources, the hardware requirements, the maximum tolerable latency, the fitment to industry, the amount of data to be handled are some of the factors that need to be considered carefully before making the choice of an architecture of a Big Data system. However, the wrong choice of architecture can result in huge decline for a company reputation and business. This paper reviews the most prominent existing Big Data architectures, their advantages and shortcomings, their hardware requirements, their open source and proprietary software requirements and some of their realworld use cases catering to each industry. The purpose of this body of work is to equip Big Data architects with the necessary resources to make better informed choices to design optimal Big Data systems.",data oriented architecture,339
7f3cd3fe2c75c3816f5fca0ac61caca5122c06cc,filtered,semantic_scholar,2016 5th International Conference on Multimedia Computing and Systems (ICMCS),2016-01-01,semantic_scholar,a multi-agent based on ant colony model for urban traffic management,https://www.semanticscholar.org/paper/7f3cd3fe2c75c3816f5fca0ac61caca5122c06cc,"This paper presents a conception model of a distributed algorithm as a heuristic (meta-heuristic) method inspired from the ant colony system which consists on exploiting pheromone information to find the shortest path from the food source to the nest, in order to optimize the urban traffic through a graph by orienting vehicles to make the best decision to choose the optimal road and to favor the fluency of the urban traffic. For this purpose, multi-agent system architecture will be proposed using embedded agents which aim to interconnect the various objects influencing the urban traffic. This interaction comprises an exchange of many informations and big data coming from many different devices existing in the real world. For this reason, the place of internet of things (IoT) technology is assured in our paper therefore will be discussed.",data oriented architecture,340
e3e7d1b50614fea583e90bd31e013e24c359319b,filtered,semantic_scholar,2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops,2013-01-01,semantic_scholar,foreword by soea4ee organizers -- service oriented enterprise architecture for enterprise engineering,https://www.semanticscholar.org/paper/e3e7d1b50614fea583e90bd31e013e24c359319b,"The goal of the workshop is to develop concepts and methods to assist the engineering and management of service oriented enterprise architectures and the software systems supporting them. Especially four themes of research have been pursued: 1. Alignment of the enterprise goals and strategies with the service-oriented enterprise architecture; 2. Design of the service-oriented enterprise architecture; 3. Mapping of service-oriented enterprise architecture to enterprise resources; 4. SoEA and Cloud-Computing; influence of cloud, social and big data.",data oriented architecture,341
abe96d6250409eaa4906436143dd90b32e426ce2,filtered,semantic_scholar,,2017-01-01,semantic_scholar,proposed architecture of mongodb-hive integration,https://www.semanticscholar.org/paper/abe96d6250409eaa4906436143dd90b32e426ce2,"There is tremendous growth in heterogeneous and unstructured data in last few years. Various NoSQL databases have been developed to store and query this humongous data. MongoDB is prevailing document oriented database among NoSQL databases. MongoDB has been chosen among other technologies because of its ability to work with variety of latest as well as conventional technologies. It provides drivers for almost every development language. This paper summarizes work of various authors who have compared and integrated MongoDB with other big data technologies. In most cases, MongoDB gives better performance in terms of various parameters. Further, after carrying out critical analysis , an architecture is being proposed to integrate MongoDB with Hive. It utilizes the SQL like features of Hive for SQL familiar users.",data oriented architecture,342
d175637c387b0399cb49fe4ec077c7b43213408d,filtered,semantic_scholar,,2018-01-01,semantic_scholar,apply uncertainty in document-oriented database (mongodb) using f-xml,https://www.semanticscholar.org/paper/d175637c387b0399cb49fe4ec077c7b43213408d,"As moving to big data world where data is increasing in unstructured way with high velocity, there is a need of data-store to store this bundle amount of data. Traditionally, relational databases are used which are now not compatible to handle this large amount of data, so it is needed to move on to non-relational data-stores. In the current study, we have proposed an extension of the MongoDB architecture to support FMQL by integrating a software layer on MongoDB translating FMQL queries to corresponding F-XML queries. Flexible queries have been done in the oriented-document database (MongoDB) by using fuzzy xml commands in the document-centric (MongoDB) injected uncertainty and expressed this commands based on F-XML and by using uncertainty. We used the fuzzy properties to improve query in the document-oriented database (MongoDB) and we showed the Position of the proposed method by the implementation and evaluation of a case study.",data oriented architecture,343
9faf9029981a0b92abdb983a60f2af96eca3aea2,filtered,semantic_scholar,IEEE Access,2020-01-01,semantic_scholar,"video big data analytics in the cloud: a reference architecture, survey, opportunities, and open research issues",https://www.semanticscholar.org/paper/9faf9029981a0b92abdb983a60f2af96eca3aea2,"The proliferation of multimedia devices over the Internet of Things (IoT) generates an unprecedented amount of data. Consequently, the world has stepped into the era of big data. Recently, on the rise of distributed computing technologies, video big data analytics in the cloud has attracted the attention of researchers and practitioners. The current technology and market trends demand an efficient framework for video big data analytics. However, the current work is too limited to provide a complete survey of recent research work on video big data analytics in the cloud, including the management and analysis of a large amount of video data, the challenges, opportunities, and promising research directions. To serve this purpose, we present this study, which conducts a broad overview of the state-of-the-art literature on video big data analytics in the cloud. It also aims to bridge the gap among large-scale video analytics challenges, big data solutions, and cloud computing. In this study, we clarify the basic nomenclatures that govern the video analytics domain and the characteristics of video big data while establishing its relationship with cloud computing. We propose a service-oriented layered reference architecture for intelligent video big data analytics in the cloud. Then, a comprehensive and keen review has been conducted to examine cutting-edge research trends in video big data analytics. Finally, we identify and articulate several open research issues and challenges, which have been raised by the deployment of big data technologies in the cloud for video big data analytics. To the best of our knowledge, this is the first study that presents the generalized view of the video big data analytics in the cloud. This paper provides the research studies and technologies advancing the video analyses in the era of big data and cloud computing.",data oriented architecture,344
113187c70da0fd3e992ec7de815135405ed6f7c6,filtered,semantic_scholar,CyberGIS for Geospatial Discovery and Innovation,2018-01-01,semantic_scholar,a smart service-oriented cybergis framework for solving data-intensive geospatial problems,https://www.semanticscholar.org/paper/113187c70da0fd3e992ec7de815135405ed6f7c6,"This chapter introduces a CyberGIS solution that aims at resolving the big data challenges in the discovery, search, visualization and interoperability of geospatial data. We describe a service-oriented architecture to make heterogeneous geospatial resources easily sharable and interoperable. OGC standards for sharing vector data, raster data, sensor observation data etc. are adopted in such an infrastructure because of their widespread popularity in the GIScience community. Three supporting techniques include: (1) a novel method that combines real-time Web crawling and meta-cataloging in support of quick identification and discovery of distributed geospatial services; (2) an ontology-enabled semantic search framework to enhance the relevancy search and ranking; (3) multi-dimensional visualization of diverse interrelated dataset for discovering underlying patterns and decision-making. Finally, we introduce two applications: Landsat Image Service Archive (LISA) and the ESIP (Earth Science Information Partnership) Semantic Web Testbed to demonstrate the applicability of proposed techniques in various Earth Science domains.",data oriented architecture,345
a86626dd3a8440a2d8248df6d1bf1286ae18a44e,filtered,semantic_scholar,IoTBDS,2019-01-01,semantic_scholar,sose4bd: service-oriented software engineering framework for big data applications,https://www.semanticscholar.org/paper/a86626dd3a8440a2d8248df6d1bf1286ae18a44e,"Service computing has emerged to address the notion of delivering software as a service and Service-Oriented Architecture emerged as a design method supporting well defined design principles of loose coupling, interface design, autonomic computing, seamless integration, and publish/subscribe paradigm. Integrated big data applications with IoT, Fog, and Cloud Computing grow exponentially: businesses as well as the speed of the data and its storage. Therefore, it is time to consider systematic and engineering approach to developing and deploying big data services as the data-driven applications and devices increasing rapidly. This paper proposes a software engineering framework and a reference architecture which is SOA based for big data applications’ development. This paper also concludes with a simulation of a complex big data Facebook application with real-time streaming using part of the requirements engineering aspect of the SOSE4BD framework with BPMN as a tool for requirement modelling and simulation to study the characteristics before big data service design, development, and deployment. The simulation results demonstrated the efficiency and effectiveness of developing big data applications using the reference architecture framework for big data.",data oriented architecture,346
3cc24a6f2ef92b4cad65b043986d95150c3a9b3a,filtered,semantic_scholar,Architecting the Digital Transformation,2021-01-01,semantic_scholar,architecting digital products and services,https://www.semanticscholar.org/paper/3cc24a6f2ef92b4cad65b043986d95150c3a9b3a,"Enterprises are currently transforming their strategy, processes, and their information systems to extend their degree of digitalization. The potential of the Internet and related digital technologies, like Internet of Things, services computing, cloud computing, artificial intelligence, big data with analytics, mobile systems, collaboration networks, and cyber physical systems both drives and enables new business designs. Digitalization deeply disrupts existing businesses, technologies and economies and fosters the architecture of digital environments with many rather small and distributed structures. This has a strong impact for new value producing opportunities and architecting digital services and products guiding their design through exploiting a Service-Dominant Logic. The main result of the book chapter extends methods for integral digital strategies with value-oriented models for digital products and services which are defined in the framework of a multi-perspective digital enterprise architecture reference model.",data oriented architecture,347
56f2a6aceb199553ce4bc1d4d5b98594c6fe044f,filtered,semantic_scholar,2017 IEEE International Congress on Big Data (BigData Congress),2017-01-01,semantic_scholar,scmat: a mechanism presuming scms to efficiently enable both olap and oltp,https://www.semanticscholar.org/paper/56f2a6aceb199553ce4bc1d4d5b98594c6fe044f,"Many commercial DBMSs based on a column-oriented storage method have been used to analyze large-scale data. However, the column-oriented DBMS is difficult to use for processing big-data analysis updated in real time, because the column-oriented storage performs inefficient OLTP when processing row-oriented updates. Therefore, we attempted to enable the column-oriented DBMS to efficiently process OLTP for performing big data analysis. In this paper, we propose a DBMS architecture by focusing on storage class memory (SCM) such as STT-MRAM, PRAM, and ReRAM of new storage devices used in future computing. Our approach assumed that SCMs have not yet been considered, we propose a TiD-based update index for modifying the column data using SCMs in real time. Moreover, the DBMS mechanism we consider is able to identify a row of the column data such that we efficiently use a materialization method for aggregation in OLAP in which users perform a similar OLAP query for data analysis.",data oriented architecture,348
37a50b24962d9b211973b3233c6ef91a6223c467,filtered,semantic_scholar,2013 IEEE 16th International Conference on Computational Science and Engineering,2013-01-01,semantic_scholar,research and implementation of mapreduce programming oriented graphical modeling system,https://www.semanticscholar.org/paper/37a50b24962d9b211973b3233c6ef91a6223c467,"Along with the beginning of the big data era, it becomes difficult to capture, store, search, share, transfer, analyze, and visualize bigger data using the traditional data processing applications. Therefore, the problem is very rigid for many larger companies and research institutes that how to correctly and efficiently extract useful information from the massive data. MapReduce is a programming model developed by Google for processing and generating large data sets in distributed environments. Hadoop, an open-source project, is used to implement Google MapReduce architecture which is wildly used by many large companies. However, it is difficult to program map-reduce functions for common users to solve real world problems because of the rigid pattern of the framework. In this paper, we develop a graphic platform to help ordinary users in creating MapReduce application by dragging encapsulated components. We are particularly concerned with simplifying development and increasing efficiency.",data oriented architecture,349
0dda959d8e17115a71a0c0c1d6a31c3d0715207b,filtered,semantic_scholar,2014 International Symposium on Computer Architecture and High Performance Computing Workshop,2014-01-01,semantic_scholar,watershed reengineering: making streams programmable,https://www.semanticscholar.org/paper/0dda959d8e17115a71a0c0c1d6a31c3d0715207b,"Most high-performance data processing (aka big-data) systems allow users to express their computation using abstractions (like map-reduce) that simplify the extraction of parallelism from applications. Most frameworks, however, do not allow users to specify how communication must take place: that element is deeply embedded into the run-time system (RTS), making changes hard to implement. In this work we describe our reengineering of the Watershed system, a framework based on the filter-stream paradigm and focused on continuous stream processing. Like other big-data environments, watershed provided object-oriented abstractions to express computation (filters), but the implementation of streams was an RTS element. By isolating stream functionality into appropriate classes, combination of communication patterns and reuse of common message handling functions (like compression and blocking) become possible. The new architecture even allow the design of new communication patterns, for example, allowing users to choose MPI, TCP or shared memory implementations of communication channels as their problem demand. Applications designed for the new interface showed reductions in code size on the order of 50%and above in some cases, with no significant performance penalty.",data oriented architecture,350
b1055951fa3125de946ca386b740e98f895389ec,filtered,semantic_scholar,2018 1st IEEE International Conference on Knowledge Innovation and Invention (ICKII),2018-01-01,semantic_scholar,a comparative study of machine learning techniques for real-time multi-tier sentiment analysis,https://www.semanticscholar.org/paper/b1055951fa3125de946ca386b740e98f895389ec,"Nowadays, Big Data, both structured and unstructured data, are generated from Social Media. Social Media are powerful marketing tools and social big data require real-time tracking and analytics because the speed may indeed be the most important competitive business profits. Compared to batch processing of Sentiment Analysis on Big Data Analytics platform, Real-time analytic is data intensive in nature and require to efficiently collect and process large volume and high velocity of data. Real-time multiclass Sentiment Analysis is oriented towards classification of text into more detailed sentiment labels in real-time manner. But Multiclass Sentiment Analysis with Single-tier architecture where single classification model is developed and entire labeled data is trained may decrease the classification accuracy. In this paper, Real-time Multi-tier Sentiment Analysis system (RMSA) is proposed to achieve high level performance of multi-class classification in Real-time manner. Lexicon and learning based classification scheme with Multi-tier architecture are combined to develop the proposed system. Real-time twitter stream data is collected by apache flume and, large volumes and high velocity of social data is efficiently analyzed by Spark. To improve the classification accuracy, the suitable classifier is selected by comparing the accuracy of three different learning based multiclass classification techniques: Naïve Bayes, Linear SVC and Logistic Regression. The evaluation results show that Real-time Multi-tier Sentiment Analysis will achieve the promising accuracy and Linear SVC is better than other techniques for Real-time Multi-tier Sentiment Analysis.",data oriented architecture,351
9307d51aa5b02f3ef7e72334476f9a35f179e191,filtered,semantic_scholar,,2016-01-01,semantic_scholar,big data empowered logistics services platform,https://www.semanticscholar.org/paper/9307d51aa5b02f3ef7e72334476f9a35f179e191,"Logistics section is one of the most important industrial sections to contribute to European economy. To improving efficiency and energy efficient of logistics, European Commission call new research theme ‘smart, green and integrated transport' in its H2020 program. The paper presents a version on providing a cloud based platform for supporting big data empowered logistics services to respond this call. The research is supported by inter-disciplinary approaches, which brings experts from telecommunication, cloud computing, sensor networking, service-oriented computing, data analysis, transportation, and logistics areas to work together to provide real-world solutions for future logistics. The research questions and challenges of the platform are highlighted. Overall architecture and data collection are presented.",data oriented architecture,352
5c4da82d61b08e94a26d39ed43820e35fa10b871,filtered,semantic_scholar,,2016-01-01,semantic_scholar,týr: efficient transactional storage for data-intensive applications,https://www.semanticscholar.org/paper/5c4da82d61b08e94a26d39ed43820e35fa10b871,"As the computational power used by large-scale applications increases, the amount of data they need to manipulate tends to increase as well. A wide range of such applications requires robust and flexible storage support for atomic, durable and concurrent transactions. Historically, databases have provided the de facto solution to transactional data management, but they have forced applications to drop control over data layout and access mechanisms, while remaining unable to meet the scale requirements of Big Data. More recently, key-value stores have been introduced to address these issues. However, this solution does not provide transactions, or only restricted transaction support, compelling users to carefully coordinate access to data in order to avoid race conditions, partial writes, overwrites, and other hard problems that cause erratic behaviour. We argue there is a gap between existing storage solutions and application requirements that limits the design of transaction-oriented data-intensive applications. In this paper we introduce Tyr, a massively parallel distributed transactional blob storage system. A key feature behind Tyr is its novel multi-versioning management designed to keep the metadata overhead as low as possible while still allowing fast queries or updates and preserving transaction semantics. Its share-nothing architecture ensures minimal contention and provides low latency for large numbers of concurrent requests. Tyr is the first blob storage system to provide sequential consistency and high throughput, while enabling unforeseen transaction support. Experiments with a real-life application from the CERN LHC show Tyr throughput outperforming state-of-the-art solutions by more than 100%.",data oriented architecture,353
b5207811f13b37582d241b6668e5699cdf534bd9,filtered,semantic_scholar,"2021 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS)",2021-01-01,semantic_scholar,architecture design of application oriented undergraduate innovation and entrepreneurship guidance service platform based on big data technology,https://www.semanticscholar.org/paper/b5207811f13b37582d241b6668e5699cdf534bd9,"A large number of homogeneous university innovation and entrepreneurship information platform construction is facing low utilization rate, which cannot support the activities and sustainable development of teachers and students. Therefore, based on the development situation of big data era, this paper establishes an innovation and entrepreneurship guidance service platform based on B/S architecture for the guidance service of innovation and entrepreneurship education system in application-oriented universities. The scheme mainly uses the advanced J2EE environment, and combined with big data to build a new model of innovation and entrepreneurship education system in application-oriented university. We also design and implement the key modules of the system combined with data sharing and Internet technology. The development process involves the storage application of Servlet, JavaBean, JSP, JavaScript and SQL technology. The system operation test results prove the feasibility of the scheme, which can effectively play the role of big data and improve the entrepreneurship rate of college graduates.",data oriented architecture,354
b3658a24133408e9282e98795500f3314d8a8077,filtered,semantic_scholar,,2014-01-01,semantic_scholar,apache karaf cookbook,https://www.semanticscholar.org/paper/b3658a24133408e9282e98795500f3314d8a8077,"Over 60 recipes to help you get the most out of your Apache Karaf deployments About This BookLeverage Apache Karaf to apply OSGi's powerful features to frameworks such as Apache ActiveMQ, Camel, Cassandra, CXF, and HadoopSet up Apache Karaf for high availabilityA thorough guide with example-based recipes to help you get a deeper understanding of Apache Karaf's capabilitiesWho This Book Is ForThis book is intended for developers who have some familiarity with Apache Karaf and who want a quick reference for practical, proven tips on how to perform common tasks such as configuring Pax modules deployed in Apache Karaf, Extending HttpService with Apache Karaf.You should have working knowledge of Apache karaf, as the book provides a deeper understanding of the capabilities of Apache Karaf. In Detail Apache Karaf is more than just an OSGi-based runtime container; it's an ecosystem of open source technologies that makes operating and managing applications easier.This book starts by covering how to make your deployment more production ready, and then covers many of the most popular Service Oriented Architecture projects that you can integrate into Karaf these are some of the most sought after developer skills in modern enterprises. The book also delves into transforming Karaf into a JSP host, distributing containers using Apache Karaf Cellar, and providing persistence to your applications. Finally, you'll explore the world of Big Data with Apache Cassandra and Hadoop, setting the stage for your Karaf deployment to handle today's large datasets.",data oriented architecture,355
164cb6e6f9ea74ceffa0b6f1493db2d9eddd1dc1,filtered,semantic_scholar,,2015-01-01,semantic_scholar,big data applications,https://www.semanticscholar.org/paper/164cb6e6f9ea74ceffa0b6f1493db2d9eddd1dc1,"The sustainability of huge and ever-growing data pools using different formats that cannot be processed with traditional software tools is the next big challenge for web designers, Internet marketers, and software engineers and requires new technologies and practices. One of the approaches to cope with Big Data is to use Semantic Web technologies, especially machine-interpretable metadata and Linked Data. Implementing the Resource Description Framework (RDF) and RDF-based standards ensures that data and its meaning are encapsulated, and concepts and relationships can be managed while connecting diverse data from various data sources. Graph representations, such as Facebook’s Open Graph, add context to and visualize Big Data for data analysis. The Service-Oriented Architecture (SOA) infrastructure over Big Data makes it possible to update Big Data in real time. Data can be automatically classified, relationships associated, and new relationships found, so that data can be collected and integrated without worrying about schemas and data descriptions, yet providing a data description. Big Data applications on the Semantic Web include, but are not limited to, next-generation Search Engine Result Pages, social media graphs, analysis of natural language content, publishing factual data about massive world events, interlinking BBC’s online content, as well as high-performance data storage and processing.",data oriented architecture,356
1711c2c6a8e476b124c6c25cd83b87650e4e9e81,filtered,semantic_scholar,,2016-01-01,semantic_scholar,systems theory based architecture framework for complex system governance,https://www.semanticscholar.org/paper/1711c2c6a8e476b124c6c25cd83b87650e4e9e81,"SYSTEMS THEORY BASED ARCHITECTURE FRAMEWORK FOR COMPLEX SYSTEM GOVERNANCE Bry Carter Old Dominion University, 2016 Director: Dr. Charles B. Keating The purpose of this research was to develop a systems theory based framework for complex system governance using grounded theory approach. Motivation for this research includes: 1) the lack of research that identifies modeling characteristics for complex system governance, 2) the lack of a framework rooted in systems theory to support performance of complex system governance functions for maintaining system viability. This research focused on answering: What systems theoretic framework can be developed to inform complex system governance and enable articulation of governance function performance? The grounded theory research approach utilized three phases. First, the literature in systems theory, management cybernetics, governance and enterprise architecture was synthesized and open-coded to generalize main themes using broad analysis in NVivo software, researcher note taking in EndNote, and cataloging in Excel spreadsheets. Second, the literature underwent axial-coding to identify interconnections and relevance to systems theory and complex system governance, primarily using Excel spreadsheets. Finally, selective coding and interrelationships were identified and the complex system governance architecture framework was shaped, reviewed, and validated by qualified experts. This research examined a grounded theory approach not traditionally used in systems theory research. It produced a useful systems theory based framework for practical application, bridging the gap between theory and practice in the emerging field of complex system governance. Theoretical implications of this research include identifying the state of knowledge in each literature domain and the production of a unique framework for performing metasystem governance functions that is analytically generalizable. Management cybernetics, governance, and systems theory are expanded through a testable tool for meta-level organizational and system governance theories. Enterprise architecture is advanced with a multi-disciplinary framework that coherently presents and facilitates new use for architecture at the metasystem level. Methodological implications of this research include using grounded theory approach for systems theory research, where it is atypical. Although a non-traditional method, it provides an example for conducting fruitful research that can contribute knowledge. Practical implications of this research include a useable framework for complex system governance which has never before existed and a living structure adaptable to evolutionary change coming from any related domain or future practical application feedback. Copyright, 2016, by Bry Carter, All Rights Reserved. iv This dissertation is dedicated to Esmeralda and Alexandra. -Together Foreverv ACKNOWLEDGMENTS I am most grateful to Dr. Charles B. Keating, my Advisor, for opening the aperture of my worldview in systems thinking and inspiring me to be part of a Learning Community on the leading edges of complex system governance. Thank you Dr. Mamadou D. Seck, Dr. Teddy Cotter, and Dr. James C. Pyne for your academic partnership and oversight as research committee members. Thank you Dr. Kim Sibson for your time and effort conducting editing review. Thank you Learning Community members for your professional partnership and critical peer reviews of this research and related briefings, journal articles, and book chapter material. I look forward to continuing the journey with you. Many cast doubt on the potential for return on investment in time and resources required to pursue this endeavor of independent scholarly research, but never once was there a shred of doubt expressed by my devoted wife or loving daughter despite the many competing challenges we faced together along the way. Esmeralda and Alexandra, thank you. vi NOMENCLATURE ADP Architecture Development Process AF-EAF Air Force Enterprise Architecture Framework AFIoT IEEE P2413 – Architecture Framework for the Internet of Things AGA Australian Government Architecture Reference Models AGATE Atelier de Gestion de l’ArchiTecturE des Systèmes d’Information et de Communication AM Avancier Methods ARCHI ArchiMate AUSDAF Australian Defence Architecture Framework AAF Automotive Architecture Framework ATO Australian Taxation Office BCA Business Capability Architecture BDAF Big Data Architecture Framework BEAM Business Enterprise Architecture Modeling BPEAM Best Practice Enterprise Architecture Management CAFCR Customer Objectives, Application, Functional, Conceptual, and Realisation Model CAFEA Common Approach to Federal Enterprise Architecture CBDI-SAE CBDI Service Architecture & Engineering (CBDI-SAETM) for SOA CEA CEA Framework: A Service Oriented Enterprise Architecture Framework CEAF Commission Enterprise IT Architecture Framework CIAF Capgemini Integrated Architecture Framework vii CSG Complex System Governance CSGAF Complex System Governance Architecture Framework DoDAF Department of Defense Architecture Framework DND/CF Canadian Department of National Defense and the Canadian Forces DNDAF DN/CF Architecture Framework DRA1 Dragon 1 DYA Dynamic Architecture EA Enterprise Architecture EAB Enterprise Architecture Blueprinting E2AF Extended Enterprise Architecture Framework EAM-PC EAM Pattern Catalog EAP Enterprise Architecture Design Principles EEAF US OMB Enterprise Architecture Assessment Framework EES Extended Enterprise Systems EPCAF EPC Global Architecture Framework ESAAF European Space Agency Architecture Framework ESG Enterprise Systems Governance ESSAF Essential Architecture Framework eTOM Business Process Framework EXAF Extreme Architecture Framework FEAF Federal Enterprise Architecture Framework FESS Framework of Enterprise Systems and Structures viii FFLV+GODS Functions-Flows-Layers-Views + Governance-OperationsDevelopment-Support FMLS-ADF FMLS Architecture Description Framework 3.0 FSAM Federal Segment Architecture Methodology GA Garland and Anthony GEAF Gartner’s Enterprise Architecture Framework GERA ISO 15704 Generic Enterprise Reference Architecture HEAF Health Enterprise Architecture Framework HV Human View (NATO) IADS IBM Architecture Description Standard IAF Index Architecture Framework ICODE iCode Security Architecture Framework IFW IBM Information Framework 3D EAF 3-Dimensional Enterprise Architecture Framework 4+1 Kruchten’s 4+1 View Model LEAD Leading Enterprise Architecture Development Practice LST Living Systems Theory MACCIS An Architecture Description Framework for Technical Infostructures and their Enterprise Environment MCS Minimal Critical Specifications MBSA Model Based System Architecture MEGAF Mega-modeling Architecture Framework MODAF Ministry of Defense Architecture Framework ix MP Metasystem Pathology MV Metasystem Viewpoint NAF NATO Architecture Framework NIST-EAM NIST Enterprise Architecture Model OIO OIO Enterprise Architecture Method PEAF Pragmatic Enterprise Architecture PPOOA Processes Pipeline in Object Oriented Architectures PRINCE2 Projects In Controlled Environments PRISM Partnership for Research in Information Systems Management QGEA Queensland Government Enterprise Architecture RASDS Reference Architecture for Space Data Systems RM-ODP ISO Reference Model for Open Distributed Processing RWSSA Rozanski and Woods S4V Siemens 4 Views SABSA Sherwood Applied Business Security Architecture SASSY Self-Architecting Software Systems SDLC System Development Life Cycle SGCAF Smart Grid Conceptual Architecture Framework SoS System of Systems ST Systems Theory TEAF (US) Treasury Enterprise Architecture Framework TOGAF The Open Group Architecture Framework TRAK The Rail Architecture Framework x UADF Universal Architecture Description Framework VCD Value Chain Diagram VSM Viable System Model WFM Work Flow Model xAF Extensible Architecture Framework ZAF Zachman Framework xi TABLE OF CONTENTS LIST OF TABLES ...................................................................................................................... xiii LIST OF FIGURES ....................................................................................................................... xv Chapter I INTRODUCTION ...................................................................................................................... 1 Problem Statement and Background ............................................................................................ 1 Research Question ....................................................................................................................... 9 Research Purpose ......................................................................................................................... 9 Research Delimitations .............................................................................................................. 10 Research Significance ................................................................................................................ 11 Research Limitations ................................................................................................................. 12 Dissertation Structure ................................................................................................................ 14 Chapter Summary ...................................................................................................................... 15 II LITERATURE REVIEW ........................................................................................................ 16 Literature Domain Reviews and Critique .................................................................................. 17 Chapter Summary ...................................................................................................................... 45 III RESEARCH PERSPECTIVE ..................................................................",data oriented architecture,357
bdff8b28cac27d9c0f14e3e4934c822c18d902bb,filtered,semantic_scholar,2016 IEEE International Conference on Big Data (Big Data),2016-01-01,semantic_scholar,big data availability: selective partial checkpointing for in-memory database queries,https://www.semanticscholar.org/paper/bdff8b28cac27d9c0f14e3e4934c822c18d902bb,"Fault tolerance is an important challenge for supporting critical big data analytic operations. Most existing solutions only provide fault tolerant data replication, requiring failed queries to be restarted. This approach is insufficient for long-running time-sensitive analytic queries, due to lost query progress. Several solutions provide intra-query fault tolerance. However, these focus on distributed or row-oriented databases and are not suitable for use with the column-oriented in-memory databases increasingly used for highperformance workloads. We propose a new approach for intra-query checkpointing that produces an optimal checkpoint solution for a fixed checkpointing budget to minimise overhead on in-memory column-oriented database clusters. We describe a modified architecture for fault tolerant query execution using this approach. We present a general model for the problem, in which an adversary is free to terminate the execution of the query, eliminating all unsaved work. We present an algorithm that represents a first step towards producing checkpoint plans by optimally placing a single checkpoint. Our analysis shows this approach allows reduced checkpoint overheads while providing resilience for long-running queries.",data oriented architecture,358
9d9e31992c2df67ac7229141340b5ea19b0981c0,filtered,semantic_scholar,KMO,2016-01-01,semantic_scholar,future prospects for knowledge management in the field of health,https://www.semanticscholar.org/paper/9d9e31992c2df67ac7229141340b5ea19b0981c0,"The health care systems in the western democracies face today problems that relate to the implementation systems in the field of health policies. Knowledge management is important since it is the prerequisite for planning and implementing more intelligent health policies and practices. Updated conceptualization of knowledge management theory is a precondition for successful health care reform in modern welfare states. This paper is conceptual and theoretically oriented paper. The purpose of this article is to define key drivers of new knowledge management theory and use the health care service system as a case example. Nonaka's classical spiral of knowledge (and SECI model with knowledge dimensions) is a foundation for thinking on the future developments of knowledge management. What Nonaka's ""dynamic ba"" actually includes, is a key question and a big challenge. In this paper, we have outlined a concrete proposal for this critical concept. Key issues of ""dynamic ba"" will be Big Data management (and associated skills), new crowdsourcing techniques, new forms of customer behaviour, systemic KM integration (service needs, service design and orchestration, service architecture, and service science) and the on-going 3rd wave of digitalization (Internet of Things and robotics).",data oriented architecture,359
fb88d54d14d03884c0dd2aa94628d8e6c69e5322,filtered,semantic_scholar,ISAT,2016-01-01,semantic_scholar,information systems architecture and technology: proceedings of 37th international conference on information systems architecture and technology - isat 2016 - part ii,https://www.semanticscholar.org/paper/fb88d54d14d03884c0dd2aa94628d8e6c69e5322,"This four volume set of books constitutes the proceedings of the 36th International Conference Information Systems Architecture and Technology 2015, or ISAT 2015 for short, held on September 20 22, 2015 in Karpacz, Poland. The conference was organized by the Computer Science and Management Systems Departments, Faculty of Computer Science and Management, Wroclaw University of Technology, Poland. The papers included in the proceedings have been subject to a thorough review process by highly qualified peer reviewers. The accepted papers have been grouped into four parts: Part I addressing topics including, but not limited to, systems analysis and modeling, methods for managing complex planning environment and insights from Big Data research projects. Part II discoursing about topics including, but not limited to, Web systems, computer networks, distributed computing, and multi-agent systems and Internet of Things. Part III discussing topics including, but not limited to, mobile and Service Oriented Architecture systems, high performance computing, cloud computing, knowledge discovery, data mining and knowledge based management. Part IV dealing with topics including, but not limited to, finance, logistics and market problems, and artificial intelligence methods",data oriented architecture,360
0e58e4214353fe3721a849a2eed593c4e4ec0a33,filtered,semantic_scholar,ICCBR,2017-01-01,semantic_scholar,building an integrated cbr-big data oriented architecture for case-based reasoning systems,https://www.semanticscholar.org/paper/0e58e4214353fe3721a849a2eed593c4e4ec0a33,"The growth of intensive data-driven decision-making is now being recognized broadly. Big data systems are mainstream and the demand for building systems that able to process data streams is growing. Yet many decision support systems act like ”black boxes”, providing little or no transparency in the rationale of their processes [1]. The ”black box” methodologies are not acceptable in crucial domains like health care, aviation, and maintenance. Experts prefer to reason the decisions. Current big data strategies tend to process in-motion data and o↵er many potential scenarios to work with. The big data term refers to dynamic, large, structured and unstructured volumes of data generated from di↵erent sources with di↵erent formats [2]. Therefore, it is a must for CBR systems that tends to process the in-motion data to manage their sub-tasks, such as collecting and formatting data, case base maintenance, cases retrieval, cases adaptation and retaining new cases [3]. In my research I will describe the idea of spanning the gap between CBR and Big Data based on the SEASALT architecture [4] [5]. SEASALT is an application independent architecture to work with heterogeneous data repositories and modularizing knowledge. It was proposed based on the CoMES approach to develop collaborative multi-expert systems and provides an application-independent architecture that features knowledge acquisition from a Web community, knowledge modularization, and agent-based knowledge maintenance. Its first research prototype was developed for the travel medicine application [4]. SEASALT aims to provide a coherent multi-agent CBR architecture that can define the outlines and interactions to develop multi-agent CBR systems.",data oriented architecture,361
994d85bae14925d0dd1a1b1518bfff86450782eb,filtered,semantic_scholar,2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT,2020-01-01,semantic_scholar,decisional support system with artificial intelligence oriented on health prediction using a wearable device and big data,https://www.semanticscholar.org/paper/994d85bae14925d0dd1a1b1518bfff86450782eb,"The proposed work describes a decision support system (DSS) based on artificial intelligence algorithms and health wearable sensors predicting health status. The discussion is mainly focused on the description of the innovative architecture of the prototype platform related to a research industry project. The platform is able to control different wearable sensors storing data into a Cassandra Big Data system. Support Vector machine (SVM) and Long Short Term Memory (LSTM) algorithms have been applied to experimental datasets, proving the basic function of physiological data prediction. The work is suitable for the implementation of multi-dimensional risk map of health status.",data oriented architecture,362
89ad27e3a948ae947bd09caa40bdeb9a183f5b66,filtered,semantic_scholar,DASFAA Workshops,2017-01-01,semantic_scholar,an online prediction framework for dynamic service-generated qos big data,https://www.semanticscholar.org/paper/89ad27e3a948ae947bd09caa40bdeb9a183f5b66,"With the prevalence of service computing, cloud computing, and Internet of Things (IoT), various service compositions are emerging on the Internet based on Service-Oriented Architecture (SOA). To evaluate the performance attribute of these service compositions, dynamic Quality of Service (QoS) data are generated abundantly, named service-generated QoS Big Data. Selecting optimal services to build high quality SOA systems can be based on these data. However, a mass of service-generated QoS data are unknown and it is become a challenge to predict these data. In this paper, we present a framework for service-generated QoS big data prediction, named DSPMF. Under this framework, we present an optimization objective function and employ online stochastic gradient descent algorithm to solve this function. Extensive experiments are conducted to verify the effectiveness and efficiency of our proposed approach.",data oriented architecture,363
eac7bafb44a15f8c8e2ac62fde153dc6dc68ee4e,filtered,semantic_scholar,Inf. Syst. Frontiers,2014-01-01,semantic_scholar,dynamic intelligence towards merging cloud and communication services,https://www.semanticscholar.org/paper/eac7bafb44a15f8c8e2ac62fde153dc6dc68ee4e,"The ever-growing next generation Cloud and Communication Services (CCS) provide dynamic intelligence and play an increasingly critical role in all aspects of our lives. Following ubiquitous computing, sensors, e-tags, networking, big data, wireless communications and cloud services is a road towards a smart world created on both cyberspaces and real spaces. “Cloud” is a common metaphor for an Internet accessible infrastructure (e.g. data storage and computing hardware), which is hidden from users. Cloud computing makes data truly mobile and a user can simply access a chosen cloud with any Internet accessible device. In Cloud Computing, IT-related capabilities are provided as services, accessible without requiring detailed knowledge of the underlying technology. Thus, many mature technologies are used as components in Cloud computing, but still there are many unresolved and open problems. Cloud service is a new cross-discipline that covers the science and technology needed to bridge the gap between business services and IT/telecommunication services. The underneath breaking technology suite includes web services and service-oriented architecture (SOA), cloud computing, business consulting methodology and utilities, business process modeling, transformation and integration. The goal of cloud and services computing is to develop new computing technology and thereby enable more advanced IT/ telecommunication services to support business services more efficiently and effectively. Today’s IT paradigm, computation and communication are embedded in the environment such that all objects can be connected and always online. This will greatly facilitate intelligent monitoring and control of different objects. On the other hand, the vision of all objects connected offers not only the potential of enable emergent applications that dynamically adapts to the environments and the contexts of their usage, but also poses a significant challenge to the collection, storage and processing of enormous amounts of data. By taking advantage of virtualized resources, cloud computing services presents an attractive means to address the challenges while realizing the potential of cloud and communication services. The CCS paradigm can be generalized to include mobile devices, which not only incorporate sophisticated methods for users to interact with the online world through numerous applications in their devices, but also are endowed with multiple sensors that enable them to contribute data as nodes in the CCS. In this context, mobile cloud services that enable widespread data collection through mobile devices, and collaborative use of mobile devices to enhance existing and realize new applications are very much of interest. It is anticipated that such mobile cloud services will enrich social networking applications, encourage the widespread adoption of crowdsourcing and crowd sensing, and facilitate ubiquitous access to multimedia entertainment contents. Integration of CCS and mobile services on the cloud is expected to efficiently enable e-health, intelligent transportation, and smart power grids, which form the basis of the future smart society. Cloud and communication services are paving the way towards a smart world in which computational intelligence is distributed throughout the physical environment to provide C.<H. Hsu (*) Department of Computer Science and Information Engineering, Chung Hua University, Hsinchu City, Taiwan e-mail: robertchh@gmail.com",data oriented architecture,364
7f31ef32e8dcff0e41b5bc6a4c54039e3e690c04,filtered,semantic_scholar,"2018 Fifth International Conference on Parallel, Distributed and Grid Computing (PDGC)",2018-01-01,semantic_scholar,big data analytics: performance evaluation for high availability and fault tolerance using mapreduce framework with hdfs,https://www.semanticscholar.org/paper/7f31ef32e8dcff0e41b5bc6a4c54039e3e690c04,"Big data analytics helps in analyzing structured data transaction and analytics programs that contain semi-structured and unstructured data. Internet clickstream data, mobile-phone call details, server logs are examples of big data. Relational database-oriented dataset doesn't fit in traditional data warehouse since big data set is updated frequently and large amount of data are generated in real time. Many open source solutions are available for handling this large scale data. The Hadoop Distributed File System (HDFS) is one of the solutions which helps in storing, managing, and analyzing big data. Hadoop has become a standard for distributed storage and computing in Big Data Analytic applications. It has the capability to manage distributed nodes for data storage and processing in distributed manner. Hadoop architecture is also known as Store everything now and decide how to process later. Challenges and issues of multi-node Hadoop cluster setup and configuration are discussed in this paper. The troubleshooting for high availability of nodes in different scenarios for Hadoop cluster failure are experimented with different sizes of datasets. Experimental analysis carried out in this paper helps to improve uses of Hadoop cluster effectively for research and analysis. It also provides suggestions for selecting size of Hadoop cluster as per data size and generation speed.",data oriented architecture,365
0942b6f9a3a0484b1a7be8a099e6ffac75f538e2,filtered,semantic_scholar,,2020-01-01,semantic_scholar,the priority of factors of building government as a platform with analytic hierarchy process analysis,https://www.semanticscholar.org/paper/0942b6f9a3a0484b1a7be8a099e6ffac75f538e2,"Nowadays, the Government as a Platform (GaaP) based on cloud computing and network, has come to be considered a new structure to manage efficiently data-driven administration in the public sector. When the GaaP concept was first introduced, the ICT infrastructures that could underpin GaaP were not sufficiently developed. However, the recent digital transformation has transformed the previous electronic government, which was system- and architecture-oriented. As part of the next generation of government models, GaaP may reinvent the government at a lower cost but with better performance, similar to the case of electronic government two decades ago. This study attempted to determine the priority of factors of GaaP by using the analytic hierarchy process (AHP) methodology. Because of the GaaP characteristics, we drew the main components for building GaaP from previous studies and a group interview with experts. The study results show that experts tend to prefer publicness in terms of building GaaP. Most of the factors that the experts weighed with the highest importance are related to the public sector, which revealed that governments should focus on their primary duty, regardless of the origin and characteristics of the platform in GaaP. However, since GaaP allows governments to be more horizontal and innovative, the platform approach can fundamentally shift the existing processes and culture of the public sector. The enhanced activity of citizens with ICT can also accelerate the introduction of GaaP. Finally, the study showed that a data-driven GaaP is necessary to efficiently handle big data, contract services, and multiple levels of on-line and off-line channels. In this public platform, government, citizens, and private sector organizations can work cooperatively as partners to seamlessly govern the hyper-connected society.",data oriented architecture,366
befda30c03cd0e69c13d0361874b29740294f219,filtered,semantic_scholar,,2019-01-01,semantic_scholar,sose 4 bd : service-oriented software engineering framework for big data applications,https://www.semanticscholar.org/paper/befda30c03cd0e69c13d0361874b29740294f219,"Service computing has emerged to address the notion of delivering software as a service and Service-Oriented Architecture emerged as a design method supporting well defined design principles of loose coupling, interface design, autonomic computing, seamless integration, and publish/subscribe paradigm. Integrated big data applications with IoT, Fog, and Cloud Computing grow exponentially: businesses as well as the speed of the data and its storage. Therefore, it is time to consider systematic and engineering approach to developing and deploying big data services as the data-driven applications and devices increasing rapidly. This paper proposes a software engineering framework and a reference architecture which is SOA based for big data applications’ development. This paper also concludes with a simulation of a complex big data Facebook application with real-time streaming using part of the requirements engineering aspect of the SOSE4BD framework with BPMN as a tool for requirement modelling and simulation to study the characteristics before big data service design, development, and deployment. The simulation results demonstrated the efficiency and effectiveness of developing big data applications using the reference architecture framework for big data.",data oriented architecture,367
0ee2f954e665c8c8fd9c1ae4b61810a9bc9d67f2,filtered,semantic_scholar,,2014-01-01,semantic_scholar,a novel web service composition and web service discovery based on map reduce algorithm,https://www.semanticscholar.org/paper/0ee2f954e665c8c8fd9c1ae4b61810a9bc9d67f2,"The paper focuses on the web service composition and web service discovery based MapReduce algorithm, which is the one of the component of the big data problem resolver tool Hadoop. Many of the IT companies are currently in the journey to Service Oriented Architecture (SOA) with web service as the standard protocol for implementation. The overwhelming popularity of web service has made a huge impact on web service repository, because of which managing it using traditional UDDI platforms has become difficult. Integrating Hadoop ecosystem with web services can provide higher QoS to the user request for web services. Web service composition and Web service discovery plays a crucial role in the management of web service. Web service discovery involves locating or finding the exact individual web services from the service registry and retrieving previously published description for new web application. Web service composition is technique to combine simple web service to satisfy the user requirement. An efficient MapReduce algorithm can help in providing better management of web services",data oriented architecture,368
03a148e2006f782adccf209d79de9fde45d5a235,filtered,semantic_scholar,Advances in Data Mining and Database Management,2021-01-01,semantic_scholar,integrated big data e-healthcare solutions to a fragmented health information system in namibia,https://www.semanticscholar.org/paper/03a148e2006f782adccf209d79de9fde45d5a235,"This chapter showcases a big data platform solution for the Namibian health sector using handheld, portable devices, mobile devices, desktops, and server systems targeted to capture patient information, keep records, monitor and process patient health status. This chapter oversees the architectural design of the system that is more oriented towards specifications of user requirements on usability of mobile devices and their applications for e-health systems. This chapter is looking ahead to the benefits that come along with good investment in the e-health, which require a very philosophical and pragmatic systematic transformation of the hardware, software, and human resources in the health sector. Sustainability of the e-health system in the future is very promising as young professionals embrace these technological advancements from the training time and can take over the system without a big IT support staff as most of them are IT literate.",data oriented architecture,369
6782131a02bc88c3a5a3a39c5d3f579da059c241,filtered,semantic_scholar,SoICT 2018,2018-01-01,semantic_scholar,overall structural system solution for supporting services and tourists management oriented on smart city in viet nam,https://www.semanticscholar.org/paper/6782131a02bc88c3a5a3a39c5d3f579da059c241,"Recently, ""Smart tourism"" has appeared as a new term to describe the application of the technological advancements that rely on sensors, big data processing technique, open data, open API, new way of connecting and exchanging between humans and machines and multi-device (such as IoT, RFID, and NFC) in tourism. When these technologies are utilized, the digital data become practical and valuable products. Besides, the mobile revolution, and specifically the role of the smartphone and its many opportunities to support travel experiences, is especially worth mentioning in this context. In addition, new management tool for the government, new business opportunities for travel agencies, as well as new experiences for tourists are created. Therefore, in this paper, a model for developing sustainable and intelligent tourism is studied and then an overall architecture model of the information system that can provide supporting services and tools for visitor management (Smart Tourism Service Centre -- STSC) is proposed for fostering the smart cities in Vietnam, in general, and Danang, in particular.",data oriented architecture,370
31dc692d87881f935918f83c44892e6dc9ee15de,filtered,semantic_scholar,Wirel. Pers. Commun.,2020-01-01,semantic_scholar,µbigmsa-microservice-based model for big data knowledge discovery: thinking beyond the monoliths,https://www.semanticscholar.org/paper/31dc692d87881f935918f83c44892e6dc9ee15de,"Enterprise thrives on software applications that are built to fulfil the core business requirements. A single business application can offer a cluster of capabilities to generate value from processing huge amount of data often termed as Big Data. The time-based requirements of these applications are satisfied frequently by applying monolithic approaches with increased complexity and less scalability. Traditional approaches for Big Data Analytics suffer from overpriced, excessive and irrelevant data transfer owing to the constricted coupling amongst computing resources and data processing logic. Service-oriented approach came into existence as a new paradigm to enable applications to be rendered as service for better flexibility and scalability. Service orientation architecture avoids monolithic style but web services, one of its major implementation encourages monolith development of software application. Thus building a scalable, robust, resilient, cost-effective and optimum solution is one of the major requirements for outsized data. New software development style Microservices offer low degree of coupling and smaller size. This work reviews the existing and prevalent approaches like monolithic architecture in this area along with their drawbacks. This work also proposes a generic microservice model µBIGMSA for handling Knowledge Discovery in Big Data. Reference applications are implemented using proposed model. The effectiveness of the proposed model is evaluated by comparing the reference application with the monolithic application using various software metrics.",data oriented architecture,371
d3911815834877ca5330481f14da7c040251308c,filtered,semantic_scholar,,2018-01-01,semantic_scholar,towards automatic generation of nosql document-oriented models,https://www.semanticscholar.org/paper/d3911815834877ca5330481f14da7c040251308c,"The growth of application architectures in all areas (e.g. Astrology, Meteorology, E-commerce, social network, etc.) has resulted in an exponential increase in data volumes, now measured in Petabytes. Managing these volumes of data has become a problem that relational databases are no longer able to handle because of the acidity properties. In response to this scaling up, new concepts have emerged such as NoSQL. In this paper, we show how to design and apply transformation rules to migrate from an SQL relational database to a Big Data solution within NoSQL. For this, we use the Model Driven Architecture (MDA) and the transformation languages like as MOF 2.0 QVT (Meta-Object Facility 2.0 Query-View-Transformation) and Acceleo which define the meta-models for the development of transformation model. The transformation rules defined in this work can generate, from the class diagram, a CQL code for creation column-oriented NoSQL database.",data oriented architecture,372
5c1f7fde3e2b4ed0f26b1d894a884140b67f55e4,filtered,semantic_scholar,,2017-01-01,semantic_scholar,some aspects of qos for high performance of service-oriented computing in load balancing cluster-based web server,https://www.semanticscholar.org/paper/5c1f7fde3e2b4ed0f26b1d894a884140b67f55e4,"Quality estimation for viability of data processing and delivering through the paradigm of service oriented computing and load balancing cluster based web server for high performance of services against extensive load of consumers is an important concern in the domain of grid and distributed computing, big data analysis and internet of things. As such, this chapter proposes a quality estimation framework considering a prototype architecture for multi service multi-functional web services deploying in load balancing cluster based Apache Tomcat web server and developing a clinical database for processing disease related queries through the architecture. The high quality of service is monitored by generating extensive load of users over the system through Mercury LoadRunner load testing tool. In this chapter, the authors will discuss the methodology to study the quality of service, recorded quality metrics against different load of users and the statistical analysis along with results to establish the feasibility, applicability and adaptability of proposed quality estimation framework. Some Aspects of QoS for High Performance of ServiceOriented Computing in Load Balancing ClusterBased Web Server",data oriented architecture,373
b54959793df1afa41a92a720b3fbba15de3e91ac,filtered,semantic_scholar,,2015-01-01,semantic_scholar,open system architecture platform for big data: an integrated emergency disaster response system architecture,https://www.semanticscholar.org/paper/b54959793df1afa41a92a720b3fbba15de3e91ac,"In situations such as emergency where urgent and active response is needed to access the case and deploy relief or support with effective service in real-time and notices drawn and effectively distributed, easy to use applications with disparate devices and wide range coverage are necessary for sharing information as well as reporting incidence based activities. Such activities may be accidents like plane crashes, train collision, road accidents, etc., natural disasters such as landslides, earthquakes, tsunamis, hurricanes, floods, volcanic eruptions etc. An integrated application is needed to accommodate different forms of reports involving the engagement of disparate devices, and hence we designed an approach of integration based on concepts of service oriented architecture and service busses with capabilities of accessing different information from disparate devices for effective analysis. In this situation, areas without telecommunication infrastructure that support internet facilities can also be hooked into the grid as well as devices without internet capabilities. We proposed an Open System Architecture Platform for Big Data: An Integrated Emergency Disaster Response System Architecture for an effective integration of applications and software systems with open standard format to help manage and made easily available disaster response systems data for easy usage by systems in an integrated manner and made available for access usage globally by software systems and publicly as well, so that other information systems can have access to the available or published data in real-time.",data oriented architecture,374
c70d482f449d192b7be3f207488b37a3706d5623,filtered,semantic_scholar,Computing,2019-01-01,semantic_scholar,bringing sql databases to key-based nosql databases: a canonical approach,https://www.semanticscholar.org/paper/c70d482f449d192b7be3f207488b37a3706d5623,"Big Data management has brought several challenges to data-centric applications, like the support to data heterogeneity, rapid data growth and huge data volume. NoSQL databases have been proposed to tackle Big Data challenges by offering horizontal scalability, schemaless data storage and high availability, among others. However, NoSQL databases do not have a standard query language, which bring on a steep learning curve for developers. On the other hand, traditional relational databases and SQL are very popular standards for storing and manipulating critical data, but they are not suitable to Big Data management. One solution for relational-based applications to move to NoSQL databases is to offer a way to access NoSQL databases through SQL instructions. Several approaches have been proposed for translating relational database schemata and operations to equivalent ones in NoSQL databases in order to improve scalability and availability. However, these approaches map relational databases only to a single NoSQL data model and, sometimes, to a specific NoSQL database product. This paper presents a canonical approach, called SQLToKeyNoSQL , that translates relational schemata as well as SQL instructions to equivalent schemata and access methods of any key-oriented NoSQL database. We present the architecture of our layer focusing on the mapping strategies as well as experiments that evaluate the benefits of our approach against some state-of-art baselines.",data oriented architecture,375
1d8376a33ce619f5b8b1b01e77d632a6bc4f116c,filtered,semantic_scholar,ISAT,2016-01-01,semantic_scholar,"information systems architecture and technology: proceedings of 36th international conference on information systems architecture and technology - isat 2015 - part ii, karpacz, poland, september 20-22, 2015",https://www.semanticscholar.org/paper/1d8376a33ce619f5b8b1b01e77d632a6bc4f116c,"This four volume set of books constitutes the proceedings of the 36th International Conference Information Systems Architecture and Technology 2015, or ISAT 2015 for short, held on September 20 22, 2015 in Karpacz, Poland. The conference was organized by the Computer Science and Management Systems Departments, Faculty of Computer Science and Management, Wroclaw University of Technology, Poland. The papers included in the proceedings have been subject to a thorough review process by highly qualified peer reviewers. The accepted papers have been grouped into four parts: Part I addressing topics including, but not limited to, systems analysis and modeling, methods for managing complex planning environment and insights from Big Data research projects. Part II discoursing about topics including, but not limited to, Web systems, computer networks, distributed computing, and multi-agent systems and Internet of Things. Part III discussing topics including, but not limited to, mobile and Service Oriented Architecture systems, high performance computing, cloud computing, knowledge discovery, data mining and knowledge based management. Part IV dealing with topics including, but not limited to, finance, logistics and market problems, and artificial intelligence methods",data oriented architecture,376
fa5de23db381ee6c9719050cd3ab6fd53a8cb2ff,filtered,semantic_scholar,Conf. Computing Frontiers,2017-01-01,semantic_scholar,selective off-loading to memory: task partitioning and mapping for pim-enabled heterogeneous systems,https://www.semanticscholar.org/paper/fa5de23db381ee6c9719050cd3ab6fd53a8cb2ff,"Processing-in-Memory (PIM) is returning as a promising solution to address the issue of memory wall as computing systems gradually step into the big data era. Researchers continually proposed various PIM architecture combined with novel memory device or 3D integration technology, but it is still a lack of universal task scheduling method in terms of the new heterogeneous platform. In this paper, we propose a formalized model to quantify the performance and energy of the PIM+CPU heterogeneous parallel system. In addition, we are the first to build a task partitioning and mapping framework to exploit different PIM engines. In this framework, an application is divided into subtasks and mapped onto appropriate execution units based on the proposed PIM-oriented Earliest-Finish-Time (PEFT) algorithm to maximize the performance gains brought by PIM. Experimental evaluations show our PIM-aware framework significantly improves the system performance compared to conventional processor architectures.",data oriented architecture,377
2f5d535d340fc7645dc03c6041cf4919341778c4,filtered,semantic_scholar,J. Syst. Control. Eng.,2019-01-01,semantic_scholar,a big data implementation of the mantis reference architecture for predictive maintenance,https://www.semanticscholar.org/paper/2f5d535d340fc7645dc03c6041cf4919341778c4,"This article presents the implementation of a reference architecture for cyber-physical systems to support condition-based maintenance of industrial assets. It also focuses on describing the data analysis approach to manage predictive maintenance of clutch-brake assets fleet over the previously defined MANTIS reference architecture. Proposals for both the architecture and data analysis implementation support working on Big Data scenarios, due to the usage of related technologies, such as Hadoop Distributed File System, Kafka or Apache Spark. The techniques are (1) root cause analysis powered by attribute-oriented induction clustering and (2) remaining useful life powered by time series forecasting. The work has been conducted in a real use case within the H2020 European project MANTIS.",data oriented architecture,378
6fa5379cb8dacbba39db3cc2aee9df709bce0645,filtered,semantic_scholar,,2020-01-01,semantic_scholar,a comprehensive overview of fog data processing and analytics for healthcare 4.0,https://www.semanticscholar.org/paper/6fa5379cb8dacbba39db3cc2aee9df709bce0645,"In recent technological era, the healthcare industry has been gaining momentum toward service-oriented facilities to the customers. The primary aim of the Healthcare 4.0 is to provide healthcare services anytime and anywhere. This is possible, as Healthcare 4.0 targets integration with current technologies like Internet of Things (IoT), Cloud Computing, Big Data, and Machine Learning. However, the integration of Healthcare 4.0, with IoT and cloud computing through Internet has several challenges in handling real-time applications such as access latency, cost, and lack of service availability. On the other hand, the fog computing (FC) is able to overcome these challenges using fog devices, that are capable of optimizing the delay in information gathering and processing. The primary advantage of the fog computing system is the geographical location of fog devices within proximity of patient and IoT healthcare systems. This enables fog computing system to perform computation, storage and networking services with lesser delay and jitter. However, the major issue in fog computing is to handle the voluminous healthcare data generate from different IoT healthcare edge systems. Hence, this chapter targets to present on various fog-based data processing and data analysis (FDPA) mechanisms in fog computing solutions toward achieving the objectives of Healthcare 4.0. This chapter is divided into five major sections namely architecture of fog data processing and analytics, applications of FDPA, data processing algorithms in fog computing and data compression mechanisms and data analysis mechanisms in Fog computing toward Healthcare 4.0. The fog data architecture discusses various layers namely sensing layer, fog gateway layer, fog-based data processing and data analysis layer, cloud layer, and service layer. Here, the process of sensing of healthcare data, maintenance of data, and various methods to analyze healthcare data are discussed. Further, the healthcare data gathered from sensor devices are raw and redundant in data, hence they are needed for various data processing algorithms for fog-based healthcare systems. Hence, various data processing techniques such as Dynamic Time Warping, Clinical Speech Processing are discussed. Next, in fog computing, the data compression techniques are required for optimizing the bandwidth consumption and energy efficiency are presented. Next, data analytics mechanism such as real-time decisive analysis, real-time control and context analysis, and real-time data analysis are presented.",data oriented architecture,379
9661f5d79bcf9e18e30beda5a44ddc75f60cef8d,filtered,semantic_scholar,,2012-01-01,semantic_scholar,research on service-oriented data mining engine based on cloud computing,https://www.semanticscholar.org/paper/9661f5d79bcf9e18e30beda5a44ddc75f60cef8d,"The scalability of data mining algorithms is restricted when dealing with large-scale data. There are sig-nificant differences in a wide range of application areas and requirements for knowledge discovery process. It is fundamental to provide effective formalisms to design distributed data mining application and support their efficient execution. This paper proposes a novel service-oriented data minging engine based on cloud computing framework,which is named as CloudDM. Differentiating from grid-based distributed data mining framework,CloudDM ex-ploits the capacity of open source cloud computing platform-Hadoop for large-scale data analysis,supports the design and execution of distributed data mining applications according to SOA(service-oriented architecture) . Moreover,it discusses and reports the key component functions and implementation technologies. According to the design principles of SOA and data mining engine based on cloud computing,the paper can solve the problems in massive data mining systems,such as big data storage,data processing and interactive operation of algorithms,etc.",data oriented architecture,380
c21a315dd1e6a7853e9f25aed34c5c0e6cba2d77,filtered,semantic_scholar,MATEC Web of Conferences,2020-01-01,semantic_scholar,a referenced cyber physical system for compressor manufacturing,https://www.semanticscholar.org/paper/c21a315dd1e6a7853e9f25aed34c5c0e6cba2d77,"Compressor is a typical high-end discrete product，with the shortening of product life cycle and the enhancement of the degree of product customization, the traditional compressor manufacturing system architecture cannot meet the requirements of comprehensive digital management of compressor from body scheme design to parts production line, logistics management, operation and maintenance monitoring and evaluation. This paper presents a compressor manufacturing system architecture based on digital twinning, and establishes an Internet platform for compressor industry oriented to remote coordination from three aspects of compressor design, production, operation and maintenance. The platform includes industrial Internet infrastructure layer, physical space entity model layer, virtual space multidimensional model layer, physical space and virtual space multidimensional model correlation and mapping layer, big data intelligent analysis decision-making layer, and digital twin application layer. Through the establishment of the compressor product design and simulation model of digital twin, compressor production process digital twin model, compressor fault diagnosis and remote operations digital twin model, implementation is based on the number of compressor collaboration in manufacturing industrial Internet platform twin system, leading the transformation and upgrading of intelligent manufacturing industry, compressor industry sustainable development ability and international competitiveness.",data oriented architecture,381
6458ab3820cad2521cf7973940c74a0cb5f701b1,filtered,semantic_scholar,,2018-01-01,semantic_scholar,a survey of cloud environment in medical images processing,https://www.semanticscholar.org/paper/6458ab3820cad2521cf7973940c74a0cb5f701b1,"Cloud computing is one of the challenging technology to process the big data. In developing technologies, advanced software for processing medical images has gained a great interest in modern medicine field. It provides valuable scientific information, and hence, can significantly improve diagnosis and provide advance treatment like tumour detection in various unknown parts of the body like. The main contribution of this study is about the various challenges and need of cloud computing environment in the field of medical images datasets. Recently, various security measures and mechanisms have been suggested to overcome these challenges and accelerate the adoption of cloud computing services in the field of medical images. In this regard, numerous cryptographic techniques are used to safely process digital medical images, techniques that make use of homomorphic cryptosystems, Secret Sharing Schemes (SSS), Service-Oriented Architecture (SOA) and Secure Multi-party Computation (SMC). The main contribution of this study consists of need, important of cloud computing environment in the field of medical image processing. Keywords— cloud computing, medical images, cloud computing environment.",data oriented architecture,382
8be57d73db4c10d9c0a41fdfc2e6d4f868689315,filtered,semantic_scholar,2018 IEEE 4th International Conference on Computer and Communications (ICCC),2018-01-01,semantic_scholar,design of manufacturing big data access platform based on soa,https://www.semanticscholar.org/paper/8be57d73db4c10d9c0a41fdfc2e6d4f868689315,"In view of the lack of big data access platform in current manufacturing industry, the big data access platform was studied based on SOA. With the analysis of big data characteristics and the big data access business in manufacturing industry, the overall architecture of the service oriented manufacturing big data access platform was built. The whole technical scheme of the platform was introduced and the platform functional design was the elaborated. The platform has functions of the data access management, data processing management, log management, database management and the distributed storage management. These provide good foundation for manufacturing big data service.",data oriented architecture,383
5ee5bca1038e3571d6f676d174b3ee2c669f14fa,filtered,semantic_scholar,,2016-01-01,semantic_scholar,electric vehicles operations oriented network and data analysis,https://www.semanticscholar.org/paper/5ee5bca1038e3571d6f676d174b3ee2c669f14fa,"We analyze characteristics of electric vehicles interaction network and present a big data analysis method for electric vehicles operations, which is based on cloud computing model. For the electric vehicles large-scale operations, we propose a scalable architecture design as well as the method to improve the data computing speed. Introduction Electric cars are clean and green, thus the development of electric cars is regarded as an effective method of energy saving and emission reduction for traffic system. However, the disadvantages such as inconvenience of battery charging, short range and other factors restrain the popularization of electric vehicles. The large-scale popularization of electronic cars needs country, company and individuals to participate in. Therefore, building a complete electric vehicles operational support system is not only the market target of power grid but also their social responsibility. Background As a new industry, there has been a lot of researches about electric vehicles, but has not yet to establish a mature business model and large-scale operations. The market environment and user scale require cultivation and development by joint efforts of several aspects. The company ‘Better Place’ which found in 2007 positioned the itself as “provider of global electric vehicle network and service”, and designed networked charging facilities of “battery rental + battery exchange”, exploring a new application mode. In 2015, the electric car ownership of China is about 1 million. Besides, China now ranks as first in the world for the number of charging stations and charging piles. Therefore, China has become the country with the greatest potential for electric vehicles operations. With the application of “graphene” technology, electric vehicles will be undoubtedly popularized and gradually begin operating in large-scale in the future. Thus, it is necessary to explore the operational architecture of electric vehicles, which can adapt to the increasing scale of the electric cars. Interaction network characteristics of electric vehicles With the development of automobile electronic technology, software system has been widely used in ordinary cars. The cars have become the “fourth screen” after TV, computer and mobile phone. Navigation and mobile computing technology have been deeply applied to cars. Compared with traditional auto industry, the industry scale of electric cars is smaller. However, the huge potential business opportunities promote the software development of electric vehicles in automobile manufacture industry, which results in gradually developmental Internet of Vehicles. Compared with the traditional cars, electric cars need more network support. For example, in order to eliminate the driver’s worries about the range, drivers need to know the car battery status in time and find convenient charging stations. This demand involves real information data of the charging stations network, and is closely related to the payment system and telecom operators’ network. Various applications such as mobile computing and social networks find their natural carrier. For example, value-added services could be expanded into automobile data recorder. Value-added services based on electric vehicles can be regarded as the fusion of telegraphic value-added services 4th National Conference on Electrical, Electronics and Computer Engineering (NCEECE 2015) © 2016. The authors Published by Atlantis Press 1463 and electric value-added services. Therefore in the performance form of the social network businesses, there is no significant difference between this field and other fields. They link public through certain ties and are consistent with the characteristics of “small world” network [1, . Some works discussed about the distribution network planning concerning to the load demand of new electric cars charging. But at the abstract level, this kind of work does not affect the structure characteristics of the electric car operations network.",data oriented architecture,384
75b0604bac271206a5297258573c009323b1a7fe,filtered,semantic_scholar,2019 1st International Conference on Unmanned Vehicle Systems-Oman (UVS),2019-01-01,semantic_scholar,automatic fault detection of power lines using unmanned aerial vehicle (uav),https://www.semanticscholar.org/paper/75b0604bac271206a5297258573c009323b1a7fe,"Safety and automation are the two major challenges in the application of Unmanned Aerial Vehicle (UAV), commonly known as drone, to the power lines inspection and fault detection. While current state-of-the-art UAVs are equipped with collision avoidance features, there is less attention to the automatic and real-time fault detection of power lines using UAVs. This paper presents the architecture of three drone-oriented concept designs for automatic and real-time fault detection of power lines using UAVs. The proposed systems could be potential candidates for replacing traditional inspection methods of power lines, which are risky and costly. By incorporating a robust neural network, i.e., Artificial Intelligence (AI), and using appropriate and efficient sensors, the systems can automatically detect various faults and defects on power lines with high precision. We propose three concept design options comprised of different hardware/software components and their feasibility factors. For instance, FLIR Duo Pro R as a thermal sensor and Zenmuse XT for thermal vision have been proposed to be used in the concept designs. For data communication, the proposed designs use cloud-based virtual private network (VPN) for a secure connection between remote control (RC) of the UAV and the server. Based on the advantages and disadvantages of the three proposed design options, the most efficient design is also discussed. This design proposes a system with lightweight sensors, which could increase the flight time of the UAV. Further, the AI interface is coded on to the RC, making it economical, without any database for big data storage. The back-end of the neural network is stored in a cloud server. With the help of GSM antenna, the AI can run on the tablet if there is an available cellular network.",data oriented architecture,385
cd876a703abbef14161ea8f1707909db6591a224,filtered,semantic_scholar,2016 International Conference on Robots & Intelligent System (ICRIS),2016-01-01,semantic_scholar,a high-performance retrieval method of mass data oriented to cloud computing,https://www.semanticscholar.org/paper/cd876a703abbef14161ea8f1707909db6591a224,"With the acceleration development of the Internet of Things and big data, the importance of high-performance mass data retrieval is gradually highlighted. Cloud computing is the distributed data calculation model that is suitable for big data, and has been widely used. In this paper, firstly, the technology of cloud computing is introduced. Secondly, retrieval technology of mass data is analyzed, finally a high-performance retrieval method of mass data based on Hadoop is proposed. The architecture of this method is composed of HDFS, MapReduce, and Hive, and is divided into four layers from bottom to top: access layer, interface layer, management layer and storage layer.",data oriented architecture,386
bc68d075e5289519965222c47b9ea703793f61c6,filtered,semantic_scholar,UCC,2017-01-01,semantic_scholar,nist big data reference architecture for analytics and beyond,https://www.semanticscholar.org/paper/bc68d075e5289519965222c47b9ea703793f61c6,"Big Data is the term used to describe the deluge of data in our networked, digitized, sensor-laden, information driven world. There is a broad agreement among commercial, academic, and government leaders about the remarkable potential of ""Big Data"" to spark innovation, fuel commerce, and drive progress. The availability of vast data resources carries the potential to answer questions previously out of reach. However, there is also broad agreement on the ability of Big Data to overwhelm traditional approaches. Big Data architectures come in many shapes and forms ranging from academic research settings to product-oriented workflows. With massive-scale dynamic data being generate from social media, Internet of Things, Smart Cities, and others, it is critical to analyze these data in real-time and provide proactive decision. With the advancement of computer architecture in multi-cores and GPUs, and fast communication between CPUs and GPUs, parallel processing utilizes these platforms could optimize resources at a reduced time. This presentation will provide the past, current, and future activities of the NIST Big Data Public Working Group (NBD-PWG) and how the NIST Reference Architecture may address the rate at which data volumes, speeds, and complexity are growing requires new forms of computing infrastructure to enable Big Data analytics interoperability such that analytics tools can be re-usable, deployable, and operational. The focus of NBD-PWG is to form a community of interest from industry, academia, and government, with the goal of developing consensus definitions, taxonomies, secure reference architectures, and standards roadmap which would create vendor-neutral, technology and infrastructure agnostic framework. The aim is to enable Big Data stakeholders to pick-and-choose best analytics tools for their processing under the most suitable computing platforms and clusters while allowing value-additions from Big Data service providers and flow of data between the stakeholders in a cohesive and secure manner.",data oriented architecture,387
bb4fafc7412de2f4ea12aeaecadb2fbb8dd57c0b,filtered,semantic_scholar,Sci. Program.,2021-01-01,semantic_scholar,research on the design of government affairs platform in the context of big data,https://www.semanticscholar.org/paper/bb4fafc7412de2f4ea12aeaecadb2fbb8dd57c0b,"Big data is a massive and diverse form of unstructured data, which needs proper analysis and management. It is another great technological revolution after the Internet, the Internet of Things, and cloud computing. This paper firstly studies the related concepts and basic theories as the origin of research. Secondly, it analyzes in depth the problems and challenges faced by Chinese government management under the impact of big data. Again, we explore the opportunities that big data brings to government management in terms of management efficiency, administrative capacity, and public services and believe that governments should seize opportunities to make changes. Brainlike computing attempts to simulate the structure and information processing process of biological neural network. This paper firstly analyzes the development status of e-government at home and abroad, studies the service-oriented architecture (SOA) and web services technology, deeply studies the e-government and SOA theory, and discusses this based on the development status of e-government in a certain region. Then, the deep learning algorithm is used to construct the monitoring platform to monitor the government behavior in real time, and the deep learning algorithm is used to conduct in-depth mining to analyze the government's intention behavior.",data oriented architecture,388
5db86e5d1bf2647d020ec6cd736e39d30766b850,filtered,semantic_scholar,,2020-01-01,semantic_scholar,background and research challenges for fc for healthcare 4.0,https://www.semanticscholar.org/paper/5db86e5d1bf2647d020ec6cd736e39d30766b850,"The revolution in the healthcare domain was originated with the emergence of modular IT system in healthcare (Health 1.0) to the healthcare extension of Industry 4.0 (Health 4.0) integrated with Internet of Things (IoT), Cyber Physical Systems, Artificial Intelligence (AI), Cloud Computing, Big Data, Bioinformatics, Robotics, Precision Medicine, to cite a few. Applying IoT in healthcare 4.0, massive amount of patients’ data is generated by the sensors and this data is accessible to the doctors at any time and at any place for analysis and for appropriate line of treatment. The sensors in the healthcare domain of IoT need to be wearable and wireless to monitor the patients on large scale. In addition, the analysis of data and decision of treatment should be done and communicated in as little amount of time as possible. Thus, the aggregation, storage, analysis, and maintenance of data should be such that the data is continuously available, portable, consistent, accurate, scalable, secure, and quickly transferable. These challenges constraint the energy, memory, communication, and processing capacity of the end devices (sensors) used. Hence, instead of relying entirely on remote data centers using Cloud computing, the gap is bridged by means of fog computing (near the healthcare premises). The factors affecting the architecture of fog computing in healthcare domain are location of patient, latency requirements, geographic distribution, heterogeneous data, scalability, real-time vs batch processing, mobility of end devices, etc. On the other side, use of fog computing in the healthcare has substantial challenges for researchers and organizations including application-oriented architecture prototype, modeling and deployment, infrastructure and network management, resource management, mobility of patients and hence data mobility, security and privacy of patients’ data, scalability, easy incorporation of various healthcare professionals’ proficiency with intelligent devices and sensors, and minimum latency time in case of life threatening situations. This chapter discusses background and research challenges of fog computing in Healthcare 4.0 with an aim to guide the researchers and stakeholders for the overall improvement in the functioning of the healthcare domain.",data oriented architecture,389
d0f3251c1eca6bcbe76aeaf267c7908b1c9e5755,filtered,semantic_scholar,,2016-01-01,semantic_scholar,the role of grid technologies: a next level combat with big data,https://www.semanticscholar.org/paper/d0f3251c1eca6bcbe76aeaf267c7908b1c9e5755,"Grid computing has successfully delivered a service oriented architecture that is ubiquitous, dynamic and scalable to the world of networking. It promises to deliver these services to the world of computations that is about to deal with high volume of scalable information involving heterogeneous data i.e., Big data. The Big data needs to explore the new era of technologies and infrastructures that can provide higher level services for managing high volumes of scalable and diverse data. Therefore, it is a timely and challenging opportunity for the Grid technologies to fulfill its promises. This chapter enlightens and examines the key challenges, issues and applications of Grid technologies in the management of Big data.",data oriented architecture,390
7cda685a46321ee7c3fb66aec55d8bac124d4159,filtered,semantic_scholar,ICEIS,2019-01-01,semantic_scholar,mda process to extract the data model from document-oriented nosql database,https://www.semanticscholar.org/paper/7cda685a46321ee7c3fb66aec55d8bac124d4159,"In recent years, the need to use NoSQL systems to store and exploit big data has been steadily increasing. Most of these systems are characterized by the property ""schema less"" which means absence of the data model when creating a database. This property brings an undeniable flexibility by allowing the evolution of the model during the exploitation of the base. However, query expression requires a precise knowledge of the data model. In this article, we propose a process to automatically extract the physical model from a document-oriented NoSQL database. To do this, we use the Model Driven Architecture (MDA) that provides a formal framework for automatic model transformation. From a NoSQL database, we propose formal transformation rules with QVT to generate the physical model. An experimentation of the extraction process was performed on the case of a medical application.",data oriented architecture,391
7bc1dd8a4d0735f49ffe64e91e2a1f1f376118be,filtered,semantic_scholar,,2019-01-01,semantic_scholar,проблема анализа больших веб-данных и использование технологии data mining для обработки и поиска закономерностей в большом массиве веб-данных на практическом примере,https://www.semanticscholar.org/paper/7bc1dd8a4d0735f49ffe64e91e2a1f1f376118be,"The purpose of the work is to study the current problems and prospects of the solution for processing big data received or stored in the Internet (web data), as well as the possibility of practical realization of Data Mining technology for big web data on practical example. Materials and methods. The study included a review of bibliographic sources on big data analysis problems. Data Mining technology was used to analyze large web data, as well as computer modeling of a practical problem using the C # programming language and creating a DDL database structure for accumulating web data. Results. In the course of the work, the specifics of big data were described, the main characteristics of big data were highlighted, and modern approaches to processing big data were analyzed. A brief description of the horizontal-scalable architecture and the BI-solution architecture for big data processing is given. The problems of processing large web data are formulated: limiting the speed of access to data, providing access via network protocols through general-purpose networks. An example showing the approach to processing large web data was also implemented. Based on the idea of big data, the described complexities of web data processing and the methods of Data Mining, techniques were proposed for effectively solving the practical problem of processing and searching patterns in a large data array. The following classes have been developed in the C # programming language: Class of receiving web data via the Internet; Data conversion class; Intelligent data processing class; Created DDL script that creates a structure for the accumulation of web data. A single UML class diagram has been developed. The constructed system of data and classes allows to solve the main part of the problems of processing large web data and perform intelligent processing using Data Mining technology in order to solve the problem posed of identifying certain records in a large array. The combination of object-oriented approach, neural networks and BI-analysis to filter data will speed up the process of data processing and obtaining the result of the study Conclusion. According to the results of the study, it can be argued that the current state of technology for analyzing large web data allows you to efficiently process data objects, identify patterns, get hidden data and get full-fledged statistical data. The obtained results can be used both for the purpose of the initial study of big data processing technologies, and as a basis for developing an already real application for analyzing web data. The use of neural networks and the created universal classes-handlers makes the created architecture flexible and self-learning, and the class declarations and the base DDL structure will greatly simplify the development of program code.",data oriented architecture,392
4419883a412b6c23a052c674705239d5f911db8d,filtered,semantic_scholar,"2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)",2018-01-01,semantic_scholar,breeding data service platform based on the new architecture of cloud technology,https://www.semanticscholar.org/paper/4419883a412b6c23a052c674705239d5f911db8d,"With the rise of information and communication technologies such as big data and Internet of things, traditional breeding data management methods have been unable to cope with the demand of large-scale breeding. Aiming at the present situation, a new breeding data service structure based on cloud technology is put forward, and a breeding data service platform is constructed. The platform with the Django Web framework, Python modeling language for the back-end operation, MongoDB for the database, uses cloud storage data center model and the user-oriented multi-level service structure, providing data storage and data analysis services for breeders. The platform provides the feasible architecture scheme for the breeding units to carry out the corresponding service, realizes the sharing of breeding data resources, and advances the process of Internet + agricultural informatization construction.",data oriented architecture,393
35aa6df81a8eaf3992658dba4b49f1d18f10094a,filtered,semantic_scholar,,2015-01-01,semantic_scholar,community-oriented networking technology,https://www.semanticscholar.org/paper/35aa6df81a8eaf3992658dba4b49f1d18f10094a,"The Internet Protocol (IP) communication technology used on the Internet has evolved and developed as a versatile communication technology that enables humans to communicate with each other. Nowadays, low-cost sensors, radio frequency identification (RFID), and scalable and high-speed wireless communication technology have made progress and have been applied to the field of “Internet of Things (IoT)” where all kinds of physical objects and things are able to connect to the Internet or the field of “cyberphysical systems” (CPS) which enables interaction between the Internet-connected physical world and cyberspace. IoT and CPS require a system for managing the vast amount of data (i.e. big data) generated by sensors, actuators and other devices, processing such data within the network, and sharing among the interested parties, but a communication model that manages all of the big data on a server or cloud has limits in terms of the communication speed and energy efficiency. Based on a recent white paper from Cisco, there will be 50 billion devices connected to Internet by 2020. Therefore, there is a need for a communication protocol with even higher scalability and real-time capabilities (immediate responsiveness) than the current IP communication. In many IoT systems and CPSs, the main communication will be the sharing of data within a community of objects, such as humans and things. However, the use of traditional IP communication based on a host-centric, end-to-end communication model for communication within a community with numerous objects will lead to an enormous number of communication paths or a significant increase in unnecessary communication traffic, resulting in overall degradation of communication performance and quality. Against such a backdrop, we propose a CommunityORiented IcN (CORIN), a community-oriented communication architecture using the concept of information-centric networking (ICN) which has been studied as a new paradigm for future network technologies. The ICN enables communication centered on information (content) rather than the host-centric communication premised by IP communication. Specifically, information (content) is acquired from a nearby router or node that stores (or caches) the content, through communication using the name of the content, without designating the location (IP address) of a server or the information provider. In CORIN, a “community name” is designated instead of the content name used in ICN to perform communication based on communities. A community used in CORIN is a group of users with common interests in information or content or network-connected users with some kind of",data oriented architecture,394
badfe56ebd7348a8654365aacb162ec4c84368af,filtered,semantic_scholar,J. Intell. Fuzzy Syst.,2021-01-01,semantic_scholar,intelligent platform for real-time page view statistics using educational big data digital resource sharing,https://www.semanticscholar.org/paper/badfe56ebd7348a8654365aacb162ec4c84368af,"In order to meet the rapid growth of educational data, to automate the processing of educational data business, improve operational efficiency and scientific decision-making, a statistical analysis platform for educational data is designed, and Hadoop-based education is designed from the conceptual model, logical model, and physical model. Data warehouse; designed and researched the storage of educational multidimensional data model; and then compared and tested the query efficiency and storage space of HBase and Hive in the Hadoop ecosystem based on educational big data, and used HBase+Hive integrated architecture to complete the education data The statistical analysis tasks and the function of the educational data statistical analysis platform are transplanted to the educational big data platform based on Hadoop; the performance test of the conversion efficiency of educational big data in the ETL link is performed, which illustrates the effectiveness of the educational big data platform based on Hadoop. An object-oriented analysis and design method used to analyze and design the business requirements of teaching resource sharing services. From the perspective of managers and teachers, use case diagrams and use case description tables to define system business requirements. The role of teachers is further refined as the theme of teaching and research. Participants, participants in the subject teaching and research, initiators of simulation teaching research and development, participants, famous teachers, high-quality course judges and experts. The recording, accumulation, statistics and analysis of students’ learning behaviors will provide more valuable applications for school education.",data oriented architecture,395
96bb8913c38529e8c2b935eb164744fdef61f100,filtered,semantic_scholar,,2020-01-01,semantic_scholar,research on garment mass customization architecture for intelligent manufacturing cloud,https://www.semanticscholar.org/paper/96bb8913c38529e8c2b935eb164744fdef61f100,"The deep integration of Internet, intelligent manufacturing and big data technology has promoted the development of products to be networked, digital, intelligent and personalized. The rapid iteration and differential segmentation of consumer demand has spawned new personalized consumer demand, transforming the traditional manufacturing model into a service-oriented manufacturing model. This paper analyses the large-scale customized operation mode of domestic and foreign clothing custom brands. In view of the transformation of traditional clothing industry, this paper proposes a solution to establish a large-scale custom clothing architecture under the vision of intelligent manufacturing cloud platform technology. This paper uses data mining and cloud computing and other methods to build an “Internet + manufacturing” innovation model with rapid collaboration under the umbrella of big data, and propose an architecture for mass customization of clothing, providing effective solutions and strategy recommendations for the transformation and upgrading of the traditional apparel industry.",data oriented architecture,396
acb50d8487af3d4066b078d69d8301644e599046,filtered,semantic_scholar,OTM Workshops,2014-01-01,semantic_scholar,enterprise networks integration in a sensing environment: a case study,https://www.semanticscholar.org/paper/acb50d8487af3d4066b078d69d8301644e599046,"Internet of things, mobile Internet, cloud computing and big data technologies build a sensing environment for all kinds of businesses. Inter enterprise collaboration is meeting new challenges of omni-channel marketing, closed-loop supply chain and enterprise networks integration. A data convergence oriented enterprise networks integration architecture is developed in the paper. How to use the developed technologies to solve problems of product lifecycle management and omni-channel marketing management are discussed in detailed cases studies.",data oriented architecture,397
00bffa682b9231e66460e7386efa9d2d80d1503e,filtered,semantic_scholar,,2016-01-01,semantic_scholar,optimized management of big data produced in brain disorder rehabilitation,https://www.semanticscholar.org/paper/00bffa682b9231e66460e7386efa9d2d80d1503e,"Brain disorders resulting from injury, disease, or health conditions can influence function of most parts of human body. Necessary medical care and rehabilitation is often impossible without close cooperation of several diverse medical specialists who must work jointly to choose methods that improve and support healing processes as well as to discover underlying principles. The key to their decisions are data resulting from careful observation or examination of the patient. We introduce the concept of scientific dataspace that involves and stores numerous and often complex types of data, e.g., the primary data captured from the application, data derived by curation and analytic processes, background data including ontology and workflow specifications, semantic relationships between dataspace items based on ontologies, and available published data. Our contribution applies big data and cloud technologies to ensure efficient exploitation of this dataspace, namely, novel software architectures, algorithms and methodology for its optimized management and utilization. We present its service-oriented architecture using a running case study and results of its data processing that involves mining and visualization of selected patterns optimized towards big and complex data we are dealing with.",data oriented architecture,398
5d3162d9fa543922b88c53403ecfc883cddb7f6b,filtered,semantic_scholar,,2016-01-01,semantic_scholar,disrupting the chinese state: new actors and new factors,https://www.semanticscholar.org/paper/5d3162d9fa543922b88c53403ecfc883cddb7f6b,"How do the development of digital technology influence the architecture of China’s governance structure? This paper will focus on two elements that, it argues, are radically transforming the modus operandi of the Chinese state. First, it will discuss the rapid emergence of the huge private corporations that have come to dominate China’s Internet, and the increasing symbiosis between them and political processes. This paper will argue that a strategic public-private nexus is forming at the centre of China’s political architecture, where the particular properties of private Internet corporations are used to counter some of the perennial problems that plague the Party-State. Second, it will discuss the leadership’s perception of how new forms of data, data gathering, processing and analysis (generally referred to as “big data” (da shuju) may enhance its governing capabilities (zhizheng nengli). Prior e-governance efforts were largely dedicated at digitization of existing data, generally held by state bodies. However, in China as elsewhere, private corporations have rapidly developed new profit modes based on the exploitation of hitherto unmined data. Unsurprisingly, China’s control-oriented government sees this as a great opportunity to enhance its ability to monitor the activities of its citizens, businesses and government officials. One particular manifestation of this approach is the social credit system (shehui xinyong tixi) that is currently under development. This paper will argue that the data-empowered agenda has the potential to radically disrupt China’s information order. From the central point of view, it will erode the separation between the centre and the periphery, as encapsulated in the well-known proverb “the mountains are high, and the emperor far away” (shan gao, huangdi yuan). Nevertheless, as Internet-based approaches become institutionalized, it is equally likely that current governance pathologies will reproduce themselves in the online sphere. Please note: this is the working version of this paper. The published version can be found through the Brill database.",data oriented architecture,399
5c84da9defb3b1636974a7c1447f20f7aba53438,filtered,semantic_scholar,2021 IEEE International Conference on Big Data (Big Data),2021-01-01,semantic_scholar,language-agnostic and language-aware multilingual natural language understanding for large-scale intelligent voice assistant application,https://www.semanticscholar.org/paper/5c84da9defb3b1636974a7c1447f20f7aba53438,"Natural language understanding (NLU) is one of the most critical components in goal-oriented dialog systems and enables innovative Big Data applications such as intelligent voice assistants (IVA) and chatbots. While recent advances in deep learning-based NLU models have achieved significant improvements in terms of accuracy, most existing works are monolingual or bilingual. In this work, we propose and experiment with techniques to develop multilingual NLU models. In particular, we first propose a purely language-agnostic multilingual NLU framework using a multilingual BERT (mBERT) encoder, a joint decoder design for intent classification and s lot filling tasks, and a novel co-appearance regularization technique. Then three distinct language-aware multilingual NLU approaches are proposed including using language code as explicit input; using language-specific parameters during decoding; and using implicit language identification as an auxiliary task. We show results for a large-scale, commercial IVA system trained on a various set of intents with huge vocabulary sizes, as well as on a public multilingual NLU dataset. We performed experiments in explicit consideration of code-mixing and language dissimilarities which are practical concerns in large-scale real-world IVA systems. We have found that language-aware designs can improve NLU performance when language dissimilarity and code-mixing exist. The empirical results together with our proposed architectures provide important insights towards designing multilingual NLU systems.",data oriented architecture,400
5de9f8b9f0730e6a505bfbbf7296309cb0f14805,filtered,semantic_scholar,SSRN Electronic Journal,2019-01-01,semantic_scholar,intelligent microservices in service-oriented architecture for big data organization,https://www.semanticscholar.org/paper/5de9f8b9f0730e6a505bfbbf7296309cb0f14805,"Service-Oriented Architecture (SOA) approach transcends the current technological innovations and automation concepts of addressing a variety of business organization problems and concerns. Microservices are an integral part of contemporary service-oriented architectures for distributed computing applications. Mining of big data with intelligence is very important for accurate predictive analysis and making critical business decisions. Big data with SOA or Service-oriented Business Intelligence (SoBI) enables business organizations to produce reliable and agile business solutions. This paper aims at presenting a brief analysis of integrating intelligence in service oriented architecture with microservices and its applications in big data organizations . The research area is based on artificial intelligence techniques like deep learning, machine learning, neural network etc. that will en-graft intelligence in mining of big data in service oriented architecture software systems.",data oriented architecture,401
3edf359def63c38a109ae4eda9b4d0fa5dbd2f66,filtered,semantic_scholar,"2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)",2016-01-01,semantic_scholar,bussola: a cloud collaborative platform of oriented services to passengers,https://www.semanticscholar.org/paper/3edf359def63c38a109ae4eda9b4d0fa5dbd2f66,"BUS Services Mobilizing Living Lab, namely BUSSOLA, focuses on means of transport for people to make a living lab on the move upon which to design, implement and test innovative services that uses and feeds platform SmartDataNet. In particular, thanks to several sensors and devices, the system pays attention on three main macro-areas: air quality monitoring, passengers monitoring and safety on board the vehicles. A distributed and modular architecture has been adopted, to communicate and manage heterogeneous information. The solution is based on cloud technology for a better flexibility and scalability system and an easier adaptation at future requirements in term of computational resource and storage. It allows to experiment and adopt paradigms typical of the world of the Internet of Things and the Internet of Services, it made available by the platform SmartDataNet starting from the processing of big data and open-data.",data oriented architecture,402
18cd855a7b321ad34cb2c683c29b5d1fad2010dc,filtered,semantic_scholar,,2015-01-01,semantic_scholar,a pattern oriented approach for designing scalable analytics applications (invited talk),https://www.semanticscholar.org/paper/18cd855a7b321ad34cb2c683c29b5d1fad2010dc,"The biggest gain in fast processing of big-data will most likely be a result of mapping computation onto clusters of machines while exploiting per-processor parallelism by means of vector instructions and multi-threading. As a result, a new generation of parallel computing infrastructure is needed, driven by the need for application scalability through harnessing growing computing resources in the public cloud, in private data centers and custom clusters, and even on the desktop. This paper uses Our Pattern Language (OPL) to guide the design of a pattern oriented software framework for analytics applications which enables scalability, flexibility, modularity and portability. Using a compute intensive financial application as a motivating example, we demonstrate how following a pattern oriented design approach leads to parallel code in which the domains of concerns for modeling and mapping the computations to the architecture are cleanly delineated, the code is portable across architectures, and accessible to both an application developer and systems developer. In future work, we seek to demonstrate this software framework by architecting and developing a portable and scalable version of quantlib, a popular open-source quantitative finance library.",data oriented architecture,403
10.1109/asru.2007.4430168,filtered,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),IEEE,2007-12-13 00:00:00,ieeexplore,a data-centric architecture for data-driven spoken dialog systems,https://ieeexplore.ieee.org/document/4430168/,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",data centric architecture,404
10.1109/icdcsw.2003.1203556,filtered,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",IEEE,2003-05-22 00:00:00,ieeexplore,"""data-centric to the max"", the splice architecture experience",https://ieeexplore.ieee.org/document/1203556/,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",data centric architecture,405
10.1109/cluster.2012.80,filtered,2012 IEEE International Conference on Cluster Computing,IEEE,2012-09-28 00:00:00,ieeexplore,a decoupled execution paradigm for data-intensive high-end computing,https://ieeexplore.ieee.org/document/6337781/,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",data centric architecture,406
10.1109/siot.2016.007,filtered,2016 International Workshop on Secure Internet of Things (SIoT),IEEE,2016-09-30 00:00:00,ieeexplore,addressing data-centric security requirements for iot-based systems,https://ieeexplore.ieee.org/document/7913560/,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",data centric architecture,407
10.1109/icce-china.2017.7991141,filtered,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),IEEE,2017-06-14 00:00:00,ieeexplore,an iot framework for intelligent roadside assistance system,https://ieeexplore.ieee.org/document/7991141/,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",data centric architecture,408
10.1109/issnip.2005.1595552,filtered,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",IEEE,2005-12-08 00:00:00,ieeexplore,architectures for wireless sensor networks,https://ieeexplore.ieee.org/document/1595552/,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,data centric architecture,409
10.1109/lanman.2015.7114718,filtered,The 21st IEEE International Workshop on Local and Metropolitan Area Networks,IEEE,2015-04-24 00:00:00,ieeexplore,boosting named data networking for efficient packet forwarding in urban vanet scenarios,https://ieeexplore.ieee.org/document/7114718/,"Named Data Networking (NDN) is a data-centric architecture designed for the future Internet. Existing works show that NDN brings significant performance improvement for typical content-centric applications, and can also fit the mobile environment well. However, directly applying NDN to Vehicular Ad hoc NETworks (VANETs) is confronted with great challenges due to the high mobility of vehicles. Most applications in VANETs are relied on data dissemination mechanisms. Therefore, we aim to improve the performance of NDN packet forwarding for the efficient content delivery in urban VANET scenarios. Specifically, we introduce the geo-location information to the NDN forwarding plane, and propose a geo-based forwarding strategy to make NDN fit the urban VANETs. Simulation results show our strategy can achieve 27% ~ 75% higher request success ratio, and 40% ~ 80% lower delay compared with the default NDN strategy in urban scenarios with different vehicle densities.",data centric architecture,410
10.1109/bigdata.2015.7363971,filtered,2015 IEEE International Conference on Big Data (Big Data),IEEE,2015-11-01 00:00:00,ieeexplore,component based dataflow processing framework,https://ieeexplore.ieee.org/document/7363971/,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",data centric architecture,411
10.1109/icsea.2010.30,filtered,2010 Fifth International Conference on Software Engineering Advances,IEEE,2010-08-27 00:00:00,ieeexplore,content server architecture pattern for evolvability and scalability,https://ieeexplore.ieee.org/document/5615125/,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",data centric architecture,412
10.1109/apwimob.2014.6920286,filtered,2014 IEEE Asia Pacific Conference on Wireless and Mobile,IEEE,2014-08-30 00:00:00,ieeexplore,critical security review and study of ddos attacks on lte mobile network,https://ieeexplore.ieee.org/document/6920286/,"Mobile network is currently evolving into data centric architecture. Long Term Evolution (LTE) based next generation 4G technology is being deployed by cellular operators around the globe. LTE supports all-IP based data, voice and streaming network with speeds in the order of hundreds of megabits per seconds. Increased speed in accessing Internet and other advanced services exposes mobile data network to be attacked by hackers using spyware, malware, phishing and distributed denial-of-service (DDoS) attacks, which were predominantly affecting Internet-only datacentres in the past. This paper presents a detailed review of security framework and authentication procedures built into the LTE system architecture evolution (SAE). A brief summary of DDoS attacks and security vulnerabilities in LTE network included. This paper reviews the diameter interface and associated security problems using it in LTE network. This paper proposes using explicit-congestion notification (ECN) based method to address congestion issues in diameter interface.",data centric architecture,413
10.1109/aero.2005.1559422,filtered,2005 IEEE Aerospace Conference,IEEE,2005-03-12 00:00:00,ieeexplore,"data centric, position-based routing in space networks",https://ieeexplore.ieee.org/document/1559422/,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",data centric architecture,414
10.1109/icccn.2019.8847129,filtered,2019 28th International Conference on Computer Communication and Networks (ICCCN),IEEE,2019-08-01 00:00:00,ieeexplore,data-centric video for mixed reality,https://ieeexplore.ieee.org/document/8847129/,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",data centric architecture,415
10.1109/netsys.2019.8854515,filtered,2019 International Conference on Networked Systems (NetSys),IEEE,2019-03-21 00:00:00,ieeexplore,information-centric iot middleware overlay: vsl,https://ieeexplore.ieee.org/document/8854515/,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",data centric architecture,416
10.1109/services51467.2021.00054,filtered,2021 IEEE World Congress on Services (SERVICES),IEEE,2021-09-10 00:00:00,ieeexplore,keynote 1: dbos: a database-oriented operating system,https://ieeexplore.ieee.org/document/9604388/,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Current operating systems are complex systems that were designed long before today’s computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today’s most important applications, propose a plan for the development of a DBOS proof of concept, and give results on a pilot that suggest the approach has merit.",data centric architecture,417
10.1109/pes.2005.1489657,filtered,"IEEE Power Engineering Society General Meeting, 2005",IEEE,2005-06-16 00:00:00,ieeexplore,moving from data architecture to event architecture in the ems environment,https://ieeexplore.ieee.org/document/1489657/,"Information models and databases are at the center of the design of most current software systems. The job done by the active portions, the applications, is to transform the data as needed. If the applications can, they work in a strictly stateless, data transforming paradigm, because this creates the simplest sort of reliable system. Our EMS systems are complex, real-time systems that cannot adopt this simplest paradigm, but they nevertheless follow a data-centric architecture. This is about to change. ""Message buses"" or ""integration buses"" or ""event buses"" are different names for the ability to connect applications with high speed flexible messaging. This technology is now ready for prime time and the question is - how are we going to use it? Are we going to take advantage of the active voice communication that events can provide? Or, are we going to stay predominantly in the familiar data orientation? The situation is somewhat analogous to the now-familiar experience that procedural programmers, when given object oriented languages, often did not go through the paradigm-shift and produced procedural code written in object languages. In this paper, we focus on the advantages that can be achieved in the temporal domain - a long-standing trouble-spot in EMS design.",data centric architecture,418
10.1109/aero.2010.5446746,filtered,2010 IEEE Aerospace Conference,IEEE,2010-03-13 00:00:00,ieeexplore,pnpsat-2 spa technology testbed initial results and development status,https://ieeexplore.ieee.org/document/5446746/,"Abstract-This paper presents the initial results and development status of the AFRL sponsored PnPSat-2 SPA Technology Testbed. The purpose of the testbed is to integrate the next generation of radiation hardened SPA technology and components (hardware and software) with a representative tactical satellite bus structure. The resulting system will be used to demonstrate system performance using Hardware in the Loop (HWIL) techniques for representative (e.g. ORS Tactical) scenarios. AFRL has led two efforts in SPA technology development to both solidify the SPA technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) was the first spacecraft to utilize the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. PnPSat-2 integrates the next generation of radiation hardened SPA components on a larger bus focused on ORS needs. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insulates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in development and test time.",data centric architecture,419
10.1109/pdcat.2010.72,filtered,"2010 International Conference on Parallel and Distributed Computing, Applications and Technologies",IEEE,2010-12-11 00:00:00,ieeexplore,sharing in-memory game states,https://ieeexplore.ieee.org/document/5704404/,"Massively multi-user virtual environments (MMVEs)are becoming increasingly popular with millions of users. Typically, commercial implementations rely on client/server architectures for managing the game state and use message passing mechanisms to communicate state changes to the clients. We have developed the Typed Grid Object Sharing (TGOS)service providing data sharing of in-memory data. TGOS aims at simplifying the development of MMVEs by sharing scene graphs in a peer-to-peer way and also data of backend services. Replication is controlled by different consistency models, including restartable transactions combined with optimistic synchronization for strong consistency. In this paper we describe the data centric architecture of the Wissenheim Worlds application and relevant parts of TGOS. Furthermore, we present an evaluation showing the feasibility and efficiency of the proposed approach.",data centric architecture,420
10.1109/aero.2017.7943816,filtered,2017 IEEE Aerospace Conference,IEEE,2017-03-11 00:00:00,ieeexplore,software architecture and design of the kontur-2 mission,https://ieeexplore.ieee.org/document/7943816/,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",data centric architecture,421
10.1109/ciot.2018.8627124,filtered,2018 3rd Cloudification of the Internet of Things (CIoT),IEEE,2018-07-04 00:00:00,ieeexplore,"fogø5: unifying the computing, networking and storage fabrics end-to-end",https://ieeexplore.ieee.org/document/8627124/,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",data centric architecture,422
10.1109/idt.2008.4802501,filtered,2008 3rd International Design and Test Workshop,IEEE,2008-12-22 00:00:00,ieeexplore,"challenges and solutions in configuring, rapid developing and deploying of a qos-enabled component middleware",https://ieeexplore.ieee.org/document/4802501/,"Data-centric design is emerging as a key tenet for building advanced data-critical distributed real-time and embedded systems. These systems must find the right data, know where to send it, and deliver it to the right place at the right time. Data distribution service (DDS) specifies an API designed for enabling real-time data distribution and is well suited for such complex distributed systems and QoS-enabled applications. It is also, widely known that control area networks (CAN) are used in real-time, distributed and parallel processing. Thus, this paper provides an overview about the problem caused by some combinations of QoS policies and gives ideas about the emerging of the new paradigm of Model Driven Middleware with QoS-enabled component, including DDS.",data centric architecture,423
10.1109/wsc.2018.8632446,filtered,2018 Winter Simulation Conference (WSC),IEEE,2018-12-12 00:00:00,ieeexplore,data-centric cyber-physical systems design with smartdata,https://ieeexplore.ieee.org/document/8632446/,"Timeliness is a fundamental property of Cyber-Physical Systems that has been intensively investigated within the scope of real-time and critical systems. The advent of the Internet of Things, however, brings an intense communication flow between devices and the Internet. In this scenario, modeling time requirements in terms of data, rather than the tasks that manipulate them, may be advantageous as a data-centric design can promptly encompass other first-order requirements, such as geolocation, security, and trustworthiness. In this paper, we propose a strategy to design complex CPSs by modeling their data using the SmartData construct, which, besides encompassing means to handle the aforementioned requirements, also defines the concept of data expiry to guide scheduling decisions. With SmartData, local tasks are scheduled to produce the freshest data and to manipulate them before expiration. Likewise, network packets are scheduled prioritizing data whose expiry is close. We validate the strategy through simulations using Castalia.",data centric architecture,424
10.1049/cp.2012.1116,filtered,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),IET,2012-03-05 00:00:00,ieeexplore,design of real-time distributed system using dds,https://ieeexplore.ieee.org/document/6492723/,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,data centric architecture,425
,filtered,2019 56th ACM/IEEE Design Automation Conference (DAC),IEEE,2019-06-06 00:00:00,ieeexplore,dr. bfs: data centric breadth-first search on fpgas,https://ieeexplore.ieee.org/document/8806902/,"The flexible architectures of Field Programmable Gate Arrays (FPGAs) lend themselves to an array of data analytical applications, among which Breadth-First Search (BFS), due to its vital importance, draws particular attention. Recent attempts that omoad BFS on FPGAs either simply imitate the existing CPU- or Graphics Processing Units (GPU)based mechanisms or suffer from scalability issues. To this end, we introduce a novel data centric design which extensively extracts the potential of FPGAs for BFS with the following two techniques. First, we advocate to partition and compress the BFS algorithmic metadata in order to buffer them in fast on-chip memory and circumvent the expensive metadata access. Second, we propose a hierarchical coalescing method to improve the throughput of graph data access. Taken together, our evaluation demonstrates that the proposed design achieves, on average, 1.6× and 2.2× speedups over the state-of-the-art FPGA designs TorusBFS and Umuroglu, respectively, across a collection of graph datasets.",data centric architecture,426
10.1109/bigdata47090.2019.9006235,filtered,2019 IEEE International Conference on Big Data (Big Data),IEEE,2019-12-12 00:00:00,ieeexplore,hybrid 2d and 3d visual analytics of network simulation data,https://ieeexplore.ieee.org/document/9006235/,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,427
10.1109/isqed.2003.1194734,filtered,"Fourth International Symposium on Quality Electronic Design, 2003. Proceedings.",IEEE,2003-03-26 00:00:00,ieeexplore,interoperability beyond design: sharing knowledge between design and manufacturing,https://ieeexplore.ieee.org/document/1194734/,"The nature of IC design is necessarily evolving to a more data-centric design flow in which EDA tools share a common information in a design database without the negative cost and quality impacts of data translation from sequential files. In support of this new paradigm, a collection of mainstream companies within the IC supply chain have sponsored the development of an open industry data model and application program interface for IC design tools, along with a database that fully implements this. This technology, called OpenAccess, is now available and being adopted by the IC design community. Another industry effort is in operation with the goal of greatly improving the cost and efficiency for IC photomasks. That effort is exploring a new paradigm similar in nature to OpenAccess in that a common data model and data access language is proposed. This data model would span both the design and mask-making communities, and possibly expand into wafer fabrication over time. Thus, it has become known as the Universal Data Model (UDM). This paper discusses some of the rationale for the UDM and highlights the attributes of the OpenAccess technology that make it the ideal base on which to build an open industry UDM.",data centric architecture,428
10.1109/searis44442.2018.9180229,filtered,2018 IEEE 11th Workshop on Software Engineering and Architectures for Real-time Interactive Systems (SEARIS),IEEE,2018-03-19 00:00:00,ieeexplore,realtime interactive hybrid 2d and 3d visual analytics on large high resolution display and immersive virtual environment,https://ieeexplore.ieee.org/document/9180229/,We present a data-flow-oriented scalable and extensible visualization system for supporting hybrid 2D and 3D visual analytics. Our application allows users to visually analyze the results of a complex multivariate Monte Carlo simulation. The simulation outputs variables describing various properties of 3D objects interacting in a dynamic 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the 3D simulation in a virtual environment showing the time-varying results of the dynamics in a 3D environment. The Unity application runs on both a 2D high resolution display system and a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the 2D and 3D visualization components. Preliminary results show our data-centric design provides a user-centric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,429
10.1109/iccworkshops49005.2020.9145301,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,supporting delay tolerant networking: a comparative study of epidemic routing and ndn,https://ieeexplore.ieee.org/document/9145301/,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",data centric architecture,430
10.1109/icdew.2016.7495633,filtered,2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW),IEEE,2016-05-20 00:00:00,ieeexplore,towards a distributed multi-tier file system for cluster computing,https://ieeexplore.ieee.org/document/7495633/,"Distributed storage systems running on clusters of commodity hardware are challenged by the ever-growing data storage and I/O demands of modern large-scale data analytics. A promising trend is to exploit the recent improvements in memory, storage media, and network technologies for sustaining high performance at low cost. While recent work explores using memory and SSDs as a cache for local storage or combining local with network-attached storage, no work has ever looked at all layers together in a distributed setting. We present a novel design for a distributed file system that is aware of heterogeneous storage media (e.g., memory, SSDs, HDDs, NAS) with different capacities and performance characteristics. The storage media are explicitly exposed to users and applications, allowing them to choose the distribution and placement of replicas in the cluster based on their own performance and fault tolerance requirements. At the same time, the system offers a variety of pluggable policies for automating data management for increased performance and better cluster utilization. We analyze the new trends and challenges that led to our application- and data-centric design choices, and discuss how those choices inspire new research opportunities for data-intensive processing systems.",data centric architecture,431
10.1109/cscwd.2006.253098,filtered,2006 10th International Conference on Computer Supported Cooperative Work in Design,IEEE,2006-05-05 00:00:00,ieeexplore,universal data model platform: the data-centric evolution for system level codesign,https://ieeexplore.ieee.org/document/4019134/,"The rapidly increasing complexity of integrated circuit design is evolving to a more data-centric design scenario that supports sharing of design information. This paper presents the concepts of universal data model platform (UDMP) which introduce the data-centric design revolution into the domain of system level design to support better cooperation of individual steps in electronic design automation (EDA) industry. The goal of UDMP is to provide a set of universal data models which enables wide variety of codesign tools to be integrated tightly and revitalizes the connection between universities and the EDA industry. Furthermore, an application programming interface (API) takes the place of traditional low-bandwidth file formats to provide access to the internal data models, thus improves efficiency of design iteration. The well-constructed structure of UDMP brings some challenges for the architects as well as current system level researchers and designers. The concepts of UDMP are applied to a simplified interface synthesis flow which contains three algorithms. Primary experiment results show that these algorithms are simplified with a running time reduction by about 10% for selected designs",data centric architecture,432
10.1007/s11390-020-9781-1,filtered,Journal of Computer Science and Technology,Springer,2020-01-01 00:00:00,springer,i/o acceleration via multi-tiered data buffering and prefetching,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11390-020-9781-1,"Modern High-Performance Computing (HPC) systems are adding extra layers to the memory and storage hierarchy, named deep memory and storage hierarchy (DMSH), to increase I/O performance. New hardware technologies, such as NVMe and SSD, have been introduced in burst buffer installations to reduce the pressure for external storage and boost the burstiness of modern I/O systems. The DMSH has demonstrated its strength and potential in practice. However, each layer of DMSH is an independent heterogeneous system and data movement among more layers is significantly more complex even without considering heterogeneity. How to efficiently utilize the DMSH is a subject of research facing the HPC community. Further, accessing data with a high-throughput and low-latency is more imperative than ever. Data prefetching is a well-known technique for hiding read latency by requesting data before it is needed to move it from a high-latency medium (e.g., disk) to a low-latency one (e.g., main memory). However, existing solutions do not consider the new deep memory and storage hierarchy and also suffer from under-utilization of prefetching resources and unnecessary evictions. Additionally, existing approaches implement a client-pull model where understanding the application’s I/O behavior drives prefetching decisions. Moving towards exascale, where machines run multiple applications concurrently by accessing files in a workflow, a more data-centric approach resolves challenges such as cache pollution and redundancy. In this paper, we present the design and implementation of Hermes: a new, heterogeneous-aware, multi-tiered, dynamic, and distributed I/O buffering system. Hermes enables, manages, supervises, and, in some sense, extends I/O buffering to fully integrate into the DMSH. We introduce three novel data placement policies to efficiently utilize all layers and we present three novel techniques to perform memory, metadata, and communication management in hierarchical buffering systems. Additionally, we demonstrate the benefits of a truly hierarchical data prefetcher that adopts a server-push approach to data prefetching. Our evaluation shows that, in addition to automatic data movement through the hierarchy, Hermes can significantly accelerate I/O and outperforms by more than 2x state-of-the-art buffering platforms. Lastly, results show 10%–35% performance gains over existing prefetchers and over 50% when compared to systems with no prefetching.",data centric architecture,433
http://arxiv.org/abs/2007.11112v1,filtered,arxiv,arxiv,2020-07-21 00:00:00,arxiv,dbos: a proposal for a data-centric operating system,http://arxiv.org/abs/2007.11112v1,"Current operating systems are complex systems that were designed before
today's computing environments. This makes it difficult for them to meet the
scalability, heterogeneity, availability, and security challenges in current
cloud and parallel computing environments. To address these problems, we
propose a radically new OS design based on data-centric architecture: all
operating system state should be represented uniformly as database tables, and
operations on this state should be made via queries from otherwise stateless
tasks. This design makes it easy to scale and evolve the OS without
whole-system refactoring, inspect and debug system state, upgrade components
without downtime, manage decisions using machine learning, and implement
sophisticated security features. We discuss how a database OS (DBOS) can
improve the programmability and performance of many of today's most important
applications and propose a plan for the development of a DBOS proof of concept.",data centric architecture,434
http://arxiv.org/abs/1708.00076v1,filtered,arxiv,arxiv,2017-07-31 00:00:00,arxiv,capturing the connections: unboxing internet of things devices,http://arxiv.org/abs/1708.00076v1,"Based upon a study of how to capture data from Internet of Things (IoT)
devices, this paper explores the challenges for data centric design
ethnography. Often purchased to perform specific tasks, IoT devices exist in a
complex ecosystem. This paper describes a study that used a variety of methods
to capture the interactions an IoT device engaged in when it was first setup.
The complexity of the study that is explored through the annotated
documentation across video and router activity, presents the ethnographic
challenges that designers face in an age of connected things.",data centric architecture,435
http://arxiv.org/abs/1206.1254v1,filtered,arxiv,arxiv,2012-06-06 00:00:00,arxiv,the kilo-degree survey,http://arxiv.org/abs/1206.1254v1,"The Kilo Degree Survey (KiDS) is a 1500 square degree optical imaging survey
with the recently commissioned OmegaCAM wide-field imager on the VLT Survey
Telescope (VST). A suite of data products will be delivered to the European
Southern Observatory (ESO) and the community by the KiDS survey team. Spread
over Europe, the KiDS team uses Astro-WISE to collaborate efficiently and pool
hardware resources. In Astro-WISE the team shares, calibrates and archives all
survey data. The data-centric architectural design realizes a dynamic 'live
archive' in which new KiDS survey products of improved quality can be shared
with the team and eventually the full astronomical community in a flexible and
controllable manner.",data centric architecture,436
http://arxiv.org/abs/1112.0886v1,filtered,arxiv,arxiv,2011-12-05 00:00:00,arxiv,astro-wise for kids survey production and quality control,http://arxiv.org/abs/1112.0886v1,"The Kilo Degree Survey (KiDS) is a 1500 square degree optical imaging survey
with the recently commissioned OmegaCAM wide-field imager on the VLT Survey
Telescope (VST). A suite of data products will be delivered to ESO and the
community by the KiDS survey team. Spread over Europe, the KiDS team uses
Astro-WISE to collaborate efficiently and pool hardware resources. In
Astro-WISE the team shares, calibrates and archives all survey data. The
data-centric architectural design realizes a dynamic 'live archive' in which
new KiDS survey products of improved quality can be shared with the team and
eventually the full astronomical community in a flexible and controllable
manner",data centric architecture,437
10.1016/j.future.2021.06.020,filtered,core,'Elsevier BV',2023-06-19 00:00:00,core,a big data-centric architecture metamodel for industry 4.0,,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",data centric architecture,438
10.1016/j.jnca.2010.03.017,filtered,core,Elsevier,2010-01-01 00:00:00,core,context- and social-aware middleware for opportunistic networks,,"Opportunistic networks are multi-hop ad hoc networks in which nodes opportunistically exploit any pair-wise contact to share and forward content, without requiring any pre-existing Internet infrastructure. Opportunistic networks tolerate partitions, long disconnections, and topology instability in general. In this challenging environment, leveraging users\u27 mobility represents the most effective way to deliver content to interested users. In this paper we propose a context- and social-aware middleware that autonomically learns context and social information on the users of the network, and that uses this information in order to predict users\u27 future movements. In order to evaluate the proposed middleware on a realistic scenario, we have designed and implemented a context- and social-aware content sharing service, exploiting the functionality of the middleware. Both the middleware and the content sharing service have been integrated with an existing data-centric architecture (the Haggle architecture) for opportunistic networks. Finally, we have validated the proposed content sharing application on a small-scale testbed and, on a larger scale, we have investigated the advantages provided by context- and social-aware sharing strategies by means of extensive simulations. The main result of this paper is the definition and implementation of a context- and social-aware middleware able to share context information with all the interested components improving the efficiency and performances of services and protocols in opportunistic networks. With respect to content sharing strategies that do not exploit context and social information, we have obtained up to 200% improvements in terms of hit rate (probability that users receive the content they request) and 99% reduction in resource consumption in terms of traffic generated on the network",data centric architecture,439
10.1145/3460418.3479362,filtered,core,'Association for Computing Machinery (ACM)',2021-01-01 00:00:00,core,towards designerly data donation,,"In-The-wild research allows the HCI community to gain insights into personal behaviour and characteristics. For designers and researchers, this means having access to rich spatiotemporal insights reflecting user's characteristics, behaviours, and needs. However, designerly contexts require contextualized and meaningful data, and collecting it in-The-wild involves a great effort. In addition, ethical implications need to be considered. In this paper, we propose designerly data donation, a participatory approach for data collection in-The-wild, as an effective and ethical way to enable data-centric design processes. We present the potential benefits of designerly data donation around three axes: value gain, data contextualization, and roles and relationships. And we introduce the challenges of designerly data donation at the intersection of HCI, UbiComp, and design.Internet of ThingsIndustrial Design Engineerin",data centric architecture,440
10.2514/6.2012-549,filtered,core,,2012-01-01 00:00:00,core,towards a unified framework using cpacs for geometry management in aircraft design,,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",data centric architecture,441
10.1002/dac.2964,filtered,core,"John Wiley & Sons, Inc.",2017-01-01 00:00:00,core,push applications and dynamic content generation over content-centric networking,,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",data centric architecture,442
,filtered,core,,2012-01-01 00:00:00,core,measurements in opportunistic networks,,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",data centric architecture,443
,filtered,core,OpenSIUC,2020-05-01 00:00:00,core,design a scalable and secure ndn-based data retrieval framework for internet of things,,"Internet of Things (IoT) has great potential in enabling many beneficial applications (i.e., connected vehicle applications). Named Data Networking (NDN) recently emerges as a promising networking paradigm in supporting IoT due to its data-centric architecture. In this dissertation, we present our research on design a scalable, efficient and secure ndn-based data retrieval framework for Internet of Things. Our work includes three parts:First, we envision an NDN-based Connected Vehicles (CV) application framework with a distributed data service model, as CV is a typical scenario of IoT. The scalability of the framework is greatly challenged by the fast mobility and vast moving area of vehicles. To handle such an issue, we develop a novel hyperbolic hierarchical NDN backbone architecture (H2NDN) by exploiting the location dependency of CV applications. H2NDN designs the backbone routers topology and the data/interest namespace by following the hierarchical architecture of geographic locations. The efficient data searching only requires static forwarding information base (FIB) configuration over NDN routers. To avoid overloading high-level routers, H2NDN integrates hyperbolic routing through carefully designed hyperbolic planes.Second, a distributed adaptive caching strategy is proposed to improve the efficiency of data caches on NDN routers. NDN provides native support to cache data at routers for future Interest packets. As we model the caching problem, the goal of cache allocation is to maximize the savings of Interest/Data forwarding hops under the limited cache space on each router. We discuss the impracticality of global optimization and provide the local caching method. Extensive ndnSIM based simulation with real traffic data proves the efficiency and scalability of the proposed H2NDN architecture.Finally, although NDN provides some security advantages such as secures data directly and uses name semantics to enable applications to reason about security, employing NDN to support IoT applications nevertheless presents some new challenges about security. In this dissertation, we focus on two resultant attacks that are not effectively handled in current studies, namely the targeted blackhole attack and the targeted content poisoning attack. We propose a lightweight and efficient approach named SmartDetour to tackle the two attacks. To ensure high scalability and collusion-resilience, SmartDetour lets each router respond to attacks (i.e., packet drops or corrupted data) independently in order to isolate attackers. The core solution contains a reputation-based probabilistic forwarding strategy and a proactive attacker detection algorithm. Extensive ndnSIM based simulation demonstrates the efficiency and accuracy of the proposed SmartDetour",data centric architecture,444
,filtered,core,,2013-09-24 00:00:00,core,s.: persistent information state in a data-centric architecture,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,445
,filtered,core,,2003-01-01 00:00:00,core,a case for staged database systems,,"Traditional database system architectures face a rapidly evolving operating environment, where millions of users store and access terabytes of data. In order to cope with increasing demands for performance, high-end DBMS employ parallel processing techniques coupled with a plethora of sophisticated features. However, the widely adopted, work-centric, thread-parallel execution model entails several shortcomings that limit server performance when executing workloads with changing requirements. Moreover, the monolithic approach in DBMS software has lead to complexanddifficulttoextenddesigns. This paper introduces a staged design for high-performance, evolvable DBMS that are easy to tune and maintain. We propose to break the database system into modules and to encapsulate them into self-contained stages connected to each other through queues. The staged, data-centric design remedies the weaknesses of modern DBMS by providing solutions at both a hardware and a software engineering level. ",data centric architecture,446
,filtered,core,,2001-01-01 00:00:00,core,adaptive collaboration for wired and wireless platforms - a data-centric architecture for collaboration environments uses xml to adapt shared data dynamically between devices with widely disparate capabilities.,,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",data centric architecture,447
,filtered,core,,2009-11-19 00:00:00,core,data-centric middleware for context-aware pervasive computing,,"The complexity of developing and deploying context-aware pervasive-computing applications calls for distributed software infrastructures that assist applications to collect, aggregate, and disseminate contextual data. In this paper, we motivate a data-centric design for such an infrastructure to support context-aware applications. Our middleware system, Solar, treats contextual data sources as stream publishers and the core of Solar is a scalable and self-organizing peer-to-peer overlay to support data-driven services. We present how different services could be systematically integrated on top of the Solar overlay. We also discuss our experience and lessons learned when using Solar to support several implemented scenarios. We conclude that a data-centric infrastructure is necessary to facilitate both development and deployment of pervasive-computing applications",data centric architecture,448
,filtered,core,,2011-01-01 00:00:00,core,data serving climate simulation science at the nasa center for climate simulation,https://core.ac.uk/download/pdf/10560731.pdf,"The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",data centric architecture,449
,filtered,core,,2004-01-01 00:00:00,core,wireless sensor networks dynamic runtime configuration,,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",data centric architecture,450
,filtered,core,,2007-01-01 00:00:00,core,design and performance of dds-based middleware for real- time control systems,,"Data-centric design is emerging as a key tenet for building advanced data-critical distributed real-time and embedded systems. These systems must find the right data, know where to send it, and deliver it to the right place at the right time. Data Distribution Service (DDS) specifies an API designed for enabling real-time data distribution and is well suited for such complex distributed systems and QoS-enabled applications. It is also, widely known that Control Area Networks (CAN) are used in real-time, distributed and parallel processing. Thus, the goal idea of this paper is to study an implementation of publish-subscribe messaging middleware that supports the DDS specifications and that is customized for real-time networking. This implementation introduces an efficient approach of data temporal consistency and real-time network-scheduler that schedules network traffic based upon DDS QoS-policies. A simulator has been developed to demonstrate that our implementation fulfills the guarantees predicted by the theoretical results. Key words: Publish-Subscribe, data distribution, Real-Time Middleware",data centric architecture,451
,filtered,core,,2009-04-07 00:00:00,core,persistent information state in a data-centric architecture ∗,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,452
,filtered,core,,2014-01-01 00:00:00,core,ixa pipeline: efficient and ready to use multilingual nlp tools,,"IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It offers robust and efficient linguistic annotation to both researchers and non-NLP experts with the aim of lowering the barriers of using NLP technology either for research purposes or for small industrial developers and SMEs. IXA pipeline can be used “as is ” or exploit its modularity to pick and change different components. Given its open-source nature, it can also be modified and extended for it to work with other languages. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish",data centric architecture,453
,filtered,core,,2020-01-01 00:00:00,core,datethics:ethical data-centric design of intelligent behaviour,,"Abstract

The Internet of Things makes human activity data — what people do, how they move, how they socialise — an abundant resource. However, this rich and intimate perspective on people, which uniquely shape and characterise their behaviours, can have tremendous ethical implication if data is handled irresponsibly. Being personal, contextual and accessible, mobile devices are key facilitators of (ir)responsible collection and use of data. In this workshop, we will use the Future Workshop approach to develop a research agenda towards ethical data-centric design of intelligent behaviours. As part of this approach, we will (1) criticise the current mechanisms and infrastructure to frame ethical challenges, (2) fantasise on futures which support user and designer values, and (3) implement a research agenda for the MobileHCI community to emphasise the barriers to tackle. The outcomes of this workshop will foster ethical research and inspire the MobileHCI community",data centric architecture,454
,filtered,core,,2017-05-01 00:00:00,core,resource management in sensing services with audio applications,https://core.ac.uk/download/158321560.pdf,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",data centric architecture,455
,filtered,core,,2012-05-19 00:00:00,core,1 social-driven internet of connected objects,,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",data centric architecture,456
,filtered,core,,2007-01-01 00:00:00,core,gestion de l'évolution des applications web,,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",data centric architecture,457
,filtered,core,,2015-08-26 00:00:00,core,adaptive collaboration for wired and wireless platforms,,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",data centric architecture,458
,filtered,core,"eScholarship, University of California",2020-01-01 00:00:00,core,the cloud is not enough: saving iot from the cloud,,"© USENIX Workshop on Hot Topics in Storage and File Systems, HotStorage 2015.All right reserved. The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, the current approach of directly connecting smart devices to the cloud has a number of disadvantages and is unlikely to keep up with either the growing speed of the IoT or the diverse needs of IoT applications. In this paper we explore these disadvantages and argue that fundamental properties of the IoT prevent the current approach from scaling. What is missing is a wellarchitected system that extends the functionality of the cloud and provides seamless interplay among the heterogeneous components in the IoT space. We argue that raising the level of abstraction to a data-centric design-focused around the distribution, preservation and protection of information-provides a much better match to the IoT. We present early work on such a distributed platform, called the Global Data Plane (GDP), and discuss how it addresses the problems with the cloud-centric architecture",data centric architecture,459
,filtered,core,,2009-08-31 00:00:00,core,a context-oriented synchronization approach,,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",data centric architecture,460
,filtered,core,HAL CCSD,2017-03-27 00:00:00,core,towards blockchain-based auditable storage and sharing of iot data,https://core.ac.uk/download/145154055.pdf,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",data centric architecture,461
,filtered,core,,2018-01-01 00:00:00,core,collaborative systems engineering in the ascent abort-2 crew module/separation ring project,https://core.ac.uk/download/pdf/161999682.pdf,"Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",data centric architecture,462
,filtered,core,"eScholarship, University of California",2016-05-01 00:00:00,core,toward a global data infrastructure,,"The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, directly connecting smart devices to the cloud has multiple disadvantages and is unlikely to keep up with the growing speed of the IoT or the diverse needs of IoT applications. Here, the authors argue that fundamental IoT properties prevent the current approach from scaling. What's missing is a well-architected system extending cloud functionality and providing seamless interplay among heterogeneous components closer to the edge in the IoT space. Raising the level of abstraction to a data-centric design-focused around the distribution, preservation, and protection of information-better matches the IoT. To address such problems with the cloud-centric architecture, the authors present their early work on a distributed platform, the Global Data Plane",data centric architecture,463
,filtered,core,DigitalCommons@USU,2009-08-12 00:00:00,core,plug and play spacecraft evolution,https://core.ac.uk/download/32550735.pdf,"The space community, led by AFRL, started developing spacecraft plug and play concepts and standards in 2004 and has resulted in the Space Plug and play Avionics (SPA) Standards. AFRL has undertaken two efforts in small satellite development to both solidify the technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) utilizes the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. The second effort is PnPSat-2 that uses the next generation of SPA components for a larger bus focused on ORS needs to make real the promise of custom performance at commodity prices. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insolates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in test time. This paper will present the steps used in designing, building, and testing SPA PnP satellites and the current status of PnPSat and PnPSat-2",data centric architecture,464
,filtered,core,"DCOS, a real-time light-weight Data Centric Operating System",2004-01-01 00:00:00,core,https://core.ac.uk/download/pdf/11461067.pdf,,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",data driven architecture,465
,filtered,core,"DCOS, a Real-Time Light-weight Data Centric Operating System",2004-01-01 00:00:00,core,https://core.ac.uk/download/pdf/11458862.pdf,,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",data driven architecture,466
a6777903dbfc256b551043f93ebbb13fa923d2d1,filtered,semantic_scholar,Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003),2003-01-01,semantic_scholar,mobishare: sharing context-dependent data & services from mobile sources,https://www.semanticscholar.org/paper/a6777903dbfc256b551043f93ebbb13fa923d2d1,"The rapid advances in wireless communications technology and mobile computing have enabled personal mobile devices that we use in everyday life to become information and service providers by complementing or replacing fixed-location hosts connected to the wireline network. Such mobile resources is highly important for other moving users, creating significant opportunities for many interesting and novel applications. The MobiShare architecture provides the infrastructure for ubiquitous mobile access and mechanisms for publishing, discovering and accessing heterogeneous mobile resources in a large area, taking into account the context of both sources and requestors. Any wireless communication technology could be used between a device and the system. Furthermore, the use of XML-related languages and protocols for describing and exchanging metadata gives the system a uniform and easily adaptable interface, allowing a variety of devices to use it. The overall approach is data-centric and service-oriented, implying that all devices are treated as producers or requestors of data wrapped as information services.",data oriented architecture,467
1dc441e8284099a7873fa22a62ff8f35b6957b06,filtered,semantic_scholar,,1995-01-01,semantic_scholar,object solutions: managing the object-oriented project,https://www.semanticscholar.org/paper/1dc441e8284099a7873fa22a62ff8f35b6957b06,"1. First Principles. When Bad Things Happen to Good Projects. Establishing a Project's Focus. Understanding a Project's Culture. The Five Habits of Successful Object-Oriented Projects. Issues in Managing Object-Oriented Projects. 2. Products and Process. In Search of Excellent Objects. Object-Oriented Architectures. The Artifacts of a Software Project. Establishing a Rational Design Process. 3. The Macro Process. The One Minute Methodology. Conceptualization. Analysis. Design. Evolution. Maintenance. 4. The Micro Process. I'm OK, My Program's OK. Identifying Classes and Objects. Identifying the Semantics of Classes and Objects. Identifying Relationships Among Classes and Objects. Implementing Classes and Objects. 5. The Development Team. Managers Who Hate Programmers, and the Programmers. Who Work For Them. Roles and Responsibilities. Resource Allocation. Technology Transfer. Tools for the Worker. 6. Management and Planning. Everything I Need to Know I'll Learn In My Next Project. Managing Risk. Planning and Scheduling. Costing and Staffing. Monitoring, Measuring, and Testing. Documenting. Projects in Crisis. 7. Special Topics. What They Don't Teach You in Programming Class. User-Centric Systems. Data-Centric Systems. Computation-Centric Systems. Distributed Systems. Legacy Systems. Information Management Systems. Real Time Systems. Frameworks. Epilogue. Summary of Recommended Practices. Summary of Rules of Thumb. Glossary. Bibliography. Index. 0805305947T04062001",data oriented architecture,468
6f6d9eb8db4b902870cff6f3c0927c2bcc137a40,filtered,semantic_scholar,2016 IEEE International Conference on Web Services (ICWS),2014-01-01,semantic_scholar,privacy preserving access control in service-oriented architecture,https://www.semanticscholar.org/paper/6f6d9eb8db4b902870cff6f3c0927c2bcc137a40,"Service-oriented Architecture (SOA) comprises a number of loosely-coupled independent services, which collaborate, interact and share data to accomplish incoming requests. A service invocation can involve multiple services, where each service accesses, processes and shares the client's data. These interactions may share data with unauthorized services and violate client's privacy. The client has no means of identifying if a violation occurred because it has no control over the service invocations beyond its trust domain. Such interactions introduce new security challenges which are not present in traditional systems. This paper proposes a data-centric approach for privacy preserving access control in SOA. Benefits of the proposed approach include the ability to dynamically define access polices by the clients and control data access at the time of each service interaction. A realistic healthcare scenario is used to evaluate the implementation of the proposed solution which validates its viability.",data oriented architecture,469
fc98ec63ffb5811fc6828dfea5b6e7423d3e186e,filtered,semantic_scholar,2010 IEEE International Conference on Web Services,2010-01-01,semantic_scholar,formal specification and verification of data-centric service composition,https://www.semanticscholar.org/paper/fc98ec63ffb5811fc6828dfea5b6e7423d3e186e,Service-oriented architecture (SOA) promotes a paradigm where ad-hoc applications are built by dynamically linking service-based software capabilities. Service providers follow specification standards to advertise their services’ capabilities and to enable loosely coupled integration between their services and other businesses over the Web. A major challenge in this domain is interpreting the data that must be marshaled between consumer and producer systems. We propose a framework to support formal modeling and contracts for data-centric Web services. We demonstrate how this framework can be used to verify correctness properties for composition of services.,data oriented architecture,470
b7e9d9e07425dc94dc6e0401277c7252f1d29629,filtered,semantic_scholar,BCS Int. Acad. Conf.,2010-01-01,semantic_scholar,a vision of the next generation internet: a policy oriented perspective,https://www.semanticscholar.org/paper/b7e9d9e07425dc94dc6e0401277c7252f1d29629,"The host centric design of the current Internet does not recognize data and end-users as integral entities of the system. The first generation of Internet has been very successful and yet business, organizations, governments are finding it difficult to enforce their policies on their networks with the same ease that they do other methods of communications and transport. Ad-Hoc solutions e.g. firewalls, NAT, middle boxes etc, that tries to mitigate these issues end up providing localized myopic fixes which often hurt the basic underlying principles of the original design. The current Internet usage is “data centric” as evidenced by the popularity of the peer-to-peer applications. Data centric view abstracts a data requestor from having to know where the data comes from. We envision the future internet to be a dynamic, heterogeneous, secure, energy efficient omnipresent network flexible enough to support innovations and policy enforcements both at the edge and the core. The first step towards the next generation is the redesign of naming and name binding mechanisms. We, therefore, propose a Policy Oriented Network Architecture (PONA) and an abstract two part protocol stack with a virtualization layer in between. PONA provides a generic architecture which allows us to implement datacentric, host-centric, and user-centric Internet architecture. We also introduce the concept of generalized communication end-points – hosts, users, data/services, instantiate the ideas with the Mapping and Negotiation layer and provide an integrated framework for the next generation Internet. Both new Internets hope to develop new, faster technologies to enhance research and communication, and it is expected that both projects will eventually improve the current commercial Internet.",data oriented architecture,471
9a3c2b7322481ed915ea8fa8116c08226a69ee8c,filtered,semantic_scholar,,2007-01-01,semantic_scholar,service oriented architecture for geographic information systems supporting real time data grids,https://www.semanticscholar.org/paper/9a3c2b7322481ed915ea8fa8116c08226a69ee8c,"Advances in distributed systems and universal adoption of the Internet helped academia, governments and industry to gain access to substantial amount of data, including geospatial data. Geographic Information Systems which are traditionally known to be highly data-centric are one of the important consumers of these data products. However several significant problems such as different types of distributed geophysical applications, and distributed nature of the geospatial data sources cause severe limitations for seamless integration of data and applications. Additionally proliferation of sensors introduces unique challenges for Geographic Information Systems because the observations and measurements obtained from a wide variety of sensors are of great interest to these systems. 
In this dissertation we propose and evaluate a Service Oriented Architecture for seamless coupling of real-time and non-real time geographic data with scientific geospatial applications. We describe necessary principles and service features for accessing both data types and outline Data Grid architecture to address these requirements. We describe various methods for improving the performance of our Web Services such as adoption of Binary XML Frameworks and integration of a message oriented middleware for streaming the responses. We introduce a novel approach to map Geography Markup Language (GML) based XML queries to relational database queries. We evaluate the performance and usefulness of our approach in several real-world applications such as earthquake science tools and real-time GPS streams.",data oriented architecture,472
48f1fab7e589582ebd360a0f5bd4a6b7aa481e7c,filtered,semantic_scholar,SAC,2017-01-01,semantic_scholar,from iot big data to iot big services,https://www.semanticscholar.org/paper/48f1fab7e589582ebd360a0f5bd4a6b7aa481e7c,"The large-scale deployments of Internet of Things (IoT) systems have introduced several new challenges in terms of processing their data. The massive amount of IoT-generated data requires design solutions to speed up data processing, scale up with the data volume and improve data adaptability and extensibility. Beyond existing techniques for IoT data collection, filtering, and analytics, innovative service computing technologies are required for provisioning data-centric and scalable IoT services. This paper presents a service-oriented design model and framework for realizing scalable and efficient acquisition, processing and integration of data-centric IoT services. In this approach, data-centric IoT services are organized in a service integrating tree structure, adhering to the architecture of many large-scale IoT systems, including recent fog-based IoT computing models. A service node in the tree is called a Big Service and acts as an integrator, collecting data from lower level Big Services, processing them, and delivering the result to higher level IoT Big Services. The service tree thereby encapsulates required data processing functions in a hierarchical manner in order to achieve scalable and real-time data collection and processing. We have implemented the IoT Big Services framework leveraging a popular cloud-based service and data platform called Firebase, and evaluated its performance in terms of real-time requirements.",data oriented architecture,473
55c3b1c1925e2f1dc36d2c2778539e350ecd3a12,filtered,semantic_scholar,,2009-01-01,semantic_scholar,a dds based framework for remote integration over the internet,https://www.semanticscholar.org/paper/55c3b1c1925e2f1dc36d2c2778539e350ecd3a12,"A framework is developed to allow multiple development teams to collaborate over the Internet on the development, integration and testing of complex system. The proposed framework is based on the Service Oriented Architecture concept and implemented in the form of data-centric publisher/subscriber architecture, employing Data Distribution Service middleware (DDS) for communications. A prototype realization of the proposed framework has been developed using a Process Control Unit rig. In the prototype, embedded real time software has been developed. Before being delivered to the integrator of the rig or a central service, the embedded software remains at the developer’s facility and has been remotely integrated and tested with operational software running in the PCU rig located remotely from the software developer. This paper presents the adopted software architecture and the middleware and rig employed to realize the framework prototype. Basic functionality for remote integration and testing is also described in the paper.",data oriented architecture,474
9392cc3705592c58ce0ff56e407f006d33d4bb25,filtered,semantic_scholar,,2005-01-01,semantic_scholar,business process management systems: strategy and implementation,https://www.semanticscholar.org/paper/9392cc3705592c58ce0ff56e407f006d33d4bb25,"Theories of Process Management What is Process Management? Early Process Concepts Modern Process Management Theories Total Quality Management Movement (TQM) Six Sigma Business Process Reengineering (BPR) Comparing Business Process Reengineering (BPR), Total Quality Management (TQM), and Six Sigma Business Process Management Business Process Management (BPM) Concepts Business Process Management (BPM) Principles Business Process Management (BPM) Practices The Value of Information Technology (IT) Convergence of Process-Focused Management Practices Process Management Lifecycle Overview of Business Process Management System Key Capabilities of Business Process Management Systems (BPMS) Introduction of the Process Layer How Business Process Management Systems (BPMS) Can Benefit Business Process Reengineering (BPR) Initiatives How Business Process Management (BPM) Can Benefit Quality Programs Data Integration Technology Open Database Connectivity (ODBC) Object Linking & Embedding Database (OLE DB) Java Database Connectivity (JDBC) Messaging-Based Integration Technology Point-to-Point Messaging Process Component-Based Integration Technology Remote Procedure Call (RPC) The Shift Toward Object-Oriented Programming Advent of Component-Based Technology Common Object Request Broker Architecture (CORBA) Microsoft Component Technologies Java Component Technologies Summary Workflow Technology Different Types of Workflows Workflow Reference Model Differences Between Workflow Management System (WfMS) and Business Process Management System (BPMS) Different Types of Business Process Management Systems Types of Business Process Management System (BPMS) Process Data-Centric Integration Product Application-Centric Integration Products Process-Centric Integration Product Future BPMS Developments Business Process Management Systems (BPMS) Standards Development of Business Process Management System (BPMS) Standards Overview of the Process Definition Standards Comparing XML Process Definition Language (XPDL), Business Process Modeling Language (BPML), and Business Process Execution Language (BPEL) Overview of Process Interaction Standards Summary Business Process Management Implementation Methodology Lessons from Business Process Reengineering (BPR) Business Process Management (BPM) Implementation Methodology Phase 1 Commit Phase 2 Research Phase 3 Analyze Phase 4 Design Phase 5 Implement Phase 6 Support Conclusion",data oriented architecture,475
3b6b3b6130fab33eb067e8efbff2d1b519c5be0a,filtered,semantic_scholar,ICSR,2009-01-01,semantic_scholar,"formal foundations of reuse and domain engineering, 11th international conference on software reuse, icsr 2009, falls church, va, usa, september 27-30, 2009. proceedings",https://www.semanticscholar.org/paper/3b6b3b6130fab33eb067e8efbff2d1b519c5be0a,Component Reuse and Verification.- Consistency Checking for Component Reuse in Open Systems.- Generating Verified Java Components through RESOLVE.- Increasing Reuse in Component Models through Genericity.- Verifying Component-Based Software: Deep Mathematics or Simple Bookkeeping?.- Feature Modeling.- Extending FeatuRSEB with Concepts from Systems Engineering.- Features Need Stories.- An Optimization Strategy to Feature Models' Verification by Eliminating Verification-Irrelevant Features and Constraints.- Reusable Model-Based Testing.- Generators and Model-Driven Development.- A Case Study of Using Domain Engineering for the Conflation Algorithms Domain.- Model Transformation Using Graph Transactions.- Refactoring Feature Modules.- Variability in Automation System Models.- Industry Experience.- A Case Study of Variation Mechanism in an Industrial Product Line.- Experience Report on Using a Domain Model-Based Extractive Approach to Software Product Line Asset Development.- Reuse with Software Components - A Survey of Industrial State of Practice.- Product Lines.- Evaluating the Reusability of Product-Line Software Fault Tree Analysis Assets for a Safety-Critical System.- Feature-Driven and Incremental Variability Generalization in Software Product Line.- Identifying Issues and Concerns in Software Reuse in Software Product Lines.- Reuse of Architectural Knowledge in SPL Development.- Reuse and Patterns.- Introducing Motivations in Design Pattern Representation.- The Managed Adapter Pattern: Facilitating Glue Code Generation for Component Reuse.- Reusing Patterns through Design Refinement.- Service-Oriented Environments.- Building Service-Oriented User Agents Using a Software Product Line Approach.- DAREonline: A Web-Based Domain Engineering Tool.- Extending a Software Component Repository to Provide Services.- A Negotiation Framework for Service-Oriented Product Line Development.- Ranking and Selecting Services.- A Reusable Model for Data-Centric Web Services.,data oriented architecture,476
7b83ec88425d41b5ee08ff4072d5c80c5703bf30,filtered,semantic_scholar,,2008-01-01,semantic_scholar,"delft fews: a proven infrastructure to bring data, sensors and models together",https://www.semanticscholar.org/paper/7b83ec88425d41b5ee08ff4072d5c80c5703bf30,"Delft FEWS is a proven real time software infrastructure for operational water management and forecasting, having been applied in several operational forecasting centres all over the world. The system has contributed to changing the paradigm of flood forecasting systems from a model centric approach to a data centric approach. The system is a time series oriented ETL-infrastructure (Extract, Transfer, Load) with the ultimate aim to provide the forecaster with relevant information in support of the operational process of flood forecasting and warning. Key to its success is the design choice for separation of data communication protocols from the content, as well as its openness to integration of other applications and data. While keeping its focus on its core tasks, the design concept has allowed the system to evolve from a stand alone application, through a client-server concept into a (web) service oriented architecture. Continued research is ongoing to explore new technologies and turn these into operational features available to operational forecasters. This paper will highlight some of our experiences in system design to combine real time data with models.",data oriented architecture,477
a1c9e2be63ed7f293ec27b260d2f9e60e57fd626,filtered,semantic_scholar,2016 IEEE Trustcom/BigDataSE/ISPA,2016-01-01,semantic_scholar,what if routers are malicious? mitigating content poisoning attack in ndn,https://www.semanticscholar.org/paper/a1c9e2be63ed7f293ec27b260d2f9e60e57fd626,"Named data networking (NDN) shifts today's host-centric Internet architecture to a new data-centric network architecture. This well suits the increasingly mobile and information-intensive applications that dominate today's Internet. NDN allows routers to cache named content, leading to a significant improvement of content retrieval which, however, opens a door for many new attacks. In this work, we focus on content poisoning attack, the content poisoned by an attacker will be cached and propagated in the NDN network. Existing solutions unfortunately cannot work when the NDN routers are compromised by attackers. We propose ROM, the Router-Oriented Mitigation of content poisoning attack in NDN, offering security guarantees even when the routers are malicious. ROM defends against content poisoning attack by temporarily excluding the malicious routers from transmission path, eliminating (or significantly reducing) the possibility that the content will be poisoned during transmission. However, localizing malicious routers in NDN is very challenging due to NDN's distributed nature and the lack of global identifiers. We attack this issue from a new angle. We introduce reputation for each NDN router, and forward content based on the reputation. A router with a better reputation will be more likely honest and has a higher probability to be included into the transmission path. In addition, we design a novel mechanism to quantify the reputation value by utilizing our unique observations for NDN. Security analysis and simulations performed in ndnSIM demonstrate that ROM can mitigate the content poisoning attack with high efficiency and excellent accuracy.",data oriented architecture,478
1b7febba27b45a71123ac45717a1ad98bff0786f,filtered,semantic_scholar,SPLASH '12,2012-01-01,semantic_scholar,"the data, context and interaction paradigm",https://www.semanticscholar.org/paper/1b7febba27b45a71123ac45717a1ad98bff0786f,"This is a design track overview tutorial that provides a foundation for exploring and applying the DCI (Data, Context and Interaction) paradigm. DCI is a means to supporting full object orientation that restores much of the original object vision that has been lost by class-based design and programming. DCI focuses on objects and their relationships to the roles of human mental models by which end users and programmers reason about them generally. DCI leads to an architecture that extends contemporary object-oriented programming from its data-centric structure to focus more on the business value of system-level operations.",data oriented architecture,479
2aadf23ee913f55b502f65f9109659bada43b9cb,filtered,semantic_scholar,,2008-01-01,semantic_scholar,temporal and modal logic based event languages for the development of reac-tive application systems,https://www.semanticscholar.org/paper/2aadf23ee913f55b502f65f9109659bada43b9cb,"The Future Internet is one of the key techniques to support the organizational processes in a reactive way. The Internet itself has developed from a mere data-centric organization into a platform for applications (services). To orchestrate the multiplicity of services in the Internet an eventdriven and language-critical architecture is needed. Moreover a simple boolean logic just differentiating the states true and wrong is not sufficient to cope with the diversity of events. States of applications in the Future Internet are time dependent and logic dealing with these problems needs to be extended in the directions of temporal logic and modal logic. Moreover existing architectures have to be extended to be able to handle events effectively. Hence, the extension of service-oriented architectures to event-driven, reactive architectures is a necessary step. To perform this task IT-experts with an interdisciplinary background are needed.",data oriented architecture,480
53511327568e7f6271acf17ba3d7432725adfccb,filtered,semantic_scholar,"2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)",2012-01-01,semantic_scholar,decentralized orchestration of data-centric workflows using the object modeling system,https://www.semanticscholar.org/paper/53511327568e7f6271acf17ba3d7432725adfccb,"Data-centric and service-oriented workflows are commonly used in scientific research to enable the composition and execution of complex analysis on distributed resources. Although there are a plethora of orchestration frameworks to implement workflows, most of them are not suitable to execute data-centric workflows. The main issue is transferring output of service invocations through a centralized orchestration engine to the next service in the workflow, which can be a bottleneck for the performance of a data-centric workflow. In this paper, we propose a flexible and lightweight workflow framework based on the Object Modeling Systems (OMS). Moreover, we take advantage of the OMS architecture to deploy and execute data-centric workflows in a decentralized manner to avoid passing through the centralized engine. The proposed framework is implemented in context of the Australian Urban Research Infrastructure Network (AURIN) project which is an initiative aiming to develop an e-Infrastructure supporting research in the urban and built environment research disciplines. Performance evaluation results using spatial data-centric workflows show that we can reduce 20% of the workflows execution time while using Cloud resources in the same network domain.",data oriented architecture,481
eac74f4ee61fd9e69163b96c0b64710b9ed13a04,filtered,semantic_scholar,,2009-01-01,semantic_scholar,beautiful architecture: leading thinkers reveal the hidden beauty in software design,https://www.semanticscholar.org/paper/eac74f4ee61fd9e69163b96c0b64710b9ed13a04,"What are the ingredients of robust, elegant, flexible, and maintainable software architecture? Beautiful Architecture answers this question through a collection of intriguing essays from more than a dozen of today's leading software designers and architects. In each essay, contributors present a notable software architecture, and analyze what makes it innovative and ideal for its purpose. Some of the engineers in this book reveal how they developed a specific project, including decisions they faced and tradeoffs they made. Others take a step back to investigate how certain architectural aspects have influenced computing as a whole. With this book, you'll discover: How Facebook's architecture is the basis for a data-centric application ecosystem The effect of Xen's well-designed architecture on the way operating systems evolve How community processes within the KDE project help software architectures evolve from rough sketches to beautiful systems How creeping featurism has helped GNU Emacs gain unanticipated functionality The magic behind the Jikes RVM self-optimizable, self-hosting runtime Design choices and building blocks that made Tandem the choice platform in high-availability environments for over two decades Differences and similarities between object-oriented and functional architectural views How architectures can affect the software's evolution and the developers' engagement Go behind the scenes to learn what it takes to design elegant software architecture, and how it can shape the way you approach your own projects, with Beautiful Architecture.",data oriented architecture,482
39ebeb0168c05a79d1e3e4603437c35818d2c60c,filtered,semantic_scholar,SIGMOD '07,2007-01-01,semantic_scholar,an in-depth look at the architecture of an object/relational mapper,https://www.semanticscholar.org/paper/39ebeb0168c05a79d1e3e4603437c35818d2c60c,"Object/relational mapping (ORM) tools can deliver a number of benefits to object-oriented, data-centric applications. These benefits are usually artifacts of the implementation of the tool used for the mapping, and not of the ORM paradigm itself. We will examine some of the significant features that the Kodo[1] ORM implementation delivers, by looking at the architecture of Kodo to see the source of these features.",data oriented architecture,483
e75423dc5514e84cd2241c135a14f3ad12fe1345,filtered,semantic_scholar,2009 IEEE International Conference on Services Computing,2009-01-01,semantic_scholar,towards a unified approach for business process modeling using context-based artifacts and web services,https://www.semanticscholar.org/paper/e75423dc5514e84cd2241c135a14f3ad12fe1345,"Service-Oriented Architecture is a paradigm for modeling and enacting business processes that promotes improved flexibility and monitor ability through the composition of loosely-coupled Web services. However, such process-centric composition, with focus on invoking Web services to reach a stated goal, still does not provide the desired flexibility. Web services implementations are typically locked into the business logic of the business processes that they implement. Additionally,monitoring such Web services compositions becomes cumbersome especially for business analysts and managers who are not IT experts. To address these issues, this paper presents a unified process- and data-centric approach with focus on Web services as a driving element to the changes affecting both processes and data. In this approach a business process is modeled as a collection of interacting (business) artifacts, each of which behaves as per a predefined state transition system called Artifact Life-Cycle (ALC). An ALC is enriched with contextual details, which permits business process execution monitoring. Throughout this paper, a realistic running example in the purchase order domain is used for illustration purposes.",data oriented architecture,484
812554e4d2acc415824c8a238bd8a092f21b7c31,filtered,semantic_scholar,APWeb/WAIM,2007-01-01,semantic_scholar,"advances in data and web management, joint 9th asia-pacific web conference, apweb 2007, and 8th international conference, on web-age information management, waim 2007, huang shan, china, june 16-18, 2007, proceedings",https://www.semanticscholar.org/paper/812554e4d2acc415824c8a238bd8a092f21b7c31,"Keynote.- Data Mining Using Fractals and Power Laws.- Exploring the Power of Links in Data Mining.- Community Systems: The World Online.- A New DBMS Architecture for DB-IR Integration.- Invited Paper.- Study on Efficiency and Effectiveness of KSORD.- Discovering Web Services Based on Probabilistic Latent Factor Model.- SCORE: Symbiotic Context Oriented Information Retrieval.- Process Aware Information Systems: A Human Centered Perspective.- Data Mining and Knowledge Discovery I.- IMCS: Incremental Mining of Closed Sequential Patterns.- Mining Time-Shifting Co-regulation Patterns from Gene Expression Data.- Tight Correlated Item Sets and Their Efficient Discovery.- Information Retrieval I.- Improved Prediction of Protein Secondary Structures Using Adaptively Weighted Profiles.- Framework for Building a High-Quality Web Page Collection Considering Page Group Structure.- Multi-document Summarization Using Weighted Similarity Between Topic and Clustering-Based Non-negative Semantic Feature.- A Fair Load Balancing Algorithm for Hypercube-Based DHT Networks.- LINP: Supporting Similarity Search in Unstructured Peer-to-Peer Networks.- Generation and Matching of Ontology Data for the Semantic Web in a Peer-to-Peer Framework.- Energy-Efficient Skyline Queries over Sensor Network Using Mapped Skyline Filters.- An Adaptive Dynamic Cluster-Based Protocol for Target Tracking in Wireless Sensor Networks.- Distributed, Hierarchical Clustering and Summarization in Sensor Networks.- Spatial and Temporal Databases I.- A New Similarity Measure for Near Duplicate Video Clip Detection.- Efficient Algorithms for Historical Continuous kNN Query Processing over Moving Object Trajectories.- Effective Density Queries for Moving Objects in Road Networks.- An Efficient Spatial Search Method Based on SG-Tree.- Getting Qualified Answers for Aggregate Queries in Spatio-temporal Databases.- Dynamic Adaptation Strategies for Long-Term and Short-Term User Profile to Personalize Search.- Using Structured Tokens to Identify Webpages for Data Extraction.- Honto? Search: Estimating Trustworthiness of Web Information by Search Results Aggregation and Temporal Analysis.- A Probabilistic Reasoning Approach for Discovering Web Crawler Sessions.- An Exhaustive and Edge-Removal Algorithm to Find Cores in Implicit Communities.- XML and Semi-structured Data I.- Active Rules Termination Analysis Through Conditional Formula Containing Updatable Variable.- Computing Repairs for Inconsistent XML Document Using Chase.- An XML Publish/Subscribe Algorithm Implemented by Relational Operators.- Retrieving Arbitrary XML Fragments from Structured Peer-to-Peer Networks.- Data Mining and Knowledge Discovery II.- Combining Smooth Graphs with Semi-supervised Learning.- Extracting Trend of Time Series Based on Improved Empirical Mode Decomposition Method.- Spectral Edit Distance Method for Image Clustering.- Mining Invisible Tasks from Event Logs.- The Selection of Tunable DBMS Resources Using the Incremental/Decremental Relationship.- Hyperclique Pattern Based Off-Topic Detection.- An Energy Efficient Connected Coverage Protocol in Wireless Sensor Networks.- A Clustered Routing Protocol with Distributed Intrusion Detection for Wireless Sensor Networks.- Continuous Approximate Window Queries in Wireless Sensor Networks.- A Survey of Job Scheduling in Grids.- Relational Nested Optional Join for Efficient Semantic Web Query Processing.- Efficient Processing of Relational Queries with Sum Constraints.- A Theoretical Framework of Natural Computing - M Good Lattice Points (GLP) Method.- Building Data Synopses Within a Known Maximum Error Bound.- Exploiting the Structure of Update Fragments for Efficient XML Index Maintenance.- Information Retrieval II.- Improvements of HITS Algorithms for Spam Links.- Efficient Keyword Search over Data-Centric XML Documents.- Promotional Ranking of Search Engine Results: Giving New Web Pages a Chance to Prove Their Values.- Adaptive Scheduling Strategy for Data Stream Management System.- A QoS-Guaranteeing Scheduling Algorithm for Continuous Queries over Streams.- A Simple But Effective Event-Driven Model for Data Stream Queries.- Spatial and Temporal Databases II.- Efficient Difference NN Queries for Moving Objects.- APCAS: An Approximate Approach to Adaptively Segment Time Series Stream.- Continuous k-Nearest Neighbor Search Under Mobile Environment.- Record Extraction Based on User Feedback and Document Selection.- Density Analysis of Winnowing on Non-uniform Distributions.- Error-Based Collaborative Filtering Algorithm for Top-N Recommendation.- A PLSA-Based Approach for Building User Profile and Implementing Personalized Recommendation.- CoXML: A Cooperative XML Query Answering System.- Concept-Based Query Transformation Based on Semantic Centrality in Semantic Peer-to-Peer Environment.- Mining Infrequently-Accessed File Correlations in Distributed File System.- Learning-Based Trust Model for Optimization of Selecting Web Services.- SeCED-FS: A New Approach for the Classification and Discovery of Significant Regions in Medical Images.- Context-Aware Search Inside e-Learning Materials Using Textbook Ontologies.- Activate Interaction Relationships Between Students Acceptance Behavior and E-Learning.- Semantic-Based Grouping of Search Engine Results Using WordNet.- XML and Semi-structured Data II.- Static Verification of Access Control Model for AXML Documents.- SAM: An Efficient Algorithm for F&B-Index Construction.- BUXMiner: An Efficient Bottom-Up Approach to Mining XML Query Patterns.- A Web Service Architecture for Bidirectional XML Updating.- (?, k)-anonymity Based Privacy Preservation by Lossy Join.- Achieving k-Anonymity Via a Density-Based Clustering Method.- k-Anonymization Without Q-S Associations.- Protecting and Recovering Database Systems Continuously.- Towards Web Services Composition Based on the Mining and Reasoning of Their Causal Relationships.- A Dynamically Adjustable Rule Engine for Agile Business Computing Environments.- A Formal Design of Web Community Interactivity.- Towards a Type-2 Fuzzy Description Logic for Semantic Search Engine.- A Type-Based Analysis for Verifying Web Application.- Homomorphism Resolving of XPath Trees Based on Automata.- An Efficient Overlay Multicast Routing Algorithm for Real-Time Multimedia Applications.- Novel NonGaussianity Measure Based BSS Algorithm for Dependent Signals.- HiBO: Mining Web's Favorites.- Frequent Variable Sets Based Clustering for Artificial Neural Networks Particle Classification.- Attributes Reduction Based on GA-CFS Method.- Towards High Performance and High Availability Clusters of Archived Stream.- Continuously Matching Episode Rules for Predicting Future Events over Event Streams.",data oriented architecture,485
5ba2e118976869e0833e2c79b11847b6e658f27b,filtered,semantic_scholar,2012 International Conference on Recent Advances in Computing and Software Systems,2012-01-01,semantic_scholar,comparative study of middleware for c4i systems web services vis-à-vis data distribution service,https://www.semanticscholar.org/paper/5ba2e118976869e0833e2c79b11847b6e658f27b,"The Command, Control, Communications, Computer and Intelligence (C4I) systems provide battlefield information for the commanders to make decisions, and to control the military forces to accomplish missions. These systems were based on static architectures to ensure high dependability, support for real-time constraints and were mission specific. However, these systems lacked the dynamic features provided by recent advances in information technology. C4I systems require that both the feature sets of static and dynamic approaches be made available to ensure dependability, real-time support, facilitating reusability and interoperability. Web Services based on the Service Oriented Architecture (SOA) is the most popular middleware used in Enterprises today. Another middleware which is becoming popular is Data Distribution Service (DDS) based on Data-Centric Publish Subscribe Infrastructure. Recent advances in both the approaches have made them competitive for implementation in C4I systems for integrating its elements. Both the approaches need to be evaluated considering the system requirements of military communications. This paper carries out a comparative study of the two middleware solutions for integrating C4I system of a weapon system deployed in modern battlefields. In this paper, we present possible solutions and remaining challenges on the way towards realizing seamless information exchange for a weapon system.",data oriented architecture,486
b334e4834323556d4c5c9d9072c5063f693f40b0,filtered,semantic_scholar,2012 IEEE Global Communications Conference (GLOBECOM),2012-01-01,semantic_scholar,content-based route lookup using cams,https://www.semanticscholar.org/paper/b334e4834323556d4c5c9d9072c5063f693f40b0,"The applications of the Internet have evolved from being host-centric to being more content-oriented, such as file sharing, online audio and video applications, which constitute the majority of Internet traffic [1]. Several future Internet architectures, putting the content (or information) in the fore-front, have lately been proposed in order to solve the limitations of the current architecture (i.e. insufficient bandwidth to servers, lack of security, mobility, virtualization, user/data centricity, etc.). However, one of the greatest challenges of a novel content-oriented Internet architecture lies in the complexity of looking up long, variable length names compared to the current 32 bit long IPv4 (or even 128 bit IPv6) addresses of today's networks. The success of widely adopting any content-oriented architecture highly depends on the success of designing algorithms that allow these complex names to be looked up at high-speed. Ternary Content Addressable Memories (TCAMs) are widely used in high-speed routers to find matching routes for packets in a routing table. They enable the longest prefix matching (LPM) operation on fixed length addresses to complete in a single clock cycle, however, they are not efficient to store and lookup name prefixes with variable lengths such as the ones proposed in name-based routing [2]–[9]. In this paper, we propose an efficient name-based longest prefix matching algorithm for information-centric networks using TCAMs. In our algorithm, we split incoming prefixes in fixed blocks and subsequently hash these blocks for fixed length storage. Our approach is flexible to support both hierarchical name based routing lookup and flat name based routing lookup. In addition, our approach can be easily modified to support multiple matchings1 instead of the longest prefix matching. The simulation results demonstrate that our approach is able to provide efficient name-based routing lookup even for the fastest backbone routers (i.e. 100+ Gbps).",data oriented architecture,487
a50ab8ce1165aa9d17ad623707d9e1bc661ca80e,filtered,semantic_scholar,2012 IEEE International Conference on Information Science and Technology,2012-01-01,semantic_scholar,an object-oriented system for dynamics-based 3d cloth simulation,https://www.semanticscholar.org/paper/a50ab8ce1165aa9d17ad623707d9e1bc661ca80e,"The dynamics-based 3D cloth simulation has very broad applications. Generally, it involves mathematical modeling, collision detection between objects, self-collision detection for deformable object, and numerical solution of differential equations. As a result, the final simulation software system is usually complex. On the other hand, currently no suitable open-source software systems are publicly available for one to easily use so that his/her idea can be quickly tested. In this paper we first present a data-centric paradigm for dynamics-based simulation, and then propose an object oriented architecture for cloth simulation. In this architecture, we design a common abstract base class for all objects and bounding-box based collision detection, from which we can easily simulate a given type of object by creating a new inherited object class. The inherited class can easily reuse the existing modules in its base class, and hence decrease the number of code lines significantly, thus reducing the complexity and coupling between modules. In particular, when a new algorithm is designed, we can expediently test and verify its effectiveness by directly reuse the other modules without having to reprogram them. The clothing simulation system that we have implemented has fully demonstrated the reusability of the proposed architecture. This architecture also has the potential to be easily used for other types of dynamics-based 3D simulations.",data oriented architecture,488
fbc95202854a30718a1de77095625b22ccda84f0,filtered,semantic_scholar,2010 International Conference on Electrical and Control Engineering,2010-01-01,semantic_scholar,service-oriented transparent interconnection between data-centric wsn and ip networks,https://www.semanticscholar.org/paper/fbc95202854a30718a1de77095625b22ccda84f0,"Wireless sensor networks (WSN) have been recently be proposed for great deal of applications in industrial automation, health and environment monitoring. Increasingly there is a need to access wireless sensor networks from other IP-based networks. However, WSN has its own application-specific non-standardized protocols such as data-centric router protocol, which is a significant challenge to establish interconnection with IP networks which is based on address-centric router protocols. Service-Oriented Architecture (SOA) has been chosen to implement the communication among distributed applications. In this paper, we propose a Service-Oriented framework for inter-connection between data-centric WSN and IP network. This framework enables service-based query for data-centric WSN based on Device Profile for Web service (DPWS). It provides transparent access from one network to the other without modifying protocols running in either network.",data oriented architecture,489
3ca01f112f3cade2d8a2957a49d4bc5e312be870,filtered,semantic_scholar,,2002-01-01,semantic_scholar,xmach-1: a multi-user benchmark for xml data management,https://www.semanticscholar.org/paper/3ca01f112f3cade2d8a2957a49d4bc5e312be870,"The specification of XMach-1 (XML Data Management benchmark, Version 1) was developed at the University of Leipzig in 2000 and published at the beginning of 2001 [BoRa01]. It was the first XML database benchmark. The benchmark defines a database of XML documents and a set of operations covering important characteristics of XML processing and querying. Key features of XMach-1 are scalability, multi-user simulation and the evaluation of the entire data management system. It has been sucessfully implemented for a variety of native XML database systems and XML-enabled relational and object-relational DBMS. The benchmark is based on a web application in order to model a typical use case of a XML data management system. The system architecture consists of four parts: the XML database, application servers, loaders to populate the database and browser clients. The application servers run a web (HTTP) server and other middleware components to support processing of the XML documents and to interact with the backend database. The XML database contains both document-centric and data-centric XML documents. The largest part is document-centric consisting of semi-structured documents with larger text portions such as books or essays. These documents are synthetically produced by a parameterizable generator. In order to achieve close-to-reality results when storing and querying text contents, text is generated from the 10,000 most frequent English words, using a distribution corresponding to natural language text. The documents varies in size (2-100 kB) as well as in structure (flat and deep element hierarchy). The second part of the database is a data-centric directory containing the metadata of the other documents such as document URL, name, insertand update time. All data in this document is stored in attributes (no mixed content) and the order of element siblings is free. Compared to stuctured data in relational databases it shows some semi-structured properties such as variable path length using recursive elements or optional attributes. The database can be scaled by increasing the number of documents, e.g. from 1000 text-oriented documents to 10 million documents. The metadata document scales proportionally with the number of text documents. A distinctive feature of XMach-1 is that documents may be schema-less or schema-based and that we increase the number schemas with the number of documents. This allows us to test a database system’s ability to cope with an increasing number of different element types and to test query execution across multiple schemas. Additionally the benchmark supports evaluating schema-less and schema-based document storage. The XMach-1 workload mix consists of 8 query operations and 3 update operations. They cover a wide range of processing features such as complete reconstruction of complex documents, full text retrieval, navigational queries, queries using sorting and grouping operators etc. In addition to the textual specification there exists a XQuery formulation of the queries [XM02]. Update operations cover inserting and deleting of documents as well as changing attribute values. Having update operations defined is unique across the XML benchmarks. Despite the missing data manipulation language for update operations it is insightful to test this functionality. Since XMach-1 is a multi-user benchmark the primary performance metric is throughput measured in Xqps (XML queries per second). This value is calculated from the workload mix which defines firm ratios for each operation. According to its simulated domain this mix emphasizes the retrieval of complete documents whereas update operations have only a minor share. Nevertheless the latter one can have a significant impact on the execution of the query operations since cache and transaction management have to provide current data. Of course, the benchmark can also be applied in single-user mode, e.g. to determine the response times of the various queries as a reference point.",data oriented architecture,490
af5f816e2d00d9190f7b1ed7635c2f5360f8949b,filtered,semantic_scholar,2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI),2017-01-01,semantic_scholar,poster abstract: data-centric iot services provisioning in fog-cloud computing systems,https://www.semanticscholar.org/paper/af5f816e2d00d9190f7b1ed7635c2f5360f8949b,"Fog computing is mainly proposed for IoT applications that are geospatially distributed, large-scale, and latency sensitive. This poses new research challenges in real-time and scalable provisioning of IoT services distributed across Fog-Cloud computing platforms. Data-centric IoT services, as a dominant type of IoT services in large-scale deployments, require design solutions to speed up data processing and notification, and scale up with the data volume. In this paper, we propose a service-oriented design architecture which is particularly focused on provisioning and processing data-centric IoT services over Fog-Cloud systems. In the proposed architecture, data-centric IoT services are organized in a service integrating tree structure, adhering to the hierarchical fog-based IoT computing models. A service node in the tree is empowered with features for real-time service data notification, local data processing and multi-level IoT data access. The initial results show that, along the design advantages of the proposed model, it does not impose any additional overhead as compared to state-of-the-art solutions.",data oriented architecture,491
fa3828b353d9cb6b11aa732344f634f4bf762d07,filtered,semantic_scholar,IoTDI,2017-01-01,semantic_scholar,data-centric iot services provisioning in fog-cloud computing systems: poster abstract,https://www.semanticscholar.org/paper/fa3828b353d9cb6b11aa732344f634f4bf762d07,"Fog computing is mainly proposed for IoT applications that are geospatially distributed, large-scale, and latency sensitive. This poses new research challenges in real-time and scalable provisioning of IoT services distributed across Fog-Cloud computing platforms. Data-centric IoT services, as a dominant type of IoT services in large-scale deployments, require design solutions to speed up data processing and notification, and scale up with the data volume. In this paper, we propose a service-oriented design architecture which is particularly focused on provisioning and processing data-centric IoT services over Fog-Cloud systems. In the proposed architecture, data-centric IoT services are organized in a service integrating tree structure, adhering to the hierarchical fog-based IoT computing models. A service node in the tree is empowered with features for real-time service data notification, local data processing and multi-level IoT data access. The initial results show that, along the design advantages of the proposed model, it does not impose any additional overhead as compared to state-of-the-art solutions.",data oriented architecture,492
903457dc6d30757580756bddb0581470cd64e0a1,filtered,semantic_scholar,MIE,2016-01-01,semantic_scholar,dynamic user interfaces for service oriented architectures in healthcare,https://www.semanticscholar.org/paper/903457dc6d30757580756bddb0581470cd64e0a1,"Electronic Health Records (EHRs) play a crucial role in healthcare today. Considering a data-centric view, EHRs are very advanced as they provide and share healthcare data in a cross-institutional and patient-centered way adhering to high syntactic and semantic interoperability. However, the EHR functionalities available for the end users are rare and hence often limited to basic document query functions. Future EHR use necessitates the ability to let the users define their needed data according to a certain situation and how this data should be processed. Workflow and semantic modelling approaches as well as Web services provide means to fulfil such a goal. This thesis develops concepts for dynamic interfaces between EHR end users and a service oriented eHealth infrastructure, which allow the users to design their flexible EHR needs, modeled in a dynamic and formal way. These are used to discover, compose and execute the right Semantic Web services.",data oriented architecture,493
2d2385f99fa1fcefd4dbda103375b0c3aa5074fe,filtered,semantic_scholar,,2006-01-01,semantic_scholar,microsoft visual studio 2012 unleashed,https://www.semanticscholar.org/paper/2d2385f99fa1fcefd4dbda103375b0c3aa5074fe,"Normal 0 false false false MicrosoftInternetExplorer4 Normal 0 false false false MicrosoftInternetExplorer4 Microsoft Visual Studio 2012 significantly improves developer productivity across virtually all application lifecycle management tasks, while providing first-class support for Windows 8, Windows Phone, WindowsRT, and Windows Azure cloud development. This end-to-end deep dive will help working developers squeeze maximum productivity out of Microsofts powerful new toolbox. The authors combine authoritative and detailed information about Microsofts latest IDE, with extensive insights and best practices drawn from decades of development experience. Developers will quickly get comfortable with Visual Studio 2012s revamped interface and discover multiple opportunities to leverage the updated .NET 4.5 platform it supports. By focusing entirely on Visual Studio 2012 Professional, the authors have gone deeper into Microsofts core product than ever before. Youll find expert coverage of everything from debugging through refactoring, automation through enterprise-class development. Throughout, this books focus is relentlessly practical: how to apply Microsofts tools to build better software, faster. Detailed information on how to... Use Visual Studio 2012s new interface to significantly improve your productivity Make the most of VS 2012s new WPF-based code editor Work with solutions, projects, browsers, explorers, and designers Create modern Windows Store applications for Windows 8 and Windows RT apps with VS 2012 and Windows Runtime Library Develop websites with ASP.NET, ASP.NET MVC, and the Razor View Engine Create richer, smarter user interfaces for software of all types Build robust service oriented architecture (SOA)-based systems Construct data-centric applications with LINQ and Entity Framework Develop SharePoint and other Microsoft Office business applications Write Windows Azure applications that live in the cloud Instrument, analyze, and test your software Refactor code for greater robustness, maintainability, and performance Leverage brand-new improvements to Windows Workflow and Windows Communication Foundation Use VS 2012s one-click web deployment capabilities Extend VS 2012 with Managed Extensibility Framework (MEF) and Automation Object Model",data oriented architecture,494
7466dc46407029fec36e896f1fb1019ba6e41418,filtered,semantic_scholar,Enterp. Inf. Syst.,2017-01-01,semantic_scholar,a method of demand-driven and data-centric web service configuration for flexible business process implementation,https://www.semanticscholar.org/paper/7466dc46407029fec36e896f1fb1019ba6e41418,"ABSTRACT Facing the rapidly changing business environments, implementation of flexible business process is crucial, but difficult especially in data-intensive application areas. This study aims to provide scalable and easily accessible information resources to leverage business process management. In this article, with a resource-oriented approach, enterprise data resources are represented as data-centric Web services, grouped on-demand of business requirement and configured dynamically to adapt to changing business processes. First, a configurable architecture CIRPA involving information resource pool is proposed to act as a scalable and dynamic platform to virtualise enterprise information resources as data-centric Web services. By exposing data-centric resources as REST services in larger granularities, tenant-isolated information resources could be accessed in business process execution. Second, dynamic information resource pool is designed to fulfil configurable and on-demand data accessing in business process execution. CIRPA also isolates transaction data from business process while supporting diverse business processes composition. Finally, a case study of using our method in logistics application shows that CIRPA provides an enhanced performance both in static service encapsulation and dynamic service execution in cloud computing environment.",data oriented architecture,495
d2494bdd4b5aed00296f83fd28086857048f4503,filtered,semantic_scholar,PCI '13,2013-01-01,semantic_scholar,wsmeta: a meta-model for web services to compare service interfaces,https://www.semanticscholar.org/paper/d2494bdd4b5aed00296f83fd28086857048f4503,"With the increasing adoption of the web-services stack of standards, service-oriented architecture has attracted substantial interest from the research community which has produced several languages and methods for describing and reasoning about services. These languages cover many concepts ranging from individual services and their code generation from specifications, service semantics, service compositions and networks, economics and business aspects around service ecosystems etc. However, this abundance of specification languages has also resulted in communication difficulties between stakeholders and hinders tasks such as service composition, discovery and maintenance. The presented work is a step towards the unification of the specifications and different aspects of service systems using Model-Driven Engineering. We propose a generic and abstract web service meta-model called WSMeta, which has the ability to describe both operation-centric web services (WS-*) and data-centric web services (REST) and can be used in tasks such as service evolution analysis and service systems maintenance.",data oriented architecture,496
3ac5a76ab14cb422f93132ab78e810da02d684f9,filtered,semantic_scholar,BIS,2011-01-01,semantic_scholar,an approach to the semantization of erp systems,https://www.semanticscholar.org/paper/3ac5a76ab14cb422f93132ab78e810da02d684f9,"The paper promotes a methodology and application model for extending traditional, data-centric Enterprise Resource Planning Systems with semantics-oriented data models, in order to enrich interaction and reporting capabilities. The proposal includes a method of automating data semantization using a mix of semantic modeling and formal concept analysis, and an extended ERP architecture which integrates legacy systems in a Semantic Web wrapper system, providing new dimensions to traditional interaction and reports in a business environment, with specific examples regarding human resources management.",data oriented architecture,497
24a792f7ace63c87ea1e54d92d0c8b0112504797,filtered,semantic_scholar,2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference,2011-01-01,semantic_scholar,research on service bus for distributed real-time control systems,https://www.semanticscholar.org/paper/24a792f7ace63c87ea1e54d92d0c8b0112504797,"Service Oriented Architecture (SOA) is a prevalent paradigm to construct a loose coupling, flexible, scalable system. There are many researches on service computing and building applications with SOA. But many enterprises do not only have data-centric applications but also have real-time application systems which need more reliability, efficiency and real time. Theses real-time applications must collect and analyses data from a large variety of heterogeneous sensors and give decisions immediately. Constructing such real-time applications with SOA methodology becomes a challenge. Meanwhile researches on Internet of Things (IOT) and Cyber Physical Systems (CPS) are facing similar problems that how to construct distributed control application systems with novel service idea. In this paper, we show a SOA-based real-time service bus model which can be used to support constructing such Distributed Real-time Control Systems (DRCS) and discuss the bus mechanism in detail.",data oriented architecture,498
548f78f3d4deb45578654fcb47f405e6a7cca4c0,filtered,semantic_scholar,2006 IEEE Sarnoff Symposium,2006-01-01,semantic_scholar,peer-to-peer wireless sensor network data acquisition system with pipelined time division scheduling,https://www.semanticscholar.org/paper/548f78f3d4deb45578654fcb47f405e6a7cca4c0,"this paper, we introduce a peer-to-peer sensor network (P2PWSNDAS) architecture with pipelined time division scheduling for sensor data acquisition from an ad hoc wireless sensor network (WSN). P2PWSNDAS takes a service-oriented, data-centric view of the deployed WSN. The wireless sensors that constitute the WSN measure physical attributes of the environment they are deployed in such as temperature, pressure, vibration, toxic chemical, biological agents, etc. In our architecture, we assume that the entire WSN can be divided into sets of 'sensor-clusters'. Each cluster has a gateway or base station that aggregates data from its sensor cluster. The gateways themselves which constitute the middleware layer between the WSN and end point clients are designed to form an IP-based distributed peer-to-peer (P2P) overlay network. Clients query the gateways for real-time sensor data via a publish/subscribe/notify paradigm implemented at the gateways, and they can also concurrently receive notifications on alarms/events of interest. Another contribution we report in this paper is a Pipelined Time- division Model (PTM) scheduling for continuous energy-aware MAC-layer communication between a gateway and its sensors. Our PTM scheduling algorithm is particularly targeted towards wireless sensors such as the MICA2 series [4] that have multichannel radio transceivers.",data oriented architecture,499
2e28595f5c783d7cffd3987bc5c430aee68bd3f0,filtered,semantic_scholar,,2013-01-01,semantic_scholar,clara: clas12 reconstruction and analysis framework,https://www.semanticscholar.org/paper/2e28595f5c783d7cffd3987bc5c430aee68bd3f0,"In this paper we present SOA based CLAS12 event Reconstruction and Analyses (CLARA) framework. CLARA design focus is on two main traits: real-time data stream processing, and service-oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions capable of processing large volumes of data interactively and substantially faster than batch systems.",data oriented architecture,500
7f78407cf3f7eb5f92a4ed5bfb37bfb37f798d7d,filtered,semantic_scholar,CAiSE,1999-01-01,semantic_scholar,toga - a customizable service for data-centric collaboration,https://www.semanticscholar.org/paper/7f78407cf3f7eb5f92a4ed5bfb37bfb37f798d7d,"Collaboration in cooperative information systems, like concurrent design and engineering, exploits common work and information spaces. In this paper we introduce the TOGA service (Transaction-Oriented Group and Coordination Service for Data-Centric Applications), which offers group management facilities and a push model for change propagation w.r.t. shared data, thus allowing for group awareness. Through TOGA’s customizability and its layered architecture the service can be adapted to a variety of different collaboration scenarios. Multiple communication protocols (CORBA, UDP/IP, TCP/IP) are supported as well as basic transaction properties. Our approach enables the evolution of a set of separate applications to form a cooperative information system, i.e., it provides a technique towards component-oriented system engineering. In this paper we report on design issues, implementation aspects, and first experiences gained with the TOGA prototype.",data oriented architecture,501
02cce23fb4d2e2b1e9190bc8c7d7042757f6722f,filtered,semantic_scholar,SGAI Conf.,2008-01-01,semantic_scholar,information management for unmanned systems: combining dl-reasoning with publish/subscribe,https://www.semanticscholar.org/paper/02cce23fb4d2e2b1e9190bc8c7d7042757f6722f,"Sharing capabilities and information between collaborating entities by using modem information- and communication-technology is a core principle in complex distributed civil or military mission scenarios. Previous work proved the suitability of Service-oriented Architectures for modelling and sharing the participating entities’ capabilities. Albeit providing a satisfactory model for capabilities sharing, pure service-orientation curtails expressiveness for information exchange as opposed to dedicated data-centric communication principles. In this paper we introduce an Information Management System which combines OWL-Ontologies and automated reasoning with Publish/Subscribe-Systems, providing for a shared but decoupled data model. While confirming existing related research results, we emphasise the novel application and lack of practical experience of using Semantic Web technologies in areas other than originally intended. That is, aiding decision support and software design in the context of a mission scenario for an unmanned system. Experiments within a complex simulation environment show the immediate benefits of a semantic information-management and -dissemination platform: Clear separation of concerns in code and data model, increased service re-usability and extensibility as well as regulation of data flow and respective system behaviour through declarative rules.",data oriented architecture,502
c56063706513cf5fbe629f43289eaed7b5024265,filtered,semantic_scholar,,2017-01-01,semantic_scholar,re-engineering data-centric information systems for the cloud – a method and architectural patterns promoting multi-tenancy,https://www.semanticscholar.org/paper/c56063706513cf5fbe629f43289eaed7b5024265,"Enterprise applications are data-centric information systems that are being increasingly deployed as Software-as-a-Service (SaaS) Cloud offerings. Such service-oriented enterprise applications allow multiple tenants (i.e., groups of service consumers) to share the computational and storage capabilities of a single Cloud application instance. Compared to a more traditional single-tenant application deployment model, a multi-tenant SaaS architecture lowers both deployment and maintenance costs. These cost reductions motivate architects to re-engineer existing enterprise applications to support multi-tenancy at the application level. However, in order to preserve data integrity and data confidentiality, the re-engineering process must guarantee that different tenants allocated to the same application instance cannot access one another’s data, including both persistent values stored in databases and transient values created during calculations. 
This chapter presents a method and a set of architectural patterns for systematically re-engineering data-sensitive enterprise applications into secure multi- tenant software services that can be deployed to public and private Cloud offerings seamlessly. Architectural refactoring is introduced as a novel re- engineering practice and the necessary steps in multi-tenant refactoring are described from planning to execution to validation (including testing and code reviews). The method and patterns are validated in a fictitious, but realistic and representative case study that was distilled from real-world requirements and application architectures.",data oriented architecture,503
5eab79c9a418325c3646209f77be91e45c156b0a,filtered,semantic_scholar,,2000-01-01,semantic_scholar,evaluating module systems for crosscutting concerns,https://www.semanticscholar.org/paper/5eab79c9a418325c3646209f77be91e45c156b0a,"Although object-oriented programming techniques support modular decomposition of data types well, there are a number of programming concerns that cannot be cleanly modularized using conventional language mechanisms. This paper classifies these concerns into several categories, and describes examples and a prototypical challenge problem from each category. It then describes several recent techniques designed to improve program modularity in the face of these concerns. The strengths and weaknesses of each technique are evaluated with respect to the challenge problems. The paper concludes with a discussion of future research directions. 1. Object-Oriented Modularity A module, as used in this paper, is a programming environment mechanism for decomposing a large software program into smaller pieces, which the environment can automatically compose into a complete program later. Modules yield a number of programming benefits [P72]. The most important benefit is the intellectual leverage gained by separating the different concerns (programming issues) within a large program into smaller modules. Effective separation of concerns makes a program easier to understand, change, and debug. A second benefit comes from information hiding, which reduces dependencies between modules, supporting program evolution and independent development of different parts of a program. Other benefits of modules include separate compilation, incremental development, easier unit testing, improved re-use, and intellectual property protection. Object-oriented programming separates data representation concerns very well using the concept of an abstract data type. Since data representations are very likely to change over the course of program evolution, object-oriented systems separate a particular data representation choice from other parts of a program by putting it together with related code in a source file and hiding the representation choice behind an interface. When the data representation changes, these mechanisms often limit the effect of that change to the particular object involved. Object-oriented inheritance also enables a related group of objects to reuse a data representation scheme. Although object-oriented programming effectively separates data representation concerns, there are other kinds of concerns that are difficult to separate into modules using conventional object-oriented language technology. In the next section, we describe and classify a number of challenging modularity problems. Section 3 describes several techniques designed to address these concerns, and section 4 evaluates the techniques against selected challenge problems. Section 5 discusses future research directions in modularity, and section 6 concludes. 2. Modularity Challenges This section classifies programming concerns (that is, the problem domain for modularity) into a number of categories. For each category, we provide a brief description, relate it to other categories, give a number of example modularity problems, and choose a representative challenge problem that captures the essence of the category. 2.1. Data Representation Data representation concerns deal with how program data should be organized; this paper assumes the reader is familiar with this concern. Existing object-oriented languages, especially those with parameterized types, modularize many data representation concerns well. Parnas [P72] proposed the KWIC index system as a challenge problem to evaluate different modularizations of a data-centric program. 2.2. Functional Concerns A functional concern is a piece of functionality, such as a requirement or use case, provided for a client, such as the user, another program, or another component. While a single object is the unit of modularity in mainstream object-oriented languages, the implementation of a functional concern may cross object boundaries or may only be part of an object’s implementation. Thus, it is difficult to isolate the functional concern’s code in a single module. A challenge problem for modularizing functional concerns is separating operations on a program representation [TOHS99]. In typical program representations, there are many different kinds of nodes like assignment and function call nodes, and operations like typechecking, various optimization passes, and code generation can be applied to the different nodes. A good modularization would separate the typechecking operations for each node into one module, the code generation operations in another module, etc, effectively separating the functional concerns implemented by the different operations. Tools might even support both an object-oriented view and a functional view (Figure 1). Other example problems include the various actions of a bottle deposit machine like depositing and printing a receipt [AR92], composable pieces of data structure functionality such as searching and allocation [SB98], user interaction concerns such as directory listings and error messages in an FTP server [LM99], adding an operation to a shape hierarchy [FF98], functional testing of a use case scenario, and many others. 2.3. Program Organization Program organization concerns address the large-scale structure of the program: how do modules, each composed of many objects, interact on a high level? Large-scale program structure (as opposed to small-scale functional and data representation concerns) is an important concern for program understanding and modular analysis, yet most languages do not support modular structure beyond the size of a single object, obscuring their high-level structure [MN97]. Work on software architecture description languages [MT00] does address this concern, but is not tightly integrated with conventional programming languages. For lack of space, this paper does not survey the area. Effective support for program organization includes specifying relationships between program components separate from the components’ code, and clarifying the relationship between components using optional restrictions on the kinds of inter-component communication. A challenge problem, inspired by an urban simulation program [NBW00], is to specify a blackboard software architecture [GS94] as in Figure 2, with an explicit connection diagram showing how a set of simulation modules interacts with a shared data store. The system should enforce the application constraint that the modules do not directly communicate, but only make modifications to the shared data. It should be easy to make changes like Object-oriented Functional Figure 1. Object-oriented and Functional Decompositions of a Program Representation Figure 2. A Blackboard Software Architecture Module 4 Blackboard Module 3 Module 2 Module 1 Statement Core Data Structs Expression Function Call Typechecking",data oriented architecture,504
b4e9a3e0ec0a9a4b0bc2afe8ecd702222dd1e528,filtered,semantic_scholar,Software Engineering Research and Practice,2004-01-01,semantic_scholar,interoperability via enterprise architecture,https://www.semanticscholar.org/paper/b4e9a3e0ec0a9a4b0bc2afe8ecd702222dd1e528,"This paper summarizes the latest research in interoperability and enterprise architecture. It evaluates their features with respect to their applicability in a wide range of domains. It also recommends a seven layer Reference Model for a distributive, object oriented, domain specific, data-centric, bottom-up design. It favors a spiral model for life cycle in heterogeneous environment enterprise architecture in order to enhance interoperability. Simple interoperability model by software engineering institute, joint technical architecture by Department of Defense, federal Reference Model by EA shared interest group and datadriven architect techniques are modified and used as the basis for this model.",data oriented architecture,505
441b6a2ecfea590592dddb01ef056c87766a9916,filtered,semantic_scholar,,2003-01-01,semantic_scholar,mobishare : sharing context-dependent data and services among mobile devices ♣,https://www.semanticscholar.org/paper/441b6a2ecfea590592dddb01ef056c87766a9916,"Initiative on Global Computing for the cooperation of autonomous and mobile entities in dynamic environments. Abstract Rapid advances in wireless and mobile communications and computing technologies have enabled handy personal mobile devices to be used in everyday life. Such small mobile devices can now become not only information browsers and service clients, but also information and service providers, complementing or replacing fixed hosts connected to the wireline network. Such mobile resources can be very important for other moving users and mobile devices, creating significant opportunities for many interesting and novel applications. The MobiShare architecture outlined in this paper provides a scalable infrastructure for ubiquitous mobile access to dynamic information and mechanisms for publishing, discovering and accessing heterogeneous mobile resources in a large area, taking into account the context of both providers and requestors. Any wireless communication technology could be employed between a device and the system. In addition, the use of XML-related languages and protocols for describing and exchanging metadata gives the system a uniform, easily adaptable and platform-independent interface, allowing a variety of devices to use it. The overall approach is data-centric and service-oriented, implying that all the devices are treated both as potential providers or requestors of data wrapped as information m-services.",data oriented architecture,506
2fd0782cc292511786535f31c3b58eb02a66864d,filtered,semantic_scholar,2012 7th Colombian Computing Congress (CCC),2012-01-01,semantic_scholar,user interface and navigation modeling methodology for mobile hypermedia systems,https://www.semanticscholar.org/paper/2fd0782cc292511786535f31c3b58eb02a66864d,"This paper shows a methodology for modeling data centric mobile web applications. This approach takes the activity process defined in OOHDM (Object Oriented Hypermedia Design Method) unifying navigation and abstract interface modeling in a single diagram. Modeling is performed entirely in UML (Unified Modeling Language) using two diagrams: a class diagram for the domain model and a component diagram for the navigation and the interface. Both diagrams are extended using stereotypes and tagged values. These extensions are used for adding information to the models allowing to configure them and making easier the code generation. This modeling technique allows having the required data to use the MDA (Model Driven Architecture) approach, which through automatic transformations generates the database and source code of the mobile web application.",data oriented architecture,507
45e79d391bb8b352cc959206f3ddaeca40ad4599,filtered,semantic_scholar,IET Softw.,2019-01-01,semantic_scholar,e2sm: a security tool for adaptive cloud-based service-oriented applications,https://www.semanticscholar.org/paper/45e79d391bb8b352cc959206f3ddaeca40ad4599,"The issue of security in the distributed system landscape of a service-oriented architecture (SOA) is a challenging one. No longer is it limited to a local application or an application domain, security must now work across a range of applications and business processes interacting with each other. This is even more true when SOA-based applications are provisioned in the cloud. Firstly, cloud applications components, and the data they might handle, that were once silos, are now being exposed as services by distinct and distrusted tenants. Secondly, such applications are often adaptive when they are provisioned in cloud environments. This study proposes an end-to-end security model (E2SM) that aims to protect data confidentiality in adaptive cloud-based SOA applications. E2SM allows the setting of data-centric security policies that go beyond services boundaries. First, security configuration is automatically calculated starting from a few intuitive business-oriented security settings. Then, the configuration is updated with minimal overhead if security policies are dynamically modified and/or SOA architecture is reconfigured. A security tool is implemented according to the proposed model. As for validation, the tool was used to secure a healthcare business process.",data oriented architecture,508
fe9ccf8bd6de10e32696aa0e13e91be2fb9e2584,filtered,semantic_scholar,OPSR,2018-01-01,semantic_scholar,algorithm/architecture co-design for near-memory processing,https://www.semanticscholar.org/paper/fe9ccf8bd6de10e32696aa0e13e91be2fb9e2584,"With mainstream technologies to couple logic tightly with memory on the horizon, near-memory processing has re-emerged as a promising approach to improving performance and energy for data-centric computing. DRAM, however, is primarily designed for density and low cost, with a rigid internal organization that favors coarse-grain streaming rather than byte-level random access. This paper makes the case that treating DRAM as a block-oriented streaming device yields significant efficiency and performance benefits, which motivate for algorithm/architecture co-design to favor streaming access patterns, even at the price of a higher order algorithmic complexity. We present the Mondrian Data Engine that drastically improves the runtime and energy efficiency of basic in-memory analytic operators, despite doing more work as compared to traditional CPU-optimized algorithms, which heavily rely on random accesses and deep cache hierarchies",data oriented architecture,509
f150f7f3521184317830bb7f96b94aece9925c74,filtered,semantic_scholar,Int. J. Online Biomed. Eng.,2019-01-01,semantic_scholar,wireless sensor networks suitable for large-scale heterogeneous networking,https://www.semanticscholar.org/paper/f150f7f3521184317830bb7f96b94aece9925c74,"In order to optimize the network architecture, addressing mechanism, heterogeneous nodes and other functions of wireless sensor networks, this study begins with the issue of networking of large-scale heterogeneous networks. A layered distributed network architecture is proposed, which provides a powerful reference for the future architecture of wireless sensor networks. Based on this architecture, the resource addressing of the corresponding hierarchical network, and the scale and location deployment of heterogeneous nodes such as sink nodes are discussed separately, and corresponding strategies and algorithms are proposed. The research results show that the core idea of the addressing mechanism is data-centric, address-oriented addressing is transformed into service-oriented addressing. Therefore, the proposed LBA addressing algorithm is suitable for other hierarchically structured networks. In addition, although the sink node is taken as an example for research, it is also suitable for the deployment of other heterogeneous nodes such as sink nodes, relay nodes, and base stations. In summary, regardless of the number of nodes or the location of the deployment, energy-saving factors need to be considered. Energy-saving is also an indispensable technology in wireless sensor network technology.",data oriented architecture,510
10.1109/i-span.2009.67,filtered,"2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks",IEEE,2009-12-16 00:00:00,ieeexplore,a data-driven architecture for remote control of sensors over a wireless sensor network and the internet,https://ieeexplore.ieee.org/document/5381871/,"This study revealed an applicable architecture in which a data-driven mechanism was designed to bridge a wireless sensor network (WSN) and the Internet. The system was divided into two independent parts. The first part is the data communication between the sensor network and the database. The other part is the data communication between the database and the user interface (UI). These two parts are connected by the database server. Asynchronous interoperation was introduced while exchanging data between these two parts. Users were not allowed to control the sensors through direct connection to the sensors and can only use the Web service to update the sensor profile built in the database. The sensors were triggered to start the action through a data-update event from the database. A sensor profile built in the database collected all sensor information and all user control command. For the information to be centralized and triggered by the database, regardless of whether sensors were measured in a periodic sampling or an event-driven environment, all sensor actions were triggered through a data-update event in the database. For the sake of improving user experience, a Web-based UI was implemented using scalable vector graphics (SVG) and Ajax technologies. All operations by users were conducted through the Hypertext Transfer Protocol (HTTP) standard method. Therefore, this system can be used via a browser and easily deployed. The proposed architecture is suitable for a healthcare system, a personal body area network, and the Infranet for control.",data driven architecture,511
10.1109/noms.2004.1317788,filtered,2004 IEEE/IFIP Network Operations and Management Symposium (IEEE Cat. No.04CH37507),IEEE,2004-04-23 00:00:00,ieeexplore,a distributed data driven architecture for operations support systems,https://ieeexplore.ieee.org/document/1317788/,"This paper proposes a distributed data driven architecture (D3A), devised for application to an operations support system (OSS). By applying this architecture to an OSS, it is possible to reduce OSS hardware and middleware costs, and to change OSS application programs rapidly and flexibly. To assure alarm reception processing performance at low cost, D3A is comprised of a lot of IA servers. With D3A, OSS application programs are divided into a lot of elements similar to UNIX processes. These elements are called processing elements (PEs). A PE is mounted on each IA server. Data that represents the execution sequence and execution condition of PEs is called processing configuration data (PCD). The PCD moves about among IA servers comprising an OSS. The PCD driver (PCDD) is a function to analyze the PCD, and determines the PE to be executed next and controls the route of the PCD. A commercial OSS is being developed by using D3A and will start running in June 2004.",data driven architecture,512
10.1109/iccic.2015.7435772,filtered,2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC),IEEE,2015-12-12 00:00:00,ieeexplore,data driven architecture based automated test generation for android mobile,https://ieeexplore.ieee.org/document/7435772/,"Test generation automation using Data Driven Architecture (DDA) is a challenging task. It involves an external database to feed test inputs to a test case sequentially. Same test case is executed repeatedly in a loop, to handle different test inputs. In this paper, a method is proposed to generate DDA based tests for Android mobiles. A tool called Virtual Test Engineer (VTE), which generates tests from Sequence diagram, is extended to incorporate DDA based test generation. Sqlite database is used to store test inputs. Test driver is generated automatically from Sequence diagram in the form of XML file. An Android application package (APK) is generated automatically to handle this XML file and Sqlite database file and subsequently execute the test cases. The effectiveness of this method is discussed from experimental results. Comparison has been made of the proposed method with others and the proposed method has been found to be more effective.",data driven architecture,513
10.1109/ismsit50672.2020.9254863,filtered,2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),IEEE,2020-10-24 00:00:00,ieeexplore,personalized quality of experience (qoe) management using data driven architecture in 5g wireless networks,https://ieeexplore.ieee.org/document/9254863/,"the aim of this paper is to Personalized Quality of Experience (QOE) Management using Data driven Architecture in 5G Wireless Networks that consume less resources. The proposed research will be the part of the overall research project, which focuses on addressing a problem that many organizations experience that introduce an Enterprise Architecture to support the integration of different services across the enterprise. With the rapid growth in mobile network usage and video streaming being the most popular service, Quality of Experience of video in mobile networks is of extreme importance to both service providers and their customers. The ability to effectively predict Quality of Experience of video is key for QoE adaptation and higher levels of customer satisfaction. In this work machine learning algorithms were used to create models that predict QoE with network QoS parameters, including wireless-specific and 5Gspecific parameters. An 5G simulation that reflects the current mobile traffic landscape was created to obtain the data set for training. An objective tool for video QoE evaluation was used to gather QoE data necessary to train the prediction models. Support Vector Machines, Random Forest, Gradient Boosted Trees and Neural Networks were chosen as the machine learning algorithms for Quality of Experience prediction, and it was shown that they achieve high accuracy. Influence of wireless-specific parameters on QoE prediction was also investigated, and it was discovered that they are suitable for use in Quality of Experience prediction models.The problem is that; organizations do not know where they either have or may encounter weaknesses in their Enterprise Architecture with Data Driven Architecture (DDA). The framework presented is based on concepts from Wireless Networks with Driven Architecture will be designed to support both Transitional Gap Analysis (TGA) and Comparative Gap Analysis (CGA). TGA is supported by comparing a baseline Data Driven Architecture (DDA) to a target QoE where both DDA have been defined from the management perspective. DDA is facilitated by mapping a QoE to two or more 5G networks. The research methodology used in the paper is design science research for the QoE management based 5G network. The QOE for implementation of 5th generation network and apply it in many different real-world organizations. The goal of the paper is to present a framework in the form an implementation and management model, called QOE, that visualizes the gaps (weaknesses) in proposed or existing enterprise architectures and to support a comparative analysis process for different a5Grnative solution approaches. a set of requirements on the QOE management can be presented and the frameworks are applied on Matlab for implementation.",data driven architecture,514
10.1109/tmc.2020.2999852,filtered,IEEE Transactions on Mobile Computing,IEEE,2021-12-01 00:00:00,ieeexplore,machine learning at the edge: a data-driven architecture with applications to 5g cellular networks,https://ieeexplore.ieee.org/document/9107476/,"The fifth generation of cellular networks (5G) will rely on edge cloud deployments to satisfy the ultra-low latency demand of future applications. In this paper, we argue that such deployments can also be used to enable advanced data-driven and Machine Learning (ML) applications in mobile networks. We propose an edge-controller-based architecture for cellular networks and evaluate its performance with real data from hundreds of base stations of a major U.S. operator. In this regard, we will provide insights on how to dynamically cluster and associate base stations and controllers, according to the global mobility patterns of the users. Then, we will describe how the controllers can be used to run ML algorithms to predict the number of users in each base station, and a use case in which these predictions are exploited by a higher-layer application to route vehicular traffic according to network Key Performance Indicators (KPIs). We show that the prediction accuracy improves when based on machine learning algorithms that rely on the controllers’ view and, consequently, on the spatial correlation introduced by the user mobility, with respect to when the prediction is based only on the local data of each single base station.",data driven architecture,515
10.1109/nssmic.1998.775181,filtered,1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255),IEEE,1998-11-14 00:00:00,ieeexplore,a 16-channel digital tdc chip,https://ieeexplore.ieee.org/document/775181/,"A 16-channel digital TDC chip has been built for the DIRC Cerenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns and the full-scale 32 microseconds. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The linearity is better than 80 ps rms on 90% of the production parts.",data driven architecture,516
10.1109/cdc.2007.4434859,filtered,2007 46th IEEE Conference on Decision and Control,IEEE,2007-12-14 00:00:00,ieeexplore,a scalable wireless communication architecture for average consensus,https://ieeexplore.ieee.org/document/4434859/,"This paper introduces a multiple-access coding technique that is tailored to solve average consensus problems efficiently in wireless networks. We propose a novel data driven architecture which grants channel access to nodes based on their local data values. We analyze the performance of the scheme in the presence of quantization errors and noise. We show that our scheme is unbiased with respect to quantized consensus algorithms, it achieves good MSE performance, and it can be configured to provide a speedup in the convergence rate. The amount of speedup achieved is a function of |Q<sub>k</sub>| which indicates the number of quantization bins used to represent the state variables exchanged during the computation.",data driven architecture,517
10.1109/emwrts.1996.557821,filtered,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,IEEE,1996-06-14 00:00:00,ieeexplore,an embedded accelerator for real-time image processing,https://ieeexplore.ieee.org/document/557821/,"The paper presents an embedded reconfigurable accelerator called Xputer, comprising a novel kind of sequencer hardware (data sequencer). For many real-time signal processing, multimedia, and other high-performance applications this new data-driven architecture increases the performance of a single processor system enormously by integrating it as a co-processor for accelerating computation-intensive parts of an application. The reconfigurable architecture and programming environment is described. Its use is illustrated with an automotive application requiring real-time image processing.",data driven architecture,518
10.1109/geoinformatics.2010.5567735,filtered,2010 18th International Conference on Geoinformatics,IEEE,2010-06-20 00:00:00,ieeexplore,an integrated spatio-temporal modeling and analysis framework for climate change research,https://ieeexplore.ieee.org/document/5567735/,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It's brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.",data driven architecture,519
10.1109/fpt.2010.5681493,filtered,2010 International Conference on Field-Programmable Technology,IEEE,2010-12-10 00:00:00,ieeexplore,automatic synthesis of processor arrays with local memories on fpgas,https://ieeexplore.ieee.org/document/5681493/,"In this paper, we present an automatic synthesis framework to map loop nests to processor arrays with local memories on FPGAs. An affine transformation approach is firstly proposed to address space-time mapping problem. Then a data-driven architecture model is introduced to enable automatic generation of processor arrays by extracting this data-driven architecture model from transformed loop nests. Some techniques including memory allocation, communication generation and control generation are presented. Synthesizable RTL codes can be easily generated from the architecture model built by these techniques. A preliminary synthesis tool is implemented based on PLUTO, an automatic polyhedral source-to-source transformation and parallelization framework.",data driven architecture,520
10.1109/icws.2008.147,filtered,2008 IEEE International Conference on Web Services,IEEE,2008-09-26 00:00:00,ieeexplore,common business components and services toward more agile and flexible industry solutions and assets,https://ieeexplore.ieee.org/document/4670150/,"In many decades, many organizations, especially large consulting companies, have been designing, implementing and managing business solutions for every industry around the globe. But due to numerous limitations in process, tooling and skills, most of those solutions were made very specific to individual industry and client needs at its early design stage. Therefore, reuse and more importantly, managing the ever changing business requirements, become almost impossible. Service-orientation and architecture, model-driven business development provides us a new and powerful approach to facilitate asset based industry solution design and development. To further accelerate this, this tutorial will discuss an innovative approach that take advantage of many proven best software engineering practices, from object/component based technology, meta-data driven architecture types (archetypes) that are used to model the common structural and in some cases non-structural business entities such as customer, product, payment, etc. In order to address the consequences introduced by abstracting those common elements out of the specific industry model and be able to enable easy and meta-data based transformation, we properly decompose business components/services into a multi-layered business architecture. Therefore, process/components/services can be decomposed accordingly to facilitate the decomposition and abstraction, while maintaining certain level of necessary traceability across various artifacts. In the realization phase, existing assets/operational systems will be mapped and transformed to the required business components and services to best leverage those existing valuable industry/client investments. To support such a SOA based, model and business driven development process, existing tooling, especially the necessary transformation and integration capability, needs to be significantly enhanced. This tutorial will also present some recommendation based on some recent design and implementation, and they could be used to guide future tooling alignment and integration effort across software modeling, implementation and solution products. In addition, we will present how to leverage existing internal or external assets or product offerings and the open industry reference models and standards (such as ACCORD, ebXML, ARTS/IxRetail). This work is based on authors' collective experience in leading the large end-to-end client engagements across many industries, while promoting various industry leading software engineering best practices.",data driven architecture,521
10.1109/nabic.2009.5393876,filtered,2009 World Congress on Nature & Biologically Inspired Computing (NaBIC),IEEE,2009-12-11 00:00:00,ieeexplore,data diverse fault tolerant architecture for component based systems,https://ieeexplore.ieee.org/document/5393876/,"Of late, component based software design has become a major focus in software engineering research and computing practice. These software components are used in a wide range of applications some of which may have mission critical requirements. In order to achieve required level of reliability, these component-based designs have to incorporate special measures to cope up with software faults. This paper presents a fault tolerant component based data driven architecture that is based on C2 architectural framework and implements data diverse fault tolerance strategies. The proposed design makes a trade-off between platform flexibility, reliability and efficiency at run time and exhibits its ability to tolerate faults in a cost effective manner. Application of proposed design is exhibited with a case study.",data driven architecture,522
10.1109/tina.1997.660723,filtered,Proceedings TINA '97 - Global Convergence of Telecommunications and Distributed Object Computing,IEEE,1997-11-20 00:00:00,ieeexplore,data-driven implementation of tina kernel transport network,https://ieeexplore.ieee.org/document/660723/,"To realize the actual TINA-based telecommunications network, the performance of the kernel Transport Network (kTN) such as availability, reliability, throughput and load tolerance becomes more crucial than for existing computer networks. The authors have been studying and developing a super-integrated data-driven processor to be applied to the TINA kTN nodes and network interfaces in CUE (Coordinating Users' requirements and Engineering constraints) project. Since the processor is primarily designed to be a scalable VLSI component, it is easily interconnected to form a super-integrated chip and multi-chip system for achieving the performance and reliability demanded in a TINA environment. We first examine the requirements for kTN. A stream-oriented data-driven architecture is then proposed with special emphasis on effective multiprocessing capability with overload tolerance. After that, we demonstrate that autonomous load balancing among super-integrated data-driven processors without adding any runtime overhead to achieve effective and reliable multiprocessing is possible by utilizing the overload tolerance of the processor. Finally, this paper shows preliminary performance estimations of the super-integrated data-driven processor being developed to perform efficient multiprocessing in protocol handling such as TCP/IP.",data driven architecture,523
10.1109/icra.2011.5979609,filtered,2011 IEEE International Conference on Robotics and Automation,IEEE,2011-05-13 00:00:00,ieeexplore,dead reckoning in a dynamic quadruped robot: inertial navigation system aided by a legged odometer,https://ieeexplore.ieee.org/document/5979609/,"It is an important ability for any mobile robot to be able to estimate its posture and to gauge the distance it travelled. The information can be obtained from various sources. In this work, we have addressed this problem in a dynamic quadruped robot. We have designed and implemented a navigation algorithm for full body state (position, velocity, and attitude) estimation that does not use any external reference (such as GPS, or visual landmarks). Extended Kalman Filter was used to provide error estimation and data fusion from two independent sources of information: Inertial Navigation System mechanization algorithm processing raw inertial data, and legged odometry, which provided velocity aiding. We present a novel data-driven architecture for legged odometry that relies on a combination of joint sensor signals and pressure sensors. Our navigation system ensures precise tracking of a running robot's posture (roll and pitch), and satisfactory tracking of its position over medium time intervals. We have shown our method to work for two different dynamic turning gaits and on two terrains with significantly different friction. We have also successfully demonstrated how our method generalizes to different velocities.",data driven architecture,524
10.1109/sam48682.2020.9104367,filtered,2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,2020-06-11 00:00:00,ieeexplore,deep radar waveform design for efficient automotive radar sensing,https://ieeexplore.ieee.org/document/9104367/,"In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a wellknown unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.",data driven architecture,525
10.1109/nssmic.2004.1466709,filtered,IEEE Symposium Conference Record Nuclear Science 2004.,IEEE,2004-10-22 00:00:00,ieeexplore,design and evaluation of the clear-pem detector for positron emission mammography,https://ieeexplore.ieee.org/document/1466709/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with adequate field-of-view dimensions for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,526
10.1109/cac.2017.8244168,filtered,2017 Chinese Automation Congress (CAC),IEEE,2017-10-22 00:00:00,ieeexplore,design and implementation of data-driven based universal data editing framework,https://ieeexplore.ieee.org/document/8244168/,"Apply Integrated Logistics Support (ILS) to weapon equipment can efficiently improve equipment's automation and digital level. ILS needs support of various integrated support systems, which have demands for data editing. Nowadays, most of data editing software used in these systems are customized and provide a form-based editing approach, which becomes an obstacle to carry out ILS. This paper brings forward to design a data-driven based universal data editing framework. In this framework, data models are taken as input and only corresponding data models need to be modified when data change. Firstly, the whole development process of data editing software that adopt form-based development mode is analyzed in detail to find out problems exists in this development mode. Then the data-driven based universal data editing framework is designed. New idea of data-driven architecture is proposed. Data-driven architecture takes data models as input and processes all data models in a universal way. Finally, key technology for framework realization is given.",data driven architecture,527
10.1109/nssmic.2000.949427,filtered,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,2000-10-20 00:00:00,ieeexplore,design and performance of the dzero data acquisition system,https://ieeexplore.ieee.org/document/949427/,"The D0 Run 2 data acquisition system features a novel design permitting complex event routing in a high speed, data driven architecture. Data blocks associated with multiple events flow freely from /spl sim/70 frontend digitization crates. Eight separate readout concentrators funnel these blocks onto optical fiber paths to the Level 3 trigger processor farm. The processor farm is divided into segments, each of which is fed by a segment bridge. Data blocks flow to each bridge in turn, where they are either routed to a Level 3 node (or nodes) in the segment, or passed onto the next segment bridge. Blocks that do not flow to a processor node are returned to the readout concentrator. Thus the system has a built-in mechanism for rate limitation. The Event Tag Generator (ETG) and segment bridges facilitate the event routing decisions in real time. The routing is based on the trigger bits from the hardware trigger. This and the availability of nodes in each segment determine to which node(s) the event is routed. We present operational and performance details of this system, designed for comfortably more than the nominal 1 kHz input; being modular and parallel, it can be easily upgraded.",data driven architecture,528
10.1109/ewdts.2010.5742121,filtered,2010 East-West Design & Test Symposium (EWDTS),IEEE,2010-09-20 00:00:00,ieeexplore,development of the data-driven readout asic for microstrip detectors,https://ieeexplore.ieee.org/document/5742121/,"Presented are the results of developing an asynchronous data-driven architecture for multichannel silicon tracker system experiments. A known event statistics in multichannel equipment makes it possible to use new variants of architecture synthesis with use of analog derandomizing blocks. There are discussed the testing and simulation results of separate prototype blocks and the whole system, aimed to achieve a compromise in a set of parameters, focused on power consumption, performance and dead time. The requirements of the silicon tracker station in CBM experiment were used in design.",data driven architecture,529
10.1109/cdc.2018.8618963,filtered,2018 IEEE Conference on Decision and Control (CDC),IEEE,2018-12-19 00:00:00,ieeexplore,discovering conservation laws from data for control,https://ieeexplore.ieee.org/document/8618963/,"Conserved quantities, i.e. constants of motion, are critical for characterizing many dynamical systems in science and engineering. These quantities are related to underlying symmetries and they provide fundamental knowledge about physical laws, describe the evolution of the system, and enable system reduction. In this work, we formulate a data-driven architecture for discovering conserved quantities based on Koopman theory. The Koopman operator has emerged as a principled linear embedding of nonlinear dynamics, and its eigenfunctions establish intrinsic coordinates along which the dynamics behave linearly. Interestingly, eigenfunctions of the Koopman operator associated with vanishing eigenvalues correspond to conserved quantities of the underlying system. In this paper, we show that these invariants may be identified with data-driven regression and power series expansions, based on the infinitesimal generator of the Koopman operator. We further establish a connection between the Koopman framework, conserved quantities, and the Lie-Poisson bracket. This data-driven method for discovering conserved quantities is demonstrated on the three-dimensional rigid body equations, where we simultaneously discover the total energy and angular momentum and use these intrinsic coordinates to develop a model predictive controller to track a given reference value.",data driven architecture,530
10.1109/nssmic.2000.949945,filtered,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,2000-10-20 00:00:00,ieeexplore,error handling for the cdf silicon vertex tracker,https://ieeexplore.ieee.org/document/949945/,"The SVT online tracker for the CDF upgrade reconstructs two-dimensional tracks using information from the Silicon Vertex detector (SVXII) and the Central Outer Tracker (COT). The SVT has an event rate of 100 kHz and a latency time of 10 /spl mu/s. The system is composed of 104 VME 9U digital boards (of 8 different types) and it is implemented as a data driven architecture. Each board runs on its own 30 MHz clock. Since the data output from the SVT (few Mbytes/sec) are a small fraction of the input data (200 Mbytes/sec), it is extremely difficult to track possible internal errors by using only the output stream. For this reason several diagnostic tools have been implemented: local error registers, error bits propagated through the data streams and the Spy Buffer system. Data flowing through each input and output stream of every board are continuously copied to memory banks named Spy Buffers which act as built in logic state analyzers hooked continuously to internal data streams. The contents of all buffers can be frozen at any time (e.g. on error detection) to take a snapshot of all data flowing through each SVT board. The Spy Buffers are coordinated at system level by the Spy Control Board. The architecture, design and implementation of this system are described.",data driven architecture,531
10.1109/ipps.1994.288217,filtered,Proceedings of 8th International Parallel Processing Symposium,IEEE,1994-04-29 00:00:00,ieeexplore,fault detection and recovery in a data-driven real-time multiprocessor,https://ieeexplore.ieee.org/document/288217/,"Introduces the mechanisms required to perform fault detection and recovery in the DART (Data-driven Architecture for Real-Time) multiprocessor architecture. The DART multiprocessor uses prioritized data-driven scheduling to ensure that multiple hard and soft deadlines are met. A data-driven checkpointing scheme has been developed that ensures that these deadlines are met even in the case of processor failures. The basic approach is to monitor the behavior of each computational thread by means of hardware timers. The results of a thread are released only if the thread completes before its given timeout period expires. Otherwise the partial computation on that processor is discarded and the thread is rescheduled on a different processor. A strategy to statically predict the system performance in the event of multiple processor failures is presented and evaluated. Simulation results are provided to illustrate the fault detection and recovery response times for single processor failures on DART multiprocessor architectures with 2, 4, 8, 16 and 32 processing elements.&lt;<ETX>&gt;</ETX>",data driven architecture,532
10.1109/nssmic.2005.1596374,filtered,"IEEE Nuclear Science Symposium Conference Record, 2005",IEEE,2005-10-29 00:00:00,ieeexplore,front end electronics and readout system for a gas radiator ring imaging cherenkov detector using multi-anode photomultiplier tubes,https://ieeexplore.ieee.org/document/1596374/,"We describe the design and performance of a novel custom made front end ASICs and their associated data acquisition (DAQ) system that we developed to process charge signals from an array of 53 Hamamatsu multi-anode photomultiplier tubes (MAPMTs) used as photon detectors for a ring imaging Cherenkov (RICH) detector. This system was tested as part of a gas radiator RICH prototype in the test beam facility at Fermilab. The VA MAPMT ASIC has 64 readout channels with built-in discriminator and parallel binary readout; features low noise, high dynamic range and is suitable for data driven architecture. We characterized a second iteration of this design that features higher dynamic range and optimum performance for large signals in our electronics laboratory test-setup.",data driven architecture,533
10.1109/cbms.2018.00079,filtered,2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS),IEEE,2018-06-21 00:00:00,ieeexplore,implementation of a situation aware and real-time approach for decision support in online surgery scheduling,https://ieeexplore.ieee.org/document/8417274/,"For decisions on operational business level it is necessary to be aware of and to understand what happens around you and what probably will happen in the near future. E.g. in Operating Room Management, and especially in Online surgery scheduling, a lot of decisions are difficult to handle, since there are high cognitive and communicational efforts to gather all necessary information to oversee the current situation and to derive decisions based on this information. However, the emerging trend of connecting devices and new methods in data analytics, allow new approaches for decision support in these areas. By using this concepts we suggested and implemented a data-driven architecture including several components for data analysis, information generation and visualization. The presented prototype means a proof-of-concept of the idea of a real-time and situation-aware decision support system for operating room managers.",data driven architecture,534
10.1109/isit45174.2021.9517812,filtered,2021 IEEE International Symposium on Information Theory (ISIT),IEEE,2021-07-20 00:00:00,ieeexplore,model-inspired deep detection with low-resolution receivers,https://ieeexplore.ieee.org/document/9517812/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector network, called LoRD-Net, for signal recovering from one-bit measurements. Our approach relies on a model-aware data-driven architecture, based on a deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely ~ 500 samples, for training.",data driven architecture,535
10.1109/icc42927.2021.9500961,filtered,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,removing channel estimation by location-only based deep learning for ris aided mobile edge computing,https://ieeexplore.ieee.org/document/9500961/,"In this paper, we investigate a deep learning architecture for lightweight online implementation of a reconfigurable intelligent surface (RIS)-aided multi-user mobile edge computing (MEC) system, where the optimized performance can be achieved based on user equipment’s (UEs’) location-only information. Assuming that each UE is endowed with a limited energy budget, we aim at maximizing the total completed task-input bits (TCTB) of all UEs within a given time slot, through jointly optimizing the RIS reflecting coefficients, the receive beamforming vectors, and UEs’ energy partition strategies for local computing and computation offloading. Due to the coupled optimization variables, a three-step block coordinate descending (BCD) algorithm is first proposed to effectively solve the formulated TCTB maximization problem iteratively with guaranteed convergence. The location-only deep learning architecture is then constructed to emulate the proposed BCD optimization algorithm, through which the pilot channel estimation and feedback can be removed for online implementation with low complexity. The simulation results reveal a close match between the performance of the BCD optimization algorithm and the location-only data-driven architecture, all with superior performance to existing benchmarks.",data driven architecture,536
10.23919/ccc50068.2020.9188717,filtered,2020 39th Chinese Control Conference (CCC),IEEE,2020-07-29 00:00:00,ieeexplore,wind turbine frequent principal fault detection based on a self-attentive lstm encoder-decoder model,https://ieeexplore.ieee.org/document/9188717/,"With the development of intelligent monitoring technology, internet information technology, and data storage technology, data-driven fault detection and diagnosis method in the wind turbine system has become a focus of research in recent years. In this paper, we design a data-driven architecture for the wind turbine frequent principal fault detection. Considering the sequential relationship in the wind power data, we introduce the long short-term memory (LSTM) model. Additionally, to retain more necessary information hidden in the wind power time series, which is too long to make the performance of the LSTM model poor, we propose a novel self-attentive LSTM encoder-decoder(SALSTMED) model to learn the high-level feature sequence other than the feature vector. Further, the dataset collected from a real wind farm is employed to verify the performance of the proposed approach. The results indicate that the proposed approach is effective for the wind turbine frequent principal fault detection.",data driven architecture,537
10.1109/30.982782,filtered,IEEE Transactions on Consumer Electronics,IEEE,2001-11-01 00:00:00,ieeexplore,a novel hdtv video decoder and decentralized control scheme,https://ieeexplore.ieee.org/document/982782/,"A novel dedicated architecture for an HDTV video decoding chip is developed. Each task is mapped to a highly optimized hardware unit by classifying the video processing tasks into three levels. On the function level, a data driven architecture is adopted to make each processing unit operate once the processing data and buffer are available. Therefore the high computing efficiency of each unit is exploited, hardware is saved, and the computing capability is maximized compared with conventional pipeline decoder. On the system level, a decentralized control scheme is designed to provide high efficient communication between all the processing units to yield the best overall performance. Moreover it features simple control logic and minimum size of the connecting buffers.",data driven architecture,538
10.1109/tns.2006.870173,filtered,IEEE Transactions on Nuclear Science,IEEE,2006-02-01 00:00:00,ieeexplore,design and evaluation of the clear-pem scanner for positron emission mammography,https://ieeexplore.ieee.org/document/1610954/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities, and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with dimensions 16.5/spl times/14.5 cm/sup 2/ for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,539
10.1109/access.2021.3071274,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,graph neural network: a comprehensive review on non-euclidean space,https://ieeexplore.ieee.org/document/9395439/,"This review provides a comprehensive overview of the state-of-the-art methods of graph-based networks from a deep learning perspective. Graph networks provide a generalized form to exploit non-euclidean space data. A graph can be visualized as an aggregation of nodes and edges without having any order. Data-driven architecture tends to follow a fixed neural network trying to find the pattern in feature space. These strategies have successfully been applied to many applications for euclidean space data. Since graph data in a non-euclidean space does not follow any kind of order, these solutions can be applied to exploit the node relationships. Graph Neural Networks (GNNs) solve this problem by exploiting the relationships among graph data. Recent developments in computational hardware and optimization allow graph networks possible to learn the complex graph relationships. Graph networks are therefore being actively used to solve many problems including protein interface, classification, and learning representations of fingerprints. To encapsulate the importance of graph models, in this paper, we formulate a systematic categorization of GNN models according to their applications from theory to real-life problems and provide a direction of the future scope for the applications of graph models as well as highlight the limitations of existing graph networks.",data driven architecture,540
10.1109/tsp.2021.3117503,filtered,IEEE Transactions on Signal Processing,IEEE,2021-01-01 00:00:00,ieeexplore,lord-net: unfolded deep detection network with low-resolution receivers,https://ieeexplore.ieee.org/document/9557819/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector entitled LoRD-Net for recovering information symbols from one-bit measurements. Our method is a model-aware data-driven architecture based on deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. LoRD-Net operates in a blind fashion, which requires addressing both the non-linear nature of the data-acquisition system as well as identifying a proper optimization objective for signal recovery. Accordingly, we propose a two-stage training method for LoRD-Net, in which the first stage is dedicated to identifying the proper form of the optimization process to unfold, while the latter trains the resulting model in an end-to-end manner. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely <inline-formula><tex-math notation=""LaTeX"">$\sim 500$</tex-math></inline-formula> samples, for training.",data driven architecture,541
10.1109/access.2021.3091716,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,modeling and key technologies of a data-driven smart city system,https://ieeexplore.ieee.org/document/9462829/,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a `two-dimension, three-layer, and six-goal' top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated.",data driven architecture,542
10.1109/iccsnt.2011.6182500,filtered,Proceedings of 2011 International Conference on Computer Science and Network Technology,IEEE,2011-12-26 00:00:00,ieeexplore,a coarse-grained asynchronous data-driven design flow,https://ieeexplore.ieee.org/document/6182500/,"As the synchronous circuit design is facing some limits, such as the power wall and the clock skew problem, the asynchronous circuit design is approaching a revival. This paper presents a coarse-grained data-driven design flow for asynchronous circuits, which aims at both performance and design efficiency. Based on a set of data-driven components, pipelined asynchronous circuits can be efficiently constructed. We optimize the circuits by combining components to form coarse-grained pipelines. Experimental results on an asynchronous pipelined 32-bit iterative multiplier show the efficiency of our design flow.",data driven architecture,543
10.1109/chicc.2015.7260946,filtered,2015 34th Chinese Control Conference (CCC),IEEE,2015-07-30 00:00:00,ieeexplore,a new control algorithm based on data-driven design to reject ship course disturbance,https://ieeexplore.ieee.org/document/7260946/,"A kind of control algorithm based on data-driven design to reject ship course disturbance is proposed. Equivalent space and vectors are directly identified by using process data. Residual generator is designed based on complete state observer, and the Youla parameterization controller is then used to tune residual error through the identified equivalent space online. The gradient of quadratic performance index is directly estimated, and the Youla parameters of the controller are optimized online by using gradient descent method. The simulation results are shown that the influences of sea wave disturbance to ship course can be effectively rejected by using the online optimized controller and the robustness of the system can be improved.",data driven architecture,544
10.1109/cdc.2011.6160771,filtered,2011 50th IEEE Conference on Decision and Control and European Control Conference,IEEE,2011-12-15 00:00:00,ieeexplore,an approach to data-driven design of feedback control systems with embedded residual generation,https://ieeexplore.ieee.org/document/6160771/,"Motivated by the increasing needs in the process industry for designing fault tolerant feedback control systems based on process data, data-driven design of feedback control systems with embedded residual generation is addressed. For this purpose, an extended internal model control (EIMC) structure aiming at accessing the residuals embedded in control loop is first proposed. Based on the identification of the so-called parity subspace and a well-established mapping between the parity vector and the solution of the Luenberger equations, a direct design scheme of EIMC from process data is developed. The achieved results are illustrated by an academic example.",data driven architecture,545
10.1109/iccphot.2014.6831800,filtered,2014 IEEE International Conference on Computational Photography (ICCP),IEEE,2014-05-04 00:00:00,ieeexplore,can we beat hadamard multiplexing? data driven design and analysis for computational imaging systems,https://ieeexplore.ieee.org/document/6831800/,"Computational Imaging (CI) systems that exploit optical multiplexing and algorithmic demultiplexing have been shown to improve imaging performance in tasks such as motion deblurring, extended depth of field, light field and hyper-spectral imaging. Design and performance analysis of many of these approaches tend to ignore the role of image priors. It is well known that utilizing statistical image priors significantly improves demultiplexing performance. In this paper, we extend the Gaussian Mixture Model as a data-driven image prior (proposed by Mitra et. al [21]) to under-determined linear systems and study compressive CI methods such as light-field and hyper-spectral imaging. Further, we derive a novel algorithm for optimizing multiplexing matrices that simultaneously accounts for (a) sensor noise (b) image priors and (c) CI design constraints. We use our algorithm to design data-optimal multiplexing matrices for a variety of existing CI designs, and we use these matrices to analyze the performance of CI systems as a function of noise level. Our analysis gives new insight into the optimal performance of CI systems, and how this relates to the performance of classical multiplexing designs such as Hadamard matrices.",data driven architecture,546
10.1109/isie.2018.8433657,filtered,2018 IEEE 27th International Symposium on Industrial Electronics (ISIE),IEEE,2018-06-15 00:00:00,ieeexplore,comparison of two performance optimization approaches for data-driven design of fault-tolerant control systems,https://ieeexplore.ieee.org/document/8433657/,"In this paper, a residual generator-based data-driven fault-tolerant control (FTC) framework is reviewed. Based on that, the gradient descent and the reinforcement learning optimal control methods for dynamic compensator design of proposed FTC systems are reviewed. Both gradient descent and reinforcement learning methods can update the control strategy and improve system performance and robustness. By analyzing the theoretical characteristics of the two methods, it is determined whether the solutions of the two methods belong to the global or the local optimum. The effectiveness of the proposed two optimization approaches and the differences between the optimality of the solutions is tested and verified by using DC-motor benchmark case study.",data driven architecture,547
10.1109/wsc.2003.1261543,filtered,"Proceedings of the 2003 Winter Simulation Conference, 2003.",IEEE,2003-12-10 00:00:00,ieeexplore,data driven design and simulation system based on xml,https://ieeexplore.ieee.org/document/1261543/,"Implementing a highly flexible manufacturing approach, like mass customization manufacturing, demands an integrated design and simulation system. This system must be able to cope with difficult issues such as a high level of product variety, uncertainty in the product demand forecast, and the reconfiguration of manufacturing resources to support the introduction and integration of new manufacturing capabilities. A data-driven design and simulation system to support flexible manufacturing is presented. A neutral model of shop information, based on the Extensible Markup Language (XML), is used to describe the important information about the manufacturing facilities and processes, to configure simulation models and to exchange data between simulation and other manufacturing applications. When demand changes, the simulation model can be quickly modified to perform analysis according to the new demand. Manufacturing capabilities and production processes can be adjusted, layout reconfigured, and resources reassigned according to the analysis results.",data driven architecture,548
10.1109/rams.2016.7448023,filtered,2016 Annual Reliability and Maintainability Symposium (RAMS),IEEE,2016-01-28 00:00:00,ieeexplore,data driven design for reliability,https://ieeexplore.ieee.org/document/7448023/,"Reliability is one of the driving factors towards perceived product value and brand image. In addition, reliability in the automotive industry plays a crucial role for product safety. During fast-paced product development, design for reliability is essential to guarantee product reliability while maintaining short iteration times. This requires detailed knowledge of relevant failure modes, loads and use cases. However, most product and test design is based on assumptions, estimations and experience. Here we show how to leverage field data to design reliability into the product along its whole development cycle. We use field reliability data to derive the reliability allocation which drives the reliability targets for the systems and subsystems. Based on actual user data, we provide design engineers with requirements for relevant use cases. Furthermore, the data helps us to develop user-specific test profiles. Our approach shows how data driven product development can reduce development times and leads to more user centered product designs. Additionally, using field data derived test profiles reveals relevant failure modes during testing and simulation. We anticipate our data driven design for reliability (DfR) process to positively influence the way reliability is implemented.",data driven architecture,549
10.1109/icmi.2002.1166984,filtered,Proceedings. Fourth IEEE International Conference on Multimodal Interfaces,IEEE,2002-10-16 00:00:00,ieeexplore,data driven design of an ann/hmm system for on-line unconstrained handwritten character recognition,https://ieeexplore.ieee.org/document/1166984/,"This paper is dedicated to a data driven design method for a hybrid ANN/HMM based handwriting recognition system. On one hand, a data driven designed neural modelling of handwriting primitives is proposed. ANNs are firstly used as state models in a HMM primitive divider that associates each signal frame with an ANN by minimizing the accumulated prediction error. Then, the neural modelling is realized by training each network on its own frame set. Organizing these two steps in an EM algorithm, precise primitive models are obtained. On the other hand, a data driven systematic method is proposed for the HMM topology inference task. All possible prototypes of a pattern class are firstly merged into several clusters by a tabu search aided clustering algorithm. Then a multiple parallel-path HMM is constructed for the pattern class. Experiments prove an 8% recognition improvement with a saving of 50% of system resources, compared to an intuitively designed referential ANN/HMM system.",data driven architecture,550
10.1109/wow45936.2019.9030612,filtered,2019 IEEE PELS Workshop on Emerging Technologies: Wireless Power Transfer (WoW),IEEE,2019-06-21 00:00:00,ieeexplore,data-driven design and assessment of dynamic wireless charging systems,https://ieeexplore.ieee.org/document/9030612/,"Dynamic wireless charging of electric vehicles has the potential to alleviate range anxiety. This paper proposes a traffic data-driven design methodology for the charging system, including the power distribution network from the substation to the transmitters. The objective is to evaluate the impact of the design on the distribution system. A high-speed US Interstate corridor is used as a case study. The results reveal that aggregate power demand may fluctuate significantly, which can be detrimental to power system operation.",data driven architecture,551
10.1109/cac.2015.7382831,filtered,2015 Chinese Automation Congress (CAC),IEEE,2015-11-29 00:00:00,ieeexplore,data-driven design for static model-based fault diagnosis,https://ieeexplore.ieee.org/document/7382831/,"This paper focuses on Data-Driven Design FOR Model-Based fault diagnosis, called D34MB for short. When the objective model is static, LVD (Latent Variable Detection) methods can be realized based on the LVE (Latent Variable Extraction) and LVR (Latent Variable Regression) techniques. A unified weight-framework for D34MB are proposed in this paper, which shows that all D34MB methods share the same procedures, i.e., LVE, LVR and LVD. The detection theorems shows that D34MB methods based on RRR (Rank Reduction Regression) and CCA (Canonical Correlation Analysis), compared with PCA (Principal Component Analysis) and PLS (Partial Least Square), tend to ensure higher calibration accuracy in terms of MSE as well as better detection performance in terms of FDR (Fault Detection Rate). In the case study, TEP (Tennessee Eastman Process) validates the correctness of our theoretical results.",data driven architecture,552
10.1109/icassp.2019.8683861,filtered,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",IEEE,2019-05-17 00:00:00,ieeexplore,data-driven design of perfect reconstruction filterbank for dnn-based sound source enhancement,https://ieeexplore.ieee.org/document/8683861/,"We propose a data-driven design method of perfect-reconstruction filterbank (PRFB) for sound-source enhancement (SSE) based on deep neural network (DNN). DNNs have been used to estimate a time-frequency (T-F) mask in the short-time Fourier transform (STFT) domain. Their training is more stable when a simple cost function as mean-squared error (MSE) is utilized comparing to some advanced cost such as objective sound quality assessments. However, such a simple cost function inherits strong assumptions on the statistics of the target and/or noise which is often not satisfied, and the mismatch of assumption results in degraded performance. In this paper, we propose to design the frequency scale of PRFB from training data so that the assumption on MSE is satisfied. For designing the frequency scale, the warped filterbank frame (WFBF) is considered as PRFB. The frequency characteristic of learned WFBF was in between STFT and the wavelet transform, and its effectiveness was confirmed by comparison with a standard STFT-based DNN whose input feature is compressed into the mel scale.",data driven architecture,553
10.1109/chicc.2015.7260619,filtered,2015 34th Chinese Control Conference (CCC),IEEE,2015-07-30 00:00:00,ieeexplore,data-driven design and implementation of an alternately adaptive residual generator for hammerstein systems,https://ieeexplore.ieee.org/document/7260619/,"This paper addresses the data-driven design and implementation of an adaptive observer-based residual generator for Hammerstein systems. The basic idea behind this study is the application of a one-to-one mapping between a parity vector and the solution of Luenberger equations, the identification of the parity space and the Hammerstein nonlinearity via the over-parameterization and least squares support vector machine (LS-SVM). For the realization of adaptivity, the linear and nonlinear parameters are separated and estimated recursively in a parallel manner, with each updating algorithm using the most up-to-date estimation produced by the other algorithm at each time instant. Hence the procedure is termed the alternately adaptive algorithm. Furthermore, the stability condition of algorithm is investigated.",data driven architecture,554
10.1109/wcica.2014.7053249,filtered,Proceeding of the 11th World Congress on Intelligent Control and Automation,IEEE,2014-07-04 00:00:00,ieeexplore,data-driven design and robust implementation of monitoring and fault detection system for amt vehicles,https://ieeexplore.ieee.org/document/7053249/,"Automated manual transmission (AMT) and its automatic shifting is of significance on the improvement of driveline performance and reliability. Due to numbers of electrical, mechanical and vehicle longitudinal dynamics, both establishing an analytical AMT model and designing its monitoring and fault detection (MFD) system become too complicated to implement for automotive engineers and servicemen. To solve the problem, in this paper, the data-driven design approach is introduced. The central idea behind the scheme is to construct a parity vector-based residual generator from test data and, based on on-line ones, to realize a robust adaptive residual generation against changes along with driving conditions. A simulation study using a driveline model constructed by the commercial software AMESim is given to illustrate the availability of the designed MFD system.",data driven architecture,555
10.1109/acc.2013.6580528,filtered,2013 American Control Conference,IEEE,2013-06-19 00:00:00,ieeexplore,data-driven design of kpi-related fault-tolerant control system for wind turbines,https://ieeexplore.ieee.org/document/6580528/,"In this paper, a scheme for an integrated design of fault-tolerant control (FTC) systems for a wind turbine benchmark is proposed, with focus on the overall performance of the system. For that a key performance indicator (KPI) which reflects the economic performance of the system is defined, and the objective of the proposed FTC scheme is to maintain the system KPI in the admissible range in faulty conditions. The basic idea behind this scheme is data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilizing controllers with an embedded residual generator for fault detection (FD) purpose. The performance and effectiveness of the proposed scheme are demonstrated through the wind turbine benchmark model proposed in [1].",data driven architecture,556
10.1109/icset.2016.7811778,filtered,2016 IEEE International Conference on Sustainable Energy Technologies (ICSET),IEEE,2016-11-16 00:00:00,ieeexplore,data-driven design of a cascaded observer for battery state of health estimation,https://ieeexplore.ieee.org/document/7811778/,"The design of an observer for battery state of charge (SoC) and state of health (SoH) using data-driven models is addressed. SoH estimation is an important issue in battery management system design for (hybrid) electrical vehicles. Without SoH correction, the accuracy of the SoC indication system will decrease progressively with battery age/degradation. In order to take the battery degradation into account, ageing data analysis using data-driven models and the associated model adaptation is addressed. Furthermore, a cascaded observer structure for combined SoC and SoH estimation is presented and preliminary results using real measurement data demonstrate the performance of the proposed concepts.",data driven architecture,557
10.1109/acc.2015.7170738,filtered,2015 American Control Conference (ACC),IEEE,2015-07-03 00:00:00,ieeexplore,data-driven design of fault detection and isolation systems subject to hammerstein nonlinearity,https://ieeexplore.ieee.org/document/7170738/,"This paper is concerned with data-driven design of fault detection and isolation (FDI) systems subject to Hammerstein nonlinearity, a static nonlinearity in the front of inputs. Specifically, the design of residual generation is then formulated as to solve a convex optimization problem by combining ideas from the over-parameterization and least squares support vector machines (LS-SVMs), and thus provides residual signals directly from process data. To solve the multiply-outputs (MOs) problem, a modified approach is proposed by means of the so-called mixed block Hankel matrices. Sufficient conditions for the existence of a parity space are established and proved. A benchmark example is given to show the effectiveness of the proposed approach.",data driven architecture,558
10.1109/icra.2017.7989268,filtered,2017 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2017-06-03 00:00:00,ieeexplore,data-driven design of implicit force control for industrial robots,https://ieeexplore.ieee.org/document/7989268/,"Standard control design for robot implicit force control is a typical example of model-based regulator synthesis. This paper proposes a method to improve closed-loop performance of standard model-based controllers for robot implicit force control in terms of closed-loop model matching, between desired and achieved closed-loop behaviour. To this end, a data-driven controller design method, based on the Virtual Reference Feedback Tuning (VRFT) approach, is introduced. Advantages in terms of robustness with respect to unknown environment stiffness are discussed and demonstrated. The effectiveness of the proposed control strategy is experimentally validated on an industrial robot equipped with a force sensor.",data driven architecture,559
10.1109/cdc42340.2020.9303853,filtered,2020 59th IEEE Conference on Decision and Control (CDC),IEEE,2020-12-18 00:00:00,ieeexplore,direct data-driven design of neural reference governors,https://ieeexplore.ieee.org/document/9303853/,"In this paper, we present a direct data-driven approach to synthesize model reference controllers for constrained nonlinear dynamical systems. To this aim, we employ a hierarchical structure composed by a receding-horizon reference governor and a data-driven low-level controller. Unlike existing approaches, here we jointly design the two blocks by solving a single optimization task, exploiting the fact that the inner controller will never be used alone. The performance of the proposed method is assessed by means of two simulation examples, involving the control of two highly nonlinear benchmark systems.",data driven architecture,560
10.1109/acc.2013.6580307,filtered,2013 American Control Conference,IEEE,2013-06-19 00:00:00,ieeexplore,direct data-driven design of sparse controllers,https://ieeexplore.ieee.org/document/6580307/,This paper deals with direct data-driven design of model-reference controllers whose number of parameters is constrained. Input-output (I/O) sparse controllers are introduced and proposed as an alternative to low-order controller tuning. The optimal I/O sparse controller is shown to be never worse than the optimal low-order controller with the same number of parameters and a suited design procedure based on convex optimization is derived. The theoretical concepts are illustrated by means of a benchmark simulation example.,data driven architecture,561
10.23919/acc50511.2021.9482806,filtered,2021 American Control Conference (ACC),IEEE,2021-05-28 00:00:00,ieeexplore,direct data-driven design of switching controllers for constrained systems,https://ieeexplore.ieee.org/document/9482806/,"This paper presents a hierarchical structure to directly design controllers for (possibly nonlinear) constrained systems. The proposed architecture combines the advantages of an inner data-driven switching controller designed to achieve a predefined closed-loop behavior and an outer model predictive controller, which is used as a reference governor. These design choices enable us to avoid the identification step typical of model-based approaches while exploiting the ability of model predictive controllers to handle constraints and optimize the closed-loop performance. As a proof of concept, a benchmark simulation example is used to demonstrate the effectiveness of the proposed strategy.",data driven architecture,562
10.1109/icet.2012.6375467,filtered,2012 International Conference on Emerging Technologies,IEEE,2012-10-09 00:00:00,ieeexplore,on fault detection in coupled liquid three tank system using subspace aided data driven design,https://ieeexplore.ieee.org/document/6375467/,The paper deals with parity based data driven design of the fault detection (FD) systems. The main idea is to extract the process model from test data using subspace system identification (SIM) methods. The identified system model is thenused to develop parity relation for detecting actuator and sensor faults. The application of the technique is shown by simulation study of coupled liquid three tank system.,data driven architecture,563
10.1109/cdc45484.2021.9683046,filtered,2021 60th IEEE Conference on Decision and Control (CDC),IEEE,2021-12-17 00:00:00,ieeexplore,probabilistically robust bayesian optimization for data-driven design of arbitrary controllers with gaussian process emulators,https://ieeexplore.ieee.org/document/9683046/,"A fundamental challenge in control applications stems from the lack of a sufficiently detailed system model that can be used for systematic controller design and tuning under uncertainty. This paper presents a fully data-driven robust controller design approach based on any finite set of closed-loop performance measures. We first present a method for emulating the unknown plant dynamics using a Gaussian process (GP) model learned from input-output data. By running closed-loop simulations under realizations of the GP model using posterior sampling, the impact of system uncertainties on the closed-loop performance measures is quantified. We then formulate the robust controller design problem as a constrained Bayesian optimization (CBO) problem defined in terms of the GP-emulated performance measures. To ensure a sufficient number of samples are used to estimate the worst-case performance measures, we derive a bound on the joint probability of violation that is independent of the number or probability distribution of the uncertainties. The advantages of the proposed approach are illustrated on a benchmark control problem, which demonstrates guaranteed probabilistic estimates on the worst-case performance measures are provided at every iteration of CBO.",data driven architecture,564
10.1109/tie.2014.2301757,filtered,IEEE Transactions on Industrial Electronics,IEEE,2014-11-01 00:00:00,ieeexplore,data-driven design and optimization of feedback control systems for industrial applications,https://ieeexplore.ieee.org/document/6718131/,"In this paper, regarding the observer form of the well-known Youla parameterization, the controller design and optimization are exhibited with an integrated residual access. To better reveal this philosophy, the feedback control loop is interpreted on the basis of the observer-based residual generator. The next main attention is drawn to the generation of residuals, the design of a deadbeat controller for system stabilization both in the data-driven environment, and later the optimal adaptive realization of a dynamic system that translates residuals into compensatory control inputs to meet certain performance specifications. Towards these goals, numerical algorithms are summarized, and for the issues of controller optimization, the reinforcement learning algorithm is introduced using only measured input-output and residual signals. In addition, the effectiveness of developed schemes for industrial applications is also illustrated by experimental studies on a laboratory continuous stirred tank heater (CSTH) process.",data driven architecture,565
10.1109/tcst.2011.2171965,filtered,IEEE Transactions on Control Systems Technology,IEEE,2013-01-01 00:00:00,ieeexplore,data-driven design of braking control systems,https://ieeexplore.ieee.org/document/6069827/,"The spread of active braking controllers on vehicles with significant mechanical differences and on low-cost products asks for control design approaches which offer easy and fast calibration and re-tuning capabilities. This task is made difficult by the use of model-based control approaches which heavily rely on specific vehicle dynamics descriptions. To address these issues, this brief paper proposes a data-driven approach to active braking control design, grounded on the virtual reference feedback tuning (VRFT) approach complemented with a data-driven nonlinear compensator. The effectiveness of the proposed approach is assessed both on a full-fledged multibody simulator and on a tire-in-the-loop experimental facility.",data driven architecture,566
10.1109/tii.2018.2843124,filtered,IEEE Transactions on Industrial Informatics,IEEE,2018-10-01 00:00:00,ieeexplore,data-driven design of fog-computing-aided process monitoring system for large-scale industrial processes,https://ieeexplore.ieee.org/document/8370742/,"Stimulated by the recent development of fog computing technology, in this paper, a fog-computing-aided process monitoring and control architecture is proposed for large-scale industrial processes, which enables reliable and efficient online performance optimization in each fog computing node without modifying predesigned control subsystems. Moreover, a closed-loop data-driven method is developed for the process monitoring system design and an adaptive configuration approach is proposed to deal with the problems caused by the changes of process parameters and operating points. The feasibility and effectiveness of the proposed design approaches are verified and demonstrated through the case study on the Tennessee Eastman benchmark system.",data driven architecture,567
10.1109/smc.2018.00531,filtered,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",IEEE,2018-10-10 00:00:00,ieeexplore,a data-driven fault detection approach for dynamic processes with sinusoidal disturbance,https://ieeexplore.ieee.org/document/8616528/,"This paper presents the latest study on the data-driven process monitoring system design for the dynamic processes with sinusoidal disturbance. In the previous study, it is understood that the row space of the deterministic disturbance is essential to the subspace method aided data-driven design. Based on the previous study, this paper first determines the row space of sinusoidal disturbance. By projecting the process data into the determined subspaces, the fault detection systems can be designed based on the identified kernel subspace of the system. The performance and effectiveness of the proposed scheme are verified and demonstrated through the numerical study on randomly generated systems.",data driven architecture,568
10.1109/icai52203.2021.9445243,filtered,2021 International Conference on Artificial Intelligence (ICAI),IEEE,2021-04-07 00:00:00,ieeexplore,a data-driven interactive system for aerodynamic and user-centred generative vehicle design,https://ieeexplore.ieee.org/document/9445243/,"In this work, we propose a data-driven design pipeline for quick design exploration of performance and appearance guided alternatives for vehicle design. At the heart of our system is a machine learning-based generative design method to provide users with a set of diverse optimal design alternatives and an interactive design technique to induce users' preference into the design exploration. The generative design method is the structure on two search process, qualitative and quantitative. To avoid the curse of dimensionality, the qualitative search process first builds up a lower-dimensional representation of a given design space, which is then explored using the unsupervised k-means clustering to synthesise a representative set of user-preferred designs. The quantitative search process explores the design space to find an optimal design in terms of performance criterion such as drag coefficient. To reduce the computational complexity, instead of evaluating drag via Computational Fluid Dynamics simulations, a surrogate model is developed to predict the drag coefficients. The designs generated after the generative design step are presented to the user at the interactive step, where potential regions of the design space are identified around the user-selected designs. Afterwards, a new design space is generated by removing the non-preferred regions, which helps to focus the computational efforts on the exploration of the user preferred regions of the design space for a design tailored to the user's requirements. We demonstrated the performance of the proposed approach on a two-dimensional side silhouette of a sport-utility vehicle.",data driven architecture,569
10.23919/acc.2018.8430792,filtered,2018 Annual American Control Conference (ACC),IEEE,2018-06-29 00:00:00,ieeexplore,a data-driven approach to stochastic constrained control of piecewise affine systems,https://ieeexplore.ieee.org/document/8430792/,"This paper addresses the design of the control input to a discrete time piecewise affine system so as to optimize its performance along a finite time horizon. The system is affected by some additive stochastic disturbance and is subject to constraints that need to be appropriately accounted for in the design. By enforcing constraints to be satisfied for almost all disturbance realizations except for a set of probability ε, we can decide to what extent trading robustness for improving performance and also cope with the case of disturbance with unbounded support. Inspired by the existing literature, we propose a method to realize this trade-off, which combines the scenario approach to chance-constrained optimization with robust optimal control of piecewise affine systems. Interestingly, no explicit knowledge of the disturbance distribution is needed but only some disturbance realizations, thus resulting in a data-driven design method.",data driven architecture,570
10.1109/isie.2013.6563842,filtered,2013 IEEE International Symposium on Industrial Electronics,IEEE,2013-05-31 00:00:00,ieeexplore,a modified observer-based prediction approach for industrial applications,https://ieeexplore.ieee.org/document/6563842/,"The prediction of key variables has great significance to monitor the running status of industrial systems. In this paper, a novel data-driven design of variable predictor is proposed. The basic idea is the realization of prediction observer, which is modified from the observer-based fault diagnose method. Different from the standard data-driven approaches, the proposed scheme is adopted for the dynamic systems due to the superior tracking ability of output observer. Additionally, by introducing an extra design freedom and the estimation of measured value, it can also be used for the case that the key variable is not on-line measurable. Finally, the proposed prediction scheme is applied to the Tennessee-Eastman plant to demonstrate the effectiveness.",data driven architecture,571
10.1109/fuzzy.2007.4295668,filtered,2007 IEEE International Fuzzy Systems Conference,IEEE,2007-07-26 00:00:00,ieeexplore,a semantic driven evolutive fuzzy clustering algorithm,https://ieeexplore.ieee.org/document/4295668/,In this paper it is show that the same semantic constraints used to ensure linguistic interpretation in data driven design of fuzzy systems are also useful in the design of evolutive fuzzy clustering algorithms. Specifically it is show that these constraints generalize the constraints used in popular fuzzy clustering algorithms such as the FCM. Experimental studies illustrate the effectiveness of this approach to clustering. The algorithm attempts to optimize the clusters' parameters as well as the number of clusters (a dynamically variable length of chromosomes is used).,data driven architecture,572
10.1109/cdc.2017.8263833,filtered,2017 IEEE 56th Annual Conference on Decision and Control (CDC),IEEE,2017-12-15 00:00:00,ieeexplore,a set-membership approach to direct data-driven control design for siso non-minimum phase plants,https://ieeexplore.ieee.org/document/8263833/,"In the context of direct data-driven design, we propose a controller design procedure on the basis of a set of experimental input/output data, with no identification of the plant model. The objective of the control problem is to make the closed-loop system to match the behavior of an assigned reference model as close as possible. As is well known, the presence of one of more non-minimum phase zeros in the plant transfer function makes the direct data-driven design procedure significantly harder since, no matter what is the considered approach among the ones proposed in the literature, the designed controller commonly leads to an unstable closed-loop system due to unstable pole-zero cancellations. In this paper we propose a new approach for performing the design of direct data-driven controller when the unknown plant may or may not have non-minimum phase zeros. The problem is formulated in the context of the set-membership estimation theory, and previous results from some ot the authors on errors-in-variables identification are exploited to compute the controller parameters. The effectiveness of the presented technique is demonstrated by means of two simulation examples.",data driven architecture,573
10.1109/iemdc.2019.8785160,filtered,2019 IEEE International Electric Machines & Drives Conference (IEMDC),IEEE,2019-05-15 00:00:00,ieeexplore,an hpc-based data-driven process for design exploration and optimization of motor drives,https://ieeexplore.ieee.org/document/8785160/,"A simulation-based data-driven design process for knowledge extraction and optimizing the size and the parameters of an integrated motor drive is proposed. With the importance of simultaneously optimizing the motor and inverter in a variable-speed application, this work provides a transition from the classical design process by introducing and investigating a data-driven design process. In addition to outlining its implementation, several practical issues associated with using a high-performance computing service are addressed, such as utilization factor and speedup ratio. In this paper, a case study of an interior permanent magnet motor coupled with a two-level inverter modulated by space vectors is simulated with the help of MATLAB/Simulink, MagNet, ThermNet and Microsoft Azure. Around 36000 motor-drive models with different geometries were created and analyzed while incorporating the electromagnetic-thermal behavior of the motor components and inverter switches. Following the design sampling and exploration, valuable knowledge is extracted to aid future procedures. Finally, a neural network model fitted to more than 20 objectives is used to optimize the motor-drive operation in transient, rated and flux weakening modes using an evolutionary optimization algorithm. With the aid of the proposed approach, existing design exploration and optimization tools can be converted to an automatic and informative application-oriented design package.",data driven architecture,574
10.1109/cdc42340.2020.9303843,filtered,2020 59th IEEE Conference on Decision and Control (CDC),IEEE,2020-12-18 00:00:00,ieeexplore,an h<inf>∞</inf> method to design the reference model in direct data-driven control design,https://ieeexplore.ieee.org/document/9303843/,"As far as direct data-driven design is concerned, no matter the design approach to be exploited, the objective of the control problem is to make the closed-loop system to match, as close as possible, the behavior of an assigned reference model M. In this work, we investigate the problem of designing a suitable reference model M by using the H<sub>∞</sub> control techniques. More specifically, we propose a procedure that provides a reference model guaranteed to fulfill a number of quantitative performance requirements for both minimum-phase (MP) and non-minimum phase (NMP) stable plant, by solving a suitably formulated fictitious H<sub>∞</sub> control problem. The effectiveness of the presented technique is demonstrated by means of a simulation example using the set-membership based direct data-driven control approach.",data driven architecture,575
10.1109/asicon.2015.7517028,filtered,2015 IEEE 11th International Conference on ASIC (ASICON),IEEE,2015-11-06 00:00:00,ieeexplore,an automated test framework for sram-based fpga,https://ieeexplore.ieee.org/document/7517028/,"An automated test framework for SRAM-based FPGA is presented. With the framework, test configurations of different categories can be partially or completely generated, and the tests be running using the generated configurations. Data driven design provides the test framework the flexibility of change the user interface and the command line arguments via software configuration files, without modifying the source code of the framework. Experimental results shows that the test framework handles the complicate test flow efficiently, and release the test engineer from the tedious testing work.",data driven architecture,576
10.1109/iecon.2015.7392366,filtered,IECON 2015 - 41st Annual Conference of the IEEE Industrial Electronics Society,IEEE,2015-11-12 00:00:00,ieeexplore,application of fictitious reference iterative tuning to vibration suppression controller for 2-inertia resonance system,https://ieeexplore.ieee.org/document/7392366/,"In this paper, we propose an off-line tuning method of the vibration suppression controller gains for 2-inertia system using Fictitious Reference Iterative Tuning (FRIT). FRIT is one of data-driven design methods using only one-shot experimental input-output data without model parameters of the controlled object. We use the modified-IPD speed controller which consists of the 2-degree of freedom PID control, considering response speed, and in addition, we use the first lag element in order to increase degree of freedom of the control design. Then, we consider the current loop for the high speed torque control. In this paper, a PI controller is used for the current control. Here, in this paper, we use the particle swarm optimization as the optimization searching method, and the performance index is the IAE. So, we confirmed the effectiveness of the proposed method which used only one-shot experiment result by experimental setup.",data driven architecture,577
10.1109/acii.2013.33,filtered,2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,IEEE,2013-09-05 00:00:00,ieeexplore,automatically recognizing facial indicators of frustration: a learning-centric analysis,https://ieeexplore.ieee.org/document/6681424/,"Affective and cognitive processes form a rich substrate on which learning plays out. Affective states often influence progress on learning tasks, resulting in positive or negative cycles of affect that impact learning outcomes. Developing a detailed account of the occurrence and timing of cognitive-affective states during learning can inform the design of affective tutorial interventions. In order to advance understanding of learning-centered affect, this paper reports on a study to analyze a video corpus of computer-mediated human tutoring using an automated facial expression recognition tool that detects fine-grained facial movements. The results reveal three significant relationships between facial expression, frustration, and learning: (1) Action Unit 2 (outer brow raise) was negatively correlated with learning gain, (2) Action Unit 4 (brow lowering) was positively correlated with frustration, and (3) Action Unit 14 (mouth dimpling) was positively correlated with both frustration and learning gain. Additionally, early prediction models demonstrated that facial actions during the first five minutes were significantly predictive of frustration and learning at the end of the tutoring session. The results represent a step toward a deeper understanding of learning-centered affective states, which will form the foundation for data-driven design of affective tutoring systems.",data driven architecture,578
10.1109/eitech.2016.7519618,filtered,2016 International Conference on Electrical and Information Technologies (ICEIT),IEEE,2016-05-07 00:00:00,ieeexplore,automating data warehouse design using ontology,https://ieeexplore.ieee.org/document/7519618/,"Requirement Analysis is a crucial and arduous task in data warehouse design process. We provide a solution to support data warehouse design, which combines need driven and data driven design approaches. Our solution is based on ontology representation language and work results on ontology alignment. Our design method occurs in two steps. The first one, which is interactive and semi-automatic, transforms user requirements into ontologies, the second step that is fully automatic, aligns the resulting ontologies from the first step and produces an ontology associated to the Multidimensional Data model. The waste management field will be our guideline to illustrate our approach.",data driven architecture,579
10.1109/werob.2017.8383868,filtered,2017 International Symposium on Wearable Robotics and Rehabilitation (WeRob),IEEE,2017-11-08 00:00:00,ieeexplore,characterisation of a soft exosuit for assistance of the elbow joint,https://ieeexplore.ieee.org/document/8383868/,"The use of fabric-based frames and Bowden cables to transmit forces and torques to the human body allows to design active assistive devices that are lighter, more comfortable and cosmetically less invasive than traditional exoskeletons. This approach has been shown to be successful in reducing the metabolic cost and muscular effort of human movements and in assisting impaired subject in daily activities. Yet still very little is known about how to optimise the transmission of forces at the interface between the suit and the human body, with significant implications for comfort, efficiency and safety of the device. This work outlines the design and characterisation of a soft, textile-based exosuit for assistance of flexion/extension of the elbow joint, with emphasis on a data-driven design for optimising the efficiency of the transmission and the distribution of forces at the human-suit interface. Quantifying and understanding how design choices such as the materials used for transmitting power and the structure of the functional components of the suit affect these parameters can help us to improve the ergonomics, safety and effectiveness of such devices. Results obtained by comparing different Bowden cables constructions show that the ones with a linear-strand construction offer the highest efficiency and stiffness, lowest backlash and lowest viscous friction. Combining semi-rigid components with fabric at the anchor points of the suit allows for a more homogeneous distribution of force at the human-suit interface, avoiding peaks of pressure that can disrupt subcutaneous blood flow and cause tissue damage.",data driven architecture,580
10.1109/cac.2015.7382832,filtered,2015 Chinese Automation Congress (CAC),IEEE,2015-11-29 00:00:00,ieeexplore,d34mb - a fdi toolbox with new features,https://ieeexplore.ieee.org/document/7382832/,"A toolbox is developed in the MATLAB/GUI environment for FDI (Fault Detection and Isolation) which is an important field of automatic control theory and engineering. It provides an interactive interface for FDI. In this GUI (Graphical User Interface), a variety of methods are available for the FDI tasks, e.g., the traditional data-driven and model-based methods. a new feature of it is D34MB (Data Driven Design for Model Based) fault diagnosis. Some other new methods, e.g., robust, adaptive and local approach are also implemented. The sufficient benchmarks toolbox and the GUI feature ensure user-friendliness for operating this toolbox. Among all the methods, D34MB is emphasized, which is why the whole toolbox is called D34MB FDI toolbox. The new feature for static and dynamic model, the design, and the application of the toolbox is illustrated in this paper.",data driven architecture,581
10.23919/acc.2018.8431376,filtered,2018 Annual American Control Conference (ACC),IEEE,2018-06-29 00:00:00,ieeexplore,data-driven controller design for boolean control networks,https://ieeexplore.ieee.org/document/8431376/,"Model identification of Boolean control networks requires not only a vast amount of data but also renders the problem of high computational complexity. The introduced data-driven design method of a stabilizing feedback controller reduces the requirements on the data set compared to the traditional two step procedure, first model identification then controller design. The idea is that for output stabilization it is not necessary to know all the internal dynamics. To widen the applicability, the method is extended to design a high order feedback controller. All the introduced algorithms are illustrated with examples.",data driven architecture,582
10.1109/cdc.2018.8619485,filtered,2018 IEEE Conference on Decision and Control (CDC),IEEE,2018-12-19 00:00:00,ieeexplore,data-driven dynamic control allocation for uncertain redundant plants,https://ieeexplore.ieee.org/document/8619485/,"This paper addresses the problem of achieving high-performance dynamic control allocation for uncertain plants by exploiting a data-driven design of the annihilator for the underlying plant. Previous work revealed that an output invisible control allocator can be decomposed as the cascade interconnection of a steady-state optimizer and an annihilator, where the latter unit modulates the allocator outputs in such a way to render such signals undetectable from the plant output. Clearly, the critical role and challenging requirements imposed on the annihilator make it the source of the fragility of control allocation schemes in the presence of uncertainty; nonetheless this critical aspect can be (almost) completely circumvented by tuning the annihilator to the actual plant parameters, namely by envisioning a data-driven control allocation scheme. Relations are also highlighted between the present results and the concepts of moments and orthogonal moments of a plant at frequencies of interest, whose use and estimation have recently been the subject of increasing interest.",data driven architecture,583
10.1109/wi-iat.2015.80,filtered,2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT),IEEE,2015-12-09 00:00:00,ieeexplore,data-driven semantic concept analysis for user profile learning in 3g recommender systems,https://ieeexplore.ieee.org/document/7397430/,"The paper presents Semantic Concept Analysis (SCA) framework intended for automatic data-driven design of actionable ontology specifying mobile device user's personal interest's hierarchy together with dual structure reflecting the user's preferences over these interests. The framework integrates known technique for semi-automatic ontology design exploiting DBpedia and Wikipedia categories, on the one hand, and the data-driven Formal Concept Analysis (FCA), on the other one. The framework implements a kind of machine-learning approach integrating algebraic and statistical models of data and knowledge structured as s a pair of dual concept semi-lattices. The proposed technology implementing SCA framework basic ideas is validated experimentally through its software prototyping and subsequent computer experimentation using natural language text data sample.",data driven architecture,584
10.1109/ans47466.2019.8963745,filtered,2019 IEEE Albany Nanotechnology Symposium (ANS),IEEE,2019-11-13 00:00:00,ieeexplore,data-driven approximate edge detection using flow-based computing on memristor crossbars,https://ieeexplore.ieee.org/document/8963745/,"Detection of edges in images is an elementary operation in computer vision that can greatly benefit from an implementation with a low power-delay product. In this paper, we propose a new approach for designing nanoscale memristor crossbars that can implement approximate edge-detection using flow-based computing. Instead of the traditional Boolean approach, our methodology uses a ternary logic approach with three outcomes: True representing an edge, False that representing the absence of an edge, and Don't Care that represents an ambivalent response. Our data-driven design approach uses a corpus of human-labeled edges in order to learn the concept of an edge in an image. A massively parallel simulated annealing search algorithm over 96 processes is used to obtain the design of the memristor crossbar for edge detection. We show that our approximate crossbar design is effective in computing edges of images on the BSD500 benchmark.",data driven architecture,585
10.1109/icamechs.2015.7287152,filtered,2015 International Conference on Advanced Mechatronic Systems (ICAMechS),IEEE,2015-08-24 00:00:00,ieeexplore,data-driven pid gain tuning for unknown impulse disturbance attenuation,https://ieeexplore.ieee.org/document/7287152/,"Data-driven design approaches based on input-output measurements with no need for help from a plant model have attracted attention from several researchers. We have proposed such a disturbance attenuation Fictitious Reference Iterative Tuning (FRIT) using input-output data generated by a step or impulse disturbance, and showed the effectiveness of the approach through experiments of DC motor control and helicopter attitude control. The present work applies the approach to the experimental data for temperature control. The PID gains are tuned so that temperature of a piece of metal would follow a disturbance reference model output signal. From the experimental result, the disturbance attenuation FRIT is effective for PID gain tuning from closed-loop input and output experimental data generated by a impulse disturbance with unknown magnitude.",data driven architecture,586
10.1109/sice.2008.4655061,filtered,2008 SICE Annual Conference,IEEE,2008-08-22 00:00:00,ieeexplore,data-driven controller design for loop-shaping using plant transient responses,https://ieeexplore.ieee.org/document/4655061/,"In this paper, a data-driven design method of a feedback gain for loop shaping is proposed for a single input plant. This method can be applied to the tuning of a static feedback gain and also that of the output matrix of a dynamical controller. Constraints on the feedback gain are derived based on the unfalsified control using the plant responses without assuming any mathematical model. A solution can be obtained by solving a linear matrix inequality, where the integral gain of the loop transfer function is maximized subject to the constraints. Numerical examples demonstrate the usefulness.",data driven architecture,587
10.1109/cdc.2017.8264604,filtered,2017 IEEE 56th Annual Conference on Decision and Control (CDC),IEEE,2017-12-15 00:00:00,ieeexplore,data-driven deadbeat control with application to output regulation,https://ieeexplore.ieee.org/document/8264604/,"In this paper, a data-driven design of deadbeat controllers is proposed, which is later generalized in different ways to allow for trade-offs between convergence rate and control effort. The proposed design is then combined with recent work on data-driven output regulation using external models, and shown to provide very desirable responses.",data driven architecture,588
10.1109/ecce44975.2020.9235958,filtered,2020 IEEE Energy Conversion Congress and Exposition (ECCE),IEEE,2020-10-15 00:00:00,ieeexplore,data-driven predictive current control for synchronous motor drives,https://ieeexplore.ieee.org/document/9235958/,"Data-driven control techniques have become increasingly popular in recent years due to the availability of massive amounts of data and several advances in data science. These control design methods bypass the system identification step and directly exploit collected data to construct the controller. In this paper, we investigate the application of data-driven methods to the control of electric motor drives, and specifically to the design of current controllers for three-phase synchronous permanent magnet motor drives. Two of the most promising data-driven algorithms are presented, namely the Subspace Predictive Control algorithm and the Data-Enabled Predictive Control algorithm. The theory behind these techniques is first reviewed in the optimization-based control framework. Standard algorithms are slightly modified to fulfill the requirements of the specific application, and then simulated in the MATLAB Simulink environment. Some key aspects of real-time implementation are studied, providing a proof-of-concept demonstration of the applicability of these algorithms. The data-driven design is proposed for three different topologies of synchronous motors, proving the flexibility of the approach.",data driven architecture,589
10.1109/ieem.2017.8290072,filtered,2017 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM),IEEE,2017-12-13 00:00:00,ieeexplore,design and development of a training module for data-driven product-service design,https://ieeexplore.ieee.org/document/8290072/,"Product-service design (PSD) is an integration of tangible product and intangible service. It comprises large number of design information aimed to offer better package design that satisfies customer requirements. The main challenge faced by designers is to ensure all the data and information is organized and readily accessible during design analysis e.g. product-service cost, configuration and quality etc. Previous literature studies are focused on data and knowledge management during design process. However, data analytics core skills such as data preparation, pre-processing and visualization with embedded programming skill are less emphasized. Thus, it is necessary for designers to have skills for managing data-driven design that helps in decision making. This study proposed design and development of a training module for data-driven PSD using ADDIE model. An expert assessment was conducted to measure the usability of our proposed training module. Our findings showed that the usability score of the module falls within the acceptable range and therefore it is suitable to be used for data-driven PSD training.",data driven architecture,590
10.1109/iccas.2016.7832442,filtered,"2016 16th International Conference on Control, Automation and Systems (ICCAS)",IEEE,2016-10-19 00:00:00,ieeexplore,design of two degree of freedom controller using data conversion method,https://ieeexplore.ieee.org/document/7832442/,"Several data-driven design methods for a feedback controller for an unknown plant were studied. The data conversion method (DCM), which is one of the methods, has improved the design ability for more various plants by using a new approach. This paper applies the revised DCM to a two degree of freedom controller. First, the paper discusses a theory when applying DCM to a two degree of freedom controller. Then, it discusses the application of DCM to three structures of two degree of freedom controllers. Several experiments show that a controller can be directly designed from outline waveforms to a two degree of freedom controller. As a result, the paper shows that DCM is a convenient method for designing a two degree of freedom controller compared to conventional methods.",data driven architecture,591
10.1109/icorr.2017.8009312,filtered,2017 International Conference on Rehabilitation Robotics (ICORR),IEEE,2017-07-20 00:00:00,ieeexplore,design parameters and torque profile modification of a spring-assisted hand-opening exoskeleton module,https://ieeexplore.ieee.org/document/8009312/,"There is a growing demand for functional rehabilitation orthotics that can effectively assist in patient recovery from motor impairments after stroke. The hand in particular is a complex system that has proven difficult to mimic with current exoskeleton technologies. This paper presents data-driven design parameters to increase the functionality and improve the assistance profile of the ArmAssist-2.0 hand module. Improvements from the previous model include adjustable linkages to fulfill the largest population of users, new joint locations to more accurately represent biomechanics of the hand, and a more impairment-appropriate torque profile to assist in hand opening, adjustable through interchangeable springs. In most passive hand orthoses, assistance forces tend to decrease as the hand and thumb extend, opposite the needs of a typical patient hand. This project utilizes a variable spring moment arm about the revolute axes to match common patient impairment more accurately. The revised assistance profile for the hand maintains a nearly linear relationship. Results conclude that the final assembled device fits comfortably in the hand with noticeable improvements in joint locations, adjustability, and the force profile for the metacarpophalangeal (MCP) joint. An issue arises with the extension of the proximal interphalangeal (PIP) joint due to the nature of rapidly changing moment arms and multiple springs in series. The issue and possible solutions are discussed.",data driven architecture,592
10.1109/acc.2012.6314904,filtered,2012 American Control Conference (ACC),IEEE,2012-06-29 00:00:00,ieeexplore,direct data-driven control of a diesel engine airpath,https://ieeexplore.ieee.org/document/6314904/,"In this paper, the direct data-driven design method introduced in [6] is applied to the airpath control problem in turbocharged Diesel engines. The method allows the employed fixed-order multivariable controller to be tuned without need of mathematically describing the system, thus avoiding the problem of dynamic undermodeling. Experimental results on a testbench facility and comparison with an existing decoupled technique validate the suitability of the proposed method for the engine application. Moreover, suited instrumental variables show to be effective when dealing with real experimental noise.",data driven architecture,593
10.1109/cdc.2012.6425955,filtered,2012 IEEE 51st IEEE Conference on Decision and Control (CDC),IEEE,2012-12-13 00:00:00,ieeexplore,direct data-driven control of internal combustion engine test benches using closed-loop experiments,https://ieeexplore.ieee.org/document/6425955/,"This paper proposes a direct data-driven design approach for multivariable control of rotational speed and torque dynamics in a dynamic internal combustion engine test bench. The controller parameters are directly identified from data using a suitably extended version of the algorithm introduced in [1], allowing closed-loop experiments to be employed. The proposed controller is designed and validated using an accurate simulator of the internal combustion engine test bench on which a comparison with other model-based control strategies is also shown.",data driven architecture,594
10.1109/icamechs.2016.7813433,filtered,2016 International Conference on Advanced Mechatronic Systems (ICAMechS),IEEE,2016-12-03 00:00:00,ieeexplore,direct design method of force controller based on input/output data,https://ieeexplore.ieee.org/document/7813433/,"This paper proposes a data-driven design method of a force controller using input/output data of a force control system, i.e., force response obtained when contacting to an unknown environment and input to a robot at that time. The force control system includes the environment to be contacted in addition to the robot itself. The force controller must be designed in consideration of the environment. Therefore, this paper focuses on the Virtual Reference Feedback Tuning (VRFT), which is one of the data-driven controller design methods. The effectiveness of the design method is verified by simulation examples and verification experiments.",data driven architecture,595
10.1109/ccdc.2008.4597351,filtered,2008 Chinese Control and Decision Conference,IEEE,2008-07-04 00:00:00,ieeexplore,direct identification of model-based fault detection system and its application to the process of lead-zinc smelting furnace,https://ieeexplore.ieee.org/document/4597351/,"This paper deals with the data-driven design of parity space based fault detection (FD) systems. The central idea is to identify parity space and the related matrices directly from test data. The method is applied to fault diagnosis of imperial smelting furnace. Firstly, select correlation process variables according to the expert experience and the correlation test result. And then the residual signal is obtained by the method of direct identification based FD systems. The real application results show that the method has an excellent performance.",data driven architecture,596
10.1109/icecem54757.2021.00075,filtered,2021 International Conference on E-Commerce and E-Management (ICECEM),IEEE,2021-09-26 00:00:00,ieeexplore,energy-efficient and sustainable construction technologies and simulation optimisation methods,https://ieeexplore.ieee.org/document/9637031/,"As a key part of sustainable urban development, constructing buildings and other infrastructures using sustainable technologies and materials is a key research field to minimize energy consumption and seek to combat climate change. This study introduced several feasible energy-efficient and environmental-friendly materials and methods, including roof gardening, advanced and recycled materials, green interior decoration, and simulation optimisation measures. Roof gardening is a kind of promising roof form that makes the functions of purifying air quality, energy conserving, and reshape the urban ecosystems all possible. However, the market still needs more encouragement from the government to better implementation in the city. Advanced materials and waste reuse materials are two key aspects of green building materials in energy saving and environment protection. The advanced material of photocatalytic self-cleaning glass has been fully applied; However, TiO2 self-cleaning glass and waste reuse materials such as rubber, straw, bamboo have some degrees of limitations due to economic and distribution constraints. The interior decoration combined with environmentally friendly materials is of great significance to enhance energy usage and environmental quality. Some new environmental protection inventions such as LED lights and artificial intelligence technologies are the main development direction in interior decoration in the future. Utilizing computer simulation and optimisation to minimize the building life cycle environmental impacts has also gained increasing attentions recently. Regarding design optimisation, emerging digital technologies (e.g., neural network, data-driven design and parametric 3D modelling, multi-disciplinary optimisation) are enablers for greater automation in early design exploration and should be encouraged in sustainable design optimisation.",data driven architecture,597
10.1109/aset.2017.7983706,filtered,2017 International Conference on Advanced Systems and Electric Technologies (IC_ASET),IEEE,2017-01-17 00:00:00,ieeexplore,engineering optimisation by heterogeneous cuckoo search algorithm: application to an irrigation station,https://ieeexplore.ieee.org/document/7983706/,"Data-driven design of accurate Takagi-Sugeno (TS) fuzzy models has attracted the attention of many researchers in the last decade, where the model structures and parameters are important and often solved in an optimization problems. The Cuckoo Search (CS) method represents a powerful search approach and an effective optimization technique. However, the classical CS algorithm is not always optimal to find the potential solution to a special problem, and it can be trap the individuals into local regions leading to premature convergence which will significantly affect the model accuracy. To overcome these drawbacks, we have presented a powerful TS fuzzy system parameters searching strategy named intelligent Takagi-Sugeno Modeling (iTaSuM), with heterogeneous cuckoo search (HeCoS) strategies based on the quantum mechanism to enhance the searching performance. Finally, the searching strategy (iTaSuM) applied to an irrigation station process in order to get an optimal T-S fuzzy model.",data driven architecture,598
10.1109/spawc51858.2021.9593131,filtered,2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),IEEE,2021-09-30 00:00:00,ieeexplore,fast power control adaptation via meta-learning for random edge graph neural networks,https://ieeexplore.ieee.org/document/9593131/,"Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,599
10.1109/cca.2015.7320615,filtered,2015 IEEE Conference on Control Applications (CCA),IEEE,2015-09-23 00:00:00,ieeexplore,fictitious reference iterative tuning of internal model controllers for a class of nonlinear systems,https://ieeexplore.ieee.org/document/7320615/,"This paper presents a direct data-driven design or tuning of the internal model control architecture for a class of non-linear systems to achieve the desired output. We assume that the structure of a nonlinear system addressed here is known and the parameters are unknown. In addition, a nonlinear system addressed here is assumed to be with the property that the input time series and the output time series has one to one relation. For this type of nonlinear system, the internal model controller that is represented by the parameters of a model is introduced. Then, fictitious reference iterative tuning, which is one of the data-driven controller tuning methods based on the direct use of one-shot experimental data, is extended for tuning the parameterized internal model controllers. It is also shown that the cost function to be minimized in fictitious reference iterative tuning is related to both of the achievement of the desired tracking and the attainment of a model. That is, the proposed method in this paper enables us to simultaneously obtain a model and a controller by applying only one-shot experimental data to the parameterized internal model controller. A numerical example is also illustrated to show the validity of the result.",data driven architecture,600
10.1109/coase.2017.8256148,filtered,2017 13th IEEE Conference on Automation Science and Engineering (CASE),IEEE,2017-08-23 00:00:00,ieeexplore,integration and visualization framework for data-driven resistance spot welded assembly design,https://ieeexplore.ieee.org/document/8256148/,"Recently, data-driven design and manufacturing provide industries potential competitive edge. With this emerging paradigm, designers can make efficient design decisions considering various manufacturing process data. Resistance Spot Welding (RSW) process is well utilized in various manufacturing industries including the automotive industry. However, the utilization of the RSW process data is still limited due to the disconnected welded assembly design models and associated process data challenges. This article presents a framework to integrate and visualize the welded assembly design and weldability knowledge extracted from RSW process datasets. In this article, a design database stores the geometric assembly design information and the STM (SpatioTemporal Mereotopology) ontology is connected to the design database. For this study, a real industry RSW test datasets are utilized to extract weldability decision rules with data mining algorithms. To build a shareable RSW weldability knowledge, an RSW ontology is utilized. Afterward, welded assembly design and weldability knowledge sets are extracted from the two ontology-based models and integrated with a X3DOM data to visualize the assembly design and weldability knowledge. Finally, multiple welded assembly models are generated and tested with the developed visualization framework.",data driven architecture,601
10.1109/icassp.2015.7178489,filtered,"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",IEEE,2015-04-24 00:00:00,ieeexplore,low-rank approximation-based distributed node-specific signal estimation in a fully-connected wireless sensor network,https://ieeexplore.ieee.org/document/7178489/,"In this paper, we consider the problem of distributed estimation of node-specific signals in a fully-connected wireless sensor network with multi-sensor nodes. The estimation relies on a data-driven design of a spatial filter, referred to as the generalized eigenvalue decomposition (GEVD)-based multi-channel Wiener filter (MWF). In non-stationary or low-SNR conditions, this GEVD-based MWF has been demonstrated to be more robust than the original MWF due to an inherent GEVD-based low-rank approximation of the sensor signal correlation matrix. In a centralized realization where a fusion center has access to all the nodes' sensor signal observations, the network-wide sensor signal correlation matrix and its low-rank approximation can be directly estimated from the sensor signals. However, in this paper we aim to avoid centralizing the sensor signal observations, in which case this network-wide correlation matrix cannot be estimated. We introduce a distributed algorithm which is able to significantly compress the broadcast signals while still converging to the centralized GEVD-based MWF as if each node would have access to all sensor signal observations.",data driven architecture,602
10.1109/fie44824.2020.9273981,filtered,2020 IEEE Frontiers in Education Conference (FIE),IEEE,2020-10-24 00:00:00,ieeexplore,machine learning for middle-schoolers: children as designers of machine-learning apps,https://ieeexplore.ieee.org/document/9273981/,"This Research to Innovative Practice Full Paper presents a multidisciplinary, design-based research study that aims to develop and study pedagogical models and tools for integrating machine-learning (ML) topics into education. Although children grow up with ML systems, few theoretical or empirical studies have focused on investigating ML and data-driven design in K-12 education to date. This paper presents the theoretical grounds for a design-oriented pedagogy and the results from exploring and implementing those theoretical ideas in practice through a case study conducted in Finland. We describe the overall process in which middle-schoolers (N = 34) co-designed and made ML applications for solving meaningful, everyday problems. The qualitative content analysis of the pre-and post-tests, student interviews, and the students' own ML design ideas indicated that co-designing real-life applications lowered the barriers for participating in some of the core practices of computer science. It also supported children in exploring abstract ML concepts and workflows in a highly personalized and embodied way. The article concludes with a discussion on pedagogical insights for supporting middle-schoolers in becoming innovators and software designers in the age of ML.",data driven architecture,603
10.1109/elnano.2017.7939716,filtered,2017 IEEE 37th International Conference on Electronics and Nanotechnology (ELNANO),IEEE,2017-04-20 00:00:00,ieeexplore,measuring spatiotemporal magnetic fields by hall effect sensors with post-processing solutions,https://ieeexplore.ieee.org/document/7939716/,"Solid state magnetic field sensors are examined. The use of III-V semiconductors in Hall effect sensors results in high bandwidth, fast response time, adequate spatiotemporal resolution, accuracy and sufficient measurement range. Despite significant advantages, there are drawbacks, such as noise, errors, nonlinearity, sensitivity, low thermal stability, etc. Noise attenuation and error reduction problems are researched. High-fidelity data analysis and filtering are accomplished using robust signal processing schemes. The results are experimentally substantiated enabling overall functionality, performance and capabilities. The statistical models of noise are examined to solve data processing and data acquisition problems. The experimentally substantiated descriptive statistics empowers data-intensive analysis, data-driven design and optimization.",data driven architecture,604
10.1109/apmrc.2018.8601117,filtered,2018 Asia-Pacific Magnetic Recording Conference (APMRC),IEEE,2018-11-17 00:00:00,ieeexplore,mixed h<inf>2</inf>/h<inf>∞</inf> data-driven control design for hard disk drives,https://ieeexplore.ieee.org/document/8601117/,"A frequency based data-driven control design considering mixed H<sub>2</sub>/H<sub>∞</sub> control objectives is developed for multiple input-single output systems. The main advantage of the data-driven control over the model-based control is its ability to use the frequency response measurements of the controlled plant directly without the need to identify a model for the plant. In the proposed methodology, multiple sets of measurements can be considered in the design process to accommodate variations in the system dynamics. The controller is obtained by translating the mixed H<sub>2</sub>/H<sub>∞</sub> control objectives into a convex optimization problem. The H<sub>∞</sub> norm is used to shape closed loop transfer functions and guarantee closed loop stability, while the H<sub>2</sub> norm is used to constrain and/or minimize the variance of signals in the time domain. The proposed data-driven design methodology is used to design a track following controller for a dual-stage Hard Disk Drive (HDD), based on the sensitivity decoupling structure.",data driven architecture,605
10.1109/infcomw.2012.6193503,filtered,2012 Proceedings IEEE INFOCOM Workshops,IEEE,2012-03-30 00:00:00,ieeexplore,modeling and characterization of urban vehicular mobility using web cameras,https://ieeexplore.ieee.org/document/6193503/,"Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios, random connectivity, and use small and biased samples. In this paper, we perform a combined study to learn the structure and connectivity of urban streets and modeling and characterization of vehicular traffic densities on them. Our dataset is a collection of 154 thousand routes and 12 million vehicular mobility images from 730 online web cameras located in four different cities. First, our study shows that driving routes and visiting locations of cities demonstrate power law distribution, indicating a planned or recently designed road infrastructure. Second, we represent cities by network graphs in which nodes are camera locations and edges are urban streets that connect the nodes. Such representation exhibits small world properties with short path lengths and large clustering coefficient. Third, traffic densities show 80% temporal correlation during several hours of a day. Finally, modeling these densities against known theoretical distributions show less than 5% deviation for Log-logistic and Gamma distribution. We believe this work will provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks.",data driven architecture,606
10.1109/aspaa.1997.625589,filtered,Proceedings of 1997 Workshop on Applications of Signal Processing to Audio and Acoustics,IEEE,1997-10-22 00:00:00,ieeexplore,on the properties of temporal processing for speech in adverse environments,https://ieeexplore.ieee.org/document/625589/,"In this paper we report on the results that we have obtained in the application of temporal processing to speech signals. We describe what are the properties that make temporal processing an interesting and useful technique to alleviate the harmful effects that environmental factors have on speech. Though temporal processing has been used in the past, its analysis and properties have not been studied in detail. We summarize some results that we obtained in a detailed analysis, and describe a data-driven design technique to design the processing. We demonstrate a speech enhancement system which illustrates some properties, advantages, and short-comings of the technique.",data driven architecture,607
10.1109/iconip.2002.1201940,filtered,"Proceedings of the 9th International Conference on Neural Information Processing, 2002. ICONIP '02.",IEEE,2002-11-22 00:00:00,ieeexplore,topology inference for an ann/hmm hybrid on-line handwriting recognition system,https://ieeexplore.ieee.org/document/1201940/,"The paper studies a data driven design approach of HMM topology in a hybrid Neuro-Markovian system for on-line cursive handwriting recognition. Artificial neural networks (ANNs) are used as primitive models at state level and hidden Markov models (HMMs) are used at character level. Primitives are shared among all characters in the alphabet and an individual handwriting is characterized by a primitive sequence. The typical prototypes of a letter are reflected in HMM's topology. Firstly, we build a prototype analyser that creates a primitive prototype for each training example. Secondly, a number of the most typical prototypes are selected for each letter through a special clustering method. At last, letter models are built by using the selected prototypes as Markov chain's topology. The concepted system is evaluated on the wildly used UNIPEN database and the advantages are clearly approved with very encouraging results.",data driven architecture,608
10.1109/cdc.2009.5399808,filtered,Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference,IEEE,2009-12-18 00:00:00,ieeexplore,tuning of dynamical controllers by a data-driven loop-shaping method for a single input plant,https://ieeexplore.ieee.org/document/5399808/,"In this paper, a data-driven design method of a feedback gain for loop shaping is proposed for a single input plant. This method can be applied to the tuning of a static feedback gain and also that of the output matrix of a dynamical controller. Constraints on the feedback gain are represented by linear matrix inequalities based on the unfalsified concept using many responses obtained by filtering a plant response. The feedback gain is a solution of a linear matrix inequality problem, where the integral gain of the loop transfer function is maximized subject to the constraints. Numerical examples demonstrate the usefulness.",data driven architecture,609
10.1109/cdc.2003.1272661,filtered,42nd IEEE International Conference on Decision and Control (IEEE Cat. No.03CH37475),IEEE,2003-12-12 00:00:00,ieeexplore,unfalsified control approach to parameter space design of pid controllers,https://ieeexplore.ieee.org/document/1272661/,"In this paper, we propose a data-driven design method of PID controllers based on unfalsified control. A necessary condition for the PID gains to satisfy a mixed sensitivity control problem is derived and the falsified region of the PID gains is drawn on the parameter plane. This method does not require constructing a mathematical model but requires the input-output responses of the plant of a feedback system excited by sinusoidal reference inputs for many frequencies. Usefulness is demonstrated by applying this method to a nonlinear plant with backlash.",data driven architecture,610
10.1109/tie.2014.2364561,filtered,IEEE Transactions on Industrial Electronics,IEEE,2015-06-01 00:00:00,ieeexplore,a new soft-sensor-based process monitoring scheme incorporating infrequent kpi measurements,https://ieeexplore.ieee.org/document/6933868/,"The development of advanced techniques for process monitoring and fault diagnosis using both model-based and data-driven approaches has led to many practical applications. One issue that has not been considered in such applications is the ability to deal with key performance indicators (KPIs) that are only sporadically measured and with significant time delay. Therefore, in this paper, the data-driven design of diagnostic-observer-based process monitoring schemes is extended to include the ability to detect changes given infrequently measured KPIs. The extended diagnostic observer is shown to be stable and hence able to converge to the true value. The proposed method is tested using both Monte Carlo simulations and the Tennessee-Eastman problem. It is shown that although time delay and sampling time increase the detection delay, the overall effect can be mitigated by using a soft sensor. Furthermore, it is shown that the results are not strongly dependent on the sampling time, but do depend on the time delay. Therefore, the proposed soft-sensor-based monitoring scheme can efficiently detect faults even in the absence of direct process information.",data driven architecture,611
10.1109/tie.2014.2301773,filtered,IEEE Transactions on Industrial Electronics,IEEE,2014-11-01 00:00:00,ieeexplore,a review on basic data-driven approaches for industrial process monitoring,https://ieeexplore.ieee.org/document/6717991/,"Recently, to ensure the reliability and safety of modern large-scale industrial processes, data-driven methods have been receiving considerably increasing attention, particularly for the purpose of process monitoring. However, great challenges are also met under different real operating conditions by using the basic data-driven methods. In this paper, widely applied data-driven methodologies suggested in the literature for process monitoring and fault diagnosis are surveyed from the application point of view. The major task of this paper is to sketch a basic data-driven design framework with necessary modifications under various industrial operating conditions, aiming to offer a reference for industrial process monitoring on large-scale industrial processes.",data driven architecture,612
10.1109/tnnls.2020.2975051,filtered,IEEE Transactions on Neural Networks and Learning Systems,IEEE,2020-12-01 00:00:00,ieeexplore,a universal approximation result for difference of log-sum-exp neural networks,https://ieeexplore.ieee.org/document/9032340/,"We show that a neural network whose output is obtained as the difference of the outputs of two feedforward networks with exponential activation function in the hidden layer and logarithmic activation function in the output node, referred to as log-sum-exp (LSE) network, is a smooth universal approximator of continuous functions over convex, compact sets. By using a logarithmic transform, this class of network maps to a family of subtraction-free ratios of generalized posynomials (GPOS), which we also show to be universal approximators of positive functions over log-convex, compact subsets of the positive orthant. The main advantage of difference-LSE networks with respect to classical feedforward neural networks is that, after a standard training phase, they provide surrogate models for a design that possesses a specific difference-of-convex-functions form, which makes them optimizable via relatively efficient numerical methods. In particular, by adapting an existing difference-of-convex algorithm to these models, we obtain an algorithm for performing an effective optimization-based design. We illustrate the proposed approach by applying it to the data-driven design of a diet for a patient with type-2 diabetes and to a nonconvex optimization problem.",data driven architecture,613
10.1109/access.2021.3123348,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,an authoritative source of truth system for ucav conceptual design,https://ieeexplore.ieee.org/document/9590556/,"Model-Based Systems Engineering (MBSE) is a part of a long-term trend toward model-centric approaches. The Authoritative Source of Truth (AST) is a crucial step of digital transformation and a core component of MBSE. Benefits include help design teams shorten the design cycle, improve design efficiency, and ensure the accuracy of design models and data compared to traditional document-based co-design methods. Data-driven design is a new direction of Unmanned Combat Aerial Vehicles (UCAV) design, and UCAV is the main force of future air warfare. How to build a UCAV conceptual design AST system is a problem that needs to be solved. We design an AST construction methodology, develop an AST system by applying the methodology, and use the UCAV concept design case to test the usability of the AST system. More specifically, the methodology includes construction goals and objects, basic construction methods, AST architecture, collaborative construction methods, dynamic management methods, basic functions and derivative tools required. In addition, the validation process is requirement analysis, functional architecture design, scheme design, and dynamic management validation. The AST system can help the implementation of MBSE in the field of aircraft design. The AST system can also help meet the requirements of the conceptual design stage, which shows the feasibility of the construction methodology’s integrity. If the AST system is used in the aircraft’s detailed design phase, further models and data will be required, and the AST system will need to be upgraded.",data driven architecture,614
10.1109/89.985546,filtered,IEEE Transactions on Speech and Audio Processing,IEEE,2002-02-01 00:00:00,ieeexplore,automatic generation of subword units for speech recognition systems,https://ieeexplore.ieee.org/document/985546/,"Large vocabulary continuous speech recognition (LVCSR) systems traditionally represent words in terms of smaller subword units. Both during training and during recognition, they require a mapping table, called the dictionary, which maps words into sequences of these subword units. The performance of the LVCSR system depends critically on the definition of the subword units and the accuracy of the dictionary. In current LVCSR systems, both these components are manually designed. While manually designed subword units generalize well, they may not be the optimal units of classification for the specific task or environment for which an LVCSR system is trained. Moreover, when human expertise is not available, it may not be possible to design good subword units manually. There is clearly a need for data-driven design of these LVCSR components. In this paper, we present a complete probabilistic formulation for the automatic design of subword units and dictionary, given only the acoustic data and their transcriptions. The proposed framework permits easy incorporation of external sources of information, such as the spellings of words in terms of a nonideographic script.",data driven architecture,615
10.1109/tcyb.2020.2969320,filtered,IEEE Transactions on Cybernetics,IEEE,2021-12-01 00:00:00,ieeexplore,data-driven false data-injection attack design and detection in cyber-physical systems,https://ieeexplore.ieee.org/document/9003529/,"In this article, a data-driven design scheme of undetectable false data-injection attacks against cyber-physical systems is proposed first, with the aid of the subspace identification technique. Then, the impacts of undetectable false data-injection attacks are evaluated by solving a constrained optimization problem, with the constraints of undetectability and energy limitation considered. Moreover, the detection of designed data-driven false data-injection attacks is investigated via the coding theory. Finally, the simulations on the model of a flight vehicle are illustrated to verify the effectiveness of the proposed methods.",data driven architecture,616
10.1109/jas.2021.1004258,filtered,IEEE/CAA Journal of Automatica Sinica,IEEE,2022-01-01 00:00:00,ieeexplore,data-driven human-robot interaction without velocity measurement using off-policy reinforcement learning,https://ieeexplore.ieee.org/document/9536670/,"In this paper, we present a novel data-driven design method for the human-robot interaction (HRI) system, where a given task is achieved by cooperation between the human and the robot. The presented HRI controller design is a two-level control design approach consisting of a task-oriented performance optimization design and a plant-oriented impedance controller design. The task-oriented design minimizes the human effort and guarantees the perfect task tracking in the outer-loop, while the plant-oriented achieves the desired impedance from the human to the robot manipulator end-effector in the inner-loop. Data-driven reinforcement learning techniques are used for performance optimization in the outer-loop to assign the optimal impedance parameters. In the inner-loop, a velocity-free filter is designed to avoid the requirement of end-effector velocity measurement. On this basis, an adaptive controller is designed to achieve the desired impedance of the robot manipulator in the task space. The simulation and experiment of a robot manipulator are conducted to verify the efficacy of the presented HRI design framework.",data driven architecture,617
10.1109/tnet.2020.2979966,filtered,IEEE/ACM Transactions on Networking,IEEE,2020-06-01 00:00:00,ieeexplore,deepcast: towards personalized qoe for edge-assisted crowdcast with deep reinforcement learning,https://ieeexplore.ieee.org/document/9047133/,"Today's anywhere and anytime broadband connection and audio/video capture have boosted the deployment of crowdsourced livecast services (or crowdcast). Bridging a massive amount of geo-distributed broadcasters and their fellow viewers, such representatives as Twitch.tv, Youtube Gaming, and Inke.tv, have greatly changed the generation and distribution landscape of streaming content. They also enable rich online interactions among the crowd, and strive to offer personalized Quality-of-Experience (QoE) for individual viewers. Given the ultra-large scale and the dynamics of the crowd, personalizing QoE however is much more challenging than in early generation streaming services. The rich interactions among the broadcasters, viewers, and the network system, on the other hand, also offer invaluable data that could be utilized towards informed management. This paper presents DeepCast, an edge-assisted crowdcast framework that explores the sheer amount of viewing data towards intelligent decisions for personalized QoE demands. DeepCast seamlessly integrates cloud, CDN, and edge servers for crowdcast content distribution, and advocates a data-driven design that extracts the hidden information from the complex interactions among the system components. Through deep reinforcement learning (DRL), it automatically identifies the most suitable strategies for viewer assignment and transcoding at edges. We collect multiple real-world datasets and evaluate the performance of DeepCast with trace-driven experiments. The results demonstrate its flexibility and effectiveness towards better personalized QoE and lower cost for crowdcast systems.",data driven architecture,618
10.1109/tmag.2018.2799856,filtered,IEEE Transactions on Magnetics,IEEE,2018-05-01 00:00:00,ieeexplore,description of statistical switching in perpendicular stt-mram within an analytical and numerical micromagnetic framework,https://ieeexplore.ieee.org/document/8306275/,"The realistic modeling of spin-transfer torque (STT)-magnetoresistive random access memory (MRAM) for the simulations of hybrid CMOS/Spintronics devices in comprehensive simulation environments requires a full description of stochastic switching processes in the state-of-the-art STT-MRAMs. Here, we compare micromagnetic simulations with an analytical formulation that takes into account the spin-torque asymmetry of the spin-polarization function by considering the mean, standard deviation, skewness, and kurtosis. We find that, while the first and second statistical moments exhibit a very similar behavior, skewness and kurtosis are substantially different and must be taken into account in order to provide an accurate prediction of the switching performance. In fact, a reasonable fit of the probability density function (PDF) of the switching time is given by a Pearson Type IV PDF. The main achievements of this paper underline the need of data-driven design of STT-MRAM that uses a full micromagnetic simulation framework for the statistical proprieties PDF of switching processes.",data driven architecture,619
10.1109/tcad.2016.2633961,filtered,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,IEEE,2017-09-01 00:00:00,ieeexplore,"design automation of cyber-physical systems: challenges, advances, and opportunities",https://ieeexplore.ieee.org/document/7778207/,"A cyber-physical system (CPS) is an integration of computation with physical processes whose behavior is defined by both computational and physical parts of the system. In this paper, we present a view of the challenges and opportunities for design automation of CPS. We identify a combination of characteristics that define the challenges unique to the design automation of CPS. We then present selected promising advances in depth, focusing on four foundational directions: combining model-based and data-driven design methods; design for human-in-the-loop systems; component-based design with contracts, and design for security and privacy. These directions are illustrated with examples from two application domains: smart energy systems and next-generation automotive systems.",data driven architecture,620
10.1109/tvlsi.2018.2883642,filtered,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,IEEE,2019-04-01 00:00:00,ieeexplore,design and implementation of an ultralow-energy fft asic for processing ecg in cardiac pacemakers,https://ieeexplore.ieee.org/document/8576661/,"In embedded biomedical applications, spectrum analysis algorithms such as fast Fourier transform (FFT) are crucial for pattern detection and have been the focus of continued research. In deeply embedded systems such as cardiac pacemakers, FFT-based signal processing is typically computed by application-specific integrated circuit (ASIC) to achieve low-power operation. This brief proposes a data-driven design approach for an FFT ASIC solution, which exploits the limited range of data encountered by these embedded systems. The optimizations proposed in this brief use the simple concept of hashing and lookup table to effectively reduce the number of arithmetic operations required to perform the FFT of an electrocardiogram (ECG) signal. By reducing the dynamic power consumption and overall energy footprint of FFT computation, the proposed design aims to achieve longer battery life for a cardiac pacemaker. The design is synthesized using a 90-nm standard cell library, and gate level switching activity is simulated to obtain accurate power consumption results. The proposed optimizations achieved a low energy consumption of 27.72 nJ per FFT, which is 14.22% lower than a standard 128-point radix-2 FFT when tested with actual ECG data collected from PhysioNet.",data driven architecture,621
10.1109/tec.2007.914164,filtered,IEEE Transactions on Energy Conversion,IEEE,2008-06-01 00:00:00,ieeexplore,designing an adaptive fuzzy controller for maximum wind energy extraction,https://ieeexplore.ieee.org/document/4458230/,"The wind power production spreading, also aided by the transition from constant to variable speed operation, involves the development of efficient control systems to improve the effectiveness of power production systems. This paper presents a data-driven design methodology able to generate a Takagi-Sugeno-Kang (TSK) fuzzy model for maximum energy extraction from variable speed wind turbines. In order to obtain the TSK model, fuzzy clustering methods for partitioning the input-output space, combined with genetic algorithms, and recursive least-squares optimization methods for model parameter adaptation are used. The implemented TSK fuzzy model, as confirmed by some simulation results on a doubly fed induction generator connected to a power system, exhibits high speed of computation, low memory occupancy, fault tolerance, and learning capability.",data driven architecture,622
10.1109/access.2021.3122234,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,dual-rate data-driven virtual reference feedback tuning: improvement in fast-tracking performance and ripple-free design,https://ieeexplore.ieee.org/document/9584867/,"In this study, a data-driven design method is proposed for a dual-rate system, where the sampling interval of a plant output is restricted and is an integer multiple of the holding interval of a control input. In our proposed method, single-rate virtual reference feedback tuning (S-VRFT), where the holding interval is the same as the sampling interval, is extended to the dual-rate virtual reference feedback tuning (D-VRFT) system. In D-VRFT, a controller is decided using a set of input/output data used in S-VRFT, and it is easy to extend S-VRFT to D-VRFT and implement D-VRFT. In this study, intersample oscillations caused in such a dual-rate control system is prevented because a weighting filter is introduced for penalizing the control input deviation between the sampling instants. The filter is designed as an integrator for weighting the low-frequency domain. The improvement in fast-tracking performance as well as the ripple-free property are demonstrated through both the numerical and experimental results.",data driven architecture,623
10.1109/tpel.2020.3043741,filtered,IEEE Transactions on Power Electronics,IEEE,2021-07-01 00:00:00,ieeexplore,enhanced fault diagnosis using broad learning for traction systems in high-speed trains,https://ieeexplore.ieee.org/document/9290131/,"Faults happen inevitably in traction systems and thus place the security of the whole high-speed train at risk. In order to improve the safety and reliability of high-speed trains, this article deals with fault detection and diagnosis (FDD) problem for traction systems. Because of high sampling frequency of equipped sensors, FDD strategies in the supervision system of high-speed trains should be of enough high computation efficiency, which is a great bottleneck for artificial intelligence-based FDD methods. For reducing the computational load while maintaining the satisfactory diagnostic accuracy, an enhanced FDD architecture using the modified principal component analysis and broad learning system is developed in this article. Based on the proposed data-driven design whose core is to extract fault information, fast and accurate FDD can be achieved without requirements for mathematical models or control mechanism of high-speed trains. The effectiveness and feasibility of the proposed online design are illustrated on the traction control platform of high-speed trains.",data driven architecture,624
10.1109/tsmc.2019.2924356,filtered,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",IEEE,2021-06-01 00:00:00,ieeexplore,event-triggered model-free adaptive control,https://ieeexplore.ieee.org/document/8754709/,"This paper investigates an event-triggered model-free adaptive control for nonaffined nonlinear systems under a data-driven design framework. By introducing a compact form dynamic linearization (CFDL) scheme, a linear data model of the nonlinear nonaffine system is derived. Then, a parameter estimation algorithm is developed to offline identify the linear data model. On the basis of the identified linear data model, a CFDL-based event-triggered model-free adaptive control (CFDL-ET-MFAC) is developed by designing an event-triggering condition to guarantee the Lyapunov stability. The control action is active only when the event-triggering condition is satisfied. Otherwise, the input signal remains the same as that at the previous triggering instant. In addition, the parameter estimation algorithm is developed for the proposed CFDL-ET-MFAC to identify the CFDL model in real time for improving the robustness to the uncertainties. Meanwhile, both a partial form dynamic linearization-based event-triggered MFAC and a full form dynamic linearization-based event-triggered MFAC are proposed to further improve the control performance by using additional parameters to capture the more complicated behavior of complex nonlinear systems. The proposed ET-MFAC methods only rely on the linear data models directly obtained from data without using any other mechanistic model information. The validity of the three ET-MFAC methods is confirmed through both theoretical analysis and simulation studies.",data driven architecture,625
10.1109/access.2021.3069130,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,impact of educational coaching programs and mentoring services on users’ perception and preferences: a qualitative and quantitative approach,https://ieeexplore.ieee.org/document/9392232/,"This study determines how educational supporting services and mentoring programs can be improved based on the users' preferences and perception by benefiting from a data-driven design model and process innovation. To this end, the study proposed a data-driven support and decision model (DSDM) that uses a mixed methodology (qualitative and quantitative) to analyze data collected from different writing centers and coaching programs who responded to an online survey that comprised of both quantitative and qualitative items. Quantitatively, we applied a Linear and Mixed-effect logistic regression analysis to investigate the critical factors that motivate the users in seeking educational support services. And, qualitatively apply the Text mining technique to analyze the opinions given by the participants in order to establish its level of impact towards the several services offered by the coaching programs. Theoretically, the proposed research model is grounded on integration of a data-structure approach that builds on the descriptive decision theory; which studies the rationality of the decisions that users are disposed to make by means of the statistical method and textual data quantification. In turn, the method allowed us to capture the influential factors and state-of-the-art in faculties-students development and coaching programs, and to provide solutions to the ever-increasing need to improve educational supporting services and quality in a competitive and rapidly changing educational environment or market that have not been done before. Although there may be a considerable variation between the different categories of educational services offered by the coaching centers. The results of our study shows that the users hold services such as “tutoring” as a major factor that influences their visit and recommendations to the writing centers or coaching programs. Moreover, most users of the coaching programs are motivated by the need to gain “support” with their educational/academic performance and productivity.",data driven architecture,626
10.1109/tcst.2016.2632533,filtered,IEEE Transactions on Control Systems Technology,IEEE,2017-11-01 00:00:00,ieeexplore,iteration tuning of disturbance observer-based control system satisfying robustness index for foptd processes,https://ieeexplore.ieee.org/document/7778205/,"A conventional disturbance observer (DOB)-based control system is a model-based control system. In this paper, a data-driven design method is proposed for the DOB-based control system using iteration feedback tuning (IFT) based on the first-order-plus-time-delay models. It is well known that the conventional data-based design methods cannot provide an explicit tradeoff between robustness and performance. Here, our goal is to develop a method to design the data-driven DOB-based control system satisfying a given robustness index. To this end, first, the tuning rules of the controller and the Q-filter in terms of the nominal process model are analytically determined for a given robustness index. Second, an optimization problem, solved by IFT algorithm, is established to find the optimal parameters of the nominal model. The merits of the proposed method are that: 1) the number of parameters needing to be tuned is reduced, since only the parameters of the nominal model are optimized and 2) the system satisfies the explicit robustness index if the parameters are optimal. Moreover, the selection of the robustness index, the output performance of the system, and the performance of the iteration algorithm are addressed. Two simulation examples and an experiment are presented to demonstrate the effectiveness and merits of the proposed method.",data driven architecture,627
10.1109/tvlsi.2009.2039501,filtered,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,IEEE,2011-04-01 00:00:00,ieeexplore,modeling and synthesis of asynchronous pipelines,https://ieeexplore.ieee.org/document/5439903/,"We propose a set of modeling rules and a synthesis method for the design of asynchronous pipelines. To keep the circuit area and power dissipation of the asynchronous control network small, the proposed approach avoids the conventional syntax-directed translation approach. Instead, it employs a data-driven design style and a coarse-grain approach to the synthesis of asynchronous control, restricting asynchronous control to the implementation of communication channels commonly found in asynchronous pipelines and operations involving these channels. The proposed approach integrates well into conventional synchronous design flows because they are based on Verilog and SystemVerilog specifications, and generate register-transfer level models suitable for functional simulation and logic synthesis using existing computer-aided design tools. Using a 32-bit microprocessor, an interpolated finite-impulse-response filter bank, and a Reed-Solomon error detector as design examples, we show that the proposed approach is competitive with other comparable reported methods.",data driven architecture,628
10.1109/tip.2007.898960,filtered,IEEE Transactions on Image Processing,IEEE,2007-07-01 00:00:00,ieeexplore,object trajectory-based activity classification and recognition using hidden markov models,https://ieeexplore.ieee.org/document/4237188/,"Motion trajectories provide rich spatiotemporal information about an object's activity. This paper presents novel classification algorithms for recognizing object activity using object motion trajectory. In the proposed classification system, trajectories are segmented at points of change in curvature, and the subtrajectories are represented by their principal component analysis (PCA) coefficients. We first present a framework to robustly estimate the multivariate probability density function based on PCA coefficients of the subtrajectories using Gaussian mixture models (GMMs). We show that GMM-based modeling alone cannot capture the temporal relations and ordering between underlying entities. To address this issue, we use hidden Markov models (HMMs) with a data-driven design in terms of number of states and topology (e.g., left-right versus ergodic). Experiments using a database of over 5700 complex trajectories (obtained from UCI-KDD data archives and Columbia University Multimedia Group) subdivided into 85 different classes demonstrate the superiority of our proposed HMM-based scheme using PCA coefficients of subtrajectories in comparison with other techniques in the literature.",data driven architecture,629
10.1109/tfuzz.2013.2278972,filtered,IEEE Transactions on Fuzzy Systems,IEEE,2014-08-01 00:00:00,ieeexplore,optifel: a convergent heterogeneous particle swarm optimization algorithm for takagi–sugeno fuzzy modeling,https://ieeexplore.ieee.org/document/6583326/,"Data-driven design of accurate and reliable Takagi-Sugeno (T-S) fuzzy systems has attracted a lot of attention, where the model structures and parameters are important and often solved in an optimization framework. The particle swarm optimization (PSO) algorithm is widely applied in the field. However, the classical PSO suffers from premature convergence, and it is trapped easily into local optima, which will significantly affect the model accuracy. To overcome these drawbacks, we have developed a new T-S fuzzy system parameters searching strategy called OptiFel with a heterogeneous multiswarm PSO (MsPSO) to enhance the searching performance. MsPSO groups the whole population into multiple cooperative subswarms, which perform different search behaviors for the potential solutions. We have found that the multiple subswarms strategy proposed in this paper is greatly helpful for finding the optimal parameters suitable for the subspaces of the T-S fuzzy model. Our theoretical proof has also demonstrated that the cooperation among the subswarms can maintain a balance between exploration and exploitation to ensure the particles converge to stable points. Experimental results show that MsPSO performs significantly better than traditional PSO algorithms on six benchmark functions. With the improved MsPSO, OptiFel can generate a good fuzzy system model with high accuracy and strong generalization ability.",data driven architecture,630
10.1109/tie.2013.2273477,filtered,IEEE Transactions on Industrial Electronics,IEEE,2014-05-01 00:00:00,ieeexplore,real-time implementation of fault-tolerant control systems with performance optimization,https://ieeexplore.ieee.org/document/6560360/,"In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.",data driven architecture,631
10.1109/tcsii.2019.2953238,filtered,IEEE Transactions on Circuits and Systems II: Express Briefs,IEEE,2020-11-01 00:00:00,ieeexplore,sparse undetectable sensor attacks against cyber-physical systems: a subspace approach,https://ieeexplore.ieee.org/document/8897641/,"In this brief, the data-driven design of sparse undetectable sensor attacks against cyber-physical systems is studied, with the aid of subspace approach. First, the undetectable and sparse sensor attack design schemes are proposed based on the physical models. Then the data-driven realizations of sparse undetectable sensor attacks are designed via identifying the subspace from the collected input and output data. Moreover, the impacts of sparse undetectable sensor attacks are evaluated by solving the constraint optimization problems. Finally, the simulations on an unmanned aerial vehicle are illustrated to testify the effectiveness of the proposed methods.",data driven architecture,632
10.1109/jsen.2020.2969470,filtered,IEEE Sensors Journal,IEEE,2020-05-15 00:00:00,ieeexplore,strategy to validate sensor-placement methodologies in the context of sparse measurement in complex urban systems,https://ieeexplore.ieee.org/document/8970368/,"The Internet of Things creates opportunities to develop data-driven design methodologies for smart cities. However, effects rather than causes are often measured in complex urban systems, requiring robust data-interpretation methodologies. Additionally, effective monitoring of large urban components, such as civil infrastructure, often involves multiple sensor devices and invasive sensor systems. In these situations, the design of measurement systems is an important task. Usually, this task is carried out by engineers using only qualitative rules of thumb and experience. Recently, researchers have developed quantitative sensor-placement methodologies to maximize the information gain of measurement systems. Nonetheless, these methodologies are only weakly validated using field measurements due to the small amount of data collected and the difficulties comparing the predicted information gain with observations. This paper proposes a validation strategy for sensor-placement methodologies. In this strategy, predictions of both individual sensor and sensor-configuration performances are compared with observations using statistical tests and hypothesis testing. The validation procedure is illustrated through three full-scale-bridge case studies. This strategy helps engineers select an appropriate methodology to design measurement systems in order to optimize data collection using sensors.",data driven architecture,633
10.1038/s42003-022-03098-1,filtered,Communications Biology,Nature,2022-02-23 00:00:00,springer,data-driven design of targeted gene panels for estimating immunotherapy biomarkers,https://www.nature.com/articles/s42003-022-03098-1,"Tumour mutation burden and other exome-wide biomarkers are used to determine which patients will benefit from immunotherapy. However, the cost of whole exome sequencing limits the widespread use of such biomarkers. Here, we introduce a data-driven framework for the design of targeted gene panels for estimating a broad class of biomarkers including tumour mutation burden and tumour indel burden. Our first goal is to develop a generative model for the profile of mutation across the exome, which allows for gene- and variant type-dependent mutation rates. Based on this model, we then propose a procedure for constructing biomarker estimators. Our approach allows the practitioner to select a targeted gene panel of prespecified size and construct an estimator that only depends on the selected genes. Alternatively, our method may be applied to make predictions based on an existing gene panel, or to augment a gene panel to a given size. We demonstrate the excellent performance of our proposal using data from three non small-cell lung cancer studies, as well as data from six other cancer types. A data-driven procedure to estimate immunotherapy biomarkers is shown to perform well on data from three Non-Small Cell Lung Cancer studies as well as data from six other cancer types. The method is based on a generative model of how mutations arise in the tumour exome.",data driven architecture,634
10.1007/978-981-16-7160-9_182,filtered,"CIGOS 2021, Emerging Technologies and Applications for Green Infrastructure",Springer,2022-01-01 00:00:00,springer,development of a bim-based master digital model using data-driven design for the suspension bridge,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7160-9_182,"Long-span cable-supported bridges are increasingly used to bridge a longer distance with a higher clearance than the other bridge types and their impressive aesthetic appearance. However, owing to challenging dynamic engineering practices, the suspension bridges, in particular, require accumulated design and construction technologies. Moreover, as the most distinctive mechanical property of the cable structures, different applied tension generates different lateral stiffness on the main cable. Without an integrated analysis model, the realistic profile of the cable structures cannot be determined. In this regard, this paper proposes a master digital model for a suspension bridge based on the data-driven approach for multiple purposes, including the structural assessment aspect. The Building Information Modeling (BIM) technique is a key factor to creating and federate all the essential engineering knowledge data regarding a suspension bridge. At first, a data schema for the suspension bridge’s main structures is created and based on that, the database for each structural member is defined. The BIM authoring using the data-driven design is proposed to generate all the individual structural members then assembly to make the entire initial model for the suspension bridge. Metadata is linked, and any efficient revisions concerning varying situations during the construction process can be easily updated into the digital model through the change of database. Finally, an analysis model is integrated into this initial model to create the federated master digital model. The advantage of this master digital model lies in the capability to continuously perform the bridge system’s stability analyses at any erection step. Furthermore, it makes the digital representation of the main cable and suspended bridge structures more dynamic, no longer just rigid objects in the general commercial BIM model. A prototyping master digital model was developed for an existing bridge is introduced along with this paper.",data driven architecture,635
10.1007/978-3-030-88181-8_1,filtered,Data-Driven Engineering Design,Springer,2022-01-01 00:00:00,springer,data-driven engineering design,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88181-8_1,"This chapter aims to introduce the basics of data-driven engineering design to design researchers and practitioners who are unnecessarily familiar with relevant notions. The background, motivation, and significance of data-driven engineering design are elaborated. From a theoretical perspective, data-driven engineering design is characterized by a novel integration between the existing design theory and methodology with the emerging data science. Therefore, a systematic design process is divided into multiple key design operations, and a complete data lifecycle is divided into multiple data operations. A theoretical framework of data-driven engineering design is presented to couple various design operations with relevant data operations for different scenarios of engineering design.",data driven architecture,636
10.1007/s00158-021-02926-y,filtered,Structural and Multidisciplinary Optimization,Springer,2021-09-01 00:00:00,springer,data-driven topology design using a deep generative model,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00158-021-02926-y,"In this paper, we propose a sensitivity-free and multi-objective structural design methodology called data-driven topology design . It is schemed to obtain high-performance material distributions from initially given material distributions in a given design domain. Its basic idea is to iterate the following processes: (i) selecting material distributions from a dataset of material distributions according to eliteness, (ii) generating new material distributions using a deep generative model trained with the selected elite material distributions, and (iii) merging the generated material distributions with the dataset. Because of the nature of a deep generative model, the generated material distributions are diverse and inherit features of the training data, that is, the elite material distributions. Therefore, it is expected that some of the generated material distributions are superior to the current elite material distributions, and by merging the generated material distributions with the dataset, the performances of the newly selected elite material distributions are improved. The performances are further improved by iterating the above processes. The usefulness of data-driven topology design is demonstrated through numerical examples.",data driven architecture,637
10.1007/s10472-020-09722-2,filtered,Annals of Mathematics and Artificial Intelligence,Springer,2021-07-01 00:00:00,springer,data driven design for online industrial auctions,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10472-020-09722-2,"Designing auction parameters for online industrial auctions is a complex problem due to highly heterogeneous items. Currently, online auctioneers rely heavily on their experts in auction design. The ability of predicting how well an auction will perform prior to the start comes in handy for auctioneers. If an item is expected to be a low-performing item, the auctioneer can take certain actions to influence the auction outcome. For instance, the starting selling price of the item can be modified, or the location where the item is displayed on the website can be changed to attract more attention. In this paper, we take a real-world industrial auction data set and investigate how we can improve upon the expert’s design using insights learned from data. More specifically, we first construct a classification model that predicts the expected performance of auctions. We propose a data driven auction design framework (called DDAD) that combines the expert’s knowledge with the learned prediction model, in order to find the best parameter values, i.e., starting price and display positions of the items, for a given new auction. The prediction model is evaluated, and the new design for several auctions is discussed and validated with the auction experts.",data driven architecture,638
10.1007/s42484-020-00032-8,filtered,Quantum Machine Intelligence,Springer,2021-02-17 00:00:00,springer,sparse quantum gaussian processes to counter the curse of dimensionality,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42484-020-00032-8,"Gaussian processes are well-established Bayesian machine learning algorithms with significant merits, despite a strong limitation: lack of scalability. Clever solutions address this issue by inducing sparsity through low-rank approximations, often based on the Nystrom method. Here, we propose a different method to achieve better scalability and higher accuracy using quantum computing, outperforming classical Bayesian neural networks for large datasets significantly. Unlike other approaches to quantum machine learning, the computationally expensive linear algebra operations are not just replaced with their quantum counterparts. Instead, we start from a recent study that proposed a quantum circuit for implementing quantum Gaussian processes and then we use quantum phase estimation to induce a low-rank approximation analogous to that in classical sparse Gaussian processes. We provide evidence through numerical tests, mathematical error bound estimation, and complexity analysis that the method can address the “curse of dimensionality,” where each additional input parameter no longer leads to an exponential growth of the computational cost. This is also demonstrated by applying the algorithm in a practical setting and using it in the data-driven design of a recently proposed metamaterial. The algorithm, however, requires significant quantum computing hardware improvements before quantum advantage can be achieved.",data driven architecture,639
10.1007/978-3-030-78679-3_6,filtered,Organization Design,Springer,2021-01-01 00:00:00,springer,how to approach an organization design,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78679-3_6,"The organization designer has two important dimensions to consider when approaching an organization design project. One is the mode of intervention, which can range from providing expert knowledge to the client to engaging in a collaborative process. The second dimension is the number of people involved in the design process, which can range from just a few members of the leadership team to groups of up to thousands (in so-called large group interventions). The approach described here uses a collaborative approach that engages a design team of a manageable size. The design team represents the organization and is mandated by the leadership team to perform the design work. Elements of approaches from other design disciplines can offer useful inspiration for the organization design approach, such as the importance of prototyping and testing. Still, a lot of challenging aspects of the design process remain, especially having to do with the inevitable political aspects at play. Data-driven tools that support the organization design process are increasingly on offer. They may offer support in analyzing the current situation, in prototyping design options, and even in generating new designs.",data driven architecture,640
10.1007/978-3-030-51295-8_15,filtered,Proceedings of the 18th International Conference on Computing in Civil and Building Engineering,Springer,2021-01-01 00:00:00,springer,augmented bim workflow for structural design through data visualization,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51295-8_15,"Structural analysis of projects generates a large amount of data, especially when it involves complex or not modular geometries. By analyzing the generated data, it is possible to create optimized outputs for structures in an iterative process, until reaching a solution that satisfies the project constraints. Often, it is challenging to conciliate optimization with issuing of intermediate versions to be used for project coordination by other stakeholders. This is due to recurrent project changes, related to architectural or client requirements that arise during the design process. Moreover, structural design is generally carried out in a variety of software by different engineers within the design team. Therefore, it is rather challenging to organize, control and analyze all the information generated in structural design at each step, aiming to enhance both general team efficiency and structural optimization. The increasing popularity of BIM (Building Information Modeling) in this field could be a pivoting factor towards data-driven design and informed decision-making in all levels of a structural project team. In this context, this paper presents a proposal and an application of a BIM data workflow to enhance the work of structural designers as well as the collaboration within the design team. The workflow is based on data extraction through visual programming, using Dynamo, and the creation of an automatically updatable dashboard within Power BI. Python is used to create custom-build operations that apply specifically to the structural assessment context. Discussion about the suitability of this process for other applications within decision-making activities in structural engineering is also given.",data driven architecture,641
10.1007/s00158-020-02523-5,filtered,Structural and Multidisciplinary Optimization,Springer,2020-06-01 00:00:00,springer,data-driven metamaterial design with laplace-beltrami spectrum as “shape-dna”,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00158-020-02523-5,"The design of multiscale metamaterial systems often suffers from high computational cost and incompatible boundaries between unit cells. As a result, unit cells are either assumed to be repeated (periodic) everywhere or limited to a small number of shapes. To address these limitations, this work proposes a data-driven design framework consisting of a metamaterial genome with a reduced-order geometrical representation as well as methods for the efficient design and analysis of 2D aperiodic metamaterials with compatible boundaries. To collect a large amount of designs, a set of unit cells generated by topology optimization is taken as initial seeds for the genome, and then expanded iteratively through random shape perturbations to form a rich database that covers a wide range of properties. For a reduced-order representation, the Laplace-Beltrami (LB) spectrum is adopted to describe complex unit cell shapes using a low number of descriptors, therefore significantly reducing the design dimensionality. Moreover, the physical and geometrical information contained in the LB spectrum is revealed through both quantitative and theoretical analysis. This information as well as the lower dimensionality allows the genome to be effectively leveraged to build a neural network model of structure-property relations for the rapid design of new unit cells. Finally, the combination of the metamaterial genome with an efficient optimization method based on the Markov random field (MRF) model is proposed to ensure connected boundaries between unit cells in multiscale aperiodic microstructure designs.",data driven architecture,642
10.1007/s00158-020-02497-4,filtered,Structural and Multidisciplinary Optimization,Springer,2020-06-01 00:00:00,springer,data-driven design approach to hierarchical hybrid structures with multiple lattice configurations,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00158-020-02497-4,"This work presents a data-driven design approach to hierarchical hybrid structures with multiple lattice configurations. Two design variables are considered for each lattice substructure, one discrete variable indicating the configuration type and the other continuous density variable determining the geometrical feature size. For each lattice configuration, a series of similar lattice substructures are sampled by varying the density variable and a corresponding data-driven interpolation model is built for an explicit representation of the constitutive behavior. To reduce the model complexity, substructuring by means of static condensation is performed on the sampled lattice substructures. To achieve hybrid structure with multiple lattice configurations, a multi-material interpolation model is adopted by synthesizing the data-driven interpolation models and the discrete lattice configuration variables. The proposed approach has proved capable of generating hierarchically strongly coupled designs, which therefore allows for direct manufacturing with no post-processing requirement as required for homogenization-based designs due to the assumption on scales separation.",data driven architecture,643
10.1007/978-3-030-62807-9_54,filtered,Product Lifecycle Management Enabling Smart X,Springer,2020-01-01 00:00:00,springer,participative method to identify data-driven design use cases,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-62807-9_54,"Paradigms such as smart factory and industry 4.0 enable the collection of data in enterprises. To enhance decision making in design, computational support that is driven by data seems to be beneficial. With this respect, an identification of data-driven use cases is needed. Still, the state of practice does not reflect the potential of data-driven design in engineering product development. With this respect, a method is proposed addressing the business and data understanding in industrial contexts and corresponding Product Lifecycle Management (PLM) environments. This allows to identify use cases for data-driven design taking into account business processes as well as the related data. In the proposed method, first the main process tasks are analyzed using a SIPOC analysis that is followed by a process decomposition to further detail and highlight corresponding applications using Enterprise Architecture principles. Following this, value stream mapping and design process failure mode effect analysis are used to identify sources of waste and the related causes. With this, a feature analysis of given data is proposed to identify use cases and enable to further use standard data science methods like CRISP-DM. The method is validated using the infrastructure of the Pilotfabrik at TU Vienna. The use case shows the applicability of the method to identify features that influence the cost of a product during the manufacturing without changing the functional specifications. The results highlight that different methods need to be combined to attain a comprehensive business and data understanding. Further, a comprehensive view of the processes is yielded that enables to further identify use cases for data-driven design. This work lays a foundation for future research with respect to data-driven design use cases identification in engineering product development.",data driven architecture,644
10.1007/978-3-030-57997-5_37,filtered,Advances in Production Management Systems. Towards Smart and Digital Manufacturing,Springer,2020-01-01 00:00:00,springer,the data-driven product-service systems design and delivery (4dpss) methodology,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-57997-5_37,"The design of Product-Service Systems (PSS) has been approached from several perspectives like the process, innovation, engineering and operational ones providing, for each one of those, a specific view on the problem. This paper proposes a Data-Driven Product-Service System Design and Delivery (4DPSS) methodology focusing on the collection and exploitation of delivery data to feed the design phase. The logic of the methodology relies on aggregating operational data (collected in the delivery phase) to build a consistent body of knowledge to be exploited in iterative PSS design activities, thanks to better identification of customer needs, and product and service process design issues. This paper presents the 4DPSS methodology at a theoretical level, the implementations of the different methods constituting the methodology are referred to in the text, while its implementation and test as a whole are demanded to future work.",data driven architecture,645
10.1007/978-3-030-57717-9_43,filtered,Addressing Global Challenges and Quality Education,Springer,2020-01-01 00:00:00,springer,data-driven game design: the case of difficulty in educational games,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-57717-9_43,"There is increasing interest in using data to design digital games that serve the purposes of learning and assessment. One game element, difficulty , could benefit vastly from applying data-driven methods as it affects both players’ overall enjoyment and efficiency of learning and qualities of assessment. However, how difficulty is being defined varies across the learning, assessment, and game perspectives, yet little is known about how educational difficulty can be balanced in educational games for each of the potentially conflicting goals. In this paper, we first review varying definitions of difficulty and then we discuss how we came up with a difficulty metric and used it to refine our game-based assessment Shadowspect . The design guidelines, metrics and lessons learned will be useful for designers of learning games and educators interested in balancing difficulty before they implement these tools in the classroom.",data driven architecture,646
10.1007/s10845-018-1430-y,filtered,Journal of Intelligent Manufacturing,Springer,2020-01-01 00:00:00,springer,"a data-driven cyber-physical approach for personalised smart, connected product co-development in a cloud-based environment",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-018-1430-y,"The rapid development of information and communication technology enables a promising market of information densely product, i.e. smart, connected product (SCP), and also changes the way of user–designer interaction in the product development process. For SCP, massive data generated by users drives its design innovation and somehow determines its final success. Nevertheless, most existing works only look at the new functionalities or values that are derived in the one-way communication by introducing novel data analytics methods. Few work discusses about an effective and systematic approach to enable individual user innovation in such context, i.e. co-development process, which sets the fundamental basis of the prevailing concept of data-driven design. Aiming to fill this gap, this paper proposes a generic data-driven cyber-physical approach for personalised SCP co-development in a cloud-based environment. A novel concept of smart, connected, open architecture product is hence introduced with a generic cyber-physical model established in a cloud-based environment, of which the interaction processes are enabled by co-development toolkits with smartness and connectedness. Both the personalized SCP modelling method and the establishment of its cyber-physical product model are described in details. To further demonstrate the proposed approach, a case study of a smart wearable device (i.e. i-BRE respiratory mask) development process is given with general discussions.",data driven architecture,647
10.1007/978-3-030-01641-8_9,filtered,Optimization in Industry,Springer,2019-01-01 00:00:00,springer,data-driven design optimization for industrial products,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01641-8_9,"Prescriptive Data-driven design data analytics along with optimization Optimization techniques in complex industrial processes lead to extraction of useful knowledge from the data, mapping of the relation between the inputs and outputs of the products and/or processes, product quality improvement, cost reduction, process simplification and designing new product with improved performance. There are several statistical methods Statistical methods and soft computing techniques, which are useful to generate the objective functions for optimization Optimization from industrial data. In this chapter, a case study is discussed where ANN Artificial Neural Network (ANN) model with desirability function Desirability function forms the objective function. GA-based search is employed to get the optimized solutions, and to find the behaviour of the alloying elements in steel with desired performance.",data driven architecture,648
10.1557/mrs.2018.207,filtered,MRS Bulletin,Springer,2018-09-01 00:00:00,springer,data-driven design of inorganic materials with the automatic flow framework for materials discovery,http://link.springer.com/openurl/fulltext?id=doi:10.1557/mrs.2018.207,"The expansion of programmatically accessible materials data has cultivated opportunities for data-driven approaches. Workflows such as the Automatic Flow Framework for Materials Discovery not only manage the generation, storage, and dissemination of materials data, but also leverage the information for thermodynamic formability modeling, such as the prediction of phase diagrams and properties of disordered materials. In combination with standardized parameter sets, the wealth of data is ideal for training machine-learning algorithms, which have already been employed for property prediction, descriptor development, design rule discovery, and the identification of candidate functional materials. These methods promise to revolutionize the path to synthesis, and ultimately transform the practice of traditional materials discovery to one of rational and autonomous materials design.",data driven architecture,649
10.1007/978-3-030-00713-3_16,filtered,Exploring Service Science,Springer,2018-01-01 00:00:00,springer,end-to-end methodological approach for the data-driven design of customer-centered digital services,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00713-3_16,"The collection, analysis, and interpretation of digital data has become an important factor for the provision of services. However, there is a lack of methodologies for using data analytics systematically in an end-to-end process for designing services. Therefore, in this paper, we develop a conceptual approach covering the innovation funnel from idea generation to market deployment. In particular, we describe how qualitative approaches alternate with quantitative approaches along the innovation process. We pay special attention to the design of data-driven value propositions including the analysis and modeling of the customer needs, a phase in which the concept of hidden needs and pains is applied. To conclude, we propose the development of a tool to support and industrialize the approach discussed in this paper.",data driven architecture,650
10.1007/s11569-017-0299-0,filtered,NanoEthics,Springer,2017-12-01 00:00:00,springer,saved by design? the case of legal protection by design,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11569-017-0299-0,"This discussion note does three things: (1) it explains the notion of ‘legal protection by design’ in relation to data-driven infrastructures that form the backbone of our new ‘onli f e world’, (2) it explains how the notion of ‘by design’ relates to the relational nature of what an environment affords its inhabitants, referring to the work of James Gibson, and (3) it explains how this affects our understanding of human capabilities in relation to the affordances of changing environments. Finally, this brief note argues that ‘safer by design’ in the case of nanotechnology will require legal protection by design to make sure that human capabilities are reinvented and sustained in nano-technical environments.",data driven architecture,651
10.1007/978-3-319-58697-7_39,filtered,"Distributed, Ambient and Pervasive Interactions",Springer,2017-01-01 00:00:00,springer,building tools for creative data exploration: a comparative overview of data-driven design and user-centered design,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-58697-7_39,"Visualization scientists seek means to inspire insights from data, which require creative thinking on the part of analysts as well as cognitive reasoning. In information visualization a focus on the user has proven highly effective in the design of usable and engaging interfaces, although it has been argued that such a focus limits innovation in insights about the data and in the creation of metaphors for visualization. If a user-centered design recapitulates existing knowledge, then a design approach which derives exclusively from the data may provide more innovative results. Our approach considers both the designers and the users, whereby our goal is to elicit creativity in both the design of visualization tools and in their application. We compare user-centered design and data-driven design through tool sets that emerged from each of these methods. User-centered design methodologies were used in the creation of a custom interface for editors at a major national newspaper that visualizes measures of each story’s popularity. Data-driven design methodologies were used to create a tangible user interface for data visualization. With UCD we built a tool that supported the use of data in editorial decisions and deployed familiar metaphors to encourage significant change in workplace practice. With DDD we unleashed creativity on the part of analysts which resulted in a more innovative approach on the part of designers and a gateway to new user communities. We compare strengths and weaknesses of each methodology through a reflection of our design outcomes.",data driven architecture,652
10.1007/978-3-319-46675-0_32,filtered,Neural Information Processing,Springer,2016-01-01 00:00:00,springer,data-driven design of type-2 fuzzy logic system by merging type-1 fuzzy logic systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-46675-0_32,"Type-2 fuzzy logic systems (T2 FLSs) have shown their superiorities in many real-world applications. With the exponential growth of data, it is a time consuming task to directly design a satisfactory T2 FLS through data-driven methods. This paper presents an ensembling approach based data-driven method to construct T2 FLS through merging type-1 fuzzy logic systems (T1 FLSs) which are generated using the popular ANFIS method. Firstly, T1FLSs are constructed using the ANFIS method based on the sub-data sets. Then, an ensembling approach is proposed to merge the constructed T1 FLSs in order to generate a T2 FLS. Finally, the constructed T2 FLS is applied to a wind speed prediction problem. Simulation and comparison results show that, compared with the well-known BPNN and ANFIS, the proposed method have similar performance but greatly reduced training time.",data driven architecture,653
10.1007/978-4-431-54403-6_8,filtered,"Principia Designae － Pre-Design, Design, and Post-Design",Springer,2015-01-01 00:00:00,springer,towards data democracy beyond fukushima,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-4-431-54403-6_8,"Data-driven design procedures on materials, artifacts (engineering products) and environmental projects are comparatively studied in accordance with view of three loops for learning, namely, learning how to learn, changing the rules and following the established rules. Materials design procedures including the three loops by data-intensive ways are under development by taking advantage of a qualified database on materials so as to establish an exemplar for data-driven design in general with an explicit articulation. Design procedures of nuclear reactors have changed from data-driven design in the beginning to experience-based design of tacit knowledge, and standard-based design reflecting number of committed experts for design and development. This explanation of the nuclear reactor design is extended to show difficult issues about design procedures for environments which have not only one directional time dependent evolutional features as natural phenomena but also are full of human dimensions of about seven billion people with consequent uncertainties. As concluding remarks, an articulation to converge into productive cycles for the latter two design problems is given, extending procedures for data-driven materials design by introducing human dimensions for nuclear reactors and adding irreversible path dependent features and human dimensions for environmental issues.",data driven architecture,654
10.1007/978-1-4471-6410-4_14,filtered,Data-driven Design of Fault Diagnosis and Fault-tolerant Control Systems,Springer,2014-01-01 00:00:00,springer,data-driven design of observer-based control systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-6410-4_14,"In the previous chapter, we have introduced the fault-tolerant architecture and the associated design parameters. In this chapter, we focus on the data-driven design of the state feedback gain matrix, an H-PRIO parameter of the fault-tolerant architecture, and its application to the observer-based control schemes.",data driven architecture,655
10.1007/978-3-642-39200-9_5,filtered,Web Engineering,Springer,2013-01-01 00:00:00,springer,semantic data driven interfaces for web applications,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39200-9_5,"Modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. These conditions require interfaces that can adapt to the changes in the <user, platform, environment> triad. The Model-Based User Interface approach has been proposed as a way to deal with these requirements. In this paper we present a data-driven, rule-based interface definition model capable of taking into account the semantics of the data it is manipulating, especially in the case of Linked Data. An implementation architecture based on the Synth environment supporting this model is presented.",data driven architecture,656
10.1007/978-3-642-23333-3_4,filtered,Electronic Participation,Springer,2011-01-01 00:00:00,springer,combining social and government open data for participatory decision-making,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23333-3_4,"In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making.",data driven architecture,657
10.1007/978-3-642-14058-7_1,filtered,Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications,Springer,2010-01-01 00:00:00,springer,data-driven design of takagi-sugeno fuzzy systems for predicting nox emissions,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-14058-7_1,"New emission abatement technologies for the internal combustion engine, like selective catalyst systems or diesel particulate filters, need of accurate, predictive emission models. These models are not only used in the system calibration phase, but can be integrated for the engine control and on-board diagnosis tasks. In this paper, we are investigating a data-driven design of prediction models for NOx emissions with the help of (regression-based) Takagi-Sugeno fuzzy systems, which are compared with analytical physical-oriented models in terms of practicability and predictive accuracy based on high-dimensional engine data recorded during steady-state and dynamic engine states. For training the fuzzy systems from data, the FLEXFIS approach (short for FLEXible Fuzzy Inference Systems ) is applied, which automatically finds an appropriate number of rules by an incremental and evolving clustering approach and estimates the consequent parameters with the local learning approach in order to optimize the weighted least squares functional.",data driven architecture,658
10.1007/978-3-642-04492-2_21,filtered,Management Enabling the Future Internet for Changing Business and New Computing Services,Springer,2009-01-01 00:00:00,springer,the proposal of service delivery platform built on distributed data driven architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04492-2_21,"SDP (Service Delivery Platform) is a recommended system platform for NGN (Next Generation Network) that is expected to resolve two common system running problems: one is functional aspects such as high availability and providing effective maintenance methods, the other is cost aspects such as simplifying development method of a service. However, SDP is still on the way to be standardized, and its architecture has two problems: the congestion of service requests and flexibility of enabler, a service component of SDP. This paper explains how to build a SDP by adopting Distributed Data Driven Architecture and how our system resolves the problems by evaluating the prototype.",data driven architecture,659
10.1007/978-3-540-24688-6_97,filtered,Computational Science - ICCS 2004,Springer,2004-01-01 00:00:00,springer,data driven design optimization methodology development and application,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-24688-6_97,"The Data Driven Design Optimization Methodology (DDDOM) is a Dynamic Data Driven Application System (DDDAS) developed for engineering design optimization. The DDDOM synergizes experiment and simulation in a concurrent integrated software system to achieve better designs in a shorter time. The data obtained from experiment and simulation dynamically guide and redirect the design optimization process in real or near-real time, and therefore realize the full potential of the Dynamic Data Driven Applications Systems concept. This paper describes the DDDOM software system developed using the Perl and Perl/Tk programming languages. The paper also presents the first results of the application of the DDDOM to the multi-objective design optimization of a submerged subsonic inlet at zero angle of attack and sideslip.",data driven architecture,660
10.1007/3-540-44864-0_34,filtered,Computational Science — ICCS 2003,Springer,2003-01-01 00:00:00,springer,data driven design optimization methodology a dynamic data driven application system,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-44864-0_34,Engineering design optimization using concurrent integrated experiment and simulation is a Dynamic Data Driven Application System (DDDAS) wherein remote experiment and simulation can be synergistically utilized in real-time to achieve better designs in less time than conventional methods. The paper describes the Data Driven Design Optimization Methodology (DDDOM) being developed for engineering design optimization.,data driven architecture,661
10.1007/978-3-540-37058-1_7,filtered,Accuracy Improvements in Linguistic Fuzzy Modeling,Springer,2003-01-01 00:00:00,springer,on the achievement of both accurate and interpretable fuzzy systems using data-driven design processes,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-37058-1_7,"In this chapter it is argued that, one of the most interesting features of fuzzy system is the insight provided on the linguistic relationship between their variables, or in other words, is the possibility of interpret their parameters as a set of linguistic rules. Both the notions of accuracy and interpretability are reviewed. A general design policy where both accuracy and interpretation can be taken into account is reviewed. It is argued that the lost of accuracy does not necessary occurs when this type of data-driven design policy is applied. For illustration purposes, simulation results are given from the realistic control problem of neuromuscular relaxation of patients under surgery using continuous infusion of atracurium.",data driven architecture,662
10.1007/3-540-53065-7_86,filtered,CONPAR 90 — VAPP IV,Springer,1990-01-01 00:00:00,springer,a decoupled data-driven architecture with vectors and macro actors,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-53065-7_86,"This paper presents the implementation of scientific programs on a decoupled data-driven architecture with vectors and macro actors. This hybrid multiprocessor combines the dynamic data-flow principles of execution with the control-flow of the von Neumann model of execution. The two major ideas utilized by the decoupled model are: vector and macro actors with variable resolution, and asynchronous execution of graph and computation operations. The compiler generates graphs with various-sized actors in order to match the characteristics of the computation. For instance, vector actors are proposed for many aspects of scientific computing while lower resolution (complier-generated collection of scalar actors) or higher resolution (scalar actors) is used for unvectorizable programs. A block-scheduling technique for extracting more parallelism from sequential constructs is incorporated in the decoupled architecture. In addition a graph-level priority-scheduling mechanism is implemented that improves resource utilization and yields higher performance. A graph unit executes all graph operations and a computation unit executes all computation operations. The independence of the two main units of the machine allows the efficient pipelined execution of macro actors with diverse granularity characteristics.",data driven architecture,663
10.1007/bf03037380,filtered,New Generation Computing,Springer,1986-03-01 00:00:00,springer,a data-driven machine for or-parallel evaluation of logic programs,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF03037380,"Research in the area of parallel evaluation mechanisms for logic programs have led to the proposal of a number of schemes exploiting various forms of parallelism. Many of the early models have been based on the conventional approach of organising concurrent components of computations as communicating processes. More recently, however, models based on more novel computation organisations, in particular, data-driven organisations, have been proposed. This paper describes the development of one such model, its implementation and the design of a data-driven machine to support it. The model exploits a form of parallelism known as OR-parallelism and is particularly suited to database applications, although it would also support general applications. It is envisaged that the proposed machine may be refined into an efficient database engine, which can then be a component of a more powerful and integrated logic programming machine.",data driven architecture,664
http://arxiv.org/abs/2202.10565v1,filtered,arxiv,arxiv,2022-02-21 00:00:00,arxiv,"t-metaset: task-aware generation of metamaterial datasets by
  diversity-based active learning",http://arxiv.org/abs/2202.10565v1,"Inspired by the recent success of deep learning in diverse domains,
data-driven metamaterials design has emerged as a compelling design paradigm to
unlock the potential of multiscale architecture. However, existing
model-centric approaches lack principled methodologies dedicated to
high-quality data generation. Resorting to space-filling design in shape
descriptor space, existing metamaterial datasets suffer from property
distributions that are either highly imbalanced or at odds with design tasks of
interest. To this end, we propose t-METASET: an intelligent data acquisition
framework for task-aware dataset generation. We seek a solution to a
commonplace yet frequently overlooked scenario at early design stages: when a
massive ($~\sim O(10^4)$) shape library has been prepared with no properties
evaluated. The key idea is to exploit a data-driven shape descriptor learned
from generative models, fit a sparse regressor as the start-up agent, and
leverage diversity-related metrics to drive data acquisition to areas that help
designers fulfill design goals. We validate the proposed framework in three
hypothetical deployment scenarios, which encompass general use, task-aware use,
and tailorable use. Two large-scale shape-only mechanical metamaterial datasets
are used as test datasets. The results demonstrate that t-METASET can
incrementally grow task-aware datasets. Applicable to general design
representations, t-METASET can boost future advancements of not only
metamaterials but data-driven design in other domains.",data driven architecture,665
http://arxiv.org/abs/2202.07448v1,filtered,arxiv,arxiv,2022-02-04 00:00:00,arxiv,"towards a unified pandemic management architecture: survey, challenges
  and future directions",http://arxiv.org/abs/2202.07448v1,"The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,
economy and society worldwide. Emerging strains are making pandemic management
increasingly challenging. There is an urge to collect epidemiological,
clinical, and physiological data to make an informed decision on mitigation
measures. Advances in the Internet of Things (IoT) and edge computing provide
solutions for pandemic management through data collection and intelligent
computation. While existing data-driven architectures attempt to automate
decision-making, they do not capture the multifaceted interaction among
computational models, communication infrastructure, and the generated data. In
this paper, we perform a survey of the existing approaches for pandemic
management, including online data repositories and contact-tracing
applications. We then envision a unified pandemic management architecture that
leverages the IoT and edge computing to automate recommendations on vaccine
distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We
elucidate the flow of data among the layers of the architecture, namely, cloud,
edge and end device layers. Moreover, we address the privacy implications,
threats, regulations, and existing solutions that may be adapted to optimize
the utility of health data with security guarantees. The paper ends with a
lowdown on the limitations of the architecture and research directions to
enhance its practicality.",data driven architecture,666
http://arxiv.org/abs/2201.11289v1,filtered,arxiv,arxiv,2022-01-27 00:00:00,arxiv,"high throughput data-driven design of laser crystallized 2d mos2
  chemical sensors",http://arxiv.org/abs/2201.11289v1,"High throughput characterization and processing techniques are becoming
increasingly necessary to navigate multivariable, data-driven design challenges
for sensors and electronic devices. For two-dimensional materials, device
performance is highly dependent upon a vast array of material properties
including number of layers, lattice strain, carrier concentration, defect
density, and grain structure. In this work, laser-crystallization was used to
locally pattern and transform hundreds of regions of amorphous MoS2 thin films
into 2D 2H-MoS2. A high throughput Raman spectroscopy approach was subsequently
used to assess the process-dependent structural and compositional variations
for each illuminated region, yielding over 5500 distinct non-resonant,
resonant, and polarized Raman spectra. The rapid generation of a comprehensive
library of structural and compositional data elucidated important trends
between structure-property-processing relationships involving
laser-crystallized MoS2, including the relationships between grain size, grain
orientation, and intrinsic strain. Moreover, extensive analysis of
structure/property relationships allowed for intelligent design, and evaluation
of major contributions to, device performance in MoS2 chemical sensors. In
particular, it is found that sensor performance is strongly dependent on the
orientation of the MoS2 grains relative to the crystal plane.",data driven architecture,667
http://arxiv.org/abs/2201.10459v1,filtered,arxiv,arxiv,2022-01-25 00:00:00,arxiv,"framed: data-driven structural performance analysis of
  community-designed bicycle frames",http://arxiv.org/abs/2201.10459v1,"This paper presents a data-driven analysis of the structural performance of
4500 community-designed bicycle frames. We present FRAMED -- a parametric
dataset of bicycle frames based on bicycles designed by bicycle practitioners
from across the world. To support our data-driven approach, we also provide a
dataset of structural performance values such as weight, displacements under
load, and safety factors for all the bicycle frame designs. By exploring a
diverse design space of frame design parameters and a set of ten competing
design objectives, we present an automated way to analyze the structural
performance of bicycle frames. Our structural simulations are validated against
physical experimentation on bicycle frames. Through our analysis, we highlight
overall trends in bicycle frame designs created by community members, study
several bicycle frames under different loading conditions, identify
non-dominated design candidates that perform well on multiple objectives, and
explore correlations between structural objectives. Our analysis shows that
over 75\% of bicycle frames created by community members are infeasible,
motivating the need for AI agents to support humans in designing bicycles. This
work aims to simultaneously serve researchers focusing on bicycle design as
well as researchers focusing on the development of data-driven design
algorithms, such as surrogate models and Deep Generative Methods. The dataset
and code are provided at http://decode.mit.edu/projects/framed/.",data driven architecture,668
http://arxiv.org/abs/2112.08268v1,filtered,arxiv,arxiv,2021-12-15 00:00:00,arxiv,"prescriptive machine learning for automated decision making: challenges
  and opportunities",http://arxiv.org/abs/2112.08268v1,"Recent applications of machine learning (ML) reveal a noticeable shift from
its use for predictive modeling in the sense of a data-driven construction of
models mainly used for the purpose of prediction (of ground-truth facts) to its
use for prescriptive modeling. What is meant by this is the task of learning a
model that stipulates appropriate decisions about the right course of action in
real-world scenarios: Which medical therapy should be applied? Should this
person be hired for the job? As argued in this article, prescriptive modeling
comes with new technical conditions for learning and new demands regarding
reliability, responsibility, and the ethics of decision making. Therefore, to
support the data-driven design of decision-making agents that act in a rational
but at the same time responsible manner, a rigorous methodological foundation
of prescriptive ML is needed. The purpose of this short paper is to elaborate
on specific characteristics of prescriptive ML and to highlight some key
challenges it implies. Besides, drawing connections to other branches of
contemporary AI research, the grounding of prescriptive ML in a (generalized)
decision-theoretic framework is advocated.",data driven architecture,669
http://arxiv.org/abs/2110.09005v1,filtered,arxiv,arxiv,2021-10-18 00:00:00,arxiv,unsupervised learned kalman filtering,http://arxiv.org/abs/2110.09005v1,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.",data driven architecture,670
http://arxiv.org/abs/2109.11658v1,filtered,arxiv,arxiv,2021-09-23 00:00:00,arxiv,"relaxation approach for learning regularizers by neural networks for a
  class of optimal control problems",http://arxiv.org/abs/2109.11658v1,"The present paper deals with the data-driven design of regularizers in the
form of artificial nerual networks, for solving inverse problems formulated as
optimal control problems. These regularizers aim at improving accuracy,
wellposedness or compensating uncertainties for a class of optimal control
problems (inner-problems). Parameterized as neural networks, their weights are
chosen in order to reduce a misfit between data and observations of the state
solution of the inner-optimal control problems. Learning these weights
constitutes the outer-problem. Based on necessary first-order optimality
conditions for the inner-problems, a relaxation approach is proposed in order
to implement efficient solving of the inner-problems, namely the forward
operator of the outer-problem. Optimality conditions are derived for the
latter, and numerical illustrations show the feasibility of the relaxation
approach, first for rediscovering standard $L^2$-regularizers, and next for
designing regularizers that compensate unknown noise on the observed state of
the inner-problem.",data driven architecture,671
http://arxiv.org/abs/2109.10798v1,filtered,arxiv,arxiv,2021-09-22 00:00:00,arxiv,data-driven design of novel halide perovskite alloys,http://arxiv.org/abs/2109.10798v1,"The great tunability of the properties of halide perovskites presents new
opportunities for optoelectronic applications as well as significant challenges
associated with exploring combinatorial chemical spaces. In this work, we
develop a framework powered by high-throughput computations and machine
learning for the design and prediction of mixed cation halide perovskite
alloys. In a chemical space of ABX$_{3}$ perovskites with a selected set of
options for A, B, and X atoms, pseudo-cubic structures of compounds with B-site
mixing are simulated using density functional theory (DFT) and several
properties are computed, including stability, lattice constant, band gap,
vacancy formation energy, refractive index, and optical absorption spectrum,
using both semi-local and hybrid functionals. Neural networks (NN) are used to
train predictive models for every property using tabulated elemental properties
of A, B, and X site atoms as descriptors. Starting from the DFT dataset of 229
points, we use the trained NN models to predict the structural, energetic,
electronic and optical properties of a complete dataset of 17,955 compounds,
and perform high-throughput screening in terms of stability, band gap and
defect tolerance, to obtain 574 promising compounds that are ranked as
potential absorbers according to their photovoltaic figure of merit.
Compositional trends in the screened set of attractive mixed cation halide
perovskites are revealed and additional computations are performed on selected
compounds. The data-driven design framework developed here is promising for
designing novel mixed compositions and can be extended to a wider perovskite
chemical space in terms of A, B, and X atoms, different kinds of mixing at the
A, B, or X sites, non-cubic phases, and other properties of interest.",data driven architecture,672
http://arxiv.org/abs/2108.13178v1,filtered,arxiv,arxiv,2021-08-04 00:00:00,arxiv,"black-box and modular meta-learning for power control via random edge
  graph neural networks",http://arxiv.org/abs/2108.13178v1,"In this paper, we consider the problem of power control for a wireless
network with an arbitrarily time-varying topology, including the possible
addition or removal of nodes. A data-driven design methodology that leverages
graph neural networks (GNNs) is adopted in order to efficiently parametrize the
power control policy mapping the channel state information (CSI) to transmit
powers. The specific GNN architecture, known as random edge GNN (REGNN),
defines a non-linear graph convolutional filter whose spatial weights are tied
to the channel coefficients. While prior work assumed a joint training approach
whereby the REGNN-based policy is shared across all topologies, this paper
targets adaptation of the power control policy based on limited CSI data
regarding the current topology. To this end, we propose both black-box and
modular meta-learning techniques. Black-box meta-learning optimizes a
general-purpose adaptation procedure via (stochastic) gradient descent, while
modular meta-learning finds a set of reusable modules that can form components
of a solution for any new network topology. Numerical results validate the
benefits of meta-learning for power control problems over joint training
schemes, and demonstrate the advantages of modular meta-learning when data
availability is extremely limited.",data driven architecture,673
http://arxiv.org/abs/2107.13147v2,filtered,arxiv,arxiv,2021-07-28 00:00:00,arxiv,mechanical cloak via data-driven aperiodic metamaterial design,http://arxiv.org/abs/2107.13147v2,"Mechanical cloaks are materials engineered to manipulate the elastic response
around objects to make them indistinguishable from their homogeneous
surroundings. Typically, methods based on material-parameter transformations
are used to design optical, thermal and electric cloaks. However, they are not
applicable in designing mechanical cloaks, since continuum-mechanics equations
are not form-invariant under general coordinate transformations. As a result,
existing design methods for mechanical cloaks have so far been limited to a
narrow selection of voids with simple shapes. To address this challenge, we
present a systematic, data-driven design approach to create mechanical cloaks
composed of aperiodic metamaterials using a large pre-computed unit cell
database. Our method is flexible to allow the design of cloaks with various
boundary conditions, multiple loadings, different shapes and numbers of voids,
and different homogeneous surroundings. It enables a concurrent optimization of
both topology and properties distribution of the cloak. Compared to
conventional fixed-shape solutions, this results in an overall better cloaking
performance, and offers unparalleled versatility. Experimental measurements on
3D-printed structures further confirm the validity of the proposed approach.
Our research illustrates the benefits of data-driven approaches in quickly
responding to new design scenarios and resolving the computational challenge
associated with multiscale designs of functional structures. It could be
generalized to accommodate other applications that require heterogeneous
property distribution, such as soft robots and implants design.",data driven architecture,674
http://arxiv.org/abs/2107.02968v2,filtered,arxiv,arxiv,2021-07-07 00:00:00,arxiv,deep extrapolation for attribute-enhanced generation,http://arxiv.org/abs/2107.02968v2,"Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.",data driven architecture,675
http://arxiv.org/abs/2106.14500v2,filtered,arxiv,arxiv,2021-06-28 00:00:00,arxiv,"learning to sample: data-driven sampling and reconstruction of fri
  signals",http://arxiv.org/abs/2106.14500v2,"Finite-rate-of-innovation (FRI) signals are ubiquitous in applications such
as radar, ultrasound, and time of flight imaging. Due to their finite degrees
of freedom, FRI signals can be sampled at sub-Nyquist rates using appropriate
sampling kernels and reconstructed using sparse-recovery algorithms. Typically,
Fourier samples of the FRI signals are used for reconstruction. The
reconstruction quality depends on the choice of Fourier samples and recovery
method. In this paper, we consider to jointly optimize the choice of Fourier
samples and reconstruction parameters. Our framework is a combination of a
greedy subsampling algorithm and a learning-based sparse recovery method.
Unlike existing techniques, the proposed algorithm can flexibly handle changes
in the sampling rate and does not suffer from differentiability issues during
training. Importantly, exact knowledge of the FRI pulse is not required.
Numerical results show that, for a given number of samples, the proposed joint
design leads to lower reconstruction error for FRI signals compared to
independent data-driven design methods for both noisy and clean samples. Our
learning to sample approach can be readily applied to other sampling setups as
well including compressed sensing problems.",data driven architecture,676
http://arxiv.org/abs/2106.01592v1,filtered,arxiv,arxiv,2021-06-03 00:00:00,arxiv,data-driven design-by-analogy: state of the art and future directions,http://arxiv.org/abs/2106.01592v1,"Design-by-Analogy (DbA) is a design methodology wherein new solutions,
opportunities or designs are generated in a target domain based on inspiration
drawn from a source domain; it can benefit designers in mitigating design
fixation and improving design ideation outcomes. Recently, the increasingly
available design databases and rapidly advancing data science and artificial
intelligence technologies have presented new opportunities for developing
data-driven methods and tools for DbA support. In this study, we survey
existing data-driven DbA studies and categorize individual studies according to
the data, methods, and applications in four categories, namely, analogy
encoding, retrieval, mapping, and evaluation. Based on both nuanced organic
review and structured analysis, this paper elucidates the state of the art of
data-driven DbA research to date and benchmarks it with the frontier of data
science and AI research to identify promising research opportunities and
directions for the field. Finally, we propose a future conceptual data-driven
DbA system that integrates all propositions.",data driven architecture,677
http://arxiv.org/abs/2105.00459v1,filtered,arxiv,arxiv,2021-05-02 00:00:00,arxiv,"fast power control adaptation via meta-learning for random edge graph
  neural networks",http://arxiv.org/abs/2105.00459v1,"Power control in decentralized wireless networks poses a complex stochastic
optimization problem when formulated as the maximization of the average sum
rate for arbitrary interference graphs. Recent work has introduced data-driven
design methods that leverage graph neural network (GNN) to efficiently
parametrize the power control policy mapping channel state information (CSI) to
the power vector. The specific GNN architecture, known as random edge GNN
(REGNN), defines a non-linear graph convolutional architecture whose spatial
weights are tied to the channel coefficients, enabling a direct adaption to
channel conditions. This paper studies the higher-level problem of enabling
fast adaption of the power control policy to time-varying topologies. To this
end, we apply first-order meta-learning on data from multiple topologies with
the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,678
http://arxiv.org/abs/2103.05844v3,filtered,arxiv,arxiv,2021-03-10 00:00:00,arxiv,"biked: a dataset for computational bicycle design with machine learning
  benchmarks",http://arxiv.org/abs/2103.05844v3,"In this paper, we present ""BIKED,"" a dataset comprised of 4500 individually
designed bicycle models sourced from hundreds of designers. We expect BIKED to
enable a variety of data-driven design applications for bicycles and support
the development of data-driven design methods. The dataset is comprised of a
variety of design information including assembly images, component images,
numerical design parameters, and class labels. In this paper, we first discuss
the processing of the dataset, then highlight some prominent research questions
that BIKED can help address. Of these questions, we further explore the
following in detail: 1) Are there prominent gaps in the current bicycle market
and design space? We explore the design space using unsupervised dimensionality
reduction methods. 2) How does one identify the class of a bicycle and what
factors play a key role in defining it? We address the bicycle classification
task by training a multitude of classifiers using different forms of design
data and identifying parameters of particular significance through
permutation-based interpretability analysis. 3) How does one synthesize new
bicycles using different representation methods? We consider numerous machine
learning methods to generate new bicycle models as well as interpolate between
and extrapolate from existing models using Variational Autoencoders. The
dataset and code are available at http://decode.mit.edu/projects/biked/.",data driven architecture,679
http://arxiv.org/abs/2102.04296v3,filtered,arxiv,arxiv,2021-02-08 00:00:00,arxiv,"data-driven design of targeted gene panels for estimating immunotherapy
  biomarkers",http://arxiv.org/abs/2102.04296v3,"We introduce a novel data-driven framework for the design of targeted gene
panels for estimating exome-wide biomarkers in cancer immunotherapy. Our first
goal is to develop a generative model for the profile of mutation across the
exome, which allows for gene- and variant type-dependent mutation rates. Based
on this model, we then propose a new procedure for estimating biomarkers such
as tumour mutation burden and tumour indel nurden. Our approach allows the
practitioner to select a targeted gene panel of a prespecified size, and then
construct an estimator that only depends on the selected genes. Alternatively,
the practitioner may apply our method to make predictions based on an existing
gene panel, or to augment a gene panel to a given size. We demonstrate the
excellent performance of our proposal using data from three non-small cell lung
cancer studies, as well as data from six other cancer types.",data driven architecture,680
http://arxiv.org/abs/2101.07085v1,filtered,arxiv,arxiv,2021-01-18 00:00:00,arxiv,"training collective variables for enhanced sampling via neural networks
  based discriminant analysis",http://arxiv.org/abs/2101.07085v1,"A popular way to accelerate the sampling of rare events in molecular dynamics
simulations is to introduce a potential that increases the fluctuations of
selected collective variables. For this strategy to be successful, it is
critical to choose appropriate variables. Here we review some recent
developments in the data-driven design of collective variables, with a focus on
the combination of Fisher's discriminant analysis and neural networks. This
approach allows to compress the fluctuations of metastable states into a
low-dimensional representation. We illustrate through several examples the
effectiveness of this method in accelerating the sampling, while also
identifying the physical descriptors that undergo the most significant changes
in the process.",data driven architecture,681
http://arxiv.org/abs/2012.05361v1,filtered,arxiv,arxiv,2020-12-09 00:00:00,arxiv,data-driven competitive algorithms for online knapsack and set cover,http://arxiv.org/abs/2012.05361v1,"The design of online algorithms has tended to focus on algorithms with
worst-case guarantees, e.g., bounds on the competitive ratio. However, it is
well-known that such algorithms are often overly pessimistic, performing
sub-optimally on non-worst-case inputs. In this paper, we develop an approach
for data-driven design of online algorithms that maintain near-optimal
worst-case guarantees while also performing learning in order to perform well
for typical inputs. Our approach is to identify policy classes that admit
global worst-case guarantees, and then perform learning using historical data
within the policy classes. We demonstrate the approach in the context of two
classical problems, online knapsack and online set cover, proving competitive
bounds for rich policy classes in each case. Additionally, we illustrate the
practical implications via a case study on electric vehicle charging.",data driven architecture,682
http://arxiv.org/abs/2010.09438v1,filtered,arxiv,arxiv,2020-10-14 00:00:00,arxiv,"how machine learning can help the design and analysis of composite
  materials and structures?",http://arxiv.org/abs/2010.09438v1,"Machine learning models are increasingly used in many engineering fields
thanks to the widespread digital data, growing computing power, and advanced
algorithms. Artificial neural networks (ANN) is the most popular machine
learning model in recent years. Although many ANN models have been used in the
design and analysis of composite materials and structures, there are still some
unsolved issues that hinder the acceptance of ANN models in the practical
design and analysis of composite materials and structures. Moreover, the
emerging machine learning techniques are posting new opportunities and
challenges in the data-based design paradigm. This paper aims to give a
state-of-the-art literature review of ANN models in the nonlinear constitutive
modeling, multiscale surrogate modeling, and design optimization of composite
materials and structures. This review has been designed to focus on the
discussion of the general frameworks and benefits of ANN models to the above
problems. Moreover, challenges and opportunities in each key problem are
identified and discussed. This paper is expected to open the discussion of
future research scope and new directions to enable efficient, robust, and
accurate data-driven design and analysis of composite materials and structures.",data driven architecture,683
http://arxiv.org/abs/2008.04808v1,filtered,arxiv,arxiv,2020-08-11 00:00:00,arxiv,3d flat: feasible learned acquisition trajectories for accelerated mri,http://arxiv.org/abs/2008.04808v1,"Magnetic Resonance Imaging (MRI) has long been considered to be among the
gold standards of today's diagnostic imaging. The most significant drawback of
MRI is long acquisition times, prohibiting its use in standard practice for
some applications. Compressed sensing (CS) proposes to subsample the k-space
(the Fourier domain dual to the physical space of spatial coordinates) leading
to significantly accelerated acquisition. However, the benefit of compressed
sensing has not been fully exploited; most of the sampling densities obtained
through CS do not produce a trajectory that obeys the stringent constraints of
the MRI machine imposed in practice. Inspired by recent success of deep
learning based approaches for image reconstruction and ideas from computational
imaging on learning-based design of imaging systems, we introduce 3D FLAT, a
novel protocol for data-driven design of 3D non-Cartesian accelerated
trajectories in MRI. Our proposal leverages the entire 3D k-space to
simultaneously learn a physically feasible acquisition trajectory with a
reconstruction method. Experimental results, performed as a proof-of-concept,
suggest that 3D FLAT achieves higher image quality for a given readout time
compared to standard trajectories such as radial, stack-of-stars, or 2D learned
trajectories (trajectories that evolve only in the 2D plane while fully
sampling along the third dimension). Furthermore, we demonstrate evidence
supporting the significant benefit of performing MRI acquisitions using
non-Cartesian 3D trajectories over 2D non-Cartesian trajectories acquired
slice-wise.",data driven architecture,684
http://arxiv.org/abs/2006.08052v2,filtered,arxiv,arxiv,2020-06-14 00:00:00,arxiv,autofocused oracles for model-based design,http://arxiv.org/abs/2006.08052v2,"Data-driven design is making headway into a number of application areas,
including protein, small-molecule, and materials engineering. The design goal
is to construct an object with desired properties, such as a protein that binds
to a therapeutic target, or a superconducting material with a higher critical
temperature than previously observed. To that end, costly experimental
measurements are being replaced with calls to high-capacity regression models
trained on labeled data, which can be leveraged in an in silico search for
design candidates. However, the design goal necessitates moving into regions of
the design space beyond where such models were trained. Therefore, one can ask:
should the regression model be altered as the design algorithm explores the
design space, in the absence of new data? Herein, we answer this question in
the affirmative. In particular, we (i) formalize the data-driven design problem
as a non-zero-sum game, (ii) develop a principled strategy for retraining the
regression model as the design algorithm proceeds---what we refer to as
autofocusing, and (iii) demonstrate the promise of autofocusing empirically.",data driven architecture,685
http://arxiv.org/abs/2006.02142v3,filtered,arxiv,arxiv,2020-06-01 00:00:00,arxiv,"metaset: exploring shape and property spaces for data-driven
  metamaterials design",http://arxiv.org/abs/2006.02142v3,"Data-driven design of mechanical metamaterials is an increasingly popular
method to combat costly physical simulations and immense, often intractable,
geometrical design spaces. Using a precomputed dataset of unit cells, a
multiscale structure can be quickly filled via combinatorial search algorithms,
and machine learning models can be trained to accelerate the process. However,
the dependence on data induces a unique challenge: An imbalanced dataset
containing more of certain shapes or physical properties can be detrimental to
the efficacy of data-driven approaches. In answer, we posit that a smaller yet
diverse set of unit cells leads to scalable search and unbiased learning. To
select such subsets, we propose METASET, a methodology that 1) uses similarity
metrics and positive semi-definite kernels to jointly measure the closeness of
unit cells in both shape and property spaces, and 2) incorporates Determinantal
Point Processes for efficient subset selection. Moreover, METASET allows the
trade-off between shape and property diversity so that subsets can be tuned for
various applications. Through the design of 2D metamaterials with target
displacement profiles, we demonstrate that smaller, diverse subsets can indeed
improve the search process as well as structural performance. By eliminating
inherent overlaps in a dataset of 3D unit cells created with symmetry rules, we
also illustrate that our flexible method can distill unique subsets regardless
of the metric employed. Our diverse subsets are provided publicly for use by
any designer.",data driven architecture,686
http://arxiv.org/abs/2003.05551v1,filtered,arxiv,arxiv,2020-03-11 00:00:00,arxiv,memory-efficient learning for large-scale computational imaging,http://arxiv.org/abs/2003.05551v1,"Critical aspects of computational imaging systems, such as experimental
design and image priors, can be optimized through deep networks formed by the
unrolled iterations of classical model-based reconstructions (termed
physics-based networks). However, for real-world large-scale inverse problems,
computing gradients via backpropagation is infeasible due to memory limitations
of graphics processing units. In this work, we propose a memory-efficient
learning procedure that exploits the reversibility of the network's layers to
enable data-driven design for large-scale computational imaging systems. We
demonstrate our method on a small-scale compressed sensing example, as well as
two large-scale real-world systems: multi-channel magnetic resonance imaging
and super-resolution optical microscopy.",data driven architecture,687
http://arxiv.org/abs/1912.05098v2,filtered,arxiv,arxiv,2019-12-11 00:00:00,arxiv,"memory-efficient learning for large-scale computational imaging --
  neurips deep inverse workshop",http://arxiv.org/abs/1912.05098v2,"Computational imaging systems jointly design computation and hardware to
retrieve information which is not traditionally accessible with standard
imaging systems. Recently, critical aspects such as experimental design and
image priors are optimized through deep neural networks formed by the unrolled
iterations of classical physics-based reconstructions (termed physics-based
networks). However, for real-world large-scale systems, computing gradients via
backpropagation restricts learning due to memory limitations of graphical
processing units. In this work, we propose a memory-efficient learning
procedure that exploits the reversibility of the network's layers to enable
data-driven design for large-scale computational imaging. We demonstrate our
methods practicality on two large-scale systems: super-resolution optical
microscopy and multi-channel magnetic resonance imaging.",data driven architecture,688
http://arxiv.org/abs/1910.06115v1,filtered,arxiv,arxiv,2019-10-11 00:00:00,arxiv,"microservices based linked data quality model for buildings energy
  management services",http://arxiv.org/abs/1910.06115v1,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality.",data driven architecture,689
http://arxiv.org/abs/1908.06778v1,filtered,arxiv,arxiv,2019-08-19 00:00:00,arxiv,"symbolic regression discovery of new perovskite catalysts with high
  oxygen evolution reaction activity",http://arxiv.org/abs/1908.06778v1,"Symbolic regression (SR) is an emerging method for building analytical
formulas to find models that best fit data sets. Here, SR was used to guide the
design of new oxide perovskite catalysts with improved oxygen evolution
reaction (OER) activities. An unprecedentedly simple descriptor, {\mu}/t, where
{\mu} and t are the octahedral and tolerance factors, respectively, was
identified, which accelerated the discovery of a series of new oxide perovskite
catalysts with improved OER activity. We successfully synthesized five new
oxide perovskites and characterized their OER activities. Remarkably, four of
them, Cs0.4La0.6Mn0.25Co0.75O3, Cs0.3La0.7NiO3, SrNi0.75Co0.25O3, and
Sr0.25Ba0.75NiO3, outperform the current state-of-the-art oxide perovskite
catalyst, Ba0.5Sr0.5Co0.8Fe0.2O3 (BSCF). Our results demonstrate the potential
of SR for accelerating data-driven design and discovery of new materials with
improved properties.",data driven architecture,690
http://arxiv.org/abs/1908.00192v1,filtered,arxiv,arxiv,2019-08-01 00:00:00,arxiv,"data changes everything: challenges and opportunities in data
  visualization design handoff",http://arxiv.org/abs/1908.00192v1,"Complex data visualization design projects often entail collaboration between
people with different visualization-related skills. For example, many teams
include both designers who create new visualization designs and developers who
implement the resulting visualization software. We identify gaps between data
characterization tools, visualization design tools, and development platforms
that pose challenges for designer-developer teams working to create new data
visualizations. While it is common for commercial interaction design tools to
support collaboration between designers and developers, creating data
visualizations poses several unique challenges that are not supported by
current tools. In particular, visualization designers must characterize and
build an understanding of the underlying data, then specify layouts, data
encodings, and other data-driven parameters that will be robust across many
different data values. In larger teams, designers must also clearly communicate
these mappings and their dependencies to developers, clients, and other
collaborators. We report observations and reflections from five large
multidisciplinary visualization design projects and highlight six data-specific
visualization challenges for design specification and handoff. These challenges
include adapting to changing data, anticipating edge cases in data,
understanding technical challenges, articulating data-dependent interactions,
communicating data mappings, and preserving the integrity of data mappings
across iterations. Based on these observations, we identify opportunities for
future tools for prototyping, testing, and communicating data-driven designs,
which might contribute to more successful and collaborative data visualization
design.",data driven architecture,691
http://arxiv.org/abs/1905.08503v1,filtered,arxiv,arxiv,2019-05-21 00:00:00,arxiv,"a universal approximation result for difference of log-sum-exp neural
  networks",http://arxiv.org/abs/1905.08503v1,"We show that a neural network whose output is obtained as the difference of
the outputs of two feedforward networks with exponential activation function in
the hidden layer and logarithmic activation function in the output node (LSE
networks) is a smooth universal approximator of continuous functions over
convex, compact sets. By using a logarithmic transform, this class of networks
maps to a family of subtraction-free ratios of generalized posynomials, which
we also show to be universal approximators of positive functions over
log-convex, compact subsets of the positive orthant. The main advantage of
Difference-LSE networks with respect to classical feedforward neural networks
is that, after a standard training phase, they provide surrogate models for
design that possess a specific difference-of-convex-functions form, which makes
them optimizable via relatively efficient numerical methods. In particular, by
adapting an existing difference-of-convex algorithm to these models, we obtain
an algorithm for performing effective optimization-based design. We illustrate
the proposed approach by applying it to data-driven design of a diet for a
patient with type-2 diabetes.",data driven architecture,692
http://arxiv.org/abs/1903.08876v1,filtered,arxiv,arxiv,2019-03-21 00:00:00,arxiv,"data-driven design of perfect reconstruction filterbank for dnn-based
  sound source enhancement",http://arxiv.org/abs/1903.08876v1,"We propose a data-driven design method of perfect-reconstruction filterbank
(PRFB) for sound-source enhancement (SSE) based on deep neural network (DNN).
DNNs have been used to estimate a time-frequency (T-F) mask in the short-time
Fourier transform (STFT) domain. Their training is more stable when a simple
cost function as mean-squared error (MSE) is utilized comparing to some
advanced cost such as objective sound quality assessments. However, such a
simple cost function inherits strong assumptions on the statistics of the
target and/or noise which is often not satisfied, and the mismatch of
assumption results in degraded performance. In this paper, we propose to design
the frequency scale of PRFB from training data so that the assumption on MSE is
satisfied. For designing the frequency scale, the warped filterbank frame
(WFBF) is considered as PRFB. The frequency characteristic of learned WFBF was
in between STFT and the wavelet transform, and its effectiveness was confirmed
by comparison with a standard STFT-based DNN whose input feature is compressed
into the mel scale.",data driven architecture,693
http://arxiv.org/abs/1903.08432v1,filtered,arxiv,arxiv,2019-03-20 00:00:00,arxiv,"designing nanophotonic structures using conditional-deep convolutional
  generative adversarial networks",http://arxiv.org/abs/1903.08432v1,"Data-driven design approaches based on deep-learning have been introduced in
nanophotonics to reduce time-consuming iterative simulations which have been a
major challenge. Here, we report the first use of conditional deep
convolutional generative adversarial networks to design nanophotonic antennae
that are not constrained to a predefined shape. For given input reflection
spectra, the network generates desirable designs in the form of images; this
form allows suggestions of new structures that cannot be represented by
structural parameters. Simulation results obtained from the generated designs
agreed well with the input reflection spectrum. This method opens new avenues
towards the development of nanophotonics by providing a fast and convenient
approach to design complex nanophotonic structures that have desired optical
properties.",data driven architecture,694
http://arxiv.org/abs/1811.12436v2,filtered,arxiv,arxiv,2018-11-29 00:00:00,arxiv,"freeform diffractive metagrating design based on generative adversarial
  networks",http://arxiv.org/abs/1811.12436v2,"A key challenge in metasurface design is the development of algorithms that
can effectively and efficiently produce high performance devices. Design
methods based on iterative optimization can push the performance limits of
metasurfaces, but they require extensive computational resources that limit
their implementation to small numbers of microscale devices. We show that
generative neural networks can train from images of periodic,
topology-optimized metagratings to produce high-efficiency, topologically
complex devices operating over a broad range of deflection angles and
wavelengths. Further iterative optimization of these designs yields devices
with enhanced robustness and efficiencies, and these devices can be utilized as
additional training data for network refinement. In this manner, generative
networks can be trained, with a onetime computation cost, and used as a design
tool to facilitate the production of near-optimal, topologically-complex device
designs. We envision that such data-driven design methodologies can apply to
other physical sciences domains that require the design of functional elements
operating across a wide parameter space.",data driven architecture,695
http://arxiv.org/abs/1808.07647v4,filtered,arxiv,arxiv,2018-08-23 00:00:00,arxiv,"machine learning at the edge: a data-driven architecture with
  applications to 5g cellular networks",http://arxiv.org/abs/1808.07647v4,"The fifth generation of cellular networks (5G) will rely on edge cloud
deployments to satisfy the ultra-low latency demand of future applications. In
this paper, we argue that such deployments can also be used to enable advanced
data-driven and Machine Learning (ML) applications in mobile networks. We
propose an edge-controller-based architecture for cellular networks and
evaluate its performance with real data from hundreds of base stations of a
major U.S. operator. In this regard, we will provide insights on how to
dynamically cluster and associate base stations and controllers, according to
the global mobility patterns of the users. Then, we will describe how the
controllers can be used to run ML algorithms to predict the number of users in
each base station, and a use case in which these predictions are exploited by a
higher-layer application to route vehicular traffic according to network Key
Performance Indicators (KPIs). We show that the prediction accuracy improves
when based on machine learning algorithms that rely on the controllers' view
and, consequently, on the spatial correlation introduced by the user mobility,
with respect to when the prediction is based only on the local data of each
single base station.",data driven architecture,696
http://arxiv.org/abs/1807.06699v5,filtered,arxiv,arxiv,2018-07-17 00:00:00,arxiv,adaptive neural trees,http://arxiv.org/abs/1807.06699v5,"Deep neural networks and decision trees operate on largely separate
paradigms; typically, the former performs representation learning with
pre-specified architectures, while the latter is characterised by learning
hierarchies over pre-specified features with data-driven architectures. We
unite the two via adaptive neural trees (ANTs) that incorporates representation
learning into edges, routing functions and leaf nodes of a decision tree, along
with a backpropagation-based training algorithm that adaptively grows the
architecture from primitive modules (e.g., convolutional layers). We
demonstrate that, whilst achieving competitive performance on classification
and regression datasets, ANTs benefit from (i) lightweight inference via
conditional computation, (ii) hierarchical separation of features useful to the
task e.g. learning meaningful class associations, such as separating natural
vs. man-made objects, and (iii) a mechanism to adapt the architecture to the
size and complexity of the training dataset.",data driven architecture,697
http://arxiv.org/abs/1805.12475v1,filtered,arxiv,arxiv,2018-05-30 00:00:00,arxiv,data-driven design: a case for maximalist game design,http://arxiv.org/abs/1805.12475v1,"Maximalism in art refers to drawing on and combining multiple different
sources for art creation, embracing the resulting collisions and heterogeneity.
This paper discusses the use of maximalism in game design and particularly in
data games, which are games that are generated partly based on open data. Using
Data Adventures, a series of generators that create adventure games from data
sources such as Wikipedia and OpenStreetMap, as a lens we explore several
tradeoffs and issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative and functional content,
and legal and ethical issues resulting from this type of generativity. This
paper sketches out the design space of maximalist data-driven games, a design
space that is mostly unexplored.",data driven architecture,698
http://arxiv.org/abs/1804.03298v1,filtered,arxiv,arxiv,2018-04-10 00:00:00,arxiv,mixed h2/h-infinity data-driven control design for hard disk drives,http://arxiv.org/abs/1804.03298v1,"A frequency based data-driven control design considering mixed H2/H-infinity
control objectives is developed for multiple input-single output systems. The
main advantage of the data-driven control over the model-based control is its
ability to use the frequency response measurements of the controlled plant
directly without the need to identify a model for the plant. In the proposed
methodology, multiple sets of measurements can be considered in the design
process to accommodate variations in the system dynamics. The controller is
obtained by translating the mixed H2/H-infinity control objectives into a
convex optimization problem. The H-infinity norm is used to shape closed loop
transfer functions and guarantee closed loop stability, while the H2 norm is
used to constrain and/or minimize the variance of signals in the time domain.
  The proposed data-driven design methodology is used to design a track
following controller for a dual-stage HDD. The sensitivity decoupling
structure[16] is considered as the controller structure. The compensators
inside this controller structure are designed and compared by decoupling the
system into two single input-single-output systems as well as solving for a
single input-double output controller.",data driven architecture,699
http://arxiv.org/abs/1803.05035v2,filtered,arxiv,arxiv,2018-03-13 00:00:00,arxiv,autonomous data-driven design of inorganic materials with aflow,http://arxiv.org/abs/1803.05035v2,"The expansion of programmatically-accessible materials data has cultivated
opportunities for data-driven approaches. Highly-automated frameworks like
AFLOW not only manage the generation, storage, and dissemination of materials
data, but also leverage the information for thermodynamic formability modeling,
such as the prediction of phase diagrams and properties of disordered
materials. In combination with standardized parameter sets, the wealth of data
is ideal for training machine learning algorithms, which have already been
employed for property prediction, descriptor development, design rule
discovery, and the identification of candidate functional materials. These
methods promise to revolutionize the path to synthesis and, ultimately,
transform the practice of traditional materials discovery to one of rational
and autonomous materials design.",data driven architecture,700
http://arxiv.org/abs/1802.00484v1,filtered,arxiv,arxiv,2018-02-01 00:00:00,arxiv,"alternative spreadsheet model designs for an operations management model
  embedded in a periodic business process",http://arxiv.org/abs/1802.00484v1,"We present a widely-used operations management model used in supply and
distribution planning, that is typically embedded in a periodic business
process that necessitates model modification and reuse. We consider three
alternative spreadsheet implementations, a data-driven design, a canonical
(textbook) design, and a novel (table-driven) technical design. We evaluate
each regarding suitability for accuracy, modification, analysis, and transfer.
We consider the degree of training and technical sophistication required to
utilize each design. The data-driven design provides insight into poor
spreadsheet practices by na\""ive modelers. The technical design can be modified
for new data and new structural elements without manual writing or editing of
cell formulas, thus speeding modification and reducing risk of error. The
technical design has potential for use with other classes of models. We
identify opportunities for future research.",data driven architecture,701
http://arxiv.org/abs/1707.02202v2,filtered,arxiv,arxiv,2017-07-07 00:00:00,arxiv,pandeia: a multi-mission exposure time calculator for jwst and wfirst,http://arxiv.org/abs/1707.02202v2,"Pandeia is the exposure time calculator (ETC) system developed for the James
Webb Space Telescope (JWST) that will be used for creating JWST proposals. It
includes a simulation-hybrid Python engine that calculates the two-dimensional
pixel-by-pixel signal and noise properties of the JWST instruments. This allows
for appropriate handling of realistic point spread functions, MULTIACCUM
detector readouts, correlated detector readnoise, and multiple photometric and
spectral extraction strategies. Pandeia includes support for all the JWST
observing modes, including imaging, slitted/slitless spectroscopy, integral
field spectroscopy, and coronagraphy. Its highly modular, data-driven design
makes it easily adaptable to other observatories. An implementation for use
with WFIRST is also available.",data driven architecture,702
http://arxiv.org/abs/1702.07739v1,filtered,arxiv,arxiv,2017-02-24 00:00:00,arxiv,"description of statistical switching in perpendicular stt-mram within an
  analytical and numerical micromagnetic framework",http://arxiv.org/abs/1702.07739v1,"The realistic modeling of STT-MRAM for the simulations of hybrid
CMOS/Spintronics devices in comprehensive simulation environments require a
full description of stochastic switching processes in state of the art
STT-MRAM. Here, we derive an analytical formulation that takes into account the
spin-torque asymmetry of the spin polarization function of magnetic tunnel
junctions studying. We studied its validity range by comparing the analytical
formulas with results achieved numerically within a full micromagnetic
framework. We also find that a reasonable fit of the probability density
function (PDF) of the switching time is given by a Pearson Type IV PDF. The
main results of this work underlines the need of data-driven design of STT-MRAM
that uses a full micromagnetic simulation framework for the statistical
proprieties PDF of switching processes.",data driven architecture,703
http://arxiv.org/abs/1505.01958v1,filtered,arxiv,arxiv,2015-05-08 00:00:00,arxiv,direct identification of fault estimation filter for sensor faults,http://arxiv.org/abs/1505.01958v1,"We propose a systematic method to directly identify a sensor fault estimation
filter from plant input/output data collected under fault-free condition. This
problem is challenging, especially when omitting the step of building an
explicit state-space plant model in data-driven design, because the inverse of
the underlying plant dynamics is required and needs to be stable. We show that
it is possible to address this problem by relying on a system-inversion-based
fault estimation filter that is parameterized using identified Markov
parameters. Our novel data-driven approach improves estimation performance by
avoiding the propagation of model reduction errors originating from
identification of the state-space plant model into the designed filter.
Furthermore, it allows additional design freedom to stabilize the obtained
filter under the same stabilizability condition as the existing model-based
system inversion. This crucial property enables its application to sensor
faults in unstable plants, where existing data-driven filter designs could not
be applied so far due to the lack of such stability guarantees (even after
stabilizing the closed-loop system). A numerical simulation example of sensor
faults in an unstable aircraft system illustrates the effectiveness of the
proposed new method.",data driven architecture,704
http://arxiv.org/abs/hep-ex/9902015v1,filtered,arxiv,arxiv,1999-02-10 00:00:00,arxiv,"a 16-channel digital tdc chip with internal buffering and selective
  readout for the dirc cherenkov counter of the babar experiment",http://arxiv.org/abs/hep-ex/9902015v1,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter
of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is
0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven
architecture integrates channel buffering and selective readout of data falling
within a programmable time window. The time measuring scale is constantly
locked to the phase of the (external) clock. The linearity is better than 80 ps
rms. The dead time loss is less than 0.1% for incoherent random input at a rate
of 100 khz on each channel. At such a rate the power dissipation is less than
100 mw. The die size is 36 mm2.",data driven architecture,705
10.14627/537690036,filtered,core,Wichmann Verlag im VDE Verlag GmbH,2020-01-01 00:00:00,core,bridging tangible and virtual realities : computational procedures for data-informed participatory processes,,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe",data driven architecture,706
10.1080/07399332.2019.1638924,filtered,core,'Informa UK Limited',2020-07-01 00:00:00,core,removing barriers to fistula care: applying appreciative inquiry to improve access to screening and treatment in nigeria and uganda,,"A research-to-action collaboration sought to understand and respond to barriers to female genital fistula treatment in Nigeria and Uganda. This was guided by appreciative inquiry, a participatory approach for transformative programing with four phases: (1) inquire, (2) imagine, (3) innovate, and (4) implement. Through this process, partners designed and refined a treatment barrier reduction intervention using multiple communication channels to disseminate a consistent fistula screening algorithm and provide transportation vouchers to those screening positive. Partnership between an implementation organization, a research institution, and local community partners enabled data-driven design and patient-centered implementation to address specific barriers experienced by women",data driven architecture,707
10.3390/buildings9050103,filtered,core,'MDPI AG',2019-04-01 00:00:00,core,data-driven design as a vehicle for bim and sustainability education,,"The development of BIM pedagogical strategies within the Architecture, Engineering, and Construction disciplines is a topic of significant research. Several approaches and theoretical lenses, such as Project-Based Learning, constructivist pedagogy, experiential learning, and Bloom&#8217;s Taxonomy have been applied to guide pedagogical education. This paper presents the development and evaluation of an approach integrating these four perspectives that was developed within an Architectural Science undergraduate program. A data-driven design project was incorporated into the curriculum to give students opportunities to engage with BIM-based simulation (cost and energy) to guide their design studio project development. The pedagogical approach is discussed, along with refinements to this project based on early implementation. Four years of data are analyzed, consisting of 1325 design iterations and student feedback on the project. A critical evaluation of the project determined that it was highly effective to engage students at an advanced level - level 4 (Analyze) of Bloom&#8217;s Taxonomy was consistently achieved (over 96% of students) and two thirds of students also engaged meaningfully at Level 5 (Evaluate; 67%) and/or 6 (Create; 8%) &#8212; while developing a high degree of competence in the use of BIM",data driven architecture,708
10.3390/s21154991,filtered,core,'MDPI AG',2021-07-01 00:00:00,core,unsupervised learning for product use activity recognition: an exploratory study of a “chatty device”,,"To create products that are better fit for purpose, manufacturers require new methods for gaining insights into product experience in the wild at scale. “Chatty Factories” is a concept that explores the transformative potential of placing IoT-enabled data-driven systems at the core of design and manufacturing processes, aligned to the Industry 4.0 paradigm. In this paper, we propose a model that enables new forms of agile engineering product development via “chatty” products. Products relay their “experiences” from the consumer world back to designers and product engineers through the mediation provided by embedded sensors, IoT, and data-driven design tools. Our model aims to identify product “experiences” to support the insights into product use. To this end, we create an experiment to: (i) collect sensor data at 100 Hz sampling rate from a “Chatty device” (device with sensors) for six common everyday activities that drive produce experience: standing, walking, sitting, dropping and picking up of the device, placing the device stationary on a side table, and a vibrating surface; (ii) pre-process and manually label the product use activity data; (iii) compare a total of four Unsupervised Machine Learning models (three classic and the fuzzy C-means algorithm) for product use activity recognition for each unique sensor; and (iv) present and discuss our findings. The empirical results demonstrate the feasibility of applying unsupervised machine learning algorithms for clustering product use activity. The highest obtained F-measure is 0.87, and MCC of 0.84, when the Fuzzy C-means algorithm is applied for clustering, outperforming the other three algorithms applied",data driven architecture,709
10.1515/nanoph-2019-0117,filtered,core,'Walter de Gruyter GmbH',2019-06-01 00:00:00,core,designing nanophotonic structures using conditional deep convolutional generative adversarial networks,,"Data-driven design approaches based on deep learning have been introduced in nanophotonics to reduce time-consuming iterative simulations, which have been a major challenge. Here, we report the first use of conditional deep convolutional generative adversarial networks to design nanophotonic antennae that are not constrained to predefined shapes. For given input reflection spectra, the network generates desirable designs in the form of images; this allows suggestions of new structures that cannot be represented by structural parameters. Simulation results obtained from the generated designs agree well with the input reflection spectrum. This method opens new avenues toward the development of nanophotonics by providing a fast and convenient approach to the design of complex nanophotonic structures that have desired optical properties",data driven architecture,710
10.1017/dsd.2020.4,filtered,core,'Cambridge University Press (CUP)',2020-01-01 00:00:00,core,data-driven design in concept development : systematic review and missed opportunities,,"The paper presents a systematic literature review investigating definitions, uses, and application of data-driven design in the concept development process. The analysis shows a predominance of the use of text mining techniques on social media and online reviews to identify customers’ needs, not exploiting the opportunity granted by the increased accessibility of IoT in cyber-physical systems. The paper argues that such a gap limits the potential of capturing tacit customers’ needs and highlights the need to proactively plan and design for a transition toward data-driven design.Open access</p",data driven architecture,711
10.1186/s13068-019-1565-x,filtered,core,'Springer Science and Business Media LLC',2019-09-30 00:00:00,core,discovery and implementation of a novel pathway for n-butanol production via 2-oxoglutarate,https://core.ac.uk/download/232203331.pdf,"Background
One of the European Union directives indicates that 10% of all fuels must be bio-synthesized by 2020. In this regard, biobutanolnatively produced by clostridial strainsposes as a promising alternative biofuel. One possible approach to overcome the difficulties of the industrial exploration of the native producers is the expression of more suitable pathways in robust microorganisms such as Escherichia coli. The enumeration of novel pathways is a powerful tool, allowing to identify non-obvious combinations of enzymes to produce a target compound.

Results
This work describes the in silico driven design of E. coli strains able to produce butanol via 2-oxoglutarate by a novel pathway. This butanol pathway was generated by a hypergraph algorithm and selected from an initial set of 105,954 different routes by successively applying different filters, such as stoichiometric feasibility, size and novelty. The implementation of this pathway involved seven catalytic steps and required the insertion of nine heterologous genes from various sources in E. coli distributed in three plasmids. Expressing butanol genes in E. coli K12 and cultivation in High-Density Medium formulation seem to favor butanol accumulation via the 2-oxoglutarate pathway. The maximum butanol titer obtained was 85±1 mg L1 by cultivating the cells in bioreactors.

Conclusions
In this work, we were able to successfully translate the computational analysis into in vivo applications, designing novel strains of E. coli able to produce n-butanol via an innovative pathway. Our results demonstrate that enumeration algorithms can broad the spectrum of butanol producing pathways. This validation encourages further research to other target compounds.This study was supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of a Ph.D. Grant (PD/BD/52366/2013) from MIT Portugal Program and the strategic funding of UID/BIO/04469 unit. Additional support was received by COMPETE 2020 (POCI-01-0145-FEDER-006684) and BioTecNorte operation (NORTE-01-0145-FEDER-000004) funded by the European Regional Development Fund under the scope of Norte2020-Programa Operacional Regional do Norte.

The authors also thank the Times New Roman project “Dynamics”, Ref. ERA-IB-2/0002/2014, funded by national funds through FCT/MCTES.

The genes thl, hbd, crt and adhE1 were kindly provided by Kristala L. Jones Prather from MIT.

The authors thank the project DDDeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission and the Project LISBOA010145 FEDER007660 (Microbiologia Molecular, Estrutural e Celular) funded by FEDER funds through COMPETE2020 Programa Operacional Competitividade e Internacionalização (POCI) and by national funds through FCT Fundacao para a Ciencia e a Tecnologiainfo:eu-repo/semantics/publishedVersio",data driven architecture,712
10.1393/ncc/i2021-21125-3,filtered,core,Societa italiana di fisica,2021-01-01 00:00:00,core,training collective variables for enhanced sampling via neural networks based discriminant analysis,,"A popular way to accelerate the sampling of rare events in molecular dynamics simulations is to introduce a potential that increases the fluctuations of selected collective variables. For this strategy to be successful, it is critical to choose appropriate variables. Here we review some recent developments in the data-driven design of collective variables, which combine Fisher’s discriminant analysis and neural networks. This approach allows to compress the fluctuations of metastable states into a low-dimensional representation. We illustrate through different applications the effectiveness of this method in accelerating the sampling, while also identifying the physical descriptors that undergo the most significant changes in the process",data driven architecture,713
10.1186/s12896-019-0529-3,filtered,core,'Springer Science and Business Media LLC',2019-12-01 00:00:00,core,genome-wide sequencing and metabolic annotation of pythium irregulare cbs 494.86: understanding eicosapentaenoic acid production,,"Pythium irregulare is an oleaginous Oomycete able to accumulate large amounts of lipids, including Eicosapentaenoic acid (EPA). EPA is an important and expensive dietary supplement with a promising and very competitive market, which is dependent on fish-oil extraction. This has prompted several research groups to study biotechnological routes to obtain specific fatty acids rather than a mixture of various lipids. Moreover, microorganisms can use low cost carbon sources for lipid production, thus reducing production costs. Previous studies have highlighted the production of EPA by P. irregulare, exploiting diverse low cost carbon sources that are produced in large amounts, such as vinasse, glycerol, and food wastewater. However, there is still a lack of knowledge about its biosynthetic pathways, because no functional annotation of any Pythium sp. exists yet. The goal of this work was to identify key genes and pathways related to EPA biosynthesis, in P. irregulare CBS 494.86, by sequencing and performing an unprecedented annotation of its genome, considering the possibility of using wastewater as a carbon source.The genome sequencing, strain acquisition and preliminary experiments and data analysis were funded by the São Paulo Research Foundation (FAPESP) and Coordination for the Improvement of Higher Education Personnel (CAPES) (Grante: 2016/10562–4). The experiment performance, data collection, analysis and interpretation of data were supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of the strategic funding of [UID/BIO/04469] unit and COMPETE 2020 [POCI01-0145-FEDER-006684] and BioTecNorte operation [NORTE-01-0145-FEDER000004] funded by the European Regional Development Fund under the scope of Norte2020 - Programa Operacional Regional do Norte. The authors thank the project DD-DeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission.info:eu-repo/semantics/publishedVersio",data driven architecture,714
10.1136/bmjopen-2019-030385,filtered,core,'BMJ',2019-07-01 00:00:00,core,collaborative design of a decision aid for stroke survivors with multimorbidity: a qualitative study in the uk engaging key stakeholders,,"Objectives: Effective secondary stroke prevention strategies are sub-optimally used. Novel development of interventions to enable healthcare professionals and stroke survivors to manage risk factors for stroke recurrence are required. We sought to engage key stakeholders in the design and evaluation of an intervention informed by a Learning Health System approach, to improve risk factor management and secondary prevention for stroke survivors with multimorbidity. Design: Qualitative, including focus groups, semi-structured interviews and usability evaluations. Data was audio-recorded, transcribed and coded thematically. Participants: Stroke survivors, carers, health and social care professionals, commissioners, policy makers and researchers. Setting: Stroke survivors were recruited from the South London Stroke Register; health and social care professionals through South London general practices and King’s College London (KCL) networks; carers, commissioners, policy-makers and researchers through KCL networks. Results: 53 stakeholders in total participated in focus groups, interviews and usability evaluations. Thirty-seven participated in focus groups and interviews, including stroke survivors and carers (N=11), health and social care professionals (N=16), commissioners and policy-makers (N=6) and researchers (N=4). Sixteen participated in usability evaluations, including stroke survivors (N=8) and general practitioners (GPs; N=8). Eight themes informed the collaborative design of DOTT (Deciding on Treatments Together), a decision aid integrated with the electronic health record system, to be used in primary care during clinical consultations between the healthcare professional and stroke survivor. DOTT aims to facilitate shared decision making on personalised treatments leading to improved treatment adherence and risk control. DOTT was found acceptable and usable among stroke survivors and GPs during a series of evaluations. Conclusions: Adopting a user-centred data-driven design approach informed an intervention that is acceptable to users and has the potential to improve patient outcomes. A future feasibility study and subsequent clinical trial will provide evidence of the effectiveness of DOTT in reducing risk of stroke recurrence",data driven architecture,715
10.1504/ijpd.2020.106464,filtered,core,'Inderscience Publishers',2020-01-01 00:00:00,core,a framework for data-driven design in a product innovation process: data analysis and visualisation for model-based decision making,,"International audienceThe paper presents a four-layer framework for the application of data-driven design in a product innovation process. The framework builds on the Knowledge Value Stream and on the Product Value Streams of a product innovation process and indicates how data-driven activities shall be structured and organised in relation to the different phases of a model-based decision process. Visualisation is proposed as a communication enabler at the top of the framework to overcome the comprehensibility barrier between data science and engineering design models. The framework is implemented in the case study of a construction equipment encompassing the analysis of operational machine data and the experimentation of suitable visualisation techniques. Ultimately, a list of challenges for the implementation of data-driven design is presented, and the capability of the framework to support the transition toward data-driven design is discussed in relation to the emergence of product-service systems solutions",data driven architecture,716
10.1007/s00170-021-07945-z,filtered,core,'Springer Science and Business Media LLC',2022-02-01 00:00:00,core,product design lifecycle information model (pdlim),,"In response to rapidly changing market and customer needs, product design and development (PDD) is evolving into a human-centred and data-driven design paradigm. The design environment gets more open often involving crowdsourcing and the design process becomes more complex, considering product family design along product whole lifecycle development, and needing more data support. Therefore, it is critical to effectively capture, share, and manage design-related information in such a complex design environment. From this perspective, it is a prerequisite to have a proper product design lifecycle information model (PDLIM) to guide information gathering, sharing and management. To the best of our knowledge, currently, there lacks such a PDLIM to support effective PDD, though digital twin (DT) technology shows a great potential of supporting product lifecycle information collection and management. In this paper, the overall structure of the proposed PDLIM is firstly developed to frame in all main product lifecycle stages and the corresponding key phases for structurally capturing and storing necessary data along a product lifecycle. Secondly, key design information items against the main product lifecycle stages and their corresponding key phases are explored from literature reviews and case study analyses. Thirdly, the necessity of the identified information items in the PDLIM is qualitatively evaluated by two case studies. Finally, the PDLIM is further evaluated by applying formal object-role modelling (ORM) to demonstrate how design information items are used and interacted in exemplary design interaction scenarios, and to approve that it can be formally described and managed as an information model. The evaluation results show that the PDLIM is feasible to be adapted in a crowdsourcing-combined PDD process for supporting design management, reviewing, quality control, and next round product redesign and improvement",data driven architecture,717
10.1017/dsi.2019.252,filtered,core,'Cambridge University Press (CUP)',2019-08-05 00:00:00,core,an affordance-based online review analysis framework,,"International audienceOne of the main tasks of today's data-driven design is to learn customers' concerns from the feedback data posted on the internet, to drive smarter and more profitable decisions during product development. Feature-based opinion mining was first performed by the computer and design scientists to analyse online product reviews. In order to provide more sophisticated customer feedback analyses and to understand in a deeper way customer concerns about products, the authors propose an affordance-based online review analysis framework. This framework allows understanding how and in what condition customers use their products, how user preferences change over years and how customers use the product innovatively. An empirical case study using the proposed approach is conducted with the online reviews of Kindle e-readers downloaded from amazon.com. A set of innovation leads and redesign paths are provided for the design of next-generation e-reader. This study suggests that bridging data analytics with classical models and methods in design engineering can bring success for data-driven design",data driven architecture,718
10.1145/3313831.3376560,filtered,core,'Association for Computing Machinery (ACM)',2020-04-01 00:00:00,core,exploring the future of data-driven product design,https://core.ac.uk/download/286713582.pdf,"Connected devices present new opportunities to advance design through data collection in the wild, similar to the way digital services evolve through analytics. However, it is still unclear how live data transmitted by connected devices informs the design of these products, going beyond performance optimisation to support creative practices. Design can be enriched by data captured by connected devices, from usage logs to environmental sensors, and data about the devices and people around them. Through a series of workshops, this paper contributes industry and academia perspectives on the future of data-driven product design. We highlight HCI challenges, issues and implications, including sensemaking and the generation of design insight. We further challenge current notions of data-driven design and envision ways in which future HCI research can develop ways to work with data in the design process in a connected, rich, human manner",data driven architecture,719
10.1017/pds.2021.475,filtered,core,'Cambridge University Press (CUP)',2021-01-01 00:00:00,core,model-driven product service systems design : the model-driven development and decision support (md3s) approach,,"The paper presents a Model-Driven approach for Product-Service System (PSS) Design promoting an increased digitalization of the PSS design process based on the combination of data-driven design (DDD) activities and value-driven design (VDD) methods. The approach is the results of an 8-year long research profile named (omitted for blind review) featuring the collaboration between (omitted for blind review) and nine industrial companies, in the field of PSS Design. It combines VDD models and the supporting data-driven activities in the frame of PSS design and aligns with the product value stream and the knowledge value stream in the product innovation process as described by Kennedy et al. (2008). The paper provides a high-level overview of the approach describing the different stages and activities, and provides references to external scientific contributions for more exhaustive descriptions of the research rationale and validity. The approach is meant to ultimately drive the development and implementation of a simulation environment for cross-functional and multi-disciplinary decision making in PSS, named Model-Driven Decision Arena, describe in the concluding part of the paper.open access</p",data driven architecture,720
10.1038/s41524-018-0096-5,filtered,core,'Springer Science and Business Media LLC',2020-02-27 00:00:00,core,materiaali-informatiikka: datalähtöinen suunnittelu ja koneoppiminen materiaalitieteen tukena,,"Materials science is the systematic study and development of materials and their properties. Materials informatics and data-driven materials science are umbrella terms for the scientific practice of systematically extracting knowledge from data produced in materials science. This practice differs from traditional scientific approaches in materials research by the volume of processed data and the more automated way information is extracted. This data-driven approach — sometimes referred to as the 4th paradigm of science — is largely driven by the use of modern hardware and software for data production and storage, the Open Science movement and the methodological developments in data mining and machine learning. 
This dissertation reviews how materials informatics can be effectively applied to accelerate materials science, focusing on computational, atomistic materials modelling. The topic is divided into two different areas: how the data-driven design and tools are being used to re-imagine the life-cycle of materials data and how machine learning, in particular, can be used to complement existing research methodologies in materials science. These topics are explored by investigating the historical development of materials informatics and by highlighting the modern tools and techniques.  
This discussion provides a guide for anyone interested in deploying these methods in their research and also covers some of the key challenges that the field of materials informatics still faces. After this overview, the original materials informatics research performed during the studies is summarized. First, the open-source software libraries developed for materials informatics are introduced. These libraries deal specifically with tasks related to the automated structural classification of complex atomistic geometries and the efficient description of materials for machine learning. Next, the studies related to materials discovery using data mining and machine learning are discussed. The first study leverages materials databases in the search for optimal coating materials for perovskite-based photovoltaics while the second study focuses on using machine learning for identifying catalytically active sites on nanoclusters.Materiaalitiede pyrkii ymmärtämään ja mallintamaan materiaalien ominaisuuksia ja valjastamaan näitä ominaisuuksia erilaisiin sovelluksiin. Materiaali-informatiikka ja datalähtöinen materiaalitiede ovat yläkäsitteitä käytännöille, joissa olemassaolevia tietomassoja hyödynnetään tehokkaasti materiaalituntemuksen edistämiseksi. Tämä eroaa perinteisistä tieteellisistä lähestymistavoista, sillä prosessoidun tiedon määrä on suurempi vaatien lähes täysin automatisoituja menetelmiä. Tätä datalähtöistä lähestymistapaa on myös kutsuttu tieteen neljänneksi paradigmaksi. Se syntyyn ovat vaikuttaneet kyky tuottaa ja tallentaa suuria tietomääriä modernin tietokonelaitteiston ja -ohjelmiston avulla, avoimen tieteen periaatteiden käyttöönotto sekä tiedon louhintaan ja koneoppimiseen käytettyjen menetelmien kehitys. 
Tässä väitöskirjassa tarkastellaan kuinka materiaali-informatiikkaa voidaan tehokkaasti soveltaa materiaalitieteen nopeuttamiseen keskittyen laskennalliseen, atomistiseen materiaalien mallintamiseen. Aihe on jaettu kahteen eri osa-alueeseen: miten datalähtöistä suunnittelua ja siihen liittyviä työkaluja käytetään materiaalitiedon elinkaaren uudelleenjärjestämiseen ja kuinka erityisesti koneoppimista voidaan käyttää olemassa olevien tutkimusmenetelmien täydentämiseksi. Näitä aiheita lähestytään tutkimalla materiaali-informatiikan historiallista kehitystä ja nostamalla esiin nykyaikaisia työkaluja ja tekniikoita. 
Tämä yhteenveto tarjoaa oppaan kaikille, jotka ovat kiinnostuneita näiden menetelmien käyttöönotosta tutkimuksessaan tuoden samalla esiin materiaali-informatiikan keskeisimpiä haasteita.Tämän yleiskatsauksen jälkeen esitellään opintojen aikana suoritettu alkuperäinen materiaalitutkimus. Aluksi käydään läpi materiaali-informaatiikkaa varten kehitetyt avoimen lähdekoodin ohjelmistokirjastot. Nämä kirjastot käsittelevät monimutkaisten atomististen geometrioiden automaattista rakenteellista luokittelua ja materiaaleja kuvaavan syötteen tehokasta muodostamista koneoppimista varten. Seuraavaksi esitellään tutkimukset, joissa tiedon louhintaa ja koneoppista käytetään uusien materiaalien etsimiseen kahdessa eri sovelluskohteessa. Ensimmäisessä tutkimuksessa hyödynnetään materiaalitietokantoja etsittäessä optimaalisia pinnoitemateriaaleja perovskiittipohjaisille aurinkokennoille, kun taas toisessa tutkimuksessa käytetään koneoppimista katalyyttisesti aktiivisten sijaintien tunnistamiseen nanoklustereissa",data driven architecture,721
10.35199/norddesign2020.26,filtered,core,'The Design Society',2020-01-01 00:00:00,core,shaping wicked problem solvers : innovating education programs through design thinking,,"Societies across the globe are facing many unprecedented challenges; climate change, pandemics, and resource depletion, just to name a few. These societal challenges, the 2030 Sustainable Development Agenda, and companies’ demands about knowledge and skills required from future employees have put pressure on academia to develop suitable education programmes in many disciplines, including product development and mechanical engineering. In this position paper, we present our work undertaken in phase-1 of the development of a new MSc programme in the field of product development and mechanical engineering at Blekinge Institute of Technology, aimed at addressing changing societal needs and demands of the future industry. We employ a generic design thinking approach, starting from key stakeholder needs with iterative execution of needfinding, benchmarking, and ideation. In these steps, we use several data collection and generation methods such as interviews, surveys, and workshops. The main outcome of phase-1 is the overall programme structure, consisting of three main focus streams — the engineering design core, three academic specializations (Product-Service Systems Design, Data-Driven Design, and Simulation- Driven Design), and the practical application profiling. Based on our experience of developing the overall programme structure, we offer recommendations for developing new programmes in this area.Open accessUtvecklingsprogram av Civilingenjörsprogram i Maskinteknik på Avancerad Niv",data driven architecture,722
10.1017/pds.2021.84,filtered,core,'Cambridge University Press (CUP)',2021-01-01 00:00:00,core,data-driven design automation for product-service systems design : framework and lessons learned from empirical studies.,,"The digitalization era has brought about unprecedented challenges for the manufacturing industries, pushing them to deliver solutions that encompass both product and service-related dimensions, known as Product-service Systems. This paper presents a number of lessons learned in the process of integrating the analysis of operational data as decision support in engineering design based on the empirical studies from two Swedish manufacturing companies operating in the construction machinery sector. The paper highlights the need to consider a five-dimensional perspective when collecting and analyzing data, encompassing data from the product, the service, the environment, the infrastructure, and the humans involved. Finally, a conceptual framework for data-driven design automation of Product-service Systems is proposed by leveraging the use of these data, introducing the concept of a Product-Service System Configurator as an enabler of design automation. The implementation of the proposed framework on multiple case studies in different industrial contexts shall be considered as the next step of the research.open access</p",data driven architecture,723
rit scholar works,filtered,core,,2017-06-16 00:00:00,core,https://core.ac.uk/download/232142182.pdf,,"Though the smart electrical grid promises many advantages in efficiency and reliability, the risks to consumer privacy have impeded its deployment. Researchers have proposed protecting privacy by aggregating user data before it reaches the utility, using techniques of homomorphic encryption to prevent exposure of unaggregated values. However, such schemes generally require users to trust in the correct operation of a single aggregation server. We propose two alternative systems based on secret sharing techniques that distribute this trust among multiple service providers, protecting user privacy against a misbehaving server. We also provide an extensive evaluation of the systems considered, comparing their robustness to privacy compromise, error handling, computational performance, and data transmission costs. We conclude that while all the systems should be computationally feasible on smart meters, the two methods based on secret sharing require much less computation while also providing better protection against corrupted aggregators. Building systems using these techniques could help defend the privacy of electricity customers, as well as customers of other utilities as they move to a more data-driven architecture",data driven architecture,724
'american institute of aeronautics and astronautics (aiaa)',filtered,core,10.2514/6.2018-0569,2018-04-17 00:00:00,core,https://core.ac.uk/download/156872734.pdf,,"Digital Thread offers the opportunity to use information generated across the product lifecycle to design the next generation of products. In this paper, we introduce a mathematical methodology that establishes the data-driven design and decision problem associated with Digital Thread. Our objectives are twofold: 1) Provide a mathematical definition of Digital Thread in the context of conceptual and preliminary design and establish a methodology for how information along the Digital Thread enters into the design problem as well how design decisions affect the Digital Thread. 2) Develop a data-driven design method that incorporates data from different sources from across the product life cycle. We illustrate aspects of our methodology through an example design of a structural fiber-steered composite component.United States. Air Force. Office of Scientific Research (Grant FA9550-16-1-0108)SUTD-MIT International Design Centre (IDC",data driven architecture,725
iterations,filtered,core,,2018-01-01 00:00:00,core,https://core.ac.uk/download/289101933.pdf,,"peer-reviewedThis article describes a developing creative practice whereby digital creative processes

adapted from mobile music making are used in the data driven design and subsequent

digital instantiation of ceramic vessels. First, related work in mobile music creation and

recent developments in the digital design and fabrication of ceramics frames the research

and puts it in a broad context. A pilot study is then detailed, concluding that although

largely successful, a number of areas of the process needed to be improved and refined.

The results of a further iteration of the process, consisting of the digital creation and

instantiation of location-specific vessels is presented, before the current state of the

research, where ceramic vessels are 3D printed, is outlined. We show that mobile phones

can become integral to a practical design process that allows the digital forms it creates to

be instantiated using 3D printing, and that these become high-quality, end-use artefacts.

The final section discusses what has been learned and contemplates how the described

practice will be developed yet further",data driven architecture,726
digitalcommons@university of nebraska - lincoln,filtered,core,,2019-05-29 00:00:00,core,https://core.ac.uk/download/222664432.pdf,,"Previous applications to design processes intend to enhance a building’s schematic design using quantitative data. Therefore, most applications to the early design phases are passed by as simple overarching ideas informed by the designer and users’ knowledge. Although this is a preferred method of choice making, the knowledge used to inform conceptual and schematic design process can be limited. With the increase of computation in all major industries, a new increase in data to describe forms of infrastructure is required. These forms being objects to analyze their performance and potential, and active forms that can describe the disposition of urban space. Previous research into data driven design has worked its way into standardization and performance goals. However, the connection between active and object forms as a network of standards has yet to be introduced as a method of advising design. Meaning design has focused on creating a single object that seems to benefit the ecology. No attempt at connecting urban active data to object data has been made to benefit both forms equally, but only to preserve the status quo. The introduction of Machine learning algorithms has the capability to connect these complex forms and inform new designs. The application of machine learning algorithms advises the early phases of architectural design process by reviewing a manifold of data, privileging complex analogical connections, and simulating the designers informed symbolic choices.
Supervisor Professor Mark A. Hoistad, AI",data driven architecture,727
'spie-intl soc optical eng',filtered,core,10.1117/12.2231768,2018-03-21 00:00:00,core,http://arxiv.org/abs/1707.02202,,"Pandeia is the exposure time calculator (ETC) system developed for the James
Webb Space Telescope (JWST) that will be used for creating JWST proposals. It
includes a simulation-hybrid Python engine that calculates the two-dimensional
pixel-by-pixel signal and noise properties of the JWST instruments. This allows
for appropriate handling of realistic point spread functions, MULTIACCUM
detector readouts, correlated detector readnoise, and multiple photometric and
spectral extraction strategies. Pandeia includes support for all the JWST
observing modes, including imaging, slitted/slitless spectroscopy, integral
field spectroscopy, and coronagraphy. Its highly modular, data-driven design
makes it easily adaptable to other observatories. An implementation for use
with WFIRST is also available",data driven architecture,728
surface at syracuse university,filtered,core,,2018-12-21 00:00:00,core,https://core.ac.uk/download/215712850.pdf,,"Autonomy and intelligence have been built into many of today’s mechatronic products, taking advantage of low-cost sensors and advanced data analytics technologies. Design of product intelligence (enabled by analytics capabilities) is no longer a trivial or additional option for the product development. The objective of this research is aimed at addressing the challenges raised by the new data-driven design paradigm for smart products development, in which the product itself and the smartness require to be carefully co-constructed.
A smart product can be seen as specific compositions and configurations of its physical components to form the body, its analytics models to implement the intelligence, evolving along its lifecycle stages. Based on this view, the contribution of this research is to expand the “Product Lifecycle Management (PLM)” concept traditionally for physical products to data-based products. As a result, a Smart Products Lifecycle Management (sPLM) framework is conceptualized based on a high-dimensional Smart Product Hypercube (sPH) representation and decomposition.
First, the sPLM addresses the interoperability issues by developing a Smart Component data model to uniformly represent and compose physical component models created by engineers and analytics models created by data scientists. Second, the sPLM implements an NPD3 process model that incorporates formal data analytics process into the new product development (NPD) process model, in order to support the transdisciplinary information flows and team interactions between engineers and data scientists. Third, the sPLM addresses the issues related to product definition, modular design, product configuration, and lifecycle management of analytics models, by adapting the theoretical frameworks and methods for traditional product design and development.
An sPLM proof-of-concept platform had been implemented for validation of the concepts and methodologies developed throughout the research work. The sPLM platform provides a shared data repository to manage the product-, process-, and configuration-related knowledge for smart products development. It also provides a collaborative environment to facilitate transdisciplinary collaboration between product engineers and data scientists",data driven architecture,729
eci digital archives,filtered,core,,2018-03-06 00:00:00,core,https://core.ac.uk/download/185674447.pdf,,"Plants produce a variety of rare natural products which are used in our daily lives as flavors, fragrances, food ingredients, cosmetics, vitamins, pharmaceuticals and agricultural chemicals. Despite their intrinsic value, however, sourcing remains a bottleneck to more widespread use due to their low abundance in nature. Manus Bio has established an innovative platform technology for engineering microbial factories grounded in modular and data-driven design and developed a commercial organism which can produce a myriad of typically ultra-rare and costly ingredients used in our daily lives. These microbes are capable of converting carbon feedstock to the product at high yields and have been adapted to produce a mature pipeline of products, or  BioAssemblyLine.  To engineer our “BioAssemblyLine,” we integrate three core technologies - our proprietary Multivariate Modular Metabolic Engineering (MMME), Pathway Integrated Protein Engineering (PIPE) and Integrated Multivariate Omics Analysis (IMOA) platforms. In this presentation, we will highlight several important insights and guiding principles established to engineer our “BioAssemblyLine” microbial factories",data driven architecture,730
"lausanne, epfl",filtered,core,10.5075/epfl-thesis-8305,2018-02-15 00:00:00,core,https://core.ac.uk/download/211981021.pdf,,"The objective of this dissertation is to develop data-driven frequency-domain methods for designing robust controllers through the use of convex optimization algorithms. Many of today's industrial processes are becoming more complex, and modeling accurate physical models for these plants using first principles may be impossible. With the increased developments in the computing world, large amounts of measured data can be easily collected and stored for processing purposes. Data can also be collected and used in an on-line fashion. Thus it would be very sensible to make full use of this data for controller design, performance evaluation, and stability analysis. The design methods imposed in this work ensure that the dynamics of a system are captured in an experiment and avoids the problem of unmodeled dynamics associated with parametric models. The devised methods consider robust designs for both linear-time-invariant (LTI) single-input-single-output (SISO) systems and certain classes of nonlinear systems. 

In this dissertation, a data-driven approach using the frequency response function of a system is proposed for designing robust controllers with H&infin; performance. Necessary and sufficient conditions are derived for obtaining H&infin; performance while guaranteeing the closed-loop stability of a system. A convex optimization algorithm is implemented to obtain the controller parameters which ensure system robustness; the controller is robust with respect to the frequency-dependent uncertainties of the frequency response function. For a certain class of nonlinearities, the proposed method can be used to obtain a best-linear-approximation with an associated frequency dependent uncertainty to guarantee the stability and performance for the underlying linear system that is subject to nonlinear distortions.

The concepts behind these design methods are then used to devise necessary and sufficient conditions for ensuring the closed-loop stability of systems with sector-bounded nonlinearities. The conditions are simple convex feasibility constraints which can be used to stabilize systems with multi-model uncertainty. Additionally, a method is proposed for obtaining H&infin; performance for an approximate model (i.e., describing function) of a sector-bounded nonlinearity. 

This work also proposes several data-driven methods for designing robust fixed-structure controllers with H&infin; performance. One method considers the solution to a non-convex problem, while another method convexifies the problem and implements an iterative algorithm to obtain the local solution (which can also consider H2 performance).

The effectiveness of the proposed method(s) is illustrated by considering several case studies that require robust controllers for achieving the desired performance. The main applicative work in this dissertation is with respect to a power converter control system at the European Organization for Nuclear Research (CERN) (which is used to control the current in a magnet to produce the desired field in controlling particle trajectories in accelerators). The proposed design methods are implemented in order to satisfy the challenging performance specifications set by the application while guaranteeing the system stability and robustness using data-driven design strategies",data driven architecture,731
'sage publications',filtered,core,10.1177/0263775818767426,2018-12-31 00:00:00,core,https://core.ac.uk/download/154409882.pdf,"[{'title': 'Environment and Planning D Society and Space', 'identifiers': ['issn: 1472-3433', 'issn:0263-7758', '0263-7758', ' 1472-3433']}]","This paper draws upon the example of High-Cost Short-Term Credit products accessed via digital interfaces and devices to examine practices of interface design and the operation of digitally mediated power. Utilising interviews with High-Cost Short-Term Credit website designers and users of these products, the paper shows how these interfaces are designed and tested to manage frictions: practical, affective or emotional contestations that interrupt or stop users from applying for these products and entering into credit and debt. We suggest that the key role of interface design is to manage these frictions by guiding action in such a way to minimise negative affective states at key thresholds of the application process. The management of friction is enabled by practices of data-driven design, where the contingency of human response is engineered through analytics in order to increase rates of application. Working through the example of High-Cost Short-Term Credit, the paper complicates a notion of control as a smooth or automatic operation of power, instead emphasising the necessity of both continuity and discontinuity as key to modulating action in a digital age. To understand the specificity of interface interactions and move beyond existing work on control, we offer a vocabulary of friction, thresholds and transitions",data driven architecture,732
association for computational creativity,filtered,core,,2018-01-01 00:00:00,core,https://core.ac.uk/download/231681156.pdf,,"Maximalism in art refers to drawing on and combining
multiple different sources for art creation, embracing
the resulting collisions and heterogeneity. This paper
discusses the use of maximalism in game design
and particularly in data games, which are games that
are generated partly based on open data. Using Data
Adventures, a series of generators that create adventure
games from data sources such as Wikipedia and Open-
StreetMap, as a lens we explore several tradeoffs and
issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative
and functional content, and legal and ethical issues
resulting from this type of generativity. This paper
sketches out the design space of maximalist data-driven
games, a design space that is mostly unexplored.peer-reviewe",data driven architecture,733
'american chemical society (acs)',filtered,core,10.1021/acsnano.9b02371,2019-06-18 00:00:00,core,http://arxiv.org/abs/1811.12436,,"A key challenge in metasurface design is the development of algorithms that
can effectively and efficiently produce high performance devices. Design
methods based on iterative optimization can push the performance limits of
metasurfaces, but they require extensive computational resources that limit
their implementation to small numbers of microscale devices. We show that
generative neural networks can train from images of periodic,
topology-optimized metagratings to produce high-efficiency, topologically
complex devices operating over a broad range of deflection angles and
wavelengths. Further iterative optimization of these designs yields devices
with enhanced robustness and efficiencies, and these devices can be utilized as
additional training data for network refinement. In this manner, generative
networks can be trained, with a onetime computation cost, and used as a design
tool to facilitate the production of near-optimal, topologically-complex device
designs. We envision that such data-driven design methodologies can apply to
other physical sciences domains that require the design of functional elements
operating across a wide parameter space.Comment: 15 pages, 5 figure",data driven architecture,734
'asme international',filtered,core,10.1115/1.4037477,2017-10-02 00:00:00,core,https://core.ac.uk/download/211520347.pdf,,"With the advances in three-dimensional (3D) scanning and sensing technologies, massive human-related data are now available and create many applications in data-driven design. Similarity identification is one of basic problems in data-driven design and can facilitate many engineering applications and product paradigm such as quality control and mass customization. Therefore, reusing information can create unprecedented opportunities in advancing the theory, method, and practice of product design. To enable information reuse, different models have to be aligned so that their similarity can be identified. This alignment is commonly known as the global registration that finds an optimal rigid transformation to align two 3D shapes (scene and model) without any assumptions on their initial positions. The Super 4-Points Congruent Sets (S4PCS) is a popular algorithm used for this shape registration. While S4PCS performs the registration using a set of 4 coplanar points, we find that incorporating the volumetric information of the models can improve the robustness and the efficiency of the algorithm, which are particularly important for mass customization. In this paper, we propose a novel algorithm, Volumetric 4PCS (V4PCS), to extend the 4 coplanar points to non-coplanar ones for global registration, and theoretically demonstrate the computational complexity is significantly reduced. Experimental tests are conducted on a number of models such as tooth aligner and hearing aid to compare with S4PCS. The experimental results show that the proposed V4PCS can achieve a maximum of 20 times speedup and can successfully compute the valid transformation with very limited number of sample points. An application of the proposed method in mass customization is also investigated",data driven architecture,735
'walter de gruyter gmbh',filtered,core,10.1515/nanoph-2019-0117,2019-07-01 00:00:00,core,https://core.ac.uk/download/288846116.pdf,"[{'title': 'Nanophotonics', 'identifiers': ['2192-8606', 'issn:2192-8606']}]","Data-driven design approaches based on deep learning have been introduced in nanophotonics to reduce time-consuming iterative simulations, which have been a major challenge. Here, we report the first use of conditional deep convolutional generative adversarial networks to design nanophotonic antennae that are not constrained to predefined shapes. For given input reflection spectra, the network generates desirable designs in the form of images; this allows suggestions of new structures that cannot be represented by structural parameters. Simulation results obtained from the generated designs agree well with the input reflection spectrum. This method opens new avenues toward the development of nanophotonics by providing a fast and convenient approach to the design of complex nanophotonic structures that have desired optical properties.11Ysciescopu",data driven architecture,736
published by elsevier b.v.,filtered,core,https://core.ac.uk/download/pdf/81999742.pdf,2012-12-31 00:00:00,core,10.1016/j.procs.2012.04.126,,"AbstractThe new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider's inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility",data driven architecture,737
'elsevier bv',filtered,core,https://core.ac.uk/download/146492122.pdf,2013-01-01 00:00:00,core,10.1016/j.procs.2013.05.357,,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",data driven architecture,738
thomas jefferson national accelerator facility (u.s.),filtered,core,,2013-12-01 00:00:00,core,10.1016/j.nima.2013.06.077,,"For the 12 GeV upgrade, the CLAS12 experiment has designed a Silicon Vertex Tracker (SVT) using single sided microstrip sensors fabricated by Hamamatsu. The sensors have graded angle design to minimize dead areas and a readout pitch of 156{micro}m, with intermediate strip. Double sided SVT module hosts three daisy-chained sensors on each side with a full strip length of 33 cm. There are 512 channels per module read out by four Fermilab Silicon Strip Readout (FSSR2) chips featuring data driven architecture, mounted on a rigid-flex hybrid. Modules are assembled on the barrel using unique cantilevered geometry to minimize the amount of material in the tracking volume. Design and performance of the SVT modules are presented, focusing on results of electrical measurements",data driven architecture,739
'association for computing machinery (acm)',filtered,core,,2011-01-01 00:00:00,core,10.1145/2069618.2069651,,"OCAD University's strategic plan Living in the Age of Imagination places a priority on focusing the lenses of art, design and media on contemporary issues and practices outside of the traditional boundaries of art and design. This has resulted in a myriad of innovative curriculum and research initiatives of specific relevance to HCI. For example in concert with led partner York University, the University of Toronto and a set of industrial partners OCAD University has created the Centre for Innovation in Information Visualization and Data Driven Design (CIV/DDD), a research hub for the development of next-generation data visualization techniques and their underlying information processing and communication technologies (ICT). This centre is the focus of this talk. The idea was that by bringing an unprecedented number of interdisciplinary artists, designers, media makers, humanist analysts and social scientists into the research partnership we would develop new paradigms of data enquiry, user-centered visualization models, and information processing and display technologies",data driven architecture,740
ieee transactions on industrial electronics,filtered,core,,2014-01-01 00:00:00,core,10.1109/tie.2014.2301757,"[{'title': None, 'identifiers': ['issn:0278-0046', '0278-0046', '1557-9948', 'issn:1557-9948']}]","In this paper, regarding the observer form of the well-known Youla parameterization, the controller design and optimization are exhibited with an integrated residual access. To better reveal this philosophy, the feedback control loop is interpreted on the basis of the observer-based residual generator. The next main attention is drawn to the generation of residuals, the design of a deadbeat controller for system stabilization both in the data-driven environment, and later the optimal adaptive realization of a dynamic system that translates residuals into compensatory control inputs to meet certain performance specifications. Towards these goals, numerical algorithms are summarized, and for the issues of controller optimization, the reinforcement learning algorithm is introduced using only measured input-output and residual signals. In addition, the effectiveness of developed schemes for industrial applications is also illustrated by experimental studies on a laboratory continuous stirred tank heater (CSTH) process.http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000337123000063&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=8e1609b174ce4e31116a60747a720701Automation &amp; Control SystemsEngineering, Electrical &amp; ElectronicInstruments &amp; InstrumentationSCI(E)EI6ARTICLEyong.zhang@pku.edu.cn; yy@mech.pku.edu.cn; steven.ding@uni-due.de;   linlin.li@uni-due.de116409-64176",data driven architecture,741
'hindawi limited',filtered,core,https://core.ac.uk/download/225887125.pdf,2012-01-01 00:00:00,core,10.1155/2012/832836,,"Published version of an article from the journal: Mathematical Problems in Engineering. Also available from the publisher:http://dx.doi.org/10.1155/2012/832836This paper presents an approach for data-driven design of fault diagnosis system. The proposed fault diagnosis scheme consists of an adaptive residual generator and a bank of isolation observers, whose parameters are directly identified from the process data without identification of complete process model. To deal with normal variations in the process, the parameters of residual generator are online updated by standard adaptive technique to achieve reliable fault detection performance. After a fault is successfully detected, the isolation scheme will be activated, in which each isolation observer serves as an indicator corresponding to occurrence of a particular type of fault in the process. The thresholds can be determined analytically or through estimating the probability density function of related variables. To illustrate the performance of proposed fault diagnosis approach, a laboratory-scale three-tank system is finally utilized. It shows that the proposed data-driven scheme is efficient to deal with applications, whose analytical process models are unavailable. Especially, for the large-scale plants, whose physical models are generally difficult to be established, the proposed approach may offer an effective alternative solution for process monitoring",data driven architecture,742
10.1016/s0168-9002(99)00453-2,filtered,core,"A 16-channel Digital TDC Chip with internal buffering and selective
  readout for the DIRC Cherenkov counter of the BABAR experiment",1999-02-10 00:00:00,core,http://arxiv.org/abs/hep-ex/9902015,,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter
of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is
0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven
architecture integrates channel buffering and selective readout of data falling
within a programmable time window. The time measuring scale is constantly
locked to the phase of the (external) clock. The linearity is better than 80 ps
rms. The dead time loss is less than 0.1% for incoherent random input at a rate
of 100 khz on each channel. At such a rate the power dissipation is less than
100 mw. The die size is 36 mm2.Comment: Latex, 18 pages, 13 figures (14 .eps files), submitted to NIM ",data driven architecture,743
10.5075/epfl-thesis-3545,filtered,core,A multitasking and data-driven architecture for multi-agents simulations,2006-04-24 00:00:00,core,https://core.ac.uk/download/147916631.pdf,,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach",data driven architecture,744
10.7494/dmms.2007.1.2.137,filtered,core,A Distributed Decision-Support System for Virtual Prototyping,2007-10-11 00:00:00,core,https://core.ac.uk/download/229296196.pdf,,"Virtual Prototyping (VP) is a data-driven design process that promotes both knowledge reuse and innovation. High-profile applications in the automotive and aerospace industries have demonstrated its potential to significantly reduce prototype cycles, time to market, and total product cost. This paper addresses VP as a specialized application of Decision-Support Systems, and discusses common requirements for engineering design tools, as well as requirements specific to the design of electronic products, such as mobile phones. Motorola Labs' test bed for VP is introduced in terms of its open, agent-based architecture utilizing Java CORBA. One of the key principles of the VP System is the reuse of expert knowledge across multiple engineering domains. This is highlighted via several use cases, showing that the system can function not only as an Intranet-accessible repository of model services but also as an integral part of decision-making within the native CAD environment",data driven architecture,745
,filtered,core,Scholar Commons,2020-06-27 00:00:00,core,electric hydrofoil and analysis software,,"Electric hydrofoil surfboards are clean alternatives to jet skis. Electric hydrofoils generate no noise, wake or emissions in comparison. Electric hydrofoil (e-Foil) boards are fun to ride and have low environmental impact. Due to the electric power source they are not dependent on weather conditions how sailing, wind surfing and kite surfing are. Commercial implementations of electric hydrofoils are expensive. The goal of this project is to construct a electric hydrofoil at a reasonable price point. Our approach involves building analysis software to provide data-driven design insights and to build o of the work of the online DIY electric hydrofoil community (efoil.builders)",data driven architecture,746
,filtered,core,Scholarly Commons @ Baystate Health,2019-09-01 00:00:00,core,education management platform enables delivery and comparison of multiple evaluation types,,"OBJECTIVE:
The purpose of this study was to determine whether an automated platform for evaluation selection and delivery would increase participation from surgical teaching faculty in submitting resident operative performance evaluations.  DESIGN:
We built a HIPAA-compliant, web-based platform to track resident operative assignments and to link embedded evaluation instruments to procedure type. The platform matched appropriate evaluations to surgeons\u27 scheduled procedures, and delivered multiple evaluation types, including Ottawa Surgical Competency Operating Room Evaluation (O-Score) evaluations and Operative Performance Rating System (OPRS) evaluations. Prompts to complete evaluations were made through a system of automatic electronic notifications. We compared the time spent in the platform to achieve evaluation completion. As a metric for the platform\u27s effect on faculty participation, we considered a task that would typically be infeasible without workflow optimization: the evaluator could choose to complete multiple, complementary evaluations for the same resident in the same case. For those cases with multiple evaluations, correlation was analyzed by Spearman rank test. Evaluation data were compared between PGY levels using repeated measures ANOVA.  SETTING:
The study took place at 4 general surgery residency programs: The University of Massachusetts Medical School-Baystate, the University of Connecticut School or Medicine, the University of Iowa Carver College of Medicine, and Maimonides Medical Center.  PARTICIPANTS:
From March 2017 to February 2019, the study included 70 surgical teaching faculty and 101 general surgery residents.  RESULTS:
Faculty completed 1230 O-Score evaluations and 106 OPRS evaluations. Evaluations were completed quickly, with a median time of 36 ± 18 seconds for O-Score evaluations, and 53 ± 51 seconds for OPRS evaluations. 89% of O-Score and 55% of OPRS evaluations were completed without optional comments within one minute, and 99% of O-Score and 82% of OPRS evaluations were completed within 2 minutes. For cases eligible for both evaluation types, attendings completed both evaluations on 74 of 221 (33%) of these cases. These paired evaluations strongly correlated on resident performance (Spearman coefficient = 0.84, p \u3c 0.00001). Both evaluation types stratified operative skill level by program year (p \u3c 0.00001).  CONCLUSIONS:
Evaluation initiatives can be hampered by the challenge of making multiple surgical evaluation instruments available when needed for appropriate clinical situations, including specific case types. As a test of the optimized evaluation workflow, and to lay the groundwork for future data-driven design of evaluations, we tested the impact of simultaneously delivering 2 evaluation instruments via a secure web-based education platform. We measured the evaluation completion rates of faculty surgeon evaluators when rating resident operative performance, and how effectively the results of evaluation could be analyzed and compared, taking advantage of a highly integrated management of the evaluative information",data driven architecture,747
,filtered,core,UR Scholarship Repository,2020-05-01 00:00:00,core,the clas12 silicon vertex tracker,,"For the 12 GeV upgrade of Jefferson Laboratory, a Silicon Vertex Tracker (SVT) has been designed for theCLAS12 spectrometer using single-sided microstrip sensors fabricated by Hamamatsu Photonics. The sensors have a graded angle design to minimize dead areas and a readout pitch of156 μm, with intermediate strips. Each double-sided SVT module hosts three daisy-chained sensors on each side with a full strip length of33 cm. There are 512 channels per module, read out by four Fermilab Silicon Strip Readout (FSSR2) chips, featuring data-driven architecture, mounted on a rigid–flex hybrid board. The modules are assembled in a barrel configuration using a unique cantilevered geometry to minimize the amount of material in the tracking volume. This paper is focused on the design, qualification of the performance, and experience in operating and commissioning the tracker during the first year of the data taking",data driven architecture,748
,filtered,core,"БГУИР, РБ",2021-01-01 00:00:00,core,data-driven approach to web design,,"Data-Driven Design (DDD) – это дизайн на основе данных, полученных в результате исследований. С приходом DDD усложнился анализ потребностей, интерфейсы стали персонализированными, дизайн стал ориентированным на бизнес-показатели, а профессия веб-дизайнера распалась на составляющие. Основное преимущество DDD-подхода состоит в том, что все дизайн-решения обоснованы, исключается элемент вкусовщины. Но DDD в чистом виде часто ведет к перегибам – «машинному» подходу при разработке продукта для людей. Наиболее успешные сервисы придерживаются несколько иного подхода – Data-Informed Design – дизайн с учетом данных, но без слепого подчинения им. Data-Driven Design (DDD) is the design based on research data. With the advent of DDD, needs analysis became more complex, interfaces became personalized, design began to be focused on business performance, and the web designer profession resolved into specializations. The main advantage of the DDD approach is that all design decisions are justified, the element of taste is excluded. But DDD in its purest form often leads to kinks – ""machine"" approach to product development. The most successful services take a bit different approach – Data-Informed Design – design with data in mind, but without blind obedience to it",data driven architecture,749
,filtered,core,,2020-03-29 00:00:00,core,a general large neighborhood search framework for solving integer programs,https://core.ac.uk/download/323312234.pdf,"This paper studies how to design abstractions of large-scale combinatorial optimization problems that can leverage existing state-of-the-art solvers in general purpose ways, and that are amenable to data-driven design. The goal is to arrive at new approaches that can reliably outperform existing solvers in wall-clock time. We focus on solving integer programs, and ground our approach in the large neighborhood search (LNS) paradigm, which iteratively chooses a subset of variables to optimize while leaving the remainder fixed. The appeal of LNS is that it can easily use any existing solver as a subroutine, and thus can inherit the benefits of carefully engineered heuristic approaches and their software implementations. We also show that one can learn a good neighborhood selector from training data. Through an extensive empirical validation, we demonstrate that our LNS framework can significantly outperform, in wall-clock time, compared to state-of-the-art commercial solvers such as Gurobi",data driven architecture,750
,filtered,core,"eScholarship, University of California",2021-01-01 00:00:00,core,data-driven online optimization and control with performance guarantees,,"This thesis considers the analysis and design of algorithms for the management and control of uncertain intelligent systems which are observable through (limited) online-accessible data. Examples include online equity trading systems under extreme price fluctuations, robotic systems moving in unknown environments, and transportation systems subject to uncertain drivers’ actions and other (accident) events.To ensure safe, reliable, and resilient system behaviors, this thesis studies various theoretical problem scenarios, which focus on reducing uncertainty with performance guarantees via the assimilation of streaming data, the data-driven design of control, and online learning of system models, resilient operations in uncertain environments, and anomaly detection.These formulations are largely rooted in two mechanisms: online optimization and distributionally robust optimization, where the first enables online-tractable formulations of the problem, and the latter accounts for systemic uncertainty with high confidence. Both approaches  are applicable beyond the particular systems of study, to virtually any type of dynamic system where sensitive data is progressively available and may be exploited to the advantage of management and control. This work is unique in that it brings together current tools in optimization, control of dynamical systems, data-based modeling and probability theory, significantly advancing the state of the art",data driven architecture,751
,filtered,core,DigitalCommons@University of Nebraska - Lincoln,2019-05-29 00:00:00,core,machine learning in architecture: connectionist approach to architectural design,https://core.ac.uk/download/220154676.pdf,"Previous applications to design processes intend to enhance a building’s schematic design using quantitative data. Therefore, most applications to the early design phases are passed by as simple overarching ideas informed by the designer and users’ knowledge. Although this is a preferred method of choice making, the knowledge used to inform conceptual and schematic design process can be limited. With the increase of computation in all major industries, a new increase in data to describe forms of infrastructure is required. These forms being objects to analyze their performance and potential, and active forms that can describe the disposition of urban space. Previous research into data driven design has worked its way into standardization and performance goals. However, the connection between active and object forms as a network of standards has yet to be introduced as a method of advising design. Meaning design has focused on creating a single object that seems to benefit the ecology. No attempt at connecting urban active data to object data has been made to benefit both forms equally, but only to preserve the status quo. The introduction of Machine learning algorithms has the capability to connect these complex forms and inform new designs. The application of machine learning algorithms advises the early phases of architectural design process by reviewing a manifold of data, privileging complex analogical connections, and simulating the designers informed symbolic choices.
Supervisor Professor Mark A. Hoistad, AI",data driven architecture,752
,filtered,core,,2020-04-28 00:00:00,core,data analysis through multivariate statistical techniques: an industrial application,https://core.ac.uk/download/322856522.pdf,"This Thesis describes an industrial procedure tailored to the company Unox S.p.A. for data analysis through multivariate statistical methodologies. Process variables are analysed for process understanding, data-driven design (creation of intuitive user-machine interface for improved user experience), process monitoring (anomalies detection during cooking process to ensure final product quality) and predictive maintenance (data-based equipment failure prediction for improved after-sale service)",data driven architecture,753
,filtered,core,SMID - Society of Media Researchers In Denmark,2020-12-11 00:00:00,core,netflix and the design of the audience: the homogenous constraints of data-driven personalization,https://core.ac.uk/download/386107667.pdf,"This paper explores how audiences engage with Netflix as an intermediary in their digital lives, and how Netflix, as it is designed, creates a highly constrained system for its users. The paper is based on a study of observed use and discussions with Netflix users. It explores the limitations that are designed into Netflix as a digital media platform, and how Netflix users engage with this system that obscures rather than clarifies the contents of the platform. The paper discusses examples of frustration, confusion, and misdirection that Netflix, as a heavily constrained system, cultivates. It argues that the thoughts, feelings, and desires of audiences are not reflected in the data-driven design of digital media platforms like Netflix. Instead, data are used by Netflix to design a personalized environment that acts as a set of blinders which constrain the agency of the audience through an interface designed to dazzle and disorient Netflix users",data driven architecture,754
,filtered,core,,2021-05-27 00:00:00,core,"biked: a dataset and machine learning benchmarks for data-driven bicycle
  design",http://arxiv.org/abs/2103.05844,"In this paper, we present ""BIKED,"" a dataset comprised of 4500 individually
designed bicycle models sourced from hundreds of designers. We expect BIKED to
enable a variety of data-driven design applications for bicycles and support
the development of data-driven design methods. The dataset is comprised of a
variety of design information including assembly images, component images,
numerical design parameters, and class labels. In this paper, we first discuss
the processing of the dataset, then highlight some prominent research questions
that BIKED can help address. Of these questions, we further explore the
following in detail: 1) Are there prominent gaps in the current bicycle market
and design space? We explore the design space using unsupervised dimensionality
reduction methods. 2) How does one identify the class of a bicycle and what
factors play a key role in defining it? We address the bicycle classification
task by training a multitude of classifiers using different forms of design
data and identifying parameters of particular significance through
permutation-based interpretability analysis. 3) How does one synthesize new
bicycles using different representation methods? We consider numerous machine
learning methods to generate new bicycle models as well as interpolate between
and extrapolate from existing models using Variational Autoencoders. The
dataset and code are available at http://decode.mit.edu/projects/biked/",data driven architecture,755
,filtered,core,,2017-12-01 00:00:00,core,https://core.ac.uk/download/158324118.pdf,,"Millions of mobile apps are used by billions of users every day. Although the design of these apps play an important role in their adoption, the design process still remains complex and time intensive. At the same time, existing apps embody multiple solutions to numerous design problems faced by app developers. How do we make this design knowledge embedded in existing apps accessible to designers? And how can it help simplify the app design process?

This dissertation introduces interaction mining, a technique to capture the designs of mobile apps in a way that supports data-driven design applications. It presents systems that implement interaction mining for Android apps without requiring any access to their source code making it possible to design mine apps at an unprecedented scale. It presents Rico, the largest publicly available mobile app design repository to date. It discusses how such repositories created using interaction mining can be used to train models that enable applications such as keyword and example-based search interactions for mobile screens and user flows. It also presents zero-integration performance testing (ZIPT), a novel technique for testing app designs. It demonstrates how ZIPT can be used to help designers understand which examples to draw from in the early stages of the app design process and perform comparative testing at scale with low cost and effort in the later stages of the process",data driven architecture,756
,filtered,core,,2018-04-09 00:00:00,core,http://arxiv.org/abs/1804.03298,,"A frequency based data-driven control design considering mixed H2/H-infinity
control objectives is developed for multiple input-single output systems. The
main advantage of the data-driven control over the model-based control is its
ability to use the frequency response measurements of the controlled plant
directly without the need to identify a model for the plant. In the proposed
methodology, multiple sets of measurements can be considered in the design
process to accommodate variations in the system dynamics. The controller is
obtained by translating the mixed H2/H-infinity control objectives into a
convex optimization problem. The H-infinity norm is used to shape closed loop
transfer functions and guarantee closed loop stability, while the H2 norm is
used to constrain and/or minimize the variance of signals in the time domain.
  The proposed data-driven design methodology is used to design a track
following controller for a dual-stage HDD. The sensitivity decoupling
structure[16] is considered as the controller structure. The compensators
inside this controller structure are designed and compared by decoupling the
system into two single input-single-output systems as well as solving for a
single input-double output controller",data driven architecture,757
,filtered,core,,2018-05-15 00:00:00,core,http://arxiv.org/abs/1803.05035,,"The expansion of programmatically-accessible materials data has cultivated
opportunities for data-driven approaches. Highly-automated frameworks like
AFLOW not only manage the generation, storage, and dissemination of materials
data, but also leverage the information for thermodynamic formability modeling,
such as the prediction of phase diagrams and properties of disordered
materials. In combination with standardized parameter sets, the wealth of data
is ideal for training machine learning algorithms, which have already been
employed for property prediction, descriptor development, design rule
discovery, and the identification of candidate functional materials. These
methods promise to revolutionize the path to synthesis and, ultimately,
transform the practice of traditional materials discovery to one of rational
and autonomous materials design.Comment: 8 pages, 2 figures, submitted to ""society magazine",data driven architecture,758
,filtered,core,,2017-02-24 00:00:00,core,http://arxiv.org/abs/1702.07739,,"The realistic modeling of STT-MRAM for the simulations of hybrid
CMOS/Spintronics devices in comprehensive simulation environments require a
full description of stochastic switching processes in state of the art
STT-MRAM. Here, we derive an analytical formulation that takes into account the
spin-torque asymmetry of the spin polarization function of magnetic tunnel
junctions studying. We studied its validity range by comparing the analytical
formulas with results achieved numerically within a full micromagnetic
framework. We also find that a reasonable fit of the probability density
function (PDF) of the switching time is given by a Pearson Type IV PDF. The
main results of this work underlines the need of data-driven design of STT-MRAM
that uses a full micromagnetic simulation framework for the statistical
proprieties PDF of switching processes",data driven architecture,759
,filtered,core,,2018-02-01 00:00:00,core,http://arxiv.org/abs/1802.00484,,"We present a widely-used operations management model used in supply and
distribution planning, that is typically embedded in a periodic business
process that necessitates model modification and reuse. We consider three
alternative spreadsheet implementations, a data-driven design, a canonical
(textbook) design, and a novel (table-driven) technical design. We evaluate
each regarding suitability for accuracy, modification, analysis, and transfer.
We consider the degree of training and technical sophistication required to
utilize each design. The data-driven design provides insight into poor
spreadsheet practices by na\""ive modelers. The technical design can be modified
for new data and new structural elements without manual writing or editing of
cell formulas, thus speeding modification and reducing risk of error. The
technical design has potential for use with other classes of models. We
identify opportunities for future research.Comment: 12 Pages, 10 Colour Figure",data driven architecture,760
,filtered,core,,2018-05-29 00:00:00,core,http://arxiv.org/abs/1805.12475,,"Maximalism in art refers to drawing on and combining multiple different
sources for art creation, embracing the resulting collisions and heterogeneity.
This paper discusses the use of maximalism in game design and particularly in
data games, which are games that are generated partly based on open data. Using
Data Adventures, a series of generators that create adventure games from data
sources such as Wikipedia and OpenStreetMap, as a lens we explore several
tradeoffs and issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative and functional content,
and legal and ethical issues resulting from this type of generativity. This
paper sketches out the design space of maximalist data-driven games, a design
space that is mostly unexplored.Comment: 9 pages, 2 Figures, Accepted in ICCC 201",data driven architecture,761
,filtered,core,,2018-01-01 00:00:00,core,https://core.ac.uk/download/222586035.pdf,,"Introduction



Currently, the learning science community is exploring the use of data-driven design to improve K12 educational systems. These “continuous-improvement systems” aim to align strategic goals, outcome metrics and human-computer system processes to support improved learning outcomes. However, the learning science community has only begun to apply systemic design to practical implementation of these systems.



In this paper, we present several examples of data-driven design in K12 educational systems in order to identify aspects that can beneﬁt from systemic design. Through these case studies, we focus on three concepts: 1) systemic designers can ensure that the system is capable of measuring successful outcomes; 2) systemic designers can ensure that system optimization will improve intended outcomes while minimizing unintended consequences; and 3) systemic designers can portray what a future with these continuous improvement systems will be like to the educational community, before any resources are committed to building the technology.



Example #1: Ensure that the system is capable of measuring successful outcomes



Data can be used to inform system stakeholders about the success of designed systems; that is, how well outcome measures align with system intentions. For instance, after providing an instructional activity (lecture, small group, video, etc) in class, a teacher might assign their students an “exit ticket” quiz to assess whether the instructional activity was successful. These quizzes support data-driven decisions about how to spend time and effort in the classroom. Variations in student performance give teachers an understanding of the students who need greater attention and the learning objectives that need greater attention. Further, digital data from exit tickets or other formative assessments can be aggregated across teachers to provide school administrators with continuous insight into the areas of need, such as students or teachers who need additional help or learning objectives that are posing special challenges. Providers of digital instruction can then aggregate usage and performance across many schools in order to identify successful and unsuccessful usage patterns. Data-driven continuous improvement can occur at multiple levels (i.e., teacher, school & software provider) when systems are designed to generate valid outcome metrics of success (goal achievement).



Example #2: Ensure that system optimization will improve intended outcomes while minimizing unintended consequence



Success metrics can be used by human teams and AI systems to drive continuous improvement. However, the optimization of metrics can produce unintended consequences when chosen metrics are not fully aligned to intended outcomes and when feedback loops about metric suitability are impoverished. In this case study, an online educational game is designed with the goal of motivating students to practice math problems. After being deployed online, the game attracts several thousand students a day; these players are randomly assigned to different game design variations to observe how



the effects of different designs on key outcome metrics (e.g., duration of voluntary play). To investigate the role of AI in system design optimization, we implemented a UCB multi-armed bandit (a reinforcement learning AL/ML algorithm) to automatically test variations in the existing game parameter space (e.g., time limits, etc). The algorithm is designed to optimally balance the exploration of potential game designs with exploitation of the most successful designs; sometimes it will randomly search the game design space for conﬁgurations that maximize metrics (duration of voluntary play time) and sometimes it will deploy the most successful variations. While the algorithm worked as intended, the system “spun out of control” and primarily deployed malformed game designs that were maximizing the outcome metric but were misaligned with the original educational intent: the game variations were likely played for long periods of time because they were absurdly easy. This shows the pitfalls of having AI systems engage in automatic optimization without humans in the loop as a governing feedback system. Systemic designers need to design feedback systems to monitor system AI to ensure that outputs are meaningfully aligned to system intentions.



Example #3: Portray what the future will be like



Artiﬁcial intelligence has the potential to facilitate the work of teachers by reducing the effort required to use data to inform personalized instruction. However, AI can be intimidating or off-putting to teachers who do not understand its operation or intentions. In this case study, we deployed a teacher-facing recommendation system that uses reinforcement learning to continuously improve recommendation usefulness to teachers. To design a reinforcement learning AI system, there must be data representations of the system state, the space of possible actions and a reward signal tied to a success metric. In our case, the system state is student digital performance on learning activities, the action possibilities are the different digital items that teachers can next assign to a student and the reward signal occurs when teachers act upon a recommendation (i.e., when they assign those digital activities recommended by the system).



This system embodies two key elements that diverge from most existing work in “adaptive learning” or “intelligent tutoring systems.” First, the system emphasizes human-technology teamwork, in contrast to human replacement, so that teachers are empowered by the assistance of the AI. Secondly, the artiﬁcial intelligence is deliberately constructed as an aggregation of human intelligence: the system learns from the activity-assignment decisions that are made by thousands of other human teachers and aggregates them into artiﬁcially intelligent recommendations. To promote adoption of this system, a key role for systemic design is making the intended future vision accessible and attractive to teachers and other stakeholders. Systemic designers can help to engage humans to participate in the decision making by presenting a glimpse of what a data-driven future might be like in the classroom.



Conclusion



Across these case studies, we show how systemic design can aid diverse participants in the implementation of data-driven design and optimization. Systemic design insight can contribute to the negotiation of meaningful and robust metrics of success, to the construction of human-in-the-loop governance of AI systems and to the representation of potential futures. We expect designers to play a crucial role in taming the complexity of practical AI-human systems and aligning system outcomes to sustainable, humanistic values",data driven architecture,762
,filtered,core,,2019-10-11 00:00:00,core,http://arxiv.org/abs/1910.06115,,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality",data driven architecture,763
,filtered,core,,2019-04-12 00:00:00,core,https://core.ac.uk/download/186332750.pdf,,This paper explores the developing co-creative relationships that arise through integrating digital making and data-driven processes as inspiration within collaborative distributed networks of design and making. It draws upon a year-long case study of landscape sound digital pattern design with a group of textile practitioners from across Scotland. The aim is to understand how these collective ‘hybrid ways of making’ between digital data-driven design and analogue maker impacts the overall democratisation of textile design and manufacturing and influences the makers’ practice,data driven architecture,764
,filtered,core,,2019-11-22 00:00:00,core,http://arxiv.org/abs/1911.10184,,"This paper studies the data-driven design of variable speed limits for
highways subject to uncertainty, including unknown driver actions as well as
vehicle arrivals and departures. With accessibility to sample measurements of
the uncertain variables, we aim to find the set of speed limits that prevents
traffic congestion and an optimum vehicle throughput with high probability.
This results into the formulation of a stochastic optimization problem (P),
which is intractable due to the unknown distribution of the uncertainty
variables. By developing a distributionally robust optimization framework, we
present an equivalent and yet tractable reformulation of (P). Further, we
propose an efficient algorithm that provides suboptimal data-driven solutions
and guarantees congestion-free conditions with high probability. We employ the
resulting control method on a traffic simulator to illustrate the effectiveness
of this approach.Comment: Submitted to TAC, a prelimineary version appeared in arxiv:1810.11385
  or DOI: 10.23919/ECC.2019.879602",data driven architecture,765
,filtered,core,,2017-02-09 00:00:00,core,https://core.ac.uk/download/76948417.pdf,,"A shared visual workspace and video in addition to voice are two functionalities or technologies which this thesis focuses on. What is clarified in this work is how these influence remote collaboration and conversational grounding in particular — where grounding refers to the pro-active process of seeking, creating and maintaining the shared meanings needed for conversational partners to communicate effectively. 



Additionally, this thesis clarifies how to support non-collocated synchronous mediated-collaboration around intelligence analytic tasks — away from traditional tasks that involve the identification or manipulation of physical objects which previous studies appear to favour.



This research is guided by these three primary research questions:



—RQ1) How can we expose aspects of conversational grounding in mediated communication involving different combinations of a video (showing a remote participant’s head and shoulder, and hands and work-area) and a fully shared visual workspace in addition to voice?



—RQ2) In relation to the negotiated process of grounding, how can we explain what is happening when parties are collaborating on an intelligence task using a fully shared visual workspace?



—RQ3) How can we design better fully shared visual workspace systems to support remote collaborative intelligence analysis tasks? 



Study1 — reported in Chapter 5, is an exploratory research which also serves as a groundwork for Study2. The findings there led to the formulation of more focused hypotheses later investigated in Study2. Further, the most significant contribution of the Study1 was the coding schema constructed for analysing the negotiation of common ground.



Chapter 6, 7, 8 make up Study2. A human-participant experiment was conducted using a 2 x 2 factorial between-subjects design with 2-person teams and four media manipulations namely: video, no video, shared visual workspace and no shared visual workspace. Conversational grounding effort is operationalized as the number of repair-episodes per min (that is repair rate). Results here indicate that teams using shared visual workspace have a lower repair rate than those teams with no access to shared visual workspace. This result is statistically significant.



Although teams using video equally had a lower repair rate than those teams not using video, this result was not statistically significant. This is consistent with prior research which found that a video showing a person’s face and shoulders is not terribly important in collaborative context. 



Results of another investigation demonstrate that regardless of the media condition, teams generally have a lower repair rate over time as the task progressed — this result was statistically significantly positive.



Additionally, assessments of a questionnaire item measuring improvements of mutual agreements and shared understanding over time, showed a statistically significantly difference between the shared visual workspace group and the no shared visual workspace group, as was the participant’s rating of the effectiveness of the medium for information sharing.



Results of a qualitative thematic analysis in Chapter 7 helps explain these statistical results and more. A conceptual process model of conversational grounding in shared visual workspace-mediated interaction is presented in Chapter 8.



The model also summarises the research findings. The discourse there offer useful implications and guidelines for moving beyond current theories and models of the negotiation of common ground. Equally, practical design recommendations for the design of shared visual workspaces are also discussed there.



Chapter 9, 10 reviews the research questions and considers how the research that has been presented addresses them, followed by a discussion of the contributions of the thesis, future work and conclusion.



Overall, this thesis delivers the following contributions:



—1) It advances existing knowledge silos and studies on media effects on conversational grounding — one of the ways it achieves that is by delivering a conceptual model framework for understanding conversational grounding processes in real-time remote collaborative intelligence analysis.



—2) It delivers a new coding schema for the analysis of the negotiation of conversational grounding in remote work. 



—3) It offers four data-driven design recommendations for good practical design of shared visual workspace groupware that better support more natural communicative nuances",data driven architecture,766
,filtered,core,,2019-03-21 00:00:00,core,http://arxiv.org/abs/1903.08876,,"We propose a data-driven design method of perfect-reconstruction filterbank
(PRFB) for sound-source enhancement (SSE) based on deep neural network (DNN).
DNNs have been used to estimate a time-frequency (T-F) mask in the short-time
Fourier transform (STFT) domain. Their training is more stable when a simple
cost function as mean-squared error (MSE) is utilized comparing to some
advanced cost such as objective sound quality assessments. However, such a
simple cost function inherits strong assumptions on the statistics of the
target and/or noise which is often not satisfied, and the mismatch of
assumption results in degraded performance. In this paper, we propose to design
the frequency scale of PRFB from training data so that the assumption on MSE is
satisfied. For designing the frequency scale, the warped filterbank frame
(WFBF) is considered as PRFB. The frequency characteristic of learned WFBF was
in between STFT and the wavelet transform, and its effectiveness was confirmed
by comparison with a standard STFT-based DNN whose input feature is compressed
into the mel scale.Comment: 5 pages, to appear in IEEE ICASSP 2019 (Paper Code: AASP-P8.8,
  Session: Spatial Audio, Audio Enhancement and Bandwidth Extension",data driven architecture,767
,filtered,core,,2011-01-01 00:00:00,core,10.3182/20110828-6-it-1002.02761,,"In this paper, an algorithm for direct data-driven design of cascade control system

is proposed and analysed. The procedure is based on the Virtual Reference Feedback Tuning

(VRFT) approach but it allows to tune either the inner and the outer loops by means of a

single set of experimental data. The main differences between the standard VRFT and the

proposed approach are highlighted and analyzed. The design technique is finally applied on a

micro-positioning control problem for Electro-HydroStatic Actuators (EHSAs)",data driven architecture,768
,filtered,core,,2012-01-01 00:00:00,core,10.1145/2307836.2307840,,"Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios and use small and biased samples. To overcome these challenges, we introduce a novel framework for large-scale monitoring, analysis, modeling, and visualization of vehicular traffic using freely available online webcams. We follow a data-driven approach that examine six metropolitan regions' more than 800 locations and 25 million vehicular mobility records around the world. Initial analysis of traffic densities show 80% temporal correlation during various hours of a day. The modeling of empirical traffic densities against known theoretical models show less than 5% deviation for heavy-tailed distributions such as Weibull. We believe this framework and the dataset provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks. © 2012 ACM",data driven architecture,769
,filtered,core,,2011-01-01 00:00:00,core,10.1109/cdc.2011.6160771,,"Motivated by the increasing needs in the process industry for designing fault tolerant feedback control systems based on process data, data-driven design of feedback control systems with embedded residual generation is addressed. For this purpose, an extended internal model control (EIMC) structure aiming at accessing the residuals embedded in control loop is first proposed. Based on the identification of the so-called parity subspace and a well-established mapping between the parity vector and the solution of the Luenberger equations, a direct design scheme of EIMC from process data is developed. The achieved results are illustrated by an academic example. ? 2011 IEEE.EI",data driven architecture,770
,filtered,core,,2010-01-01 00:00:00,core,10.1109/geoinformatics.2010.5567735,,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",data driven architecture,771
,filtered,core,,2012-01-01 00:00:00,core,10.1109/infcomw.2012.6193503,"[{'title': None, 'identifiers': ['2159-4228', 'issn:2159-4228']}]","Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios, random connectivity, and use small and biased samples. In this paper, we perform a combined study to learn the structure and connectivity of urban streets and modeling and characterization of vehicular traffic densities on them. Our dataset is a collection of 154 thousand routes and 12 million vehicular mobility images from 730 online web cameras located in four different cities. First, our study shows that driving routes and visiting locations of cities demonstrate power law distribution, indicating a planned or recently designed road infrastructure. Second, we represent cities by network graphs in which nodes are camera locations and edges are urban streets that connect the nodes. Such representation exhibits small world properties with short path lengths and large clustering coefficient. Third, traffic densities show 80% temporal correlation during several hours of a day. Finally, modeling these densities against known theoretical distributions show less than 5% deviation for Log-logistic and Gamma distribution. We believe this work will provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks. © 2012 IEEE",data driven architecture,772
,filtered,core,,2011-01-01 00:00:00,core,10.1115/dscc2011-5934,,"The design of an active stability control system for twowheeled

vehicles is a fully open problem and it constitutes a

challenging task due to the complexity of two-wheeled vehicles

dynamics and the strong interaction between the vehicle and the

driver. This paper describes and compares two different methods,

a model-based and a data-driven approach, to tune a Multi-

Input-Multi-Output controller which allows to enhance the safety

while guaranteeing a good driving feeling. The two strategies are

tested on a multibody motorcycle simulator on challenging maneuvers

such as kick-back and strong braking while cornering at

high speed",data driven architecture,773
,filtered,core,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",2008-01-01 00:00:00,core,https://core.ac.uk/download/pdf/195383281.pdf,,"This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",data driven architecture,774
,filtered,core,Program Partitioning for a Control/Data Driven Computer,1993-01-01 00:00:00,core,https://core.ac.uk/download/81372427.pdf,,"The paper examines the problem of dataflow graph partitioning aiming to improve the efficiency of macro-dataflow computing on a hybrid control/data driven architecture. The partitioning consists of dataflow graph synchronization and scheduling of the synchronous graph. A new scheduling algorithm, called Global Arc Minimization (GAM), is introduced. The performance of the GAM algorithm is evaluated relative to some other known heuristic methods for static scheduling. When interprocessor communication delays are taken into account, the GAM algorithm achieves better performance on the simulated hybrid architecture",data driven architecture,775
bd566b88df8a3a045962f78ddb2d64d541845a39,filtered,semantic_scholar,IEEE Communications Magazine,2019-01-01,semantic_scholar,a hierarchical architecture for the future internet of vehicles,https://www.semanticscholar.org/paper/bd566b88df8a3a045962f78ddb2d64d541845a39,"Recent advances in wireless communication, sensing, computation and control technologies have paved the way for the development of a new era of Internet of Vehicles (IoV). Demanded by the requirements of information-centric and data-driven intelligent transportation systems (ITS), it is of great significance to explore new paradigms of IoV in supporting large-scale, real-time, and reliable information services. In this article, we propose a hierarchical system architecture, which aims at synthesizing the paradigms of software defined networking and fog computing in IoV and best exploiting their synergistic effects on information services. Specifically, a four-layer architecture is designed, comprising the application layer, the control layer, the virtualization layer, and the data layer, with objectives of enabling logically centralized control via the separation of the control plane and the data plane; facilitating adaptive resource allocation and QoS oriented services based on network functions virtualization and network slicing, and enhancing system scalability, responsiveness, and reliability by exploiting the networking, computation, communication, and storage capacities of fog-based services. On this basis, we further analyze newly arising challenges and discuss future research directions by presenting a cross-layer protocol stack. Finally, for the proof of concept, we implement the system prototype and give two case studies in real-world IoV environments. The results of field tests not only demonstrate the great potential of the new architecture, but also give insight into the development of future ITS.",data oriented architecture,776
450b1e34bc072589ed83f72f6f9b00af6d39b311,filtered,semantic_scholar,IEEE Softw.,1995-01-01,semantic_scholar,the 4+1 view model of architecture,https://www.semanticscholar.org/paper/450b1e34bc072589ed83f72f6f9b00af6d39b311,"The 4+1 View Model organizes a description of a software architecture using five concurrent views, each of which addresses a specific set of concerns. Architects capture their design decisions in four views and use the fifth view to illustrate and validate them. The logical view describes the design's object model when an object-oriented design method is used. To design an application that is very data driven, you can use an alternative approach to develop some other form of logical view, such as an entity-relationship diagram. The process view describes the design's concurrency and synchronization aspects. The physical view describes the mapping of the software onto the hardware and reflects its distributed aspect. The development view describes the software's static organization in its development environment. >",data oriented architecture,777
2b878ebba7d88eeadf9c4fd6f54df34b813a6d0b,filtered,semantic_scholar,IEEE Transactions on Automation Science and Engineering,2010-01-01,semantic_scholar,data-driven service composition in enterprise soa solutions: a petri net approach,https://www.semanticscholar.org/paper/2b878ebba7d88eeadf9c4fd6f54df34b813a6d0b,"Under Service Oriented Architecture (SOA), service composition is used to integrate service components together to meet new business needs. In this paper, we propose a novel data-driven method to provide service composition guidance to implement given requirements. Based on the relations between business domain data and service domain data, we generate additional data mediations according to three composition rules. With these data relations and composition rules, we propose a Petri-net based approach to the composition of services. In our approach, all the in/output messages of the service operations are modeled as colored places, and service operations themselves are modeled as transitions with input/output places. We first generate a Service Net (SN) that contains all operations in a given service portfolio, and then use Petri-net decomposition techniques to derive a subnet of SN, and this subnet meets the need of the business requirement. Our work can be seen as an effort to bridge the gap between business and service domains.",data oriented architecture,778
1eb7ae4f9700717ed5f1b9de2d85928125745d8b,filtered,semantic_scholar,TMI,2007-01-01,semantic_scholar,towards hybrid quality-oriented machine translation – on linguistics and probabilities in mt,https://www.semanticscholar.org/paper/1eb7ae4f9700717ed5f1b9de2d85928125745d8b,"We present a hybrid MT architecture, combining state-of-the-art linguistic processing with advanced stochastic techniques. Grounded in a theoretical reflection on the division of labor between rule-based and probabilistic elements in the MT task, we summarize per-component approaches to ranking, including empirical results when evaluated in isolation. Combining component-internal scores and a number of additional sources of (probabilistic) information, we explore discriminative re-ranking of n-best lists of candidate translations through an eclectic combination of knowledge sources, and provide evaluation results for various configurations. 1 Background—Motivation Machine Translation is back in fashion, with data-driven approaches and specifically Statistical MT (SMT) as the predominant paradigm— both in terms of scientific interest and evaluation results inMT competitions. But (fullyautomated) machine translation remains a hard— if not ultimately impossible—challenge. The task encompasses not only all strata of linguistic description—phonology to discourse—but in the general case requires potentially unlimited knowledge about the actual world and situated language use (Kay, 1980, 1997). Although the majority of commercialMT systems still have large sets of hand-crafted rules at their core (often using techniques first invented in the 1960s and 1970s),MT research in the once mainstream linguistic tradition has become the privilege of a small, faithful minority. Like a growing number of colleagues, we question the long-term value of purely statistical (or data-driven) approaches, both practically and scientifically. Large (parallel) training corpora remain scarce for most languages, and wordand phrase-level alignment continue to be active research topics. Assuming sufficient training material, statistical translation quality still leaves much to be desired; and probabilistic NLP experience in general suggests that one must expect ‘ceiling’ effects on system evolution. Statistical MT research has yet to find a satisfactory role for linguistic analysis; on its own, it does not further our understanding of language. Progress on combining rule-based and datadriven approaches toMT will depend on a sustained stream of state-of-the-art, MT-oriented linguistics research. The NorwegianLOGON initiative capitalizes on linguistic precision for high-quality translation and, accordingly, puts scalable, general-purpose linguistic resources—complemented with advanced stochastic components—at its core. Despite frequent cycles of overly high hopes and subsequent disillusionment,MT in our view is the type of application that may demand knowledge-heavy, ‘deep’ approaches toNLP for its ultimate, longterm success. Much like Riezler & Maxwell III (2006) and Llitjós & Vogel (2007)—being faithful minority members ourselves—we approach a hybrid MT architecture with a semantic transfer backbone as our vantage point. Plurality of approaches to grammatical description, reusability of component parts, and the interplay of linguistic and stochastic processes are among the strong points of theLOGON system. In the following, we provide a brief overview of theLOGON architecture ( §2) and a bit of theoretical reflection on the role of probability theory",data oriented architecture,779
55166c861a3ec9a09e8fc7e548c7b6749e11206f,filtered,semantic_scholar,2007 5th IEEE International Conference on Industrial Informatics,2007-01-01,semantic_scholar,an agent-oriented programming model for soa & web services,https://www.semanticscholar.org/paper/55166c861a3ec9a09e8fc7e548c7b6749e11206f,"More and more Service-Oriented Architecture (SOA) is recognized by the industries as the reference blueprint for building interoperable and flexible distributed Enterprise applications, based on open standards such as Web Services (WS). In the state-of-the-art, the programming models for engineering SOA systems proposed by leading industries are essentially component-based, typically based upon object-oriented abstractions and technologies. In this paper we argue that such a choice-which benefits indeed from the well-know advantages of component-based software engineering and from the maturity of the available technologies-does not provide, however, the suitable level of abstraction for modelling as first-class concepts some fundamental aspects in SOA, such as autonomy, control-uncoupling, data-driven interaction, to cite some. Such features instead can be modelled quite naturally by adopting an agent-oriented perspective. Accordingly, we introduce here a programming model for SOA and Web Services called SA&A (Service Agents and Artifacts-based Architecture), based on a general-purpose conceptual model called A&A (Agents and Artifacts). The approach makes it possible to conceive, design and program services (and applications using services) as workspaces where ensemble of proactive activity-oriented entities (agents) work together exploiting different kinds of passive function-oriented entities (artifacts) used as resources and tools to support their business activities.",data oriented architecture,780
6e03f62325d2fe78b9e77c647939f7bbe8568443,filtered,semantic_scholar,,1984-01-01,semantic_scholar,on supercomputing with systolic/wavefront array processors,https://www.semanticscholar.org/paper/6e03f62325d2fe78b9e77c647939f7bbe8568443,"In many scientific and signal processing applications, there are increasing demands for large-volume and/or high-speed computations which call for not only high-speed computing hardware, but also for novel approaches in computer architecture and software techniques in future supercomputers. Tremendous progress has been made on several promising parallel architectures for scientific computations, including a variety of digital filters, fast Fourier transform (FFT) processors, data-flow processors, systolic arrays, and wavefront arrays. This paper describes these computing networks in terms of signal-flow graphs (SFG) or data-flow graphs (DFG), and proposes a methodology of converting SFG computing networks into synchronous systolic arrays or data-driven wavefront arrays. Both one- and two-dimensional arrays are discussed theoretically, as well as with illustrative examples. A wavefront-oriented programming language, which describes the (parallel) data flow in systolic/wavefront-type arrays, is presented. The structural property of parallel recursive algorithms points to the feasibility of a Hierarchical Iterative Flow-Graph Design (HIFD) of VLSI Array Processors. The proposed array processor architectures, we believe, will have significant impact on the development of future supercomputers.",data oriented architecture,781
b9894d01eb14834220ac6133a600f2070ed9c41d,filtered,semantic_scholar,Proceedings of IEEE Workshop on FPGA's for Custom Computing Machines,1994-01-01,semantic_scholar,a reconfigurable data-driven alu for xputers,https://www.semanticscholar.org/paper/b9894d01eb14834220ac6133a600f2070ed9c41d,"A reconfigurable data-driven datapath architecture for ALUs is presented which may be used for custom computing machines (CCMs), Xputers (a class of CCMs) and other adaptable computer systems as well as for rapid prototyping of high speed datapaths. Fine grained parallelism is achieved by using simple reconfigurable processing elements which are called datapath units (DPUs). The word-oriented datapath simplifies the mapping of applications onto the architecture. Pipelining is supported by the architecture. The programming environment allows automatic mapping of the operators from high level descriptions. Two implementations, one by FPGAs and one with standard cells are shown.<<ETX>>",data oriented architecture,782
a29ff9c3d0c5c80716ef1ddb23079c7ca6c1e5c1,filtered,semantic_scholar,,1988-01-01,semantic_scholar,symbolic/subsymbolic sentence analysi: exploiting the best of two worlds,https://www.semanticscholar.org/paper/a29ff9c3d0c5c80716ef1ddb23079c7ca6c1e5c1,"A NUMBER OF SEMANTICALLY-ORIENTED TECHNIQUES HAVE BEEN DEVISED OVER THE YEARS TO ADDRESS THE PROBLEMS OF CONCEPTUAL SENTENCE ANALYSIS. WE HAVE IMPLEMENTED A NATURAL LANGUAGE SENTENCE ANALYZER, `CIRCUS'', WHICH INCORPOR- ATES A NUMBER OF WELL-KNOWN TECHNIQUES FROM THE SYMBOLIC INFORMATION PRO- CESSING TRADITION ALONG WITH ORIGINAL TECHNIQUES BASED ON NUMERICAL RELAXA- TION. OUR BASIC SYSTEM ARCHITECTURE SUPPORTS A STACK-CONTROLLED MECHANISM FOR MANAGING SYNTACTIC PREDITIONS, AS WELL AS MODULES FOR HANDLING TWO FUNDAMENTALLY DISTINCT TYPES OF SEMANTIC PREFERENCES: PREDICTIVE SEMANTICS AND DATA-DRIVEN SEMANTICS. A MARKER PASSING ALGORITHM IS USED FOR PREDIC- TIVE SEMANTICS, AND NUMERICAL RELAXATION IS USED FOR DATA-DRIVEN SEMANTICS. THIS PAPER PROVIDES A GENERAL INTRODUCTION TO `CIRCUS'', THE OPPORTUNITIES FOR DIFFERENT KINDS OF MEMORY INTERACTIONS WITH `CIRCUS'', AND DETAILED (BUT NOT TECHNICAL) DESCRIPTIONS OF OUR MARKER PASSING AND NUMERICAL RELAXATION ALGORITHMS. `CIRCUS'' IS CURRENTLY RUNNING UNDER COMMON LISP ON THE TI EXPLORER.",data oriented architecture,783
973bf397826261e3d1add7a57a78cd62f057442e,filtered,semantic_scholar,IEICE Trans. Electron.,2006-01-01,semantic_scholar,design philosophy of a networking-oriented data-driven processor: cue,https://www.semanticscholar.org/paper/973bf397826261e3d1add7a57a78cd62f057442e,"To realize a secure networking infrastructure, the author is carrying out CUE (Coordinating Users' requirements and Engineering constraints) project with a network carrier and a VLSI manufacture. Since CUE-series data-driven processors developed in the project were specifically designed to be an embedded programmable component as well as a multi-processor element, particular design considerations were taken to achieve real-time multiprocessing capabilities essentially needed in multimedia communication environment. A novel data-driven paradigm is first introduced with special emphasis on VLSI-oriented parallel processing architectures. Data-driven protocol handlings on CUE-p and CUE-vl are then discussed for their real-time multiprocessing capability without any runtime overheads. The emulation facility RESCUE (Real-time Execution System for CUE-series data-driven processors) was also built to develop scalable chip multi-processors in self-evolutional manner. Based on emulation results, the latest version named CUE-v2 was realized as a hybrid processor enabling simultaneous processing of data-driven and control-driven threads to achieve higher performance for inline processing and to avoid any bottlenecks in sequential parts of real-time programs frequently encountered in actual time-sensitive applications. Effectiveness of the data-driven chip multi-processor architecture will finally be addressed for lower power consumption and scalability to realize future VLSI processors in the sub-100 nm era.",data oriented architecture,784
41899777087921f277d98a2e88971d1dacdf687f,filtered,semantic_scholar,2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA),2016-01-01,semantic_scholar,data-driven workflows for microservices: genericity in jolie,https://www.semanticscholar.org/paper/41899777087921f277d98a2e88971d1dacdf687f,"Microservices is an architectural style inspired by service-oriented computing that has recently started gainingpopularity. Jolie is a programming language based on the microservices paradigm: the main building block of Jolie systems are services, in contrast to, e.g., functions or objects. The primitives offered by the Jolie language elicit many of the recurring patterns found in microservices, like load balancers and structured processes. However, Jolie still lacks some useful constructs for dealing with message types and data manipulation that are present in service-oriented computing. In this paper, we focus on the possibility of expressing choices at the level of data types, a feature well represented in standards for Web Services, e.g., WSDL. We extend Jolie to support such type choices, and enable Jolie processes to act on data generically (without knowing which type it has in the choice). We show the impact of our implementation on some of the typical scenarios found in microservice systems. This shows how computation can move from a process-driven to a data-driven approach, and leads to the preliminary identification of recurring communication patterns that can be shaped as design patterns.",data oriented architecture,785
15949023dc3ebd2cf190b4e4df0a446f7413956c,filtered,semantic_scholar,ICEIS,2016-01-01,semantic_scholar,"the data-driven factory - leveraging big industrial data for agile, learning and human-centric manufacturing",https://www.semanticscholar.org/paper/15949023dc3ebd2cf190b4e4df0a446f7413956c,"Global competition in the manufacturing industry is characterized by ever shorter product life cycles, increasing complexity and a turbulent environment. High product quality, continuously improved processes as well as changeable organizational structures constitute central success factors for manufacturing companies. With the rise of the internet of things and Industrie 4.0, the increasing use of cyber-physical systems as well as the digitalization of manufacturing operations lead to massive amounts of heterogeneous industrial data across the product life cycle. In order to leverage these big industrial data for competitive advantages, we present the concept of the data-driven factory. The data-driven factory enables agile, learning and human-centric manufacturing and makes use of a novel IT architecture, the Stuttgart IT Architecture for Manufacturing (SITAM), overcoming the insufficiencies of the traditional information pyramid of manufacturing. We introduce the SITAM architecture and discuss its conceptual components with respect to service-oriented integration, advanced analytics and mobile information provisioning in manufacturing. Moreover, for evaluation purposes, we present a prototypical implementation of the SITAM architecture as well as a real-world application scenario from the automotive industry to demonstrate the benefits of the data-driven factory.",data oriented architecture,786
e753801de53102aae656d2088a64647aab85d9ca,filtered,semantic_scholar,Proceedings International Conference on Computer Design VLSI in Computers and Processors,1997-01-01,semantic_scholar,prophid: a heterogeneous multi-processor architecture for multimedia,https://www.semanticscholar.org/paper/e753801de53102aae656d2088a64647aab85d9ca,"PROPHID is a design method aiming at high-performance systems with a focus on high-throughput signal processing for multimedia applications. The processing and communication bandwidth requirements of such systems are very high. To obtain a good balance between performance, programmability and efficiency in terms of speed, area and power PROPHID uses a novel heterogeneous multi-processor architecture template which exploits task-level concurrency. A general purpose processor aimed at control-oriented tasks and low to medium-performance signal processing tasks, as well as application domain specific processors aimed at high-performance signal processing tasks are available in this template. Next to a central control-oriented bus a special high-throughput communication network is used to meet the high bandwidth requirements of the application domain specific processors. This paper discusses the characteristics and advantages of the PROPHID architecture showing that high performance is obtained by embedding multiple autonomous data-driven processors in a stream-based communication environment.",data oriented architecture,787
d5b8cdaa0cfe4102c323168a791655e1c1271da7,filtered,semantic_scholar,,2006-01-01,semantic_scholar,semantic web technologies: trends and research in ontology-based systems,https://www.semanticscholar.org/paper/d5b8cdaa0cfe4102c323168a791655e1c1271da7,"Foreword. 1. Introduction. 1.1. Semantic Web Technologies. 1.2. The Goal of the Semantic Web. 1.3. Ontologies and Ontology Languages. 1.4. Creating and Managing Ontologies. 1.5. Using Ontologies. 1.6. Applications. 1.7. Developing the Semantic Web. References. 2. Knowledge Discovery for Ontology Construction. 2.1. Introduction. 2.2. Knowledge Discovery. 2.3. Ontology Definition. 2.4. Methodology for Semi-automatic Ontology Construction. 2.5. Ontology Learning Scenarios. 2.6. Using Knowledge Discovery for Ontology Learning. 2.7. Related Work on Ontology Construction. 2.8. Discussion and Conclusion. Acknowledgments. References. 3. Semantic Annotation and Human Language Technology. 3.1. Introduction. 3.2. Information Extraction: A Brief Introduction. 3.3. Semantic Annotation. 3.4. Applying 'Traditional' IE in Semantic Web Applications. 3.5. Ontology-based IE. 3.6. Deterministic Ontology Authoring using Controlled Language IE. 3.7. Conclusion. References. 4. Ontology Evolution. 4.1. Introduction. 4.2. Ontology Evolution: State-of-the-art. 4.3. Logical Architecture. 4.4. Data-driven Ontology Changes. 4.5. Usage-driven Ontology Changes. 4.6. Conclusion. References. 5. Reasoning With Inconsistent Ontologies: Framework, Prototype, and Experiment. 5.1. Introduction. 5.2. Brief Survey of Approaches to Reasoning with Inconsistency. 5.3. Brief Survey of Causes for Inconsistency in the Semantic WEB. 5.4. Reasoning with Inconsistent Ontologies. 5.5. Selection Functions. 5.6. Strategies for Selection Functions. 5.7. Syntactic Relevance-Based Selection Functions. 5.8. Prototype of Pion. 5.9. Discussion and Conclusions. Acknowledgment. References. 6. Ontology Mediation, Merging, and Aligning. 6.1. Introduction. 6.2. Approaches in Ontology Mediation. 6.3. Mapping and Querying Disparate Knowledge Bases. 6.4. Summary. References. 7. Ontologies for Knowledge Management. 7.1. Introduction. 7.2. Ontology usage Scenario. 7.3. Terminology. 7.4. Ontologies as RDBMS Schema. 7.5. Topic-ontologies versus Schema-ontologies. 7.6. Proton Ontology. 7.7. Conclusion. References. 8. Semantic Information Access. 8.1. Introduction. 8.2. Knowledge Access and the Semantic WEB. 8.3. Natural Language Generation from Ontologies. 8.4. Device Independence: Information Anywhere. 8.5. SEKTAgent. 8.6. Concluding Remarks. References. 9. Ontology Engineering Methodologies. 9.1. Introduction. 9.2. The Methodology Focus. 9.3. Past and Current Research. 9.4. Diligent Methodology. 9.5. First Lessons Learned. 9.6. Conclusion and Next Steps. References. 10. Semantic Web Services-Approaches and Perspectives. 10.1. Semantic Web Services-A Short Overview. 10.2. The WSMO Approach. 10.3. The OWL-S Approach. 10.4. The SWSF Approach. 10.5. The IRS-III Approach. 10.6. The WSDL-S Approach. 10.7. Semantic Web Services Grounding: The Link Between The SWS and Existing Web Services Standards. 10.8. Conclusions and Outlook. References. 11. Applying Semantic Technology to a Digital Library. 11.1. Introduction. 11.2. Digital Libraries: The State-of-the-art. 11.3. A Case Study: the BT Digital Library. 11.4. The Users' View. 11.5. Implementing Semantic Technology in a Digital Library. 11.6. Future Directions. References. 12. Semantic Web: A Legal Case Study. 12.1. Introduction. 12.2. Profile of The Users. 12.3. Ontologies for Legal Knowledge. 12.4. Architecture. 12.5. Conclusions. References. 13. A Semantic Service Oriented Architecture for the Telecommunications Industry. 13.1. Introduction. 13.2. Introduction to Service Oriented Architectures. 13.3. A Semantic Service Orientated Architecture. 13.4. Semantic Mediation. 13.5. Standards and Ontologies in Telecommunications. 13.6. Case Study. 13.7. Conclusion. References. 14. Conclusion and Outlook. 14.1. Management of Networked Ontologies. 14.2. Engineering of Networked Ontologies. 14.3. Contextualizing Ontologies. 14.4. Cross Media Resources. 14.5. Social Semantic Desktop. 14.6. Applications. Index.",data oriented architecture,788
758ef1269c1cf2b5f2be5479fde9dfc610226eed,filtered,semantic_scholar,International Journal of Parallel Programming,2011-01-01,semantic_scholar,acotes project: advanced compiler technologies for embedded streaming,https://www.semanticscholar.org/paper/758ef1269c1cf2b5f2be5479fde9dfc610226eed,"Streaming applications are built of data-driven, computational components, consuming and producing unbounded data streams. Streaming oriented systems have become dominant in a wide range of domains, including embedded applications and DSPs. However, programming efficiently for streaming architectures is a challenging task, having to carefully partition the computation and map it to processes in a way that best matches the underlying streaming architecture, taking into account the distributed resources (memory, processing, real-time requirements) and communication overheads (processing and delay). These challenges have led to a number of suggested solutions, whose goal is to improve the programmer’s productivity in developing applications that process massive streams of data on programmable, parallel embedded architectures. StreamIt is one such example. Another more recent approach is that developed by the ACOTES project (Advanced Compiler Technologies for Embedded Streaming). The ACOTES approach for streaming applications consists of compiler-assisted mapping of streaming tasks to highly parallel systems in order to maximize cost-effectiveness, both in terms of energy and in terms of design effort. The analysis and transformation techniques automate large parts of the partitioning and mapping process, based on the properties of the application domain, on the quantitative information about the target systems, and on programmer directives. This paper presents the outcomes of the ACOTES project, a 3-year collaborative work of industrial (NXP, ST, IBM, Silicon Hive, NOKIA) and academic (UPC, INRIA, MINES ParisTech) partners, and advocates the use of Advanced Compiler Technologies that we developed to support Embedded Streaming.",data oriented architecture,789
0a3e9d879d01d558583865e101d9fffc84d6bf23,filtered,semantic_scholar,2009 International Conference on Software Testing Verification and Validation,2009-01-01,semantic_scholar,ws-taxi: a wsdl-based testing tool for web services,https://www.semanticscholar.org/paper/0a3e9d879d01d558583865e101d9fffc84d6bf23,"Web Services (WSs) are the W3C-endorsed realization of the Service-Oriented Architecture (SOA). Since they are supposed to be implementation-neutral, WSs are typically tested black-box at their interface. Such an interface is generally specified in an XML-based notation called the WS Description Language (WSDL). Conceptually, these WSDL documents are eligible for fully automated WS test generation using syntax-based testing approaches. Towards such goal, we introduce the WS-TAXI framework, in which we combine the coverage of WS operations with data-driven test generation. In this paper we present an early-stage implementation of WS-TAXI, obtained by the integration of two existing softwares: soapUI, a popular tool for WS testing, and TAXI, an application we have previously developed for the automated derivation of XML instances from a XML schema. WS-TAXI delivers a complete suite of test messages ready for execution. Test generation is driven by basic coverage criteria and by the application of some heuristics. The application of WS-TAXI to a real case study gave encouraging results.",data oriented architecture,790
0b89c538059cfbed6529010f2d7548767f5bcf9c,filtered,semantic_scholar,2013 IEEE International Conference on Big Data,2013-01-01,semantic_scholar,on mixing high-speed updates and in-memory queries: a big-data architecture for real-time analytics,https://www.semanticscholar.org/paper/0b89c538059cfbed6529010f2d7548767f5bcf9c,"Up-to-date business intelligence has become a critical differentiator for the modern data-driven highly engaged enterprise. It requires rapid integration of new information on a continuous basis for subsequent analyses. ETL-based and traditionally batch-processing oriented methods of absorbing changes into a relational database schema take time, and are therefore incompatible with very low-latency demands of realtime analytics. Instead, in-memory clustered stores that employ tunable consistency mechanisms are becoming attractive since they dispense with the need to transform and transit data between storage layouts and tiers. When data is updated infrequently, in-memory approaches such as RDD transformations in Spark can suffice, but as updates become frequent, such in-memory approaches need to be extended to support dynamic datasets. This paper describes a few key additional requirements that result from having to support in-memory processing of data while updates proceed concurrently. The paper describes Real-time Analytics Foundation (RAF), an architecture to meet the new requirements. Performance of an early implementation of RAF is also described: for an unaudited TPC-H derived workload, RAF shows a node-to-node scaling ratio of 88% at 8 nodes, and for a query equivalent to Q6 in the TPC-H set, RAF is able to show 9x improvement over that of Hive-Hadoop. The paper also describes two RAF based solutions that are being put together by two independent software vendors in China.",data oriented architecture,791
29e04a9a210cda16656ef4cf8ee1efa619c4b408,filtered,semantic_scholar,,2020-01-01,semantic_scholar,information sharing for manufacturing supply chain management based on blockchain technology,https://www.semanticscholar.org/paper/29e04a9a210cda16656ef4cf8ee1efa619c4b408,"Internet of Things (IoT) and blockchain technology-based information system (IS) can be used to improve tracking of goods and services in offering and build a collaborative operating environment among the business-partners of the manufacturing industry. In this process IS architecture plays an important role in storing, processing, and distributing data. Despite contributing to the rapid development of IoT applications, the current IoT-centric architecture has led to a myriad of isolated data silos that hinder the full potential of holistic data-driven decision-support applications with the IoT because of technical issues (e.g., standalone IoT applications suffer from security and privacy-related problems). This chapter presents a proof of concept of a hybrid enterprise information system architecture, which consists of IoT-based applications and a blockchain-oriented distributed-ledger system to support-transaction services within a multiparty global manufacturing (e.g., textile and clothing business) network.",data oriented architecture,792
8d25b018a4743de1087cab6abc49dbaa4fa16f37,filtered,semantic_scholar,,1998-01-01,semantic_scholar,"building scalable database applications : object-oriented design, architectures, and implementations",https://www.semanticscholar.org/paper/8d25b018a4743de1087cab6abc49dbaa4fa16f37,"Foreword. Preface. Acknowledgments. About the Author. I. AN OBJECT-ORIENTED VIEW ON PERSISTENCE. 1. A New Generation of Software. From Data to Information. Improving Software Quality. Databases Everywhere. To Have and to Hold. Concentrating on the Essence. The Importance of Scalability. Application Program Interfaces. The Road to Follow. 2. The Database Community Today. Walking among Dinosaurs. Database Usage. Database Users. Designing Database Applications. Relational Databases. Client / Server Systems. Distributed Software. Problems with Traditional Systems. 4GL: The Solution? Object-Oriented Databases. Preserving Openness. Summary. 3. An Object-Oriented View on Database Applications. Data-Driven Software Design. Supporting Multiple Applications. Object-Oriented Software Design. The Object Model. Example: Student Administration. Business Models and Supporting Multiple Applications. C++, Java, or Smalltalk: The Ultimate Answer? Building Reusable Software. Toward Open Client / Server Applications. Object Orientation and Client / Server Design. User Interfaces. Analogy between User Interfaces and Databases. Object-Oriented or Relational? Persistence from a Different Angle. Persistence and Separation of Concerns. Safety Issues. Summary. II. AN ARCHITECTURE FOR OBJECT PERSISTENCE. 4. Making Objects Persistent. Introduction. Basic Requirements of a Persistence Framework. Obtaining Scalability. Interfacing with a Relational World: Problems to Conquer. Abstracting the Database. An Architecture for Object Persistence. 5. Abstracting the Database. A Persistent Container Class. Basic Functionality of PSet. Implementing the Persistence Architecture. Resolving the Impedance Mismatch. Reading and Writing Objects. Direct Instances of PSet. Searching for Objects. Supporting Multiple Technologies. 6. Encapsulating Data Access. Deriving from PSet. Example: Class City. Using Class City. Member Objects. Derived IM Resolvers. Class Extension. Link-Time Decoupling. Reuse and Migration to Other Technologies. III. IMPLEMENTING BUSINESS MODELS. 7. Designing Business Objects. Developing a Simple Invoicing System. Searching Compound Objects. Object ID versus Primary Key. Developing Generic IM Resolvers. An OID-Based Reference Class. Supporting Existing Database Layouts. Versioning. Stability of Program Code against Schema Changes. Storing Multimedia Objects. Efficiency. 8. Inheritance of Persistent Objects. Specialization: Using Inheritance for Reuse. Generalization: Using Inheritance for Polymorphism. Using Generalizations as Member Objects. Inheritance in Relational Database Systems. Designing Reusable Software Components. Summary. 9. Associations. Many-to-One Relationships. Attributes versus Associations. Collections: One-to-Many Relationships. Associations and Reuse. Many-to-Many Relationships. A Closer Look at Associations. Associations as Independent Entities. Referential Integrity. 10. Transaction Management and Concurrency Control. The Transaction. The ACID Test. Transaction Management Exceeds the Database Level. Concurrency Control: Locking. Example: A Transaction Class. Transactions in Relational Database Systems. Using Transactions. Nested Transactions. Distributed Database Systems. Other Levels of Concurrency. Lock Notification through Call-Back Functions. 11. The Front End. Analogy between User Interfaces and Databases. Separating the User Interface from the Business Model. What to Put Where. Navigating through Persistent Sets. 12. Case Study: An Electronic Telephone Directory. Project Definition. Comparing Development Approaches. Designing the User Interface. The Database Model. Designing the Business Model. Comparing the Business Model and the Database Model. Implementing the Business Objects. Making Classes Persistent. Impedance Mismatch Examples. Implementing the User Interface. 13. Toward Open Applications. Third-Party Access to Your Application's Data. Standard Report Generators and Query Tools. Informationbases. Interoperability with Other Applications. Implementing an Informationbase. Architecture for Next-Generation Software. 14. Conclusion. Appendix. DBtools-Based Implementation of Scoop. PSet. DataSet. IM_Resolver. Resolving Impedance Mismatch. Building the Select Statement. 0201310139T04062001",data oriented architecture,793
f427ed32ab1585f33d0c6b7dd6582a40c1fe0463,filtered,semantic_scholar,International Conference on Computational Science,2007-01-01,semantic_scholar,realization of dynamically adaptive weather analysis and forecasting in lead: four years down the road,https://www.semanticscholar.org/paper/f427ed32ab1585f33d0c6b7dd6582a40c1fe0463,"Linked Environments for Atmospheric Discovery (LEAD) is a large-scale cyberinfrastructure effort in support of mesoscale meteorology. One of the primary goals of the infrastructure is support for real-time dynamic, adaptive response to severe weather. In this paper we revisit the conception of dynamic adaptivity as appeared in our 2005 DDDAS workshop paper, and discuss changes since the original conceptualization, and lessons learned in working with a complex service oriented architecture in support of data driven science.",data oriented architecture,794
ac1629c05abb92b40cccb66b0ed7325bedd2e600,filtered,semantic_scholar,INLG,1998-01-01,semantic_scholar,de-constraining text generation,https://www.semanticscholar.org/paper/ac1629c05abb92b40cccb66b0ed7325bedd2e600,"We argue that the current, predominantly task-oriented, approaz~hes to modularizing text • generation, while plausible and useful conceptually, set up spurious conceptual and operational constraints. We propose a data-driven approach to modularization and illustrate how it eliminates • •the previously ubiquitous constraints on combination of evidence across modules and on • control. We also briefly overview the constraint-based control architecture that enables such an approach and facilitates near linear-time processing with realistic texts.",data oriented architecture,795
651d0f1bfc127119ad3fc92df2510fff525ec668,filtered,semantic_scholar,Proceedings of IEEE International Workshop on Research Issues in Data Engineering: Active Databases Systems,1994-01-01,semantic_scholar,an alternative paradigm for active databases,https://www.semanticscholar.org/paper/651d0f1bfc127119ad3fc92df2510fff525ec668,Most active database models adopted an event-driven approach in which whenever a given event occurs the database triggers some actions. This paper presents a reflective paradigm implemented in a dependency-oriented fashion. According to this paradigm data driven rules are specified as invariants. The invariants are translated to a dependency graph and the execution logic is self-determined at run-time using this dependency graph. This architecture is presented and discussed as a solution both for data driven rules and for event driven rules.<<ETX>>,data oriented architecture,796
5ae6651d19abe75bc6b12ae9bd4d2f3bdfe2f522,filtered,semantic_scholar,,2014-01-01,semantic_scholar,intersecting knowledge fields and integrating data-driven computational design en route to performance-oriented and intensely local architectures,https://www.semanticscholar.org/paper/5ae6651d19abe75bc6b12ae9bd4d2f3bdfe2f522,"This paper discusses research by design efforts in architectural education, focused on developing concepts and methods for the design of performance-oriented and intensely local architectures. The pursued notion of performance foregrounds the interaction between a given architecture and its local setting, with consequences not only for the design product but also for the related processes by which it is generated. Integrated approaches to data-driven computational design serve to generate such designs. The outlined approach shifts the focus of design attention away from the delivery of finite architectural objects and towards an expanded range of architecture-environment interactions that are registered, instrumentalised and modulated over time. This paper examines ongoing efforts in integrating specific architectural goals and approaches, computational data-driven design methods and generative design processes, based on a range of context-specific and often real-time data sets. The work discussed is produced in the context of the Research Centre for Architecture and Tectonics (RCAT) and the Advanced Computational Design Laboratory (ACDL) at the Oslo School of Architecture and Design.",data oriented architecture,797
428c581e43a2459971d6b76d53567f387decf531,filtered,semantic_scholar,2006 Second IEEE International Symposium on Service-Oriented System Engineering (SOSE'06),2006-01-01,semantic_scholar,a tuple-space-based coordination architecture for test agents in the mast framework,https://www.semanticscholar.org/paper/428c581e43a2459971d6b76d53567f387decf531,"Service-oriented architecture (SOA) is becoming the mainstream of distributed system integration. Trustworthiness is critical for cross-domain service interaction, and testing is necessary to build the trust among the different parties involved in SOA. MAST, a multi-agent-based service testing framework, was proposed for testing service-based applications in our previous work. This paper further explores the agent coordination issues in the MAST framework to address the challenge of effective agent communication and interaction. A hybrid coordination architecture is presented which combines data-driven and control-driven models based on the reactive tuple space technique. Different tuple spaces are introduced to facilitate data sharing and asynchronous coordination among test agents. A subscription mechanism is introduced to associate programmable reactions to the events occurred and state changes on the tuple space. The mobile agent technique is also introduced to implement the test agents, which are created on line carrying the tasks, and migrate to the host computers to execute various tasks. A prototype system is designed and implemented to illustrate the proposed approach",data oriented architecture,798
af12f457c4412e1d85e44b7f7188687a67d7676a,filtered,semantic_scholar,"2010 IEEE International Conference on Systems, Man and Cybernetics",2010-01-01,semantic_scholar,service-oriented dynamic data driven application systems to traffic signal control,https://www.semanticscholar.org/paper/af12f457c4412e1d85e44b7f7188687a67d7676a,"Dynamic traffic signal control in Intelligent Transportation Systems (ITS) has been widely developed in major cities' urban areas around the world to provide more efficient way for solving traffic congestion problem. However, the problems in dynamic traffic signal control systems such as system flexibility, data standard common interface, transmission of required information, prediction performance, and real-time measurement data are all important issues. Therefore, in this paper, we proposed a new framework to integrate dynamic data driven application systems (DDDAS) with service-oriented architecture (SOA) and web services technology, for a decentralized traffic signal control system. An efficient and effective distributed data-driven optimization algorithm is designed in this framework to produce an optimal result and best strategy for signal control.",data oriented architecture,799
c452896d0ba5c7f36b7ba500dc6869c2b522ebcd,filtered,semantic_scholar,IEEE Transactions on Visualization and Computer Graphics,2015-01-01,semantic_scholar,munin: a peer-to-peer middleware for ubiquitous analytics and visualization spaces,https://www.semanticscholar.org/paper/c452896d0ba5c7f36b7ba500dc6869c2b522ebcd,"We present Munin, a software framework for building ubiquitous analytics environments consisting of multiple input and output surfaces, such as tabletop displays, wall-mounted displays, and mobile devices. Munin utilizes a service-based model where each device provides one or more dynamically loaded services for input, display, or computation. Using a peer-to-peer model for communication, it leverages IP multicast to replicate the shared state among the peers. Input is handled through a shared event channel that lets input and output devices be fully decoupled. It also provides a data-driven scene graph to delegate rendering to peers, thus creating a robust, fault-tolerant, decentralized system. In this paper, we describe Munin's general design and architecture, provide several examples of how we are using the framework for ubiquitous analytics and visualization, and present a case study on building a Munin assembly for multidimensional visualization. We also present performance results and anecdotal user feedback for the framework that suggests that combining a service-oriented, data-driven model with middleware support for data sharing and event handling eases the design and execution of high performance distributed visualizations.",data oriented architecture,800
6d1411047ee7f89b38620f095c670958833675d5,filtered,semantic_scholar,2007 IEEE International Conference on Information Reuse and Integration,2007-01-01,semantic_scholar,defining dependable dynamic data-driven software architectures,https://www.semanticscholar.org/paper/6d1411047ee7f89b38620f095c670958833675d5,"The thesis of this vision paper is that the dynamic data driven applications systems (DDDAS) is a promising paradigm to adopt for assisting architectures to self-maintain their dependability properties, as the software architecture tends to evolve in response to changes in the operating environment, changes in contexts, and dynamic usages of the application. In this perspective, the architecture becomes an integrated computational and measurement artifact aimed at measuring, simulating, and controlling the runtime evolution of dependable software systems. This perspective is novel and has the promise to form a built-in support for the runtime dependability analyses, reasoning, and evaluation for many architecture-centric approaches such as product-line, service oriented, and model-driven paradigms. The contribution of this position paper is a definition of Dependable Dynamic Data-Driven Software Architectures (DSA), inspired by this paradigm. We describe the major components which can ""orchestrate "" to realize DSA. We highlight some challenges and opportunities.",data oriented architecture,801
b895ee008741a82194abd8f99ed2baa2dedf0731,filtered,semantic_scholar,Int. J. Cooperative Inf. Syst.,1993-01-01,semantic_scholar,a reflective approach for data-driven rules,https://www.semanticscholar.org/paper/b895ee008741a82194abd8f99ed2baa2dedf0731,"This paper presents an alternative to the E-C-A approach adopted by most active database models, in which, whenever a given event occurs the database triggers some actions. A reflective paradigm is implemented in a dependency-oriented fashion. According to this paradigm, data driven rules are specified as invariants. The invariants are translated to a dependency graph and the execution logic is being self-determined at run-time using this dependency graph. This architecture is presented and discussed as a solution for data-driven rules with an extension to support event-driven rules.",data oriented architecture,802
61b2ead1ebc64c3abfc99965fb2c2f7b8484988f,filtered,semantic_scholar,ICSOC,2008-01-01,semantic_scholar,towards automated wsdl-based testing of web services,https://www.semanticscholar.org/paper/61b2ead1ebc64c3abfc99965fb2c2f7b8484988f,"With the emergence of service-oriented computing, proper approaches are needed to validate a Web Service (WS) behaviour. In the last years several tools automating WS testing have been released. However, generally the selection of which and how many test cases should be run, and the instantiation of the input data into each test case, is still left to the human tester. 
 
In this paper we introduce a proposal to automate WSDL-based testing, which combines the coverage of WS operations with data-driven test case generation. We sketch the general architecture of a test environment that basically integrates two existing tools: soapUI, which is a popular tool for WS testing, and TAXI, which is a tool we have previously developed for the automated derivation of XML instances from a XML Schema. 
 
The test suite generation can be driven by basic coverage criteria and by the application of some heuristics, aimed in particular at systematically combining the generated instance elements in different ways, and at opportunely varying the cardinalities and the data values used for the generated instances.",data oriented architecture,803
fe653e72c6f42ddd8e861db01d20ede1e497a0dc,filtered,semantic_scholar,CACM,1990-01-01,semantic_scholar,introduction—object-oriented design,https://www.semanticscholar.org/paper/fe653e72c6f42ddd8e861db01d20ede1e497a0dc,"Object-oriented, a buzzword of the late 1980s, has evolved into an accepted technology that has recognized benefits for the software development process. In its progression from a purely procedural approach, software development reached a data-driven—object-based—approach, and has grown beyond that to the object-oriented approach.
The impact of the object-oriented approach is not limited to the design portion of the software development life cycle—its effects are evident at every phase. One of the strengths of the object model is that it provides a unifying element that is common to every phase of the life cycle. This uniformity provides a smooth transition from one phase to the next.
The article by Henderson-Sellers and Edwards presents a revision of the traditional life cycle based on the object-oriented approach. It discusses the unique view of the design process and describes how it works: the process takes a specified problem and decomposes it. The resulting product forms the framework for a computer-based solution to the problem. Object-oriented techniques begin this decomposition process in the analysis phase and carry it on into the design phase. A modeling paradigm is used for the decomposition process: The top layer of an object-oriented system is a model of the real-life situation for which the software system is being created. The underlying layers provide the implementation of this model.
The “pieces” produced by object-oriented techniques are as unique as the design perspective. Its obvious similarities to and subtle differences from abstract data type (ADT) technology have led to much discussion of objects and classes in terms of ADTs. The unique coupling of data and behavior in the object-oriented components provides much more than a syntactic distinction from the usual ADT. Added to the modeling approach, it produces a recognizably different approach to systems development.
The term object-oriented is defined differently by different people. Many professionals agree with the basics of Wegner's definition1 that object-oriented includes three concepts: objects, classes, and class inheritance. Some would add a variety of other requirements including such concepts as polymorphism, dynamic binding, encapsulation, etc. The article by Korson and McGregor provides an overview of these concepts, leaving room for the reader to decide which to include and which to exclude; it also provides an overview of the basic concepts of object-oriented design.
The production of software in an increasingly competitive environment is making reuse a priority of software professionals. The popularity of the object-oriented technique is due, in part, to its support for reuse. Two important factors influence reuse: First, it is necessary to have a set of high-quality components that are worth reusing. Second, the components must be well-defined, easy to integrate, and efficient. Meyer's article presents some experiences in developing the classes for the Eiffel library; it also discusses characteristics of the library. For components to be reused, the designer must have the means to locate a component which models an entity in the current problem. Not only must the component be located, but often necessary supporting pieces must be found as well. The article by Gibbs et al. provides information on the management of classes and the software components of the object-oriented paradigm.
Tom DeMarco, in a recent interview,2 declared parallel computing to be the emerging new paradigm. According to DeMarco object-oriented techniques will be an integral partner in this emergence. DeMarco observed that designing with objects preserves the natural parallelism in a problem. Agha addresses models for parallel objects, presenting an overview of the problem and focusing on the actor model as a possible solution. He presents examples of design issues when using the actor model. He also considers a basic reflective design architecture.
The importance of well-defined and well-managed abstractions in the software development process is discussed in the articles by Meyer and by Gibbs et al as they explore what has come to be called the software base, the set of software components from which future products will be built.
The unique components developed by object-oriented methods are characterized by an interface that is separate from the implementation of that behavior. The designer is free to concentrate on modeling the problem at hand either by developing specific classes or by locating and reusing existing classes that model some subset of the needed behavior. Meyer focuses on what he quotes McIlroy as terming a “software components subindustry,”3 presenting a case study of the development of the Eiffel libraries.
The final article in this special issue, by Henderson-Sellers and Edwards discusses modifications to the traditional life cycle supported by the object-oriented approach. The modified life cycle recognizes the iterative nature of the development process and incorporates that characteristic into its model.
Wirfs-Brock and Johnson present a sampling of current research into several aspects of object-oriented design. Their survey includes efforts to improve reusability through design technique and paradigm-specific tools. The works are representative of the broad spectrum of research activity currently under way.
We would like to thank the authors in this special issue for their hours of work both in developing their own articles and for the time spent evaluating and commenting upon the other articles.",data oriented architecture,804
24e5b0963cfc1d2f2405df2d751cee41d7e7e266,filtered,semantic_scholar,Journal of medical Internet research,2018-01-01,semantic_scholar,possible sources of bias in primary care electronic health record data use and reuse,https://www.semanticscholar.org/paper/24e5b0963cfc1d2f2405df2d751cee41d7e7e266,"Background Enormous amounts of data are recorded routinely in health care as part of the care process, primarily for managing individual patient care. There are significant opportunities to use these data for other purposes, many of which would contribute to establishing a learning health system. This is particularly true for data recorded in primary care settings, as in many countries, these are the first place patients turn to for most health problems. Objective In this paper, we discuss whether data that are recorded routinely as part of the health care process in primary care are actually fit to use for other purposes such as research and quality of health care indicators, how the original purpose may affect the extent to which the data are fit for another purpose, and the mechanisms behind these effects. In doing so, we want to identify possible sources of bias that are relevant for the use and reuse of these type of data. Methods This paper is based on the authors’ experience as users of electronic health records data, as general practitioners, health informatics experts, and health services researchers. It is a product of the discussions they had during the Translational Research and Patient Safety in Europe (TRANSFoRm) project, which was funded by the European Commission and sought to develop, pilot, and evaluate a core information architecture for the learning health system in Europe, based on primary care electronic health records. Results We first describe the different stages in the processing of electronic health record data, as well as the different purposes for which these data are used. Given the different data processing steps and purposes, we then discuss the possible mechanisms for each individual data processing step that can generate biased outcomes. We identified 13 possible sources of bias. Four of them are related to the organization of a health care system, whereas some are of a more technical nature. Conclusions There are a substantial number of possible sources of bias; very little is known about the size and direction of their impact. However, anyone that uses or reuses data that were recorded as part of the health care process (such as researchers and clinicians) should be aware of the associated data collection process and environmental influences that can affect the quality of the data. Our stepwise, actor- and purpose-oriented approach may help to identify these possible sources of bias. Unless data quality issues are better understood and unless adequate controls are embedded throughout the data lifecycle, data-driven health care will not live up to its expectations. We need a data quality research agenda to devise the appropriate instruments needed to assess the magnitude of each of the possible sources of bias, and then start measuring their impact. The possible sources of bias described in this paper serve as a starting point for this research agenda.",data oriented architecture,805
c9cce66b351a09343012ca1940289ab63e993649,filtered,semantic_scholar,2008 International Symposium on Intelligent Information Technology Application Workshops,2008-01-01,semantic_scholar,toward domain-driven data mining,https://www.semanticscholar.org/paper/c9cce66b351a09343012ca1940289ab63e993649,"Traditional data mining is a data-driven trial-an-error process. It stops at discovered pattern/rule, either views data mining as an autonomous process, or only analyzes the issues in an isolated and case-by-case manner. As a result, the knowledge discovered is not interesting and actionable to constrained business. However, in many real world data mining tasks, for instance financial data mining in capital markets are highly constraint-based and domain- oriented. This paper proposes a new methodology named domain-driven data mining (DDDM), aims to discovery interesting and actionable knowledge for real user needs, overcome the gap between academia and business. DDDM integrates domain knowledge, expert experience, user interestingness, rule action ability and data into mining system. In this paper, A few basic concepts and methodologies are introduced firstly, after that the architecture is proposed and working detail is addressed. Finally, we specify issues that are either not addressed or insufficiently suited yet.",data oriented architecture,806
00088f7245e78851e7f459435da86737d84fa261,filtered,semantic_scholar,,2008-01-01,semantic_scholar,geo-information for disaster management,https://www.semanticscholar.org/paper/00088f7245e78851e7f459435da86737d84fa261,"Plenary Contributions.- Orchestra: Developing a Unified Open Architecture for Risk Management Applications.- Laser Scanning Applications on Disaster Management.- Big Brother or Eye in the Sky? Legal Aspects of Space-Based Geo-Information for Disaster Management.- ICT for Environmental Risk Management in the EU Research Context.- Airborne Passive Microwave Radiometry for Emergency Response.- Flood Vulnerability Analysis and Mapping in Vietnam.- Oral Contributions.- Geo Information Breaks through Sector Think.- Accurate On-Time Geo-Information for Disaster Management and Disaster Prevention by Precise Airborne Lidar Scanning.- Methodology for Making Geographic Information Relevant to Crisis Management.- The Value of Gi4DM for Transport & Water Management.- A Case Study in Multiagency GIS for Managing a Large-Scale Natural Disaster.- User-Oriented Provision of Geo-Information in Disaster Management: Potentials of Spatial Data Infrastructures considering Brandenburg/Germany as an Example.- PEGASUS: A Future Tool for Providing Near Real-Time High Resolution Data for Disaster Management.- Disaster Management: The Challenges for a National Geographic Information Provider.- CNES Research and Development and Available Software in the Framework of Space-Images Based Risk and Disaster Management.- A Decision Support System for Preventive Evacuation of People.- Poster contributions.- Considering Elevation Uncertainty for Managing Probable Disasters.- Emergency Preparedness System for the Lower Mekong River Basin: A Conceptual Approach Using Earth Observation and Geomatics.- Framing Spatial Decision-Making and Disaster Management in Time.- Disaster Monitoring Based on Portable Terminal for Real-Time RADARSAT-1 Data Acquisition.- User Requirements for a Mobile Disaster Documentation System.- Plenary Contributions.- Use of Photogrammetry, Remote Sensing and Spatial Information Technologies in Disaster Management, especially Earthquakes.- The 26 December 2004 Sumatra Earthquake and Tsunami Seen by Satellite Altimeters and GPS.- Near-Real Time Post-Disaster Damage Assessment with Airborne Oblique Video Data.- Abilities of Airborne and Space-Borne Sensors for Managing Natural Disasters.- The Use of GIS Technologies within the NOAA Climate Prediction Center's FEWS-NET Program.- Geo-Information for Urban Risk Assessment in Developing Countries: The SLARIM project.- Oral Contributions.- Mass Movement Monitoring Using Terrestrial Laser Scanner for Rock Fall Management.- Findings of the European Platform of New Technologies for Civil Protection: Current Practice and Challenges.- Geo-Information at the Belgian Federal Crisis Centre.- Real Time 3D Environment Simulation Applied to the Disaster Management Field: Our Experience.- Geo-Information for Disaster Management: Lessons from 9/11.- Soft Real-Time GIS for Disaster Monitoring.- Step-Wise Improvement of Precursor Services to an Integrated Crisis Information Center for Mountainous Areas.- Alsat-1: First Member of the DMC.- Experience and Perspective of Providing Satellite Based Crisis Information, Emergency Mapping & Disaster Monitoring Information to Decision Makers and Relief Workers.- Poster contributions.- Survey Methodologies for the Preservation of Cultural Heritage Sites.- A New Geo-Information Architecture for Risk Management.- Software to Support a Specialized Bank of Electronic Maps.- Project OCTAGON: Special UAVs - Autonomous Airborne Platforms.- Disaster Prevention for Alpine Routes.- Step by Step Constitution of an Emergency Management Based Object Model and Database System on Linux for the I.T.U. Campus D.I.S..- Development of a Web-Based GIS Using SDI for Disaster Management.- Visual System for Metric 3D Data Gathering and Processing in Real Time.- Plenary Contributions.- Risk Assessment Using Spatial Prediction Model for Natural Disaster Preparedness.- Automatically Extracting Manmade Objects from Pan-Sharpened High-Resolution Satellite Imagery Using a Fuzzy Segmentation Method.- Oral Contributions.- Extension of NASA's Science and Technology Results, Earth Observations for Decision Support.- A Concept of an Intelligent Decision Support for Crisis Management in the OASIS project.- Mapping World Events.- Allocation of Functional Behavior to Geo-Information for Improved Disaster Planning and Management.- Towards an Integrated Concept for Geographical Information Systems in Disaster Management.- A Distributed Spatial Data Library for Emergency Management.- On Quality-Aware Composition of Geographic Information Services for Disaster Management.- Web-Based Assessment and Decision Support Technology.- Evaluating the Relevance of Spatial Data in Time Critical Situations.- Dealing with Uncertainty in the Real-Time Knowledge Discovery Process.- Poster Contributions.- Experience in Applying Information Technologies to Ensure Safe Operation of Russian Nuclear Industry Facilities.- Building Disaster Anticipation Information into the Ghana Development and Poverty Mapping and Monitoring System.- Vulnerability Assessment for Food Crisis Management in the Sahel Region.- Using Remote Sensing Data for Earthquake Damage Assessment in Afghanistan: The Role of the International Charter.- 3D Buffering: A Visualization Tool for Disaster Management.- Plenary Contributions.- A GIS-Based Spatial Decision Support System for Emergency Services: London's King's Cross St. Pancras Underground Station.- CityGML: Interoperable Access to 3D City Models.- Population Density Estimations for Disaster Management: Case Study Rural Zimbabwe.- The Fourth Column in Action: Dutch Municipalities Organizing Geo-Information for Disaster Management.- Oral Contributions.- GRIFINOR: Integrated Object-Oriented Solution for Navigating Real-Time 3D Virtual Environments.- An Intelligent Hybrid Agent for Medical Emergency Vehicles Navigation in Urban Spaces.- GIS Solutions in Public Safety: A Case Study of the Broward County Sheriff.- Information Management Boosts Command & Control.- Task-Centred Adaptation of Geographic Information to Support Disaster Management.- The Adoption of Geo-information and Geographic Information Systems for Natural Disaster Risk Management by Local Authorities.- Web-Based 3D Visual User Interface to a Flood Forecasting System.- A Web Application for Landslide Inventory Using Data-Driven SVG.- High-Resolution Satellite Image Sources for Disaster Management in Urban Areas.- Geo-Information as an Integral Component of the National Disaster Hazard and Vulnerability ""ATLAS"".- Poster Contributions.- Seismic Emergency Management: Technologies at Work.- Plenary Contributions.- Pedestrian Navigation in Difficult Environments: Results of the ESA Project SHADE.- Location Interoperability Services for Medical Emergency Operations during Disasters.- Oral Contributions.- Evacuation Route Calculation of Inner Buildings.- Poster Contributions.- Geo Embedded Navigation.- LoBI-X: Location-Based, Bi-Directional, Information Exchange, over Wireless Networks.- Plenary Contributions.- Integrated Distributed GIS Approach for Earthquake Disaster Modeling and Visualization.- M3Flood: An Integrated System for Flood Forecasting and Emergency Management.- Oral Contributions.- Mobile Hardware and Software Complex to Support Work of Radiation Safety Experts in Field Conditions.- The New Zoning Approach for Earthquake Risk Assessment.- Application of Remote Sensing and GIS Technology in Forest Fire Risk Modeling and Management of Forest Fires: A Case Study in the Garhwal Himalayan Region.- A Web GIS for Managing Post-Earthquake Emergencies.- Web Based Information System for Natural Hazard Analysis in an Alpine Valley.- Using Explorative Spatial Analysis to Improve Fire and Rescue Services.- The Global Terrestrial Network for River Discharge (GTN-R): Near Real-Time Data Acquisition and Dissemination Tool for Online River Discharge and Water Level Information.- Contribution of Earth Observation Data Supplied by the New Satellite Sensors to Flood Disaster Assessment and Hazard Reduction.- The Relationship between Settlement Density and Informal Settlement Fires: Case Study of Imizamo Yethu, Hout Bay and Joe Slovo, Cape Town Metropolis.- Poster Contributions.- AVHRR Data for Real-Time Operational Flood Forecasting in Malaysia.- Supporting Flood Disaster Response by Freeware Spatial Data in Hungary.- The Use of GIS as Tool to Support Risk Assessment.- Ignored Devastating Disasters and Hazards: The Case of the Horn of Africa.- Tight Coupling of SFlood and ArcView GIS 3.2 for Flood Risk Analysis.- Public Participation Geographic Information Sharing Systems for Community Based Urban Disaster Mitigation.",data oriented architecture,807
68c94cae2b9478f0cefd4b264bff4142767c5429,filtered,semantic_scholar,5th Working IEEE/IFIP Conference on Software Architecture (WICSA'05),2005-01-01,semantic_scholar,dmda - a dynamic service architecture for scientific computing,https://www.semanticscholar.org/paper/68c94cae2b9478f0cefd4b264bff4142767c5429,"The objective of this paper is to address the design of an architecture for scientific applications utilizing sensor data. The proposed architecture models applications as services in a service-oriented architecture. This architecture is, mapped to a heterogeneous architecture that contains highperformance, data-driven components and SOA-style components, and a superimposed on a service architecture that provides dynamism.",data oriented architecture,808
250a727d4ae4cc0262dca57cb247e035fff9b01c,filtered,semantic_scholar,ArXiv,2020-01-01,semantic_scholar,model-based deep learning,https://www.semanticscholar.org/paper/250a727d4ae4cc0262dca57cb247e035fff9b01c,"Signal processing, communications, and control have traditionally relied on classical statistical modeling techniques. Such model-based methods utilize mathematical formulations that represent the underlying physics, prior information and additional domain knowledge. Simple classical models are useful but sensitive to inaccuracies and may lead to poor performance when real systems display complex or dynamic behavior. On the other hand, purely data-driven approaches that are model-agnostic are becoming increasingly popular as datasets become abundant and the power of modern deep learning pipelines increases. Deep neural networks (DNNs) use generic architectures which learn to operate from data, and demonstrate excellent performance, especially for supervised problems. However, DNNs typically require massive amounts of data and immense computational resources, limiting their applicability for some signal processing scenarios. We are interested in hybrid techniques that combine principled mathematical models with data-driven systems to benefit from the advantages of both approaches. Such model-based deep learning methods exploit both partial domain knowledge, via mathematical structures designed for specific problems, as well as learning from limited data. In this article we survey the leading approaches for studying and designing model-based deep learning systems. We divide hybrid model-based/data-driven systems into categories based on their inference mechanism. We provide a comprehensive review of the leading approaches for combining model-based algorithms with deep learning in a systematic manner, along with concrete guidelines and detailed signal processing oriented examples from recent literature. Our aim is to facilitate the design and study of future systems on the intersection of signal processing and machine learning that incorporate the advantages of both domains.",data oriented architecture,809
63ae5cb530d266a912d33def14392804b8e8bf94,filtered,semantic_scholar,Grid-Based Problem Solving Environments,2007-01-01,semantic_scholar,"grid-based problem solving environments - ifip tc2/ wg 2.5 working conference on grid-based problem solving environments: implications for development and deployment of numerical software july 17-21, 2006, prescott, arizona, usa",https://www.semanticscholar.org/paper/63ae5cb530d266a912d33def14392804b8e8bf94,"Workflow Tools.- Programming Paradigms for Scientific Problem Solving Environments.- Why Performance Models Matter for Grid Computing.- Automation of Network-Based Scientific Workflows.- Application Experience.- Virtual Manufacturing A Vision for Virtual Paint Operations.- Service-oriented Computation in Magnetic Fusion Research.- Lessons Learned from the GECEM Project.- Infrastructure: Services.- Open Grid Services Architecture.- Middleware for Dynamic Adaptation of Component Applications.- A Virtual Organisation deployed on a Service Orientated Architecture for Distributed Data Mining applications.- Infrastructure: Numerical Software.- THCORE: A Parallel Computation Services Model and Runtime System.- PythonCLServiceTool: A Utility for Wrapping Command-Line Applications for The Grid.- GridSolve: The Evolution of A Network Enabled Solver.- A Test Harness TH for Numerical Applications and Libraries.- Event Driven Applications.- Dynamic Data-Driven Application Systems for Empty Houses, Contaminat Tracking, and Wildland Fireline Prediction.- Designing a Dynamic Data Driven Application System for Coastal and Environmental Modeling.- SPRUCE: A System for Supporting Urgent High-Performance Computing.- Data Management in Dynamic Environment-driven Computational Science.- Applications I.- Efficient Algorithm to Compute PDEs on the Grid.- On the Use of Services to Support Numerical Weather Prediction.- Mathematical Service Discovery.- Applications II.- A Problem Solving Environment based on Grid Services: NAREGI-PSE.- Grid Enabling of Nano-Science Applications in NAREGI.- Grid Architecture for Scientitic Communities.- Scientific Software Frameworks and Grid Computing.- Grid-based Imaging.- Monitoring and Migration of a PETSc-based Parallel Application for Medical Imaging in a Grid computing PSE.- Grid-based Image Registration.- Conference Summary Strategy for Future Activities.- Observations on WoCo9.- Future Directions for Numerical Software Research - Comments during Discussions at WoCo9, Prescott, AZ, July 16-21, 2006.",data oriented architecture,810
5a6a599e9895d621bddd7c9ffe714112f6d5c58d,filtered,semantic_scholar,2008 Tenth IEEE International Symposium on Multimedia,2008-01-01,semantic_scholar,a semantics- and data-driven soa for biomedical multimedia systems,https://www.semanticscholar.org/paper/5a6a599e9895d621bddd7c9ffe714112f6d5c58d,"Due to the problems of heterogeneous data and platforms, abundant functional and QoS requirements, high data size, and tangling correlation between data/contents and software functionalities, developing large-scale biomedical multimedia database systems is a challenging task. This paper presents a semantics- and data-driven service-oriented architecture (SOA) to take the interoperability and scalability advantages of conventional SOA and solve the aforementioned problems. By establishing data ontology with respect to data properties, contents, QoS, and biomedical regulations and expanding service ontology to describe more functional and QoS specifications supported by services, appropriate services for processing biomedical multimedia data may be discovered, performed, tuned up or replaced as needed. Additionally, six transmission services are introduced to support dynamic adaptation under specific requirements.",data oriented architecture,811
b50b7b84df434ae9ef4f7f0c57cbb43916dfc6a7,filtered,semantic_scholar,IEEE Transactions on Industrial Informatics,2021-01-01,semantic_scholar,an overview of recent advances in coordinated control of multiple autonomous surface vehicles,https://www.semanticscholar.org/paper/b50b7b84df434ae9ef4f7f0c57cbb43916dfc6a7,"Autonomous surface vehicles (ASVs) are marine vessels capable of performing various marine operations without a crew in a variety of cluttered and hostile water/ocean environments. For complex missions, there are increasing needs for deploying a fleet of ASVs instead of a single one to complete difficult tasks. Cooperative operations with a fleet of ASVs offer great advantages with enhanced capability and efficacy. Despite various application potentials, coordinated motion control of ASVs pose great challenges due to the multiplicity of ASVs, complexity of intravehicle interactions and fleet formation with collision avoidance requirements, and scarcity of communication bandwidths in sea environments. Coordinated control of multiple ASVs has received considerable attention in the last decade. This article provides an overview of recent advances in coordinated control of multiple ASVs. First, some challenging issues and scenarios in motion control of ASVs are presented. Next, coordinated control architecture and methods of multiple ASVs are briefly discussed. Then, recent results on trajectory-guided, path-guided, and target-guided coordinated control of multiple ASVs are reviewed in detail. Finally, several theoretical and technical issues are suggested to direct future investigations including network-based coordination, event-triggered coordination, collision-free coordination, optimization-based coordination, data-driven coordination of ASVs, and task-region-oriented coordination of multiple ASVs and autonomous underwater vehicles.",data oriented architecture,812
9884653e7a961a602858884858e821ece17e0e13,filtered,semantic_scholar,ICSOFT,2010-01-01,semantic_scholar,an approach to data-driven adaptable service processes,https://www.semanticscholar.org/paper/9884653e7a961a602858884858e821ece17e0e13,"Within the currently forming pervasive computing environment, services and information sources thrive. Instantiations of the service oriented computing paradigm, e.g. Web, Peer-to-Peer (P2P) and Grid services, are continuously emerging, whilst information can be collected from several information sources, e.g. materializations of the Web 2.0 and Web 3.0 trends, Social Networking apps and Sensor Networks. Within this context the development of adaptable service oriented processes utilizing heterogeneous services, in addition to available information, is an emerging trend. This paper presents an approach and an enabling architecture that leverage the provision of data-driven, adaptable, heterogeneous service processes. Core within the proposed architecture is a set of interacting components that accommodate the acquisition of information, the execution of service chains and their adaptation, based on collected information.",data oriented architecture,813
10a1b9d832fec5a034054b6248be5206ac0199ac,filtered,semantic_scholar,,2007-01-01,semantic_scholar,rationale for and design of a generic tiled hierarchical phased array beamforming architecture,https://www.semanticscholar.org/paper/10a1b9d832fec5a034054b6248be5206ac0199ac,"The purpose of the phased array beamforming project is to develop a generic flexible efficient phased array receiver platform, using a mixed signal hardware/software-codesign approach. The results will be applicable to any radio (RF) system, but we will focus on satellite receiver (DVB-S) and radar applications. We will present a preliminary mapping of beamforming processing on a tiled architecture and determine its scalability.

The functionality, size and cost constraints imply an integrated mixed signal CMOS solution. For a generic flexible multi-standard solution, a software defined radio approach is taken. Because a scalable and dependable solution is needed, a tiled hierarchical architecture is proposed with reconfigurable hardware to regain flexibility. A mapping is provided of beamforming on the proposed architecture. The advantages and disadvantages of each solution are discussed with respect to applicability and scalability.

Different beamforming processing solutions can be mapped on the same proposed tiled hierarchical architecture. This provides a flexible, scalable and reconfigurable solution for a wide application domain. Beamforming is a data-driven streaming process which lends itself well for a regular scalable architecture. Beamsteering on the other hand is much more control-oriented and future work will focus on how to support beamsteering on the proposed architecture as well.",data oriented architecture,814
c05d30af61f3442c6d333a018b961695ef7bb04b,filtered,semantic_scholar,SAG,2005-01-01,semantic_scholar,"scientific applications of grid computing, first international workshop, sag 2004, beijing, china, september 20-24, 2004, revised selected and invited papers",https://www.semanticscholar.org/paper/c05d30af61f3442c6d333a018b961695ef7bb04b,"Data-Based Applications.- to OGSA-DAI Services.- Using OGSA-DQP to Support Scientific Applications for the Grid.- Mobile Agent-Based Service Provision in Distributed Data Archives.- A Proxy Service for the xrootd Data Server.- A Flexible Two-Level I/O Architecture for Grids.- Data Driven Infrastructure and Policy Selection to Enhance Scientific Applications in Grid.- BioApplications.- Modelling a Protein Structure Comparison Application on the Grid Using PROTEUS.- Grid Services Complemented by Domain Ontology Supporting Biomedical Community.- Applications Architecture, Frameworks and Models.- A Generic Architecture for Sensor Data Integration with the Grid.- Embarrassingly Distributed and Master-Worker Paradigms on the Grid.- A Framework for the Design and Reuse of Grid Workflows.- Towards Peer-to-Peer Access Grid.- A Service Oriented Architecture for Integration of Fault Diagnostics.- GAM: A Grid Awareness Model for Grid Environments.- Accounting and Market-Based Architecture.- Grid Accounting Service Infrastructure for Service-Oriented Grid Computing Systems.- Mercatus: A Toolkit for the Simulation of Market-Based Resource Allocation Protocols in Grids.- Resource and Information Management in Grid.- A Resource Monitoring and Management Middleware Infrastructure for Semantic Resource Grid.- A Service-Oriented Framework for Traffic Information Grid.",data oriented architecture,815
8e60928342ee18517ac7221c841173a2d91c0bb7,filtered,semantic_scholar,VDM Europe,1987-01-01,semantic_scholar,a formal description of object-oriented programming using vdm,https://www.semanticscholar.org/paper/8e60928342ee18517ac7221c841173a2d91c0bb7,"In this paper we present a formal definition of an object-oriented environment using the specification language VDM [1]. Object-oriented architectures have been of considerable importance in the Artificial InteIligence community [2,3,4] and are of increasing importance in a wider software engineering context [5]. The principal concepts to be defined are those of inheritance and message passing. Smalltalk [5] has a particular architecture which has gained immense popularity. Here we present an environment derived from the Smalltalk architecture, which is simpler but sufficiently powerful to support real applications and has the merit of having been given a concise formal specification. We begin by giving an example of using an object-oriented class hierarchy to describe a simple network of nodes containing data. Then we present a VDM specification of a class hierarchy with a particular model of inheritance. We discuss the facility of passing messages between objects in the class hierarchy as a means of maintaining constraints on the data in our example network. Equipped with the full power of inheritance and message passing, we give examples of propagating constraints through the network in the styles of demand and data driven programming. When presenting the specifications we will assume that the reader has prior knowledge of VDM. Finally, we discuss how the use of formal specification has allowed us to iterate upon the design of this particular object-oriented facility and how we have validated the design by turning the specification into a prototype using the me too method [6,7]. The software specified in this paper has eventually been implemented in LISP and is being used for the development of some business applications. We comment briefly on these matters.",data oriented architecture,816
33564d53a82a45f74a8c9e6cd33f36aceb117e5b,filtered,semantic_scholar,Concurr. Pract. Exp.,1995-01-01,semantic_scholar,programming pipelined cad applications on message-passing architectures,https://www.semanticscholar.org/paper/33564d53a82a45f74a8c9e6cd33f36aceb117e5b,"Programming applications in computer-aided design of VLSI are difficult on parallel architectures, especially pipelined implementations derived from their sequential counterparts by algorithmic partitioning. The difficulty is primarily due to lack of good program development environments and tools. Our solution, applicable to message-passing architectures, is based upon a definition of a broad class of non-linear pipeline configurations and an asynchronous data-driven model for pipeline stage interactions. It provides object-oriented definitions of stages and interconnecting channels. These objects are embedded in C++ so that the correctness of application programs can be tested on a workstation in a simulated environment. The simulation is instrumented to provide data useful in assessing relative computational loading and balancing of stages. Thus a large part of program development can take place in the environment of a workstation familiar to the programmer. A non-trivial application is developed to illustrate these ideas.",data oriented architecture,817
e40705fe62e4989e9e37be2c33e3913873b2defe,filtered,semantic_scholar,Proceedings Fifth IEEE International Workshop on Computer Architectures for Machine Perception,2000-01-01,semantic_scholar,active computer vision system,https://www.semanticscholar.org/paper/e40705fe62e4989e9e37be2c33e3913873b2defe,"We present a modular architecture for image understanding and active computer vision which consists of the following major components: sensor and actor interfaces required for data-driven active vision are encapsulated to hide machine-dependent parts; image segmentation is implemented in object-oriented programming as a hierarchy of image operator classes, guaranteeing simple and uniform interfaces. We apply this architecture to appearance-based object recognition. This is used for an autonomous mobile service robot which has to locate objects using visual sensors.",data oriented architecture,818
100aa77d828b3cacc421ae0342fbaf4bff2bb952,filtered,semantic_scholar,International Workshop on Innovative Architecture for Future Generation High-Performance Processors and Systems,2002-01-01,semantic_scholar,a networking oriented data-driven processor: cue,https://www.semanticscholar.org/paper/100aa77d828b3cacc421ae0342fbaf4bff2bb952,"This paper presents the CUE (coordinating users' requirements and engineering constraints) processor architecture as a networking oriented processor architecture to efficiently execute media processing and protocol processing in real time. The CUE processor is a chip multiprocessor based on a dynamic data-driven scheme to exploit various levels of parallelism in problems naturally and efficiently. Since it can simultaneously execute multiple processes as long as sufficient pipeline resources are available, it can perform real-time processing without runtime overheads. Experimental results for a data-driven implementation of protocol processing in CORBA (Common Object Request Broker Architecture) demonstrate the efficiency of the real-time processing scheme. In addition, through the evaluation results of data-driven implementation of protocol and media processing, this paper re-examines heterogeneous multiprocessor configurations, instruction sets, packet formats, and the sequential processing scheme of the CUE processor.",data oriented architecture,819
2780780d866ea58b79c5526f3f1d20c56d4d4268,filtered,semantic_scholar,ICVS,1999-01-01,semantic_scholar,active knowledge-based scene analysis,https://www.semanticscholar.org/paper/2780780d866ea58b79c5526f3f1d20c56d4d4268,"We present a modular architecture for image understanding and active computer vision which consists of three major components: Sensor and actor interfaces required for data-driven active vision are encapsulated to hide machine-dependent parts; image segmentation is implemented in object-oriented programming as a hierarchy of image operator classes, guaranteeing simple and uniform interfaces; knowledge about the environment is represented either as a semantic network or as statistical object models or as a combination of both; the semantic network formalism is used to represent actions which are needed in explorative vision. 
 
We apply these modules to create two application systems. The emphasis here is object localization and recognition in an office room: an active purposive camera control is applied to recover depth information and to focus on interesting objects; color segmentation is used to compute object features which are relatively insensitive to small aspect changes. Object hypotheses are verified by an A*-based search using the knowledge base.",data oriented architecture,820
12927b26339410d407fbb6b4d9a320b0fff69c28,filtered,semantic_scholar,Prod. Eng.,2018-01-01,semantic_scholar,a novel approach for data-driven process and condition monitoring systems on the example of mill-turn centers,https://www.semanticscholar.org/paper/12927b26339410d407fbb6b4d9a320b0fff69c28,"Implementing condition monitoring functionality in production machinery often proves to be a difficult task. Device- and process-specific algorithms must be created while inhomogeneous industrial communication networks hinder the aggregation of control signals and process variables. Further challenges arise from the advance of flexible cyber-physical systems (CPS) and the industrial internet of things (IIoT). They demand a service-oriented condition monitoring architecture, which seamlessly adapts to quickly changing production topologies. In this context, data-driven systems which are capable of unsupervised learning are promising approaches. The aim is the autonomous identification of significant process variables and patterns. This paper describes a machine learning approach for a condition and process monitoring system on the basis of pattern recognition within structure-borne noise of rotating cutting machinery. Process states are defined under application of non-negative matrix factorization (NMF). A production model is learned and deployed on the basis of Gaussian mixture models (GMM) and hidden Markov models (HMM) in a two stage process. Additionally a generic framework to ease the implementation of decentralized condition monitoring functionalities is given. A decentralized component, the monitoring module, constitutes a part of a holistic condition monitoring architecture managed by a central server. The approach is evaluated on the example of mill-turn centers.",data oriented architecture,821
3cc9cc167905f2bd0f12fc310acb0bbf8df4c3ab,filtered,semantic_scholar,SIAP,2012-01-01,semantic_scholar,service-oriented dynamic data driven application systems to urban traffic management in resource-bounded environment,https://www.semanticscholar.org/paper/3cc9cc167905f2bd0f12fc310acb0bbf8df4c3ab,"With advance in distributed system technology, data has become ubiquitous and its dynamics has increased. Therefore, in this paper we proposed a new framework to integrate dynamic data driven application systems (DDDAS) with service-oriented architecture (SOA) and web services technology to tackle dynamic data issue in a real-time and resource-bounded environment. Nowadays, traffic management in Intelligent Transportation Systems (ITS) has been widely developed in major cities' urban areas around the world to provide more efficient way for solving traffic congestion problem. However, the problems in dynamic traffic management systems such as system flexibility, data standard common interface, transmission of required information, prediction performance, and real-time measurement data are all important issues but not totally supported. An efficient and effective service-oriented dynamic data-driven framework algorithm is designed in this paper to support prediction strategies for traffic management. The simulation results of vehicle navigation show that our algorithm outperforms the Dijkstra algorithm by improving 24.43% in average vehicle travelling time. On the other hand, the results of traffic signal control also show that our algorithm improves the performance in vehicles average number of stops by 43.7%, and 70.62% in average delay time that is compared with the fixed time control method.",data oriented architecture,822
be954c909c33dde1b20b5683341b88b85d8a1b2d,filtered,semantic_scholar,IEEE Computational Intelligence Magazine,2020-01-01,semantic_scholar,enabling computational intelligence for green internet of things: data-driven adaptation in lpwa networking,https://www.semanticscholar.org/paper/be954c909c33dde1b20b5683341b88b85d8a1b2d,"With the exponential expansion of the number of Internet of Things (IoT) devices, many state-of-the-art communication technologies are being developed to use the lowerpower but extensively deployed devices. Due to the limits of pure channel characteristics, most protocols cannot allow an IoT network to be simultaneously large-scale and energy-efficient, especially in hybrid architectures. However, different from the original intention to pursue faster and broader connectivity, the daily operation of IoT devices only requires stable and low-cost links. Thus, our design goal is to develop a comprehensive solution for intelligent green IoT networking to satisfy the modern requirements through a data-driven mechanism, so that the IoT networks use computational intelligence to realize self-regulation of composition, size minimization, and throughput optimization. To the best of our knowledge, this study is the first to use the green protocols of LoRa and ZigBee to establish an ad hoc network and solve the problem of energy efficiency. First, we propose a unique initialization mechanism that automatically schedules node clustering and throughput optimization. Then, each device executes a procedure to manage its own energy consumption to optimize switching in and out of sleep mode, which relies on AI-controlled service usage habit prediction to learn the future usage trend. Finally, our new theory is corroborated through real-world deployment and numerical comparisons. We believe that our new type of network organization and control system could improve the performance of all green-oriented IoT services and even change human lifestyle habits.",data oriented architecture,823
6f8157d52d07286c18c4d72dcd15bf035683a4b6,filtered,semantic_scholar,Sensors,2018-01-01,semantic_scholar,a robust predicted performance analysis approach for data-driven product development in the industrial internet of things,https://www.semanticscholar.org/paper/6f8157d52d07286c18c4d72dcd15bf035683a4b6,"Industrial Internet of Things (IoT) is a ubiquitous network integrating various sensing technologies and communication technologies to provide intelligent information processing and smart control abilities for the manufacturing enterprises. The aim of applying industrial IoT is to assist manufacturers manage and optimize the entire product manufacturing process to improve product quality and production efficiency. Data-driven product development is considered as one of the critical application scenarios of industrial IoT, which is used to acquire the satisfied and robust design solution according to customer demands. Performance analysis is an effective tool to identify whether the key performance have reached the requirements in data-driven product development. The existing performance analysis approaches mainly focus on the metamodel construction, however, the uncertainty and complexity in product development process are rarely considered. In response, this paper investigates a robust performance analysis approach in industrial IoT environment to help product developers forecast the performance parameters accurately. The service-oriented layered architecture of industrial IoT for product development is first described. Then a dimension reduction approach based on mutual information (MI) and outlier detection is proposed. A metamodel based on least squares support vector regression (LSSVR) is established to conduct performance prediction process. Furthermore, the predicted performance analysis method based on confidence interval estimation is developed to deal with the uncertainty to improve the robustness of the forecasting results. Finally, a case study is given to show the feasibility and effectiveness of the proposed approach.",data oriented architecture,824
e711dba759f242847ca4f43c24c1d8fb4a2e1c92,filtered,semantic_scholar,Proceedings 2001 IEEE International Symposium on Computational Intelligence in Robotics and Automation (Cat. No.01EX515),2000-01-01,semantic_scholar,"intelligent robot system using ""model of knowledge, emotion and intention"" and ""information sharing architecture""",https://www.semanticscholar.org/paper/e711dba759f242847ca4f43c24c1d8fb4a2e1c92,"Japan has become a highly aged society. Therefore, realization of welfare support systems which use human-friendly-robots technology is desired. We intend to construct a robot system which provides welfare support. These systems must understand a human's desire and share with other robot system's knowledge because these systems have plural robots. Therefore, we fuse two functions in the paper. (1) The model of knowledge, emotion and intention which creates robot action by human directions. (2) The information sharing architecture which uses Soft DNA (soft computing oriented data driven functional scheduling architecture) and ontology for construction of these systems.",data oriented architecture,825
30b93606b582f22abee447947ca9255420ab07e2,filtered,semantic_scholar,,2001-01-01,semantic_scholar,high performance mass storage and parallel i/o: technologies and applications,https://www.semanticscholar.org/paper/30b93606b582f22abee447947ca9255420ab07e2,"From the Publisher: 
The definitive roadmap through the complex and fast-growing field of high performance I/O architecture 
Todays data-driven high performance computer technologies demand reliable delivery systems that combine high-level computing, storage, I/O, and network communication performance. Due to the growth of Internet-driven applications like digital libraries, virtual laboratories, video on demand, e-commerce, web services, and collaborative systems, issues such as storage capacity and access speed have become critical in the design of todays computer systems. 
High Performance Mass Storage and Parallel I/O fills the need for a readily accessible single reference source on the subject of high performance, large-scale storage and delivery systems, specifically the use of Redundant Arrays of Inexpensive Disks (RAID) that are accessed using parallel input/output (I/O) architecture. The authors, all internationally recognized experts in the field, have combined the best of the current literature on the subject with important information on emerging technologies and future trends. 
Topics covered include: 
Redundant disk array Architecture 
Fault Tolerance Issues in Disk Arrays 
Caching and Prefetching 
Parallel File and I/O Systems 
Emerging Technologies and Future Trends 
 
 
A valuable resource for both students of computer technology and professionals in the field, High Performance Mass Storage and Parallel I/O delivers state-of-the-art information that will help todays system designers and application developers meet the increasing demand for high-performance, large-scale storage systems. 
Author Biography: HAI JIN is a professor of computer science at Huazhong University of Science and Technology, Wuhan, China. He holds both a B.A. and M.S. degree in computer science, and a Ph.D. in electrical and electronics engineering from the same University. He is currently a postdoctoral fellow in the Department of Electrical and Electronics Engineering at the University of Hong Kong in addition to being a visiting scholar at the Internet and Cluster Computing Laboratory at the University of Southern California. Dr. Jin has coauthored three books and published more than 50 papers in international journals and conferences. 
TONI CORTES is an associate professor at Universitat Politecnica de Catalunya, Barcelona, Spain. He obtained his M.S. and Ph.D. degrees in computer science at the same university, and is currently the coordinator of the single-system image technical area in the IEEE Task Force on Cluster Computing (TFCC). Dr. Cortes has also been working on several European industrial projects and has published more than 15 papers in international journals and conferences. RAJKUMAR BUYYA is Co-Chair of the IEEE Task Force on Cluster Computing and an international speaker in the IEEE Computer Society Chapter Tutorials Program. Currently at Monash University, Melbourne, Australia, he is conducting R&D on the use of an economics paradigm for peer-to-peer and grid-based service-oriented computing. He has co-authored Microprocessor x86 Programming and Mastering C++, and edited a popular two-volume book on high performance cluster computing. He has published over 50 research articles in major international journals and conferences.",data oriented architecture,826
6eafeb07023b34b350c75d40648918bfa9f112d2,filtered,semantic_scholar,ICTC 2011,2011-01-01,semantic_scholar,distributed mobility control for mobile-oriented future internet environments,https://www.semanticscholar.org/paper/6eafeb07023b34b350c75d40648918bfa9f112d2,"Ever-increasing demand of mobile Internet traffics makes mobile networks change from hierarchical architecture to flat architecture. Most of the current mobility protocols are based on a centralized mobility anchor, by which all the control and data traffics are processed. In the flat network architecture, however, the centralized mobility scheme has some limitations, which include unwanted traffic flowing into core network, service degradation by a point of failure, and increased operational costs, etc. In this paper, we propose the three distributed mobility control schemes for flat architecture of future mobile networks: Partially Distributed Mobility Control (PDMC), Data-driven Distributed Mobility Control (DDMC), and Signal-driven Distributed Mobility Control (SDMC). By numerical analysis, we compare the proposed distributed mobility schemes with the existing centralized mobility scheme using Proxy Mobile IPv6 (PMIP) in terms of binding update and packet delivery costs. From the results, it is shown that the three proposed distributed schemes give better performance than the existing centralized PMIP scheme, and the SDMC scheme provides the best performance among the three proposed distributed schemes.",data oriented architecture,827
403bab59aead2bd21705c51229076faca3e7dc70,filtered,semantic_scholar,TOIT,2014-01-01,semantic_scholar,web service compositions with fuzzy preferences: a graded dominance relationship-based approach,https://www.semanticscholar.org/paper/403bab59aead2bd21705c51229076faca3e7dc70,"Data-driven Web services build on service-oriented technologies to provide an interoperable method of interacting with data sources on top of the Web. Data Web services composition has emerged as a flexible solution to answer users’ complex queries on the fly. However, as the number of Web services on the Web grows quickly, a large number of candidate compositions that would use different (most likely competing) services may be used to answer the same query. User preferences are a key factor that can be used to rank candidate services/compositions and retain only the best ones. In this article, we present a novel approach for computing the top-k data service compositions based on user preferences. In our approach, we model user preferences using fuzzy sets and incorporate them into the composition query. We use an efficient RDF query rewriting algorithm to determine the relevant services that may be used to answer the composition query. We match the (fuzzy) constraints of the relevant services to those of the query and determine their matching degrees using a set of matching methods. We then rank-order the candidate services based on a fuzzification of Pareto dominance and compute the top-k data service compositions. In addition, we introduce a new method for increasing the diversity of returned top-k compositions while maintaining as much as possible the compositions with the highest scores. Finally, we describe the architecture of our system and present a thorough experimental study of our proposed techniques and algorithms. The experimental study demonstrates the efficiency and the effectiveness of our techniques in different settings.",data oriented architecture,828
9c7fe9f8ea4626717a427286f7928ee2cf021563,filtered,semantic_scholar,2013 IEEE Ninth World Congress on Services,2013-01-01,semantic_scholar,a dataflow language for decentralised orchestration of web service workflows,https://www.semanticscholar.org/paper/9c7fe9f8ea4626717a427286f7928ee2cf021563,"Orchestrating centralised service-oriented workflows presents significant scalability challenges that include: the consumption of network bandwidth, degradation of performance, and single points of failure. This paper presents a high-level dataflow specification language that attempts to address these scalability challenges. This language provides simple abstractions for orchestrating large-scale web service workflows, and separates between the workflow logic and its execution. It is based on a data-driven model that permits parallelism to improve the workflow performance. We provide a decentralised architecture that allows the computation logic to be moved ""closer"" to services involved in the workflow. This is achieved through partitioning the workflow specification into smaller fragments that may be sent to remote orchestration services for execution. The orchestration services rely on proxies that exploit connectivity to services in the workflow. These proxies perform service invocations and compositions on behalf of the orchestration services, and carry out data collection, retrieval, and mediation tasks. The evaluation of our architecture implementation concludes that our decentralised approach reduces the execution time of workflows, and scales accordingly with the increasing size of data sets.",data oriented architecture,829
39aa0f5424b2c7e7fbac8196da22f012f5bd9153,filtered,semantic_scholar,,2010-01-01,semantic_scholar,implementation of building information modeling in architectural firms in india,https://www.semanticscholar.org/paper/39aa0f5424b2c7e7fbac8196da22f012f5bd9153,"Building Information Modeling (BIM) is an integrated process of generating and managing a building by exploring a digital model before the actual project is constructed and later during its construction, facility operation and maintenance. BIM has been adopted by construction contractors and architects in United States (US) and United Kingdom (UK) to improve the planning and management of construction projects. On the contrary, Indian contractors seem to have made a head-start by using BIM in their projects, but the architects in the nation have still not embraced this new thinking and technology as a part of their way of working. Since BIM is not just software but a process, the Indian architectural industry needs to analyze if there is a need to start over with a completely new platform or the same goals can be achieved through a predictable and evolutionary course. This proposal will survey the difficulties faced in implementing BIM in architectural firms in India and, thus, find obstacles in doing the same. By surveying and collecting data about problems faced by these architectural firms, it will be analyzed how to avoid those situations from rising and, thus, introducing BIM capabilities in such firms in the most effective way. Hence, a roadmap for the transitioning steps needs to be formed, defining the expectations such firms should have from this metamorphosis. Since implementing BIM is a business decision, all this calls for the development of a BIM implementation strategy. Aakanksha – Directed Project Report 4 Implementation of Building Information Modeling in Architectural Firms in India Building Information Modeling (BIM) simulates the construction project by creating an accurate virtual model of the building with all its properties. It is the latest generation of object-oriented computer-aided design systems (OOCAD) where intelligent building-objects are combined to form a virtual building. This building information model encompasses the building geometry, spatial relationships, geographic information, and quantities and properties of building components. For almost half a century, the industry used flat 2-dimensional (2D) drawings and later developed 3D parametric technology. The scope of BIM extends beyond 3D, to 4D where the aspect of time is added to form schedules and to 5D where the cost component helps create estimates. Even the 6D aspect with project controls and life-cycle management is being developed, but nothing substantial with a good BIM workflow has been established yet. For these added-values to the project, all the user needs to do is to input the data for families, components, etc., hence, building the model using intelligent materials. BIM is one of the most promising developments in the recent years in the architecture, engineering, construction, and facility management (AECFM) industry. It has been heard of and researched upon a lot in the past decade. The integrated database allows everyone involved in the building lifecycle (that includes architects, engineers, contractors, developers, and building owners) to collocate together, allowing them to view the model in different ways, and impeccably share information. Orthographic views, quantity surveying, various performance and design analyses, fabrication inputs and rationalization, supply chain integration are just few of the deliverable products one can expect from this powerful tool which completely transforms the business. Aakanksha – Directed Project Report 5 Most BIM users today utilize it for visualization in design and documentation of the design. Data-driven analysis as the second phase is being experimented with and is yet not smoothly integrated. The last phase includes simulations where BIM imitates the characteristics of the physical system i.e. the construction project, for optimization, engineering, testing and gaining insight into the functioning. Hence, BIM not only helps in better visualization, but is also a catalyst of a new and better process in the design and construction industry, which attempts to improvise the functioning within the project team. The transformation in the workflow of an AEC team brought about by BIM needs to be actively monitored rather than handled impromptu. BIM implementation in an architectural firm is comparable to a new technology’s pursuit in any office, which requires an implementation strategy. But these process-improvement efforts should start with a conscious decision to develop optimal and not just favorable work processes. The consideration of technology should not be deferred till the end, until after the process is designed, looking at it just as a support. This process defers consideration and analyses of various processes related to the technology, thus, leading to mere automation of the old way of working. Hence, the technology should be tapped to do things not done presently. CAD files constitute of raw data, where the facts need to be inferred by the user for understanding the relevance and meaning. This is where BIM is a step ahead of CAD. It provides all information about the elements as they are simulations of actual building components because of element’s relevance to other elements and meaning and function being embedded within. This inclusion radically improves the collaboration in the design and construction team by a widely-shared knowledge and information base. Due to Aakanksha – Directed Project Report 6 sudden increase in the type and number of specialists involved with a building project today, the feedback from these to the designer has greatly suffered. The coordination occurring only at discrete points, with varying frequencies and discontinuities, causes lots of errors and rework that beleaguer the whole process finally leading to fragmentation and related overhead costs. BIM tools can feed these data into the integrated model in parallel to the design process drastically increasing the speed, accuracy and quality of the output. These add-ons available simultaneously can serve as an aid of the design, rather than surface later to repair it, thus helping cut down on time and money wasted in the latter mode. The BIM tools serve as omnipresent consultants and help designers make decisions faster, based on quicker comparisons and analyses provided within hours, instead of days taken for feedback by traditional consultants. BIM takes an understanding of both the industry and the technology to leverage its full potential. To ensure integrated delivery, the BIM generated simulation must be digital, spatial, measurable, comprehensive, accessible and durable. Presently, no software uses all these characteristics and it may take several years to develop one. But the software applications being used for BIM all over the world (for instance: Autodesk Revit, Autodesk Navisworks, Graphisoft ArchiCAD) currently use a combination of the above mentioned characteristics. Though BIM is currently being employed by professionals on all building types from the simplest warehouse to many of the most complex new buildings, BIM design method is currently young in its development. Aakanksha – Directed Project Report 7 Summary Problem Statement Designers all over the world are implementing BIM as a new technology in their firms, while their Indian counterparts are not tapping the true potential of BIM tools and using them for visualizations and walkthroughs (Autodesk, 2005). This neither implies that the Indian designers are ignorant of BIM and its ability, nor does it exhibit a dearth of skilled BIM users in the Indian AEC industry. In fact, there is lot of outsourcing of full range of BIM services by development centers in India, delivering built environments for projects designed in US, UK and European countries, thus, helping them steer clear of huge delays, major cost overruns, clashes detected on site, etc. AEC firms in US, UK and European countries are utilizing the Indian talent. These firms are enjoying the benefits of not only the cost effective production but the expertise that India has developed in over 2 decades of experience. (PRLog, 2007) Indian architects are suddenly designing complex and multifarious projects. There is a need for direction of development, integration of information technology and business processes for simulation, coordination, communication and knowledge sharing to support design and construction. Currently, there is no clear consistency about the process of implementation or usage of BIM anywhere in the world. Even the Associated General Contractors (AGC) of America realizes that there is an absence of a single document that instructs application of BIM in firms. Several software firms are trying to cash-in on the new inquisitiveness for BIM and have developed programs to address certain aspects of BIM technology, but none of them treat it as a process of transformation. This fact brings forward the need to standardize and create guidelines for the implementation of BIM process in the global context. Aakanksha – Directed Project Report 8 Significance Architecture is a profitable business in India, which has a diverse client base (Autodesk, 2005). Staff is well trained and all systems and processes are consistent with global best practices. In the past decade, India's hunger for IT parks, mega-malls, and huge residential communities became insatiable and, hence, architects designed supersize projects dreamed up by Indian developers. India is a developing country and there is still a shortage of housing and office space. There is also a shortage of just about every kind of infrastructure for the huge population and growth in every sector (Autodesk, 2005). And thus, there is lot of planning and construction in full swing. India has a large and relatively inexpensive labor pool which decreases the value of productivity improvements that BIM offers. Lower cost of workers has discouraged efforts to replace field labor with automated solutions",data oriented architecture,830
b50d46088bfa144b3542acc60919500680e7cc53,filtered,semantic_scholar,,2000-01-01,semantic_scholar,information extraction from the web,https://www.semanticscholar.org/paper/b50d46088bfa144b3542acc60919500680e7cc53,The goal of information extraction from the Web is to provide an integrated view on data from autonomous heterogeneous information sources The main problem with current wrap per mediator approaches is that they rely on very di erent formalisms and tools for wrappers and mediators thus leading to an impedance mismatch between the wrapper and mediator level Additionally most approaches nowadays are restricted to access information only from a xed set of sources On the other hand generic Web querying approaches are restricted to pure syntactical and structural queries and do not deal with semantical issues In this paper we discuss an integrated architecture for Web exploration wrapping media tion and querying Our system is based on a uni ed framework i e data model and language in which all tasks are performed We regard the Web and its contents as a unit represented in an object oriented data model the Web structure given by its hyperlinks the parse trees of Web pages and its contents are all included in the internal world model of the system The advantage of this uni ed view is that the same data manipulation and querying language can be used for the Web structure and the application level model The model is complemented by a rule based object oriented language which is extended by Web access capabilities and structured document analysis Thus accessing Web pages wrapping mediating and querying information can be done using the same language This integration also allows for data driven Web exploration which is independent from a given network of individual prede ned wrappers and mediators Thus in addition to the classical wrapper and mediator functionality a system with this architecture can be equipped with Web navigation and exploration functionality Queries to existing Web indexing and searching engines can also be integrated In particular we present a methodology for reusing generic rule patterns for typical extrac tion integration and restructuring tasks using this framework In an abstract sense the system contains a universal wrapper which can be applied to arbitrary Web pages that the system learns about during information processing Equipped with suitably intelligent rules the sys tem can potentially explore initially unknown parts of the Web thus coping with the steady growth of the Web We show the practicability of our approach by using the Florid system HKL The approach is illustrated by two case studies,data oriented architecture,831
63e99795d535c1371b6c6689c0e374a91a80c97b,filtered,semantic_scholar,INLG,1998-01-01,semantic_scholar,communicative goal-driven nl generation and data-driven graphics generation: an architectural synthesis for multimedia page generation,https://www.semanticscholar.org/paper/63e99795d535c1371b6c6689c0e374a91a80c97b,"In this paper we presen t a system for automatically producing multimedia pages of information that draws both from results in data-driven aggregation in information visualization and from results in communicative-goal oriented natural language generation. Our system constitutes an architectural synthesis of these two directions, allowing a beneficial cross-fertilization of research methods. We suggest that data-driven visualization provides a general approach to aggregation in NLG, and that text planning allows higher user-responsiveness in visualization via automatic diagram design. • 1 I n t r o d u c t i o n In this paper we present one of the most significant system-architectural •results relevant for NLG achieved within the KOMET-PAVE multimedia page generation experiment (GMD-IPSI: 1994-1996). l Based on previous, separate experiences in natural language generation (see: Teich & Bateman 1994, Bateman & Teich 1995) and in automatic diagram design and visualization (see: Htiser, Reichenberger, Rostek & Streitz 1995), the KOMET-PAVE experiment sought to combine NLG and visualization into a single integrated information presentation system capable • of producing effectively designed pages of information analogous to 'overviews' found in print-based publications such as encyclopediae or magazines. During this work, it became evident that there were significant overlaps both in the processes and organizations of data most supportive of information presentation. Moreover, the individual approaches offered complementary solutions for presentation subproblems that proved independent of the particular presentation modalities for which they were originally developed. A thorough architectural synthesis was therefore strongly indicated. The particular complementarity that provides the focus of the present paper is the following. First, it is widely accepted in both NLG and graphic design that the design decisions adopted must be sensitive not only to communicative purposes and the ""user' but also to contingent and emergent organizational properties of the data. However, the effectiveness of the solutions proposed for these is in complementary distribution across the two modalities. Approaches to respecting communicative purpose are underdeveloped in graphic design, while NLG has powerful techniques for imposing adherence to communicative purpose (e.g., goaldriven text planning); and, similarly, approaches to data-driven organization (i.e., 'aggregation') are comparatively weak in NLG, while automatic visualization now has a range of powerful techniques for identifying emergent organizational properties of large datasets. The architecture constructed in KOMET-PAVE builds on a combination of these individually developed techniques, resulting in a significant 'cross-fertilization' of approaches. • I KOMET ('Knowledge-oriented production of multimodal documents') and PAVE ('Publication and advanced visualization environments') were two departments of the German National Research Center for Information Technology's (GMD) institute for Integrated Publication and Information Systems (IPSI) in Darmstadt that cooperated closely for the work described in this paper. The authors would therefore like to thank all the members of those departments who contributed, and particularly Lothar Rostek, Melina Alexa, Elke Teich, Wiebke M6hr and Klaas Jan Rondhuis. 1 I .1 We organize the discussion as follows. We first introduce the visualization and automatic diagram design methods developed within the PAVE component of our system, drawing explicit attention to the similarities between the decisions made during diagram generation a n d those necessary during NL generation (Section 2). ThisProvides necessary background to our claim that the methods and algorithms developed for visualization can also serve as a general solution to the problem of aggregation in tactical generation (Section 3). We then briefly show the same algorithms at work at the level of text organization, helping to motivate informational structures necessary for constraining page layout and for allocating presentation modalities in the complete page generation scenario (Section 4), We conclude the paper by summarizingthe main points of architectural synthesis that we have pursued and outlining some prominent lines of ongoing work and future development. 2 Automatic Diagram Generation using Dependency Lattices The approach to diagram generation adopted within the KOMET-PAVE experiment has been developed both theoretically and practically. The practical side was originally built as part of an 'Editor's Workbench"" aimed at facilitating the work of an editor preparing large-scale publications such as encyclopediae (Rostek, M t h r & Fischer 1994). A range Of flexible automatic visualisation tools (cf. Reichenberger, Kamps & Golovchinsky 1995, Htiser et al. 1995) were developed in this context. To illustrate our discussions below, we will adopt one trial application domain in which the Editor's Workbench has been used and for which a significant knowledge base has been constructedwthat is, the art and art history domain already used as a basis for NLG in Teich & Bateman (1994) and Bateman & Teich (1995). Typical information maintained by this knowledge base involves information about artists (particularly biographical information such as birthdates, dates of working in particular institutions, date s of movements, works of art created, etc.), details of works of art and art movements, as well as pictures and full text representations of several thousand biographies. Visualization in the context of the Editor's Workbench focused on providing a high degree of control over all the visual aspects of its presentations: including layout of information and diagram design. The particular aim of visualization was to be able to present overviews of datasets rather than elaborating on specifics, and. this required methods for discovering regularities in the data thatcould then be used to motivate particular presentation strategies. The theoretical basis for the methods developed is given in detail in Kamps (1997) and rests on a new application of Formal Concept Analysis (FCA: Wille 1982). We now show briefly how FCA allows theconstruction of dependency lattices that support flexible diagram design. W e adopt as a simple example the set of 'facts' displayed in the following table. These facts • together show the subject areas, institutions, and time periods in which the shown • artists were active. 2 Person gl Gropius g2 Breuer g3 A. Albers g4 J. Albers g5 Moholy-Nagy g6 Hilberseimer Profession Architect Architect Designer Urban Planner Urban Planner Architect School Harvard Harvard Black Mountain College Black Mountain College New Bauhaus Illinois Institute of Technology Workperiod 1937-1951 1937-1946 1933-1949 1933-1949 1937-1938 1938-1967 2.1 Algor i thm for the construction of the concept lattice Dependency lattices represent effectively the functional and set-valued functional dependencies that are established among the domains of a data relation. They can be computed from plain relation tables such as 2The names, institutions, periods, etc. used in this paper are selected primarily for illustrative purposes and should not be taken as reliable statements of art history!",data oriented architecture,832
97b84ee0790d7b3ea56fb0463b13ba32eb7484f7,filtered,semantic_scholar,,1994-01-01,semantic_scholar,a concurrent object-oriented programming language system for highly parallel data-driven computers and its applications,https://www.semanticscholar.org/paper/97b84ee0790d7b3ea56fb0463b13ba32eb7484f7,"With recent developments of highly parallel computers, practical methods for developing programs on such machines become urgent. In this study, we regard our practical concurrent object-oriented programming language as a basic language for highly parallel machines and pursue necessary software approaches to achieving high performance by implementing the language system and developing application programs/parallel algorithms. As for the language system, we propose a language design suitable for parallel execution and implementation schemes that achieve high performance. Our implementation target is a ne-grained data-driven parallel computer, EM-4, developed at Electrotechnical Laboratories. We present and discuss the design of our runtime architecture and optimizing compiler, including reactive representations of objects, e cient management of message bu ers with freelists, interruptible pipelined message sends, plan-do style intermediate code, an e cient implementation scheme for table look-up, and advanced register/storage allocation. As for application programs/parallel algorithms, we present concurrent objectoriented algorithms for highly parallel computers, (e.g., N-body problem) and evaluate them. We have developed a prototype compiler and a runtime system which run the N-body problem program on the real machine, and measured its performance. Performance measurements on EM-4 show that the cost of each remote object-creation and remote message-passing can be, in order, comparable to that of a sequential procedure call and the N -body algorithm based on the concurrent object-oriented models can be executed e ciently for a wide range of N . Our results indicate that the object-oriented concurrent computation models and languages are extremely suitable for realizing practical parallel systems. ANY OTHER IDENTIFYING INFORMATION OF THIS REPORT This report is the author's thesis submitted to the graduate school of the University of Tokyo in partial ful llment of the requirements for the degree of doctor of science in information science. DISTRIBUTION STATEMENT This technical report is available ONLY via anonymous FTP from ftp.is.s.u-tokyo.ac.jp (directory /pub/tech-reports). SUPPLEMENTARY NOTES REPORT DATE April 5, 1994 TOTAL NO. OF PAGES 124 WRITTEN LANGUAGE English NO. OF REFERENCES 37 DEPARTMENT OF INFORMATION SCIENCE Faculty of Science, University of Tokyo 7-3-1 Hongo, Bunkyo-ku Tokyo, 113 Japan A CONCURRENT OBJECT-ORIENTED PROGRAMMING",data oriented architecture,833
484b9dbbf1425957589aed3d42ff9f9c461caa11,filtered,semantic_scholar,2017 IEEE Symposium on Service-Oriented System Engineering (SOSE),2017-01-01,semantic_scholar,soa based integrated software to develop fault diagnosis models using machine learning in rotating machinery,https://www.semanticscholar.org/paper/484b9dbbf1425957589aed3d42ff9f9c461caa11,"Fault detection and diagnostic software (FDDS) supports technicians and engineers to deal with operational matters, in major cases related to complicated systems and advanced technology that require higher performance expectation. Information and communication technologies play an importantrole for implementing efficient maintenance software, therefore, the development of FDDS is posed as an industrial necessity. In case of industrial rotating machinery, data-driven FDDS using available vibration signals, or other related signals monitored from sensors, is currently viewed as an industrial informatics requirement. This paper proposes the application of a Service Oriented Architecture (SOA) to implement an integrated tool for automatically developing and testing machine learning based fault diagnosis models in rotating machinery. As a result, a generic architecture is obtained which is able to build and implement diagnosis models in similar devices or processes. A condition monitoring software application, using the proposed SOA, was implemented in Java and deployed on a computational environment to test its performance in a experimental test bed, under realistic fault mechanical conditions in a gearbox.",data oriented architecture,834
db2623c46b81f6010dcfc97a2f31cc4b3b0541d7,filtered,semantic_scholar,,2005-01-01,semantic_scholar,towards dynamic model driven architectures,https://www.semanticscholar.org/paper/db2623c46b81f6010dcfc97a2f31cc4b3b0541d7,"Scientific applications using data from networks of sensors must be both highly flexible and high performing. A service-oriented architecture makes sense for modelling such applications, but not for implementing them, due to performance issues and architectural mismatch. In this paper we present an architecture that aims at solving these problems. Applications are modelled as services in a service-oriented architecture, mapped to high-performance, data-driven architectures. Each component is a parallel application. This mapping is done using a MDA approach and is changeable at runtime due to a dynamic Architecture Pattern.",data oriented architecture,835
037d455efb951ce03d0fcd73f7dc7a1265691727,filtered,semantic_scholar,2018 Sixth International Conference on Enterprise Systems (ES),2018-01-01,semantic_scholar,specification of a software architecture for an industry 4.0 environment,https://www.semanticscholar.org/paper/037d455efb951ce03d0fcd73f7dc7a1265691727,"Data-driven decision making is at the core of Industry 4.0. This paper describes the specification of a conceptual architecture of a smart system for supporting decision making in the context of disruptive events in manufacturing operations. Following a viewpoint-oriented approach, the proposed architecture identifies the functional components that facilitate decision making and establishes the interfaces between them, demonstrates the information flow within the manufacturing ecosystem for vertical / horizontal integration and establishes the mapping of the functional components to different software containers, execution environments and physical devices.",data oriented architecture,836
147cc4d3e3364bdc525b28138c2da5e8e4a3d017,filtered,semantic_scholar,IEEE Transactions on Information Forensics and Security,2019-01-01,semantic_scholar,calpa-net: channel-pruning-assisted deep residual network for steganalysis of digital images,https://www.semanticscholar.org/paper/147cc4d3e3364bdc525b28138c2da5e8e4a3d017,"Over the past few years, detection performance improvements of deep-learning based steganalyzers have been usually achieved through structure expansion. However, excessive expanded structure results in huge computational cost, storage overheads, and consequently difficulty in training and deployment. In this paper we propose CALPA-NET, a ChAnneL-Pruning-Assisted deep residual network architecture search approach to shrink the network structure of existing vast, over-parameterized deep-learning based steganalyzers. We observe that the broad inverted-pyramid structure of existing deep-learning based steganalyzers might contradict the well-established model diversity oriented philosophy, and therefore is not suitable for steganalysis. Then a hybrid criterion combined with two network pruning schemes is introduced to adaptively shrink every involved convolutional layer in a data-driven manner. The resulting network architecture presents a slender bottleneck-like structure. We have conducted extensive experiments on BOSSBase + BOWS2 dataset, more diverse ALASKA dataset and even a large-scale subset extracted from ImageNet CLS-LOC dataset. The experimental results show that the model structure generated by our proposed CALPA-NET can achieve comparative performance with less than two percent of parameters and about one third FLOPs compared to the original steganalytic model. The new model possesses even better adaptivity, transferability, and scalability.",data oriented architecture,837
26e75fe747ebdad63b29f63a007b5d92a1ce40fa,filtered,semantic_scholar,WOA,2007-01-01,semantic_scholar,simpa-ws: a simple agent-oriented programming model & technology for developing soa & web services,https://www.semanticscholar.org/paper/26e75fe747ebdad63b29f63a007b5d92a1ce40fa,"Service-Oriented Architecture (SOA) is more and more recognised by the industry as the reference blueprint for building inter-operable, distributed enterprise applications based on open standards such as Web Services (WS). In the current state-of-the-art, the programming models for engineering SOA systems proposed by the leading industries are essentially component-based – typically, rooted in object-oriented abstractions and technologies. On the side, such a choice benefits from the well-know advantages of component-based software engineering and from the maturity of the available technologies; on the other, however, the abstraction level provided is inadequate to model some fundamental SOA aspects – such as autonomy, control-uncoupling, data-driven interaction, activities – as firstclass concepts. Such features can be modelled quite naturally by adopting an agent-oriented perspective. In this paper we describe simpA-WS, a Java-based framework for developing SOA/WS applications which adopts an agentoriented programming model based on the general-purpose Agents and Artifacts meta-model (AA we then show how agents and artifacts can be programmed in simpA and how SOA/WS applications can be programmed in simpA-WS; a simple running example is discussed for concreteness.",data oriented architecture,838
0f8c77b44ec46dd1f5aeedfc7343e26ca2ce64be,filtered,semantic_scholar,AI*IA,2007-01-01,semantic_scholar,"ai*ia 2007: artificial intelligence and human-oriented computing, 10th congress of the italian association for artificial intelligence, rome, italy, september 10-13, 2007, proceedings",https://www.semanticscholar.org/paper/0f8c77b44ec46dd1f5aeedfc7343e26ca2ce64be,"Invited Talks.- Learning to Select Team Strategies in Finite-Timed Zero-Sum Games.- Expressive Intelligence: Artificial Intelligence, Games and New Media.- Artificial Ontologies and Real Thoughts: Populating the Semantic Web?.- Knowledge Representation and Reasoning.- Model-Based Diagnosability Analysis for Web Services.- Finite Model Reasoning on UML Class Diagrams Via Constraint Programming.- Model Checking and Preprocessing.- Some Issues About Cognitive Modelling and Functionalism.- Understanding the Environment Through Wireless Sensor Networks.- An Implementation of a Free-Variable Tableaux for KLM Preferential Logic P of Nonmonotonic Reasoning: The Theorem Prover FreeP 1.0.- Ranking and Reputation Systems in the QBF Competition.- A Top Down Interpreter for LPAD and CP-Logic.- Multiagent Systems, Distributed AI.- A Multi-layered General Agent Model.- Goal Generation with Ordered Beliefs.- Verifying Agent Conformance with Protocols Specified in a Temporal Action Logic.- Knowledge Engineering, Ontologies and the Semantic Web.- Harvesting Relational and Structured Knowledge for Ontology Building in the WPro Architecture.- English Querying over Ontologies: E-QuOnto.- Use of Ontologies in Practical NL Query Interpretation.- Machine Learning.- Evolving Complex Neural Networks.- Discovering Relational Emerging Patterns.- Advanced Tree-Based Kernels for Protein Classification.- A Genetic Approach to the Automatic Generation of Fuzzy Control Systems from Numerical Controllers.- Trip Around the HMPerceptron Algorithm: Empirical Findings and Theoretical Tenets.- Instance-Based Query Answering with Semantic Knowledge Bases.- A Hierarchical Clustering Procedure for Semantically Annotated Resources.- Similarity-Guided Clause Generalization.- Structured Hidden Markov Model: A General Framework for Modeling Complex Sequences.- Nearest Local Hyperplane Rules for Pattern Classification.- Natural Language Processing.- The JIGSAW Algorithm for Word Sense Disambiguation and Semantic Indexing of Documents.- Data-Driven Dialogue for Interactive Question Answering.- GlossExtractor: A Web Application to Automatically Create a Domain Glossary.- A Tree Kernel-Based Shallow Semantic Parser for Thematic Role Extraction.- Inferring Coreferences Among Person Names in a Large Corpus of News Collections.- Dependency Tree Semantics: Branching Quantification in Underspecification.- Information Retrieval and Extraction.- User Modelling for Personalized Question Answering.- A Comparison of Genetic Algorithms for Optimizing Linguistically Informed IR in Question Answering.- A Variant of N-Gram Based Language Classification.- Planning and Scheduling.- SAT-Based Planning with Minimal-#actions Plans and ""soft"" Goals.- Plan Diagnosis and Agent Diagnosis in Multi-agent Systems.- Boosting the Performance of Iterative Flattening Search.- Real-Time Trajectory Generation for Mobile Robots.- AI and Applications.- Curricula Modeling and Checking.- Case-Based Support to Small-Medium Enterprises: The Symphony Project.- Synthesizing Proactive Assistance with Heterogeneous Agents.- Robust Color-Based Skin Detection for an Interactive Robot.- Building Quality-Based Views of the Web.- Special Track: AI and Robotics.- Reinforcement Learning in Complex Environments Through Multiple Adaptive Partitions.- Uses of Contextual Knowledge in Mobile Robots.- Natural Landmark Detection for Visually-Guided Robot Navigation.- Real-Time Visual Grasp Synthesis Using Genetic Algorithms and Neural Networks.- Attention-Based Environment Perception in Autonomous Robotics.- A 3D Virtual Model of the Knee Driven by EMG Signals.- Special Track: AI and Expressive Media.- 'O Francesca, ma che sei grulla?' Emotions and Irony in Persuasion Dialogues.- Music Expression Understanding Based on a Joint Semantic Space.- Towards Automated Game Design.- Tonal Harmony Analysis: A Supervised Sequential Learning Approach.- Words Not Cast in Stone.- Special Track: Intelligent Access to Multimedia Information.- Annotations as a Tool for Disclosing Hidden Relationships Between Illuminated Manuscripts.- Mining Web Data for Image Semantic Annotation.- Content Aware Image Enhancement.- Semantic Annotation of Complex Human Scenes for Multimedia Surveillance.- Synthesis of Hypermedia Using OWL and Jess.- NaviTexte, a Text Navigation Tool.- TV Genre Classification Using Multimodal Information and Multilayer Perceptrons.- Posters.- Hierarchical Text Categorization Through a Vertical Composition of Classifiers.- Text Categorization in Non-linear Semantic Space.- A System Supporting Users of Cultural Resource Management Semantic Portals.- Interactive Analysis of Time in Film Stories.- Towards MKDA: A Knowledge Discovery Assistant for Researches in Medicine.- Mobile Robots and Intelligent Environments.- Multi-robot Interacting Through Wireless Sensor Networks.- Design of a Multiagent Solution for Demand-Responsive Transportation.- Planning the Behaviour of a Social Robot Acting as a Majordomo in Public Environments.- Enhancing Comprehension of Ontologies and Conceptual Models Through Abstractions.- Recognizing Chinese Proper Nouns with Transformation-Based Learning and Ontology.- Toward Image-Based Localization for AIBO Using Wavelet Transform.- Crosslingual Retrieval in an eLearning Environment.- Constraint-Based School Timetabling Using Hybrid Genetic Algorithms.",data oriented architecture,839
aeb64e2af3d4a5d45e515d7c41395109ca786a7f,filtered,semantic_scholar,,2017-01-01,semantic_scholar,uncovering flipped-classroom problems at an engineering course on systems architecture through data-driven learning design,https://www.semanticscholar.org/paper/aeb64e2af3d4a5d45e515d7c41395109ca786a7f,"Flipped classroom is a student-centered methodology that can help engineering students to acquire the cross-curricular skills demanded by society. However, its effectiveness relies on the commitment of both instructors and students. In particular, this strategy requires students to work on a number of proposed activities before face-to-face classes. Then, in order to follow the most appropriate path in those classes, instructors need a reliable way to know at which degree their students worked on those proposed activities, what issues they encountered while doing them and which concepts need to be reinforced in class. This paper presents a case study of a flipped-classroom undergraduate engineering course. By using data-driven learning design and learning analytics techniques we show that: (1) by delaying their work on the course activities our students actually drove the course towards the traditional approach; (2) despite directly asking students at the beginning of a face-to-face class might seem to be an appropriate way of getting reliable information about their previous work, it may lead instructors to erroneous conclusions; (3) our students were strongly mark- and deadline-oriented, but even a small grade encouraged them to work on the assignments; (4) the gathering and checking of students’ learning data before the class can help instructors to tailor the lesson design; and (5) if students did not work on pre-class activities, dedicating a small amount of time of the in-class lesson to explain the most difficult concepts can help students to be more efficient with their work, at the cost of losing some of the spirit of the flipped classroom.",data oriented architecture,840
fa2184732b9a20d2afc815bc6ab60e73f62ce094,filtered,semantic_scholar,,2011-01-01,semantic_scholar,data-driven scenario test generation for informationsystems,https://www.semanticscholar.org/paper/fa2184732b9a20d2afc815bc6ab60e73f62ce094,"on the data-driven scenario testing process. The first part of article starts with the general introduction into software testing. After that scenario testing is presented and also relations of scenario testing to functional requirements specifications are pointed out. Model-View-View Model architectural pattern is showed as an ideal candidate of testing friendly architecture of object oriented software system. Second part is devoted to proposal of data-driven scenario testing generation captured via UML notation. Finally, the proposal implementation is described in the context of real world object oriented system. The main goal of this article was to simplify task of testing complex functional user requirements by usage of scenarios in order to be agile enough, cut test preparation time and improve quality of the resulting software product.",data oriented architecture,841
15bfc2f3da21963c5bdf6e859d66a182ae59f32f,filtered,semantic_scholar,Bell Labs Technical Journal,2003-01-01,semantic_scholar,data-driven fault management within a distributed object-oriented oam&p framework,https://www.semanticscholar.org/paper/15bfc2f3da21963c5bdf6e859d66a182ae59f32f,"The design of the Universal Mobile Telecommunications System (UMTS) terrestrial radio access network (UTRAN) radio network controller (RNC) required the integration of hardware and software from multiple vendors and development organizations across a multinational project. The RNC architects, drawing on their experience with previous object-oriented projects, designed an abstract, distributed, object-oriented operations, administration, maintenance, and provisioning (OAM&P) system. A key component is the innovative data-driven fault management (FM) design. It is not just integrated with the devices being controlled; it is integrated into the entire system. FM data is a central project resource used to drive internal error and fault handling, operational state changes, external alarms, and generation of customer documentation. The design takes advantage of well-known commonality and variability design concepts for easy implementation and maintenance. The FM architecture makes the definition of an error, fault, alarm, and fault-handling behavior as simple as adding a row of data. © 2003 Lucent Technologies Inc.",data oriented architecture,842
8ae309e268c677d0d222fbac70d2c8b0c7959ba3,filtered,semantic_scholar,,2008-01-01,semantic_scholar,a network of metadata and web services for integrated coastal zone management,https://www.semanticscholar.org/paper/8ae309e268c677d0d222fbac70d2c8b0c7959ba3,"ABSTRACT Web based tools facilitate intersectoral views of resources by providing for technological solutions of networking and distributed data management in a service oriented architecture, which relies on the ISO standards 19115 for metadata and 19117 for web services. Key features of the described infor-mation infrastructure are a metadata authoring tool, a web portal with detailed discovery interface, where distinct information spaces can be combined for search operations, and workflow embedded mechanisms for metadata production and use. 1. INTRODUCTION The documentation of public geographic and scientific data with standardized metadata is turning into common practice as Spatial Data Infrastructures are being set up on local, regional, national and in-ternational levels to support vertical information flow. PORTER, D.E. et al. (2004), e.g., describe the elements of an estuarine monitoring program as part of a regional coastal observation system that supports the US integrated ocean observing system IOOS. In Europe, the national SDI’s ultimately feed into INSPIRE, the Infrastructure for Spatial InfoRmation in Europe. As outlined by the EURO-PEAN PARLIAMENT AND COUNCIL (2007) this network aims at transparency of information and public access to resources maintained by national spatial data infrastructures. A WORKING GROUP ARCHITECTURE SDI-GERMANY (2007) has put forward the technological concepts and a master plan to implement an appropriate infrastructure in Germany. In addition, several research and devel-opment projects have already been funded to establish a metadata driven information infrastructure for the coastal zone. LEHFELDT, R. et al. (2002) give details on the North Sea and Baltic Sea Coastal Information System NOKIS, which provides a working environment to create metadata appropriate for documentation and data discovery purposes, www.nokis.org. The key issue of this paper is to discuss the basic elements for a network of metadata and web services to disseminate and use coastal infor-mation.",data oriented architecture,843
2705c0ebccb40a11f2d8aec0f5c8e0667741e26f,filtered,semantic_scholar,,2008-01-01,semantic_scholar,acoustic models for posterior features in speech recognition,https://www.semanticscholar.org/paper/2705c0ebccb40a11f2d8aec0f5c8e0667741e26f,"In this thesis, we investigate the use of posterior probabilities of sub-word units directly as input features for automatic speech recognition (ASR). These posteriors, estimated from data-driven methods, display some favourable properties such as increased speaker invariance, but unlike conventional speech features also hold some peculiarities, such that their components are non-negative and sum up to one. State-of-the-art acoustic models for ASR rely on general-purpose similarity measures like Euclidean-based distances or likelihoods computed from Gaussian mixture models (GMMs), hence, they do not explicitly take into account the particular properties of posterior-based speech features. We explore here the use of the Kullback-Leibler (KL) divergence as similarity measure in both non-parametric methods using templates and parametric models that rely on an architecture based on hidden Markov models (HMMs). Traditionally, template matching (TM)-based ASR uses cepstral features and requires a large number of templates to capture the natural variability of spoken language. Thus, TM-based approaches are generally oriented to speaker-dependent and small vocabulary recognition tasks. In our work, we use posterior features to represent the templates and test utterances. Given the discriminative nature of posterior features, we show that a limited number of templates can accurately characterize a word. Experiments on different databases show that using KL divergence as local similarity measure yields significantly better performance than traditional TM-based approaches. The entropy of posterior features can also be used to further improve the results. In the context of HMMs, we propose a novel acoustic model where each state is parameterized by a reference multinomial distribution and the state score is based on the KL divergence between the reference distribution and the posterior features. Besides the fact that the KL divergence is a natural dissimilarity measure between posterior distributions, we further motivate the use of the KL divergence by showing that the proposed model can be interpreted in terms of maximum likelihood and information theoretic clustering. Furthermore, the KL-based acoustic model can be seen as a general case of other known acoustic models for posterior features such as hybrid HMM/MLP and discrete HMM. The presented approach has been extended to large vocabulary recognition tasks. When compared to state-of-the-art HMM/GMM, the KL-based acoustic model yields comparable results while using significantly fewer parameters.",data oriented architecture,844
0d80e3f663d7b7f94dc60159f58357733ee57a93,filtered,semantic_scholar,ECSA Companion,2020-01-01,semantic_scholar,composition algorithm adaptation in service oriented systems,https://www.semanticscholar.org/paper/0d80e3f663d7b7f94dc60159f58357733ee57a93,"Architecting and constructing software systems using Service Oriented Architecture (SOA) is a widely employed paradigm. Application functionality is commonly delivered by composing Internet communicable software components or services. Using SOA, applications are constructed by a well-defined composition process that implements composition logic to meet an application’s functional and non-functional requirements. Various composition techniques have been proposed in the literature, with varying performance guarantees and resource usage. Service composition also has to adapt to unanticipated conditions posed by a highly dynamic environment due to changing services, evolving architectures, and user requirements. Current adaptive methodologies determine a composition technique at design time and adapt selection and binding of service at runtime. In this paper, we propose adaptation of composition techniques for each user request. Our data driven approach selects the best composition technique for a given application dependency graph. It learns adaptation rules from execution data and trades-off resource usage and solution quality of composition techniques.",data oriented architecture,845
1a55bb3c774c33cf4cf97d02316d6b932a756df1,filtered,semantic_scholar,,2014-01-01,semantic_scholar,applying flow-based programming methodology to data-driven applications development for smart environments,https://www.semanticscholar.org/paper/1a55bb3c774c33cf4cf97d02316d6b932a756df1,"This paper describes initial results of applying the Flow-based Programming methodology to developing data-driven applications for smart environments. This paradigm recently gained popularity in creating concurrent data-driven applications in a wider domain of distributed systems. We investigate this approach applied to the smart environment applications domain and compare it to the Object-Oriented approach typically used in the framework of SOA-based middlewares for the Internet of Things. Our preliminary results show that the Flow-based Programming approach leads to a clear transformation of the design architecture into the software implementation, speeds up the development process, and increases code reuse and maintainability. Keywords–Flow-based programming; data flow; data-driven application; smart environment; software engineering.",data oriented architecture,846
2e1f00fff480e568a0575536028efea0e6484cc7,filtered,semantic_scholar,SAC,2011-01-01,semantic_scholar,service-oriented dynamic data driven application systems to potential field method vehicle navigation,https://www.semanticscholar.org/paper/2e1f00fff480e568a0575536028efea0e6484cc7,"With advance in distributed system technology, data has become ubiquitous and its dynamics has increased. Therefore, in this paper we proposed a new framework to integrate dynamic data driven application systems (DDDAS) with service-oriented architecture (SOA) and web services technology to tackle dynamic data issue in a real-time environment. An efficient and effective service-oriented dynamic data-driven framework algorithm is designed to support a prediction strategy for vehicle navigation. The simulation results show that our algorithm outperforms the Dijkstra algorithm by improving 24.43% in average vehicle traveling time.",data oriented architecture,847
a9cd6550a5e4f97917e9858d2a3da8f732e40605,filtered,semantic_scholar,,2003-01-01,semantic_scholar,variation risk management: focusing quality improvements in product development and production,https://www.semanticscholar.org/paper/a9cd6550a5e4f97917e9858d2a3da8f732e40605,"Preface. Figures. Tables. Text Boxes. Nomenclature. Acronyms. 1. Introduction. 1.1. The Competitive Advantage of VRM. 1.2. Guide to Readers. 2. Basics of Variation Risk Management. 2.1. Basic Principles of VRM. 2.1.1. VRM Must Be Holistic. 2.1.2. VRM Must Be Process Oriented. 2.1.3. VRM Must Be Data Driven. 2.2. Variation and Its Impact on Quality. 2.3. Summary. 3. Identification. 3.1. Definition of Key Characteristics and Variation Flowdown. 3.1.1. Key Characteristics. 3.1.2. Variation Flowdown. 3.2. Defining the Scope of the VRM Application. 3.3. Identifying Critical System Requirements. 3.3.1. Identify the Voice of the Customer. 3.3.2. Identify Specifications and Requirements. 3.3.3. Identify Critical System Requirements. 3.4. Identifying System Key Characteristics. 3.4.1. What Is a System Key Characteristic? 3.4.2. Examples of System Key Characteristics. 3.5. Creating the Variation Flowdown. 3.5.1. What Information to Gather. 3.5.2. How to Conduct the Top-Down Process. 3.5.3. How to Conduct the Bottom-Up Process. 3.5.4. How to Conduct and Document the Identification Procedure. 3.6. Summary. 4. Overview of Assessment. 4.1. Assessment during Product Development. 4.2. Assessment during Production. 5. Assessment of Defect Rates. 5.1. Predicting the Frequency of Defects. 5.1.1. Variation Models. 5.1.2. Prediction Tools. 5.2. Estimating the Contributions of Part and Process KCs. 5.2.1. Qualitative Analysis of Variation Contribution. 5.2.2. Quantitative Analysis of Variation Contribution. 5.3. Measuring the Frequency of Defects. 5.4. Measuring the Contributions of Part and Process KCs. 5.5. Summary. 6. Assessment of Cost and Risk. 6.1. Cost and Risk Assessment during Product Development. 6.1.1. Qualitative Assessments. 6.1.2. Step Cost Functions. 6.1.3. Continuous Cost Functions. 6.2. Total Cost of Variation Assessment during Production. 6.2.1. Cost Sources. 6.2.2. Representation of the Total Cost of Variation. 6.2.3. Cost Analysis and Aggregation. 6.3. Summary. 7. Assessment of the Quality Control System. 7.1. QC Plan Maturity. 7.1.1. Detection Capability and Effectiveness. 7.1.2. Diagnosis Capability. 7.1.3. Efficient Resource Utilization. 7.2. QC Location in the Manufacturing Process. 7.3. QC Effectiveness Matrix. 7.4. Summary. 8. Mitigation. 8.1. Mitigation during Product Development and Production. 8.1.1. Mitigation during Product Development. 8.1.2. Mitigation during Production. 8.2. Identifying Mitigation Strategies. 8.2.1. Design Changes. 8.2.2. Manufacturing Process Changes. 8.2.3. Manufacturing Process Improvements. 8.2.4. Monitoring and Controlling Manufacturing Processes. 8.2.5. Testing and Inspection. 8.3. Selecting a Mitigation Strategy. 8.4. Selecting a Project Portfolio. 8.5. Executing Mitigation Strategies. 8.6. Summary. 9. Integration of Variation Risk Management with Product Development. 9.1. Basics of Product Development. 9.1.1. Stage Gate Product Development Process. 9.1.2. VRM during Product Development. 9.1.3. Metrics. 9.2. Requirements Development. 9.3. Concept Development. 9.4. Product Architecture Design. 9.5. System Concept Design. 9.6. Detail Design. 9.7. Product Testing and Refinement. 9.8. Transition to Production. 9.8.1. Handling Customer Complaints. 9.8.2. Wrap-Up. 9.8.3. Documenting the Key Characteristic Plan. 9.9. Production. 9.9.1. Continually Monitor Total Cost of Variation. 9.9.2. Track Customer Complaint Data. 9.9.3. Review Quality Control Data. 9.9.4. Track Impact of Changes. 9.10. Summary. 10. Roles and Responsibilities in Variation Risk Management. 10.1. Product Development. 10.1.1. The Integrated Product Team Approach. 10.1.2. Expert Teams. 10.1.3. Coaches. 10.2. Production. 10.2.1. Production Teams. 10.2.2. Expert Teams. 10.3. Suppliers' Roles and Responsibilities. 10.3.1. Role of Suppliers during Product Development. 10.3.2. Role of Suppliers during Production. 10.3.3. What Does a KC Mean to a Supplier? 10.4. Summary. 11. Planning and Implementing a Variation Risk Management Program. 11.1. Planning a VRM Program. 11.1.1. Gathering Management Support. 11.1.2. Gathering Organizational Support. 11.1.3. Baselining the Existing VRM Processes. 11.1.4. Formalizing VRM. 11.1.5. Developing KC Tracking Methods. 11.1.6. Identifying Lead Users. 11.1.7. Developing Training Materials. 11.2. Implementing the VRM Program. 11.2.1. Identifying Initial Projects. 11.2.2. Training the Team. 11.2.3. Applying VRM. 11.2.4. Gathering Feedback. 11.3. Summary. 12. Summary. Appendix A: Maturity Models. Appendix B: Process Capability Databases. B.1. Background on Process Capability Data. B.1.1. Importance of Using Process Capability Data. B.1.2. Structure and Content of a Process Capability Database. B.1.3. Difficulties in Implementing Process Capability Databases. B.2. The Right Structure. B.2.1. Designing the Indexing Scheme. B.2.2. Choosing the Database Implementation Approach. B.2.3. Creating the User Interfaces and Data Analysis. B.3. The Right Data. B.4. The Right Management Support. B.5. The Right Usage. B.6. Implementation of a Process Capability Database. B.6.1. Who Should Be Involved. B.6.2. What Decisions Should Be Made. B.6.3. Implementation Steps. B.7. Summary. Appendix C: Other Initiatives. C.1. Six Sigma. C.2. Design for Six Sigma. C.3. Lean Manufacturing. C.4. Continual Improvement, TQM, and Kaizen. C.5. Dimensional Management. C.6. Design for Manufacturing. C.7. Quality Function Deployment (House of Quality). C.8. FMEA. C.9. Summary. Appendix D: Summary of Process Diagrams. Glossary. Bibliography. Index.",data oriented architecture,848
3d3e7d6884b0e34c34627871d7d6b3449e6e4c0f,filtered,semantic_scholar,MODSEC@MoDELS,2008-01-01,semantic_scholar,model driven security management: making security management manageable in complex distributed systems,https://www.semanticscholar.org/paper/3d3e7d6884b0e34c34627871d7d6b3449e6e4c0f,"Today, the challenge in security of complex distributed systems does not anymore lie in encryption or access control of a single middleware platform, but in the protection of the system as a whole. This includes the definition of correct security policies at various abstraction layers, and also in the unified and correct management and enforcement of the correct security policy at all relevant places in the system. The authors have learned in the development even of comparatively simple distributed systems that this is not possible anymore by a manual definition of encryption properties and access control rules. Human security administrators are not able to define all these fine grained rules with sufficient assurance, to distribute them to all Policy Enforcement Points and to check many log files or admin consoles. This is especially impossible in highly distributed and agile service oriented or data driven systems. In this paper we will illustrate the approach and architecture behind Model Driven Security Management and provide a healthcare regulatory compliance case study using our OpenPMF 2.0 technology.",data oriented architecture,849
ce6141a89812338095003cde4f837e252c703b10,filtered,semantic_scholar,,,semantic_scholar,a first-order formalization of knowl- edge and action for a multi-agent planning system. in,https://www.semanticscholar.org/paper/ce6141a89812338095003cde4f837e252c703b10,"(1988). MANDIS/Amoeba: A widely dispersed object-oriented operating system. The contract-net protocol: high-level communication and control in a distributed problem solver. ent cooperation is a considered to be a difficult task (Lesser and Corkill, 1981; Davis and Smith, 1983). CONCLUSIONS Research in cooperation and coordination among independent nodes involves both distributed artificial intelligence, distributed operating systems and studies of cooperation in natural systems. In this paper, we have mainly focused on concepts within DAI. StormCast is a distributed artificial intelligence application for severe storm forecasting (Hartvig-sen and Johansen, 1989) which has functioned as a means of gaining real experience with DAI. In the StormCast project, our main strategy in the design and implementation of the system have been simplification – to keep the design and the source code as simple as possible without main losses in the functionality. The major motivation for this has been the transparency requirements. A modular design together with the utilization of de facto industrial standards has appeared to be sufficient in the task of weather forecasting in a distributed artificial intelligence concept. In addition, through the use of our simplifying approach, we have avoided problems with global state detections, synchronization , etc., which in term influences the transparent view the users have of the application. One of the main problems to face in distributed artificial intelligence applications is the coordination of cooperating nodes. A lot of effort has been spent on the coordination problem, and several approaches to improving coordination among cooperating nodes have been presented. A common denominator for the approach presented seems to be real-time computing, which in our experience is a very resource intensive solution. Therefore, we have used a non real-time approach in order to reduce the complexity, but maintain the functionality. However, even if our choice of system architecture, a data-driven forward-chaining expert system module together with the simple blackboard system (the knowledge layer), has shown some of the possibilities with this kind of application, still much work remain to be done to obtain a commercial application. Further research might include the study of a more complex rule-based expert system that includes both forward and backward chaining, certainty factors, possibly frame-based reasoning, etc., and the diversification of the blackboard in small specialized parts, each guarded by its own monitor. This may in turn increase both the qualitative and the quantitative system performance.",data oriented architecture,850
68fdb331fccc3bc456fc70b548c8389b43a57454,filtered,semantic_scholar,Lecture Notes in Computer Science,2003-01-01,semantic_scholar,computational methods in neural modeling,https://www.semanticscholar.org/paper/68fdb331fccc3bc456fc70b548c8389b43a57454,Biological Models.- Modeling Neuronal Firing in the Presence of Refractoriness.- A Study of the Action Potential Initiation Site Along the Axosomatodendritic Axis of Neurons Using Compartmental Models.- Real Neurons and Neural Computation: A Summary of Thoughts.- Synchronous firing in a population of inhibitory interneurons coupled by electrical and chemical synapses.- Stochastic Networks with Subthreshold Oscillations and Spiking Activity.- Selective Inactivation of Neuronal Dendritic Domains: Computational Approach to Steady Potential Gradients.- Intermittent burst synchronization in neural networks.- Diffusion Associative Network: Diffusive Hybrid Neuromodulation and Volume Learning.- The Minimum-Variance Theory Revisited.- Sleep and wakefulness in the cuneate nucleus: a computational study.- Effiects of different connectivity patterns in a model of cortical circuits.- A Digital Neural Model of Visual Deficits in Parkinson's Disease.- Intersensorial Summation as a Nonlinear Contribution to Cerebral Excitation.- Interacting Modalities through Functional Brain Modeling.- Life-long learning: consolidation of novel events into dynamic memory representations.- Functional Models.- Real-time Sound Source Localization and Separation based on Active Audio-Visual Integration.- Hierarchical Neuro-Fuzzy Systems.- A functional spiking neuron hardware oriented model.- SO(2)-Networks as Neural Oscillators.- A Rotated Kernel Probabilistic Neural Network (RKPNN) for Multi-class Classification.- Independent Residual Analysis for Temporally Correlated Signals.- MLP+H: a Hybrid Neural Architecture Formed by the Interaction of Hopfield and Multi-Layer Perceptron Neural Networks.- Linear unit relevance in multiclass NLDA networks.- Bootstrap for model selection: linear approximation of the optimism.- Learning.- A learning rule to model the development of orientation selectivity in visual cortex.- Sequence learning using the neural coding.- Improved Kernel Learning Using Smoothing Parameter Based Linear Kernel.- Automatic Car Parking: A Reinforcement Learning Approach.- Discriminative Training of the Scanning N-Tuple Classifier.- A Wrapper Approach with Support Vector Machines for Text Categorization.- Robust Expectation Maximization Learning Algorithm for Mixture of Experts.- Choosing among algorithms to improve accuracy.- Evolutionary Approach to Overcome Initialization Parameters in Classification Problems.- Text Categorisation Using a Partial-Matching Strategy.- A new learning method for single layer neural networks based on a regularized cost function.- A better selection of patterns in lazy learning radial basis neural networks.- An Iterative Fuzzy Prototype Induction Algorithm.- A Recurrent Multivalued Neural Network for codebook generation in Vector Quantization.- The recurrent IML-network.- Estimation of Multidimensional Regression Model with Multilayer Perceptrons.- Principal Components Analysis Competitive Learning.- Self-Organizing Systems.- Progressive Concept Formation in Self-organising Maps.- Supervised Classification with Associative SOM.- Neural Implementation of Dijkstra's Algorithm..- Spurious minima and basins of attraction in higher-order Hopfield networks.- Cooperative Co-evolution of Multilayer Perceptrons.- A statistical model of pollution-caused pulmonary crises.- A new penalty-based criterion for model selection in regularized nonlinear models.- Data Driven Multiple Neural Network Models Generator Based on a Tree-like Scheduler.- Performance-Enhancing Bifurcations in a Self-organising Neural Network.- A Competitive Neural Network based on dipoles.- An N-Parallel Multivalued Network: Applications to the Travelling Salesman Problem.- Parallel ACS for weighted MAX-SAT.- Learning to Generate Combinatorial Action Sequences Utilizing the Initial Sensitivity of Deterministic Dynamical Systems.- BICONN: A Binary Competitive Neural Network.- SASEGASA: An Evolutionary Algorithm for Retarding Premature Convergence by Self-Adaptive Selection Pressure Steering.- Cooperative Ant Colonies for Solving the Maximum Weighted Satisfiability Problem.- Designing a Phenotypic Distance Index for Radial Basis Function Neural Networks.- The Antiquadrupolar Phase of the Biquadratic Neural Network.- Co-Evolutionary Algorithm for RBF by Self- Organizing Population of neurons.- Studying the Capacity of Grammatical Encoding to Generate FNN Architectures.- Optimal Phasor Measurement Unit Placement using Genetic Algorithms.- On the Evolutionary Inference of Temporal Boolean Networks.- Specifying evolutionary algorithms in XML.- Analysis of the Univariate Marginal Distribution Algorithm modeled by Markov chains.- Node level crossover applied to neural network evolution.- Genetic Search of Block-Based Structures of Dynamical Process Models.- Visualization of Neural Net Evolution.- Separable Recurrent Neural Networks Treated with Stochastic Velocities.- Studying the Convergence of the CFA Algorithm.- Auto-Adaptive Neural Network Tree Structure Based on Complexity Estimator.- Artificial Intelligence and Cognition.- Intelligence and Computation: A View from Physiology.- Image Understanding analysis at the Knowledge Level as a Design Task.- Morphological Clustering of the SOM for Multi-dimensional Image Segmentation.- Introducing Long Term Memory in an ANN based Multilevel Darwinist Brain.- New Directions in Connectionist Language Modeling.- Rules and Generalization Capacity Extraction from ANN with GP.- Numerosity and the Consolidation of Episodic Memory.- Rule Extraction from a Multilayer Feedforward Trained Network via Interval Arithmetic Inversion.- Necessary First-Person Axioms of Neuroconsciousness.- An Agent Based Approach of Collective Foraging.- Hybrid Architecture Based on Support Vector Machines.- A neural approach to extended logic programs.- Bioinspired Developments.- Solving SAT in Linear Time with a Neural-like Membrane System.- An Exponential-Decay Synapse Integrated Circuit For Bio-inspired Neural Networks..- A high level synthesis of an auditory mechanical to neural transduction circuit..- Restriction Enzyme Computation.- Neurally Inspired Mechanisms for the Dynamic Visual Attention Map Generation Task.- A Model of Dynamic Visual Attention for Object Tracking in Natural Image Sequences.- Neural competitive structures for segmentation based on motion features.- Background Pixel Classification for Motion Detection in Video Image Sequences.- COBRA: An Evolved Online Tool for Mammography Interpretation.- CBA generated receptive fields implemented in a Facial expression recognition task.- A Hybrid Face Detector based on an Asymmetrical Adaboost Cascade Detector and a Wavelet-Bayesian- Detector.- Neural Net Generation of Facial Displays in Talking Heads.,data oriented architecture,851
90fb729b8f2ea9cd1043098fa229cb6269219c2e,filtered,semantic_scholar,2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2),2021-01-01,semantic_scholar,a survey of deep neural network in acoustic direction finding,https://www.semanticscholar.org/paper/90fb729b8f2ea9cd1043098fa229cb6269219c2e,"Direction of Arrival (DoA) estimation has importance in many industries such as speech enhancement, spatial audio coding, radio frequency and radio telescope. Deep Neural Network (DNN) has find its way into DoA applications along with the well-known methods such as subspace-based or time difference of arrival methods, which opens-up the data-driven approach towards estimating the DoA. This paper first surveys different DNN architectures and their supporting methods and datasets that are used for estimating DoA in different scenarios. Then a promising architecture based on convolutional recurrent neural network (CRNN) is re-presented on the Spatially Oriented Format for Acoustics (SOFA) dataset, where the average error rate of 9.68° has been achieved.",data oriented architecture,852
92b889406beb784a7a9f98750612648c51b33f58,filtered,semantic_scholar,2019 Winter Simulation Conference (WSC),2019-01-01,semantic_scholar,a study of lightweight dddas architecture for real-time public safety applications through hybrid simulation,https://www.semanticscholar.org/paper/92b889406beb784a7a9f98750612648c51b33f58,"Utilizing the Dynamic Data Driven Applications Systems (DDDAS) framework for Smart Cities, a Smart Public Safety (SPS) system has become feasible by integrating heterogeneous computing devices to collaboratively provide public safety services. However, a service oriented architecture (SOA) is difficult to provide scalable and extensible services in a city-wide distributed Internet of Things (IoT)-based SPS system. Furthermore, traditional management and security solutions rely on a centralized authority, which can be the performance bottleneck or single point of failure. Inspired by the microservices architecture and blockchain technology, a Lightweight IoT based Smart Public Safety (LISPS) framework is proposed on top of a permissioned blockchain network. Through decoupling a monolithic complex system into independent sub-tasks, the LISPS system possesses high flexibility in the design process and online maintenance. The experimental results demonstrate the feasibility of the approach to provide a secured data sharing and access control mechanism.",data oriented architecture,853
d497f21b9433370585d28a2de9db0cd9bcc56c42,filtered,semantic_scholar,,2009-01-01,semantic_scholar,acotes: advanced compiler technologies for embedded streaming submission to the special issue on european hipeac noe member's projects,https://www.semanticscholar.org/paper/d497f21b9433370585d28a2de9db0cd9bcc56c42,"Streaming applications are based on a data-driven approach where compute components consume and produce unbounded data vec- tors. Streaming oriented systems have become dominant in a wide range of domains, including embedded applications and DSPs However, programming efficiently for streaming architectures is a very challenging task, having to carefully partition the computation and map it to processes in a way that best matches the underlying multi-core streaming architectures, as well as having to take into account the needed resources (memory, processing, real-time re- quirements, etc.) and communication overheads (processing and delay) between the processors. These challenges have led to a number of suggested solu- tions, whose goal is to improve the programmer's efficiency in developing applications that process massive streams of data on programmable, parallel embedded architectures. StreamIt is one such example. Another more recent approach is that developed by the ACOTES (Advanced Compiler Technologies for Embedded Streaming) project. The ACOTES approach for streaming appli- cations consists of compiler-assisted mapping of streaming tasks to highly parallel systems in order to maximize cost-effectiveness, both in terms of energy and in terms of design effort. The analysis and transformation techniques automate large parts of the partition- ing and mapping process, based on the properties of the application domain, on the quantitative information about the target systems, and on programmer directives. This paper presents the outcomes of the ACOTES project, a 3- year collaborative work of industrial (NXP, ST, IBM, Silicon Hive, NOKIA) and academic (UPC, INRIA, MINES ParisTech) partners, and advocates the use the Advanced Compiler Technologies that we developed to support Embedded Streaming.",data oriented architecture,854
3f769b65303541f8e27e43a550110b3f1ad311aa,filtered,semantic_scholar,ARCS,2013-01-01,semantic_scholar,gals-cmp: chip-multiprocessor for gals embedded systems,https://www.semanticscholar.org/paper/3f769b65303541f8e27e43a550110b3f1ad311aa,"In this paper we present a novel multi-processor architecture for concurrent execution of programs that follow the Globally Asynchronous Locally Synchronous (GALS) formal model of computation. Programs are specified using the SystemJ concurrent programming language, suitable for modeling heterogeneous embedded applications that contain reactive and control driven parts and interact with the external environment. The proposed architecture is based on separating the control-driven and data-driven operations and executing them on distinct cores that support both types of operations, implemented as two modes within the single processor core. Each core can switch between two modes without any overhead. The core as the basic building block of the multiprocessor extends Java Optimized Processor (JOP), suitable for data-driven transformational operations, with control-oriented constructs that implement concurrency, reactivity, and control flow in SystemJ. Experimental evaluation over a range of benchmarks shows significant performance improvements over the existing platforms developed for the execution of the SystemJ program.",data oriented architecture,855
29daed885f85f78664af6c4334f00ef186e5e775,filtered,semantic_scholar,2019 IEEE 15th International Conference on Automation Science and Engineering (CASE),2019-01-01,semantic_scholar,iterative learning control for power profile shaping in selective laser melting,https://www.semanticscholar.org/paper/29daed885f85f78664af6c4334f00ef186e5e775,"Selective laser melting (SLM) can be used to manufacture functional metal parts with complex geometries that cannot be produced by traditional manufacturing methods. However, SLM process control cannot yet guarantee the end part quality required for critical applications. The application of model-based control strategies to SLM is complicated by both the closed architecture of industrial SLM machines and the lack of suitable control-oriented process models. In this paper we (1) present an open-source SLM printer that allows implementation of the on-the-fly power adjustment and (2) use a data-driven method, iterative learning control (ILC) to learn the suitable laser power profile using the melt pool emission measurements from a coaxial camera. We demonstrate the effectiveness of the proposed ILC approach through experiments on the open-source SLM machine.",data oriented architecture,856
e2cc3c468cbf3b7dd0827e1621a6c726ada00b32,filtered,semantic_scholar,,2017-01-01,semantic_scholar,design and implementation of hybrid test automation framework for web based application,https://www.semanticscholar.org/paper/e2cc3c468cbf3b7dd0827e1621a6c726ada00b32,"There many ways to create Web application UI Test Automation Framework. This paper elaborates the creation of the Hybrid Test Automation Framework, and explains the architecture and design of the framework. This Framework is easy to use and incorporate the use of high level programming language allowing object oriented design, permits low level access to the UL components and recover quickly for UI changes in the application under test. The architecture of the framework as multi layer design which isolates the browser UI compounds and test scripts. This Framework Architecture is a merged combination of Library and Data Driven Test Automation Framework. This Framework contents multi packages with classes which isolates the reusable functions and involves the external database on fetching the data. In this framework we can execute the same test case repeatedly in a loop to handle different test input which is retrieved from the database. Keywords— Test Framework, Data driven Architecture, Library Test Architecture.",data oriented architecture,857
b2076d15e86a5bd8e2dd3e8240e0c08254865c94,filtered,semantic_scholar,ArXiv,2019-01-01,semantic_scholar,accelerating pde-constrained inverse solutions with deep learning and reduced order models,https://www.semanticscholar.org/paper/b2076d15e86a5bd8e2dd3e8240e0c08254865c94,"Inverse problems are pervasive mathematical methods in inferring knowledge from observational and experimental data by leveraging simulations and models. Unlike direct inference methods, inverse problem approaches typically require many forward model solves usually governed by Partial Differential Equations (PDEs). This a crucial bottleneck in determining the feasibility of such methods. While machine learning (ML) methods, such as deep neural networks (DNNs), can be employed to learn nonlinear forward models, designing a network architecture that preserves accuracy while generalizing to new parameter regimes is a daunting task. Furthermore, due to the computation-expensive nature of forward models, state-of-the-art black-box ML methods would require an unrealistic amount of work in order to obtain an accurate surrogate model. On the other hand, standard Reduced-Order Models (ROMs) accurately capture supposedly important physics of the forward model in the reduced subspaces, but otherwise could be inaccurate elsewhere. In this paper, we propose to enlarge the validity of ROMs and hence improve the accuracy outside the reduced subspaces by incorporating a data-driven ML technique. In particular, we focus on a goal-oriented approach that substantially improves the accuracy of reduced models by learning the error between the forward model and the ROM outputs. Once an ML-enhanced ROM is constructed it can accelerate the performance of solving many-query problems in parametrized forward and inverse problems. Numerical results for inverse problems governed by elliptic PDEs and parametrized neutron transport equations will be presented to support our approach.",data oriented architecture,858
c92b7a5a26e81fb0a6080b3a1572b287d1f2fcb5,filtered,semantic_scholar,Proceedings. Second Euromicro Workshop on Parallel and Distributed Processing,1994-01-01,semantic_scholar,wavefront scheduling in logflow,https://www.semanticscholar.org/paper/c92b7a5a26e81fb0a6080b3a1572b287d1f2fcb5,"Recently inrensive research h,as been started on investigaring the possibility of implementing logic programming languages on distributed memiry computers [KaWi92]. The LOGFLOW project belongs to this class of projects and is unique in the sense that is based on a data driven execution model which is highly optimised towards the execution on neighborhoodo~ented~~geneous processor spaces. The main contribution of the current paper is the description of a dynamic scheduling scheme thal is able to adaptively control the distribution of Prolog work in the processor space based on the a c t d workbad of processors. 1: Introduction Parallel implementation of Prolog on different kinds of parallel computers has intensively been investigated since the mid eighties. The variety of parallel computers entailed a large number of proposals and experimental work on parallel Prolog, but most of these research efforts have been concentrated on implementing Prolog or a F’rolog variant on shared memory multiprocessors [GuJS], [HeCir90], [AlKaW], [CoWY91], [Dove%]. Recently intensive research has been started on investigating the possibility of implementing logic programming languages on distributed memory computers as well [KaWi92]. Many research projects aimed at parallelizing logic programs based on a dataflow execution model, but except for [BaCR92], the others consideired real dataflow machines as target architecture for a possible implementation @aAm84], [ItO8s], [Hali86], [BiLe87], [SiswSS]. The LOGFLOW project is also based on a data driven execution model but this model is highly optimised towards the execution on neighborhood oriented homogeneous processor spaces. Prolog programs are compiled into the Dataflow Search Graph and the computahion is based on this graph. An early version of the underlying abstract parallel execution model was described in [KacsW]. A revised version and its interpreted implementatioin on distributed memory multicomputers like multi-Transputers has been shown in [Kacs9l]. Based on the revised execution model a distributed data driven Prolog abstract machine, called the 3DPAh4 was designed and described in detail in mcs921. The implementation of the 3DPAM in a two-layer multi-transputer based machine, called the LOGFLOW machine is shown in Dcs931. In the present paper we give a detailed explanation of how to schedule parallel activities in the LOGFLOW machine based on a dynamic mapping and scheduling scheme that is able to adaptively control the distribution of Prolog work in the processor space based on the actual workload of processors. The scheduling of processes in parallel Prolog systems has been thoroughly investigated for shared memory systems [Herm87], [But188], [AlKa91], [Beau911 and recently for distributed memory systems, mainly for multi-transputers [Bria92] . The work described in [Can11921 has many similarities with our scheduling approach. 2: LOGFLOW The objective of the LOGFLour project is to implement CPA-Prolog (a slight modification of Prolog) on tightly-coupled distributed memory parallel computers where the communication cost between neighboring processors is significantly less than between remote processors. In CPA-Prolog everything is parallel by default, and therefore database oriented sideeffect * The current paper is part of the project titled “Highly Parallel Implementation of :Prolog on Distributed Memory Computers” supported by the National Scientific Research Foundation (Hungary) under the Grant Number T4045. 0-8186-5370-1/94 $3.00",data oriented architecture,859
310abd4932ff60f7f263bc3d4f44320f6f7d4a26,filtered,semantic_scholar,,2006-01-01,semantic_scholar,adaptive information systems for the web 2.0: developing a mobile learning architecture,https://www.semanticscholar.org/paper/310abd4932ff60f7f263bc3d4f44320f6f7d4a26,"The Web 2.0 is a collection of concepts and patterns that attempt to deÞ ne the nature of contemporary web applications. It has much in common with Service Oriented Architecture (SOA) concepts, which rely heavily on the use of XML and interoperable schemas, as well as embracing open web based APIs. One of the key design patterns of the Web 2.0 is software above the level of a single device, whilst one of its key concepts is the data driven nature of services and the core value of specialised databases. In both cases, XML has an essential role to play, both for data and metadata. In this paper, we explore some aspects of developing information systems in the context of the Web 2.0, focusing particularly on device adaptivity, data transformation and interoperability with other services, including the mashup approach. We describe a generic architecture for adaptive web applications and apply this to the development of a prototype mobile learning system.",data oriented architecture,860
10fc71551cc0cae6430d695c2f2c739f2a8a9f36,filtered,semantic_scholar,SBP-BRiMS,2018-01-01,semantic_scholar,digilego: a standardized analytics-driven consumer-oriented connected health framework,https://www.semanticscholar.org/paper/10fc71551cc0cae6430d695c2f2c739f2a8a9f36,"Connected health solutions provide novel pathways to provide integrated and affordable care. Emerging research suggests these connected tools can result improved health outcomes and sustainable self-health management. However, current health technology frameworks limit flexibility, engagement, and reusability of underlying connected health components. The objective of this paper is to develop a data-driven consumer engagement framework, which we call Digilego, to facilitate development of connected health solutions that are targeted, modular, extensible, and engaging. The major components include social media analysis, patient engagement features, and behavioral intervention technologies. We propose implementation of these Digilego components using FHIR specification such that the resulting technology is compliant to industry standards. We apply and evaluate the proposed framework to characterize four individual building blocks (DigiMe, DigiSocial, DigiConnect, DigiEHR) for a connected health solution that is responsive to cancer survivor needs. Results indicate that the framework (a) allows identification of survivor needs (e.g. social integration, treatment side effects) through semi-automated social media analysis, (b) facilitates infusion of engagement elements (e.g. smart health trackers, integrated electronic health records), and (c) integrates behavior change constructs into the design architecture of survivorship applications (e.g. goal setting, emotional coping). End user evaluation with 16 cancer survivors indicated general user acceptance and enthusiasm to adopt the solution for self-care management. Implications for design of patient-engaging chronic disease management solutions are discussed.",data oriented architecture,861
eb902eddbc65d568eec589af7c3b015359b93622,filtered,semantic_scholar,IF&GIS,2007-01-01,semantic_scholar,architecture types of the bit permutation instruction for general purpose processors,https://www.semanticscholar.org/paper/eb902eddbc65d568eec589af7c3b015359b93622,"In large information systems different data transform algorithms including the bit permutation operations requiring an execution of great number of cycles are used. To increase significantly the software performance of such algorithm a controlled bit permutation instruction (BPI) is desirable. Here a question of justification of embedding a new command, controlled BPI, into the standard set of instructions of general-purpose processor for increasing the efficiency of different types algorithms implemented in software is studied. In a variety of applications two different types of bit permutation operations are required: arbitrary fixed permutations and variable permutations. The last are used in a new fast cipher designs based on data-dependent permutations. Accounting for an expediency of embedding the controlled permutation command into the set of elementary processor operations the cryptographic applications form only one of the motivation elements. Another strong motivation is BPI’s use for solving variety of non-cryptographic problems. The multipurpose architecture of the BPI operation oriented to the efficient execution of both the cryptographic functions based on data-driven permutations and the algorithms including arbitrary bit permutations is proposed.",data oriented architecture,862
37e48f8378e4e1ee28c9aaea9c33b803a3e706ab,filtered,semantic_scholar,,2001-01-01,semantic_scholar,a bioinformatics discovery-oriented computing framework,https://www.semanticscholar.org/paper/37e48f8378e4e1ee28c9aaea9c33b803a3e706ab,"In Bioinformatics, interdisciplinary researchers study how to capture, manage, analyze, and disseminate biological information in the emerging drug discovery and disease management paradigms. Bioinformatics presents computer scientists with unparalleled challenges and opportunities. Current researchers and developers in bioinformatics face these challenges: (1) extracting and integrating biological data; (2) representing, managing, and reasoning about biological data; (3) integrating biological knowledge management and biological discovery process; (4) studying large-scale biology in an interdisciplinary environment; and ultimately (5) enabling the discovery of encyclopedic biological knowledge. 
In this thesis, I describe the design of a bioinformatics discovery-oriented computing framework based on the extended relational database management systems (E-RDBMS) architecture. The framework supports an integrated biological discovery process that combines both the “data-driven” view and the “hypothesis-driven” view. It consists of two primary research components, genomic data modeling and complex query modeling, and one extension component, the Similar_Join operator. In genomic data modeling, I have enabled biological data analysts to represent biological sequence data by extending data modeling techniques from content-neutral domains to the genomics domain. In complex query modeling, I have enabled biological data analysts to accomplish complex database querying by inventing new notation and techniques. In the Similar_Join operator design, I have enabled biology users to shift the computational burdens of a routine bioinformatics task—batch sequence similarity searches—back to the computing system by extending the general-purpose database management system into the biology domain. 
Using the framework, I have accomplished real world bioinformatics research projects, which I present as three bioinformatics case studies. Joining three bioinformatics development teams, I have enabled high-throughput and high-performance (1) annotation of anonymous plant ESTs, (2) comparison of gene expression detection algorithms, and (3) sequence selection for three Affymetrix commercial GeneChip microarrays. 
Overall, I have contributed to both computer science and bioinformatics: I have extended existing database system research into the emerging field of bioinformatics; meanwhile, I have enabled interdisciplinary teams of biologists and computational scientists to perform “large-scale integrated biology”. I believe the framework will inspire the development of new bioinformatics platforms, which will lead to the ultimate discovery of the Holy Grail in biology.",data oriented architecture,863
d5de644f340b7d2d82f6c0dfeac2f8907d61da4a,filtered,semantic_scholar,,2005-01-01,semantic_scholar,d cooperating services for data-driven computational experimentation,https://www.semanticscholar.org/paper/d5de644f340b7d2d82f6c0dfeac2f8907d61da4a,"characterized by dynamic adaptation in response to external data. Applications of this type, which are often dataand I/O-intensive, run as parallel or distributed computations on high-end resources such as distributed clusters or symmetric multiprocessing machines. On-demand weather forecasting is a canonical example of a data-driven application. As the article “Service-Oriented Environments in Research and Education for Dynamically Interacting with Mesoscale Weather” (pp. XX–YY in this issue) describes, on-demand weather forecasting is the automated process of invoking a forecast model run in response to the detection of a severe weather condition. The existing framework for running forecast models has drawbacks that we must overcome to bring about dynamic on-demand forecasting. For instance, the current investigation process requires a lot of human involvement, particularly in the staging and moving of the files required by the model and in the invocation of downstream tools to visualize and analyze model results. Although scripts exist to automate some of the process, a knowledgeable expert must properly configure them. The Linked Environments for Atmospheric Discovery (LEAD) project addresses the limitations of current weather forecast frameworks through a new, service-oriented architecture capable of responding to unpredicted weather events and response patterns in real time. These services are intended to support the execution of multimodel simulations of weather forecasts on demand across a distributed Grid of resources while dynamically adapting resource allocation in response to the results. At the system’s heart is a suite of core services that together provide the essential functionality needed to invoke and run a complex experiment with minimal human involvement. Specifically, it lets the user define an experiment workflow, execute the experiment, and store the results. (See the “Related Work” sidebar for a discussion of other work in this area.) In this article, we focus on three services—the MyLEAD metadata catalog service, notification service, and workflow service—that together form the core services for managing complex experimental meteorological investigations and managing the data products used in and generated during the computational experimentation. We show how",data oriented architecture,864
bbcfc2fd448de0e144c931768e2feb706e50844b,filtered,semantic_scholar,,2007-01-01,semantic_scholar,error awareness and recovery in conversational spoken language interfaces,https://www.semanticscholar.org/paper/bbcfc2fd448de0e144c931768e2feb706e50844b,"One of the most important and persistent problems in the development of conversational spoken language interfaces is their lack of robustness when confronted with understanding-errors. Most of these errors stem from limitations in current speech recognition technology, and, as a result, appear across all domains and interaction types. There are two approaches towards increased robustness: prevent the errors from happening, or recover from them through conversation, by interacting with the users. 
In this dissertation we have engaged in a research program centered on the second approach. We argue that three capabilities are needed in order to seamlessly and efficiently recover from errors: (1) systems must be able to detect the errors, preferably as soon as they happen, (2) systems must be equipped with a rich repertoire of error recovery strategies that can be used to set the conversation back on track, and (3) systems must know how to choose optimally between different recovery strategies at run-time, i.e. they must have good error recovery policies . This work makes a number of contributions in each of these areas. 
First, to provide a real-world experimental platform this error handling research program, we developed RavenClaw, a plan-based dialog management framework for task-oriented domains. The framework has a modular architecture that decouples the error handling mechanisms from the do main-specific dialog control logic; in the process, it lessens system authoring effort, promotes portability and reusability, and ensures consistency in error handling behaviors both within and across domains. To date, RavenClaw has been used to develop and successfully deploy a number of spoken dialog systems spanning different domains an interaction types. Together with these systems, RavenClaw provides the infrastructure for the error handling work described in this dissertation. 
To detect errors, spoken language interfaces typically rely on confidence scores. In this work we investigated in depth current supervised learning techniques for building error detection models. In addition, we proposed a novel, implicitly-supervised approach for this task. No developer supervision is required in this case; rather, the system obtains the supervision signal online, from naturally-occurring patterns in the interaction. We believe this learning paradigm represents an important step towards constructing autonomously self-improving systems. Furthermore, we developed a scalable, data-driven approach that allows a system to continuously monitor and update beliefs throughout the conversation; the proposed approach leads to significant improvements in both the overall effectiveness and efficiency of the interaction. 
We developed and empirically investigated a large set of recovery strategies, targeting two types of understanding-errors that commonly occur in these systems: misunderstandings and nonunderstandings. Our results add to an existing body of knowledge about the advantages and disadvantages of these strategies, and highlight the importance of good recovery policies. 
In the last part of this work, we proposed and evaluated a novel online-learning based approach for developing recovery policies. The system constructs runtime estimates for the likelihood of success of each recovery strategy, together with confidence bounds for those estimates. These estimates are then used to construct a policy online, while balancing the system's exploration and exploitation goals. Experiments with a deployed spoken dialog system showed that the system was able to learn a more effective recovery policy in a relatively short time period.",data oriented architecture,865
48af6a9c07b274d4221d2fb92076f04cedbf4658,filtered,semantic_scholar,IEEE Robotics and Automation Letters,2020-01-01,semantic_scholar,sim-to-real transfer learning approach for tracking multi-dof ankle motions using soft strain sensors,https://www.semanticscholar.org/paper/48af6a9c07b274d4221d2fb92076f04cedbf4658,"A data-driven approach has recently been investigated for identifying human joint angles by means of soft strain sensors because of the corresponding modeling difficulty. However, this approach commonly incurs a high computational burden due to the voluminous amount of data required and the time-series-oriented network architecture. Moreover, the nature of soft sensors makes the problem worse due to the inherent nonlinearity and hysteresis of the material. In this study, we developed a novel wearable sensing brace design for measuring multiple degrees of freedom (DOF) ankle motions to minimize hysteresis and to improve the measurement repeatability and developed a computationally efficient calibration method based on sim-to-real transfer learning. By attaching the soft sensors to shin links rather than directly to the ankle joint, the effects of external disturbances during joint motions were minimized. To calibrate the sensors to body motions, transfer learning was used based on the results from musculoskeletal simulation(OpenSim) and sensor data. The average tracking error for ankle motions using the proposed method was found to be 12.0° for five healthy subjects, while the direct deep neural network approach showed an error of 17.9°. The proposed method could be used to calibrate the soft sensors with 1000 times faster training speed while maintaining comparable tracking accuracy with a smaller amount of data.",data oriented architecture,866
3af19665f88f5b4a5782deec8909b41173319c3b,filtered,semantic_scholar,EC-Web,2009-01-01,semantic_scholar,metadata-driven soa-based application for facilitation of real-time data warehousing,https://www.semanticscholar.org/paper/3af19665f88f5b4a5782deec8909b41173319c3b,"Service-oriented architecture (SOA) has already been widely recognized as an effective paradigm for achieving integration of diverse information systems. SOA-based applications can cross boundaries of platforms, operation systems and proprietary data standards, commonly through the usage of Web Services technology. On the other side, metadata is also commonly referred to as a potential integration tool given the fact that standardized metadata objects can provide useful information about specifics of unknown information systems with which one has interest in communicating with, using an approach commonly called ""model-based integration"". This paper presents the result of research regarding possible synergy between those two integration facilitators. This is accomplished with a vertical example of a metadata-driven SOA-based business process that provides ETL (Extraction, Transformation and Loading) and metadata services to a data warehousing system in need of a real-time ETL support.",data oriented architecture,867
8400f32e444d0d161a34e797b798f3ddf665ae4f,filtered,semantic_scholar,Other Conferences,1990-01-01,semantic_scholar,a blackboard-based architecture for the interpretation of image sequences,https://www.semanticscholar.org/paper/8400f32e444d0d161a34e797b798f3ddf665ae4f,"In recent works about automatic target recognition, researchers try to make the most of the use of context. We have built a tool to study the use of context during the interpretation of an image sequence. This tool is written in an object-oriented language we have developed, AIRELLE and has a meta-level blackboard architecture. It runs according to a prediction-verification-propagation cycle. The strategy is both data-driven and model-driven; the focus of attention areas created thanks to the hypotheses enable a more rapid convergence towards a consistent interpretation of the scene. In this paper, AIRELLE and the blackboard architecture of the system are described in detail. Then, we show how our system for the interpretation of image sequences was designed and we describe its knowledge representation and knowledge sources.",data oriented architecture,868
56ec57f9db38a8467b1cf5672dda307661f635fc,filtered,semantic_scholar,,2010-01-01,semantic_scholar,modeling and simulation technology oriented to machining-assembly combined production system,https://www.semanticscholar.org/paper/56ec57f9db38a8467b1cf5672dda307661f635fc,"In view of the problem of collaborative production relationship between machining or assembly isolated by the separately modeling and simulation for each production system,the modeling and simulation technology oriented to machine-assembly combined production system,which supports the JIT (just-in-time) production pattern,is put forward.By importing the concept of the integrity assembly work station,the unified process description data structure for the combined production system is proposed and the collaborative production relationship between the machining and assembly is defined.Based on the hierarchical and interaction architecture of the workshop-work station-equipment,the modular modeling library embodied as the logic controller,corresponding with each level of the architecture,is constructed,and the lot-sizing process logic controller is also derived in order to reflect practice of the portfolio production.By utilizing the separation strategy between the physical model and control blocks,the layout and process data-driven rapid modeling methodology is brought forward on the basis of the mapping between the layout element and logic controllers.The task data-driven,hierarchical and modular simulation control mechanism is presented under the guidance of mapping methodology between the practical operation of the production system and the collaborating interaction among logic controller.The statistics of the equipment,queue and product driven by the simulation event is gathered and can support the optimization decision based on simulation.The optimization planning case of the task's production release time based on comparative analysis with such practical combined production system in a research institution shows that data-driven modeling and simulation technology can effectively be used for lean production decision.",data oriented architecture,869
4fabe5ce8ea799f834282266affdec97711c1a60,filtered,semantic_scholar,SBSI,2019-01-01,semantic_scholar,polyflow: a soa for analyzing workflow heterogeneous provenance data in distributed environments,https://www.semanticscholar.org/paper/4fabe5ce8ea799f834282266affdec97711c1a60,"In the last decade the (big) data-driven science paradigm became a wide-spread reality. However, this approach has some limitations such as a performance dependency on the quality of the data and the lack of reproducibility of the results. In order to enable this reproducibility, many tools such as Workflow Management Systems were developed to formalize process pipelines and capture execution traces. However, interoperating data generated by these solutions became a problem, since most systems adopted proprietary data models. To support interoperability across heterogeneous provenance data, we propose a Service Oriented Architecture with a polystore storage design in which provenance is conceptually represented utilizing the ProvONE model. A wrapper layer is responsible for transforming data described by heterogeneous formats into ProvONE-compliant. Moreover, we propose a query layer that provides location and access transparency to users. Furthermore, we conduct two feasibility studies, showcasing real usecase scenarios. Firstly, we illustrate how two research groups can compare their processes and results. Secondly, we show how our architecture can be used as a queriable provenance repository. We show Polyflow's viability for both scenarios using the Goal-Question-Metric methodology. Finally, we show our solution usability and extensibility appeal by comparing it to similar approaches.",data oriented architecture,870
c5c7a3a286c088444af73cb06822a310723e8527,filtered,semantic_scholar,User Modeling,2005-01-01,semantic_scholar,"user modeling 2005, 10th international conference, um 2005, edinburgh, scotland, uk, july 24-29, 2005, proceedings",https://www.semanticscholar.org/paper/c5c7a3a286c088444af73cb06822a310723e8527,"Invited Talks.- User Modeling Meets Usability Goals.- Hey, That's Personal!.- Inhabited Models: Supporting Coherent Behavior in Online Systems.- Papers.- Integrating Open User Modeling and Learning Content Management for the Semantic Web.- Modeling Suppositions in Users' Arguments.- Generative Programming Driven by User Models.- Data-Driven Refinement of a Probabilistic Model of User Affect.- Recognizing Emotion from Postures: Cross-Cultural Differences in User Modeling.- Recognizing, Modeling, and Responding to Users' Affective States.- Using Learner Focus of Attention to Detect Learner Motivation Factors.- Player Modeling Impact on Player's Entertainment in Computer Games.- Using Learning Curves to Mine Student Models.- Exploiting Probabilistic Latent Information for the Construction of Community Web Directories.- ExpertiseNet: Relational and Evolutionary Expert Modeling.- Task-Oriented Web User Modeling for Recommendation.- Ontologically-Enriched Unified User Modeling for Cross-System Personalization.- Using Student and Group Models to Support Teachers in Web-Based Distance Education.- Using Similarity to Infer Meta-cognitive Behaviors During Analogical Problem Solving.- COPPER: Modeling User Linguistic Production Competence in an Adaptive Collaborative Environment.- User Cognitive Style and Interface Design for Personal, Adaptive Learning. What to Model?.- Tailored Responses for Decision Support.- Decision Theoretic Dialogue Planning for Initiative Problems.- A Semi-automated Wizard of Oz Interface for Modeling Tutorial Strategies.- Generating Artificial Corpora for Plan Recognition.- Reasoning About Interaction in a Multi-user System.- A Comparison of HMMs and Dynamic Bayesian Networks for Recognizing Office Activities.- Modeling Agents That Exhibit Variable Performance in a Collaborative Setting.- Detecting When Students Game the System, Across Tutor Subjects and Classroom Cohorts.- A Bayesian Approach to Modelling Users' Information Display Preferences.- Modeling of the Residual Capability for People with Severe Motor Disabilities: Analysis of Hand Posture.- Non-intrusive User Modeling for a Multimedia Museum Visitors Guide System.- Modelling the Behaviour of Elderly People as a Means of Monitoring Well Being.- Bayesphone: Precomputation of Context-Sensitive Policies for Inquiry and Action in Mobile Devices.- Just Do What I Tell You: The Limited Impact of Instructions on Multimodal Integration Patterns.- Motion-Based Adaptation of Information Services for Mobile Users.- Interaction-Based Adaptation for Small Screen Devices.- Adapting Home Behavior to Its Inhabitants.- Design and Evaluation of a Music Retrieval Scheme That Adapts to the User's Impressions.- The Pursuit of Satisfaction: Affective State in Group Recommender Systems.- An Economic Model of User Rating in an Online Recommender System.- Incorporating Confidence in a Naive Bayesian Classifier.- Modeling User's Opinion Relevance to Recommending Research Papers.- User- and Community-Adaptive Rewards Mechanism for Sustainable Online Community.- Off-line Evaluation of Recommendation Functions.- Evaluating the Intrusion Cost of Recommending in Recommender Systems.- Introducing Prerequisite Relations in a Multi-layered Bayesian Student Model.- Exploring Eye Tracking to Increase Bandwidth in User Modeling.- Modeling Students' Metacognitive Errors in Two Intelligent Tutoring Systems.- Modeling Individual and Collaborative Problem Solving in Medical Problem-Based Learning.- User Modeling in a Distributed E-Learning Architecture.- Computer Adaptive Testing: Comparison of a Probabilistic Network Approach with Item Response Theory.- A Framework for Browsing, Manipulating and Maintaining Interoperable Learner Profiles.- Towards Efficient Item Calibration in Adaptive Testing.- Synergy of Performance-Based Model and Cognitive Trait Model in DP-ITS.- Up and Down the Number-Line: Modelling Collaboration in Contrasting School and Home Environments.- Temporal Blurring: A Privacy Model for OMS Users.- A Framework of Context-Sensitive Visualization for User-Centered Interactive Systems.- Gumo - The General User Model Ontology.- Balancing Awareness and Interruption: Investigation of Notification Deferral Policies.- A Decomposition Model for the Layered Evaluation of Interactive Adaptive Systems.- User Control over User Adaptation: A Case Study.- Towards User Modeling Meta-ontology.- Evaluation of a System for Personalized Summarization of Web Contents.- Social Navigation Support Through Annotation-Based Group Modeling.- Discovering Stages in Web Navigation.- The Impact of Link Suggestions on User Navigation and User Perception.- Doctoral Consortium Papers.- Modeling Emotions from Non-verbal Behaviour in an Affective Tutoring System.- Ubiquitous User Modeling in Recommender Systems.- User Modelling to Support User Customization.- ETAPP: A Collaboration Framework That Copes with Uncertainty Regarding Team Members.- Towards Explicit Physical Object Referencing.- Adaptive User Interfaces for In-vehicle Devices.- Agent-Based Ubiquitous User Modeling.- Using Qualitative Modelling Approach to Model Motivational Characteristics of Learners.- Improving Explicit Profile Acquisition by Means of Adaptive Natural Language Dialog.- Modelling User Ability in Computer Games.- Constraint-Sensitive Privacy Management for Personalized Web-Based Systems.- Modularized User Modeling in Conversational Recommender Systems.",data oriented architecture,871
bf5a2a87e4f4f7b3136857e121635e749a06626d,filtered,semantic_scholar,,2004-01-01,semantic_scholar,"affective dialogue systems : tutorial and research workshop, ads 2004, kloster irsee, germany, june 14-16, 2004 : proceedings",https://www.semanticscholar.org/paper/bf5a2a87e4f4f7b3136857e121635e749a06626d,"Emotion Recognition.- From Emotion to Interaction: Lessons from Real Human-Machine-Dialogues.- Emotions in Short Vowel Segments: Effects of the Glottal Flow as Reflected by the Normalized Amplitude Quotient.- Towards Real Life Applications in Emotion Recognition.- Emotion Recognition Using Bio-sensors: First Steps towards an Automatic System.- Neural Architecture for Temporal Emotion Classification.- Affective User Modeling.- Empathic Embodied Interfaces: Addressing Users' Affective State.- Cognitive-Model-Based Interpretation of Emotions in a Multi-modal Dialog System.- Affective Advice Giving Dialogs.- Emotional Databases, Annotation Schemes, and Tools.- A Categorical Annotation Scheme for Emotion in the Linguistic Content of Dialogue.- Data-Driven Tools for Designing Talking Heads Exploiting Emotional Attitudes.- Design of a Hungarian Emotional Database for Speech Analysis and Synthesis.- Affective Conversational Agents and Dialogue Simulation.- Emotion and Dialogue in the MRE Virtual Humans.- Coloring Multi-character Conversations through the Expression of Emotions.- Domain-Oriented Conversation with H.C. Andersen.- Simulating the Emotion Dynamics of a Multimodal Conversational Agent.- Design and First Tests of a Chatter.- Endowing Spoken Language Dialogue Systems with Emotional Intelligence.- Do You Want to Talk About It?.- Application of D-Script Model to Emotional Dialogue Simulation.- Synthesis of Emotional Speech and Facial Animations.- Modeling and Synthesizing Emotional Speech for Catalan Text-to-Speech Synthesis.- Dimensional Emotion Representation as a Basis for Speech Synthesis with Non-extreme Emotions.- Extra-Semantic Protocols Input Requirements for the Synthesis of Dialogue Speech.- How (Not) to Add Laughter to Synthetic Speech.- Modifications of Speech Articulatory Characteristics in the Emotive Speech.- Expressive Animated Agents for Affective Dialogue Systems.- Affective Tutoring Systems.- Affective Feedback in a Tutoring System for Procedural Tasks.- Generating Socially Appropriate Tutorial Dialog.- Evaluation of Affective Dialogue Systems.- The Role of Affect and Sociality in the Agent-Based Collaborative Learning System.- Evaluation of Synthetic Faces: Human Recognition of Emotional Facial Displays.- How to Evaluate Models of User Affect?.- Preliminary Cross-Cultural Evaluation of Expressiveness in Synthetic Faces.- Demonstrations.- Conversational H.C. Andersen First Prototype Description.- Experiences with an Emotional Sales Agent.- A Freely Configurable, Multi-modal Sensor System for Affective Computing.- Gesture Synthesis in a Real-World ECA.",data oriented architecture,872
bdf614547e22ef85f5c6c8377935d678b0c2fe59,filtered,semantic_scholar,,2002-01-01,semantic_scholar,sumatratt: towards a universal data preprocessor,https://www.semanticscholar.org/paper/bdf614547e22ef85f5c6c8377935d678b0c2fe59,"In the practice of data mining (DM) and data warehousing (DWH), real-life data arrive in various different formats, and without putting them into an acceptable shape, even the most intelligent DM/DWH tool would be useless. SumatraTT (Transformation Tool) is an original universal data pre-processing tool allowing to access and transform data stored in various types of datasources (e.g. plain text, SQL etc.). We briefly review the concept of the system and summarize its recent developments. The paper briefly overviews the connectivity with inductive logic programming (ILP) systems and then informs on more recently added features consisting of new data interfaces, scripting features, and templates. The usage of Sumatra TT on an example application is shortly demonstratied. After a brief touch upon near-future plans, we finally discuss some questions typically arising at the first usage of SumatraTT. 1 OUR MOTIVATION AND GOALS DM algorithms [6] are being designed by researchers and SW houses all over the world. There are many of them and their offer is continuously growing. Their different available implementations differ in principles as well as in tiny details such as the format used for the input data. Moreover, most often the data subjected to DM have not been collected for DM purposes primarily; on the contrary they serve e.g. as a company archive. Consequently, the format of such data cannot meet the requirements of a specific DM algorithm most often. The challenge of a DM task is in finding the algorithm which will reveal interesting observations in the considered data. But to reach this goal many experiments have to be done. One cannot decide in advance which set of DM tools or which derived attributes will prove most useful for the given problem. Thus original data have to be processed or transformed in different ways to make them usable by the chosen DM algorithms. Format of data has to be changed, data has to be cleaned, filtered, aggregated, etc. This is the purpose of data transformation systems which have recently appeared as independent SW tools supporting DM process itself [14]. This is an important step simplifying data preparation processes and supporting experiments with real life data. The common pain of state-of-art data transformation systems is their insufficient generality. Our goal is to overcome this problem by designing a developing a system • that allows for virtually any customization with respect to different data standards and requirements on the transformation, • but at the same time provides ultimate ease-of-use in cases where only standard procedures are required. The former goal can be achieved by providing a dataprocessing oriented scripting language, and the latter goal by providing templates of the common procedures and standard interfaces to many kinds of datasources. These ideas form the design principles of the data preprocessing tool SumatraTT described briefly in the next section. Most industries benefit from appropriate standardization. Positive reaction of the research community to the activity of the PMML group proves this is the case of the research field concerned with decision support systems, too. Prediction Model Mark-up Language is being developed to simplify exchange or sharing the results „between compliant vendorś applications ... so that proprietary issues and incompababilities are no longer a barrier“ ( http://www.dmg.org/pmmlspecs_v2/ ). Similar view can be taken towards data-transformations. We hope that our study of data transfomations using SumatraTT will complemet to development of a standard for data transfomation, namely to the Data Transformation Markup Language (DTML) supporting e.g. reuse of the same data by different algorithms through seemless import, rapid development of derived attributes, etc. 2 THE CONCEPT OF SUMATRA SumatraTT (Transformation Tool) is a metadata-driven, platform independent, extensible, and universal data processing tool [3]. The mentioned features have been achieved by building the tool as an interpreter of the transformation-oriented scripting language called Sumatra [2]. The Sumatra language is a fully interpreted Java-like language combining data access, metadata access, and common programming constructions. Furthermore, it supports the RAD (Rapid Application Development) technology by means of the library of reusable transformation templates. The principal scheme of SumatraTT is shown in Figure 1. As can be seen in the figure, the central part of SumatraTT is the Metadata repository module. Basically, the repository plays two roles. It is the central storage consisting of descriptions of all data sources and data transformations to be used. Moreover, the repository contains data objects interconnecting the abstract data access level in the Sumatra interpreter with real-life data sources. This intermediated connection helps to unify data access to very different data sources (e.g. SQL-based data sources, plain text files, etc). Such unification makes the process of transformation script development easier and data source independent. Moreover it separates the transformation ""logic"" from the data connection problems. In the case of very complicated data pre-processing task, the development of a data transformation script can be rather time consuming. SumatraTT allows to speed up this process by using reapplicable transformation templates. The idea of reusable templates is based on the library of solved types of tasks. E.g. there is a data set containing time series and we need to calculate a statistical characterization of the data. If this is carried out for the first time, a new template has to be developed. But the next time, the statistical transformation script can be developed via a parametric modification of the existing template within a fraction of the time required before. Every pre-processing task realized using SumatraTT consists of design and run-time phases. It corresponds to a client-server architecture where the design phase consists of the definition of all data sources and the development of transformation scripts on the client side. Regarding a typical user who is an expert in data mining or data warehousing but who is not a programmer, the design phase can be carried out using graphical user interface. The GUI allows to interactively realize both the data definition and script development by simple clicking on wizards. On the other hand, the run-time phase corresponds to a script execution on the server side. From the user's perspective, the execution can be invoked immediately or scheduled for a later run.",data oriented architecture,873
80ace40c2eeb40ac2c7599ed3ba5797518807249,filtered,semantic_scholar,SAMOS,2005-01-01,semantic_scholar,"embedded computer systems: architectures, modeling, and simulation 5th international workshop, samos 2005, samos, greece, july 18-20, 2005, proceedings",https://www.semanticscholar.org/paper/80ace40c2eeb40ac2c7599ed3ba5797518807249,"Keynote.- Platform Thinking in Embedded Systems.- Reconfigurable System Design and Implementations.- Interprocedural Optimization for Dynamic Hardware Configurations.- Reconfigurable Embedded Systems: An Application-Oriented Perspective on Architectures and Design Techniques.- Reconfigurable Multiple Operation Array.- RAPANUI: Rapid Prototyping for Media Processor Architecture Exploration.- Data-Driven Regular Reconfigurable Arrays: Design Space Exploration and Mapping.- Automatic FIR Filter Generation for FPGAs.- Two-Dimensional Fast Cosine Transform for Vector-STA Architectures.- Configurable Computing for High-Security/High-Performance Ambient Systems.- FPL-3E: Towards Language Support for Reconfigurable Packet Processing.- Processor Architectures, Design and Simulation.- Flux Caches: What Are They and Are They Useful?.- First-Level Instruction Cache Design for Reducing Dynamic Energy Consumption.- A Novel JAVA Processor for Embedded Devices.- Formal Specification of a Protocol Processor.- Tuning a Protocol Processor Architecture Towards DSP Operations.- Observations on Power-Efficiency Trends in Mobile Communication Devices.- CORDIC-Augmented Sandbridge Processor for Channel Equalization.- Power-Aware Branch Logic: A Hardware Based Technique for Filtering Access to Branch Logic.- Exploiting Intra-function Correlation with the Global History Stack.- Power Efficient Instruction Caches for Embedded Systems.- Micro-architecture Performance Estimation by Formula.- Offline Phase Analysis and Optimization for Multi-configuration Processors.- Hardware Cost Estimation for Application-Specific Processor Design.- Ultra Fast Cycle-Accurate Compiled Emulation of Inorder Pipelined Architectures.- Generating Stream Based Code from Plain C.- Fast Real-Time Job Selection with Resource Constraints Under Earliest Deadline First.- A Programming Model for an Embedded Media Processing Architecture.- Automatic ADL-Based Assembler Generation for ASIP Programming Support.- Sandbridge Software Tools.- Architectures and Implementations.- A Hardware Accelerator for Controlling Access to Multiple-Unit Resources in Safety/Time-Critical Systems.- Pattern Matching Acceleration for Network Intrusion Detection Systems.- Real-Time Stereo Vision on a Reconfigurable System.- Application of Very Fast Simulated Reannealing (VFSR) to Low Power Design.- Compressed Swapping for NAND Flash Memory Based Embedded Systems.- A Radix-8 Multiplier Design and Its Extension for Efficient Implementation of Imaging Algorithms.- A Scalable Embedded JPEG2000 Architecture.- A Routing Paradigm with Novel Resources Estimation and Routability Models for X-Architecture Based Physical Design.- Benchmarking Mesh and Hierarchical Bus Networks in System-on-Chip Context.- DDM-CMP: Data-Driven Multithreading on a Chip Multiprocessor.- System Level Design, Modeling and Simulation.- Modeling NoC Architectures by Means of Deterministic and Stochastic Petri Nets.- High Abstraction Level Design and Implementation Framework for Wireless Sensor Networks.- The ODYSSEY Tool-Set for System-Level Synthesis of Object-Oriented Models.- Design and Implementation of a WLAN Terminal Using UML 2.0 Based Design Flow.- Rapid Implementation and Optimisation of DSP Systems on SoPC Heterogeneous Platforms.- DVB-DSNG Modem High Level Synthesis in an Optimized Latency Insensitive System Context.- SystemQ: A Queuing-Based Approach to Architecture Performance Evaluation with SystemC.- Moving Up to the Modeling Level for the Transformation of Data Structures in Embedded Multimedia Applications.- A Case for Visualization-Integrated System-Level Design Space Exploration.- Mixed Virtual/Real Prototypes for Incremental System Design - A Proof of Concept.",data oriented architecture,874
fe0c10685faec0e4e543cddc47b533417538b1f1,filtered,semantic_scholar,,2013-01-01,semantic_scholar,"web and wireless geographical information systems : 12th international symposium, w2gis 2013, banff, canada, ab, april 4-5, 2013 : proceedings",https://www.semanticscholar.org/paper/fe0c10685faec0e4e543cddc47b533417538b1f1,Grounding Linked Open Data in WordNet: The Case of the OSM Semantic Network.- A Strategy for Optimizing a Multi-Site Query in a Distributed Spatial Database.- The Impact of Spatial Resolution and Representation on Human Mobility Predictability.- A Data-driven Approach for Convergence Prediction on Road Network.- Tour Suggestion for Outdoor Activities.- Interpreting Pedestrian Bahaviour by Visualising and Clustering Movement Data.- A Multi-Modal Communication Approach to Describing the Surroundings to Mobile Users.- An Adaptive Context Acquisition Framework to Support Mobile Spatial and Context-Aware Applications.- Comparing Close Destination and Route-based Similarity Metrics for the Analysis of Map User Trajectories A Sensor Data Mediator Bridging the OGC Sensor Observation Service (SOS) and the OASIS Open Data Protocol (OData).- Dynamic Objects E_ect on Visibility Analysis in 3D Urban Environments.- Exploring Spatial Business Data: A Resource Oriented Architecture eCampus Application.- ISOGA: a System for Geographical Reachability Analysis Enhanced with Statistics.- A high performance Web-based system for analyzing and visualizing spatiotemporal data for climate studies.- Personalized Accessibility Maps (PAMs) for Communities with Special Needs.- A probabilistic model for road selection in mobile maps.,data oriented architecture,875
679f3a482b36e3ba20a493a3d545b29bbd4966ca,filtered,semantic_scholar,2013 Military Communications and Information Systems Conference (MilCIS),2013-01-01,semantic_scholar,a rule-based platform for distributed real-time soa with application in defence systems,https://www.semanticscholar.org/paper/679f3a482b36e3ba20a493a3d545b29bbd4966ca,"Modularity has been a key issue in the design and development of modern embedded Real-Time Software Systems (RTS), where modularity enables flexibility with respect to changes in platform, environment, and requirements, as well as reuse. In distributed RTS, similar ideas have led to the adoption of COTS components integrated via Service-Oriented Architecture (SOA) principles and technologies that are already well-established in business-oriented information systems. However, current SOA implementations, with respect to service activation and orchestration, do not meet strict time-dependent constraints on scalability and latency required by RTS. We present a novel approach to RTS development where the orchestration of real-time processes is distributed among the services within a fully distributed data-driven process framework. Our framework wraps around COTS components implementing individual processing steps in a distributed real-time process. Our execution model is configurable through message routing policies distributed as a knowledge base containing rule sets, thus maintaining real-time constraints, and therefore dispenses with the need for a central orchestration component which could easily become a bottleneck. Deterministic behaviour can therefore be achieved through the validation of the rule-sets and the use of Modular Performance Analysis.",data oriented architecture,876
9f22e8223b3b270648ddf6a0c0c0ff551beb5647,filtered,semantic_scholar,MICAI,2006-01-01,semantic_scholar,"micai 2006: advances in artificial intelligence, 5th mexican international conference on artificial intelligence, apizaco, mexico, november 13-17, 2006, proceedings",https://www.semanticscholar.org/paper/9f22e8223b3b270648ddf6a0c0c0ff551beb5647,"Artificial Intelligence Arrives to the 21st Century.- Artificial Intelligence Arrives to the 21st Century.- Knowledge Representation and Reasoning.- Properties of Markovian Subgraphs of a Decomposable Graph.- Pre-conceptual Schema: A Conceptual-Graph-Like Knowledge Representation for Requirements Elicitation.- A Recognition-Inference Procedure for a Knowledge Representation Scheme Based on Fuzzy Petri Nets.- Inference Scheme for Order-Sorted Logic Using Noun Phrases with Variables as Sorts.- Answer Set General Theories and Preferences.- A Framework for the E-R Computational Creativity Model.- Fuzzy Logic and Fuzzy Control.- First-Order Interval Type-1 Non-singleton Type-2 TSK Fuzzy Logic Systems.- Fuzzy State Estimation of Discrete Event Systems.- Real-Time Adaptive Fuzzy Motivations for Evolutionary Behavior Learning by a Mobile Robot.- Fuzzy-Based Adaptive Threshold Determining Method for the Interleaved Authentication in Sensor Networks.- A Fuzzy Logic Model for Software Development Effort Estimation at Personal Level.- Reconfigurable Networked Fuzzy Takagi Sugeno Control for Magnetic Levitation Case Study.- Automatic Estimation of the Fusion Method Parameters to Reduce Rule Base of Fuzzy Control Complex Systems.- A Fault Detection System Design for Uncertain T-S Fuzzy Systems.- Uncertainty and Qualitative Reasoning.- An Uncertainty Model for a Diagnostic Expert System Based on Fuzzy Algebras of Strict Monotonic Operations.- A Connectionist Fuzzy Case-Based Reasoning Model.- Error Bounds Between Marginal Probabilities and Beliefs of Loopy Belief Propagation Algorithm.- Applications of Gibbs Measure Theory to Loopy Belief Propagation Algorithm.- A Contingency Analysis of LeActiveMath's Learner Model.- Constructing Virtual Sensors Using Probabilistic Reasoning.- Solving Hybrid Markov Decision Processes.- Comparing Fuzzy Naive Bayes and Gaussian Naive Bayes for Decision Making in RoboCup 3D.- Using the Beliefs of Self-Efficacy to Improve the Effectiveness of ITS: An Empirical Study.- Qualitative Reasoning and Bifurcations in Dynamic Systems.- Evolutionary Algorithms and Swarm Intelligence.- Introducing Partitioning Training Set Strategy to Intrinsic Incremental Evolution.- Evolutionary Method for Nonlinear Systems of Equations.- A Multi-objective Particle Swarm Optimizer Hybridized with Scatter Search.- Neural Networks.- An Interval Approach for Weight's Initialization of Feedforward Neural Networks.- Aggregating Regressive Estimators: Gradient-Based Neural Network Ensemble.- The Adaptive Learning Rates of Extended Kalman Filter Based Training Algorithm for Wavelet Neural Networks.- Multistage Neural Network Metalearning with Application to Foreign Exchange Rates Forecasting.- Genetic Optimizations for Radial Basis Function and General Regression Neural Networks.- Complexity of Alpha-Beta Bidirectional Associative Memories.- A New Bi-directional Associative Memory.- Optimization and Scheduling.- A Hybrid Ant Algorithm for the Airline Crew Pairing Problem.- A Refined Evaluation Function for the MinLA Problem.- ILS-Perturbation Based on Local Optima Structure for the QAP Problem.- Application of Fuzzy Multi-objective Programming Approach to Supply Chain Distribution Network Design Problem.- Route Selection and Rate Allocation Using Evolutionary Computation Algorithms in Multirate Multicast Networks.- A Polynomial Algorithm for 2-Cyclic Robotic Scheduling.- A New Algorithm That Obtains an Approximation of the Critical Path in the Job Shop Scheduling Problem.- A Quay Crane Scheduling Method Considering Interference of Yard Cranes in Container Terminals.- Comparing Schedule Generation Schemes in Memetic Algorithms for the Job Shop Scheduling Problem with Sequence Dependent Setup Times.- A Fuzzy Set Approach for Evaluating the Achievability of an Output Time Forecast in a Wafer Fabrication Plant.- Machine Learning and Feature Selection.- How Good Are the Bayesian Information Criterion and the Minimum Description Length Principle for Model Selection? A Bayesian Network Analysis.- Prediction of Silkworm Cocoon Yield in China Based on Grey-Markov Forecasting Model.- A Novel Hybrid System with Neural Networks and Hidden Markov Models in Fault Diagnosis.- Power System Database Feature Selection Using a Relaxed Perceptron Paradigm.- Feature Elimination Approach Based on Random Forest for Cancer Diagnosis.- On Combining Fractal Dimension with GA for Feature Subset Selecting.- Locally Adaptive Nonlinear Dimensionality Reduction.- Classification.- Fuzzy Pairwise Multiclass Support Vector Machines.- Support Vector Machine Classification Based on Fuzzy Clustering for Large Data Sets.- Optimizing Weighted Kernel Function for Support Vector Machine by Genetic Algorithm.- Decision Forests with Oblique Decision Trees.- Using Reliable Short Rules to Avoid Unnecessary Tests in Decision Trees.- Selection of the Optimal Wavebands for the Variety Discrimination of Chinese Cabbage Seed.- Hybrid Method for Detecting Masqueraders Using Session Folding and Hidden Markov Models.- Toward Lightweight Detection and Visualization for Denial of Service Attacks.- Tri-training and Data Editing Based Semi-supervised Clustering Algorithm.- Knowledge Discovery.- Automatic Construction of Bayesian Network Structures by Means of a Concurrent Search Mechanism.- Collaborative Design Optimization Based on Knowledge Discovery from Simulation.- Behavioural Proximity Approach for Alarm Correlation in Telecommunication Networks.- The MineSP Operator for Mining Sequential Patterns in Inductive Databases.- Visual Exploratory Data Analysis of Traffic Volume.- Computer Vision.- A Fast Model-Based Vision System for a Robot Soccer Team.- Statistics of Visual and Partial Depth Data for Mobile Robot Environment Modeling.- Automatic Facial Expression Recognition with AAM-Based Feature Extraction and SVM Classifier.- Principal Component Net Analysis for Face Recognition.- Advanced Soft Remote Control System Using Hand Gesture.- IMM Method Using Tracking Filter with Fuzzy Gain.- Image Processing and Image Retrieval.- Complete FPGA Implemented Evolvable Image Filters.- Probabilistic Rules for Automatic Texture Segmentation.- A Hybrid Segmentation Method Applied to Color Images and 3D Information.- Segmentation of Medical Images by Using Wavelet Transform and Incremental Self-Organizing Map.- Optimal Sampling for Feature Extraction in Iris Recognition Systems.- Histograms, Wavelets and Neural Networks Applied to Image Retrieval.- Adaptive-Tangent Space Representation for Image Retrieval Based on Kansei.- Natural Language Processing.- Distributions of Functional and Content Words Differ Radically.- Speeding Up Target-Language Driven Part-of-Speech Tagger Training for Machine Translation.- Defining Classifier Regions for WSD Ensembles Using Word Space Features.- Impact of Feature Selection for Corpus-Based WSD in Turkish.- Spanish All-Words Semantic Class Disambiguation Using Cast3LB Corpus.- An Approach for Textual Entailment Recognition Based on Stacking and Voting.- Textual Entailment Beyond Semantic Similarity Information.- On the Identification of Temporal Clauses.- Issues in Translating from Natural Language to SQL in a Domain-Independent Natural Language Interface to Databases.- Information Retrieval and Text Classification.- Interlinguas: A Classical Approach for the Semantic Web. A Practical Case.- A Fuzzy Embedded GA for Information Retrieving from Related Data Set.- On Musical Performances Identification, Entropy and String Matching.- Adaptive Topical Web Crawling for Domain-Specific Resource Discovery Guided by Link-Context.- Evaluating Subjective Compositions by the Cooperation Between Human and Adaptive Agents.- Using Syntactic Distributional Patterns for Data-Driven Answer Extraction from the Web.- Applying NLP Techniques and Biomedical Resources to Medical Questions in QA Performance.- Fast Text Categorization Based on a Novel Class Space Model.- A High Performance Prototype System for Chinese Text Categorization.- A Bayesian Approach to Classify Conference Papers.- An Ontology Based for Drilling Report Classification.- Topic Selection of Web Documents Using Specific Domain Ontology.- Speech Processing.- Speech Recognition Using Energy, MFCCs and Rho Parameters to Classify Syllables in the Spanish Language.- Robust Text-Independent Speaker Identification Using Hybrid PCA&LDA.- Hybrid Algorithm Applied to Feature Selection for Speaker Authentication.- Using PCA to Improve the Generation of Speech Keys.- Multiagent Systems.- Verifying Real-Time Temporal, Cooperation and Epistemic Properties for Uncertain Agents.- Regulating Social Exchanges Between Personality-Based Non-transparent Agents.- Using MAS Technologies for Intelligent Organizations: A Report of Bottom-Up Results.- Modeling and Simulation of Mobile Agents Systems Using a Multi-level Net Formalism.- Using AI Techniques for Fault Localization in Component-Oriented Software Systems.- Robotics.- Exploring Unknown Environments with Randomized Strategies.- Integration of Evolution with a Robot Action Selection Model.- A Hardware Architecture Designed to Implement the GFM Paradigm.- Bioinformatics and Medical Applications.- Fast Protein Structure Alignment Algorithm Based on Local Geometric Similarity.- Robust EMG Pattern Recognition to Muscular Fatigue Effect for Human-Machine Interaction.- Classification of Individual and Clustered Microcalcifications in Digital Mammograms Using Evolutionary Neural Networks.- Heart Cavity Detection in Ultrasound Images with SOM.- An Effective Method of Gait Stability Analysis Using Inertial Sensors.",data oriented architecture,877
4de357867043852b1a0f5897d9eeccf6a1426654,filtered,semantic_scholar,,2004-01-01,semantic_scholar,"adaptive hypermedia and adaptive web-based systems: third international conference, ah 2004, eindhoven, the netherlands, august 23-26, 2004, proceedings (lecture notes in computer science)",https://www.semanticscholar.org/paper/4de357867043852b1a0f5897d9eeccf6a1426654,"Keynote Speakers (Abstracts).- Ambient Intelligence.- Collaborative Agents for 2D Interfaces and 3D Robots.- A Curse of Riches or a Blessing? Information Access and Awareness Under Scarce Cognitive Resources.- Full Papers.- Supporting Metadata Creation with an Ontology Built from an Extensible Dictionary.- Interaction with Web Services in the Adaptive Web.- Social Adaptive Navigation Support for Open Corpus Electronic Textbooks.- PROS: A Personalized Ranking Platform for Web Search.- A P2P Distributed Adaptive Directory.- Developing Active Learning Experiences for Adaptive Personalised eLearning.- Adaptive User Modeling for Personalization of Web Contents.- Invoking Web Applications from Portals: Customisation Implications.- The Personal Reader: Personalizing and Enriching Learning Resources Using Semantic Web Technologies.- An Experiment in Social Search.- Recent Soft Computing Approaches to User Modeling in Adaptive Hypermedia.- A Flexible Composition Engine for Adaptive Web Sites.- Intelligent Support to the Retrieval of Information About Hydric Resources.- CUMAPH: Cognitive User Modeling for Adaptive Presentation of Hyper-documents. An Experimental Study..- Personalized Web Advertising Method.- Flexible Navigation Support in the WINDS Learning Environment for Architecture and Design.- Evaluation of WINDS Authoring Environment.- On the Dynamic Generation of Compound Critiques in Conversational Recommender Systems.- Evaluating Adaptive Problem Selection.- Adaptive Presentation and Navigation for Geospatial Imagery Tasks.- Myriad: An Architecture for Contextualized Information Retrieval and Delivery.- Cross-Media and Elastic Time Adaptive Presentations: The Integration of a Talking Head Tool into a Hypermedia Formatter.- Assessing Cognitive Load in Adaptive Hypermedia Systems: Physiological and Behavioral Methods.- Context-Aware Recommendations in the Mobile Tourist Application COMPASS.- Utilizing Artificial Learners to Help Overcome the Cold-Start Problem in a Pedagogically-Oriented Paper Recommendation System.- Unison-CF: A Multiple-Component, Adaptive Collaborative Filtering System.- Using SiteRank for Decentralized Computation of Web Document Ranking.- Short Papers.- Web Information Retrieval Based on User Profile.- Adaptive Support for Collaborative and Individual Learning (ASCIL): Integrating AHA! and CLAROLINE.- Specification of Adaptive Behavior Using a General-Purpose Design Methodology for Dynamic Web Applications.- Using the X3D Language for Adaptive Manipulation of 3D Web Content.- Evaluation of APeLS - An Adaptive eLearning Service Based on the Multi-model, Metadata-Driven Approach.- SearchGuide: Beyond the Results Page.- Modeling Learners as Individuals and as Groups.- Adaptive Help for Webbased Applications.- Empirical Evaluation of an Adaptive Multiple Intelligence Based Tutoring System.- Evaluating Information Filtering Techniques in an Adaptive Recommender System.- Adaptive Educational Hypermedia Proposal Based on Learning Styles and Quality Evaluation.- Adaptive Course Player for Individual Learning Styles.- Rhetorical Patterns for Adaptive Video Documentaries.- Location-Aware Adaptive Interfaces for Information Access with Handheld Computers.- PSO: A Language for Web Information Extraction and Web Page Clipping.- Swarm-Based Adaptation: Wayfinding Support for Lifelong Learners.- Giving More Adaptation Flexibility to Authors of Adaptive Assessments.- A Generic Adaptivity Model in Adaptive Hypermedia.- Doctoral Consortium.- Extreme Adaptivity.- A Learner Model in a Distributed Environment.- A Semantic Meta-model for Adaptive Hypermedia Systems.- Adaptive Navigation for Self-assessment Quizzes.- Posters.- Towards Adaptive Learning Designs.- Time-Based Extensions to Adaptation Techniques.- On the Use of Collaborative Filtering Techniques for the Prediction of Web Search Result Rank.- A Thematic Guided Tour Model for Contextualized Concept Presentations.- A Fuzzy Set Based Tutoring System for Adaptive Learning.- Offering Collaborative-Like Recommendations When Data Is Sparse: The Case of Attraction-Weighted Information Filtering.- Using Concept Maps for Enhancing Adaptation Processes in Declarative Knowledge Learning.- An Adaptive Tutoring System Based on Hierarchical Graphs.- A Brief Introduction to the New Architecture of SIETTE.- A Reinforcement Learning Approach to Achieve Unobtrusive and Interactive Recommendation Systems for Web-Based Communities.- GEAHS: A Generic Educational Adaptive Hypermedia System Based on Situation Calculus.- Problem Solving with Adaptive Feedback.- Machine Learning Methods for One-Session Ahead Prediction of Accesses to Page Categories.- Gender-Biased Adaptations in Educational Adaptive Hypermedia.- An Overview of aLFanet: An Adaptive iLMS Based on Standards.- A General Meta-model for Adaptive Hypermedia Systems.- Adaptive Services for Customised Knowledge Delivery.",data oriented architecture,878
faf427a862e3eff614e78eb5bd870c595cff9766,filtered,semantic_scholar,,1994-01-01,semantic_scholar,a reconfigurable arithmetic datapath architecture,https://www.semanticscholar.org/paper/faf427a862e3eff614e78eb5bd870c595cff9766,"A reconfigurable data-driven arithmetic datapath architecture for ALUs is presented which may be used for custom computing machines, Xputers and other adaptable computer systems as well as for rapid prototyping of high speed datapaths. Fine grained parallelism is achieved by using simple reconfigurable processing elements which are called datapath units (DPUs). The word-oriented datapath simplifies the mapping of applications onto the architecture. Pipelining is supported by the architecture. The programming environment allows automatic mapping of the operators from high level descriptions. Two implementations, one by FPGAs and one with standard cells are shown.",data oriented architecture,879
d81e8b60fd2cc9f14412a45ac9243431ebd0ad7c,filtered,semantic_scholar,2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops),2011-01-01,semantic_scholar,decoupling context-aware services,https://www.semanticscholar.org/paper/d81e8b60fd2cc9f14412a45ac9243431ebd0ad7c,"We present a novel software architecture for context-aware applications based on a distributed, non-monolithic, simple and extensible relational model for representing context; a service-oriented architecture for computing these relations in a decoupled, flexible fashion; and with data driven, event based communication providing the kind of fine grained dynamic service composition required in mobile and volatile environments. A prototype implementation is running a Bluetooth-sensor-based active map of users at our home university.",data oriented architecture,880
a242bfc8cddc52784dc68ed46a14adbbe9e3abd0,filtered,semantic_scholar,,2021-01-01,semantic_scholar,operationalizing heterogeneous data-driven process models for various industrial sectors through microservice-oriented cloud-based architecture,https://www.semanticscholar.org/paper/a242bfc8cddc52784dc68ed46a14adbbe9e3abd0,"Industrial performance optimization increasingly makes the use of various analytical data-driven models. In this context, modern machine learning capabilities to predict future production quality outcomes, model predictive control to better account for complex multivariable environments of process industry, Bayesian Networks enabling improved decision support systems for diagnostics and fault detection are some of the main examples to be named. The key challenge is to integrate these highly heterogeneous models in a holistic system, which would also be suitable for applications from the most different industries. Core elements of the underlying solution architecture constitute highly decoupled model microservices, ensuring the creation of largely customizable model runtime environments. Deployment of isolated user-space instances, called containers, further extends the overall possibilities to integrate heterogeneous models. Strong requirements on high availability, scalability, and security are satisfied through the application of cloud-based services. Tieto successfully applied the outlined approach during the participation in FUture DIrections for Process industry Optimization (FUDIPO), a project funded by the European Commission under the H2020 program, SPIRE-02-2016.",data oriented architecture,881
062a5b4fbc9e2decd5d38151531ec78c72980ea2,filtered,semantic_scholar,2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS),2020-01-01,semantic_scholar,improving data quality in medical research: a monitoring architecture for clinical and translational data warehouses,https://www.semanticscholar.org/paper/062a5b4fbc9e2decd5d38151531ec78c72980ea2,"Clinical and translational data warehouses are important infrastructure building blocks for modern data-driven approaches in medical research. These analytics-oriented databases have been designed to integrate heterogeneous biomedical datasets from different sources and to support use cases such as cohort selection and ad-hoc data analyses. However, the lack of clear definitions of source data and controlled data collection procedures often raises concerns about the quality of data provided in such environments and, consequently, about the evidence level of related findings. To address these problems, we present an architecture that helps to monitor data quality issues when importing data into warehousing solutions using ETL (Extraction, Transformation, Load) processes. Our approach provides software developers with an API (Application Programming Interface) for logging detailed and structured information about data quality issues encountered. This information can then be displayed in dynamic dashboards, the evolution of data quality can be monitored over time, and quality issues can be traced back to their source. Our architecture supports several well-known data quality dimensions, addressing conformance, completeness, and plausibility. We present an open-source implementation, which is compatible with common clinical and translational data warehousing platforms, such as i2b2 and tranSMART, and which can be used in conjunction with many ETL environments.",data oriented architecture,882
8bf515f6bca6c76ff30988bb410b6aa29587cdd0,filtered,semantic_scholar,ArXiv,2017-01-01,semantic_scholar,joint auto-encoders: a flexible multi-task learning framework,https://www.semanticscholar.org/paper/8bf515f6bca6c76ff30988bb410b6aa29587cdd0,"The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples. Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest. Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion. We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task. Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations. The method deals with domain adaptation and multi-task learning in a unified fashion, and can easily deal with data arising from different types of sources. Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network.",data oriented architecture,883
b47e88102b1c5e1ddbc0b733b0a033dc5a4d0379,filtered,semantic_scholar,,2020-01-01,semantic_scholar,temporal learning in video data using deep learning and gaussian processes,https://www.semanticscholar.org/paper/b47e88102b1c5e1ddbc0b733b0a033dc5a4d0379,"This paper presents an approach for data-driven modeling of hidden, stationary temporal dynamics in sequential images or videos using deep learning and Bayesian non-parametric techniques. In particular, a deep Convolutional Neural Network (CNN) is used to extract spatial features in an unsupervised fashion from individual images and then, a Gaussian process is used to model the temporal dynamics of the spatial features extracted by the deep CNN. By decomposing the spatial and temporal components and utilizing the strengths of deep learning and Gaussian processes for the respective sub-problems, we are able to construct a model that is able to capture complex spatio-temporal phenomena while using relatively small number of free parameters. The proposed approach is tested on high-speed grey-scale video data obtained of combustion flames in a swirl-stabilized combustor, where certain protocols are used to induce instability in combustion process. The proposed approach is then used to detect and predict the transition of the combustion process from stable to unstable regime. It is demonstrated that the proposed approach is able to detect unstable flame conditions using very few frames from high-speed video. This is useful as early detection of unstable combustion can lead to better control strategies to mitigate instability. Results from the proposed approach are compared and contrasted with several baselines and recent work in this area. The performance of the proposed approach is found to be significantly better in terms of detection accuracy, model complexity and lead-time to detection. Devesh Jha et al. This is an open-access article distributed under the terms of the Creative Commons Attribution 3.0 United States License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. 1. MOTIVATION AND INTRODUCTION Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstractions (LeCun, Bengio, & Hinton, 2015; Bengio, Courville, & Vincent, 2013; Hinton & Salakhutdinov, 2006). Deep learning methods are representation-learning techniques obtained by composition of non-linear modules or layers that each transform the representation at the previous level into a higher and slightly more abstract level in a hierarchical manner. The main idea is that by cascading a large number of such transformations, very complex functions can be learned in a data-driven manner. Convolutional deep neural nets (Krizhevsky, Sutskever, & Hinton, 2012; Lee, Grosse, Ranganath, & Ng, 2009) are designed to process data that come in the form of multiple arrays, for example images. In this technique, a discrete spatial convolution filter is used for detecting highly correlated distinctive motifs across an image. The same process can be extended to find temporal features by using a convolution filter over time, and using a stack of images as input. However, this will lead to an increase in the number of the hyperparameters used to train such a spatio-temporal convolutional network. Instead, we propose a framework, where a convolutional network is used to extract features from images and a Bayesian nonparametric model like the Gaussian process (Rasmussen & Williams, 2006) is used to model the temporal dynamics of the features; the objective is to reduce the number of parameters used to train such a network while modeling the spatiotemporal dynamics in an image sequence or videos. The proposed algorithm is used to detect stable and unstable combustion flame dynamics in a swirl-stabilized combustor. Another motivation is that adding a Gaussian process-based filter might allow to reduce over-fitting of the deep CNN to some extent as it allows to relate to the causal dynamics present in the data in a much lower dimensional space. International Journal of Prognostics and Health Management, ISSN2153-2648, 2016 022 1 INTERNATIONAL JOURNAL OF PROGNOSTICS AND HEALTH MANAGEMENT Combustion instability is a highly nonlinear coupled thermoacoustic phenomenon that results in self-sustained oscillations in a combustor. These oscillations may result in severe structural degradation in gas turbine engines. Some good surveys on the current understanding of the mechanisms for combustion instability phenomena can be found in (O’Connor, Acharya, & Lieuwen, 2015; Sé et al., 2003; Candel, Durox, Schuller, Bourgouin, & Moeck, 2014; Huang & Yang, 2009; Moeck, Bourgouin, Durox, Schuller, & Candel, 2012). The current state-of-the-art techniques rely heavily on model-based approaches for analysis of the process. The current technical literature lacks rigorous statistical analysis of the combustion instability phenomenon so that the predictive power of the data has been largely overlooked. Active combustion instability control (ACIC) with fuel modulation has proven to be an effective approach for reducing pressure oscillations in combustors (Banaszuk, Mehta, Jacobson, & Khibnik, 2006; Banaszuk, Mehta, & Hagen, 2007). Based on the work available in literature, one can conclude that the performance of ACIC is primarily limited by large delays in the feedback loop and limited actuator bandwidth (Banaszuk et al., 2006, 2007). Model-based approaches for active control are infeasible as complexity of the models and uncertain measurements make real-time estimates difficult. On the other hand, use of machine learning techniques for information extraction remain unexplored for this problem. From the perspective of active control of the unstable phenomena, it is necessary to accurately detect and, desirably, predict the future states of the combustion process. The goal of this paper is to present a statistical model for the instability phenomenon during combustion which could be used to design a statistical filter to accurately predict the system states. This can potentially alleviate the problems with delay in the ACIC feedback loop and thus possibly improve the performance. Some recent work on statistical analysis of combustion instability using pressure time-series data could be found in (Jha, Virani, & Ray, 2016; Virani, Jha, & Ray, 2016). The work presented in (Jha et al., 2016) shows the change in the underlying Markov model for pressure data as the system approaches the unstable regime resulting in self-sustained oscillations of the flame. Some other popular methods for detection of coherent structures include proper orthogonal decomposition (POD) (Berkooz, Holmes, & Lumley, 1993) and dynamic mode decomposition (DMD) (Schmid, 2010), which use tools of spectral theory to derive spatial coherent structure modes. Specifically, DMD has been used to estimate growth rates and frequencies from experimental data and also for stability analysis of experimental data. Recently, some analyses were also presented using deep learning for detection of combustion instabilities (Sarkar, Lore, Sarkar, Ramanan, et al., 2015; Sarkar, Jha, Lore, Sarkar, & Ray, 2016). More recently the work done in (Sarkar, Lore, & Sarkar, 2015) presents a neuro-symbolic approach where the output a deep convolutional network are analyzed by a Markov modeling module to construct an anomaly measure. However, as we demonstrate later, the advantages of using a deep neural network is unclear. Another analysis is presented in (Hauser, Li, Li, & Ray, 2016) using various image analysis techniques like histogram of oriented gradients (HOG) and Wavelets; however, the final decision is made by making a Markov model out of the features and thus requires long sequences to arrive at a decision. Moreover, perfect separability between stable and unstable classes is not achieved. This paper presents further insights into the combustion instability phenomena from a data-driven perspective (Darema, 2005) and presents a framework which allows temporal learning in video data in a lower dimensional subspace of features produced by a deep learning module. We show that flames have different spatial structures at unstable behavior when compared to stable behavior and with an appropriate architecture of neural network, we can perfectly capture the associated distinguishing features. Contributions: This paper presents a framework for modeling of spatio-temporal dynamics in sequential images using deep learning and Gaussian processes. We use the proposed algorithm to present a statistical analysis of the complex combustion instability phenomena and show that we are able to capture the change in the model as the system moves from a stable regime to an unstable regime. We show that the deep CNN is able to achieve fairly good classification performance; however the use of a Gaussian process filter to model temporality of extracted features results in perfect detection with very low false alarm rates and much shorter lead time to detection. The advantage of the proposed method is that it can be used for making early predictions of the transition from a stable regime to quasi-periodic unstable oscillations in combustion system. 2. PRELIMINARIES AND PROBLEM FORMULATION In this section, we will very briefly describe the convolutional neural nets and Gaussian processes. Interested readers are referred to (Lee et al., 2009; Rasmussen & Williams, 2006; Bengio et al., 2013) for an in-depth discussion on these topics. After the brief review, we will state the problem considered in this paper. The idea to use Gaussian processes to model the features obtained from deep CNN is to be able to add memory to the estimation filter without going to the architecture of a recurrent neural network. 2.1. Convolutional Neural Networks In this section, we briefly introduce the deep convolutional neural networks (CNN) for the completeness of the paper and motivation for use in this work. Deep convolutional neural networks have a long history (Le Cun Y. et al., 1990) but",data oriented architecture,884
5a3a44d2dc2c762602e4b3e886bfd30c8af231c6,filtered,semantic_scholar,ArXiv,2015-01-01,semantic_scholar,data-driven workflows for microservices,https://www.semanticscholar.org/paper/5a3a44d2dc2c762602e4b3e886bfd30c8af231c6,"Microservices is an architectural style inspired by service-oriented computing that has recently started gaining popularity. Jolie is a programming language based on the microservices paradigm: the main building block of Jolie systems are services, in contrast to, e.g., functions or objects. The primitives offered by the Jolie language elicit many of the recurring patterns found in microservices, like load balancers and structured processes. However, Jolie still lacks some useful constructs for dealing with message types and data manipulation that are present in service-oriented computing. In this paper, we focus on the possibility of expressing choices at the level of data types, a feature well represented in standards for Web Services, e.g., WSDL. We extend Jolie to support such type choices and show the impact of our implementation on some of the typical scenarios found in microservice systems. This shows how computation can move from a process-driven to a data-driven approach, and leads to the preliminary identification of recurring communication patterns that can be shaped as design patterns.",data oriented architecture,885
f2caba706e31cee0553f6c99276c6b28da0e628a,filtered,semantic_scholar,2015 10th International Joint Conference on Software Technologies (ICSOFT),2015-01-01,semantic_scholar,automatic generation of test data for xml schema-based testing of web services,https://www.semanticscholar.org/paper/f2caba706e31cee0553f6c99276c6b28da0e628a,"Service-Oriented Architecture (SOA) is a widely accepted paradigm for development of distributed applications using interoperable and flexible software components. Still the preferred technology for SOA implementation is provided by the web services. Their interface as well as complex interactions are described with XML-based standards, such as Web Service Description Language (WSDL) and Business Process Execution Language for Web Services (WS-BPEL). The WSDL and WS-BPEL documents allow automation of test data generation through instantiation of the referenced XML Schemas. The approach proposed in this paper is a step towards such goal. It provides derivation of XML instances from a given XML Schema. The approach is automated in a software tool supporting data-driven test definition. The tool automatically extracts an XML Schema form a WSDL or WS-BPEL documents and generates XML messages needed for web service interactions. Since the proposed approach supports generation of both correct and incorrect XML instances, the tool is applicable to functional as well as robustness testing of web services.",data oriented architecture,886
699929ca666c2de678cc925da2c0e92a6d6d37c0,filtered,semantic_scholar,,2016-01-01,semantic_scholar,urban energy simulation based on 3d city models: a service-oriented approach,https://www.semanticscholar.org/paper/699929ca666c2de678cc925da2c0e92a6d6d37c0,"Recent advancements in technology has led to the development of sophisticated software tools revitalizing growth in different domains. Taking advantage of this trend, urban energy domain have developed several compute intensive physical and data driven models. These models are used in various distinct simulation softwares to simulate the whole life-cycle of energy flow in cities from supply, distribution, conversion, storage and consumption. Since some simulation software target a specific energy system, it is necessary to integrate them to predict present and future urban energy needs. However, a key drawback is that, these tools are not compatible with each other as they use custom or propriety formats. Furthermore, they are designed as desktop applications and cannot be easily integrated with third-party tools (open source or commercial). Thereby, missing out on potential model functionalities which are required for sustainable urban energy management. In this paper, we propose a solution based on Service Oriented Architecture (SOA). Our approach relies on open interfaces to offer flexible integration of modelling and computational functionality as loosely coupled distributed services.",data oriented architecture,887
c6e097227b1c37abec6fc9d593fe4df6c5c6924b,filtered,semantic_scholar,,2012-01-01,semantic_scholar,cloud computing for mission design and operations,https://www.semanticscholar.org/paper/c6e097227b1c37abec6fc9d593fe4df6c5c6924b,"The space mission design and operations community already recognizes the value of cloud computing and virtualization. However, natural and valid concerns, like security, privacy, up-time, and vendor lock-in, have prevented a more widespread and expedited adoption into official workflows. In the interest of alleviating these concerns, we propose a series of guidelines for internally deploying a resource-oriented hub of data and algorithms. These guidelines provide a roadmap for implementing an architecture inspired in the cloud computing model: associative, elastic, semantical, interconnected, and adaptive. The architecture can be summarized as exposing data and algorithms as resource-oriented Web services, coordinated via messaging, and running on virtual machines; it is simple, and based on widely adopted standards, protocols, and tools. The architecture may help reduce common sources of complexity intrinsic to data-driven, collaborative interactions and, most importantly, it may provide the means for teams and agencies to evaluate the cloud computing model in their specific context, with minimal infrastructure changes, and before committing to a specific cloud services provider.",data oriented architecture,888
b026efb31ee0ad78eef8a9c6ae667f73eecc9a73,filtered,semantic_scholar,,2013-01-01,semantic_scholar,goal-driven automated dynamic retraining for space weather abnormality detection,https://www.semanticscholar.org/paper/b026efb31ee0ad78eef8a9c6ae667f73eecc9a73,"This paper addresses the application of automatically adaptive data-driven and goal-driven software tools for the detection and environment caused characterization of abnormal space system behavior with a priori unknown signatures. Goal-driven abnormality detection determines when retraining is needed, what data to train on, what data to test on, how to test, whether additional training is needed, and whether to promote the updated software. We discuss the design of automated space weather (SpWx) attribution tools and show sample results on real data. The space weather attribution, context assessment, and visualization tools described in this paper are extendable for characterization of fused multiple source abnormal event tracks from new sources using the Smoking Gun (SG) and the Bayesian Fusion Node (BFN). SG identifies correlation relationships such as between space weather and satellite system abnormal events. The BFN is runtime configurable with regard to input formats, taxonomy specification, decision logic, and processing. BACKGROUND Situational Awareness forms the framework for operations, planning, and decision making. Space Situational Awareness (SSA) brings knowledge of the operational space environment, its supporting ground elements and links and the projection of its future status. To achieve effective space situational awareness, the SSA system architecture must provide the decision maker and user the right data, information, tools, and decision aids at the right time. Using a net-centric service-oriented data fusion approach will allow a rapid assessment of the situation, capitalize on many available data sources, and adapt to situations in a timely manner. Information will need to be gathered across a broad range of DOD, civil, and commercial sources. Once this data is identified, it will need to be developed into actionable information for the decision maker. Space assets are susceptible to numerous anomalous conditions including: space weather events, radio frequency interference (RFI), satellite payload jamming, dazzling, proximity operations, breakup, bus failures, and other satellite anomalies. Given this variety of problematic situations, decision makers need a distributed satellite resource management system to effectively accomplish their space access mission. Near real-time integrated Space Situational Awareness (SSA) methods are needed to: detect & distinguish between environmental, man-made, and unintentional acts; predict actor intent; and provide real-time response recommendations to evolving scenarios. Distributed satellite resource management promises continued access to space capabilities so as to maintain mission-critical information after space-based asset degradation. Currently, in the event that space-based assets suffer an outage or abnormality, the responsibility falls to the human-in-the-loop to follow checklist procedures to restore operations. Unfortunately, these procedural checklists are time-consuming and are not always optimized with consideration of the need to maintain SSA. Also, systems used to compensate for satellites suffering outages may not achieve the restoration of service with sufficient time to adequately support ongoing missions. A semi-automated satellite mission re-planning system capable of confirming and characterizing abnormalities and then recommending space-based asset responses will be integral to the future improved use of US space order of battle assets. This system will run continuously, monitoring the relationships between space asset events, the potential for satellite system outages, and the ongoing missions relying on space-based assets. The system will provide immediate input to the human-in-the-loop in the form of a series of satellite mission re-planning and response options based on the current SSA that will balance support to ongoing operations with the need to ensure US space missions. There are five functional levels of SSA. Namely, incident detection/ causality, event tracking/characterization, event relationship assessment, mission impact prediction, and process & context assessments) and five dual response management levels within which the automated response decision aids of interest reside. These five levels have been described based upon the Data Fusion & Resource Management (DF&RM) Dual Node Network (DNN) technical architecture which is an extension of the JDL fusion model [1 and 2]. Activities include development of space weather attribution technologies, performance assessments, and services that utilize real sources of space systems data (e.g., State of Health (SOH), Signal to Noise Ratio (SNR), signal strength, etc.) and authoritative space weather sources. Scope and Relationships of This Work The DF&RM DNN technical architecture has been applied to guide the system architecture development for numerous DF&RM capabilities developed for SSA. The divide & conquer techniques in the DF&RM DNN technical architecture begin with guidance to functionally partition by layer and at the applications layer by “DF&RM functional levels” that are extensions and duals of the Joint Director’s Lab (JDL) data fusion model from the 1980’s [1]. The five fusion levels are summarized as follows:  Signal/Feature Assessment -Level 0: estimation of entity feature states  Entity Assessment -Level 1: estimation of entity states  Situation Assessment -Level 2: estimation of entity relationship states  Impact Assessment -Level 3: estimation of the mission impact of fused states  Process Assessment -Level 4: estimation of the DF&RM system performance, context conformity, and distributed DF&RM consistency measures both internal and external to the baseline DF&RM system. At each fusion level the DF node is designed to perform: data preparation, data association, and state estimation. This decomposition of the data driven decision support problem into fusion levels and corresponding nodes allows relatively constrained and low-risk development of each processing step in a loosely coupled manner, where many of the nodes in the fusion node network can be used and tested independently. The DNN technical architecture engineering guidelines provide for building the SSA capability as process flows of fusion and management node networks. These process flows cleanly map onto services composing a Service Oriented Architecture (SOA) as described in the STP quoted above. At the output side, modular visualization UDOP components can provide graphical user interfaces. These modular services and components will provide reusable building blocks for supporting a more agile enterprise for rapid, cost-effective development of SSA mission capabilities. The SOA building-block approach to constructing mission-specific applications is conducive to the spiral development approach providing iterative, agile, incremental development to achieve SSA objective prototype systems. This work aimed to develop and demonstrate a data fusion application that could be used across multiple domains for higher level data fusion (primarily multiple source levels 1-3) to increase SSA and provide timely and highly summarized data driven decision support to analysts and operators.",data oriented architecture,889
80fe80f3d7814239530ef2ce10428fb692f7e311,filtered,semantic_scholar,ECIS,2019-01-01,semantic_scholar,what is smart about services? breaking the bond between the smart product and the service,https://www.semanticscholar.org/paper/80fe80f3d7814239530ef2ce10428fb692f7e311,"While the conceptual delineation between conventional and smart products is rather conspicuous, the distinction between conventional services and their smart counterparts remains elusive. This study develops a conceptual framework for understanding the distinctive attributes of smart services and their relationship to smart products. In a systematic literature review of publications from top information systems outlets, 30 contributions holding relevant information on smart services are identified and subjected to content analysis. The analysis reveals a variety of different definitions and characterizations of smart services and relations to concepts like data-driven services and services associated to smart products and smart objects. These findings are used to examine artifacts developed in rather design-oriented papers to derive five dimensions that impact the level of smartness of services: richness of the data, the knowledge intensiveness of the engine for decision support, the level of sophistication of the outcome delivered to the service user(s), the architecture of the stakeholders, and the automation level of the service processes. Within this scope, the product can have four roles: sensor, computer, interface, or integrator. The paper concludes by identifying some gaps in the overall research landscape and provides directions for future research.",data oriented architecture,890
1fd708d6427cb36ed304d964833d089cc3df7764,filtered,semantic_scholar,,1996-01-01,semantic_scholar,"foundations of intelligent systems : 9th international symposium, ismis '96, zakopane, poland, june 9-13, 1996 : proceedings",https://www.semanticscholar.org/paper/1fd708d6427cb36ed304d964833d089cc3df7764,"Putting objects to work on a massive scale.- Approximate and commonsense reasoning: From theory to practice.- Cooperative information systems engineering.- Towards a Worldwide Knowledge base extended abstract.- Data mining and knowledge discovery in business databases.- Learning composite concepts in description logics: A first step.- Comparison of conceptual graphs for modelling knowledge of multiple experts.- Semantical considerations for knowledge base updates.- Partial evaluation in Constraint Logic Programming.- The AQ17-DCI system for data-driven constructive induction and its application to the analysis of world economics.- Induction of classification rules from imperfect data.- Induction of expert system rules from databases based on rough set theory and Resampling methods.- Mining patterns at each scale in massive data.- On evolving intelligence.- Intelligent mutation rate control in canonical genetic algorithms.- A fine-grained parallel evolutionary program for concept induction.- Evolutionary exploration of search spaces.- Evolutionary computation: One project, many directions.- Signed formula logic programming: Operational semantics and applications (extended abstract).- Automating proofs of integrity constraints in situation calculus.- Towards programming in default logic.- A sound and complete fuzzy logic system using Zadeh's implication operator.- Meeting the deadline: On the formal specification of temporal deontic constraints.- Validity queries and completeness queries.- Explanation for Cooperative Information Systems.- Toward intelligent representation of database content.- Reducing information systems with uncertain attributes.- Object and dependency oriented programming in FLO.- Knowledge simplification.- A model-based approach to consistency-checking.- Resource-based vs. task-based approaches for scheduling problems.- A Fuzzy Behaviorist Approach to sensor-based robot control.- Knowledge-based fuzzy neural networks.- Coevolutionary game theoretic multi-agent systems.- Searching for features defined by hyperplanes.- Inductive database design.- Enhancing query processing of information systems.- Structuring and retrieval of the complex predicate arguments proper to the NKRL conceptual language.- On the handling of imperfect data in relational database systems from null values to possibility distributions.- Modified component valuations in Valuation Based systems as a way to optimize query processing.- Learning for decision making: The FRD approach and a comparative study.- The application of rough sets-based data mining technique to differential diagnosis of meningoenchepahlitis.- A rough set framework for data mining of prepositional default rules.- An empirical study on the incompetence of attribute selection criteria.- Locally finite, proper and complete operators for refining Datalog programs.- Forest fire management with Negoplan.- An architecture for a deductive Fuzzy Relational Database.- A multi-step process for discovering, managing and refining strong functional relations hidden in databases.- An architecture and methodology for the design and development of Technical Information Systems.- Explaining explanation closure.- PAC-learning logic programs under the closed-world assumption.- Planning, truth criteria and the systematic approach to action and change.- Automated inductive reasoning as a support of deductive reasoning in a user-independent automation of inductive theorem proving.- Semantic query optimization for bottom-up evaluation.- Dynamically changing behavior: An agent-oriented view to modeling intelligent information systems.- A multi-layer architecture for knowledge-based system synthesis.- MuRaLi: An architecture for multiple reasoning.- Heterogeneous view integration via sketches and equations.- DLAB: A declarative language bias formalism.- Knowledge discovery in databases and data mining.- Learning with noise in engineering domains.- Hierarchical conceptual clustering in a first order representation.- Rule discovery from databases with decision matrices.",data oriented architecture,891
53132b18c0b4b0432e8933eb181bea225816173c,filtered,semantic_scholar,CAiSE,2006-01-01,semantic_scholar,"advanced information systems engineering, 18th international conference, caise 2006, luxembourg, luxembourg, june 5-9, 2006, proceedings",https://www.semanticscholar.org/paper/53132b18c0b4b0432e8933eb181bea225816173c,Keynotes.- Trust: From Cognition to Conceptual Models and Design.- Dealing with Trust in eGov Services.- Trusted Interaction: User Control and System Responsibilities in Interaction Design for Information Systems.- Security.- Designing Security Requirements Models Through Planning.- Towards a Comprehensive Framework for Secure Systems Development.- Role-Based Modelling of Interactions in Database Applications.- Conceptual Modelling.- Incremental Evaluation of OCL Constraints.- Object-Relational Representation of a Conceptual Model for Temporal Data Warehouses.- Data Translation Between Taxonomies.- Queries.- Managing Quality Properties in a ROLAP Environment.- Comprehensible Answers to Precis Queries.- An Efficient Approach to Support Querying Secure Outsourced XML Information.- Document Conceptualisation.- Wrapping PDF Documents Exploiting Uncertain Knowledge.- Supporting Customised Collaboration over Shared Document Repositories.- Data Conceptualisation for Web-Based Data-Centred Application Design.- Service Composition.- Resolving Underconstrained and Overconstrained Systems of Conjunctive Constraints for Service Requests.- Discovering Remote Software Services that Satisfy Requirements: Patterns for Query Reformulation.- A Library of OCL Specification Patterns for Behavioral Specification of Software Components.- Workflow.- Data-Driven Process Control and Exception Handling in Process Management Systems.- Workflow Exception Patterns.- Dynamic Workflow Modeling and Verification.- Business Modelling.- On the Notion of Value Object.- Inter-organisational Controls as Value Objects in Network Organisations.- Landscape Maps for Enterprise Architectures.- Configuration and Separation.- Model-Driven Enterprise Systems Configuration.- Configuration Management in a Method Engineering Context.- Why Software Engineers Do Not Keep to the Principle of Separating Business Logic from Display: A Method Rationale Analysis.- Business Process Modelling.- Translating Standard Process Models to BPEL.- Semantic Annotation Framework to Manage Semantic Heterogeneity of Process Models.- A Study of the Evolution of the Representational Capabilities of Process Modeling Grammars.- Agent Orientation.- From Stakeholder Intentions to Software Agent Implementations.- Modeling Mental States in Agent-Oriented Requirements Engineering.- On the Quantitative Analysis of Agent-Oriented Models.- Requirements Management.- An Empirical Evaluation of the i* Framework in a Model-Based Software Generation Environment.- Towards an End-User Development Approach for Web Engineering Methods.- Modeling Volatile Concerns as Aspects.,data oriented architecture,892
6cd96cedac9b77bebb3f5e8dbf5d76d1ac906971,filtered,semantic_scholar,,1990-01-01,semantic_scholar,"conpar 90 - vapp iv: joint international conference on vector and parallel processing, zurich, switzerland, september 10-13, 1990. proceedings",https://www.semanticscholar.org/paper/6cd96cedac9b77bebb3f5e8dbf5d76d1ac906971,"Digital electronics for 50 years: No limits to growth?.- Parallel computing : An Indian perspective.- POOMA, POOL and parallel symbolic computing: An assessment.- A decoupled data-driven architecture with vectors and macro actors.- A novel paradigm of parallel computation and its use to implement simple high performance hardware.- Presto: A bus-connected multiprocessor for a rete-based production system.- A model for performance prediction of message passing multiprocessors achieving concurrency by domain decomposition.- Workloads, observables, benchmarks and instrumentation.- A method for performance prediction of parallel programs.- Divide and conquer: A new parallel algorithm for the solution of a tridiagonal linear system of equations.- Sparse matrix algorithms for SUPRENUM.- Parallel givens factorization on a shared memory multiprocessor.- Study of a parallel inference machine for parallel execution of logic programs.- Parallel implementation of logic languages.- Prolog implementations on parallel computers.- Performance evaluation of parallel programs in parallel and distributed systems.- The ELAN performance analysis environment.- Monitoring and debugging Transputer-networks with NETMON-II.- An adaptive blocking strategy for matrix factorizations.- Factorizations of band matrices using level 3 BLAS.- On the computation of breeding values.- Code parallelization for the LGDG large-grain dataflow computation.- Development of portable parallel programs with large-grain data flow 2.- ADAM: a coarse-grain dataflow architecture that addresses the load balancing and throttling problems.- A latency tolerant code generation algorithm for a coarse grain dataflow machine.- Cedar Fortrand its compiler.- Optimizing communication in SUPERB.- A design of performance-optimized control-based synchronization.- Interprocess analysis and optimization in the equational language compiler.- Transputer based distributed cartographic image processing.- MPS-an experimental multi-microprocessor based parallel system.- Parallel implementation of the convolution method in image reconstruction.- SYDAMA II: A heterogeneous multiprocessor system for real time image processing.- Analysis and design of circuit switching interconnection networks using 4x4 nodes.- Design and simulation of a multistage interconnection network.- A reconfigurable interconnection network for flexible pipelining.- A fast distributed mapping algorithm.- A note on the load balancing problem for coarse grained hypercube dictionary machines.- Hierarchical wiring in multigrids.- Optimal data structures for an efficient vectorized finite element code.- FFTVPLIB, a collection of Fast Fourier transforms for vectorprocessors.- Improving the vector performance via algorithmic domain decomposition.- Implementation of parallel numerical routines using broadcast communication schemes.- A process and memory model for a parallel distributed-memory machine.- A deadlock free routing algorithm with network size independent buffering space.- From object-oriented programming to automatic load distribution.- Partitioning programs into processes.- An MIMD execution environment with a fixed number of processes.- Sorting large data files on POOMA.- Parallelizing divide-and-conquer algorithms - Microtasking versus autotasking.- The performance of linear algebra subprograms on the siemens S series.- A family of highly parallel computers.- A distributed shared memory multiprocessor kit with scalable local complexity.- Scalable cache coherence for large shared memory multiprocessors.- Design and implementation of an exception handling mechanism for communicating sequential processes.- Creating and controlling concurrency in object oriented systems - A case study -.- A distributed algorithm for dynamic task scheduling.- TeNOR++: A dynamic configurer for SuperNode machines.- Parallel modelling of electromagnetic field scattering: A new approach using the Edinburgh concurrent supercomputer facility.- 3D multigrid correction methods for Transputer networks.- A comparative study of two wavefront implementations of a LU solver algorithm.- Systolic array architecture for two-dimensional discrete Fourier transform.- Design and implementation of M1 Cellprocessor.- A comparison of microtasking implementations of the applicative language SISAL.- An efficient scheme for fine-grain software pipelining.- Sisal on a message passing architecture.- The TOPSYS architecture.- MMK - A distributed operating system kernel with integrated dynamic loadbalancing.- The distributed monitor system of TOPSYS.- Hybrid algorithms for the elgensolution of large sparse symmetric matrices on the AMT DAP 510.- Virtual systems architecture on the AMT DAP.- Numerical simulation of thermal convection on SIMD computers.- Massively parallel realization of logical operations in distributed parallel systems.- High-performance computer system ""Siberia"".- EDS hardware architecture.- Visualizing and analysing the runtime behavior of parallel programs.- PATOP for performance tuning of parallel programs.- Real-time visualization of concurrent processes.- Achieving superlinear speedups for the multiple polynomial quadratic sieve factoring algorithm on a distributed memory multiprocessor.- A performance analysis of network topologies in finding the roots of a polynomial.- Parallel multigrid algorithms for some specialized computer systems.- Computation race at CONPAR 90, VAPP IV ETH Zurich, Sep 10-13, 1990.",data oriented architecture,893
3da4e392ca4c782457c5d1334897b9073b4a043c,filtered,semantic_scholar,,2018-01-01,semantic_scholar,"a hybrid e-learning framework: process-based, semantically-enriched and service-oriented",https://www.semanticscholar.org/paper/3da4e392ca4c782457c5d1334897b9073b4a043c,"Despite the recent innovations in e-Learning, much development is needed to ensure better learning experience for everyone and bridge the research gap in the current state of the art e-Learning artefacts. Contemporary 
e-learning artefacts possess various limitations as follows. First, they offer inadequate variations of adaptivity, since their recommendations are limited to e-learning resources, peers or communities. Second, they are often overwhelmed with technology at the expense of proper pedagogy and learning theories underpinning e-learning practices. Third, they do not comprehensively capture the e-learning experiences as their focus shifts to e-learning activities instead of e-learning processes. In reality, learning is a complex process that includes various activities and interactions between different roles to achieve certain gaols in a continuously evolving environment. Fourth, they tend more towards legacy systems and lack the agility and flexibility in their structure and design. 
To respond to the above limitations, this research aims at investigating the effectiveness of combining three advanced technologies (i.e., Business Process Modelling and Enactment, Semantics and Service Oriented Computing – SOC–) with learning pedagogy in order to enhance the e-learner experience. The key design artefact of this research is the development of the HeLPS e-Learning Framework – Hybrid e-Learning Framework that is Process-based, Semantically-enriched and Service Oriented-enabled. In this framework, a generic e-learning process has been developed bottom-up based on surveying a wide range of e-learning models (i.e., practical artefacts) and their underpinning pedagogies/concepts (i.e., theories); and then forming a generic e-learning process. Furthermore, an e-Learning Meta-Model has been developed in order to capture the semantics of 
e-learning domain and its processes. Such processes have been formally modelled and dynamically enacted using a service-oriented enabled architecture. This framework has been evaluated using a concern-based evaluation employing both static and dynamic approaches. The HeLPS e-Learning Framework along with its components have been evaluated by applying a data-driven approach and artificially-constructed case study to check its effectiveness in capturing the semantics, enriching e-learning processes and deriving services that can enhance the e-learner experience. Results revealed the effectiveness of combining the above-mentioned technologies in order to enhance the e-learner experience. Also, further research directions have been suggested. 
This research contributes to enhancing the e-learner experience by making the e-learning artefacts driven by pedagogy and informed by the latest technologies. One major novel contribution of this research is the introduction of a layered architectural framework (i.e., HeLPS) that combines business process modelling and enactment, semantics and SOC together. Another novel contribution is adopting the process-based approach in e-learning domain through: identifying these processes and developing a generic business process model from a set of related e-learning business process models that have the same goals and associated objectives. A third key contribution is the development of the e-Learning Meta-Model, which captures a high-abstract view of learning domain and encapsulates various domain rules using the Semantic Web Rule Language. Additional contribution is promoting the utilisation of Service-Orientation in e-learning through developing a semantically-enriched approach to identify and discover web services from e-learning business process models. Fifth, e-Learner Experience Model (eLEM) and e-Learning Capability Maturity Model (eLCMM) have been developed, where the former aims at identifying and quantifying the e-learner experience and the latter represents a well-defined evolutionary plateau towards achieving a mature e-learning process from a technological perspective. Both models have been combined with a new developed data-driven Validation and Verification Model to develop a Concern-based Evaluation Approach for e-Learning artefacts, which is considered as another contribution.",data oriented architecture,894
