doi,type,publication,publisher,publication_date,database,title,url,abstract,domain,id,status
10.1109/iccda.2010.5540715,to_check,2010 International Conference On Computer Design and Applications,IEEE,6/27/2010 0:00,ieeexplore,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://ieeexplore.ieee.org/document/5540715/,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,1,included
10.1109/icacc.2010.5487131,to_check,2010 2nd International Conference on Advanced Computer Control,IEEE,3/29/2010 0:00,ieeexplore,data-oriented architecture of ln function,https://ieeexplore.ieee.org/document/5487131/,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,2,included
10.1109/icetc.2010.5529337,to_check,2010 2nd International Conference on Education Technology and Computer,IEEE,6/24/2010 0:00,ieeexplore,data-oriented architecture of sine,https://ieeexplore.ieee.org/document/5529337/,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,3,included
10.1109/icacte.2010.5579358,to_check,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),IEEE,8/22/2010 0:00,ieeexplore,data-oriented architecture of sine and cosine functions,https://ieeexplore.ieee.org/document/5579358/,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,4,included
10.1109/icepe.2014.6970070,to_check,2014 International Conference and Exposition on Electrical and Power Engineering (EPE),IEEE,10/18/2014 0:00,ieeexplore,domain specific languages in power systems engineering,https://ieeexplore.ieee.org/document/6970070/,"This paper proposes an information system for data mining that allows the specification of ad-hoc queries on a data warehouse, which contain historical information relative to exceptions (i.e., operating faults) recorded by a SCADA system in a power distribution network. The proposed application can be used by the power system engineers to explore the existent historical data, with no need for any “low level” programming expertise. The data-oriented architecture of the system provides important advantages related to application development and system maintainability.",data oriented architecture,5,included
10.1109/cse.2014.128,to_check,2014 IEEE 17th International Conference on Computational Science and Engineering,IEEE,12/21/2014 0:00,ieeexplore,exploring the benefits of introducing network coding into named data networking,https://ieeexplore.ieee.org/document/7023638/,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,6,not included
10.1007/978-3-030-88207-5_17,to_check,"Cooperative Design, Visualization, and Engineering",Springer,1/1/2021 0:00,springer,building a big data oriented architecture for enterprise integration,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88207-5_17,"Digital transformation is happening across all industries and affecting all facets of our daily life. However, in many corporations, this important process is fragmented and is undertaken without a farsighted plan to take advantage of an invaluable resource: data. This can be due to a variety of reasons, for example, lack of funding, poor business vision, inappropriate consulting or deployment. Digital transformation is a considerable investment since it will determine the system’s ability to grow and adapt to the company’s changing requirements. To achieve that end, the architecture must be flexible both in development and deployment and must also be able to harness the ever-increasing data of the corporation. Among the widely used information system architectures being used in the world, Micro-service is a standout with many advantages. The adaptation of this architecture to work with Big Data, as well as to tackle different aspects of a data system such as load-balancing, file handling and storage, etc. is a very practical area of research. This paper presents such an enterprise integration solution for a mega-corporation client in Vietnam, the An Pha Petrol Group Joint Stock Company, including the architecture and technologies used to build a comprehensive system that brings novel experiences to its 2,000 internal users. It consists of building the information infrastructure and system, super applications for both desktop and mobile devices to enhance the work performance and quality. The approaches and results of this paper are applicable to similar large enterprise solutions.",data oriented architecture,7,included
http://arxiv.org/abs/1706.03968v2,to_check,arxiv,arxiv,6/13/2017 0:00,arxiv,asynchronous graph pattern matching on multiprocessor systems,http://arxiv.org/abs/1706.03968v2,"Pattern matching on large graphs is the foundation for a variety of
application domains. Strict latency requirements and continuously increasing
graph sizes demand the usage of highly parallel in-memory graph processing
engines that need to consider non-uniform memory access (NUMA) and concurrency
issues to scale up on modern multiprocessor systems. To tackle these aspects,
graph partitioning becomes increasingly important. Hence, we present a
technique to process graph pattern matching on NUMA systems in this paper. As a
scalable pattern matching processing infrastructure, we leverage a
data-oriented architecture that preserves data locality and minimizes
concurrency-related bottlenecks on NUMA systems. We show in detail, how graph
pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,8,included
10.15598/aeee.v19i4.4183,to_check,core,"'VSB Technical University of Ostrava, Faculty of Electrical Engineering and Computer Sciences'",1/1/2021 0:00,core,intelligent bearing fault diagnosis method based on hnr envelope and classification using supervised machine learning algorithms,https://core.ac.uk/download/490710719.pdf,"Research on data-driven bearing fault diagnosis techniques has recently drawn more and more attention due to the availability of massive condition monitoring data. The research work presented in this paper aims to develop an architecture for the detection and diagnosis of bearing faults in the induction machines. The developed data-oriented architecture uses vibration signals collected by sensors placed on the machine, which is based, in the first place, on the extraction of fault indicators based on the harmonics-to-noise ratio envelope. Normalisation is then applied to the extracted indicators to create a well-processed data set. The evolution of these indicators will be studied afterwards according to the type and severity of defects using sequential backward selection technique. Supervised machine learning classification methods are developed to classify the measurements described by the feature vector with respect to the known modes of operation. In the last phase concerning decision making, ten classifiers are tested and applied based on the selected and combined indicators. The developed classification methods allow classifying the observations, with respect to the different modes of bearing condition (outer race, inner race fault or healthy condition). The proposed method is validated on data collected using an experimental bearing test bench. The experimental results indicate that the proposed architecture achieves high accuracy in bearing fault detection under all operational conditions. The results show that, compared to some proposed approaches, our proposed architecture can achieve better performance overall in terms of the number of optimal features and the accuracy of the tests",data oriented architecture,9,not included
10.3390/electronics10151810,to_check,core,'MDPI AG',7/1/2021 0:00,core,on-board data management layer: connected vehicle as data platform,,"For connected vehicles, as well as generally for the transportation sector, data are now seen as a precious resource. They can be used to make right decisions, improve road safety, reduce CO2 emissions, or optimize processes. However, analyzing these data is not so much a question of which technologies to use, but rather about where these data are analyzed. Thereby, the emerging vehicle architecture has to become a data-oriented architecture based on embedded computing platforms and take into account new applications, artificial intelligence elements, advanced analytics, and operating systems. Accordingly, in this paper, we introduce the concept of data management to the vehicle by proposing an on-board data management layer, so that the vehicle can play the role of data platform capable of storing, processing, and diffusing data. Our proposed layer supports analytics and data science to deliver additional value from the connected vehicle data and stimulate the development of new services. In addition, our data platform can also form or contribute to shaping the backbone of data-driven transport. An on-board platform was built where the dataset size was reduced 80% and a rate of 99% accuracy was achieved in a 5 min traffic flow prediction using artificial neural networks (ANNs)",data oriented architecture,10,included
10.1109/asru.2007.4430168,to_check,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),IEEE,12/13/2007 0:00,ieeexplore,a data-centric architecture for data-driven spoken dialog systems,https://ieeexplore.ieee.org/document/4430168/,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",data centric architecture,11,included
10.1109/icdcsw.2003.1203556,to_check,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",IEEE,5/22/2003 0:00,ieeexplore,"""data-centric to the max"", the splice architecture experience",https://ieeexplore.ieee.org/document/1203556/,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",data centric architecture,12,included
10.1109/cluster.2012.80,to_check,2012 IEEE International Conference on Cluster Computing,IEEE,9/28/2012 0:00,ieeexplore,a decoupled execution paradigm for data-intensive high-end computing,https://ieeexplore.ieee.org/document/6337781/,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",data centric architecture,13,included
10.1109/siot.2016.007,to_check,2016 International Workshop on Secure Internet of Things (SIoT),IEEE,9/30/2016 0:00,ieeexplore,addressing data-centric security requirements for iot-based systems,https://ieeexplore.ieee.org/document/7913560/,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",data centric architecture,14,included
10.1109/icce-china.2017.7991141,to_check,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),IEEE,6/14/2017 0:00,ieeexplore,an iot framework for intelligent roadside assistance system,https://ieeexplore.ieee.org/document/7991141/,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",data centric architecture,15,not included
10.1109/issnip.2005.1595552,to_check,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",IEEE,12/8/2005 0:00,ieeexplore,architectures for wireless sensor networks,https://ieeexplore.ieee.org/document/1595552/,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,data centric architecture,16,included
10.1109/cast.2016.7914932,to_check,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",IEEE,12/21/2016 0:00,ieeexplore,big data architecture with mobile cloud in cdroid operating system for storing huge data,https://ieeexplore.ieee.org/document/7914932/,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,data centric architecture,17,included
10.1109/waina.2013.19,to_check,2013 27th International Conference on Advanced Information Networking and Applications Workshops,IEEE,3/28/2013 0:00,ieeexplore,ccn-tv: a data-centric approach to real-time video services,https://ieeexplore.ieee.org/document/6550523/,"Content-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCN-TV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies.",data centric architecture,18,included
10.1109/bigdata.2015.7363971,to_check,2015 IEEE International Conference on Big Data (Big Data),IEEE,11/1/2015 0:00,ieeexplore,component based dataflow processing framework,https://ieeexplore.ieee.org/document/7363971/,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",data centric architecture,19,included
10.1109/icsea.2010.30,to_check,2010 Fifth International Conference on Software Engineering Advances,IEEE,8/27/2010 0:00,ieeexplore,content server architecture pattern for evolvability and scalability,https://ieeexplore.ieee.org/document/5615125/,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",data centric architecture,20,included
10.1109/aero.2005.1559422,to_check,2005 IEEE Aerospace Conference,IEEE,3/12/2005 0:00,ieeexplore,"data centric, position-based routing in space networks",https://ieeexplore.ieee.org/document/1559422/,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",data centric architecture,21,included
10.1109/icccn.2019.8847129,to_check,2019 28th International Conference on Computer Communication and Networks (ICCCN),IEEE,8/1/2019 0:00,ieeexplore,data-centric video for mixed reality,https://ieeexplore.ieee.org/document/8847129/,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",data centric architecture,22,included
10.1109/netsys.2019.8854515,to_check,2019 International Conference on Networked Systems (NetSys),IEEE,3/21/2019 0:00,ieeexplore,information-centric iot middleware overlay: vsl,https://ieeexplore.ieee.org/document/8854515/,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",data centric architecture,23,included
10.1109/trustcom.2016.0248,to_check,2016 IEEE Trustcom/BigDataSE/ISPA,IEEE,8/26/2016 0:00,ieeexplore,rethinking high performance computing system architecture for scientific big data applications,https://ieeexplore.ieee.org/document/7847131/,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",data centric architecture,24,included
10.1109/aero.2017.7943816,to_check,2017 IEEE Aerospace Conference,IEEE,3/11/2017 0:00,ieeexplore,software architecture and design of the kontur-2 mission,https://ieeexplore.ieee.org/document/7943816/,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",data centric architecture,25,not included
10.1109/ciot.2018.8627124,to_check,2018 3rd Cloudification of the Internet of Things (CIoT),IEEE,7/4/2018 0:00,ieeexplore,"fogø5: unifying the computing, networking and storage fabrics end-to-end",https://ieeexplore.ieee.org/document/8627124/,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",data centric architecture,26,included
10.1109/tcc.2015.2474385,to_check,IEEE Transactions on Cloud Computing,IEEE,6/1/2020 0:00,ieeexplore,cross-cloud mapreduce for big data,https://ieeexplore.ieee.org/document/7229313/,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",data centric architecture,27,included
10.1147/jrd.2019.2960220,to_check,IBM Journal of Research and Development,IBM,7/1/2020 0:00,ieeexplore,the coral supercomputer systems,https://ieeexplore.ieee.org/document/8935422/,"In 2014, the U.S. Department of Energy (DoE) initiated a multiyear collaboration between Oak Ridge National Laboratory (ORNL), Argonne National Laboratory, and Lawrence Livermore National Laboratory (LLNL), known as “CORAL,” the next major phase in the DoE's scientific computing roadmap. The IBM CORAL systems are based on a fundamentally new data-centric architecture, where compute power is embedded everywhere data resides, combining powerful central processing units (CPUs) with graphics processing units (GPUs) optimized for scientific computing and artificial intelligence workloads. The IBM CORAL systems were built on the combination of mature technologies: 9th-generation POWER CPU, 6th-generation NVIDIA GPU, and 5th-generation Mellanox InfiniBand. These systems are providing scientists with computing power to solve challenges in many research areas beyond previously possible. This article provides an overview of the system solutions deployed at ORNL and LLNL.",data centric architecture,28,included
10.1049/cp.2012.1116,to_check,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),IET,3/5/2012 0:00,ieeexplore,design of real-time distributed system using dds,https://ieeexplore.ieee.org/document/6492723/,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,data centric architecture,29,included
10.1109/bigdata47090.2019.9006235,to_check,2019 IEEE International Conference on Big Data (Big Data),IEEE,12/12/2019 0:00,ieeexplore,hybrid 2d and 3d visual analytics of network simulation data,https://ieeexplore.ieee.org/document/9006235/,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,30,included
10.1109/iccworkshops49005.2020.9145301,to_check,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,6/11/2020 0:00,ieeexplore,supporting delay tolerant networking: a comparative study of epidemic routing and ndn,https://ieeexplore.ieee.org/document/9145301/,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",data centric architecture,31,not included
http://arxiv.org/abs/1705.04958v1,to_check,arxiv,arxiv,5/14/2017 0:00,arxiv,a proposed architecture for big data driven supply chain analytics,http://arxiv.org/abs/1705.04958v1,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.",data centric architecture,32,included
10.1016/j.future.2021.06.020,to_check,core,'Elsevier BV',6/19/2023 0:00,core,a big data-centric architecture metamodel for industry 4.0,,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",data centric architecture,33,included
10.2514/6.2012-549,to_check,core,,1/1/2012 0:00,core,towards a unified framework using cpacs for geometry management in aircraft design,,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",data centric architecture,34,included
10.1002/dac.2964,to_check,core,"John Wiley & Sons, Inc.",1/1/2017 0:00,core,push applications and dynamic content generation over content-centric networking,,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",data centric architecture,35,included
10.1109/i-span.2009.67,to_check,"2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks",IEEE,12/16/2009 0:00,ieeexplore,a data-driven architecture for remote control of sensors over a wireless sensor network and the internet,https://ieeexplore.ieee.org/document/5381871/,"This study revealed an applicable architecture in which a data-driven mechanism was designed to bridge a wireless sensor network (WSN) and the Internet. The system was divided into two independent parts. The first part is the data communication between the sensor network and the database. The other part is the data communication between the database and the user interface (UI). These two parts are connected by the database server. Asynchronous interoperation was introduced while exchanging data between these two parts. Users were not allowed to control the sensors through direct connection to the sensors and can only use the Web service to update the sensor profile built in the database. The sensors were triggered to start the action through a data-update event from the database. A sensor profile built in the database collected all sensor information and all user control command. For the information to be centralized and triggered by the database, regardless of whether sensors were measured in a periodic sampling or an event-driven environment, all sensor actions were triggered through a data-update event in the database. For the sake of improving user experience, a Web-based UI was implemented using scalable vector graphics (SVG) and Ajax technologies. All operations by users were conducted through the Hypertext Transfer Protocol (HTTP) standard method. Therefore, this system can be used via a browser and easily deployed. The proposed architecture is suitable for a healthcare system, a personal body area network, and the Infranet for control.",data driven architecture,36,included
10.1109/sensors47125.2020.9278616,to_check,2020 IEEE SENSORS,IEEE,10/28/2020 0:00,ieeexplore,a data-driven architecture for sensor validation based on neural networks,https://ieeexplore.ieee.org/document/9278616/,"In this paper, we propose a novel sensor validation architecture, which performs sensor fault detection, isolation and accommodation (SFDIA). More specifically, a machine-learning based architecture is presented to detect faults in sensors measurements within the system, identify the faulty ones and replace them with estimated values. In our proposed architecture, sensor estimators based on neural networks are constructed for each sensor node in order to accommodate faulty measurements along with a classifier to determine the failure detection and isolation. Finally, numerical results are presented to confirm the effectiveness of the proposed architecture on a publicly-available air quality (AQ) chemical multi-sensor data-set.",data driven architecture,37,not included
10.1109/bigcomp51126.2021.00080,to_check,2021 IEEE International Conference on Big Data and Smart Computing (BigComp),IEEE,1/20/2021 0:00,ieeexplore,a modular data-driven architecture for empathetic conversational agents,https://ieeexplore.ieee.org/document/9373265/,"Empathy is a fundamental mechanism of human interactions. As such, it should be an integral part of Human-Computer Interaction systems to make them more relatable. With this work, we focused on conversational scenarios where integrating empathy is crucial to perceive the computer like a human. As a result, we derived the high-level architecture of an Empathetic Conversational Agent we are willing to implement. We relied on theories about artificial empathy to derive the function approximating this mechanism and selected the conversational aspects to control for an empathetic interaction. In particular, we designed a core empathetic controller manages the empathetic responses, predicting, at each turn, the high-level content of the response. The derived architecture integrates empathy in a task-agnostic manner; hence we can employ it in multiple scenarios by changing the objective of the controller.",data driven architecture,38,not included
10.1109/lra.2019.2896485,to_check,IEEE Robotics and Automation Letters,IEEE,4/1/2019 0:00,ieeexplore,learning from humans how to grasp: a data-driven architecture for autonomous grasping with anthropomorphic soft hands,https://ieeexplore.ieee.org/document/8629968/,"Soft hands are robotic systems that embed compliant elements in their mechanical design. This enables an effective adaptation with the items and the environment, and ultimately, an increase in their grasping performance. These hands come with clear advantages in terms of ease-to-use and robustness if compared with classic rigid hands, when operated by a human. However, their potential for autonomous grasping is still largely unexplored, due to the lack of suitable control strategies. To address this issue, in this letter, we propose an approach to enable soft hands to autonomously grasp objects, starting from the observations of human strategies. A classifier realized through a deep neural network takes as input the visual information on the object to be grasped, and predicts which action a human would perform to achieve the goal. This information is hence used to select one among a set of human-inspired primitives, which define the evolution of the soft hand posture as a combination of anticipatory action and touch-based reactive grasp. The architecture is completed by the hardware component, which consists of an RGB camera to look at the scene, a 7-DoF manipulator, and a soft hand. The latter is equipped with inertial measurement units at the fingernails for detecting contact with the object. We extensively tested the proposed architecture with 20 objects, achieving a success rate of 81.1% over 111 grasps.",data driven architecture,39,not included
10.1109/nssmic.1998.775181,to_check,1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255),IEEE,11/14/1998 0:00,ieeexplore,a 16-channel digital tdc chip,https://ieeexplore.ieee.org/document/775181/,"A 16-channel digital TDC chip has been built for the DIRC Cerenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns and the full-scale 32 microseconds. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The linearity is better than 80 ps rms on 90% of the production parts.",data driven architecture,40,not included
10.1109/emwrts.1996.557821,to_check,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,IEEE,6/14/1996 0:00,ieeexplore,an embedded accelerator for real-time image processing,https://ieeexplore.ieee.org/document/557821/,"The paper presents an embedded reconfigurable accelerator called Xputer, comprising a novel kind of sequencer hardware (data sequencer). For many real-time signal processing, multimedia, and other high-performance applications this new data-driven architecture increases the performance of a single processor system enormously by integrating it as a co-processor for accelerating computation-intensive parts of an application. The reconfigurable architecture and programming environment is described. Its use is illustrated with an automotive application requiring real-time image processing.",data driven architecture,41,not included
10.1109/geoinformatics.2010.5567735,to_check,2010 18th International Conference on Geoinformatics,IEEE,6/20/2010 0:00,ieeexplore,an integrated spatio-temporal modeling and analysis framework for climate change research,https://ieeexplore.ieee.org/document/5567735/,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It's brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.",data driven architecture,42,not included
10.1109/fpt.2010.5681493,to_check,2010 International Conference on Field-Programmable Technology,IEEE,12/10/2010 0:00,ieeexplore,automatic synthesis of processor arrays with local memories on fpgas,https://ieeexplore.ieee.org/document/5681493/,"In this paper, we present an automatic synthesis framework to map loop nests to processor arrays with local memories on FPGAs. An affine transformation approach is firstly proposed to address space-time mapping problem. Then a data-driven architecture model is introduced to enable automatic generation of processor arrays by extracting this data-driven architecture model from transformed loop nests. Some techniques including memory allocation, communication generation and control generation are presented. Synthesizable RTL codes can be easily generated from the architecture model built by these techniques. A preliminary synthesis tool is implemented based on PLUTO, an automatic polyhedral source-to-source transformation and parallelization framework.",data driven architecture,43,not included
10.1109/icws.2008.147,to_check,2008 IEEE International Conference on Web Services,IEEE,9/26/2008 0:00,ieeexplore,common business components and services toward more agile and flexible industry solutions and assets,https://ieeexplore.ieee.org/document/4670150/,"In many decades, many organizations, especially large consulting companies, have been designing, implementing and managing business solutions for every industry around the globe. But due to numerous limitations in process, tooling and skills, most of those solutions were made very specific to individual industry and client needs at its early design stage. Therefore, reuse and more importantly, managing the ever changing business requirements, become almost impossible. Service-orientation and architecture, model-driven business development provides us a new and powerful approach to facilitate asset based industry solution design and development. To further accelerate this, this tutorial will discuss an innovative approach that take advantage of many proven best software engineering practices, from object/component based technology, meta-data driven architecture types (archetypes) that are used to model the common structural and in some cases non-structural business entities such as customer, product, payment, etc. In order to address the consequences introduced by abstracting those common elements out of the specific industry model and be able to enable easy and meta-data based transformation, we properly decompose business components/services into a multi-layered business architecture. Therefore, process/components/services can be decomposed accordingly to facilitate the decomposition and abstraction, while maintaining certain level of necessary traceability across various artifacts. In the realization phase, existing assets/operational systems will be mapped and transformed to the required business components and services to best leverage those existing valuable industry/client investments. To support such a SOA based, model and business driven development process, existing tooling, especially the necessary transformation and integration capability, needs to be significantly enhanced. This tutorial will also present some recommendation based on some recent design and implementation, and they could be used to guide future tooling alignment and integration effort across software modeling, implementation and solution products. In addition, we will present how to leverage existing internal or external assets or product offerings and the open industry reference models and standards (such as ACCORD, ebXML, ARTS/IxRetail). This work is based on authors' collective experience in leading the large end-to-end client engagements across many industries, while promoting various industry leading software engineering best practices.",data driven architecture,44,not included
10.1109/tina.1997.660723,to_check,Proceedings TINA '97 - Global Convergence of Telecommunications and Distributed Object Computing,IEEE,11/20/1997 0:00,ieeexplore,data-driven implementation of tina kernel transport network,https://ieeexplore.ieee.org/document/660723/,"To realize the actual TINA-based telecommunications network, the performance of the kernel Transport Network (kTN) such as availability, reliability, throughput and load tolerance becomes more crucial than for existing computer networks. The authors have been studying and developing a super-integrated data-driven processor to be applied to the TINA kTN nodes and network interfaces in CUE (Coordinating Users' requirements and Engineering constraints) project. Since the processor is primarily designed to be a scalable VLSI component, it is easily interconnected to form a super-integrated chip and multi-chip system for achieving the performance and reliability demanded in a TINA environment. We first examine the requirements for kTN. A stream-oriented data-driven architecture is then proposed with special emphasis on effective multiprocessing capability with overload tolerance. After that, we demonstrate that autonomous load balancing among super-integrated data-driven processors without adding any runtime overhead to achieve effective and reliable multiprocessing is possible by utilizing the overload tolerance of the processor. Finally, this paper shows preliminary performance estimations of the super-integrated data-driven processor being developed to perform efficient multiprocessing in protocol handling such as TCP/IP.",data driven architecture,45,included
10.1109/sam48682.2020.9104367,to_check,2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,6/11/2020 0:00,ieeexplore,deep radar waveform design for efficient automotive radar sensing,https://ieeexplore.ieee.org/document/9104367/,"In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a wellknown unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.",data driven architecture,46,not included
10.1109/nssmic.2004.1466709,to_check,IEEE Symposium Conference Record Nuclear Science 2004.,IEEE,10/22/2004 0:00,ieeexplore,design and evaluation of the clear-pem detector for positron emission mammography,https://ieeexplore.ieee.org/document/1466709/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with adequate field-of-view dimensions for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,47,included
10.1109/cac.2017.8244168,to_check,2017 Chinese Automation Congress (CAC),IEEE,10/22/2017 0:00,ieeexplore,design and implementation of data-driven based universal data editing framework,https://ieeexplore.ieee.org/document/8244168/,"Apply Integrated Logistics Support (ILS) to weapon equipment can efficiently improve equipment's automation and digital level. ILS needs support of various integrated support systems, which have demands for data editing. Nowadays, most of data editing software used in these systems are customized and provide a form-based editing approach, which becomes an obstacle to carry out ILS. This paper brings forward to design a data-driven based universal data editing framework. In this framework, data models are taken as input and only corresponding data models need to be modified when data change. Firstly, the whole development process of data editing software that adopt form-based development mode is analyzed in detail to find out problems exists in this development mode. Then the data-driven based universal data editing framework is designed. New idea of data-driven architecture is proposed. Data-driven architecture takes data models as input and processes all data models in a universal way. Finally, key technology for framework realization is given.",data driven architecture,48,included
10.1109/nssmic.2000.949945,to_check,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,10/20/2000 0:00,ieeexplore,error handling for the cdf silicon vertex tracker,https://ieeexplore.ieee.org/document/949945/,"The SVT online tracker for the CDF upgrade reconstructs two-dimensional tracks using information from the Silicon Vertex detector (SVXII) and the Central Outer Tracker (COT). The SVT has an event rate of 100 kHz and a latency time of 10 /spl mu/s. The system is composed of 104 VME 9U digital boards (of 8 different types) and it is implemented as a data driven architecture. Each board runs on its own 30 MHz clock. Since the data output from the SVT (few Mbytes/sec) are a small fraction of the input data (200 Mbytes/sec), it is extremely difficult to track possible internal errors by using only the output stream. For this reason several diagnostic tools have been implemented: local error registers, error bits propagated through the data streams and the Spy Buffer system. Data flowing through each input and output stream of every board are continuously copied to memory banks named Spy Buffers which act as built in logic state analyzers hooked continuously to internal data streams. The contents of all buffers can be frozen at any time (e.g. on error detection) to take a snapshot of all data flowing through each SVT board. The Spy Buffers are coordinated at system level by the Spy Control Board. The architecture, design and implementation of this system are described.",data driven architecture,49,included
10.1109/isit45174.2021.9517812,to_check,2021 IEEE International Symposium on Information Theory (ISIT),IEEE,7/20/2021 0:00,ieeexplore,model-inspired deep detection with low-resolution receivers,https://ieeexplore.ieee.org/document/9517812/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector network, called LoRD-Net, for signal recovering from one-bit measurements. Our approach relies on a model-aware data-driven architecture, based on a deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely ~ 500 samples, for training.",data driven architecture,50,not included
10.1109/icc42927.2021.9500961,to_check,ICC 2021 - IEEE International Conference on Communications,IEEE,6/23/2021 0:00,ieeexplore,removing channel estimation by location-only based deep learning for ris aided mobile edge computing,https://ieeexplore.ieee.org/document/9500961/,"In this paper, we investigate a deep learning architecture for lightweight online implementation of a reconfigurable intelligent surface (RIS)-aided multi-user mobile edge computing (MEC) system, where the optimized performance can be achieved based on user equipment’s (UEs’) location-only information. Assuming that each UE is endowed with a limited energy budget, we aim at maximizing the total completed task-input bits (TCTB) of all UEs within a given time slot, through jointly optimizing the RIS reflecting coefficients, the receive beamforming vectors, and UEs’ energy partition strategies for local computing and computation offloading. Due to the coupled optimization variables, a three-step block coordinate descending (BCD) algorithm is first proposed to effectively solve the formulated TCTB maximization problem iteratively with guaranteed convergence. The location-only deep learning architecture is then constructed to emulate the proposed BCD optimization algorithm, through which the pilot channel estimation and feedback can be removed for online implementation with low complexity. The simulation results reveal a close match between the performance of the BCD optimization algorithm and the location-only data-driven architecture, all with superior performance to existing benchmarks.",data driven architecture,51,not included
10.1109/30.982782,to_check,IEEE Transactions on Consumer Electronics,IEEE,11/1/2001 0:00,ieeexplore,a novel hdtv video decoder and decentralized control scheme,https://ieeexplore.ieee.org/document/982782/,"A novel dedicated architecture for an HDTV video decoding chip is developed. Each task is mapped to a highly optimized hardware unit by classifying the video processing tasks into three levels. On the function level, a data driven architecture is adopted to make each processing unit operate once the processing data and buffer are available. Therefore the high computing efficiency of each unit is exploited, hardware is saved, and the computing capability is maximized compared with conventional pipeline decoder. On the system level, a decentralized control scheme is designed to provide high efficient communication between all the processing units to yield the best overall performance. Moreover it features simple control logic and minimum size of the connecting buffers.",data driven architecture,52,included
10.1109/tns.2006.870173,to_check,IEEE Transactions on Nuclear Science,IEEE,2/1/2006 0:00,ieeexplore,design and evaluation of the clear-pem scanner for positron emission mammography,https://ieeexplore.ieee.org/document/1610954/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities, and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with dimensions 16.5/spl times/14.5 cm/sup 2/ for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,53,included
10.1109/access.2021.3071274,to_check,IEEE Access,IEEE,1/1/2021 0:00,ieeexplore,graph neural network: a comprehensive review on non-euclidean space,https://ieeexplore.ieee.org/document/9395439/,"This review provides a comprehensive overview of the state-of-the-art methods of graph-based networks from a deep learning perspective. Graph networks provide a generalized form to exploit non-euclidean space data. A graph can be visualized as an aggregation of nodes and edges without having any order. Data-driven architecture tends to follow a fixed neural network trying to find the pattern in feature space. These strategies have successfully been applied to many applications for euclidean space data. Since graph data in a non-euclidean space does not follow any kind of order, these solutions can be applied to exploit the node relationships. Graph Neural Networks (GNNs) solve this problem by exploiting the relationships among graph data. Recent developments in computational hardware and optimization allow graph networks possible to learn the complex graph relationships. Graph networks are therefore being actively used to solve many problems including protein interface, classification, and learning representations of fingerprints. To encapsulate the importance of graph models, in this paper, we formulate a systematic categorization of GNN models according to their applications from theory to real-life problems and provide a direction of the future scope for the applications of graph models as well as highlight the limitations of existing graph networks.",data driven architecture,54,not included
10.1109/tsp.2021.3117503,to_check,IEEE Transactions on Signal Processing,IEEE,1/1/2021 0:00,ieeexplore,lord-net: unfolded deep detection network with low-resolution receivers,https://ieeexplore.ieee.org/document/9557819/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector entitled LoRD-Net for recovering information symbols from one-bit measurements. Our method is a model-aware data-driven architecture based on deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. LoRD-Net operates in a blind fashion, which requires addressing both the non-linear nature of the data-acquisition system as well as identifying a proper optimization objective for signal recovery. Accordingly, we propose a two-stage training method for LoRD-Net, in which the first stage is dedicated to identifying the proper form of the optimization process to unfold, while the latter trains the resulting model in an end-to-end manner. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely <inline-formula><tex-math notation=""LaTeX"">$\sim 500$</tex-math></inline-formula> samples, for training.",data driven architecture,55,not included
10.1109/access.2021.3091716,to_check,IEEE Access,IEEE,1/1/2021 0:00,ieeexplore,modeling and key technologies of a data-driven smart city system,https://ieeexplore.ieee.org/document/9462829/,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a `two-dimension, three-layer, and six-goal' top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated.",data driven architecture,56,included
10.1109/tkde.2019.2953839,to_check,IEEE Transactions on Knowledge and Data Engineering,IEEE,6/1/2021 0:00,ieeexplore,open relation extraction for chinese noun phrases,https://ieeexplore.ieee.org/document/8903488/,"Relation Extraction (RE) aims at harvesting relational facts from texts. A majority of existing research targets at knowledge acquisition from sentences, where subject-verb-object structures are usually treated as the signals of existence of relations. In contrast, relational facts expressed within noun phrases are highly implicit. Previous works mostly relies on human-compiled assertions and textual patterns in English to address noun phrase-based RE. For Chinese, the corresponding task is non-trivial because Chinese is a highly analytic language with flexible expressions. Additionally, noun phrases tend to be incomplete in grammatical structures, where clear mentions of predicates are often missing. In this article, we present an unsupervised Noun Phrase-based Open RE system for the Chinese language (NPORE), which employs a three-layer data-driven architecture. The system contains three components, i.e., Modifier-sensitive Phrase Segmenter, Candidate Relation Generator and Missing Relation Predicate Detector. It integrates with a graph clique mining algorithm to chunk Chinese noun phrases, considering how relations are expressed. We further propose a probabilistic method with knowledge priors and a hypergraph-based random walk process to detect missing relation predicates. Experiments over Chinese Wikipedia show NPORE outperforms state-of-the-art, capable of extracting 55.2 percent more relations than the most competitive baseline, with a comparable precision at 95.4 percent.",data driven architecture,57,not included
10.1109/acc.2013.6580528,to_check,2013 American Control Conference,IEEE,6/19/2013 0:00,ieeexplore,data-driven design of kpi-related fault-tolerant control system for wind turbines,https://ieeexplore.ieee.org/document/6580528/,"In this paper, a scheme for an integrated design of fault-tolerant control (FTC) systems for a wind turbine benchmark is proposed, with focus on the overall performance of the system. For that a key performance indicator (KPI) which reflects the economic performance of the system is defined, and the objective of the proposed FTC scheme is to maintain the system KPI in the admissible range in faulty conditions. The basic idea behind this scheme is data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilizing controllers with an embedded residual generator for fault detection (FD) purpose. The performance and effectiveness of the proposed scheme are demonstrated through the wind turbine benchmark model proposed in [1].",data driven architecture,58,not included
10.23919/acc50511.2021.9482806,to_check,2021 American Control Conference (ACC),IEEE,5/28/2021 0:00,ieeexplore,direct data-driven design of switching controllers for constrained systems,https://ieeexplore.ieee.org/document/9482806/,"This paper presents a hierarchical structure to directly design controllers for (possibly nonlinear) constrained systems. The proposed architecture combines the advantages of an inner data-driven switching controller designed to achieve a predefined closed-loop behavior and an outer model predictive controller, which is used as a reference governor. These design choices enable us to avoid the identification step typical of model-based approaches while exploiting the ability of model predictive controllers to handle constraints and optimize the closed-loop performance. As a proof of concept, a benchmark simulation example is used to demonstrate the effectiveness of the proposed strategy.",data driven architecture,59,not included
10.1109/tii.2018.2843124,to_check,IEEE Transactions on Industrial Informatics,IEEE,10/1/2018 0:00,ieeexplore,data-driven design of fog-computing-aided process monitoring system for large-scale industrial processes,https://ieeexplore.ieee.org/document/8370742/,"Stimulated by the recent development of fog computing technology, in this paper, a fog-computing-aided process monitoring and control architecture is proposed for large-scale industrial processes, which enables reliable and efficient online performance optimization in each fog computing node without modifying predesigned control subsystems. Moreover, a closed-loop data-driven method is developed for the process monitoring system design and an adaptive configuration approach is proposed to deal with the problems caused by the changes of process parameters and operating points. The feasibility and effectiveness of the proposed design approaches are verified and demonstrated through the case study on the Tennessee Eastman benchmark system.",data driven architecture,60,not included
10.1109/spawc51858.2021.9593131,to_check,2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),IEEE,9/30/2021 0:00,ieeexplore,fast power control adaptation via meta-learning for random edge graph neural networks,https://ieeexplore.ieee.org/document/9593131/,"Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,61,not included
10.1109/tie.2013.2273477,to_check,IEEE Transactions on Industrial Electronics,IEEE,5/1/2014 0:00,ieeexplore,real-time implementation of fault-tolerant control systems with performance optimization,https://ieeexplore.ieee.org/document/6560360/,"In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.",data driven architecture,62,not included
10.1007/s10845-018-1430-y,to_check,Journal of Intelligent Manufacturing,Springer,1/1/2020 0:00,springer,"a data-driven cyber-physical approach for personalised smart, connected product co-development in a cloud-based environment",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-018-1430-y,"The rapid development of information and communication technology enables a promising market of information densely product, i.e. smart, connected product (SCP), and also changes the way of user–designer interaction in the product development process. For SCP, massive data generated by users drives its design innovation and somehow determines its final success. Nevertheless, most existing works only look at the new functionalities or values that are derived in the one-way communication by introducing novel data analytics methods. Few work discusses about an effective and systematic approach to enable individual user innovation in such context, i.e. co-development process, which sets the fundamental basis of the prevailing concept of data-driven design. Aiming to fill this gap, this paper proposes a generic data-driven cyber-physical approach for personalised SCP co-development in a cloud-based environment. A novel concept of smart, connected, open architecture product is hence introduced with a generic cyber-physical model established in a cloud-based environment, of which the interaction processes are enabled by co-development toolkits with smartness and connectedness. Both the personalized SCP modelling method and the establishment of its cyber-physical product model are described in details. To further demonstrate the proposed approach, a case study of a smart wearable device (i.e. i-BRE respiratory mask) development process is given with general discussions.",data driven architecture,63,included
10.1007/978-3-319-75429-1_18,to_check,Integrated Uncertainty in Knowledge Modelling and Decision Making,Springer,1/1/2018 0:00,springer,big data driven architecture for medical knowledge management systems in intracranial hemorrhage diagnosis,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75429-1_18,"Stroke is the most common and dangerous cerebrovascular disease. According to the statistics from World Health Organization (WHO), only following heart attack, stroke is one of the two leading causes of human deaths. In addition, in Vietnam, a shortage of specialized equipment and qualified professionals is becoming a significant problem for not only accurate diagnosis but also timely and effective treatment of stroke, especially intracranial hemorrhage (ICH), an acute case of stroke. This research will analyze challenges and show solutions for constructing an effective knowledge system in ICH diagnosis and treatment that helps to shorten professional gap among hospitals and regions. We suggest a service-oriented architecture for the big data driven knowledge system based on medical imaging of ICH. The architecture ensures the development of knowledge obeying a systematic and complete process including the exploration and exploitation of knowledge from medical imaging. Besides, the architecture adapts to modern trends in knowledge service modeling.",data driven architecture,64,included
10.1007/978-3-319-07863-2_21,to_check,Human Interface and the Management of Information. Information and Knowledge in Applications and Services,Springer,1/1/2014 0:00,springer,data driven enterprise ux: a case study of enterprise management systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07863-2_21,"This paper describes and makes a case for a data driven user experience design process for Enterprise IT. The method described employs an approach that focuses on defining the key modules (objects) in an enterprise IT software and the data sets used by these modules very early in the design process. We discuss how mapping parent child relationships between key entities in the software and the linked data helps create a holistic view of the product ecosystem which in turn allows the designer to create an uncluttered information architecture and user journey that maps closely to mental construct of the system in the user’s mind. We further argue that in the present age of big data, working with well-defined data sets and visible data relationships creates a valuable information repository for the designer to take decisions regarding task optimization and building business intelligence in the system itself. We also discuss the urgent need, advantages and methods of ‘consumerizing’ the Enterprise UI to increase users productivity and reduce the learning curve. Lastly, these ideas are exemplified through a real life case study for an enterprise server management system.",data driven architecture,65,not included
10.1007/978-3-642-39200-9_5,to_check,Web Engineering,Springer,1/1/2013 0:00,springer,semantic data driven interfaces for web applications,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39200-9_5,"Modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. These conditions require interfaces that can adapt to the changes in the <user, platform, environment> triad. The Model-Based User Interface approach has been proposed as a way to deal with these requirements. In this paper we present a data-driven, rule-based interface definition model capable of taking into account the semantics of the data it is manipulating, especially in the case of Linked Data. An implementation architecture based on the Synth environment supporting this model is presented.",data driven architecture,66,included
10.1007/978-3-642-23333-3_4,to_check,Electronic Participation,Springer,1/1/2011 0:00,springer,combining social and government open data for participatory decision-making,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23333-3_4,"In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making.",data driven architecture,67,not included
10.1007/978-3-642-04492-2_21,to_check,Management Enabling the Future Internet for Changing Business and New Computing Services,Springer,1/1/2009 0:00,springer,the proposal of service delivery platform built on distributed data driven architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04492-2_21,"SDP (Service Delivery Platform) is a recommended system platform for NGN (Next Generation Network) that is expected to resolve two common system running problems: one is functional aspects such as high availability and providing effective maintenance methods, the other is cost aspects such as simplifying development method of a service. However, SDP is still on the way to be standardized, and its architecture has two problems: the congestion of service requests and flexibility of enabler, a service component of SDP. This paper explains how to build a SDP by adopting Distributed Data Driven Architecture and how our system resolves the problems by evaluating the prototype.",data driven architecture,68,included
10.1007/978-94-015-8196-7_6,to_check,Linear Algebra for Large Scale and Real-Time Applications,Springer,1/1/1993 0:00,springer,a parallel image rendering algorithm and architecture based on ray tracing and radiosity shading,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-015-8196-7_6,"Algorithms for rendering color scenes on a video screen potentially belong to the class of massively parallel algorithms. Developing effective and efficient data-driven architectures for algorithms from this class is in general a hard problem. However, in case of application specific algorithms, such as the rendering algorithm described in this paper, feasible solutions are conceivable. The parallel algorithm/architecture presented in this paper is a linear speed-up accelerator for the rendering of photo realistic scenes in interaction time.",data driven architecture,69,included
http://arxiv.org/abs/2202.07448v1,to_check,arxiv,arxiv,2/4/2022 0:00,arxiv,"towards a unified pandemic management architecture: survey, challenges
  and future directions",http://arxiv.org/abs/2202.07448v1,"The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,
economy and society worldwide. Emerging strains are making pandemic management
increasingly challenging. There is an urge to collect epidemiological,
clinical, and physiological data to make an informed decision on mitigation
measures. Advances in the Internet of Things (IoT) and edge computing provide
solutions for pandemic management through data collection and intelligent
computation. While existing data-driven architectures attempt to automate
decision-making, they do not capture the multifaceted interaction among
computational models, communication infrastructure, and the generated data. In
this paper, we perform a survey of the existing approaches for pandemic
management, including online data repositories and contact-tracing
applications. We then envision a unified pandemic management architecture that
leverages the IoT and edge computing to automate recommendations on vaccine
distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We
elucidate the flow of data among the layers of the architecture, namely, cloud,
edge and end device layers. Moreover, we address the privacy implications,
threats, regulations, and existing solutions that may be adapted to optimize
the utility of health data with security guarantees. The paper ends with a
lowdown on the limitations of the architecture and research directions to
enhance its practicality.",data driven architecture,70,included
http://arxiv.org/abs/2110.09005v1,to_check,arxiv,arxiv,10/18/2021 0:00,arxiv,unsupervised learned kalman filtering,http://arxiv.org/abs/2110.09005v1,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.",data driven architecture,71,not included
http://arxiv.org/abs/2108.13178v1,to_check,arxiv,arxiv,8/4/2021 0:00,arxiv,"black-box and modular meta-learning for power control via random edge
  graph neural networks",http://arxiv.org/abs/2108.13178v1,"In this paper, we consider the problem of power control for a wireless
network with an arbitrarily time-varying topology, including the possible
addition or removal of nodes. A data-driven design methodology that leverages
graph neural networks (GNNs) is adopted in order to efficiently parametrize the
power control policy mapping the channel state information (CSI) to transmit
powers. The specific GNN architecture, known as random edge GNN (REGNN),
defines a non-linear graph convolutional filter whose spatial weights are tied
to the channel coefficients. While prior work assumed a joint training approach
whereby the REGNN-based policy is shared across all topologies, this paper
targets adaptation of the power control policy based on limited CSI data
regarding the current topology. To this end, we propose both black-box and
modular meta-learning techniques. Black-box meta-learning optimizes a
general-purpose adaptation procedure via (stochastic) gradient descent, while
modular meta-learning finds a set of reusable modules that can form components
of a solution for any new network topology. Numerical results validate the
benefits of meta-learning for power control problems over joint training
schemes, and demonstrate the advantages of modular meta-learning when data
availability is extremely limited.",data driven architecture,72,not included
http://arxiv.org/abs/2105.00459v1,to_check,arxiv,arxiv,5/2/2021 0:00,arxiv,"fast power control adaptation via meta-learning for random edge graph
  neural networks",http://arxiv.org/abs/2105.00459v1,"Power control in decentralized wireless networks poses a complex stochastic
optimization problem when formulated as the maximization of the average sum
rate for arbitrary interference graphs. Recent work has introduced data-driven
design methods that leverage graph neural network (GNN) to efficiently
parametrize the power control policy mapping channel state information (CSI) to
the power vector. The specific GNN architecture, known as random edge GNN
(REGNN), defines a non-linear graph convolutional architecture whose spatial
weights are tied to the channel coefficients, enabling a direct adaption to
channel conditions. This paper studies the higher-level problem of enabling
fast adaption of the power control policy to time-varying topologies. To this
end, we apply first-order meta-learning on data from multiple topologies with
the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,73,not included
http://arxiv.org/abs/1910.06115v1,to_check,arxiv,arxiv,10/11/2019 0:00,arxiv,"microservices based linked data quality model for buildings energy
  management services",http://arxiv.org/abs/1910.06115v1,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality.",data driven architecture,74,not included
http://arxiv.org/abs/1807.06699v5,to_check,arxiv,arxiv,7/17/2018 0:00,arxiv,adaptive neural trees,http://arxiv.org/abs/1807.06699v5,"Deep neural networks and decision trees operate on largely separate
paradigms; typically, the former performs representation learning with
pre-specified architectures, while the latter is characterised by learning
hierarchies over pre-specified features with data-driven architectures. We
unite the two via adaptive neural trees (ANTs) that incorporates representation
learning into edges, routing functions and leaf nodes of a decision tree, along
with a backpropagation-based training algorithm that adaptively grows the
architecture from primitive modules (e.g., convolutional layers). We
demonstrate that, whilst achieving competitive performance on classification
and regression datasets, ANTs benefit from (i) lightweight inference via
conditional computation, (ii) hierarchical separation of features useful to the
task e.g. learning meaningful class associations, such as separating natural
vs. man-made objects, and (iii) a mechanism to adapt the architecture to the
size and complexity of the training dataset.",data driven architecture,75,not included
10.14627/537690036,to_check,core,Wichmann Verlag im VDE Verlag GmbH,1/1/2020 0:00,core,bridging tangible and virtual realities : computational procedures for data-informed participatory processes,,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe",data driven architecture,76,not included
'elsevier bv',to_check,core,https://core.ac.uk/download/146492122.pdf,1/1/2013 0:00,core,10.1016/j.procs.2013.05.357,,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",data driven architecture,77,included
10.5075/epfl-thesis-3545,to_check,core,A multitasking and data-driven architecture for multi-agents simulations,4/24/2006 0:00,core,https://core.ac.uk/download/147916631.pdf,,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach",data driven architecture,78,not included
,to_check,core,,1/1/1994 0:00,core,"a language-independent, data-oriented architecture for grapheme-to-phoneme conversion",,"We report on an implemented grapheme-to-phoneme conversion architecture. Given a set of examples (spelling words with their associated phonetic representation) in a language, a grapheme-to-phoneme conversion system is automatically produced for that language which takes as its input the spelling of words, and produces as its output the phonetic transcription according to the rules implicit in the training data. This paper describes the architecture and focuses on our solution to the alignment problem: given the spelling and the phonetic trancription of a word (often differing in length), these two representations have to be aligned in such a way that grapheme symbols or strings of grapheme symbols are consistently associated with the same phonetic symbol. If this alignment has to be done by hand, it is extremely labour-intensive. 1 Introduction  Grapheme-to-phoneme conversion is an essential module in any text-to-speech system. Various language-specific sources of linguistic knowledge ..",data oriented architecture,79,included
,to_check,core,,1/1/2012 0:00,core,measurements in opportunistic networks,,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",data centric architecture,80,included
,to_check,core,,9/24/2013 0:00,core,s.: persistent information state in a data-centric architecture,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,81,included
,to_check,core,,1/1/2001 0:00,core,adaptive collaboration for wired and wireless platforms - a data-centric architecture for collaboration environments uses xml to adapt shared data dynamically between devices with widely disparate capabilities.,,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",data centric architecture,82,included
,to_check,core,,1/1/2001 0:00,core,emacspeak - toward the speech-enabled semantic www,,"Emacspeak has pioneered the speech-enabling approach to providing intelligent  spoken feedback for a variety of daily computing tasks. This includes audio  formatted output from World Wide Web (WWW) pages by utilizing Aural Cascading  Style Sheets (ACSS). However, until recently such spoken output has been  limited by presentational HTML pages optimized for visual interaction.  The WWW is presently transitioning toward a data-centric architecture; content  ---and its semantics--- is encapsulated in XML ([W3C98]) pages designed to  be served in a manner most appropriate to a given client. This opens up significant  opportunities in generating high-quality spoken feedback from richly encoded  WWW content. Though XML is still in its early stages of wide-spread adoption,  some of the benefits to come can already be seen today. Many sites now offer  access to both presentational HTML, as well as the underlying data. Examples  include historical stock charts, driving directions, and other useful information.  Emacspeak now exploits the availability of such semantically encoded content  to provide a richer end-user experience. This article introduces some of the data  acquisition techniques used in Emacspeak and focuses on the end-user experience  when interacting with such structured information.  ",data centric architecture,83,not included
,to_check,core,,1/1/2011 0:00,core,data serving climate simulation science at the nasa center for climate simulation,https://core.ac.uk/download/pdf/10560731.pdf,"The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",data centric architecture,84,included
,to_check,core,,1/1/2004 0:00,core,wireless sensor networks dynamic runtime configuration,,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",data centric architecture,85,included
,to_check,core,,5/1/2017 0:00,core,resource management in sensing services with audio applications,https://core.ac.uk/download/158321560.pdf,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",data centric architecture,87,included
,to_check,core,,5/19/2012 0:00,core,1 social-driven internet of connected objects,,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",data centric architecture,88,not included
,to_check,core,,1/1/2007 0:00,core,gestion de l'évolution des applications web,,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",data centric architecture,89,not included
,to_check,core,,8/26/2015 0:00,core,adaptive collaboration for wired and wireless platforms,,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",data centric architecture,90,included
,to_check,core,,8/31/2009 0:00,core,a context-oriented synchronization approach,,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",data centric architecture,91,included
,to_check,core,HAL CCSD,3/27/2017 0:00,core,towards blockchain-based auditable storage and sharing of iot data,https://core.ac.uk/download/145154055.pdf,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",data centric architecture,92,included
,to_check,core,,1/1/2018 0:00,core,collaborative systems engineering in the ascent abort-2 crew module/separation ring project,https://core.ac.uk/download/pdf/161999682.pdf,"Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",data centric architecture,93,not included
,to_check,core,,10/11/2019 0:00,core,http://arxiv.org/abs/1910.06115,,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality",data driven architecture,94,not included
,to_check,core,,1/1/2010 0:00,core,10.1109/geoinformatics.2010.5567735,,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",data driven architecture,95,not included
,to_check,core,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",1/1/2008 0:00,core,https://core.ac.uk/download/pdf/195383281.pdf,,"This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",data driven architecture,96,included
987f1feddb599eac1c924ce5dc39f9c57e93d5e0,to_check,semantic_scholar,,40909,semantic_scholar,data-oriented architecture for system integration,https://www.semanticscholar.org/paper/987f1feddb599eac1c924ce5dc39f9c57e93d5e0,"According to the problem that,in the process of integrating large-scale distributed system,the subsystems are difficult to manage,extend,and maintenance,which caused by their different implementation technologies and tightly-coupled design.A pattern of data-oriented design is introduced,and the principle based on the pattern and the related middleware technology were discussed.A data-oriented architecture for system integration was proposed.Finally,based on the example of a real-time package tracking system-of-systems,the architecture of data-oriented integration was discussed in detail.",data oriented architecture,97,unknown
8f07a47646ca8fcc6adb1948b118c0969e844d3b,to_check,semantic_scholar,2010 2nd International Conference on Education Technology and Computer,40179,semantic_scholar,data-oriented architecture of sine,https://www.semanticscholar.org/paper/8f07a47646ca8fcc6adb1948b118c0969e844d3b,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,98,unknown
045c7665e95ae9f0dbdac771ca307c5427ab6426,to_check,semantic_scholar,2010 2nd International Conference on Advanced Computer Control,40179,semantic_scholar,data-oriented architecture of ln function,https://www.semanticscholar.org/paper/045c7665e95ae9f0dbdac771ca307c5427ab6426,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,99,unknown
6d5165205564bc98c1afcf20a1652a21f1e3e61e,to_check,semantic_scholar,,39083,semantic_scholar,data-oriented architecture: a loosely-coupled real-time soa,https://www.semanticscholar.org/paper/6d5165205564bc98c1afcf20a1652a21f1e3e61e,"2007 August "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,100,unknown
585b18385db6eb806e207b797ae7262143b9bd28,to_check,semantic_scholar,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),40179,semantic_scholar,data-oriented architecture of sine and cosine functions,https://www.semanticscholar.org/paper/585b18385db6eb806e207b797ae7262143b9bd28,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,101,unknown
9fc03132540aa5d53f50b875bb4ccb620dee09ea,to_check,semantic_scholar,,39083,semantic_scholar,data-oriented architecture,https://www.semanticscholar.org/paper/9fc03132540aa5d53f50b875bb4ccb620dee09ea,"2007 January "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,102,unknown
f7946ea31a3da644fd59303be9fff721579987fd,to_check,semantic_scholar,IEEE Internet of Things Journal,42736,semantic_scholar,a data-oriented m2m messaging mechanism for industrial iot applications,https://www.semanticscholar.org/paper/f7946ea31a3da644fd59303be9fff721579987fd,"Machine-to-machine (M2M) communication is a key enabling technology for the future industrial Internet of Things applications. It plays an important role in the connectivity and integration of computerized machines, such as sensors, actuators, controllers, and robots. The requirements in flexibility, efficiency, and cross-platform compatibility of the intermodule communication between the connected machines raise challenges for the M2M messaging mechanism toward ubiquitous data access and events notification. This investigation determines the challenges facing the M2M communication of industrial systems and presents a data-oriented M2M messaging mechanism based on ZeroMQ for the ubiquitous data access in rich sensing pervasive industrial applications. To prove the feasibility of the proposed solution, the EU funded PickNPack production line with a reference industrial network architecture is presented, and the communication between a microwave sensor device and the quality assessment and sensing module controller of the PickNPack line is illustrated as a case study. The evaluation is carried out through qualitative analysis and experimental studies, and the results demonstrate the feasibility of the proposed messaging mechanism. Due to the flexibility in dealing with hierarchical system architecture and cross-platform heterogeneity of industrial applications, this messaging mechanism deserves extensive investigations and further evaluations.",data oriented architecture,103,unknown
b0e0e1172296a6da7de25aa40f51cce9614ae8fc,to_check,semantic_scholar,,42005,semantic_scholar,allocation strategies for data-oriented architectures,https://www.semanticscholar.org/paper/b0e0e1172296a6da7de25aa40f51cce9614ae8fc,"Data orientation is a common design principle in distributed data management systems. In contrast to process-oriented or transaction-oriented system designs, dataoriented architectures are based on data locality and function shipping. The tight coupling of data and processing thereon is implemented in different systems in a variety of application scenarios such as data analysis, database-as-a-service, and data management on multiprocessor systems. Data-oriented systems, i.e., systems that implement a data-oriented architecture, bundle data and operations together in tasks which are processed locally on the nodes of the distributed system. Allocation strategies, i.e., methods that decide the mapping from tasks to nodes, are core components in data-oriented systems. Good allocation strategies can lead to balanced systems while bad allocation strategies cause skew in the load and therefore suboptimal application performance and infrastructure utilization. Optimal allocation strategies are hard to find given the complexity of the systems, the complicated interactions of tasks, and the huge solution space. To ensure the scalability of dataoriented systems and to keep them manageable with hundreds of thousands of tasks, thousands of nodes, and dynamic workloads, fast and reliable allocation strategies are mandatory. In this thesis, we develop novel allocation strategies for data-oriented systems based on graph partitioning algorithms. Therefore, we show that systems from different application scenarios with different abstraction levels can be generalized to generic infrastructure and workload descriptions. We use weighted graph representations to model infrastructures with bounded and unbounded, i.e., overcommited, resources and possibly non-linear performance characteristics. Based on our generalized infrastructure and workload model, we formalize the allocation problem, which seeks valid and balanced allocations that minimize communication. Our allocation strategies partition the workload graph using solution heuristics that work with single and multiple vertex weights. Novel extensions to these solution heuristics can be used to balance penalized and secondary graph partition weights. These extensions enable the allocation strategies to handle infrastructures with non-linear performance behavior. On top of the basic algorithms, we propose methods to incorporate heterogeneous infrastructures and to react to changing workloads and infrastructures by incrementally updating the partitioning. We evaluate all components of our allocation strategy algorithms and show their applicability and scalability with synthetic workload graphs. In end-to-end– performance experiments in two actual data-oriented systems, a database-as-aservice system and a database management system for multiprocessor systems, we prove that our allocation strategies outperform alternative state-of-the-art methods.",data oriented architecture,104,unknown
d202d37f5d90cb7fbb7dff2d454fcad944a3176e,to_check,semantic_scholar,GeoInfo,38353,semantic_scholar,local spatial data infrastructures based on a service-oriented architecture,https://www.semanticscholar.org/paper/d202d37f5d90cb7fbb7dff2d454fcad944a3176e,"Sharing geographic information is an essential activity which has been sought since the early days of GIS, mostly due to the cost of information collection and maintenance. Having once depended on the establishment of data transfer standards, sharing initiatives gradually evolved towards the creation of clearinghouses, Web resources that centralize links to various GI sources, but are still data-oriented. The current focus on spatial data infrastructures changes that, by establishing a service-oriented view, thus allowing for the creation of shared, distributed, and interoperable environments through Web services. This paper explores, in a preliminary fashion, such an architecture as applied to distributed geographic applications, focusing on the potential for local services and local uses, and proposing specialized services deemed essential for urban-scale applications.",data oriented architecture,105,unknown
0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,to_check,semantic_scholar,J. Database Manag.,36892,semantic_scholar,a metadata oriented architecture for building datawarehouse,https://www.semanticscholar.org/paper/0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,"Data warehouse is an intelligent store of data that can aggregate vast amounts of information. A metadata is critical for implementing data warehouse. Therefore, integrating data warehouse with its metadata offers a new opportunity to create a more adaptive information system. This paper proposes a metadata-oriented data warehouse architecture that consists of seven components: legacy system, extracting software, operational data store, data warehouse, data mart, application, and metadata. A taxonomy for dataflow and metaflow is proposed for better understanding of the architecture. In addition, a metadata schema is built within the framework of the seven components. The architecture with its metadata component is applied to a real-life data warehouse for a large medical center in order to illustrate its practical usefulness.",data oriented architecture,106,unknown
a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,to_check,semantic_scholar,2019 IEEE/CVF International Conference on Computer Vision (ICCV),43466,semantic_scholar,auto-fpn: automatic network architecture adaptation for object detection beyond classification,https://www.semanticscholar.org/paper/a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,"Abstract Neural architecture search (NAS) has shown great potential in automating the manual process of designing a good CNN architecture for image classification. In this paper, we study NAS for object detection, a core computer vision task that classifies and localizes object instances in an image. Existing works focus on transferring the searched architecture from classification task (ImageNet) to the detector backbone, while the rest of the architecture of the detector remains unchanged. However, this pipeline is not task-specific or data-oriented network search which cannot guarantee optimal adaptation to any dataset. Therefore, we propose an architecture search framework named Auto-FPN specifically designed for detection beyond simply searching a classification backbone. Specifically, we propose two auto search modules for detection: Auto-fusion to search a better fusion of the multi-level features; Auto-head to search a better structure for classification and bounding-box(bbox) regression. Instead of searching for one repeatable cell structure, we relax the constraint and allow different cells. The search space of both modules covers many popular designs of detectors and allows efficient gradient-based architecture search with resource constraint (2 days for COCO on 8 GPU cards). Extensive experiments on Pascal VOC, COCO, BDD, VisualGenome and ADE demonstrate the effectiveness of the proposed method, e.g. achieving around 5% improvement than FPN in terms of mAP while requiring around 50% fewer parameters on the searched modules.",data oriented architecture,107,unknown
a323992739aaa0e477c206fdcad9f7cb87139360,to_check,semantic_scholar,IEEE Transactions on Nanotechnology,42005,semantic_scholar,an energy-efficient nonvolatile in-memory computing architecture for extreme learning machine by domain-wall nanowire devices,https://www.semanticscholar.org/paper/a323992739aaa0e477c206fdcad9f7cb87139360,"The data-oriented applications have introduced increased demands on memory capacity and bandwidth, which raises the need to rethink the architecture of the current computing platforms. The logic-in-memory architecture is highly promising as future logic-memory integration paradigm for high throughput data-driven applications. From memory technology aspect, as one recently introduced nonvolatile memory device, domain-wall nanowire (or race-track) not only shows potential as future power efficient memory, but also computing capacity by its unique physics of spintronics. This paper explores a novel distributed in-memory computing architecture where most logic functions are executed within the memory, which significantly alleviates the bandwidth congestion issue and improves the energy efficiency. The proposed distributed in-memory computing architecture is purely built by domain-wall nanowire, i.e., both memory and logic are implemented by domain-wall nanowire devices. As a case study, neural network-based image resolution enhancement algorithm, called DW-NN, is examined within the proposed architecture. We show that all operations involved in machine learning on neural network can be mapped to a logic-in-memory architecture by nonvolatile domain-wall nanowire. Domain-wall nanowire-based logic is customized for in machine learning within image data storage. As such, both neural network training and processing can be performed locally within the memory. The experimental results show that the domain-wall memory can reduce 92% leakage power and 16% dynamic power compared to main memory implemented by DRAM; and domain-wall logic can reduce 31% both dynamic and 65% leakage power under the similar performance compared to CMOS transistor-based logic. And system throughput in DW-NN is improved by 11.6x and the energy efficiency is improved by 56x when compared to conventional image processing system.",data oriented architecture,108,unknown
e0b54bc395fccf323645a4839d04b646431eb369,to_check,semantic_scholar,IEEE Transactions on Circuits and Systems II: Express Briefs,42005,semantic_scholar,a fast integral image computing hardware architecture with high power and area efficiency,https://www.semanticscholar.org/paper/e0b54bc395fccf323645a4839d04b646431eb369,"Integral image computing is an important part of many vision applications and is characterized by intensive computation and frequent memory accessing. This brief proposes an approach for fast integral image computing with high area and power efficiency. For the data flow of the integral image computation a dual-direction data-oriented integral image computing mechanism is proposed to improve the processing efficiency, and then a pipelined parallel architecture is designed to support this mechanism. The parallelism and time complexity of the approach are analyzed and the hardware implementation cost of the proposed architecture is also presented. Compared with the state-of-the-art methods this architecture achieves the highest processing speed with comparatively low logic resources and power consumption.",data oriented architecture,109,unknown
a312fd2a6feffb5bd907a08548a359f071b1e2fe,to_check,semantic_scholar,SIGCOMM '09,39814,semantic_scholar,lipsin: line speed publish/subscribe inter-networking,https://www.semanticscholar.org/paper/a312fd2a6feffb5bd907a08548a359f071b1e2fe,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.
 In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.",data oriented architecture,110,unknown
70e6fa53b806b17d603bdc7d47a7d615d7834670,to_check,semantic_scholar,2011 IEEE Third International Conference on Cloud Computing Technology and Science,40544,semantic_scholar,a cloud environment for data-intensive storage services,https://www.semanticscholar.org/paper/70e6fa53b806b17d603bdc7d47a7d615d7834670,"The emergence of cloud environments has made feasible the delivery of Internet-scale services by addressing a number of challenges such as live migration, fault tolerance and quality of service. However, current approaches do not tackle key issues related to cloud storage, which are of increasing importance given the enormous amount of data being produced in today's rich digital environment (e.g. by smart phones, social networks, sensors, user generated content). In this paper we present the architecture of a scalable and flexible cloud environment addressing the challenge of providing data-intensive storage cloud services through raising the abstraction level of storage, enabling data mobility across providers, allowing computational and content-centric access to storage and deploying new data-oriented mechanisms for QoS and security guarantees. We also demonstrate the added value and effectiveness of the proposed architecture through two real-life application scenarios from the healthcare and media domains.",data oriented architecture,111,unknown
bb4b9316c514860dbfd54bbd50baec757e37b83d,to_check,semantic_scholar,,40909,semantic_scholar,data as a service (daas) in cloud computing,https://www.semanticscholar.org/paper/bb4b9316c514860dbfd54bbd50baec757e37b83d,"Data has become the enabling technology for many of the recent innovations. ""More data trumps smarter algorithms"" has been the mantra behind this revolution in computing. Given the rate at which the data is produced, there is need for scalable solutions to extract information out of them. Allowing the data to be stored in the cloud and be accessed without geographical and scalability limitations will remove many bottlenecks in bringing data-oriented innovations. Current cloud architecture solves the issues of accessibility and scalability, but poses several new challenges such as automatic management of the service, pricing the data, and security of the data. This talk will include several techniques to address these challenges using automatic physical design, servicebased pricing, and cryptographic mechanisms. Data Information Knowledge Intelligence.",data oriented architecture,112,unknown
78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,to_check,semantic_scholar,IEEE Communications Magazine,41275,semantic_scholar,on functionality separation for green mobile networks: concept study over lte,https://www.semanticscholar.org/paper/78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,"Traditional wireless networks are designed for ubiquitous network access provision with low-rate voice services, which thus preserve the homogeneous architecture and tight coupling for infrastructures such as base stations. With the traffic explosion and the paradigm shift from voice-oriented services to data-oriented services, traditional homogeneous architecture no longer maintains its optimality, and heterogeneous deployment with flexible network control capability becomes a promising evolution direction. To achieve this goal, in this article, we propose a two-layer network functionality separation scheme, targeting at low control signaling overhead and flexible network reconfiguration for future mobile networks. The proposed scheme is shown to support all kinds of user activities defined in current networks. Moreover, we give two examples to illustrate how the proposed scheme can be applied to multicarrier networks and suggest two important design principles for future green networks. Numerical results show that the proposed scheme achieves significant energy reduction over traditional LTE networks, and can be recommended as a candidate solution for future green mobile networks.",data oriented architecture,113,unknown
4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,to_check,semantic_scholar,IEEE Transactions on Industrial Electronics,42005,semantic_scholar,design and optimization of multiclocked embedded systems using formal techniques,https://www.semanticscholar.org/paper/4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,"Today's system-on-chip and distributed systems are commonly equipped with multiple clocks. The key challenge in designing such systems is that two situations have to be captured and evaluated in a single framework. The first is the heterogeneous control-oriented and data-oriented behaviors within one clock domain, and the second is the asynchronous communications between two clock domains. In this paper, we propose to use timed automata and synchronous dataflow to model the dynamic behaviors of the multiclock train-control system, and a multiprocessor architecture for the implementation from our model to the real system. Data-oriented behaviors are captured by synchronous dataflow, control-oriented behaviors are captured by timed automata, and asynchronous communications of the interclock domain can be modeled as an interface timed automaton or a synchronous dataflow module. The behaviors of synchronous dataflow are interpreted by some equivalent timed automata to maintain the semantic consistency of the mixed model. Then, various functional properties that are important to guarantee the correctness of the system can be simulated and verified within the framework. We apply the framework to the design of a control system described in the standard IEC 61 375 and several bugs are detected. The bugs in the standard have been fixed, and the new version has been implemented and used in the real-world subway communication control system.",data oriented architecture,114,unknown
1112c1cd0e7b0c96a1f5231bd1767603466d4300,to_check,semantic_scholar,CIDR,38718,semantic_scholar,turning cluster management into data management; a system overview,https://www.semanticscholar.org/paper/1112c1cd0e7b0c96a1f5231bd1767603466d4300,"This paper introduces the CondorJ2 cluster management system. Traditionally, cluster management systems such as Condor employ a process-oriented approach with little or no use of modern database system technology. In contrast, CondorJ2 employs a data-centric, 3-tier web-application architecture for all system functions (e.g., job submission, monitoring and scheduling; node configuration, monitoring and management, etc.) except for job execution. Employing a data-oriented approach allows the core challenge (i.e., managing and coordinating a large set of distributed computing resources) to be transformed from a relatively low-level systems problem into a more abstract, higher-level data management problem. Preliminary results suggest that CondorJ2’s use of standard 3-tier software represents a significant step forward to the design and implementation of large clusters (1,000 to 10,000 nodes).",data oriented architecture,115,unknown
96be97fc6ec58a35601ada2e353e17b1afa09335,to_check,semantic_scholar,IEEE J. Sel. Areas Commun.,37622,semantic_scholar,a summary of the hornet project: a next-generation metropolitan area network,https://www.semanticscholar.org/paper/96be97fc6ec58a35601ada2e353e17b1afa09335,"Metropolitan area networks are currently undergoing an evolution aimed at more efficiently transport of data-oriented traffic. However, the incoming generation of metro networks is based on conventional technology, which prevents them scaling cost-effectively to ultrahigh capacities. We have developed a new architecture and set of protocols for the next generation of metro networks. The architecture, named HORNET (hybrid optoelectronic ring network), is a packet-over-wavelength-division multiplexing ring network that utilizes fast-tunable packet transmitters and wavelength routing to enable it to scale cost-effectively to ultrahigh capacities. A control-channel-based media access control (MAC) protocol enables the network nodes to share the bandwidth of the network while preventing collisions. The MAC protocol is designed to transport variable-sized packets and to provide fairness control to all network end users. The efficiency and the fairness of the MAC protocol is demonstrated with custom-designed simulations. The implementation of the MAC protocol and the survivability of the network have been demonstrated in a laboratory experimental testbed. The article summarizes the accomplishments of the HORNET project, including the design, analysis, and demonstration of a metro architecture and a set of protocols. The HORNET architecture is an excellent candidate for next-generation high-capacity metro networks.",data oriented architecture,116,unknown
ea835ee626baa1d719a54206f4af3f5e6349173e,to_check,semantic_scholar,Third IEEE International Conference on Data Mining,37622,semantic_scholar,a dynamic adaptive self-organising hybrid model for text clustering,https://www.semanticscholar.org/paper/ea835ee626baa1d719a54206f4af3f5e6349173e,"Clustering by document concepts is a powerful way of retrieving information from a large number of documents. This task in general does not make any assumption on the data distribution. For this task we propose a new competitive self-organising (SOM) model, namely the dynamic adaptive self-organising hybrid model (DASH). The features of DASH are a dynamic structure, hierarchical clustering, nonstationary data learning and parameter self-adjustment. All features are data-oriented: DASH adjusts its behaviour not only by modifying its parameters but also by an adaptive structure. The hierarchical growing architecture is a useful facility for such a competitive neural model which is designed for text clustering. We have presented a new type of self-organising dynamic growing neural network which can deal with the nonuniform data distribution and the nonstationary data sets and represent the inner data structure by a hierarchical view.",data oriented architecture,117,unknown
ac3df9cff34e5b9331a114c70d5e308f03370bfd,to_check,semantic_scholar,"2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems",42005,semantic_scholar,a data-oriented method for scheduling dependent tasks on high-density multi-gpu systems,https://www.semanticscholar.org/paper/ac3df9cff34e5b9331a114c70d5e308f03370bfd,"The rapidly-changing computer architectures, though improving the performance of computers, have been challenging the programming environments for efficiently harnessing the potential of novel architectures. In this area, though the high-density multi-GPU architecture enabled unparalleled performance advantage of dense GPUs in a single server, it has increased the difficulty for scheduling diversified and dependent tasks. We therefore propose a data-oriented method for scheduling dependent tasks for this architecture while providing its implementation. In our method, we model a parallel program as a collection of data-dependent tasks for which data dependencies are managed by an expressive matrix. Accordingly, we develop a hierarchical scheduler infrastructure for our model. In this, a top scheduler is built for querying the data-dependency matrix; three downstream schedulers for queuing computation tasks that are exclusively assigned to processor, accelerator or either; and a multitude of bottom schedulers each for providing a processing element with assigned tasks. We experiment our scheduler for examples of Strassen matrix multiplication and Cholesky matrix inversion algorithms on a computer that has 8 Tesla K40 GPUs. The results show that our method is capable of offering the efficient task parallelism while fulfilling the complex task dependencies. When advanced task-oriented schedulers have been widely designed for distributed systems, a lightweight data-driven scheduler could be an alternative and handy approach that can handle the dependent yet diversified tasks of data-intensive applications for the novel high-density multi-accelerator system.",data oriented architecture,118,unknown
f66df4762da27773e3a6ed820665aa74d4db0e76,to_check,semantic_scholar,2018 IEEE European Symposium on Security and Privacy (EuroS&P),43101,semantic_scholar,security risks in asynchronous web servers: when performance optimizations amplify the impact of data-oriented attacks,https://www.semanticscholar.org/paper/f66df4762da27773e3a6ed820665aa74d4db0e76,"Over the past decade, many innovations have been achieved with respect to improving the responsiveness of highly-trafficked servers. These innovations are fueled by a desire to support complex and data-rich web applications while consuming minimal resources. One of the chief advancements has been the emergence of the asynchronous web server architecture, which is built from the ground up for scalability. While this architecture can offer a significant boost in performance over classic forking servers, it does so at the cost of abandoning memory space isolation between client interactions. This shift in design, that delegates the handling of many unrelated requests within the same process, enables powerful and covert data-oriented attacks that rival complete web server takeover — without ever hijacking the control flow of the server application. To demonstrate the severity of this threat, we present a technique for identifying security-critical web server data by tracing memory accesses committed by the program in generating responses to client requests. We further develop a framework for performing live memory analysis of a running server in order to understand how low-level memory structures can be corrupted for malicious intent. A fundamental goal of our work is to assess the realism of such data-oriented attacks in terms of the types of memory errors that can be leveraged to perform them, and to understand the prominence of these errors in real-world web servers. Our case study on a leading asynchronous architecture, namely Nginx, shows how dataoriented attacks allow an adversary to re-configure an Nginx instance on the fly in order to degrade or disable services (e.g., error reporting, security headers like HSTS, access control), steal sensitive information, as well as distribute arbitrary web content to unsuspecting clients — all by manipulating only a few bytes in memory. Our empirical findings on the susceptibility of modern asynchronous web servers to two wellknown CVEs show that the damage could be severe. To address this threat, we also discuss several potential mitigations. Taken as a whole, our work tells a cautionary tale regarding the risks of blindly pushing forward with performance optimizations.",data oriented architecture,119,unknown
3c43e848a6cf8f90c17298d6298ce0b58007881e,to_check,semantic_scholar,,40909,semantic_scholar,generic adaptation framework for unifying adaptive web-based systems,https://www.semanticscholar.org/paper/3c43e848a6cf8f90c17298d6298ce0b58007881e,"The Generic Adaptation Framework (GAF) research project first and foremost creates a common formal framework for describing current and future adaptive hypermedia (AHS) and adaptive webbased systems in general. It provides a commonly agreed upon taxonomy and a reference model that encompasses the most general architectures of the present and future, including conventional AHS, and different types of personalization-enabling systems and applications such as recommender systems (RS) personalized web search, semantic web enabled applications used in personalized information delivery, adaptive e-Learning applications and many more. At the same time GAF is trying to bring together two (seemingly not intersecting) views on the adaptation: a classical pre-authored type, with conventional domain and overlay user models and data-driven adaptation which includes a set of data mining, machine learning and information retrieval tools. To bring these research fields together we conducted a number GAF compliance studies including RS, AHS, and other applications combining adaptation, recommendation and search. We also performed a number of real systems’ case-studies to prove the point and perform a detailed analysis and evaluation of the framework. Secondly it introduces a number of new ideas in the field of AH, such as the Generic Adaptation Process (GAP) which aligns with a layered (data-oriented) architecture and serves as a reference adaptation process. This also helps to understand the compliance features mentioned earlier. Besides that GAF deals with important and novel aspects of adaptation enabling and leveraging technologies such as provenance and versioning. The existence of such a reference basis should stimulate AHS research and enable researchers to demonstrate ideas for new adaptation methods much more quickly than if they had to start from scratch. GAF will thus help bootstrap any adaptive web-based system research, design, analysis and evaluation.",data oriented architecture,120,unknown
bdd38349d22ab12ddd44a500d5720853ee17286b,to_check,semantic_scholar,2012 IEEE International Conference on Communications (ICC),40909,semantic_scholar,traffic engineering for information-centric networks,https://www.semanticscholar.org/paper/bdd38349d22ab12ddd44a500d5720853ee17286b,"Information-centric networking (ICN) proposes a networking architecture that uses methodologies such as publish-subscribe to achieve a data-oriented approach as opposed to a destination based approach found in the current Internet. This new architecture brings both new problems to be solved and also natural solutions to existing problems. This paper investigates an intra-domain traffic engineering (TE) problem for an information-centric networking (ICN) architecture where a form of source routing is used as the forwarding mechanism. The TE goal is to maximise the residual capacity in the network so that the load is spread evenly. A network flow approach is used and it is shown that the source routing mechanism allows the traffic to be split across multiple paths in a manner that is difficult to achieve using existing IP or IP/MPLS networks. Allowing splittable flows means that a fully polynomial-time approximation scheme can be used that has superior results when compared to existing constraint based routing schemes for flows that cannot be split. Consequently, this work demonstrates that the ICN architecture can simplify the given TE problem in a natural manner.",data oriented architecture,121,unknown
536ab937378e5965f8687b5bf29af2e360aac3bb,to_check,semantic_scholar,2006 ieee/aiaa 25TH Digital Avionics Systems Conference,38718,semantic_scholar,system-wide information management (swim) demonstration security architecture,https://www.semanticscholar.org/paper/536ab937378e5965f8687b5bf29af2e360aac3bb,"System-wide information management (SWIM) is a Federal Aviation Administration (FAA) network-centric environment that facilitates software application integration in the National Airspace System (NAS). Built on a set of five core service types - interfaces, registries, message brokers, information assurance and system management - SWIM accelerates NAS evolution by defining a secure common infrastructure for application integration and a framework for information modeling and exchange. Providing information security in this distributed network-centric environment is a significant challenge. System users must be confident that their critical data is protected. Competing requirements, the transportation of sensitive data and air-to-ground bandwidth constraints mean that a network layer-based approach to security is no longer sufficient. Trusted security at every layer of a network-centric architecture - combined with strong identity management and a data-oriented approach to information assurance - is the key to success. This paper introduces the FAA SWIM demonstration security architecture, and explores some of the methods and mechanisms used to provide end-to-end security, confidentiality, integrity, availability and privacy for NAS applications and their users",data oriented architecture,122,unknown
b728578e4b46a145a24cf02a2f5b70c01eb9b78a,to_check,semantic_scholar,FM,38353,semantic_scholar,verification of a signature architecture with hol-z,https://www.semanticscholar.org/paper/b728578e4b46a145a24cf02a2f5b70c01eb9b78a,"We report on a case study in using HOL-Z, an embedding of Z in higher-order logic, to specify and verify a security architecture for administering digital signatures. We have used HOL-Z to formalize and combine both data-oriented and process-oriented architectural views. Afterwards, we formalized temporal requirements in Z and carried out verification in higher-order logic. 
 
The same architecture has been previously verified using the SPIN model checker. Based on this, we provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with rich data. Moreover, our comparison highlights the advantages of this approach and provides evidence that, in the hands of experienced users, theorem proving is neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,123,unknown
449b756485d77d452b0cc0805b1a7a6767d8f525,to_check,semantic_scholar,IEEE Transactions on Industrial Informatics,42736,semantic_scholar,iot-based techniques for online m2m-interactive itemized data registration and offline information traceability in a digital manufacturing system,https://www.semanticscholar.org/paper/449b756485d77d452b0cc0805b1a7a6767d8f525,"The integration of internet-of-things (IoT) technologies in the industry benefits digital manufacturing applications by allowing ubiquitous interaction and collaborative automation between machines. Online data collection and data interaction are critical for real-time decision making and machine collaborations. However, due to the specificity of digital manufacturing applications, the technical gap between IoT techniques and practical machine operation could hinder the efficient data interactions, collaborations between machines, and the effectiveness as well as the accuracy of itemized data collection. This investigation, therefore, identifies some major technical problems and challenges that current IoT-based digital manufacturing is facing, and proposes a method to bridge the technical gap for itemized product management. The highlights of this investigation are: 1) a data-oriented system architecture toward flexible data interaction between machines, 2) a customized machine-to-machine protocol for machine discovery, presence, and messaging, (3) flexible data structure and data presentation for interoperability, and (4) versatile information tracing approaches for product management. The proposed solutions have been implemented in PicknPack digital food manufacturing line, and achieved ubiquitous data interaction, online data collection, and versatile product information tracing methods have shown the feasibility and significance of the presented methods.",data oriented architecture,124,unknown
9703eec800ca2f2cbbcdb8edc565da15ba15af8c,to_check,semantic_scholar,Formal Aspects of Computing,39083,semantic_scholar,verifying a signature architecture: a comparative case study,https://www.semanticscholar.org/paper/9703eec800ca2f2cbbcdb8edc565da15ba15af8c,"We report on a case study in applying different formal methods to model and verify an architecture for administrating digital signatures. The architecture comprises several concurrently executing systems that authenticate users and generate and store digital signatures by passing security relevant data through a tightly controlled interface. The architecture is interesting from a formal-methods perspective as it involves complex operations on data as well as process coordination and hence is a candidate for both data-oriented and process-oriented formal methods.We have built and verified two models of the signature architecture using two representative formal methods. In the first, we specify a data model of the architecture in Z that we extend to a trace model and interactively verify by theorem proving. In the second, we model the architecture as a system of communicating processes that we verify by finite-state model checking. We provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with complex operations on data. Moreover, our comparison highlights the advantages of proving theorems about such models and provides evidence that, in the hands of an experienced user, theorem proving may be neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,125,unknown
5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,to_check,semantic_scholar,ICON 2012,40909,semantic_scholar,application design over named data networking with its features in mind,https://www.semanticscholar.org/paper/5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,"Designed around host-reachability, today’s Internet architecture faces many limitations while serving data-oriented applications, which produce most traffic load to the Internet. Many clean-slate designs of the content/data oriented network have emerged to adapt to these needs. Named Data Networking (also known as CCN) is one of these designs to address these limitations from the fundamental level by building network architecture around named data. In this paper, we identify five key features crucial to application design over Named Data Networking and take the voice conference system as an example to show how this features impact the application design significantly in detail. We identify three major challenges facing current voice conference system and illustrate how NDN could help to solve these challenges. A NDN-based design of voice conference system is presented along with discussing its reliability and congestion control. Keywords-Named Data Networking; Application Design;",data oriented architecture,126,unknown
102b85595c9d0ffddf74517124ad3e9dca61b271,to_check,semantic_scholar,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),43831,semantic_scholar,making iot data ready for smart city applications,https://www.semanticscholar.org/paper/102b85595c9d0ffddf74517124ad3e9dca61b271,"Modern smart city projects are evolving to the next level of data-centric situation awareness and decision makings, thereby requiring much intensive data integration over various data sources made from city space. In order to satisfy a variety of data demands for diverse smart city applications, we have been developing an integrated IoT data service, IoTDA, to provide essential data-oriented services from data collecting to deep learning based data analysis. In this paper, we introduce the overall architecture and functions of the service platform and explain how the platform will be used with a case study of road surface analysis. In particular, we examine how our data service can be connected to public smart city applications and present the common direction that these types of urban data services should provide for advanced city services.",data oriented architecture,127,unknown
328fb04c4cfe6a90de32041c31810c6d8908e439,to_check,semantic_scholar,IEEE Transactions on Circuits and Systems for Video Technology,40544,semantic_scholar,communication mechanisms and middleware for distributed video surveillance,https://www.semanticscholar.org/paper/328fb04c4cfe6a90de32041c31810c6d8908e439,"A new generation of advanced surveillance systems is being conceived as a collection of multisensor components such as video, audio, and mobile robots interacting in a cooperating manner to enhance situation awareness capabilities to assist surveillance personnel. The prominent issues that these systems face are the improvement of existing intelligent video surveillance systems, the inclusion of wireless networks, the use of low power sensors, the design architecture, the communication between different components, the fusion of data emerging from different type of sensors, the location of personnel (providers and consumers), and the scalability of the system. This paper focuses on the aspects pertaining to real-time distributed architecture and scalability. For example, to meet real-time requirements, these systems need to process data streams in concurrent environments, designed by taking into account scheduling and synchronization. This paper proposes a framework for the design of visual surveillance systems based on components derived from the principles of real-time networks/data-oriented requirements implementation scheme. It also proposes the implementation of these components using the well-known middleware technology common object request broker architecture. Results using this architecture for video surveillance are presented through an implemented prototype.",data oriented architecture,128,unknown
48d9424e505f7be05ff74d68229fcf96c00929e0,to_check,semantic_scholar,Bell Labs Technical Journal,36526,semantic_scholar,the enhanced service manager: a service management system for next-generation networks,https://www.semanticscholar.org/paper/48d9424e505f7be05ff74d68229fcf96c00929e0,"In this paper, we describe a service management product, the Enhanced Service Manager (eSM), that provides not only fast service development and easy maintenance but also performance, reliability, and Web-enabled provisioning. Competition is fierce in the business world, especially in telecommunications. Being first to offer a service is typically a key decision-making factor for service providers in selecting an operations support system product to manage their services. Furthermore, we have seen the operations network landscape evolving from switch-based to intelligent network-oriented services and from circuit-based to more data-oriented networks. This paper illustrates how open architecture elements such as Common Object Request Broker Architecture (CORBA∗), Extensible Markup Language (XML), and Java∗/JavaServer Pages∗ (JSP∗) technology have been woven with off-the-shelf components into a product designed to meet current business needs. We discuss our architectural approach as well as a future direction.",data oriented architecture,129,unknown
eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,to_check,semantic_scholar,2009 Seventh Annual Communication Networks and Services Research Conference,39814,semantic_scholar,optical access-metro network architecture based on passive access and burst-mode transmission,https://www.semanticscholar.org/paper/eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,"A network architecture that integrates several WDM PON access segments in a metropolitan area network and uses optical circuit/burst switching is presented here. This architecture targets the delivery of very high speed end to end optical communications between the edge nodes connecting the end users. The combination of circuit switching and burst transmission allows the simultaneous delivery of real-time applications (VoIP, Video) and other data-oriented applications (Internet, peer-to-peer). In the proposed architecture there is a clear separation of the functions in data plane and a control plane. A centralized control entity manages the overall architecture. A dedicated aggregation node acts as a gateway to external networks. After a presentation of the proposed network architecture, this paper focuses on the performance evaluation of the control plane using simulation. Our results show that the queuing delay remains acceptable even under heavy traffic loads.",data oriented architecture,130,unknown
f925f3d29d9161514719651dd16a7310e051d56b,to_check,semantic_scholar,2005 Asia-Pacific Conference on Communications,38353,semantic_scholar,a conceptual architecture for adaptation in remote desktop systems driven by the user perception of multimedia,https://www.semanticscholar.org/paper/f925f3d29d9161514719651dd16a7310e051d56b,Current thin-client remote desktop systems were designed for data-oriented applications over low-quality LAN links and they do not provide satisfactory end-user performance in enterprise environment for more and more popular graphical and multimedia applications. To improve perception of those applications in thin-client environment we propose architecture of a server-side quality of service (QoS) management component responsible for mapping application QoS requirements into network QoS. We analyze how service differentiation and traffic management techniques combined with user perception monitoring can be used in order to adjust network level resource allocation when performance of multimedia applications in remote desktop environment is not meeting user requirements. Our objective is to provide QoS-aware remote desktop systems which will be able to manage available resources in intelligent manner and meet end-user performance expectations,data oriented architecture,131,unknown
13acc27d419769500af8c3b0d04ad065402f816e,to_check,semantic_scholar,ISPRS Int. J. Geo Inf.,43101,semantic_scholar,hibuffer: buffer analysis of 10-million-scale spatial data in real time,https://www.semanticscholar.org/paper/13acc27d419769500af8c3b0d04ad065402f816e,"Buffer analysis, a fundamental function in a geographic information system (GIS), identifies areas by the surrounding geographic features within a given distance. Real-time buffer analysis for large-scale spatial data remains a challenging problem since the computational scales of conventional data-oriented methods expand rapidly with increasing data volume. In this paper, we introduce HiBuffer, a visualization-oriented model for real-time buffer analysis. An efficient buffer generation method is proposed which introduces spatial indexes and a corresponding query strategy. Buffer results are organized into a tile-pyramid structure to enable stepless zooming. Moreover, a fully optimized hybrid parallel processing architecture is proposed for the real-time buffer analysis of large-scale spatial data. Experiments using real-world datasets show that our approach can reduce computation time by up to several orders of magnitude while preserving superior visualization effects. Additional experiments were conducted to analyze the influence of spatial data density, buffer radius, and request rate on HiBuffer performance, and the results demonstrate the adaptability and stability of HiBuffer. The parallel scalability of HiBuffer was also tested, showing that HiBuffer achieves high performance of parallel acceleration. Experimental results verify that HiBuffer is capable of handling 10-million-scale data.",data oriented architecture,132,unknown
dc9df4822e7e894c8da4b936599be6cffb17ea29,to_check,semantic_scholar,,35796,semantic_scholar,hoss: an environment to support structural computing,https://www.semanticscholar.org/paper/dc9df4822e7e894c8da4b936599be6cffb17ea29,"There have been two distinct trends in hypermedia work over the last decade. One has concerned the construction of increasingly more powerful infrastructure for the support of open hypermedia navigation systems, while the other has concerned the application of hypermedia technologies and concepts to increasingly diverse domains. This dissertation addresses how these trends can be merged, resulting in a framework for design of powerful, general infrastructure. 
An examination of the domains to which hypermedia concepts have been applied yields to the conclusion that all rely on general structure and general structural computation. A philosophy of computation is presented called structural computing that stresses the primacy of these concepts. Without such a philosophy, structure is seen as an ad hoc functionality to be added over data-oriented programs. Different structure-oriented domains are seen as special cases of navigational hypertext, with a corresponding confusion of basic terminologies. 
An analysis of the historical development of hypermedia systems leads to the conclusion that current open hypermedia systems can be modified in a straightforward way to support structural computing by opening the link server layer in traditional hypermedia architectures. The resultant generalized link server is called a structure processor (Sproc). Different Sprocs encapsulate tailoring and extension of the structure and structural computation models provided by the structure store of the system. 
A conceptual architecture for an environment to support structural computing (named HOSS) is presented. This architecture is divided into two parts. The operating system layer describes the basic services available to all HOSS programs. The computing environment layer consists of an open set of programs that run address specific structural computing domains. A prototypic implementation of the operating system layer and several example computing environment layer programs is described, which provides a proof of concept of the structural computing environment architecture presented. The sample programs substantiate the claims that such an environment can support the design and implementation of a wide variety of structural computing programs. 
The dissertation concludes with an evaluation of the philosophy of structural computing and the design and implementation of HOSS, a description of directions for possible future work, and conclusions.",data oriented architecture,133,unknown
3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,to_check,semantic_scholar,EMISA,38718,semantic_scholar,challenges and solutions in planning information systems for networked value constellations,https://www.semanticscholar.org/paper/3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,"Nowadays businesses often decide to form networked value constellations in order to satisfy complex customer needs. To fulfill the value-based requirements of an e-Business idea and to realize the coordination of such a multi-actor network an adequate underlying information systems architecture has to be conceptualized. This paper discusses the applicability of classical information system planning approaches, such as Information Engineering to cross-organizational settings expressed
through value-based requirements. On the basis of this analysis several requirements for the enhancement and adaptation of Information Engineering-like methodologies
for e-Business ideas are defined for the purpose of enabling alignment between a value-based business context and the information systems architecture in a networked environment.
The paper proposes a way to derive data-orientation from value-orientation,
i.e. an enterprise model from a value model. This in turn enables afterwards the
straightforward use of traditional data-oriented techniques for value-based business
models.",data oriented architecture,134,unknown
b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,to_check,semantic_scholar,Defense + Security,42370,semantic_scholar,icrowd: agent-based behavior modeling and crowd simulator,https://www.semanticscholar.org/paper/b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,"Initially designed in the context of the TASS (Total Airport Security System) FP-7 project, the Crowd Simulation platform developed by the Integrated Systems Lab of the Institute of Informatics and Telecommunications at N.C.S.R. Demokritos, has evolved into a complete domain-independent agent-based behavior simulator with an emphasis on crowd behavior and building evacuation simulation. Under continuous development, it reﬂects an eﬀort to implement a modern, multithreaded, data-oriented simulation engine employing latest state-of-the-art programming technologies and paradigms. It is based on an extensible architecture that separates core services from the individual layers of agent behavior, oﬀering a concrete simulation kernel designed for high-performance and stability. Its primary goal is to deliver an abstract platform to facilitate implementation of several Agent-Based Simulation solutions with applicability in several domains of knowledge, such as: (i) Crowd behavior simulation during [in/out] door evacuation. (ii) Non-Player Character AI for Game-oriented applications and Gamiﬁcation activities. (iii) Vessel traﬃc modeling and simulation for Maritime Security and Surveillance applications. (iv) Urban and Highway Traﬃc and Transportation Simulations. (v) Social Behavior Simulation and Modeling.",data oriented architecture,135,unknown
7261028c80d1ac82828f26c46318557a50c42176,to_check,semantic_scholar,,39083,semantic_scholar,biofederator: a data federation system for bioinformatics on the web,https://www.semanticscholar.org/paper/7261028c80d1ac82828f26c46318557a50c42176,"A problem facing many bioinformatics researchers today is the aggregation and analysis of vast amounts of data produced by large scale projects from various laboratories around the world. Depositing such data into centralized web-based repositories (e.g. NCBI, UCSCGenome Browser) is the common approach. However, the distributed nature of the data, its growth rate, and increased collaborative needs represent real challenges calling for novel decentralized web architectures. The BioFederator is a web services-based data federation architecture for bioinformatics applications. Based on collaborations with bioinformatics researchers, several domainspecific data federation challenges and needs are identified. The BioFederator addresses such challenges and provides an architecture that incorporates a series of utility services. These address issues like automatic workflow composition, domain semantics, and the distributed nature of the data. It also incorporates a series of data-oriented services that facilitate the actual integration of data. The BioFederator is deployed on a grid environment over the web. The proposed design, services, and usage scenarios are discussed in detail. We demonstrate how our architecture can be leveraged for a real-world bioinformatics problem involving tissue specificity of gene expression.",data oriented architecture,136,unknown
52c5ec6acd2dfb2194ec655bd695474f76876754,to_check,semantic_scholar,,37622,semantic_scholar,when theory meets practice: building traffic control systems made easy,https://www.semanticscholar.org/paper/52c5ec6acd2dfb2194ec655bd695474f76876754,"Two separate road developments in traffic management in the Netherlands have been the Motorway Traffic Control Architecture (MTCA) and the implementation of data-oriented middleware by Trinite in the first Traffic Management Centre in the Netherlands. The move towards integration in different systems at the traffic management level is described. The principles behind the MTCA are outlined. The architecture had to offer a framework for existing and future traffic control (TC) measures, to adopt an infrastruture-oriented approach and the different parts had to be integrated. Measures are controlled by so-called Traffic Controls, software components that are based on the composite design pattern. The programmable distributed architecture developed by Trinite is the platform on which Traffic Controls are realised in the software. The implementation of an infrastructural system with Traffic Controls involves determining the information needs, adding information elements and adding functionality.",data oriented architecture,137,unknown
60881ba191ac396c88bf081b940b547c51d1b5b0,to_check,semantic_scholar,,36161,semantic_scholar,a scalable service architecture for computer-telephony integration,https://www.semanticscholar.org/paper/60881ba191ac396c88bf081b940b547c51d1b5b0,"The convergence of traditional voice-oriented telecommunications networks and data-oriented computer communications networks is yielding new challenges for building systems equally adept at handling voice and data applications. While there is much discussion about packetized voice over IP networks, a little explored opportunity is the ability to more easily deploy innovative new services based on the Internet’s client-server paradigm and the ease with which software agents can be introduced and migrated around the network. We discuss our new architecture for middleware services that more effectively enables the integration of telephone and data application. This horizontally-integrated architecture supports competition between interchangeable service implementations, based upon features, cost, etc. It is characterized by pervasive and seamless access across multiple cascaded networks. We describe our experiences in integrating an Internet-based core with cellular and other access networks, and our analysis of IP performance in this testbed using a graphical multi-layer protocol analysis tool. Based on our architecture, we have developed prototype converged applications for voice-actuated room control and personal “universal in-box” information management.",data oriented architecture,138,unknown
c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,to_check,semantic_scholar,"2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools",39814,semantic_scholar,run-time reconfigurable array using magnetic ram,https://www.semanticscholar.org/paper/c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,"This paper presents the implementation of a coarse-grained Magnetic RAM based Reconfigurable Array. The Reconfigurable Array architecture is organized as a one- dimensional array of programmable ALU, with the configura- tion bits stored in magnetic random-access memories. The use of MRAM technology to implement run-time reconfigurable hardware devices is a very promising technological solution because MRAM can provide non-volatility with cell areas and access speeds comparable to those of SRAM, and with lower process complexity than flash memory. This type of coarse- grained array, where each reconfigurable element computes on 4-bit or larger input words, is more suitable to execute data-oriented algorithms and is more able to exploit larger amounts of operation-level parallelism than common fine- grained architectures. By substantially reducing the overhead for configurability, this coarse-grain architecture is also more apt to efficiently exploit run-time reconfiguration and therefore to take advantage of multi-context MRAM-based configuration memories. Keywords-reconfigurable array; MRAM; programmable fab- rics;",data oriented architecture,139,unknown
826ac2113812ee288da45f585759f81318ce4c85,to_check,semantic_scholar,,42736,semantic_scholar,information management for enabling systems medicine,https://www.semanticscholar.org/paper/826ac2113812ee288da45f585759f81318ce4c85,"Abstract Systems medicine is a data-oriented approach in research and clinical practice to support study and treatment of complex diseases. It relies on well-defined information management processes providing comprehensive and up to date information as basis for electronic decision support. The authors suggest a three-layer information technology (IT) architecture for systems medicine and a cyclic data management approach including a knowledge base that is dynamically updated by extract, transform, and load (ETL) procedures. Decision support is suggested as case-based and rule-based components. Results are presented via a user interface to acknowledging clinical requirements in terms of time and complexity. The systems medicine application was implemented as a prototype.",data oriented architecture,140,unknown
61f0f98f644912b1c71d137a829db60782eebd63,to_check,semantic_scholar,IEEE Access,43831,semantic_scholar,cyber physical and social networks in iov (cpsn-iov): a multimodal architecture in edge-based networks for optimal route selection using 5g technologies,https://www.semanticscholar.org/paper/61f0f98f644912b1c71d137a829db60782eebd63,"Humans are blessed with the intelligence to create links, develop semantic metaphors and models for reasoning; construct rules for decision making; and to form bounded loops for interaction, socialization and knowledge sharing. But machines are inadequate with these extraordinary abilities rather, numerous algorithms and mathematical models can be used to connect physical resources with cyberspaces to control objects and, develop cognitive learning for optimal decision making. Connected users and devices in closed virtual and physical proximity give direction towards the plethora of real-world applications for physical, social and, cyber computing. Because of the increase in social media networking and 5G communication links offer real-time crowdsourcing and sensing as a complementary base for information. Proceeding this idea, in this study we have proposed Cyber-Physical and Social Networks (CPSN) for two fundamental operations in IoV (Internet of Vehicles) as CPSN-IoV; (1) to define conceptual architecture of CPSN-IoV for data-oriented network for smart infrastructure and, (2) to create the significant virtual space where the instances of smart vehicles, devices, and things will have meaningful links with the real world objects where, CPSN-IoV will evolve, emerge, compete, and collaborate with all connected objects to strengthen the decision making process. To investigate the potential impact of our proposed study, we have simulated the taxicab trajectory data of the urban city of Portugal in OMNeT++ for the in-depth understanding of road topology, connected vehicles and things, and their traffic trends; and users’ social media streams in respective edge for efficient route planning. The results of simulation demonstrate that our proposed framework has the ability to achieve human-machine intellectual association for managing the smart environment.",data oriented architecture,141,unknown
141ac67c51134b03e993dca1a4e038266c6a45aa,to_check,semantic_scholar,WABBWUAS@UMAP,40179,semantic_scholar,generic adaptation process,https://www.semanticscholar.org/paper/141ac67c51134b03e993dca1a4e038266c6a45aa,Adaptive Hypermedia Systems (AHS) have long been mainly represented by domain- or application-specific systems. Few reference models exist and they provide only a brief overview of how to describe and organize the ‘adaptation process’ in a generic way. In this paper we consider the process aspects of AHS from the very first classical ‘user modelling-adaptation’ loop to a generic detailed flowchart of the adaptation in AHS.We introduce a Generic Adaptation Process and by aligning it with a layered (data-oriented) AHS architecture we show that it can serve as the process part of a new reference model for AHS.,data oriented architecture,142,unknown
44c75858494b9aecb62b9c50fe4cea48a7e045d1,to_check,semantic_scholar,"CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.",37622,semantic_scholar,a method to find unique sequences on distributed genomic databases,https://www.semanticscholar.org/paper/44c75858494b9aecb62b9c50fe4cea48a7e045d1,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled. Hence, it becomes feasible to analyze the entire genomic information all at once. On the other hand, the quantity of the genomic information stocked on databases is increasing day after day. In order to process the whole information, we have to develop an effective method to deal with lots of data. Therefore, it is indispensable not only to make an effective and rapid algorithm but also to use high-speed computer resource so as to analyze the biological information. For this purpose, as one of the most promised computing environments, the grid computing architecture has appeared recently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11]. In the field of bioinformatics, it is important to find unique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found they can be useful for target specific probes/primers design, gene sequence comparison and so on. In this paper, we propose a method to discover unique sequences from among genomic databases located in a distributed environment. Next, we implement this method upon the European Data Grid and show the calculation results for E. coli genomes.",data oriented architecture,143,unknown
59bb50285c3e3807a03617b98aac00233cc5ce28,to_check,semantic_scholar,2010 IFIP Wireless Days,40179,semantic_scholar,a software radio architecture for the baseband level of the multi-standard user terminal: design methodology and computational assessment,https://www.semanticscholar.org/paper/59bb50285c3e3807a03617b98aac00233cc5ce28,In this paper we present a design methodology and system prototyping for the baseband level of the Software Defined Radio (SDR)-based portable multi-standard terminal. The SDR-based architecture consists of three main layers denoted as: i) Upper Layer to provide communication with an end user and a network; ii) Middle Layer to establish the required protocol configuration; and iii) Bottom Layer to execute the protocol algorithm. Main concern was based on the examination of the SDR-based module behavior in the heterogeneous environment. As a case study we have chosen two different wireless communication standards: data-oriented WiMAX (IEEE 802.16d) and voice-oriented UMTS (release 1999). The simulation of the digital signal processing for both standards was performed in the MATLAB environment. The goal is to achieve and to verify the given system configuration depending on the environment characteristics. For this reason we show that SDR-based module can recognize the required protocol configuration and tune the system accordingly.,data oriented architecture,144,unknown
a96539c753dd3b547cd5a3f390b6678b63c0d648,to_check,semantic_scholar,2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS),44197,semantic_scholar,iot microservice architecture for iotaas device users,https://www.semanticscholar.org/paper/a96539c753dd3b547cd5a3f390b6678b63c0d648,"Scaling up the Internet of Things (IoT) as a service (IoTaaS) is still facing many challenges including the demand of IoTass users to gain a more privilege access on IoT device to configure necessary parameters such as data rate and actuator rotation speed for custom object tracking methods. To address this challenge, this paper aims to propose a micro service architecture of IoT, particularly to provide configurable IoT device platform. Compared to previous works focusing on data-oriented high-level architecture of IoT solution, the proposed architecture provides a solution for IoT device users and, hence, this study is critical to extend the capabilities of IoTaaS.",data oriented architecture,145,unknown
00c4a804484051d385c992e2221bc406a54aa598,to_check,semantic_scholar,Int. J. Digit. Libr. Syst.,40544,semantic_scholar,a presentation-preserved compositional approach for integrating heterogeneous systems: using e-learning as an example,https://www.semanticscholar.org/paper/00c4a804484051d385c992e2221bc406a54aa598,"In traditional SCW environments, related web services are integrated into business processes. Web service still brings less than expected benefits to small corporations and end-users for two reasons: 1 the web service only focuses on data level and is difficult to implement the presentation-centric business contexts. 2 The small corporations and end-users usually do not have enough IT competences to write a client or user interface to interact with web services. In order to solve these problems, the author proposes a presentation-preserved compositional approach for service-oriented architecture PCSOA, which extends the existing data-oriented compositional approaches for web services to provide a more flexible methodology to orchestrate both data level and presentation level services during the workflow integration. A prototype is also built to validate the feasibility of the approach.",data oriented architecture,146,unknown
350f27ef714c25235870a50015837790cafb1147,to_check,semantic_scholar,2010 International Conference On Computer Design and Applications,40179,semantic_scholar,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://www.semanticscholar.org/paper/350f27ef714c25235870a50015837790cafb1147,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,147,unknown
fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,to_check,semantic_scholar,,43101,semantic_scholar,a research on the security of wisdom campus based on geospatial big data,https://www.semanticscholar.org/paper/fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,"Wang Haiying School of Land and Resource China West Normal University Nanchong, China e-mail: wanghaiying8228@163.com Abstract— There are some difficulties in wisdom campus, such as geospatial big data sharing, function expansion, data management, analysis and mining geospatial big data for a characteristic, especially the problem of data security can't guarantee cause prominent attention increasingly. In this article we put forward a data-oriented software architecture which is designed by the ideology of orienting data and data as kernel, solve the problem of traditional software architecture broaden the campus space data research, develop the application of wisdom campus.",data oriented architecture,148,unknown
442567e7d47373f6d305a249b7ae05b81d15782e,to_check,semantic_scholar,"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",43466,semantic_scholar,consideration and research on data architecture for the future cyber society,https://www.semanticscholar.org/paper/442567e7d47373f6d305a249b7ae05b81d15782e,"The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.",data oriented architecture,149,unknown
01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,to_check,semantic_scholar,,43101,semantic_scholar,research on digital power grid information integration solution,https://www.semanticscholar.org/paper/01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,"Information integration is an important part of the digital grid architecture. The purpose is to solve the information interaction obstacles between heterogeneous systems on the basis of making full use of the old system. This paper analyzes the development stage of digital power grid information integration from the perspective of information integration, and points out that the information integration of current digital power grid is mainly data-oriented integration. Based on the characteristics of digital power grid information integration, this paper puts forward a digital power grid information Integration solution combining horizontal information integration and vertical information integration, designs the overall architecture of digital power grid information integration, and elaborates the horizontal integration and vertical integration respectively.",data oriented architecture,150,unknown
cddb42247b854abce14ee1e059f332f42be54c5d,to_check,semantic_scholar,2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP),42005,semantic_scholar,rapid customization of image processors using halide,https://www.semanticscholar.org/paper/cddb42247b854abce14ee1e059f332f42be54c5d,"Image processing applications typically involve data-oriented kernels with limited control divergence. In order to efficiently exploit the data level parallelism, image processors include SIMD instructions and other parallel computation resources. Generic processors that can be purchased off-the-shelf are adequate for most of the use scenarios of image processing. However, especially with embedded mobile devices, they might not be optimal for the algorithm, the environment, or the energy budget at hand. Such cases call for programmable customized architectures with just enough hardware resources to ensure the high priority applications reach their real time goals with minimal overheads. In order to maintain high engineer productivity, implementing image algorithms for customized processors should be as easy as with standard processors. This is emphasized at the processor co-design time; because the program is used to drive the processor design space exploration towards an optimized architecture, assembly programming is not feasible due to the required porting effort whenever the architecture is modified. In this paper we propose an image processor customization flow that exploits the domain-specific Halide language as an input to a processor co-design environment. In addition to efficiently exploiting standard resources in the customized processors, the flow provides an easy way to invoke special instructions from Halide programs. We validate the performance benefits of custom operations using example filters described with the Halide language.",data oriented architecture,151,unknown
de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,to_check,semantic_scholar,2017 International Carnahan Conference on Security Technology (ICCST),42736,semantic_scholar,"encrypted computing: speed, security and provable obfuscation against insiders",https://www.semanticscholar.org/paper/de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,"Over the past few years we have articulated theory that describes ‘encrypted computing’, in which data remains in encrypted form while being worked on inside a processor, by virtue of a modified arithmetic. The last two years have seen research and development on a standards-compliant processor that shows that near-conventional speeds are attainable via this approach. Benchmark performance with the US AES-128 flagship encryption and a 1GHz clock is now equivalent to a 433MHz classic Pentium, and most block encryptions fit in AES's place. This summary article details how user data is protected by a system based on the processor from being read or interfered with by the computer operator, for those computing paradigms that entail trust in data-oriented computation in remote locations where it may be accessible to powerful and dishonest insiders. We combine: (i) the processor that runs encrypted; (ii) a slightly modified conventional machine code instruction set architecture with which security is achievable; (iii) an ‘obfuscating’ compiler that takes advantage of its possibilities, forming a three-point system that provably provides cryptographic ‘semantic security’ for user data against the operator and system insiders.",data oriented architecture,152,unknown
bf25baf2eac5677cad335addbfab8b1c51ee360e,to_check,semantic_scholar,,37622,semantic_scholar,a method to find uniq e sequences on distrib ted genomic databases,https://www.semanticscholar.org/paper/bf25baf2eac5677cad335addbfab8b1c51ee360e,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled.Hence, it becomes feasible to analyze the entire genomicinformation all at once. On the other hand, the quantity ofthe genomic information stocked on databases is increasingday after day. In order to process the whole information, wehave to develop an effective method to deal with lots of data.Therefore, it is indis ensable not only to make an effectiveand rapid algorithm but also to use high-speed computerresource so as to analyze the biological information. Forthis purpose, as one of the most promised computing environments, the grid computing architecture has appearedrecently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11].In the field of bioinformatics, it is important to findunique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found, theycan be useful for target specific probes/primers design, genesequence comparison and so on. In this paper, we propose amethod to discover unique sequences from among genomicdatabases located in a distributed environment. Next, weimplement this method upon the European Data Grid andshow the calculation results for E. coli genomes.",data oriented architecture,153,unknown
88af34df634edebdfe39871f82166e61ad0a4835,to_check,semantic_scholar,,40179,semantic_scholar,electronic communications of the easst volume 28 ( 2010 ) proceedings of the third international discotec workshop on context-aware adaptation mechanisms for pervasive and ubiquitous services ( campus 2010 ) modelling feedback control loops for self-adaptive systems,https://www.semanticscholar.org/paper/88af34df634edebdfe39871f82166e61ad0a4835,"Feedback Control Loops (FCLs) are the heart of any self-adaptive system. Existing engineering approaches for building self-ad aptive systems mask FCL by providing abstraction layers that hide the application c mplexity. In this paper, we investigate a model-driven approach for the engineering of FCLs whose architecture is based on the Service Component Architecture (SCA) model. Our proposal consists in exploiting the data streaming model, to specify the characteristics of the control policies, and to generate FCLs of self-adaptive sys tem deployed in largescale environment. We argue that the use of a data-oriented m odel for designing self-adaptive systems significantly increases FCL visibil ity.",data oriented architecture,154,unknown
05fbbfb5cdab641e15c49690064b9aa1728bd2c3,to_check,semantic_scholar,,42005,semantic_scholar,non-volatile in-memory computing,https://www.semanticscholar.org/paper/05fbbfb5cdab641e15c49690064b9aa1728bd2c3,"The analysis of big-data at exa-scale (1018 bytes or flops) has called for an urgent need to re-examine the existing hardware platform that can support intensive data-oriented computing. A big-data-driven application requires huge bandwidth and yet able to ensure low-power density. For example, web-searching application involves crawling, comparing, ranking, and paging of billions of web-pages with extensive memory access. The existing memory technologies have critical challenges of scaling at nano-scale due to process variation, leakage current and I/O access limitations. Recently, the emerging non-volatile memory (NVM) technologies such as resistive-RAM (ReRAM), spintransfer torque RAM (STT-RAM), domain-wall nanowire racetrack memory etc., have all shown significantly reduced standby power and increased integration density, not forgetting the close-to DRAM/SRAM access speed. Therefore, they are considered as promising candidates of universal memory for future big-data applications. The primary challenge to validate a hybrid design with both CMOS and nonvolatile devices is the lack of design platform that can validate the large-scale NVM circuit and system design accurately and efficiently. In addition, due to the use of non-electrical states of emerging NVM devices, new cells structures and their agreeing circuits for both read and write operations are needed to harness non-volatile memory with unique operations. For example, the transistor-free crossbar array that associates with NVM is different from conventional access transistor based memory structure. What is more, leveraging the NVM for computing, one also needs to examine the potential logic-inmemory computing architecture with significantly improved bandwidth and reduced power. In order to tackle above challenges ranging from device to system levels, this PhD thesis has explored the development of NVM design platform to support designs of non-volatile memories, readout and logic circuit designs, as well as the in-memory computing architecture. For the NVM design platform, the target is to perform accurate yet efficient circuit level simulation. The previous approaches either ignore dynamic effect without considering non-volatile states for dynamic behavior, or need equivalent circuits with high complexity to curve-fit non-linearity of those devices. We proposed a SPICE simulaiii tor named NVM-SPICE. This tool takes advantages of its new modified nodal analysis (MNA) framework, which can effectively support the non-electrical state variables of emerging non-volatile devices, such as ReRAM and spintronics devices. Due to the physics based modeling approach, NVM-SPICE is able to perform hybrid NVM/CMOS circuits efficiently and accurately. Compared to the equivalent circuit model based approach, the NVM-SPICE simulator exhibits more than 117x faster simulation speed for spintronics category devices and 40x faster speed for RRAM category devices. For NVM in-memory architecture, both memory elements and logic elements are implemented by emerging spintronics devices, which leads to a system purely composed of non-volatile devices. The detailed non-volatile memory and logic circuits are explored within the NVM-SPICE platform. In addition, logic is built inside the memory so that the I/O workload can be alleviated. Applications such as data retention, encryption, machine learning that play critical roles for big-data computing are explored within the non-volatile in-memory architecture. The evaluation results show that the purely non-volatile memory based platforms with in-memory architecture greatly contribute to power efficiency and throughput improvement for big-data oriented applications, and thus are potential candidates to be next generation information and communication technology.",data oriented architecture,155,unknown
47963243de795b321fe10edb46a3a9d1931960ec,to_check,semantic_scholar,,35796,semantic_scholar,toward an exemplar-based computational model for cognitive grammar,https://www.semanticscholar.org/paper/47963243de795b321fe10edb46a3a9d1931960ec,"An exemplar-based computational framework is presented which is compatible with Cognitive Grammar. In an exemplar-based approach, language acquisition is modeled as the incremental, data-oriented storage of experiential patterns, and language performance as the extrapolation of information from those stored patterns on the basis of a language-independent information-theoretic similarity metric. We show that this simple architecture works for many aspects of phonological, morphological, and morphosyntactic acquisition and processing. Furthermore, we sketch how the approach may also work for syntactic processing. A central insight of the approach, based on the results of computational modeling experiments, is that abstraction of representations is not only unnecessary to achieve generalization (i.e. to make the system productive, and to make it gòbeyond' the learned patterns), but even harmful, and that useful language-independent metrics can be found for deening similarity in the context of language processing. In the generative tradition, generality is achieved by means of abstraction, and the representations of choice to describe these abstractions are rules. This implies that redundancy and the storage of individual instances are to be avoided, except for exceptions to the generalizations expressed in rules. In Langacker, 1991 (Chapter 10), this methodology is critically examined, and cognitive grammar is described as an alternative usage-based model of language structure. In the latter, bottom-up, approach, patterns (rules, generalizations) and (redundant) instantiations of those rules are assumed to co-exist in the grammar, describing phenomena at all levels of generality, from exceptionless regularities to idiosyncratic exceptions. Rules are presumed to be necessary for the computation of novel instantiations. In the remainder of this paper we will introduce an exemplar-based approach to language acquisition and processing. The approach is in large part compatible with Lan-gacker's usage-based model, but is more radical in its ""maximalism"": language knowledge is supposed to consist only of ""instantiations"" (exemplars); there is no role for explicit abstractions corresponding to (sub)regularities. We will argue on the basis of computational modeling experiments that the adoption of abstractions (rules, patterns), taken as necessary for explaining generalization and productivity in both the generative and the cognitive grammar approach, is misguided. Furthermore, the exemplar-based approach contributes to making cognitive grammar ideas more concrete by providing computational operationalisations of both acquisition and processing in such a framework.",data oriented architecture,156,unknown
f1d7ddb9bc63fee86bfece409732bd977899b254,to_check,semantic_scholar,CFI,40909,semantic_scholar,on adapting http protocol to content centric networking,https://www.semanticscholar.org/paper/f1d7ddb9bc63fee86bfece409732bd977899b254,"Designed around host-reachability, today's Internet architecture faces many limitations while serving content-oriented applications which generate most traffic load to the Internet. CCN (Content Centric Networking) [1] is one of the most important proposals for future Internet architecture, which aims to build a content/data oriented network to solve these limitations. On the other hand, HTTP is the most important protocol to deploy new services and applications on current TCP/IP-based Internet. In this paper, we attempt to run HTTP protocol on CCN and combine the two by stitching them semantically on their content-oriented features, such as content caching. We expect that this combination can be leveraged to build CCN testbed with real HTTP traffic which is vital to validation and redesigning of specific mechanisms of CCN and to finding a transition way of CCN in which great incentive is provided for service providers in the economic ecosystem of content distribution. We designed and implemented a HTTP-CCN gateway to transform HTTP request and HTTP response into CCN Interest and Data respectively. We illustrate how to semantically map HTTP caching to CCN caching, which is one of the most attractive properties of CCN. We also discuss how to achieve transparent caching with CCN and find out that it is nontrivial to achieve complete transparency of caching with CCN given no cooperation with CDNs and content providers.",data oriented architecture,157,unknown
85d191b722bf7e0724cb431d7bef69d1cad8b54a,to_check,semantic_scholar,China Communications,42736,semantic_scholar,"digital rights management: model, technology and application",https://www.semanticscholar.org/paper/85d191b722bf7e0724cb431d7bef69d1cad8b54a,"with rapid achievement of current information technology and computing ability and applications, much more digital content such as films, cartoons, design drawings, office documents and software source codes are produced in daily work, however to protect the content being copying, shared or deliberately stolen by inside or outside, digital rights management (DRM) became more and more important for digital content protection. In this paper, we studied various DRM model, technology and application, and first proposed DRM Security Infrastructure (DSI), in which we defined encryption, hash, signature algorithm, watermarking algorithms, authentication, usage control, trusted counter, conditional trace, secure payment, and based on the DSI we then proposed a whole classification approach and architecture of all kinds of DRMs, in which we proposed 6 typical classes of copyrights and content protection DRMs architecture: (1) Software-oriented DRM,(2) eBook-oriented DRM, (3) Video-oriented DRM, (4)Image-Oriented DRM (5) Unstructured data oriented DRM, (6) Text-oriented DRM. Based on the above DSI, we then proposed a dynamic DRM model selection method for various DRM application, which can be adapted dynamically for different technology of different applications, which can provide a whole solution for variant DRM development in a rapid and customized mode. The proposed DRM method, technology and application in this paper provided a common, flexible and extendable solution for variant DRM scenes, and can support rapid and customized development. Moreover, we proposed an opinion that the future life will enter into a new era that the content usage and consumption will not again adopt DRM technology rather than with law, liberty and morality.",data oriented architecture,158,unknown
e4313c807b2de4d0d1c4078cb2bebdd6a4576022,to_check,semantic_scholar,Wirel. Pers. Commun.,38353,semantic_scholar,analysis of sub-carrier multiplexed radio over fiber link for the simultaneous support of wlan and wcdma systems,https://www.semanticscholar.org/paper/e4313c807b2de4d0d1c4078cb2bebdd6a4576022,"The present third generation (3G) wireless technology can provide data oriented applications. However, the bit rate is limited to around 2 Mbps with limited mobility. Today, more applications demand high data rate and reasonable mobility. Therefore, by integrating 3G cellular system and wireless local area network (WLAN), there is a potential to push the data rate higher. This integration means 3G cellular users can enjoy high data rate at a location that is within WLAN coverage area. Similarly, WLAN users also can have data services as long as they are under the coverage of the 3G cellular system. The 3G cellular system has a much larger coverage than the WLAN. In this paper, we present the first step toward an integration of the two systems. This paper presents a fiber-wireless architecture that simultaneously supports the wideband code division multiple access (WCDMA) system and the IEEE 802.11b WLAN. Our approach uses sub-carrier multiplexed (SCM) architecture to combine and transmit 2.4 GHz WLAN and 1.9 GHz WCDMA signals through an optical fiber from a central base station (CBS) to a radio access point (RAP, single antenna unit). After the fiber, the signals continue to propagate through the air interface to respective mobile stations. The WLAN access point is also located at the CBS. For the SCM architecture, we investigate three areas: i) the signal to noise ratio of the uplink and the downlink, ii) the cell coverage area for the WCDMA and WLAN systems, and iii) the throughput of the IEEE 802.11b WLAN. Our results show that with up to 2.5 km cell radius, better than 18 dB SNR is possible with 5 km fiber link for WLAN system. Simultaneously, the WCDMA system has at least 18 dB SNR for a cell coverage radius of 8 km. These numbers depend on the relative RF power of each system in the fiber.",data oriented architecture,159,unknown
3fa248cfa1491c657bb5f32f237fac4a6a882bfe,to_check,semantic_scholar,,34335,semantic_scholar,communications architecture: towards a more robust understanding of information flows and emergent patterns of communication in organizations,https://www.semanticscholar.org/paper/3fa248cfa1491c657bb5f32f237fac4a6a882bfe,"With the proliferation of telecommunications technologies, the information-based communication infrastructure is becoming an increasingly critical organization resource. In order effectively to channel limited resources (skills, capital, technology) to the most strategically critical communication needs of the organization, the development of business driven planning methodologies which result in a well-defined architecture (blueprint) of organizational communication processes are needed. Unfortunately, while architectural issues are of utmost importance today, researchers have focused almost exclusively on data oriented models. This study attempts to expand this view and provide a holistic representation of information architecture. With the perspective provided by this definitional framework, two methods for development of communications architecture are discussed and evaluated: (1) a flow based approach; and (2) network analysis. Network analysis in particular shows great promise in constructing robust representations of organizational communication processes.",data oriented architecture,160,unknown
407ebbe7b9a024c71d459a370deaf614455e3c8e,to_check,semantic_scholar,,42736,semantic_scholar,named data networking in vanet: a survey,https://www.semanticscholar.org/paper/407ebbe7b9a024c71d459a370deaf614455e3c8e,"Named Data Networking is futuristic data oriented communication model, currently applied to different area of networking. VANET is one area of networking, that named data networking applied on it, to overcome the problem of classically TCP/IP based architecture. As VANET has become a likely area in wireless communication, which can provide a lot of service: traffic efficiency, road safety, and driving comfort. So, Named data networking architecture provide a lot purpose for VANET such as in network caching, security and efficient data distribution between vehicles due to caching capabilities in NDN, this feature make VANET more efficient than TCP/IP network. In existing IP based internet architecture the end points identified by IP addresses but in NDN contents are named with human readable names that provide VANET to retrieve data by sending content name without knowing the location of the provider. This paper also present some research challenge in the VANET via NDN. Keywords— NDN, VANET, Caching, ICN.",data oriented architecture,161,unknown
2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,to_check,semantic_scholar,,38353,semantic_scholar,model checking circus,https://www.semanticscholar.org/paper/2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,"As software complexity increases, so does the need for precision. For some areas, such as high-integrity and safety-critical domains, this precision is imperative rather than optional. To address this issue, both academia and industry have been applying formal methods and formal verification techniques, where model checking and theorem proving are the most successful. Model checking is a verification technique that exhaustively searches the state space of a system represented by some formal notation. It became a successful technique applied by both academia and industry, due to its high level of automation and the ability to provide counter-examples as a debugging device in the case of failure. The difficulty of applying this technique is the state explosion problem that often happens in software verification, hence making such technique unsuitable for representation by computer. In order to finitely represent infinite state systems to be analysed by computer, one needs to resort to the more powerful technique of theorem proving. It allows precise description with less compromise on the state representation, as it uses symbols and quantifiers rather than actual values. The problem is that the higher the expressiveness of a notation, the lower the level of automation that it supports and greater the demand for user expertise and interactivity. The maturity of these techniques, as well as the wide availability of tools, pushed the demand for more expressive techniques with powerful automation tool support. Thus, combination of formalisms and their tools have become a topic of great interest in current research in formal methods. The combination of formalisms usually involve blending mature techniques that cover different aspects of software development in a common semantical framework. For instance, combining data oriented languages, such as Z and B, with behaviour oriented languages, such as CCS and CSP has been the focus of considerable research. The next step in this direction is to provide tool support for these combined languages. The combination of model checking and theorem proving have become the state-of-the-art in terms of tool development for formal verification techniques, as it combines expressiveness with high levels of automation. In this thesis, our main goal is to provide model checking support with integrated theorem proving for Circus, a concurrent language for refinement that combines Z, CSP, and the refinement calculus. Its semantic model is based on Hoare and He’s Unifying Theories of Programming (UTP), which provides an integrated theoretical framework for development and extension of different programming paradigms. From the partnership of our research group with QinetiQ Malvern, it is clear that there is demand for integrated formalisms and respective tool support. Our aim is to provide tool support for Circus, in order to allow its use in real applications, where we are able to formally specify different aspects of systems including, but not limited to, data and behaviour. As Circus is based in UTP, it is possible to integrate other aspects, such as mobility, and real-time, and research in these fronts is well advanced. To fulfill our goal, we provided an operational semantics for model checking Circus, which enables the representation of Circus programs as automata, as well as a search algorithm enabling us to establish refinement between two programs. Throughout the development process, we have decided to take our own medicine and use formal specification and verification, in order to increase the levels of integrity of our tools and techniques. The semantics and the underlying automata theory has been formally defined and mechanised in the Z/Eves theorem prover. Next, we proposed a model checking architecture, which integrates theorem proving facilities, and is implemented as a model checker prototype in Java. This architecture has been formally defined in Circus itself, and we augmented the Java code with JML annotations and assertions representing our findings from the formal specification. Finally, from the abstract Circus specification of the model checker architecture, we calculated a sequential refinement search algorithm using Circus refinement laws, where generated proof obligations have been discharged using Z/Eves again. This effort gave rise to a prototype model checking tool for Circus, which integrates refinement model checking with theorem proving in an extensible framework compliant with the Z Standard.",data oriented architecture,162,unknown
96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,to_check,semantic_scholar,Proceedings 11th International Workshop on Database and Expert Systems Applications,36526,semantic_scholar,an object-based architecture for wap-compliant applications,https://www.semanticscholar.org/paper/96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,"The Wireless Application Protocol (WAP) is an emerging standard for the deployment of data oriented applications in wireless environments. Although some components of the WAP suite have been developed, it lacks a complete general architecture integrating software components of both the Internet and wireless contexts in a transparent way. The paper presents a general architectural framework to develop and deploy portable applications and services accessible by WAP-compliant mobile terminals, extending end-to-end services between terminal and business applications. Moreover, a technique to handle client disconnection is presented.",data oriented architecture,163,unknown
769159b55700871db1e514b15f7636e750a1d985,to_check,semantic_scholar,2014 IEEE 17th International Conference on Computational Science and Engineering,41640,semantic_scholar,exploring the benefits of introducing network coding into named data networking,https://www.semanticscholar.org/paper/769159b55700871db1e514b15f7636e750a1d985,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,164,unknown
1ee9b2571008acac45a7f27b205df71b6cbf756a,to_check,semantic_scholar,2019 IEEE Global Communications Conference (GLOBECOM),43466,semantic_scholar,mc-track: a cloud based data oriented vehicular tracking system with adaptive security,https://www.semanticscholar.org/paper/1ee9b2571008acac45a7f27b205df71b6cbf756a,"In this paper, we propose Mc-Track, a new secure data oriented Cloud based vehicular tracking system. We introduced in Mc-Track an adaptive approach which consists in selection of security level according to data kinds. The architecture of the Mc-Track is composed of three levels: the vehicular network, the Cloud service, and proxies called Tracking Authorities, in charge of performing Attribute Based Encryption (ABE). We provided selective encryption and adaptive security in the Tracking Authority (TA), using the machine learning classifier k-Nearest Neighbours (k-NN). We conducted experimental study to evaluate the efficiency of the proposed k-NN classifier in selective encryption and adaptive security. So we compared the accuracy of the predictions of k-NN classifier to the accuracy of predictions using Support Vector Machine (SVM) classifier. Experimental results, has shown that the k-NN classifier is more accurate than SVM classifier.",data oriented architecture,165,unknown
04887833a763e3025714350a9ec3b547be731214,to_check,semantic_scholar,Wirel. Pers. Commun.,42736,semantic_scholar,trends in the evolution of voice services: a comprehensive survey,https://www.semanticscholar.org/paper/04887833a763e3025714350a9ec3b547be731214,"Mobile network operators are increasingly striving to substitute legacy telecommunication technologies in their networks with the contemporary ones. Modern, future-proof architecture that provides better service quality, requires easier and cheaper maintenance, and consequently brings greater financial benefits is the main driving force for that action. In this moment, Long Term Evolution (LTE) deployment is a goal most mobile network operators are aspiring to. This paper describes presently ongoing changes in the mobile communication networks from the perspective of voice services they provide. Namely, LTE network is, so far, mainly recognized as a “data oriented” network. Having in mind enormous mobile data traffic increase, deployment of that kind of network is fully understandable and justified. However, voice services are still important part of telecommunications’ market offer. So, the above mentioned changes are leading not only toward satisfaction of growing needs regarding mobile data traffic, but also toward utilization of LTE network attributes for the purposes of voice communication. Complete transformation of mobile networks architecture and evolution of traditional voice communication will occur in the process. So far, that evolution has resulted with development of a mechanism know as voice over LTE. However, the mentioned changes are coming gradually and will take a certain time to be fully accomplished. In the meantime, some transition solutions are defined and deployed, in order to enable uninterrupted provisioning of voice services. Their description is included in the paper as well. At the end, relevant forecasts of several network parameters have been discussed.",data oriented architecture,166,unknown
5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,to_check,semantic_scholar,,40179,semantic_scholar,software design and class diagrams,https://www.semanticscholar.org/paper/5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,"ion • ignoring detail to get the high level structure right Decomposition and Modularization • big systems are composed from small components Encapsulation/information hiding • the ability to hide detail (linked to abstraction) Defined interfaces • separable from implementation Evaluation of structure • Coupling: How interlinked a component is • Cohesion: How coherent a component is © 2004-2007 SEOC Lecture Note 04 5 Architecture and Structure Architectural structures and viewpoints Architectural styles Design patterns • small-scale patterns to guide the designer Families and frameworks • component sets and ways of plugging them together • software product lines Architectural design Architectural structures and viewpoints deal with system facets (e.g., physical view, functional or logical view, security view, etc.) separately. Depending on the architectural emphasis, there are different styles, for example, Three-tier architecture for a distributed system (interface, middleware, back-end database), Blackboard, Layered architectures, Model-View-Controller, Time-triggered and so forth. Architectural Design supports stakeholder communication, system analysis and large-scale reuse. It is possible to distinguish diverse design strategies: function oriented (sees the design of the functions as primary), data oriented (sees the data as the primary structured element and drives design from there), object oriented (sees objects as the primary element of design). There is no clear distinction between Sub-systems and modules. Intuitively, sub-systems are independent and composed of modules, have defined interfaces for communication with other sub-systems. Modules are system components and provide/make use of service(s) to/provided by other modules. The system architecture affects the quality attributes (e.g., performance, security, availability, modifiability, portability, reusability, testability, maintainability, etc.) of a system. It supports quality analysis (e.g., reviewing techniques, static analysis, simulation, performance analysis, prototyping, etc.). It allows to define (predictive) measures (i.e., metrics) on the design, but they are usually very dependent on the process in use. The software architecture is the fundamental framework for structuring the system. Different architectural models (e.g., system organizational models, modular decomposition models and control models) may be developed. Design decisions enhance system attributes like, for instance, performance (e.g., localize operations to minimize sub-system communication), security (e.g., use a layered architecture with critical assets in inner layers), safety (e.g., isolate safety-critical components), availability (e.g., include redundant components in the architecture) and maintainability (e.g., use fine-grain self-contained components). Readings • P. Kruchten, H. Obbink, J. Stafford. The Past, Present and Future of Software Architecture. IEEE Software, March/April 2006. © 2004-2007 SEOC Lecture Note 04 6 Architecture Models A static structural model that shows the subsystems or components that are to be developed as separate units. A dynamic process model that shows how the system is organized into processes at run-time. This may be different from the static model. An interface model that defines the services offered by each sub-system through their public interface. A relationship model that shows relationships such as data flow between the sub-systems. Comparing Architecture Design Notations • Modeling Components: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Connectors: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Configurations: Understandable Specifications, Compositionality (and Conposability), Refinement and Traceability, Heterogeneity, Scalability, Evolvability, Dynamism, Constraints, Non-functional Properties UML Design Notations • Static Notations: Class and object diagrams, Component diagrams, Deployment diagrams, CRC Cards • Dynamic Notations: Activity diagrams, Communication diagrams, Statecharts, Sequence diagrams What are the Architect’s Duties? • Get it Defined, documented and communicated, Act as the emissary of the architecture, Maintain morale • Make sure everyone is using it (correctly), management understands it, the software and system architectures are in synchronization, the right modeling is being done, to know that quality attributes are going to be met, the architecture is not only the right one for operations, but also for deployment and maintenance • Identify architecture timely stages that support the overall organization progress, suitable tools and design environments, (and interact) with stakeholders • Resolve disputes and make tradeoffs, technical problems • Manage risk identification and risk mitigation strategies associated with the architecture, understand and plan for evolution © 2004-2007 SEOC Lecture Note 04 7 Class Diagrams Support architectural design • Provide a structural view of systems Represent the basics of Object-Oriented systems • identify what classes there are, how they interrelate and how they interact • Capture the static structure of Object-Oriented systems how systems are structured rather than how they behave Constrain interactions and collaborations that support functional requirements • Link to Requirements",data oriented architecture,167,unknown
f323b4f434bdfc48836d8eebd5cf267c9258aa09,to_check,semantic_scholar,BDCA'17,42736,semantic_scholar,exploiting open data to improve the business intelligence & business discovery experience,https://www.semanticscholar.org/paper/f323b4f434bdfc48836d8eebd5cf267c9258aa09,"The extent to which data mining tools are able to make efficient use of an open data oriented strategy in a smart city is limited. In a sense that it is not fully automated, incompatible or has to be supervised. These sets of tools may offer the possibility to import a dataset in a certain predefined standardized format, still, they do not make it a part of their workflow and algorithms in a fully unsupervised manner (i.e without ongoing human guidance). In a departure from previous research works, in this paper, we present a middleware architecture that exploits open data as background knowledge by acting as a bridge between data mining tools and open data resources.",data oriented architecture,168,unknown
