doi,type,publication,publisher,publication_date,database,title,url,abstract,domain,id
10.1109/iccda.2010.5540715,filtered,2010 International Conference On Computer Design and Applications,IEEE,6/27/2010 0:00,ieeexplore,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://ieeexplore.ieee.org/document/5540715/,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,1
10.1109/icacc.2010.5487131,filtered,2010 2nd International Conference on Advanced Computer Control,IEEE,3/29/2010 0:00,ieeexplore,data-oriented architecture of ln function,https://ieeexplore.ieee.org/document/5487131/,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,2
10.1109/icetc.2010.5529337,filtered,2010 2nd International Conference on Education Technology and Computer,IEEE,6/24/2010 0:00,ieeexplore,data-oriented architecture of sine,https://ieeexplore.ieee.org/document/5529337/,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,3
10.1109/icacte.2010.5579358,filtered,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),IEEE,8/22/2010 0:00,ieeexplore,data-oriented architecture of sine and cosine functions,https://ieeexplore.ieee.org/document/5579358/,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,4
10.1109/icepe.2014.6970070,filtered,2014 International Conference and Exposition on Electrical and Power Engineering (EPE),IEEE,10/18/2014 0:00,ieeexplore,domain specific languages in power systems engineering,https://ieeexplore.ieee.org/document/6970070/,"This paper proposes an information system for data mining that allows the specification of ad-hoc queries on a data warehouse, which contain historical information relative to exceptions (i.e., operating faults) recorded by a SCADA system in a power distribution network. The proposed application can be used by the power system engineers to explore the existent historical data, with no need for any “low level” programming expertise. The data-oriented architecture of the system provides important advantages related to application development and system maintainability.",data oriented architecture,5
10.1109/cse.2014.128,filtered,2014 IEEE 17th International Conference on Computational Science and Engineering,IEEE,12/21/2014 0:00,ieeexplore,exploring the benefits of introducing network coding into named data networking,https://ieeexplore.ieee.org/document/7023638/,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,6
10.1109/icmss.2010.5577074,filtered,2010 International Conference on Management and Service Science,IEEE,8/26/2010 0:00,ieeexplore,research of soa-based crm in telecommunications industry,https://ieeexplore.ieee.org/document/5577074/,"This paper first analyzes the architecture of the existing CRM in operators and its disadvantages. When operators integrate the 3G services into their business, it is necessary to propel their business support system shift from DOA (data-oriented architecture) to SOA (service-oriented architecture).Then an architecture of the CRM system based on SOA is presented. The paper finally takes an example of how to integrate the CRM and SFS based on SOA.",data oriented architecture,7
10.1109/lcomm.2016.2645768,filtered,IEEE Communications Letters,IEEE,4/1/2017 0:00,ieeexplore,broadcast-based content delivery in information-centric hybrid multihop wireless networks,https://ieeexplore.ieee.org/document/7801039/,"Information-centric networking is a “data-oriented” architecture for Future Internet. Since unicast routing cannot exploit the natural broadcast property of wireless networks and unicast paths may be broken down frequently due to node mobility, broadcast transmission is applied for content delivery in information-centric multihop wireless networks. It will face two key challenges: which nodes that receive the broadcasted packet should forward it, and how to avoid multiple nodes simultaneously transmitting it. In this letter, we solve these two issues by taking node mobility and available link capacity into account. A mobility-based forward node selection algorithm is proposed, which tends to select the less mobility nodes as the forward ones. An available link capacity-based forwarding scheme is proposed, which tends to select forward nodes with larger available link capacities to forward packets. Simulation results demonstrate the effectiveness of the proposed mechanism.",data oriented architecture,8
10.1007/978-3-030-88207-5_17,filtered,"Cooperative Design, Visualization, and Engineering",Springer,1/1/2021 0:00,springer,building a big data oriented architecture for enterprise integration,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88207-5_17,"Digital transformation is happening across all industries and affecting all facets of our daily life. However, in many corporations, this important process is fragmented and is undertaken without a farsighted plan to take advantage of an invaluable resource: data. This can be due to a variety of reasons, for example, lack of funding, poor business vision, inappropriate consulting or deployment. Digital transformation is a considerable investment since it will determine the system’s ability to grow and adapt to the company’s changing requirements. To achieve that end, the architecture must be flexible both in development and deployment and must also be able to harness the ever-increasing data of the corporation. Among the widely used information system architectures being used in the world, Micro-service is a standout with many advantages. The adaptation of this architecture to work with Big Data, as well as to tackle different aspects of a data system such as load-balancing, file handling and storage, etc. is a very practical area of research. This paper presents such an enterprise integration solution for a mega-corporation client in Vietnam, the An Pha Petrol Group Joint Stock Company, including the architecture and technologies used to build a comprehensive system that brings novel experiences to its 2,000 internal users. It consists of building the information infrastructure and system, super applications for both desktop and mobile devices to enhance the work performance and quality. The approaches and results of this paper are applicable to similar large enterprise solutions.",data oriented architecture,9
10.1007/978-3-319-44881-7_1,filtered,Resource Management for Big Data Platforms,Springer,1/1/2016 0:00,springer,performance modeling of big data-oriented architectures,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-44881-7_1,"Big Data applications provide new, disruptive tools to advance our knowledge about the mechanisms that characterize complex aspects of reality. Be it a high energy physics experiment or an analysis of social networks data, the strength of the approach is the availability of a huge richness of data; but, at the same time, it is also the main challenge, as this abundance of information must be processed at a bearable cost per information unit and requires higher scale systems to provide enough computing power. This is only possible if the Big Data platform is properly managed and exploited according to the needs of the applications, and a fundamental premise is the capability for a proper performance evaluation of the platform. In this chapter, we provide a glance over the main aspects of performance evaluation for Big Data architectures, together with some examples of model-based evaluation, in order to show how it is possible to characterize big scale architectures to support their correct management, and suggest a methodological coarse grain solution to exploit different conceptual and technical tools to integrate a flexible, model-based, performance analysis supported approach to Big Data systems design, capable of scaling up easily in the core evaluation stage means of Markovian agents.",data oriented architecture,10
http://arxiv.org/abs/1706.03968v2,filtered,arxiv,arxiv,6/13/2017 0:00,arxiv,asynchronous graph pattern matching on multiprocessor systems,http://arxiv.org/abs/1706.03968v2,"Pattern matching on large graphs is the foundation for a variety of
application domains. Strict latency requirements and continuously increasing
graph sizes demand the usage of highly parallel in-memory graph processing
engines that need to consider non-uniform memory access (NUMA) and concurrency
issues to scale up on modern multiprocessor systems. To tackle these aspects,
graph partitioning becomes increasingly important. Hence, we present a
technique to process graph pattern matching on NUMA systems in this paper. As a
scalable pattern matching processing infrastructure, we leverage a
data-oriented architecture that preserves data locality and minimizes
concurrency-related bottlenecks on NUMA systems. We show in detail, how graph
pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,11
http://arxiv.org/abs/1310.5488v1,filtered,arxiv,arxiv,10/21/2013 0:00,arxiv,"a practical approach to ontology-enabled control systems for
  astronomical instrumentation",http://arxiv.org/abs/1310.5488v1,"Even though modern service-oriented and data-oriented architectures promise
to deliver loosely coupled control systems, they are inherently brittle as they
commonly depend on a priori agreed interfaces and data models. At the same
time, the Semantic Web and a whole set of accompanying standards and tools are
emerging, advocating ontologies as the basis for knowledge exchange. In this
paper we aim to identify a number of key ideas from the myriad of
knowledge-based practices that can readily be implemented by control systems
today. We demonstrate with a practical example (a three-channel imager for the
Mercator Telescope) how ontologies developed in the Web Ontology Language (OWL)
can serve as a meta-model for our instrument, covering as many engineering
aspects of the project as needed. We show how a concrete system model can be
built on top of this meta-model via a set of Domain Specific Languages (DSLs),
supporting both formal verification and the generation of software and
documentation artifacts. Finally we reason how the available semantics can be
exposed at run-time by adding a ""semantic layer"" that can be browsed, queried,
monitored etc. by any OPC UA-enabled client.",data oriented architecture,12
,filtered,core,International Foundation for Telemetering,10/1/2008 0:00,core,a data-oriented software architecture for telemetry,,"ITC/USA 2008 Conference Proceedings / The Forty-Fourth Annual International Telemetering Conference and Technical Exhibition / October 27-30, 2008 / Town and Country Resort & Convention Center, San Diego, CaliforniaBuilding modern telemetry systems is fraught with challenges involving subsystem integration, the role and management of data, scalability issues, disparate technologies, concerns about cost-effectiveness and more. This article addresses today's challenges with a solution based on adopting a data-oriented architecture and relying on a standards-based, integrated high-performance middleware platform with standards-based programmable components. Key to the solution is integrating around the system information model instead of the application or technology infrastructure. A standards-based middleware infrastructure that breaks away from traditional assumptions is at the core of this approach. The article also presents successful applications of data-oriented architecture using standards-based middleware.International Foundation for TelemeteringProceedings from the International Telemetering Conference are made available by the International Foundation for Telemetering and the University of Arizona Libraries. Visit http://www.telemetry.org/index.php/contact-us if you have questions about items in this collection",data oriented architecture,13
10.15598/aeee.v19i4.4183,filtered,core,"'VSB Technical University of Ostrava, Faculty of Electrical Engineering and Computer Sciences'",1/1/2021 0:00,core,intelligent bearing fault diagnosis method based on hnr envelope and classification using supervised machine learning algorithms,https://core.ac.uk/download/490710719.pdf,"Research on data-driven bearing fault diagnosis techniques has recently drawn more and more attention due to the availability of massive condition monitoring data. The research work presented in this paper aims to develop an architecture for the detection and diagnosis of bearing faults in the induction machines. The developed data-oriented architecture uses vibration signals collected by sensors placed on the machine, which is based, in the first place, on the extraction of fault indicators based on the harmonics-to-noise ratio envelope. Normalisation is then applied to the extracted indicators to create a well-processed data set. The evolution of these indicators will be studied afterwards according to the type and severity of defects using sequential backward selection technique. Supervised machine learning classification methods are developed to classify the measurements described by the feature vector with respect to the known modes of operation. In the last phase concerning decision making, ten classifiers are tested and applied based on the selected and combined indicators. The developed classification methods allow classifying the observations, with respect to the different modes of bearing condition (outer race, inner race fault or healthy condition). The proposed method is validated on data collected using an experimental bearing test bench. The experimental results indicate that the proposed architecture achieves high accuracy in bearing fault detection under all operational conditions. The results show that, compared to some proposed approaches, our proposed architecture can achieve better performance overall in terms of the number of optimal features and the accuracy of the tests",data oriented architecture,14
10.3390/electronics10151810,filtered,core,'MDPI AG',7/1/2021 0:00,core,on-board data management layer: connected vehicle as data platform,,"For connected vehicles, as well as generally for the transportation sector, data are now seen as a precious resource. They can be used to make right decisions, improve road safety, reduce CO2 emissions, or optimize processes. However, analyzing these data is not so much a question of which technologies to use, but rather about where these data are analyzed. Thereby, the emerging vehicle architecture has to become a data-oriented architecture based on embedded computing platforms and take into account new applications, artificial intelligence elements, advanced analytics, and operating systems. Accordingly, in this paper, we introduce the concept of data management to the vehicle by proposing an on-board data management layer, so that the vehicle can play the role of data platform capable of storing, processing, and diffusing data. Our proposed layer supports analytics and data science to deliver additional value from the connected vehicle data and stimulate the development of new services. In addition, our data platform can also form or contribute to shaping the backbone of data-driven transport. An on-board platform was built where the dataset size was reduced 80% and a rate of 99% accuracy was achieved in a 5 min traffic flow prediction using artificial neural networks (ANNs)",data oriented architecture,15
10.1007/978-3-642-45249-9_36,filtered,core,'Springer Science and Business Media LLC',1/4/2014 0:00,core,towards a new internetworking architecture: a new deployment approach for information centric networks,,"International audienceNew research efforts are trying to evolve the current Inter-net. With satisfying communication hardware, the intent is to switch to data oriented networks. In this new vision, data will be the heart of the architecture and protocols have to be changed to dial with this concept. Promising ideas are proposed up in order to develop clean slate design solutions. However, these propositions encounter many deployment problems. In this paper, we propose new approach based on Bloom Filter to cope with storage space problem in data oriented architecture DONA",data oriented architecture,16
10.1109/asru.2007.4430168,filtered,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),IEEE,12/13/2007 0:00,ieeexplore,a data-centric architecture for data-driven spoken dialog systems,https://ieeexplore.ieee.org/document/4430168/,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",data centric architecture,17
10.1109/icdcsw.2003.1203556,filtered,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",IEEE,5/22/2003 0:00,ieeexplore,"""data-centric to the max"", the splice architecture experience",https://ieeexplore.ieee.org/document/1203556/,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",data centric architecture,18
10.1109/cluster.2012.80,filtered,2012 IEEE International Conference on Cluster Computing,IEEE,9/28/2012 0:00,ieeexplore,a decoupled execution paradigm for data-intensive high-end computing,https://ieeexplore.ieee.org/document/6337781/,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",data centric architecture,19
10.1109/siot.2016.007,filtered,2016 International Workshop on Secure Internet of Things (SIoT),IEEE,9/30/2016 0:00,ieeexplore,addressing data-centric security requirements for iot-based systems,https://ieeexplore.ieee.org/document/7913560/,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",data centric architecture,20
10.1109/icce-china.2017.7991141,filtered,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),IEEE,6/14/2017 0:00,ieeexplore,an iot framework for intelligent roadside assistance system,https://ieeexplore.ieee.org/document/7991141/,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",data centric architecture,21
10.1109/issnip.2005.1595552,filtered,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",IEEE,12/8/2005 0:00,ieeexplore,architectures for wireless sensor networks,https://ieeexplore.ieee.org/document/1595552/,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,data centric architecture,22
10.1109/cast.2016.7914932,filtered,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",IEEE,12/21/2016 0:00,ieeexplore,big data architecture with mobile cloud in cdroid operating system for storing huge data,https://ieeexplore.ieee.org/document/7914932/,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,data centric architecture,23
10.1109/lanman.2015.7114718,filtered,The 21st IEEE International Workshop on Local and Metropolitan Area Networks,IEEE,4/24/2015 0:00,ieeexplore,boosting named data networking for efficient packet forwarding in urban vanet scenarios,https://ieeexplore.ieee.org/document/7114718/,"Named Data Networking (NDN) is a data-centric architecture designed for the future Internet. Existing works show that NDN brings significant performance improvement for typical content-centric applications, and can also fit the mobile environment well. However, directly applying NDN to Vehicular Ad hoc NETworks (VANETs) is confronted with great challenges due to the high mobility of vehicles. Most applications in VANETs are relied on data dissemination mechanisms. Therefore, we aim to improve the performance of NDN packet forwarding for the efficient content delivery in urban VANET scenarios. Specifically, we introduce the geo-location information to the NDN forwarding plane, and propose a geo-based forwarding strategy to make NDN fit the urban VANETs. Simulation results show our strategy can achieve 27% ~ 75% higher request success ratio, and 40% ~ 80% lower delay compared with the default NDN strategy in urban scenarios with different vehicle densities.",data centric architecture,24
10.1109/innovate-data.2017.14,filtered,2017 International Conference on Big Data Innovations and Applications (Innovate-Data),IEEE,8/23/2017 0:00,ieeexplore,bringing big data into the car: does it scale?,https://ieeexplore.ieee.org/document/8316294/,"The increasing velocity of big data captured by various sensors and processed in real-time offers support for a range of new application domains. For car information systems (CIS), data from different sources including IoT needs to be combined to offer an adequate service to the user. In this paper, we introduce a novel CIS big data-centric architecture based on a smart streaming infrastructure integrating data source in and outside of the car. We have created a prototype implementation of this architecture and run several experiments to validate the quality of our solution. Especially, we have examined the fault tolerance of the architecture by systematically introducing failures and evaluating their effects on the car information system. The experimental results show that our solution for a smart data based car information system is both scalable and fault tolerant.",data centric architecture,25
10.1109/waina.2013.19,filtered,2013 27th International Conference on Advanced Information Networking and Applications Workshops,IEEE,3/28/2013 0:00,ieeexplore,ccn-tv: a data-centric approach to real-time video services,https://ieeexplore.ieee.org/document/6550523/,"Content-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCN-TV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies.",data centric architecture,26
10.1109/bigdata.2015.7363971,filtered,2015 IEEE International Conference on Big Data (Big Data),IEEE,11/1/2015 0:00,ieeexplore,component based dataflow processing framework,https://ieeexplore.ieee.org/document/7363971/,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",data centric architecture,27
10.1109/icsea.2010.30,filtered,2010 Fifth International Conference on Software Engineering Advances,IEEE,8/27/2010 0:00,ieeexplore,content server architecture pattern for evolvability and scalability,https://ieeexplore.ieee.org/document/5615125/,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",data centric architecture,28
10.1109/apwimob.2014.6920286,filtered,2014 IEEE Asia Pacific Conference on Wireless and Mobile,IEEE,8/30/2014 0:00,ieeexplore,critical security review and study of ddos attacks on lte mobile network,https://ieeexplore.ieee.org/document/6920286/,"Mobile network is currently evolving into data centric architecture. Long Term Evolution (LTE) based next generation 4G technology is being deployed by cellular operators around the globe. LTE supports all-IP based data, voice and streaming network with speeds in the order of hundreds of megabits per seconds. Increased speed in accessing Internet and other advanced services exposes mobile data network to be attacked by hackers using spyware, malware, phishing and distributed denial-of-service (DDoS) attacks, which were predominantly affecting Internet-only datacentres in the past. This paper presents a detailed review of security framework and authentication procedures built into the LTE system architecture evolution (SAE). A brief summary of DDoS attacks and security vulnerabilities in LTE network included. This paper reviews the diameter interface and associated security problems using it in LTE network. This paper proposes using explicit-congestion notification (ECN) based method to address congestion issues in diameter interface.",data centric architecture,29
10.1109/aero.2005.1559422,filtered,2005 IEEE Aerospace Conference,IEEE,3/12/2005 0:00,ieeexplore,"data centric, position-based routing in space networks",https://ieeexplore.ieee.org/document/1559422/,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",data centric architecture,30
10.1109/icccn.2019.8847129,filtered,2019 28th International Conference on Computer Communication and Networks (ICCCN),IEEE,8/1/2019 0:00,ieeexplore,data-centric video for mixed reality,https://ieeexplore.ieee.org/document/8847129/,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",data centric architecture,31
10.1109/cts.2014.6867550,filtered,2014 International Conference on Collaboration Technologies and Systems (CTS),IEEE,5/23/2014 0:00,ieeexplore,defining architecture components of the big data ecosystem,https://ieeexplore.ieee.org/document/6867550/,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a socalled Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.",data centric architecture,32
10.1109/netsys.2019.8854515,filtered,2019 International Conference on Networked Systems (NetSys),IEEE,3/21/2019 0:00,ieeexplore,information-centric iot middleware overlay: vsl,https://ieeexplore.ieee.org/document/8854515/,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",data centric architecture,33
10.1109/services51467.2021.00054,filtered,2021 IEEE World Congress on Services (SERVICES),IEEE,9/10/2021 0:00,ieeexplore,keynote 1: dbos: a database-oriented operating system,https://ieeexplore.ieee.org/document/9604388/,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Current operating systems are complex systems that were designed long before today’s computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today’s most important applications, propose a plan for the development of a DBOS proof of concept, and give results on a pilot that suggest the approach has merit.",data centric architecture,34
10.1109/pes.2005.1489657,filtered,"IEEE Power Engineering Society General Meeting, 2005",IEEE,6/16/2005 0:00,ieeexplore,moving from data architecture to event architecture in the ems environment,https://ieeexplore.ieee.org/document/1489657/,"Information models and databases are at the center of the design of most current software systems. The job done by the active portions, the applications, is to transform the data as needed. If the applications can, they work in a strictly stateless, data transforming paradigm, because this creates the simplest sort of reliable system. Our EMS systems are complex, real-time systems that cannot adopt this simplest paradigm, but they nevertheless follow a data-centric architecture. This is about to change. ""Message buses"" or ""integration buses"" or ""event buses"" are different names for the ability to connect applications with high speed flexible messaging. This technology is now ready for prime time and the question is - how are we going to use it? Are we going to take advantage of the active voice communication that events can provide? Or, are we going to stay predominantly in the familiar data orientation? The situation is somewhat analogous to the now-familiar experience that procedural programmers, when given object oriented languages, often did not go through the paradigm-shift and produced procedural code written in object languages. In this paper, we focus on the advantages that can be achieved in the temporal domain - a long-standing trouble-spot in EMS design.",data centric architecture,35
10.1109/aero.2010.5446746,filtered,2010 IEEE Aerospace Conference,IEEE,3/13/2010 0:00,ieeexplore,pnpsat-2 spa technology testbed initial results and development status,https://ieeexplore.ieee.org/document/5446746/,"Abstract-This paper presents the initial results and development status of the AFRL sponsored PnPSat-2 SPA Technology Testbed. The purpose of the testbed is to integrate the next generation of radiation hardened SPA technology and components (hardware and software) with a representative tactical satellite bus structure. The resulting system will be used to demonstrate system performance using Hardware in the Loop (HWIL) techniques for representative (e.g. ORS Tactical) scenarios. AFRL has led two efforts in SPA technology development to both solidify the SPA technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) was the first spacecraft to utilize the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. PnPSat-2 integrates the next generation of radiation hardened SPA components on a larger bus focused on ORS needs. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insulates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in development and test time.",data centric architecture,36
10.1109/trustcom.2016.0248,filtered,2016 IEEE Trustcom/BigDataSE/ISPA,IEEE,8/26/2016 0:00,ieeexplore,rethinking high performance computing system architecture for scientific big data applications,https://ieeexplore.ieee.org/document/7847131/,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",data centric architecture,37
10.1109/pdcat.2010.72,filtered,"2010 International Conference on Parallel and Distributed Computing, Applications and Technologies",IEEE,12/11/2010 0:00,ieeexplore,sharing in-memory game states,https://ieeexplore.ieee.org/document/5704404/,"Massively multi-user virtual environments (MMVEs)are becoming increasingly popular with millions of users. Typically, commercial implementations rely on client/server architectures for managing the game state and use message passing mechanisms to communicate state changes to the clients. We have developed the Typed Grid Object Sharing (TGOS)service providing data sharing of in-memory data. TGOS aims at simplifying the development of MMVEs by sharing scene graphs in a peer-to-peer way and also data of backend services. Replication is controlled by different consistency models, including restartable transactions combined with optimistic synchronization for strong consistency. In this paper we describe the data centric architecture of the Wissenheim Worlds application and relevant parts of TGOS. Furthermore, we present an evaluation showing the feasibility and efficiency of the proposed approach.",data centric architecture,38
10.1109/aero.2017.7943816,filtered,2017 IEEE Aerospace Conference,IEEE,3/11/2017 0:00,ieeexplore,software architecture and design of the kontur-2 mission,https://ieeexplore.ieee.org/document/7943816/,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",data centric architecture,39
10.1109/ciot.2018.8627124,filtered,2018 3rd Cloudification of the Internet of Things (CIoT),IEEE,7/4/2018 0:00,ieeexplore,"fogø5: unifying the computing, networking and storage fabrics end-to-end",https://ieeexplore.ieee.org/document/8627124/,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",data centric architecture,40
10.1109/tcc.2015.2474385,filtered,IEEE Transactions on Cloud Computing,IEEE,6/1/2020 0:00,ieeexplore,cross-cloud mapreduce for big data,https://ieeexplore.ieee.org/document/7229313/,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",data centric architecture,41
10.1109/jiot.2021.3061531,filtered,IEEE Internet of Things Journal,IEEE,8/1/2001 20:21,ieeexplore,smartdetour: defending blackhole and content poisoning attacks in iot ndn networks,https://ieeexplore.ieee.org/document/9360863/,"Named data networking (NDN) recently arises as a promising networking paradigm to support the Internet of Things (IoT) due to its data-centric architecture. However, NDN integrates application-layer semantics into the packet forwarding plane, which presents new attack faces. In this article, we aim to handle two attacks that exploit such vulnerabilities, namely the blackhole attack and the content poisoning attack. The two attacks are not handled efficiently by existing approaches due to the challenge in minimizing routers that need to be detoured to isolate attackers. Therefore, in this article, we propose a novel method named SmartDetour to tackle the challenge in a distributed manner. SmartDetour contains two components: 1) a proactive reputation updating algorithm and 2) a reputation-based probabilistic forwarding strategy. The former updates the reputation of forwarding candidates based on whether they must be detoured upon packet failures. The latter selects the next-hop router for interest packets probabilistically based on the reputations of forwarding candidates. The two components work together to isolate attackers with minimal detouring needed. Extensive ndnSIM-based simulation shows that SmartDetour can effectively identify and isolate attackers.",data centric architecture,42
10.1147/jrd.2019.2960220,filtered,IBM Journal of Research and Development,IBM,7/1/2020 0:00,ieeexplore,the coral supercomputer systems,https://ieeexplore.ieee.org/document/8935422/,"In 2014, the U.S. Department of Energy (DoE) initiated a multiyear collaboration between Oak Ridge National Laboratory (ORNL), Argonne National Laboratory, and Lawrence Livermore National Laboratory (LLNL), known as “CORAL,” the next major phase in the DoE's scientific computing roadmap. The IBM CORAL systems are based on a fundamentally new data-centric architecture, where compute power is embedded everywhere data resides, combining powerful central processing units (CPUs) with graphics processing units (GPUs) optimized for scientific computing and artificial intelligence workloads. The IBM CORAL systems were built on the combination of mature technologies: 9th-generation POWER CPU, 6th-generation NVIDIA GPU, and 5th-generation Mellanox InfiniBand. These systems are providing scientists with computing power to solve challenges in many research areas beyond previously possible. This article provides an overview of the system solutions deployed at ORNL and LLNL.",data centric architecture,43
10.1049/cp.2012.1116,filtered,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),IET,3/5/2012 0:00,ieeexplore,design of real-time distributed system using dds,https://ieeexplore.ieee.org/document/6492723/,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,data centric architecture,44
,filtered,2019 56th ACM/IEEE Design Automation Conference (DAC),IEEE,6/6/2019 0:00,ieeexplore,dr. bfs: data centric breadth-first search on fpgas,https://ieeexplore.ieee.org/document/8806902/,"The flexible architectures of Field Programmable Gate Arrays (FPGAs) lend themselves to an array of data analytical applications, among which Breadth-First Search (BFS), due to its vital importance, draws particular attention. Recent attempts that omoad BFS on FPGAs either simply imitate the existing CPU- or Graphics Processing Units (GPU)based mechanisms or suffer from scalability issues. To this end, we introduce a novel data centric design which extensively extracts the potential of FPGAs for BFS with the following two techniques. First, we advocate to partition and compress the BFS algorithmic metadata in order to buffer them in fast on-chip memory and circumvent the expensive metadata access. Second, we propose a hierarchical coalescing method to improve the throughput of graph data access. Taken together, our evaluation demonstrates that the proposed design achieves, on average, 1.6× and 2.2× speedups over the state-of-the-art FPGA designs TorusBFS and Umuroglu, respectively, across a collection of graph datasets.",data centric architecture,45
10.1109/hoticn50779.2020.9350821,filtered,2020 3rd International Conference on Hot Information-Centric Networking (HotICN),IEEE,12/14/2020 0:00,ieeexplore,hierarchical identity-based security mechanism using blockchain in named data networking,https://ieeexplore.ieee.org/document/9350821/,"Named Data Networking (NDN) with the data-centric design has been viewed as a promising future Internet architecture. It requires a new security model orienting data but not host. In this paper, a Hierarchical Identity-based Security Mechanism by Blockchain (HISM-B) is to be proposed for NDN networks. It could satisfy the two assumptions specified in the NDN testbed to maintain the data-oriented authentication. At one hand, the hierarchical identity-based cryptology is used to bind the data name with the public key and then two signatures are encapsulated in the data packet so that the data source authentication and the integrity of data packet can be supported. At the other hand, a blockchain is employed to manage public keys for different domains to avoid catastrophes due to a single node failure. The validation result shows that the proposed HISM-B is safe.",data centric architecture,46
10.1109/bigdata47090.2019.9006235,filtered,2019 IEEE International Conference on Big Data (Big Data),IEEE,12/12/2019 0:00,ieeexplore,hybrid 2d and 3d visual analytics of network simulation data,https://ieeexplore.ieee.org/document/9006235/,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,47
10.1109/iccworkshops49005.2020.9145301,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,6/11/2020 0:00,ieeexplore,supporting delay tolerant networking: a comparative study of epidemic routing and ndn,https://ieeexplore.ieee.org/document/9145301/,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",data centric architecture,48
http://arxiv.org/abs/2007.11112v1,filtered,arxiv,arxiv,7/21/2020 0:00,arxiv,dbos: a proposal for a data-centric operating system,http://arxiv.org/abs/2007.11112v1,"Current operating systems are complex systems that were designed before
today's computing environments. This makes it difficult for them to meet the
scalability, heterogeneity, availability, and security challenges in current
cloud and parallel computing environments. To address these problems, we
propose a radically new OS design based on data-centric architecture: all
operating system state should be represented uniformly as database tables, and
operations on this state should be made via queries from otherwise stateless
tasks. This design makes it easy to scale and evolve the OS without
whole-system refactoring, inspect and debug system state, upgrade components
without downtime, manage decisions using machine learning, and implement
sophisticated security features. We discuss how a database OS (DBOS) can
improve the programmability and performance of many of today's most important
applications and propose a plan for the development of a DBOS proof of concept.",data centric architecture,49
http://arxiv.org/abs/1705.04958v1,filtered,arxiv,arxiv,5/14/2017 0:00,arxiv,a proposed architecture for big data driven supply chain analytics,http://arxiv.org/abs/1705.04958v1,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.",data centric architecture,50
10.1016/j.future.2021.06.020,filtered,core,'Elsevier BV',6/19/2023 0:00,core,a big data-centric architecture metamodel for industry 4.0,,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",data centric architecture,51
10.1016/j.jnca.2010.03.017,filtered,core,Elsevier,1/1/2010 0:00,core,context- and social-aware middleware for opportunistic networks,,"Opportunistic networks are multi-hop ad hoc networks in which nodes opportunistically exploit any pair-wise contact to share and forward content, without requiring any pre-existing Internet infrastructure. Opportunistic networks tolerate partitions, long disconnections, and topology instability in general. In this challenging environment, leveraging users\u27 mobility represents the most effective way to deliver content to interested users. In this paper we propose a context- and social-aware middleware that autonomically learns context and social information on the users of the network, and that uses this information in order to predict users\u27 future movements. In order to evaluate the proposed middleware on a realistic scenario, we have designed and implemented a context- and social-aware content sharing service, exploiting the functionality of the middleware. Both the middleware and the content sharing service have been integrated with an existing data-centric architecture (the Haggle architecture) for opportunistic networks. Finally, we have validated the proposed content sharing application on a small-scale testbed and, on a larger scale, we have investigated the advantages provided by context- and social-aware sharing strategies by means of extensive simulations. The main result of this paper is the definition and implementation of a context- and social-aware middleware able to share context information with all the interested components improving the efficiency and performances of services and protocols in opportunistic networks. With respect to content sharing strategies that do not exploit context and social information, we have obtained up to 200% improvements in terms of hit rate (probability that users receive the content they request) and 99% reduction in resource consumption in terms of traffic generated on the network",data centric architecture,52
10.2514/6.2012-549,filtered,core,,1/1/2012 0:00,core,towards a unified framework using cpacs for geometry management in aircraft design,,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",data centric architecture,53
10.1002/dac.2964,filtered,core,"John Wiley & Sons, Inc.",1/1/2017 0:00,core,push applications and dynamic content generation over content-centric networking,,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",data centric architecture,54
10.1109/i-span.2009.67,filtered,"2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks",IEEE,12/16/2009 0:00,ieeexplore,a data-driven architecture for remote control of sensors over a wireless sensor network and the internet,https://ieeexplore.ieee.org/document/5381871/,"This study revealed an applicable architecture in which a data-driven mechanism was designed to bridge a wireless sensor network (WSN) and the Internet. The system was divided into two independent parts. The first part is the data communication between the sensor network and the database. The other part is the data communication between the database and the user interface (UI). These two parts are connected by the database server. Asynchronous interoperation was introduced while exchanging data between these two parts. Users were not allowed to control the sensors through direct connection to the sensors and can only use the Web service to update the sensor profile built in the database. The sensors were triggered to start the action through a data-update event from the database. A sensor profile built in the database collected all sensor information and all user control command. For the information to be centralized and triggered by the database, regardless of whether sensors were measured in a periodic sampling or an event-driven environment, all sensor actions were triggered through a data-update event in the database. For the sake of improving user experience, a Web-based UI was implemented using scalable vector graphics (SVG) and Ajax technologies. All operations by users were conducted through the Hypertext Transfer Protocol (HTTP) standard method. Therefore, this system can be used via a browser and easily deployed. The proposed architecture is suitable for a healthcare system, a personal body area network, and the Infranet for control.",data driven architecture,55
10.1109/sensors47125.2020.9278616,filtered,2020 IEEE SENSORS,IEEE,10/28/2020 0:00,ieeexplore,a data-driven architecture for sensor validation based on neural networks,https://ieeexplore.ieee.org/document/9278616/,"In this paper, we propose a novel sensor validation architecture, which performs sensor fault detection, isolation and accommodation (SFDIA). More specifically, a machine-learning based architecture is presented to detect faults in sensors measurements within the system, identify the faulty ones and replace them with estimated values. In our proposed architecture, sensor estimators based on neural networks are constructed for each sensor node in order to accommodate faulty measurements along with a classifier to determine the failure detection and isolation. Finally, numerical results are presented to confirm the effectiveness of the proposed architecture on a publicly-available air quality (AQ) chemical multi-sensor data-set.",data driven architecture,56
10.1109/bigcomp51126.2021.00080,filtered,2021 IEEE International Conference on Big Data and Smart Computing (BigComp),IEEE,1/20/2021 0:00,ieeexplore,a modular data-driven architecture for empathetic conversational agents,https://ieeexplore.ieee.org/document/9373265/,"Empathy is a fundamental mechanism of human interactions. As such, it should be an integral part of Human-Computer Interaction systems to make them more relatable. With this work, we focused on conversational scenarios where integrating empathy is crucial to perceive the computer like a human. As a result, we derived the high-level architecture of an Empathetic Conversational Agent we are willing to implement. We relied on theories about artificial empathy to derive the function approximating this mechanism and selected the conversational aspects to control for an empathetic interaction. In particular, we designed a core empathetic controller manages the empathetic responses, predicting, at each turn, the high-level content of the response. The derived architecture integrates empathy in a task-agnostic manner; hence we can employ it in multiple scenarios by changing the objective of the controller.",data driven architecture,57
10.1109/noms.2004.1317788,filtered,2004 IEEE/IFIP Network Operations and Management Symposium (IEEE Cat. No.04CH37507),IEEE,4/23/2004 0:00,ieeexplore,a distributed data driven architecture for operations support systems,https://ieeexplore.ieee.org/document/1317788/,"This paper proposes a distributed data driven architecture (D3A), devised for application to an operations support system (OSS). By applying this architecture to an OSS, it is possible to reduce OSS hardware and middleware costs, and to change OSS application programs rapidly and flexibly. To assure alarm reception processing performance at low cost, D3A is comprised of a lot of IA servers. With D3A, OSS application programs are divided into a lot of elements similar to UNIX processes. These elements are called processing elements (PEs). A PE is mounted on each IA server. Data that represents the execution sequence and execution condition of PEs is called processing configuration data (PCD). The PCD moves about among IA servers comprising an OSS. The PCD driver (PCDD) is a function to analyze the PCD, and determines the PE to be executed next and controls the route of the PCD. A commercial OSS is being developed by using D3A and will start running in June 2004.",data driven architecture,58
10.1109/imtc.1994.352173,filtered,Conference Proceedings. 10th Anniversary. IMTC/94. Advanced Technologies in I & M. 1994 IEEE Instrumentation and Measurement Technolgy Conference (Cat. No.94CH3424-9),IEEE,5/12/1994 0:00,ieeexplore,data driven architecture for mixed signal ate to improve cad connectivity,https://ieeexplore.ieee.org/document/352173/,"This paper describes outlines of a tester architecture designed to simplify test designs of mixed signal devices. It also describes the results of integration the test environment to the CAD environment by application of the object oriented technology to controls of the test systems. It also describes the fact that, as a secondary effect of this architecture, the throughput of tests has been improved more than double the previous figures.&lt;<ETX>&gt;</ETX>",data driven architecture,59
10.1109/ismsit50672.2020.9254863,filtered,2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),IEEE,10/24/2020 0:00,ieeexplore,personalized quality of experience (qoe) management using data driven architecture in 5g wireless networks,https://ieeexplore.ieee.org/document/9254863/,"the aim of this paper is to Personalized Quality of Experience (QOE) Management using Data driven Architecture in 5G Wireless Networks that consume less resources. The proposed research will be the part of the overall research project, which focuses on addressing a problem that many organizations experience that introduce an Enterprise Architecture to support the integration of different services across the enterprise. With the rapid growth in mobile network usage and video streaming being the most popular service, Quality of Experience of video in mobile networks is of extreme importance to both service providers and their customers. The ability to effectively predict Quality of Experience of video is key for QoE adaptation and higher levels of customer satisfaction. In this work machine learning algorithms were used to create models that predict QoE with network QoS parameters, including wireless-specific and 5Gspecific parameters. An 5G simulation that reflects the current mobile traffic landscape was created to obtain the data set for training. An objective tool for video QoE evaluation was used to gather QoE data necessary to train the prediction models. Support Vector Machines, Random Forest, Gradient Boosted Trees and Neural Networks were chosen as the machine learning algorithms for Quality of Experience prediction, and it was shown that they achieve high accuracy. Influence of wireless-specific parameters on QoE prediction was also investigated, and it was discovered that they are suitable for use in Quality of Experience prediction models.The problem is that; organizations do not know where they either have or may encounter weaknesses in their Enterprise Architecture with Data Driven Architecture (DDA). The framework presented is based on concepts from Wireless Networks with Driven Architecture will be designed to support both Transitional Gap Analysis (TGA) and Comparative Gap Analysis (CGA). TGA is supported by comparing a baseline Data Driven Architecture (DDA) to a target QoE where both DDA have been defined from the management perspective. DDA is facilitated by mapping a QoE to two or more 5G networks. The research methodology used in the paper is design science research for the QoE management based 5G network. The QOE for implementation of 5th generation network and apply it in many different real-world organizations. The goal of the paper is to present a framework in the form an implementation and management model, called QOE, that visualizes the gaps (weaknesses) in proposed or existing enterprise architectures and to support a comparative analysis process for different a5Grnative solution approaches. a set of requirements on the QOE management can be presented and the frameworks are applied on Matlab for implementation.",data driven architecture,60
10.1109/lra.2019.2896485,filtered,IEEE Robotics and Automation Letters,IEEE,4/1/2019 0:00,ieeexplore,learning from humans how to grasp: a data-driven architecture for autonomous grasping with anthropomorphic soft hands,https://ieeexplore.ieee.org/document/8629968/,"Soft hands are robotic systems that embed compliant elements in their mechanical design. This enables an effective adaptation with the items and the environment, and ultimately, an increase in their grasping performance. These hands come with clear advantages in terms of ease-to-use and robustness if compared with classic rigid hands, when operated by a human. However, their potential for autonomous grasping is still largely unexplored, due to the lack of suitable control strategies. To address this issue, in this letter, we propose an approach to enable soft hands to autonomously grasp objects, starting from the observations of human strategies. A classifier realized through a deep neural network takes as input the visual information on the object to be grasped, and predicts which action a human would perform to achieve the goal. This information is hence used to select one among a set of human-inspired primitives, which define the evolution of the soft hand posture as a combination of anticipatory action and touch-based reactive grasp. The architecture is completed by the hardware component, which consists of an RGB camera to look at the scene, a 7-DoF manipulator, and a soft hand. The latter is equipped with inertial measurement units at the fingernails for detecting contact with the object. We extensively tested the proposed architecture with 20 objects, achieving a success rate of 81.1% over 111 grasps.",data driven architecture,61
10.1109/tmc.2020.2999852,filtered,IEEE Transactions on Mobile Computing,IEEE,12/1/2021 0:00,ieeexplore,machine learning at the edge: a data-driven architecture with applications to 5g cellular networks,https://ieeexplore.ieee.org/document/9107476/,"The fifth generation of cellular networks (5G) will rely on edge cloud deployments to satisfy the ultra-low latency demand of future applications. In this paper, we argue that such deployments can also be used to enable advanced data-driven and Machine Learning (ML) applications in mobile networks. We propose an edge-controller-based architecture for cellular networks and evaluate its performance with real data from hundreds of base stations of a major U.S. operator. In this regard, we will provide insights on how to dynamically cluster and associate base stations and controllers, according to the global mobility patterns of the users. Then, we will describe how the controllers can be used to run ML algorithms to predict the number of users in each base station, and a use case in which these predictions are exploited by a higher-layer application to route vehicular traffic according to network Key Performance Indicators (KPIs). We show that the prediction accuracy improves when based on machine learning algorithms that rely on the controllers’ view and, consequently, on the spatial correlation introduced by the user mobility, with respect to when the prediction is based only on the local data of each single base station.",data driven architecture,62
10.1109/jsen.2020.3029459,filtered,IEEE Sensors Journal,IEEE,2/15/2015 20:21,ieeexplore,"sensor-fault detection, isolation and accommodation for digital twins via modular data-driven architecture",https://ieeexplore.ieee.org/document/9216114/,"Sensor technologies empower Industry 4.0 by enabling integration of in-field and real-time raw data into digital twins. However, sensors might be unreliable due to inherent issues and/or environmental conditions. This article aims at detecting anomalies in measurements from sensors, identifying the faulty ones and accommodating them with appropriate estimated data, thus paving the way to reliable digital twins. More specifically, we propose a general machine-learning-based architecture for sensor validation built upon a series of neural-network estimators and a classifier. Estimators correspond to virtual sensors of all unreliable sensors (to reconstruct normal behaviour and replace the isolated faulty sensor within the system), whereas the classifier is used for detection and isolation tasks. A comprehensive statistical analysis on three different real-world data-sets is conducted and the performance of the proposed architecture validated under hard and soft synthetically-generated faults.",data driven architecture,63
10.1109/nssmic.1998.775181,filtered,1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255),IEEE,11/14/1998 0:00,ieeexplore,a 16-channel digital tdc chip,https://ieeexplore.ieee.org/document/775181/,"A 16-channel digital TDC chip has been built for the DIRC Cerenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns and the full-scale 32 microseconds. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The linearity is better than 80 ps rms on 90% of the production parts.",data driven architecture,64
10.1109/cdc.2007.4434859,filtered,2007 46th IEEE Conference on Decision and Control,IEEE,12/14/2007 0:00,ieeexplore,a scalable wireless communication architecture for average consensus,https://ieeexplore.ieee.org/document/4434859/,"This paper introduces a multiple-access coding technique that is tailored to solve average consensus problems efficiently in wireless networks. We propose a novel data driven architecture which grants channel access to nodes based on their local data values. We analyze the performance of the scheme in the presence of quantization errors and noise. We show that our scheme is unbiased with respect to quantized consensus algorithms, it achieves good MSE performance, and it can be configured to provide a speedup in the convergence rate. The amount of speedup achieved is a function of |Q<sub>k</sub>| which indicates the number of quantization bins used to represent the state variables exchanged during the computation.",data driven architecture,65
10.1109/emwrts.1996.557821,filtered,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,IEEE,6/14/1996 0:00,ieeexplore,an embedded accelerator for real-time image processing,https://ieeexplore.ieee.org/document/557821/,"The paper presents an embedded reconfigurable accelerator called Xputer, comprising a novel kind of sequencer hardware (data sequencer). For many real-time signal processing, multimedia, and other high-performance applications this new data-driven architecture increases the performance of a single processor system enormously by integrating it as a co-processor for accelerating computation-intensive parts of an application. The reconfigurable architecture and programming environment is described. Its use is illustrated with an automotive application requiring real-time image processing.",data driven architecture,66
10.1109/geoinformatics.2010.5567735,filtered,2010 18th International Conference on Geoinformatics,IEEE,6/20/2010 0:00,ieeexplore,an integrated spatio-temporal modeling and analysis framework for climate change research,https://ieeexplore.ieee.org/document/5567735/,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It's brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.",data driven architecture,67
10.1109/fpt.2010.5681493,filtered,2010 International Conference on Field-Programmable Technology,IEEE,12/10/2010 0:00,ieeexplore,automatic synthesis of processor arrays with local memories on fpgas,https://ieeexplore.ieee.org/document/5681493/,"In this paper, we present an automatic synthesis framework to map loop nests to processor arrays with local memories on FPGAs. An affine transformation approach is firstly proposed to address space-time mapping problem. Then a data-driven architecture model is introduced to enable automatic generation of processor arrays by extracting this data-driven architecture model from transformed loop nests. Some techniques including memory allocation, communication generation and control generation are presented. Synthesizable RTL codes can be easily generated from the architecture model built by these techniques. A preliminary synthesis tool is implemented based on PLUTO, an automatic polyhedral source-to-source transformation and parallelization framework.",data driven architecture,68
10.1109/nssmic.2005.1596398,filtered,"IEEE Nuclear Science Symposium Conference Record, 2005",IEEE,10/29/2005 0:00,ieeexplore,beam test results of a c/sub 4/f/sub 8/o gas radiator cherenkov detector using multi-anode photomultiplier tubes,https://ieeexplore.ieee.org/document/1596398/,"We present the main results from a beam test done at Fermilab of a novel gaseous RICH detector that uses Hamamatsu multi-anode photomultiplier tubes (MAPMT) as photon detectors and a new gas C/sub 4/F/sub 8/O as a Cherenkov radiator. A novel front end electronics ASIC has been developed geared towards reading out the charge signals from the photon detectors. The ASIC features low noise and high dynamic range and is suitable for data driven architecture. The data acquisition system was developed to read 52 MAPMTs. An external trigger was used and the events were built using the time stamp information provided by the readout chips. We report the number of detected photons, the angular resolution per photon and the resolution per track after averaging over the photons. We also compare our measurements with simulations.",data driven architecture,69
10.1109/icws.2008.147,filtered,2008 IEEE International Conference on Web Services,IEEE,9/26/2008 0:00,ieeexplore,common business components and services toward more agile and flexible industry solutions and assets,https://ieeexplore.ieee.org/document/4670150/,"In many decades, many organizations, especially large consulting companies, have been designing, implementing and managing business solutions for every industry around the globe. But due to numerous limitations in process, tooling and skills, most of those solutions were made very specific to individual industry and client needs at its early design stage. Therefore, reuse and more importantly, managing the ever changing business requirements, become almost impossible. Service-orientation and architecture, model-driven business development provides us a new and powerful approach to facilitate asset based industry solution design and development. To further accelerate this, this tutorial will discuss an innovative approach that take advantage of many proven best software engineering practices, from object/component based technology, meta-data driven architecture types (archetypes) that are used to model the common structural and in some cases non-structural business entities such as customer, product, payment, etc. In order to address the consequences introduced by abstracting those common elements out of the specific industry model and be able to enable easy and meta-data based transformation, we properly decompose business components/services into a multi-layered business architecture. Therefore, process/components/services can be decomposed accordingly to facilitate the decomposition and abstraction, while maintaining certain level of necessary traceability across various artifacts. In the realization phase, existing assets/operational systems will be mapped and transformed to the required business components and services to best leverage those existing valuable industry/client investments. To support such a SOA based, model and business driven development process, existing tooling, especially the necessary transformation and integration capability, needs to be significantly enhanced. This tutorial will also present some recommendation based on some recent design and implementation, and they could be used to guide future tooling alignment and integration effort across software modeling, implementation and solution products. In addition, we will present how to leverage existing internal or external assets or product offerings and the open industry reference models and standards (such as ACCORD, ebXML, ARTS/IxRetail). This work is based on authors' collective experience in leading the large end-to-end client engagements across many industries, while promoting various industry leading software engineering best practices.",data driven architecture,70
10.1109/nabic.2009.5393876,filtered,2009 World Congress on Nature & Biologically Inspired Computing (NaBIC),IEEE,12/11/2009 0:00,ieeexplore,data diverse fault tolerant architecture for component based systems,https://ieeexplore.ieee.org/document/5393876/,"Of late, component based software design has become a major focus in software engineering research and computing practice. These software components are used in a wide range of applications some of which may have mission critical requirements. In order to achieve required level of reliability, these component-based designs have to incorporate special measures to cope up with software faults. This paper presents a fault tolerant component based data driven architecture that is based on C2 architectural framework and implements data diverse fault tolerance strategies. The proposed design makes a trade-off between platform flexibility, reliability and efficiency at run time and exhibits its ability to tolerate faults in a cost effective manner. Application of proposed design is exhibited with a case study.",data driven architecture,71
10.1109/tina.1997.660723,filtered,Proceedings TINA '97 - Global Convergence of Telecommunications and Distributed Object Computing,IEEE,11/20/1997 0:00,ieeexplore,data-driven implementation of tina kernel transport network,https://ieeexplore.ieee.org/document/660723/,"To realize the actual TINA-based telecommunications network, the performance of the kernel Transport Network (kTN) such as availability, reliability, throughput and load tolerance becomes more crucial than for existing computer networks. The authors have been studying and developing a super-integrated data-driven processor to be applied to the TINA kTN nodes and network interfaces in CUE (Coordinating Users' requirements and Engineering constraints) project. Since the processor is primarily designed to be a scalable VLSI component, it is easily interconnected to form a super-integrated chip and multi-chip system for achieving the performance and reliability demanded in a TINA environment. We first examine the requirements for kTN. A stream-oriented data-driven architecture is then proposed with special emphasis on effective multiprocessing capability with overload tolerance. After that, we demonstrate that autonomous load balancing among super-integrated data-driven processors without adding any runtime overhead to achieve effective and reliable multiprocessing is possible by utilizing the overload tolerance of the processor. Finally, this paper shows preliminary performance estimations of the super-integrated data-driven processor being developed to perform efficient multiprocessing in protocol handling such as TCP/IP.",data driven architecture,72
10.1109/icra.2011.5979609,filtered,2011 IEEE International Conference on Robotics and Automation,IEEE,5/13/2011 0:00,ieeexplore,dead reckoning in a dynamic quadruped robot: inertial navigation system aided by a legged odometer,https://ieeexplore.ieee.org/document/5979609/,"It is an important ability for any mobile robot to be able to estimate its posture and to gauge the distance it travelled. The information can be obtained from various sources. In this work, we have addressed this problem in a dynamic quadruped robot. We have designed and implemented a navigation algorithm for full body state (position, velocity, and attitude) estimation that does not use any external reference (such as GPS, or visual landmarks). Extended Kalman Filter was used to provide error estimation and data fusion from two independent sources of information: Inertial Navigation System mechanization algorithm processing raw inertial data, and legged odometry, which provided velocity aiding. We present a novel data-driven architecture for legged odometry that relies on a combination of joint sensor signals and pressure sensors. Our navigation system ensures precise tracking of a running robot's posture (roll and pitch), and satisfactory tracking of its position over medium time intervals. We have shown our method to work for two different dynamic turning gaits and on two terrains with significantly different friction. We have also successfully demonstrated how our method generalizes to different velocities.",data driven architecture,73
10.1109/sam48682.2020.9104367,filtered,2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,6/11/2020 0:00,ieeexplore,deep radar waveform design for efficient automotive radar sensing,https://ieeexplore.ieee.org/document/9104367/,"In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a wellknown unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.",data driven architecture,74
10.1109/nssmic.2004.1466709,filtered,IEEE Symposium Conference Record Nuclear Science 2004.,IEEE,10/22/2004 0:00,ieeexplore,design and evaluation of the clear-pem detector for positron emission mammography,https://ieeexplore.ieee.org/document/1466709/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with adequate field-of-view dimensions for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,75
10.1109/cac.2017.8244168,filtered,2017 Chinese Automation Congress (CAC),IEEE,10/22/2017 0:00,ieeexplore,design and implementation of data-driven based universal data editing framework,https://ieeexplore.ieee.org/document/8244168/,"Apply Integrated Logistics Support (ILS) to weapon equipment can efficiently improve equipment's automation and digital level. ILS needs support of various integrated support systems, which have demands for data editing. Nowadays, most of data editing software used in these systems are customized and provide a form-based editing approach, which becomes an obstacle to carry out ILS. This paper brings forward to design a data-driven based universal data editing framework. In this framework, data models are taken as input and only corresponding data models need to be modified when data change. Firstly, the whole development process of data editing software that adopt form-based development mode is analyzed in detail to find out problems exists in this development mode. Then the data-driven based universal data editing framework is designed. New idea of data-driven architecture is proposed. Data-driven architecture takes data models as input and processes all data models in a universal way. Finally, key technology for framework realization is given.",data driven architecture,76
10.1109/nssmic.2000.949427,filtered,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,10/20/2000 0:00,ieeexplore,design and performance of the dzero data acquisition system,https://ieeexplore.ieee.org/document/949427/,"The D0 Run 2 data acquisition system features a novel design permitting complex event routing in a high speed, data driven architecture. Data blocks associated with multiple events flow freely from /spl sim/70 frontend digitization crates. Eight separate readout concentrators funnel these blocks onto optical fiber paths to the Level 3 trigger processor farm. The processor farm is divided into segments, each of which is fed by a segment bridge. Data blocks flow to each bridge in turn, where they are either routed to a Level 3 node (or nodes) in the segment, or passed onto the next segment bridge. Blocks that do not flow to a processor node are returned to the readout concentrator. Thus the system has a built-in mechanism for rate limitation. The Event Tag Generator (ETG) and segment bridges facilitate the event routing decisions in real time. The routing is based on the trigger bits from the hardware trigger. This and the availability of nodes in each segment determine to which node(s) the event is routed. We present operational and performance details of this system, designed for comfortably more than the nominal 1 kHz input; being modular and parallel, it can be easily upgraded.",data driven architecture,77
10.1109/ewdts.2010.5742121,filtered,2010 East-West Design & Test Symposium (EWDTS),IEEE,9/20/2010 0:00,ieeexplore,development of the data-driven readout asic for microstrip detectors,https://ieeexplore.ieee.org/document/5742121/,"Presented are the results of developing an asynchronous data-driven architecture for multichannel silicon tracker system experiments. A known event statistics in multichannel equipment makes it possible to use new variants of architecture synthesis with use of analog derandomizing blocks. There are discussed the testing and simulation results of separate prototype blocks and the whole system, aimed to achieve a compromise in a set of parameters, focused on power consumption, performance and dead time. The requirements of the silicon tracker station in CBM experiment were used in design.",data driven architecture,78
10.1109/cdc.2018.8618963,filtered,2018 IEEE Conference on Decision and Control (CDC),IEEE,12/19/2018 0:00,ieeexplore,discovering conservation laws from data for control,https://ieeexplore.ieee.org/document/8618963/,"Conserved quantities, i.e. constants of motion, are critical for characterizing many dynamical systems in science and engineering. These quantities are related to underlying symmetries and they provide fundamental knowledge about physical laws, describe the evolution of the system, and enable system reduction. In this work, we formulate a data-driven architecture for discovering conserved quantities based on Koopman theory. The Koopman operator has emerged as a principled linear embedding of nonlinear dynamics, and its eigenfunctions establish intrinsic coordinates along which the dynamics behave linearly. Interestingly, eigenfunctions of the Koopman operator associated with vanishing eigenvalues correspond to conserved quantities of the underlying system. In this paper, we show that these invariants may be identified with data-driven regression and power series expansions, based on the infinitesimal generator of the Koopman operator. We further establish a connection between the Koopman framework, conserved quantities, and the Lie-Poisson bracket. This data-driven method for discovering conserved quantities is demonstrated on the three-dimensional rigid body equations, where we simultaneously discover the total energy and angular momentum and use these intrinsic coordinates to develop a model predictive controller to track a given reference value.",data driven architecture,79
10.1109/nssmic.2000.949945,filtered,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,10/20/2000 0:00,ieeexplore,error handling for the cdf silicon vertex tracker,https://ieeexplore.ieee.org/document/949945/,"The SVT online tracker for the CDF upgrade reconstructs two-dimensional tracks using information from the Silicon Vertex detector (SVXII) and the Central Outer Tracker (COT). The SVT has an event rate of 100 kHz and a latency time of 10 /spl mu/s. The system is composed of 104 VME 9U digital boards (of 8 different types) and it is implemented as a data driven architecture. Each board runs on its own 30 MHz clock. Since the data output from the SVT (few Mbytes/sec) are a small fraction of the input data (200 Mbytes/sec), it is extremely difficult to track possible internal errors by using only the output stream. For this reason several diagnostic tools have been implemented: local error registers, error bits propagated through the data streams and the Spy Buffer system. Data flowing through each input and output stream of every board are continuously copied to memory banks named Spy Buffers which act as built in logic state analyzers hooked continuously to internal data streams. The contents of all buffers can be frozen at any time (e.g. on error detection) to take a snapshot of all data flowing through each SVT board. The Spy Buffers are coordinated at system level by the Spy Control Board. The architecture, design and implementation of this system are described.",data driven architecture,80
10.1109/ipps.1994.288217,filtered,Proceedings of 8th International Parallel Processing Symposium,IEEE,4/29/1994 0:00,ieeexplore,fault detection and recovery in a data-driven real-time multiprocessor,https://ieeexplore.ieee.org/document/288217/,"Introduces the mechanisms required to perform fault detection and recovery in the DART (Data-driven Architecture for Real-Time) multiprocessor architecture. The DART multiprocessor uses prioritized data-driven scheduling to ensure that multiple hard and soft deadlines are met. A data-driven checkpointing scheme has been developed that ensures that these deadlines are met even in the case of processor failures. The basic approach is to monitor the behavior of each computational thread by means of hardware timers. The results of a thread are released only if the thread completes before its given timeout period expires. Otherwise the partial computation on that processor is discarded and the thread is rescheduled on a different processor. A strategy to statically predict the system performance in the event of multiple processor failures is presented and evaluated. Simulation results are provided to illustrate the fault detection and recovery response times for single processor failures on DART multiprocessor architectures with 2, 4, 8, 16 and 32 processing elements.&lt;<ETX>&gt;</ETX>",data driven architecture,81
10.1109/nssmic.2005.1596374,filtered,"IEEE Nuclear Science Symposium Conference Record, 2005",IEEE,10/29/2005 0:00,ieeexplore,front end electronics and readout system for a gas radiator ring imaging cherenkov detector using multi-anode photomultiplier tubes,https://ieeexplore.ieee.org/document/1596374/,"We describe the design and performance of a novel custom made front end ASICs and their associated data acquisition (DAQ) system that we developed to process charge signals from an array of 53 Hamamatsu multi-anode photomultiplier tubes (MAPMTs) used as photon detectors for a ring imaging Cherenkov (RICH) detector. This system was tested as part of a gas radiator RICH prototype in the test beam facility at Fermilab. The VA MAPMT ASIC has 64 readout channels with built-in discriminator and parallel binary readout; features low noise, high dynamic range and is suitable for data driven architecture. We characterized a second iteration of this design that features higher dynamic range and optimum performance for large signals in our electronics laboratory test-setup.",data driven architecture,82
10.1109/hicss.1997.667356,filtered,Proceedings of the Thirtieth Hawaii International Conference on System Sciences,IEEE,1/10/1997 0:00,ieeexplore,graph analysis and transformation techniques for runtime minimization in multi-threaded architectures,https://ieeexplore.ieee.org/document/667356/,"Describes a method of analysis for detecting and minimizing memory latency using a directed data dependency graph produced from a compiler. These results are applicable to the development of methods for the optimal generation of instruction threads to be executed on a multi-threaded, data-driven architecture. The resulting runtime reductions are accomplished by minimizing memory access times by individual processing elements. Additionally, these analysis methods can be used to predict measures of achievable parallelism for a given program graph which can be exploited by a reconfigurable, multi-threaded architecture.",data driven architecture,83
10.1109/cbms.2018.00079,filtered,2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS),IEEE,6/21/2018 0:00,ieeexplore,implementation of a situation aware and real-time approach for decision support in online surgery scheduling,https://ieeexplore.ieee.org/document/8417274/,"For decisions on operational business level it is necessary to be aware of and to understand what happens around you and what probably will happen in the near future. E.g. in Operating Room Management, and especially in Online surgery scheduling, a lot of decisions are difficult to handle, since there are high cognitive and communicational efforts to gather all necessary information to oversee the current situation and to derive decisions based on this information. However, the emerging trend of connecting devices and new methods in data analytics, allow new approaches for decision support in these areas. By using this concepts we suggested and implemented a data-driven architecture including several components for data analysis, information generation and visualization. The presented prototype means a proof-of-concept of the idea of a real-time and situation-aware decision support system for operating room managers.",data driven architecture,84
10.1109/icsp.2018.8652415,filtered,2018 14th IEEE International Conference on Signal Processing (ICSP),IEEE,8/16/2018 0:00,ieeexplore,joint embedding with multi-task learning for multi-label zero-shot action recognition,https://ieeexplore.ieee.org/document/8652415/,"Action recognition, one of the most significant fields of computer vision, has gain great success over the past few years mainly due to the popularity of deep and data-driven architecture. However, when it comes to a real-world scenario that includes unseen actions, the previous methods which are supervised directly by labels may lead to two main problems, namely domain adaptation and laborious annotation. Therefore, we propose a novel joint space model of visual data and semantic information to address zero-shot action recognition problems. Furthermore, in order to take better advantage of semantic relationship between seen and unseen classes by word vectors, auto-encoder is introduced to our framework to narrow the semantic gap and improve the recognition accuracy. Moreover, we utilize the ε-greedy based max-pooling technique to select the most relevant visual segment from an instance according to the label. Finally, we employ multi-task learning to overall optimize classification and ranking tasks in joint latent space. We evaluate our work on a weakly annotated human action dataset Charades. The experimental results demonstrate that the proposed method significantly outperforms the state-of-the-arts in both accuracy and efficiency.",data driven architecture,85
10.1109/isit45174.2021.9517812,filtered,2021 IEEE International Symposium on Information Theory (ISIT),IEEE,7/20/2021 0:00,ieeexplore,model-inspired deep detection with low-resolution receivers,https://ieeexplore.ieee.org/document/9517812/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector network, called LoRD-Net, for signal recovering from one-bit measurements. Our approach relies on a model-aware data-driven architecture, based on a deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely ~ 500 samples, for training.",data driven architecture,86
10.1109/icc42927.2021.9500961,filtered,ICC 2021 - IEEE International Conference on Communications,IEEE,6/23/2021 0:00,ieeexplore,removing channel estimation by location-only based deep learning for ris aided mobile edge computing,https://ieeexplore.ieee.org/document/9500961/,"In this paper, we investigate a deep learning architecture for lightweight online implementation of a reconfigurable intelligent surface (RIS)-aided multi-user mobile edge computing (MEC) system, where the optimized performance can be achieved based on user equipment’s (UEs’) location-only information. Assuming that each UE is endowed with a limited energy budget, we aim at maximizing the total completed task-input bits (TCTB) of all UEs within a given time slot, through jointly optimizing the RIS reflecting coefficients, the receive beamforming vectors, and UEs’ energy partition strategies for local computing and computation offloading. Due to the coupled optimization variables, a three-step block coordinate descending (BCD) algorithm is first proposed to effectively solve the formulated TCTB maximization problem iteratively with guaranteed convergence. The location-only deep learning architecture is then constructed to emulate the proposed BCD optimization algorithm, through which the pilot channel estimation and feedback can be removed for online implementation with low complexity. The simulation results reveal a close match between the performance of the BCD optimization algorithm and the location-only data-driven architecture, all with superior performance to existing benchmarks.",data driven architecture,87
10.23919/ccc50068.2020.9188717,filtered,2020 39th Chinese Control Conference (CCC),IEEE,7/29/2020 0:00,ieeexplore,wind turbine frequent principal fault detection based on a self-attentive lstm encoder-decoder model,https://ieeexplore.ieee.org/document/9188717/,"With the development of intelligent monitoring technology, internet information technology, and data storage technology, data-driven fault detection and diagnosis method in the wind turbine system has become a focus of research in recent years. In this paper, we design a data-driven architecture for the wind turbine frequent principal fault detection. Considering the sequential relationship in the wind power data, we introduce the long short-term memory (LSTM) model. Additionally, to retain more necessary information hidden in the wind power time series, which is too long to make the performance of the LSTM model poor, we propose a novel self-attentive LSTM encoder-decoder(SALSTMED) model to learn the high-level feature sequence other than the feature vector. Further, the dataset collected from a real wind farm is employed to verify the performance of the proposed approach. The results indicate that the proposed approach is effective for the wind turbine frequent principal fault detection.",data driven architecture,88
10.1109/30.982782,filtered,IEEE Transactions on Consumer Electronics,IEEE,11/1/2001 0:00,ieeexplore,a novel hdtv video decoder and decentralized control scheme,https://ieeexplore.ieee.org/document/982782/,"A novel dedicated architecture for an HDTV video decoding chip is developed. Each task is mapped to a highly optimized hardware unit by classifying the video processing tasks into three levels. On the function level, a data driven architecture is adopted to make each processing unit operate once the processing data and buffer are available. Therefore the high computing efficiency of each unit is exploited, hardware is saved, and the computing capability is maximized compared with conventional pipeline decoder. On the system level, a decentralized control scheme is designed to provide high efficient communication between all the processing units to yield the best overall performance. Moreover it features simple control logic and minimum size of the connecting buffers.",data driven architecture,89
10.1109/tns.2006.870173,filtered,IEEE Transactions on Nuclear Science,IEEE,2/1/2006 0:00,ieeexplore,design and evaluation of the clear-pem scanner for positron emission mammography,https://ieeexplore.ieee.org/document/1610954/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities, and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with dimensions 16.5/spl times/14.5 cm/sup 2/ for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,90
10.1109/access.2021.3071274,filtered,IEEE Access,IEEE,1/1/2021 0:00,ieeexplore,graph neural network: a comprehensive review on non-euclidean space,https://ieeexplore.ieee.org/document/9395439/,"This review provides a comprehensive overview of the state-of-the-art methods of graph-based networks from a deep learning perspective. Graph networks provide a generalized form to exploit non-euclidean space data. A graph can be visualized as an aggregation of nodes and edges without having any order. Data-driven architecture tends to follow a fixed neural network trying to find the pattern in feature space. These strategies have successfully been applied to many applications for euclidean space data. Since graph data in a non-euclidean space does not follow any kind of order, these solutions can be applied to exploit the node relationships. Graph Neural Networks (GNNs) solve this problem by exploiting the relationships among graph data. Recent developments in computational hardware and optimization allow graph networks possible to learn the complex graph relationships. Graph networks are therefore being actively used to solve many problems including protein interface, classification, and learning representations of fingerprints. To encapsulate the importance of graph models, in this paper, we formulate a systematic categorization of GNN models according to their applications from theory to real-life problems and provide a direction of the future scope for the applications of graph models as well as highlight the limitations of existing graph networks.",data driven architecture,91
10.1109/tsp.2021.3117503,filtered,IEEE Transactions on Signal Processing,IEEE,1/1/2021 0:00,ieeexplore,lord-net: unfolded deep detection network with low-resolution receivers,https://ieeexplore.ieee.org/document/9557819/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector entitled LoRD-Net for recovering information symbols from one-bit measurements. Our method is a model-aware data-driven architecture based on deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. LoRD-Net operates in a blind fashion, which requires addressing both the non-linear nature of the data-acquisition system as well as identifying a proper optimization objective for signal recovery. Accordingly, we propose a two-stage training method for LoRD-Net, in which the first stage is dedicated to identifying the proper form of the optimization process to unfold, while the latter trains the resulting model in an end-to-end manner. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely <inline-formula><tex-math notation=""LaTeX"">$\sim 500$</tex-math></inline-formula> samples, for training.",data driven architecture,92
10.1109/access.2021.3091716,filtered,IEEE Access,IEEE,1/1/2021 0:00,ieeexplore,modeling and key technologies of a data-driven smart city system,https://ieeexplore.ieee.org/document/9462829/,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a `two-dimension, three-layer, and six-goal' top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated.",data driven architecture,93
10.1109/tkde.2019.2953839,filtered,IEEE Transactions on Knowledge and Data Engineering,IEEE,6/1/2021 0:00,ieeexplore,open relation extraction for chinese noun phrases,https://ieeexplore.ieee.org/document/8903488/,"Relation Extraction (RE) aims at harvesting relational facts from texts. A majority of existing research targets at knowledge acquisition from sentences, where subject-verb-object structures are usually treated as the signals of existence of relations. In contrast, relational facts expressed within noun phrases are highly implicit. Previous works mostly relies on human-compiled assertions and textual patterns in English to address noun phrase-based RE. For Chinese, the corresponding task is non-trivial because Chinese is a highly analytic language with flexible expressions. Additionally, noun phrases tend to be incomplete in grammatical structures, where clear mentions of predicates are often missing. In this article, we present an unsupervised Noun Phrase-based Open RE system for the Chinese language (NPORE), which employs a three-layer data-driven architecture. The system contains three components, i.e., Modifier-sensitive Phrase Segmenter, Candidate Relation Generator and Missing Relation Predicate Detector. It integrates with a graph clique mining algorithm to chunk Chinese noun phrases, considering how relations are expressed. We further propose a probabilistic method with knowledge priors and a hypergraph-based random walk process to detect missing relation predicates. Experiments over Chinese Wikipedia show NPORE outperforms state-of-the-art, capable of extracting 55.2 percent more relations than the most competitive baseline, with a comparable precision at 95.4 percent.",data driven architecture,94
10.1109/acc.2013.6580528,filtered,2013 American Control Conference,IEEE,6/19/2013 0:00,ieeexplore,data-driven design of kpi-related fault-tolerant control system for wind turbines,https://ieeexplore.ieee.org/document/6580528/,"In this paper, a scheme for an integrated design of fault-tolerant control (FTC) systems for a wind turbine benchmark is proposed, with focus on the overall performance of the system. For that a key performance indicator (KPI) which reflects the economic performance of the system is defined, and the objective of the proposed FTC scheme is to maintain the system KPI in the admissible range in faulty conditions. The basic idea behind this scheme is data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilizing controllers with an embedded residual generator for fault detection (FD) purpose. The performance and effectiveness of the proposed scheme are demonstrated through the wind turbine benchmark model proposed in [1].",data driven architecture,95
10.23919/acc50511.2021.9482806,filtered,2021 American Control Conference (ACC),IEEE,5/28/2021 0:00,ieeexplore,direct data-driven design of switching controllers for constrained systems,https://ieeexplore.ieee.org/document/9482806/,"This paper presents a hierarchical structure to directly design controllers for (possibly nonlinear) constrained systems. The proposed architecture combines the advantages of an inner data-driven switching controller designed to achieve a predefined closed-loop behavior and an outer model predictive controller, which is used as a reference governor. These design choices enable us to avoid the identification step typical of model-based approaches while exploiting the ability of model predictive controllers to handle constraints and optimize the closed-loop performance. As a proof of concept, a benchmark simulation example is used to demonstrate the effectiveness of the proposed strategy.",data driven architecture,96
10.1109/tii.2018.2843124,filtered,IEEE Transactions on Industrial Informatics,IEEE,10/1/2018 0:00,ieeexplore,data-driven design of fog-computing-aided process monitoring system for large-scale industrial processes,https://ieeexplore.ieee.org/document/8370742/,"Stimulated by the recent development of fog computing technology, in this paper, a fog-computing-aided process monitoring and control architecture is proposed for large-scale industrial processes, which enables reliable and efficient online performance optimization in each fog computing node without modifying predesigned control subsystems. Moreover, a closed-loop data-driven method is developed for the process monitoring system design and an adaptive configuration approach is proposed to deal with the problems caused by the changes of process parameters and operating points. The feasibility and effectiveness of the proposed design approaches are verified and demonstrated through the case study on the Tennessee Eastman benchmark system.",data driven architecture,97
10.1109/spawc51858.2021.9593131,filtered,2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),IEEE,9/30/2021 0:00,ieeexplore,fast power control adaptation via meta-learning for random edge graph neural networks,https://ieeexplore.ieee.org/document/9593131/,"Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,98
10.1109/cca.2015.7320615,filtered,2015 IEEE Conference on Control Applications (CCA),IEEE,9/23/2015 0:00,ieeexplore,fictitious reference iterative tuning of internal model controllers for a class of nonlinear systems,https://ieeexplore.ieee.org/document/7320615/,"This paper presents a direct data-driven design or tuning of the internal model control architecture for a class of non-linear systems to achieve the desired output. We assume that the structure of a nonlinear system addressed here is known and the parameters are unknown. In addition, a nonlinear system addressed here is assumed to be with the property that the input time series and the output time series has one to one relation. For this type of nonlinear system, the internal model controller that is represented by the parameters of a model is introduced. Then, fictitious reference iterative tuning, which is one of the data-driven controller tuning methods based on the direct use of one-shot experimental data, is extended for tuning the parameterized internal model controllers. It is also shown that the cost function to be minimized in fictitious reference iterative tuning is related to both of the achievement of the desired tracking and the attainment of a model. That is, the proposed method in this paper enables us to simultaneously obtain a model and a controller by applying only one-shot experimental data to the parameterized internal model controller. A numerical example is also illustrated to show the validity of the result.",data driven architecture,99
10.1109/access.2021.3123348,filtered,IEEE Access,IEEE,1/1/2021 0:00,ieeexplore,an authoritative source of truth system for ucav conceptual design,https://ieeexplore.ieee.org/document/9590556/,"Model-Based Systems Engineering (MBSE) is a part of a long-term trend toward model-centric approaches. The Authoritative Source of Truth (AST) is a crucial step of digital transformation and a core component of MBSE. Benefits include help design teams shorten the design cycle, improve design efficiency, and ensure the accuracy of design models and data compared to traditional document-based co-design methods. Data-driven design is a new direction of Unmanned Combat Aerial Vehicles (UCAV) design, and UCAV is the main force of future air warfare. How to build a UCAV conceptual design AST system is a problem that needs to be solved. We design an AST construction methodology, develop an AST system by applying the methodology, and use the UCAV concept design case to test the usability of the AST system. More specifically, the methodology includes construction goals and objects, basic construction methods, AST architecture, collaborative construction methods, dynamic management methods, basic functions and derivative tools required. In addition, the validation process is requirement analysis, functional architecture design, scheme design, and dynamic management validation. The AST system can help the implementation of MBSE in the field of aircraft design. The AST system can also help meet the requirements of the conceptual design stage, which shows the feasibility of the construction methodology’s integrity. If the AST system is used in the aircraft’s detailed design phase, further models and data will be required, and the AST system will need to be upgraded.",data driven architecture,100
10.1109/tpel.2020.3043741,filtered,IEEE Transactions on Power Electronics,IEEE,7/1/2021 0:00,ieeexplore,enhanced fault diagnosis using broad learning for traction systems in high-speed trains,https://ieeexplore.ieee.org/document/9290131/,"Faults happen inevitably in traction systems and thus place the security of the whole high-speed train at risk. In order to improve the safety and reliability of high-speed trains, this article deals with fault detection and diagnosis (FDD) problem for traction systems. Because of high sampling frequency of equipped sensors, FDD strategies in the supervision system of high-speed trains should be of enough high computation efficiency, which is a great bottleneck for artificial intelligence-based FDD methods. For reducing the computational load while maintaining the satisfactory diagnostic accuracy, an enhanced FDD architecture using the modified principal component analysis and broad learning system is developed in this article. Based on the proposed data-driven design whose core is to extract fault information, fast and accurate FDD can be achieved without requirements for mathematical models or control mechanism of high-speed trains. The effectiveness and feasibility of the proposed online design are illustrated on the traction control platform of high-speed trains.",data driven architecture,101
10.1109/tie.2013.2273477,filtered,IEEE Transactions on Industrial Electronics,IEEE,5/1/2014 0:00,ieeexplore,real-time implementation of fault-tolerant control systems with performance optimization,https://ieeexplore.ieee.org/document/6560360/,"In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.",data driven architecture,102
10.1007/978-3-030-87571-8_64,filtered,Web Information Systems and Applications,Springer,1/1/2021 0:00,springer,a big data driven design method of helicopter health management system,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87571-8_64,"This article briefly describes the development process of aircraft health management, and discusses the basic principles of helicopter health and use monitoring systems. Then proposed a big data-driven helicopter health management system architecture, analyzed the relationship between the components of the helicopter health management system, and analyzed the sources of the helicopter health management big data, and finally proposed Big data and knowledge-driven helicopter health management system Program. This paper explores the design method of the helicopter health management system driven by big data, and reserves the theoretical basis for the practical research of the future system.",data driven architecture,103
10.1007/s10845-018-1430-y,filtered,Journal of Intelligent Manufacturing,Springer,1/1/2020 0:00,springer,"a data-driven cyber-physical approach for personalised smart, connected product co-development in a cloud-based environment",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-018-1430-y,"The rapid development of information and communication technology enables a promising market of information densely product, i.e. smart, connected product (SCP), and also changes the way of user–designer interaction in the product development process. For SCP, massive data generated by users drives its design innovation and somehow determines its final success. Nevertheless, most existing works only look at the new functionalities or values that are derived in the one-way communication by introducing novel data analytics methods. Few work discusses about an effective and systematic approach to enable individual user innovation in such context, i.e. co-development process, which sets the fundamental basis of the prevailing concept of data-driven design. Aiming to fill this gap, this paper proposes a generic data-driven cyber-physical approach for personalised SCP co-development in a cloud-based environment. A novel concept of smart, connected, open architecture product is hence introduced with a generic cyber-physical model established in a cloud-based environment, of which the interaction processes are enabled by co-development toolkits with smartness and connectedness. Both the personalized SCP modelling method and the establishment of its cyber-physical product model are described in details. To further demonstrate the proposed approach, a case study of a smart wearable device (i.e. i-BRE respiratory mask) development process is given with general discussions.",data driven architecture,104
10.1007/978-981-10-6611-5_37,filtered,Humanizing Digital Reality,Springer,1/1/2018 0:00,springer,navigating the intangible spatial-data-driven design modelling in architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-6611-5_37,"Over the past few decades, digital technologies have played an increasingly substantial role in how we relate to our environment. Through mobile devices, sensors, big data and ubiquitous computing amongst other technologies, our physical surroundings can be augmented with intangible data, suggesting that architects of the future could start to view the increasingly digitally saturated world around them as an information-rich environment (McCullough in Ambient commons: attention in the age of embodied information, The MIT Press, Cambridge, 2013 ). The adoption of computational design and digital fabrication processes in has given architects and designers the opportunity to design and fabricate architecture with unseen material performance and precision. However, attempts to combine these tools with methods for navigating and integrating the vast amount of available data into the design process have appeared slow and complicated. This research proposes a method for data capture and visualization which, despite its infancy, displays potentials for use in projects ranging in scale from the urban to the interior evaluation of existing buildings. The working research question is as follows: “How can we develop a near real-time data capture and visualization method, which can be used across multiple scales in various architectural design processes?”",data driven architecture,105
10.1007/978-3-319-75429-1_18,filtered,Integrated Uncertainty in Knowledge Modelling and Decision Making,Springer,1/1/2018 0:00,springer,big data driven architecture for medical knowledge management systems in intracranial hemorrhage diagnosis,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75429-1_18,"Stroke is the most common and dangerous cerebrovascular disease. According to the statistics from World Health Organization (WHO), only following heart attack, stroke is one of the two leading causes of human deaths. In addition, in Vietnam, a shortage of specialized equipment and qualified professionals is becoming a significant problem for not only accurate diagnosis but also timely and effective treatment of stroke, especially intracranial hemorrhage (ICH), an acute case of stroke. This research will analyze challenges and show solutions for constructing an effective knowledge system in ICH diagnosis and treatment that helps to shorten professional gap among hospitals and regions. We suggest a service-oriented architecture for the big data driven knowledge system based on medical imaging of ICH. The architecture ensures the development of knowledge obeying a systematic and complete process including the exploration and exploitation of knowledge from medical imaging. Besides, the architecture adapts to modern trends in knowledge service modeling.",data driven architecture,106
10.1007/978-3-319-07863-2_21,filtered,Human Interface and the Management of Information. Information and Knowledge in Applications and Services,Springer,1/1/2014 0:00,springer,data driven enterprise ux: a case study of enterprise management systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07863-2_21,"This paper describes and makes a case for a data driven user experience design process for Enterprise IT. The method described employs an approach that focuses on defining the key modules (objects) in an enterprise IT software and the data sets used by these modules very early in the design process. We discuss how mapping parent child relationships between key entities in the software and the linked data helps create a holistic view of the product ecosystem which in turn allows the designer to create an uncluttered information architecture and user journey that maps closely to mental construct of the system in the user’s mind. We further argue that in the present age of big data, working with well-defined data sets and visible data relationships creates a valuable information repository for the designer to take decisions regarding task optimization and building business intelligence in the system itself. We also discuss the urgent need, advantages and methods of ‘consumerizing’ the Enterprise UI to increase users productivity and reduce the learning curve. Lastly, these ideas are exemplified through a real life case study for an enterprise server management system.",data driven architecture,107
10.1007/978-1-4471-6410-4_14,filtered,Data-driven Design of Fault Diagnosis and Fault-tolerant Control Systems,Springer,1/1/2014 0:00,springer,data-driven design of observer-based control systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4471-6410-4_14,"In the previous chapter, we have introduced the fault-tolerant architecture and the associated design parameters. In this chapter, we focus on the data-driven design of the state feedback gain matrix, an H-PRIO parameter of the fault-tolerant architecture, and its application to the observer-based control schemes.",data driven architecture,108
10.1007/978-3-642-39200-9_5,filtered,Web Engineering,Springer,1/1/2013 0:00,springer,semantic data driven interfaces for web applications,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39200-9_5,"Modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. These conditions require interfaces that can adapt to the changes in the <user, platform, environment> triad. The Model-Based User Interface approach has been proposed as a way to deal with these requirements. In this paper we present a data-driven, rule-based interface definition model capable of taking into account the semantics of the data it is manipulating, especially in the case of Linked Data. An implementation architecture based on the Synth environment supporting this model is presented.",data driven architecture,109
10.1007/978-3-642-23333-3_4,filtered,Electronic Participation,Springer,1/1/2011 0:00,springer,combining social and government open data for participatory decision-making,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23333-3_4,"In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making.",data driven architecture,110
10.1007/978-3-642-04492-2_21,filtered,Management Enabling the Future Internet for Changing Business and New Computing Services,Springer,1/1/2009 0:00,springer,the proposal of service delivery platform built on distributed data driven architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04492-2_21,"SDP (Service Delivery Platform) is a recommended system platform for NGN (Next Generation Network) that is expected to resolve two common system running problems: one is functional aspects such as high availability and providing effective maintenance methods, the other is cost aspects such as simplifying development method of a service. However, SDP is still on the way to be standardized, and its architecture has two problems: the congestion of service requests and flexibility of enabler, a service component of SDP. This paper explains how to build a SDP by adopting Distributed Data Driven Architecture and how our system resolves the problems by evaluating the prototype.",data driven architecture,111
10.1007/978-3-540-30117-2_119,filtered,Field Programmable Logic and Application,Springer,1/1/2004 0:00,springer,an environment for exploring data-driven architectures,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-30117-2_119,"A wide range of reconfigurable coarse-grain architectures has been proposed in recent years, for an extensive set of applications. These architectures vary widely in the interconnectivity, number, granularity and complexity of the processing elements (PEs). The performance of a specific application usually depends heavily on the adequacy of the PEs to the particular tasks involved, but tools to efficiently experiment architectural features are lacking. This work proposes an environment for exploration and simulation of coarse-grain reconfigurable data-driven architectures. The proposed environment takes advantage of Java and XML technologies to enable a very efficient backend for experiments with different architectural trade-offs, from the array connectivity and topology to the granularity and complexity of each PE. For a proof of concept, we show results on implementing different versions of a FIR filter on a hexagonal data-driven array.",data driven architecture,112
10.1007/978-94-015-8196-7_6,filtered,Linear Algebra for Large Scale and Real-Time Applications,Springer,1/1/1993 0:00,springer,a parallel image rendering algorithm and architecture based on ray tracing and radiosity shading,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-015-8196-7_6,"Algorithms for rendering color scenes on a video screen potentially belong to the class of massively parallel algorithms. Developing effective and efficient data-driven architectures for algorithms from this class is in general a hard problem. However, in case of application specific algorithms, such as the rendering algorithm described in this paper, feasible solutions are conceivable. The parallel algorithm/architecture presented in this paper is a linear speed-up accelerator for the rendering of photo realistic scenes in interaction time.",data driven architecture,113
10.1007/3-540-53065-7_86,filtered,CONPAR 90 — VAPP IV,Springer,1/1/1990 0:00,springer,a decoupled data-driven architecture with vectors and macro actors,http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-53065-7_86,"This paper presents the implementation of scientific programs on a decoupled data-driven architecture with vectors and macro actors. This hybrid multiprocessor combines the dynamic data-flow principles of execution with the control-flow of the von Neumann model of execution. The two major ideas utilized by the decoupled model are: vector and macro actors with variable resolution, and asynchronous execution of graph and computation operations. The compiler generates graphs with various-sized actors in order to match the characteristics of the computation. For instance, vector actors are proposed for many aspects of scientific computing while lower resolution (complier-generated collection of scalar actors) or higher resolution (scalar actors) is used for unvectorizable programs. A block-scheduling technique for extracting more parallelism from sequential constructs is incorporated in the decoupled architecture. In addition a graph-level priority-scheduling mechanism is implemented that improves resource utilization and yields higher performance. A graph unit executes all graph operations and a computation unit executes all computation operations. The independence of the two main units of the machine allows the efficient pipelined execution of macro actors with diverse granularity characteristics.",data driven architecture,114
http://arxiv.org/abs/2202.10565v1,filtered,arxiv,arxiv,2/21/2022 0:00,arxiv,"t-metaset: task-aware generation of metamaterial datasets by
  diversity-based active learning",http://arxiv.org/abs/2202.10565v1,"Inspired by the recent success of deep learning in diverse domains,
data-driven metamaterials design has emerged as a compelling design paradigm to
unlock the potential of multiscale architecture. However, existing
model-centric approaches lack principled methodologies dedicated to
high-quality data generation. Resorting to space-filling design in shape
descriptor space, existing metamaterial datasets suffer from property
distributions that are either highly imbalanced or at odds with design tasks of
interest. To this end, we propose t-METASET: an intelligent data acquisition
framework for task-aware dataset generation. We seek a solution to a
commonplace yet frequently overlooked scenario at early design stages: when a
massive ($~\sim O(10^4)$) shape library has been prepared with no properties
evaluated. The key idea is to exploit a data-driven shape descriptor learned
from generative models, fit a sparse regressor as the start-up agent, and
leverage diversity-related metrics to drive data acquisition to areas that help
designers fulfill design goals. We validate the proposed framework in three
hypothetical deployment scenarios, which encompass general use, task-aware use,
and tailorable use. Two large-scale shape-only mechanical metamaterial datasets
are used as test datasets. The results demonstrate that t-METASET can
incrementally grow task-aware datasets. Applicable to general design
representations, t-METASET can boost future advancements of not only
metamaterials but data-driven design in other domains.",data driven architecture,115
http://arxiv.org/abs/2202.07448v1,filtered,arxiv,arxiv,2/4/2022 0:00,arxiv,"towards a unified pandemic management architecture: survey, challenges
  and future directions",http://arxiv.org/abs/2202.07448v1,"The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,
economy and society worldwide. Emerging strains are making pandemic management
increasingly challenging. There is an urge to collect epidemiological,
clinical, and physiological data to make an informed decision on mitigation
measures. Advances in the Internet of Things (IoT) and edge computing provide
solutions for pandemic management through data collection and intelligent
computation. While existing data-driven architectures attempt to automate
decision-making, they do not capture the multifaceted interaction among
computational models, communication infrastructure, and the generated data. In
this paper, we perform a survey of the existing approaches for pandemic
management, including online data repositories and contact-tracing
applications. We then envision a unified pandemic management architecture that
leverages the IoT and edge computing to automate recommendations on vaccine
distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We
elucidate the flow of data among the layers of the architecture, namely, cloud,
edge and end device layers. Moreover, we address the privacy implications,
threats, regulations, and existing solutions that may be adapted to optimize
the utility of health data with security guarantees. The paper ends with a
lowdown on the limitations of the architecture and research directions to
enhance its practicality.",data driven architecture,116
http://arxiv.org/abs/2110.09005v1,filtered,arxiv,arxiv,10/18/2021 0:00,arxiv,unsupervised learned kalman filtering,http://arxiv.org/abs/2110.09005v1,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.",data driven architecture,117
http://arxiv.org/abs/2108.13178v1,filtered,arxiv,arxiv,8/4/2021 0:00,arxiv,"black-box and modular meta-learning for power control via random edge
  graph neural networks",http://arxiv.org/abs/2108.13178v1,"In this paper, we consider the problem of power control for a wireless
network with an arbitrarily time-varying topology, including the possible
addition or removal of nodes. A data-driven design methodology that leverages
graph neural networks (GNNs) is adopted in order to efficiently parametrize the
power control policy mapping the channel state information (CSI) to transmit
powers. The specific GNN architecture, known as random edge GNN (REGNN),
defines a non-linear graph convolutional filter whose spatial weights are tied
to the channel coefficients. While prior work assumed a joint training approach
whereby the REGNN-based policy is shared across all topologies, this paper
targets adaptation of the power control policy based on limited CSI data
regarding the current topology. To this end, we propose both black-box and
modular meta-learning techniques. Black-box meta-learning optimizes a
general-purpose adaptation procedure via (stochastic) gradient descent, while
modular meta-learning finds a set of reusable modules that can form components
of a solution for any new network topology. Numerical results validate the
benefits of meta-learning for power control problems over joint training
schemes, and demonstrate the advantages of modular meta-learning when data
availability is extremely limited.",data driven architecture,118
http://arxiv.org/abs/2106.15356v2,filtered,arxiv,arxiv,6/26/2021 0:00,arxiv,"scalable gaussian processes for data-driven design using big data with
  categorical factors",http://arxiv.org/abs/2106.15356v2,"Scientific and engineering problems often require the use of artificial
intelligence to aid understanding and the search for promising designs. While
Gaussian processes (GP) stand out as easy-to-use and interpretable learners,
they have difficulties in accommodating big datasets, categorical inputs, and
multiple responses, which has become a common challenge for a growing number of
data-driven design applications. In this paper, we propose a GP model that
utilizes latent variables and functions obtained through variational inference
to address the aforementioned challenges simultaneously. The method is built
upon the latent variable Gaussian process (LVGP) model where categorical
factors are mapped into a continuous latent space to enable GP modeling of
mixed-variable datasets. By extending variational inference to LVGP models, the
large training dataset is replaced by a small set of inducing points to address
the scalability issue. Output response vectors are represented by a linear
combination of independent latent functions, forming a flexible kernel
structure to handle multiple responses that might have distinct behaviors.
Comparative studies demonstrate that the proposed method scales well for large
datasets with over 10^4 data points, while outperforming state-of-the-art
machine learning methods without requiring much hyperparameter tuning. In
addition, an interpretable latent space is obtained to draw insights into the
effect of categorical factors, such as those associated with building blocks of
architectures and element choices in metamaterial and materials design. Our
approach is demonstrated for machine learning of ternary oxide materials and
topology optimization of a multiscale compliant mechanism with aperiodic
microstructures and multiple materials.",data driven architecture,119
http://arxiv.org/abs/2105.00459v1,filtered,arxiv,arxiv,5/2/2021 0:00,arxiv,"fast power control adaptation via meta-learning for random edge graph
  neural networks",http://arxiv.org/abs/2105.00459v1,"Power control in decentralized wireless networks poses a complex stochastic
optimization problem when formulated as the maximization of the average sum
rate for arbitrary interference graphs. Recent work has introduced data-driven
design methods that leverage graph neural network (GNN) to efficiently
parametrize the power control policy mapping channel state information (CSI) to
the power vector. The specific GNN architecture, known as random edge GNN
(REGNN), defines a non-linear graph convolutional architecture whose spatial
weights are tied to the channel coefficients, enabling a direct adaption to
channel conditions. This paper studies the higher-level problem of enabling
fast adaption of the power control policy to time-varying topologies. To this
end, we apply first-order meta-learning on data from multiple topologies with
the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,120
http://arxiv.org/abs/2008.00442v2,filtered,arxiv,arxiv,8/2/2020 0:00,arxiv,"identifying the elastic isotropy of architectured materials based on
  deep learning method",http://arxiv.org/abs/2008.00442v2,"With the achievement on the additive manufacturing, the mechanical properties
of architectured materials can be precisely designed by tailoring
microstructures. As one of the primary design objectives, the elastic isotropy
is of great significance for many engineering applications. However, the
prevailing experimental and numerical methods are normally too costly and
time-consuming to determine the elastic isotropy of architectured materials
with tens of thousands of possible microstructures in design space. The quick
mechanical characterization is thus desired for the advanced design of
architectured materials. Here, a deep learning-based approach is developed as a
portable and efficient tool to identify the elastic isotropy of architectured
materials directly from the images of their representative microstructures with
arbitrary component distributions. The measure of elastic isotropy for
architectured materials is derived firstly in this paper to construct a
database with associated images of microstructures. Then a convolutional neural
network is trained with the database. It is found that the convolutional neural
network shows good performance on the isotropy identification. Meanwhile, it
exhibits enough robustness to maintain the performance under fluctuated
material properties in practical fabrications. Moreover, the well-trained
convolutional neural network can be successfully transferred among different
types of architectured materials, including two-phase composites and porous
materials, which greatly enhance the efficiency of the deep learning-based
approach. This study can give new inspirations on the fast mechanical
characterization for the big-data driven design of architectured materials.",data driven architecture,121
http://arxiv.org/abs/1910.06115v1,filtered,arxiv,arxiv,10/11/2019 0:00,arxiv,"microservices based linked data quality model for buildings energy
  management services",http://arxiv.org/abs/1910.06115v1,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality.",data driven architecture,122
http://arxiv.org/abs/1909.10819v2,filtered,arxiv,arxiv,9/24/2019 0:00,arxiv,"investigating customization strategies and convergence behaviors of
  task-specific admm",http://arxiv.org/abs/1909.10819v2,"Alternating Direction Method of Multiplier (ADMM) has been a popular
algorithmic framework for separable optimization problems with linear
constraints. For numerical ADMM fail to exploit the particular structure of the
problem at hand nor the input data information, leveraging task-specific
modules (e.g., neural networks and other data-driven architectures) to extend
ADMM is a significant but challenging task. This work focuses on designing a
flexible algorithmic framework to incorporate various task-specific modules
(with no additional constraints) to improve the performance of ADMM in
real-world applications. Specifically, we propose Guidance from Optimality
(GO), a new customization strategy, to embed task-specific modules into ADMM
(GO-ADMM). By introducing an optimality-based criterion to guide the
propagation, GO-ADMM establishes an updating scheme agnostic to the choice of
additional modules. The existing task-specific methods just plug their
task-specific modules into the numerical iterations in a straightforward
manner. Even with some restrictive constraints on the plug-in modules, they can
only obtain some relatively weaker convergence properties for the resulted ADMM
iterations. Fortunately, without any restrictions on the embedded modules, we
prove the convergence of GO-ADMM regarding objective values and constraint
violations, and derive the worst-case convergence rate measured by iteration
complexity. Extensive experiments are conducted to verify the theoretical
results and demonstrate the efficiency of GO-ADMM.",data driven architecture,123
http://arxiv.org/abs/1905.06179v1,filtered,arxiv,arxiv,5/15/2019 0:00,arxiv,differentiable linearized admm,http://arxiv.org/abs/1905.06179v1,"Recently, a number of learning-based optimization methods that combine
data-driven architectures with the classical optimization algorithms have been
proposed and explored, showing superior empirical performance in solving
various ill-posed inverse problems, but there is still a scarcity of rigorous
analysis about the convergence behaviors of learning-based optimization. In
particular, most existing analyses are specific to unconstrained problems but
cannot apply to the more general cases where some variables of interest are
subject to certain constraints. In this paper, we propose Differentiable
Linearized ADMM (D-LADMM) for solving the problems with linear constraints.
Specifically, D-LADMM is a K-layer LADMM inspired deep neural network, which is
obtained by firstly introducing some learnable weights in the classical
Linearized ADMM algorithm and then generalizing the proximal operator to some
learnable activation function. Notably, we rigorously prove that there exist a
set of learnable parameters for D-LADMM to generate globally converged
solutions, and we show that those desired parameters can be attained by
training D-LADMM in a proper way. To the best of our knowledge, we are the
first to provide the convergence analysis for the learning-based optimization
method on constrained problems.",data driven architecture,124
http://arxiv.org/abs/1811.03782v3,filtered,arxiv,arxiv,11/9/2018 0:00,arxiv,"a theoretically guaranteed deep optimization framework for robust
  compressive sensing mri",http://arxiv.org/abs/1811.03782v3,"Magnetic Resonance Imaging (MRI) is one of the most dynamic and safe imaging
techniques available for clinical applications. However, the rather slow speed
of MRI acquisitions limits the patient throughput and potential indi cations.
Compressive Sensing (CS) has proven to be an efficient technique for
accelerating MRI acquisition. The most widely used CS-MRI model, founded on the
premise of reconstructing an image from an incompletely filled k-space, leads
to an ill-posed inverse problem. In the past years, lots of efforts have been
made to efficiently optimize the CS-MRI model. Inspired by deep learning
techniques, some preliminary works have tried to incorporate deep architectures
into CS-MRI process. Unfortunately, the convergence issues (due to the
experience-based networks) and the robustness (i.e., lack real-world noise
modeling) of these deeply trained optimization methods are still missing. In
this work, we develop a new paradigm to integrate designed numerical solvers
and the data-driven architectures for CS-MRI. By introducing an optimal
condition checking mechanism, we can successfully prove the convergence of our
established deep CS-MRI optimization scheme. Furthermore, we explicitly
formulate the Rician noise distributions within our framework and obtain an
extended CS-MRI network to handle the real-world nosies in the MRI process.
Extensive experimental results verify that the proposed paradigm outperforms
the existing state-of-the-art techniques both in reconstruction accuracy and
efficiency as well as robustness to noises in real scene.",data driven architecture,125
http://arxiv.org/abs/1808.07647v4,filtered,arxiv,arxiv,8/23/2018 0:00,arxiv,"machine learning at the edge: a data-driven architecture with
  applications to 5g cellular networks",http://arxiv.org/abs/1808.07647v4,"The fifth generation of cellular networks (5G) will rely on edge cloud
deployments to satisfy the ultra-low latency demand of future applications. In
this paper, we argue that such deployments can also be used to enable advanced
data-driven and Machine Learning (ML) applications in mobile networks. We
propose an edge-controller-based architecture for cellular networks and
evaluate its performance with real data from hundreds of base stations of a
major U.S. operator. In this regard, we will provide insights on how to
dynamically cluster and associate base stations and controllers, according to
the global mobility patterns of the users. Then, we will describe how the
controllers can be used to run ML algorithms to predict the number of users in
each base station, and a use case in which these predictions are exploited by a
higher-layer application to route vehicular traffic according to network Key
Performance Indicators (KPIs). We show that the prediction accuracy improves
when based on machine learning algorithms that rely on the controllers' view
and, consequently, on the spatial correlation introduced by the user mobility,
with respect to when the prediction is based only on the local data of each
single base station.",data driven architecture,126
http://arxiv.org/abs/1807.06699v5,filtered,arxiv,arxiv,7/17/2018 0:00,arxiv,adaptive neural trees,http://arxiv.org/abs/1807.06699v5,"Deep neural networks and decision trees operate on largely separate
paradigms; typically, the former performs representation learning with
pre-specified architectures, while the latter is characterised by learning
hierarchies over pre-specified features with data-driven architectures. We
unite the two via adaptive neural trees (ANTs) that incorporates representation
learning into edges, routing functions and leaf nodes of a decision tree, along
with a backpropagation-based training algorithm that adaptively grows the
architecture from primitive modules (e.g., convolutional layers). We
demonstrate that, whilst achieving competitive performance on classification
and regression datasets, ANTs benefit from (i) lightweight inference via
conditional computation, (ii) hierarchical separation of features useful to the
task e.g. learning meaningful class associations, such as separating natural
vs. man-made objects, and (iii) a mechanism to adapt the architecture to the
size and complexity of the training dataset.",data driven architecture,127
http://arxiv.org/abs/hep-ex/9902015v1,filtered,arxiv,arxiv,2/10/1999 0:00,arxiv,"a 16-channel digital tdc chip with internal buffering and selective
  readout for the dirc cherenkov counter of the babar experiment",http://arxiv.org/abs/hep-ex/9902015v1,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter
of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is
0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven
architecture integrates channel buffering and selective readout of data falling
within a programmable time window. The time measuring scale is constantly
locked to the phase of the (external) clock. The linearity is better than 80 ps
rms. The dead time loss is less than 0.1% for incoherent random input at a rate
of 100 khz on each channel. At such a rate the power dissipation is less than
100 mw. The die size is 36 mm2.",data driven architecture,128
10.14627/537690036,filtered,core,Wichmann Verlag im VDE Verlag GmbH,1/1/2020 0:00,core,bridging tangible and virtual realities : computational procedures for data-informed participatory processes,,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe",data driven architecture,129
10.22260/isarc2020/0010,filtered,core,'International Association for Automation and Robotics in Construction (IAARC)',1/1/2020 0:00,core,towards circular economy in architecture by means of data-driven design-to- robotic-production,,"While the global impact of plastic waste is increasingly concerning, the application of reused materials in the built environment remains little explored. This paper presents research into the reuse of plastic in architecture by means of computational design and robotic fabrication. Design possibilities using reclaimed plastic artefacts were explored by testing their structural stability and robotically modifying them in order to create a pavilion. While the design conceptualization started with the reclaimed material and the analysis of its potential, the digital workflow involved generative and performance- driven design, structural optimization and geometry generation for robotic fabrication.Architectural Engineerin",data driven architecture,130
10.1016/j.jii.2019.04.003,filtered,core,'Elsevier BV',9/1/2019 0:00,core,a data-driven scheduling approach to smart manufacturing,https://core.ac.uk/download/286208185.pdf,"Traditional methods of scheduling are mostly based on the use of pieces of information directly related to the performance of schedules, as for instance processing times, delivery dates, etc., assuming that the production system is operating normally. In the case of malfunctions, the literature concentrates on the ensuing corrective operations, like scheduling with machine breakdowns or under remanufacturing considerations. These event-driven approaches are mainly used in dynamic scheduling or rescheduling systems. Unlike those, Smart Manufacturing and Industry 4.0 production environments integrate the physical and decision-making aspects of manufacturing processes in order to achieve their decentralization and autonomy. On these grounds we propose a data-driven architecture for scheduling, in which the system has real time access to data. Then, scheduling decisions can be made ahead of time, on the basis of more information. This promising approach is based on the architecture of cyber-physical systems, with a data-driven engine that uses, in particular, Big Data techniques to extract vital information for Industry 4.0 systems.Fil: Rossit, Daniel Alejandro. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Tohmé, Fernando Abel. Universidad Nacional del Sur. Departamento de Economía; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Frutos, Mariano. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Investigaciones Económicas y Sociales del Sur. Universidad Nacional del Sur. Departamento de Economía. Instituto de Investigaciones Económicas y Sociales del Sur; Argentin",data driven architecture,131
10.1016/j.xhgg.2021.100035,filtered,core,'Elsevier BV',7/1/2021 0:00,core,a data-driven architecture using natural language processing to improve phenotyping efficiency and accelerate genetic diagnoses of rare disorders,,"Summary: Effective genetic diagnosis requires the correlation of genetic variant data with detailed phenotypic information. However, manual encoding of clinical data into machine-readable forms is laborious and subject to observer bias. Natural language processing (NLP) of electronic health records has great potential to enhance reproducibility at scale but suffers from idiosyncrasies in physician notes and other medical records. We developed methods to optimize NLP outputs for automated diagnosis. We filtered NLP-extracted Human Phenotype Ontology (HPO) terms to more closely resemble manually extracted terms and identified filter parameters across a three-dimensional space for optimal gene prioritization. We then developed a tiered pipeline that reduces manual effort by prioritizing smaller subsets of genes to consider for genetic diagnosis. Our filtering pipeline enabled NLP-based extraction of HPO terms to serve as a sufficient replacement for manual extraction in 92% of prospectively evaluated cases. In 75% of cases, the correct causal gene was ranked higher with our applied filters than without any filters. We describe a framework that can maximize the utility of NLP-based phenotype extraction for gene prioritization and diagnosis. The framework is implemented within a cloud-based modular architecture that can be deployed across health and research institutions",data driven architecture,132
10.1016/j.neunet.2019.07.018,filtered,core,'Elsevier BV',1/1/2020 0:00,core,the gh-exin neural network for hierarchical clustering,,"Hierarchical clustering is an important tool for extracting information from data in a multi-resolution way. It is more meaningful if driven by data, as in the case of divisive algorithms, which split data until no more division is allowed. However, they have the drawback of the splitting threshold setting. The neural networks can address this problem, because they basically depend on data. The growing hierarchical GH-EXIN neural network builds a hierarchical tree in an incremental (data-driven architecture) and self-organized way. It is a top-down technique which defines the horizontal growth by means of an anisotropic region of influence, based on the novel idea of neighborhood convex hull. It also reallocates data and detects outliers by using a novel approach on all the leaves, simultaneously. Its complexity is estimated and an analysis of its user-dependent parameters is given. The advantages of the proposed approach, with regard to the best existing networks, are shown and analyzed, qualitatively and quantitatively, both in benchmark synthetic problems and in a real application (image recognition from video), in order to test the performance in building hierarchical trees. Furthermore, an important and very promising application of GH-EXIN in two-way hierarchical clustering, for the analysis of gene expression data in the study of the colorectal cancer is described",data driven architecture,133
rit scholar works,filtered,core,,6/16/2017 0:00,core,https://core.ac.uk/download/232142182.pdf,,"Though the smart electrical grid promises many advantages in efficiency and reliability, the risks to consumer privacy have impeded its deployment. Researchers have proposed protecting privacy by aggregating user data before it reaches the utility, using techniques of homomorphic encryption to prevent exposure of unaggregated values. However, such schemes generally require users to trust in the correct operation of a single aggregation server. We propose two alternative systems based on secret sharing techniques that distribute this trust among multiple service providers, protecting user privacy against a misbehaving server. We also provide an extensive evaluation of the systems considered, comparing their robustness to privacy compromise, error handling, computational performance, and data transmission costs. We conclude that while all the systems should be computationally feasible on smart meters, the two methods based on secret sharing require much less computation while also providing better protection against corrupted aggregators. Building systems using these techniques could help defend the privacy of electricity customers, as well as customers of other utilities as they move to a more data-driven architecture",data driven architecture,134
published by elsevier b.v.,filtered,core,https://core.ac.uk/download/pdf/81999742.pdf,12/31/2012 0:00,core,10.1016/j.procs.2012.04.126,,"AbstractThe new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider's inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility",data driven architecture,135
'elsevier bv',filtered,core,https://core.ac.uk/download/146492122.pdf,1/1/2013 0:00,core,10.1016/j.procs.2013.05.357,,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",data driven architecture,136
thomas jefferson national accelerator facility (u.s.),filtered,core,,12/1/2013 0:00,core,10.1016/j.nima.2013.06.077,,"For the 12 GeV upgrade, the CLAS12 experiment has designed a Silicon Vertex Tracker (SVT) using single sided microstrip sensors fabricated by Hamamatsu. The sensors have graded angle design to minimize dead areas and a readout pitch of 156{micro}m, with intermediate strip. Double sided SVT module hosts three daisy-chained sensors on each side with a full strip length of 33 cm. There are 512 channels per module read out by four Fermilab Silicon Strip Readout (FSSR2) chips featuring data driven architecture, mounted on a rigid-flex hybrid. Modules are assembled on the barrel using unique cantilevered geometry to minimize the amount of material in the tracking volume. Design and performance of the SVT modules are presented, focusing on results of electrical measurements",data driven architecture,137
10.1016/s0168-9002(99)00453-2,filtered,core,"A 16-channel Digital TDC Chip with internal buffering and selective
  readout for the DIRC Cherenkov counter of the BABAR experiment",2/10/1999 0:00,core,http://arxiv.org/abs/hep-ex/9902015,,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter
of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is
0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven
architecture integrates channel buffering and selective readout of data falling
within a programmable time window. The time measuring scale is constantly
locked to the phase of the (external) clock. The linearity is better than 80 ps
rms. The dead time loss is less than 0.1% for incoherent random input at a rate
of 100 khz on each channel. At such a rate the power dissipation is less than
100 mw. The die size is 36 mm2.Comment: Latex, 18 pages, 13 figures (14 .eps files), submitted to NIM ",data driven architecture,138
10.5075/epfl-thesis-3545,filtered,core,A multitasking and data-driven architecture for multi-agents simulations,4/24/2006 0:00,core,https://core.ac.uk/download/147916631.pdf,,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach",data driven architecture,139
10.7494/dmms.2007.1.2.137,filtered,core,A Distributed Decision-Support System for Virtual Prototyping,10/11/2007 0:00,core,https://core.ac.uk/download/229296196.pdf,,"Virtual Prototyping (VP) is a data-driven design process that promotes both knowledge reuse and innovation. High-profile applications in the automotive and aerospace industries have demonstrated its potential to significantly reduce prototype cycles, time to market, and total product cost. This paper addresses VP as a specialized application of Decision-Support Systems, and discusses common requirements for engineering design tools, as well as requirements specific to the design of electronic products, such as mobile phones. Motorola Labs' test bed for VP is introduced in terms of its open, agent-based architecture utilizing Java CORBA. One of the key principles of the VP System is the reuse of expert knowledge across multiple engineering domains. This is highlighted via several use cases, showing that the system can function not only as an Intranet-accessible repository of model services but also as an integral part of decision-making within the native CAD environment",data driven architecture,140
,filtered,core,,1/1/1994 0:00,core,"a language-independent, data-oriented architecture for grapheme-to-phoneme conversion",,"We report on an implemented grapheme-to-phoneme conversion architecture. Given a set of examples (spelling words with their associated phonetic representation) in a language, a grapheme-to-phoneme conversion system is automatically produced for that language which takes as its input the spelling of words, and produces as its output the phonetic transcription according to the rules implicit in the training data. This paper describes the architecture and focuses on our solution to the alignment problem: given the spelling and the phonetic trancription of a word (often differing in length), these two representations have to be aligned in such a way that grapheme symbols or strings of grapheme symbols are consistently associated with the same phonetic symbol. If this alignment has to be done by hand, it is extremely labour-intensive. 1 Introduction  Grapheme-to-phoneme conversion is an essential module in any text-to-speech system. Various language-specific sources of linguistic knowledge ..",data oriented architecture,141
,filtered,core,,1/1/2012 0:00,core,measurements in opportunistic networks,,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",data centric architecture,142
,filtered,core,OpenSIUC,5/1/2020 0:00,core,design a scalable and secure ndn-based data retrieval framework for internet of things,,"Internet of Things (IoT) has great potential in enabling many beneficial applications (i.e., connected vehicle applications). Named Data Networking (NDN) recently emerges as a promising networking paradigm in supporting IoT due to its data-centric architecture. In this dissertation, we present our research on design a scalable, efficient and secure ndn-based data retrieval framework for Internet of Things. Our work includes three parts:First, we envision an NDN-based Connected Vehicles (CV) application framework with a distributed data service model, as CV is a typical scenario of IoT. The scalability of the framework is greatly challenged by the fast mobility and vast moving area of vehicles. To handle such an issue, we develop a novel hyperbolic hierarchical NDN backbone architecture (H2NDN) by exploiting the location dependency of CV applications. H2NDN designs the backbone routers topology and the data/interest namespace by following the hierarchical architecture of geographic locations. The efficient data searching only requires static forwarding information base (FIB) configuration over NDN routers. To avoid overloading high-level routers, H2NDN integrates hyperbolic routing through carefully designed hyperbolic planes.Second, a distributed adaptive caching strategy is proposed to improve the efficiency of data caches on NDN routers. NDN provides native support to cache data at routers for future Interest packets. As we model the caching problem, the goal of cache allocation is to maximize the savings of Interest/Data forwarding hops under the limited cache space on each router. We discuss the impracticality of global optimization and provide the local caching method. Extensive ndnSIM based simulation with real traffic data proves the efficiency and scalability of the proposed H2NDN architecture.Finally, although NDN provides some security advantages such as secures data directly and uses name semantics to enable applications to reason about security, employing NDN to support IoT applications nevertheless presents some new challenges about security. In this dissertation, we focus on two resultant attacks that are not effectively handled in current studies, namely the targeted blackhole attack and the targeted content poisoning attack. We propose a lightweight and efficient approach named SmartDetour to tackle the two attacks. To ensure high scalability and collusion-resilience, SmartDetour lets each router respond to attacks (i.e., packet drops or corrupted data) independently in order to isolate attackers. The core solution contains a reputation-based probabilistic forwarding strategy and a proactive attacker detection algorithm. Extensive ndnSIM based simulation demonstrates the efficiency and accuracy of the proposed SmartDetour",data centric architecture,143
,filtered,core,,9/24/2013 0:00,core,s.: persistent information state in a data-centric architecture,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,144
,filtered,core,,1/1/2003 0:00,core,a case for staged database systems,,"Traditional database system architectures face a rapidly evolving operating environment, where millions of users store and access terabytes of data. In order to cope with increasing demands for performance, high-end DBMS employ parallel processing techniques coupled with a plethora of sophisticated features. However, the widely adopted, work-centric, thread-parallel execution model entails several shortcomings that limit server performance when executing workloads with changing requirements. Moreover, the monolithic approach in DBMS software has lead to complexanddifficulttoextenddesigns. This paper introduces a staged design for high-performance, evolvable DBMS that are easy to tune and maintain. We propose to break the database system into modules and to encapsulate them into self-contained stages connected to each other through queues. The staged, data-centric design remedies the weaknesses of modern DBMS by providing solutions at both a hardware and a software engineering level. ",data centric architecture,145
,filtered,core,,1/1/2001 0:00,core,adaptive collaboration for wired and wireless platforms - a data-centric architecture for collaboration environments uses xml to adapt shared data dynamically between devices with widely disparate capabilities.,,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",data centric architecture,146
,filtered,core,,1/1/2001 0:00,core,emacspeak - toward the speech-enabled semantic www,,"Emacspeak has pioneered the speech-enabling approach to providing intelligent  spoken feedback for a variety of daily computing tasks. This includes audio  formatted output from World Wide Web (WWW) pages by utilizing Aural Cascading  Style Sheets (ACSS). However, until recently such spoken output has been  limited by presentational HTML pages optimized for visual interaction.  The WWW is presently transitioning toward a data-centric architecture; content  ---and its semantics--- is encapsulated in XML ([W3C98]) pages designed to  be served in a manner most appropriate to a given client. This opens up significant  opportunities in generating high-quality spoken feedback from richly encoded  WWW content. Though XML is still in its early stages of wide-spread adoption,  some of the benefits to come can already be seen today. Many sites now offer  access to both presentational HTML, as well as the underlying data. Examples  include historical stock charts, driving directions, and other useful information.  Emacspeak now exploits the availability of such semantically encoded content  to provide a richer end-user experience. This article introduces some of the data  acquisition techniques used in Emacspeak and focuses on the end-user experience  when interacting with such structured information.  ",data centric architecture,147
,filtered,core,,1/1/2013 0:00,core,architecture framework and components for the big data ecosystem draft version 0.2,,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a so-called Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties ( also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Dat",data centric architecture,148
,filtered,core,,1/1/2011 0:00,core,data serving climate simulation science at the nasa center for climate simulation,https://core.ac.uk/download/pdf/10560731.pdf,"The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",data centric architecture,149
,filtered,core,,1/1/2004 0:00,core,wireless sensor networks dynamic runtime configuration,,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",data centric architecture,150
,filtered,core,,4/7/2009 0:00,core,persistent information state in a data-centric architecture ∗,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,151
,filtered,core,,1/1/2014 0:00,core,ixa pipeline: efficient and ready to use multilingual nlp tools,,"IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It offers robust and efficient linguistic annotation to both researchers and non-NLP experts with the aim of lowering the barriers of using NLP technology either for research purposes or for small industrial developers and SMEs. IXA pipeline can be used “as is ” or exploit its modularity to pick and change different components. Given its open-source nature, it can also be modified and extended for it to work with other languages. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish",data centric architecture,152
,filtered,core,,5/1/2017 0:00,core,resource management in sensing services with audio applications,https://core.ac.uk/download/158321560.pdf,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",data centric architecture,153
,filtered,core,International Institute of Informatics and Cybernetics,8/1/2003 0:00,core,artery: a data-centric architecture for wireless sensor networks,,"Sensor networks, composed of large amount of micro-sensors, are considered promising, both in academic research and in real life applications. To ensure highly efficient communications between event observers and sensor network users, new infrastructures and algorithms are being developed. This paper describes Artery, a novel architecture that delivers queries and data between multiple observers and multiple mobile users. Simulation results show that Artery outperforms some major data dissemination algorithms",data centric architecture,154
,filtered,core,,5/19/2012 0:00,core,1 social-driven internet of connected objects,,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",data centric architecture,155
,filtered,core,"eScholarship, University of California",1/1/2011 0:00,core,declarative systems,,"Building system software is a notoriously complex and arduous endeavor.Developing tools and methodologies for practical system software engineeringhas long been an active area of research.  This thesis explores system softwaredevelopment through the lens of a declarative, data-centric programminglanguage that can succinctly express high-level system specifications and bedirectly compiled to executable code.  By unifying specification andimplementation, our approach avoids the common problem of implementationsdiverging from specifications over time.  In addition, we show that using adeclarative language often results in drastic reductions in code size (100× andmore) relative to procedural languages like Java and C++.  We demonstrate theseadvantages by implementing a host of functionalities at various levels of thesystem hierarchy, including network protocols, query optimizers, and schedulingpolicies.  In addition to providing a compact and optimized implementation, wedemonstrate that our declarative implementations often map very naturally totraditional specifications: in many cases they are line-by-line translations ofpublished pseudcode.We started this work with the hypothesis that declarative languages --originally developed for the purposes of data management and querying -- couldbe fruitfully adapted to the specification and implementation of core systeminfrastructure.  A similar argument had been made for networking protocols afew years earlier [61].  However, our goals were quite different: we wanted toexplore a broader range of algorithms and functionalities (dynamic programming,scheduling, program rewriting, and system auditing) that were part of complex,real-world software systems.  We identified two existing system components --query optimizers in a DBMS and task schedulers in a cloud computing system --that we felt would be better specified via a declarative language.  Given ourinterest in delivering real-world software, a key challenge was identifying theright system boundary that would permit meaningful declarative implementationsto coexist within existing imperative system architectures.  We found thatrelations were a natural boundary for maintaining the ongoing system state onwhich the imperative and declarative code was based, and provided an elegantway to model system architectures.This thesis explores the boundaries of declarative systems via two projects.We begin with Evita Raced; an extensible compiler for the Overlog language usedin our declarative networking system, P2.  Evita Raced is a metacompiler -- anOverlog compiler written in Overlog -- that integrates seamlessly with the P2dataflow architecture.  We first describe the minimalist design of Evita Raced,including its extensibility interfaces and its reuse of the P2 data model andruntime engine.  We then demonstrate that a declarative language like Overlogis well-suited to expressing traditional and novel query optimizations as wellas other program manipulations, in a compact and natural fashion.  FollowingEvita Raced, we describe the initial work in BOOM Analytics, which began as alarge-scale experiment at building ""cloud"" software in a declarative language.Specifically, we used the Overlog language to implement a ""Big Data"" analyticsstack that is API-compatible with the Hadoop MapReduce architecture andprovides comparable performance.  We extended our declarative version of Hadoopwith complex distributed features that remain absent in the stock Hadoop Javaimplementation, including alternative scheduling policies, online aggregation,continuous queries, and unique monitoring and debugging facilities.  We presentquantitative and anecdotal results from our experience, providing concreteevidence that both data-centric design and declarative languages cansubstantially simplify systems programming",data centric architecture,156
,filtered,core,,1/1/2007 0:00,core,gestion de l'évolution des applications web,,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",data centric architecture,157
,filtered,core,,8/26/2015 0:00,core,adaptive collaboration for wired and wireless platforms,,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",data centric architecture,158
,filtered,core,"eScholarship, University of California",1/1/2020 0:00,core,the cloud is not enough: saving iot from the cloud,,"© USENIX Workshop on Hot Topics in Storage and File Systems, HotStorage 2015.All right reserved. The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, the current approach of directly connecting smart devices to the cloud has a number of disadvantages and is unlikely to keep up with either the growing speed of the IoT or the diverse needs of IoT applications. In this paper we explore these disadvantages and argue that fundamental properties of the IoT prevent the current approach from scaling. What is missing is a wellarchitected system that extends the functionality of the cloud and provides seamless interplay among the heterogeneous components in the IoT space. We argue that raising the level of abstraction to a data-centric design-focused around the distribution, preservation and protection of information-provides a much better match to the IoT. We present early work on such a distributed platform, called the Global Data Plane (GDP), and discuss how it addresses the problems with the cloud-centric architecture",data centric architecture,159
,filtered,core,,8/31/2009 0:00,core,a context-oriented synchronization approach,,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",data centric architecture,160
,filtered,core,HAL CCSD,3/27/2017 0:00,core,towards blockchain-based auditable storage and sharing of iot data,https://core.ac.uk/download/145154055.pdf,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",data centric architecture,161
,filtered,core,,1/1/2018 0:00,core,collaborative systems engineering in the ascent abort-2 crew module/separation ring project,https://core.ac.uk/download/pdf/161999682.pdf,"Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",data centric architecture,162
,filtered,core,"eScholarship, University of California",5/1/2016 0:00,core,toward a global data infrastructure,,"The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, directly connecting smart devices to the cloud has multiple disadvantages and is unlikely to keep up with the growing speed of the IoT or the diverse needs of IoT applications. Here, the authors argue that fundamental IoT properties prevent the current approach from scaling. What's missing is a well-architected system extending cloud functionality and providing seamless interplay among heterogeneous components closer to the edge in the IoT space. Raising the level of abstraction to a data-centric design-focused around the distribution, preservation, and protection of information-better matches the IoT. To address such problems with the cloud-centric architecture, the authors present their early work on a distributed platform, the Global Data Plane",data centric architecture,163
,filtered,core,,9/26/2016 0:00,core,analysis of the big data based on mapreduce,,"Abstract. Big Data are becoming a popular technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. Big Data is bringing a positive change in the decision making process of various business organizations.In this paper, MapReduce big data analysis methods, and with SQL server performance comparison, the experimental results show that, compared to SQL server, MapReduce method loads a small time, as the data set increases, the performance MapReduce approach is better. So MapReduce method has better scalability and speedup for large data processing applications. ",data centric architecture,164
,filtered,core,DigitalCommons@USU,8/12/2009 0:00,core,plug and play spacecraft evolution,https://core.ac.uk/download/32550735.pdf,"The space community, led by AFRL, started developing spacecraft plug and play concepts and standards in 2004 and has resulted in the Space Plug and play Avionics (SPA) Standards. AFRL has undertaken two efforts in small satellite development to both solidify the technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) utilizes the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. The second effort is PnPSat-2 that uses the next generation of SPA components for a larger bus focused on ORS needs to make real the promise of custom performance at commodity prices. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insolates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in test time. This paper will present the steps used in designing, building, and testing SPA PnP satellites and the current status of PnPSat and PnPSat-2",data centric architecture,165
,filtered,core,UR Scholarship Repository,5/1/2020 0:00,core,the clas12 silicon vertex tracker,,"For the 12 GeV upgrade of Jefferson Laboratory, a Silicon Vertex Tracker (SVT) has been designed for theCLAS12 spectrometer using single-sided microstrip sensors fabricated by Hamamatsu Photonics. The sensors have a graded angle design to minimize dead areas and a readout pitch of156 μm, with intermediate strips. Each double-sided SVT module hosts three daisy-chained sensors on each side with a full strip length of33 cm. There are 512 channels per module, read out by four Fermilab Silicon Strip Readout (FSSR2) chips, featuring data-driven architecture, mounted on a rigid–flex hybrid board. The modules are assembled in a barrel configuration using a unique cantilevered geometry to minimize the amount of material in the tracking volume. This paper is focused on the design, qualification of the performance, and experience in operating and commissioning the tracker during the first year of the data taking",data driven architecture,166
,filtered,core,,10/11/2019 0:00,core,http://arxiv.org/abs/1910.06115,,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality",data driven architecture,167
,filtered,core,,1/1/2012 0:00,core,10.3182/20120829-3-mx-2028.00125,,"In this paper, a scheme for the design of a fault-tolerant control architecture using process data is proposed, whose core is an observer-based realization of the Youla parameterization of all stabilization controllers. The realization of a fault-tolerant control scheme based on the proposed architecture is demonstrated on a benchmark process. ? 2012 IFAC.EI",data driven architecture,168
,filtered,core,,1/1/2010 0:00,core,10.1109/geoinformatics.2010.5567735,,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",data driven architecture,169
,filtered,core,"DCOS, a real-time light-weight Data Centric Operating System",1/1/2004 0:00,core,https://core.ac.uk/download/pdf/11461067.pdf,,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",data driven architecture,170
,filtered,core,"DCOS, a Real-Time Light-weight Data Centric Operating System",1/1/2004 0:00,core,https://core.ac.uk/download/pdf/11458862.pdf,,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",data driven architecture,171
,filtered,core,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",1/1/2008 0:00,core,https://core.ac.uk/download/pdf/195383281.pdf,,"This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",data driven architecture,172
,filtered,core,Program Partitioning for a Control/Data Driven Computer,1/1/1993 0:00,core,https://core.ac.uk/download/81372427.pdf,,"The paper examines the problem of dataflow graph partitioning aiming to improve the efficiency of macro-dataflow computing on a hybrid control/data driven architecture. The partitioning consists of dataflow graph synchronization and scheduling of the synchronous graph. A new scheduling algorithm, called Global Arc Minimization (GAM), is introduced. The performance of the GAM algorithm is evaluated relative to some other known heuristic methods for static scheduling. When interprocessor communication delays are taken into account, the GAM algorithm achieves better performance on the simulated hybrid architecture",data driven architecture,173
987f1feddb599eac1c924ce5dc39f9c57e93d5e0,filtered,semantic_scholar,,40909,semantic_scholar,data-oriented architecture for system integration,https://www.semanticscholar.org/paper/987f1feddb599eac1c924ce5dc39f9c57e93d5e0,"According to the problem that,in the process of integrating large-scale distributed system,the subsystems are difficult to manage,extend,and maintenance,which caused by their different implementation technologies and tightly-coupled design.A pattern of data-oriented design is introduced,and the principle based on the pattern and the related middleware technology were discussed.A data-oriented architecture for system integration was proposed.Finally,based on the example of a real-time package tracking system-of-systems,the architecture of data-oriented integration was discussed in detail.",data oriented architecture,174
8f07a47646ca8fcc6adb1948b118c0969e844d3b,filtered,semantic_scholar,2010 2nd International Conference on Education Technology and Computer,40179,semantic_scholar,data-oriented architecture of sine,https://www.semanticscholar.org/paper/8f07a47646ca8fcc6adb1948b118c0969e844d3b,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,175
045c7665e95ae9f0dbdac771ca307c5427ab6426,filtered,semantic_scholar,2010 2nd International Conference on Advanced Computer Control,40179,semantic_scholar,data-oriented architecture of ln function,https://www.semanticscholar.org/paper/045c7665e95ae9f0dbdac771ca307c5427ab6426,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,176
b671e6b6ad4b5cb346f19414c709f78e862da379,filtered,semantic_scholar,2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),43466,semantic_scholar,uav-gcs centralized data-oriented communication architecture for crowd surveillance applications,https://www.semanticscholar.org/paper/b671e6b6ad4b5cb346f19414c709f78e862da379,"In recent years, a large number of researchers investigate the conception of systems that use a unique Unmanned Ariel Vehicles (UAV) or multiple independent UAVs to conduct civil or military missions, with minimal human intervention. In this paper we focus on using multiple UAVs to cooperatively monitor a crowded area. Communication in such UAVs network is an ongoing project. Due to the lack of proper communication standards and rules, designing a reliable communication model is essential for: (i) multi-UAV coordination, (ii) efficient bandwidth sharing according to data priority and urgency and (iii) avoiding useless transmission of the same data by multiple UAVs. To address the above challenges, we propose a centralized data-oriented communication architecture for crowd surveillance allocations using an UAV fleet. The Ground Control Station (GCS) is used as a central coordinator to manage bandwidth usage for the UAV fleet in its coverage area. To allow UAVs to send priority messages urgently to the GCS, we define two classes of urgent messages: critical state and important result. The class of the data as well as other relevant information about the detected event will be used by the GCS to authorize or not UAV data transmission and hence to optimize the bandwidth usage efficiency.",data oriented architecture,177
6d5165205564bc98c1afcf20a1652a21f1e3e61e,filtered,semantic_scholar,,39083,semantic_scholar,data-oriented architecture: a loosely-coupled real-time soa,https://www.semanticscholar.org/paper/6d5165205564bc98c1afcf20a1652a21f1e3e61e,"2007 August "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,178
585b18385db6eb806e207b797ae7262143b9bd28,filtered,semantic_scholar,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),40179,semantic_scholar,data-oriented architecture of sine and cosine functions,https://www.semanticscholar.org/paper/585b18385db6eb806e207b797ae7262143b9bd28,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,179
9fc03132540aa5d53f50b875bb4ccb620dee09ea,filtered,semantic_scholar,,39083,semantic_scholar,data-oriented architecture,https://www.semanticscholar.org/paper/9fc03132540aa5d53f50b875bb4ccb620dee09ea,"2007 January "" Data dominates. If you've chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to programming. Abstract As more devices and systems get woven into the fabric of our networked world, the scale and the complexity of integration is growing at a rapid pace. Our existing methodologies and training for system software design, rooted in principles of object-oriented design, that worked superbly for small scale systems begin to break down as we discover operational limits which requires frequent and unintended redesigns in programs year over year. Fundamentally, object-oriented thinking leads us to think in terms of tightly-coupled interactions that include strong state assumptions. Large scale distributed systems are often a mix of subsystems created by independent parties, often using different middleware technologies, with misaligned interfaces. Integrating such subsystems using object-oriented thinking poses some fundamental challenges: (1) it is brittle to incremental and independent development, where interfaces can change without notice; (2) there is often an ""impedance mis-match"" between subsystems in the quantity and the quality of information that must be exchanged between the two sides; (3) there is a real need to dynamically adapt in real-time to network topology reconfigurations and failures; (4) scalability, performance, and up-time cannot always be compromised in this dynamic environment. A different paradigm is needed in order to address these new challenges in a systematic manner. As the scale of the integration and complexity grows, the only unifying common denominators between disparate subsystems (generally numbering more than two) are: (1) the data they produce and consume; (2) the services they use and offer. In order to scale, system software architecture must be organized around a common ""shared information model"" that spans multiple systems. This leads us to the principle of ""data-oriented"" design: expose the data and hide the code. In this paper, we will discuss the principles of data-oriented thinking, and discuss why it offers an appropriate paradigm to address large scale system integration. We discuss the critical role played by the middleware infrastructure in applying data-oriented design, and describe a generic data-oriented integration architecture based on the data distribution service (DDS) middleware standard. We analyze popular architectural styles including data flow architecture, event driven architecture, and service oriented architecture from this perspective and establish that they can be viewed as specializations of the generic data-oriented architecture. Finally we illustrate …",data oriented architecture,180
f7946ea31a3da644fd59303be9fff721579987fd,filtered,semantic_scholar,IEEE Internet of Things Journal,42736,semantic_scholar,a data-oriented m2m messaging mechanism for industrial iot applications,https://www.semanticscholar.org/paper/f7946ea31a3da644fd59303be9fff721579987fd,"Machine-to-machine (M2M) communication is a key enabling technology for the future industrial Internet of Things applications. It plays an important role in the connectivity and integration of computerized machines, such as sensors, actuators, controllers, and robots. The requirements in flexibility, efficiency, and cross-platform compatibility of the intermodule communication between the connected machines raise challenges for the M2M messaging mechanism toward ubiquitous data access and events notification. This investigation determines the challenges facing the M2M communication of industrial systems and presents a data-oriented M2M messaging mechanism based on ZeroMQ for the ubiquitous data access in rich sensing pervasive industrial applications. To prove the feasibility of the proposed solution, the EU funded PickNPack production line with a reference industrial network architecture is presented, and the communication between a microwave sensor device and the quality assessment and sensing module controller of the PickNPack line is illustrated as a case study. The evaluation is carried out through qualitative analysis and experimental studies, and the results demonstrate the feasibility of the proposed messaging mechanism. Due to the flexibility in dealing with hierarchical system architecture and cross-platform heterogeneity of industrial applications, this messaging mechanism deserves extensive investigations and further evaluations.",data oriented architecture,181
d0bdc150887cfca9e8ee50db6e2f17d7c08520bc,filtered,semantic_scholar,ReArch '09,39814,semantic_scholar,lanes: an inter-domain data-oriented routing architecture,https://www.semanticscholar.org/paper/d0bdc150887cfca9e8ee50db6e2f17d7c08520bc,"Data-oriented networking has attracted research recently, but the efficiency of the state-of-the-art solutions can still be improved. Our work towards this goal is set in a clean-slate architecture consisting of modular rendezvous, routing, and forwarding functions. In this paper we present the interdomain routing layer and its interplay with the other components of the system. The proposed system is built around two types of nodes: forwarding nodes and branching nodes. The forwarding nodes are optimized for throughput with no per-subscription state and no need to change passing packets, while branching nodes contain a large memory for caching and can make complex routing decisions. The amount of storage space and bandwidth can be independently scaled to suit the needs of each network. In the background, topology nodes perform load-balancing and configure routes in each domain using a two-dimensional addressing mechanism. The paths taken by packets adapt to the number of active subscribers to keep the amount of in-network state and latency low. A new data-oriented congestion control scheme is introduced, which takes into account the use of storage resources on-path and is fair to multicast flows.",data oriented architecture,182
b0e0e1172296a6da7de25aa40f51cce9614ae8fc,filtered,semantic_scholar,,42005,semantic_scholar,allocation strategies for data-oriented architectures,https://www.semanticscholar.org/paper/b0e0e1172296a6da7de25aa40f51cce9614ae8fc,"Data orientation is a common design principle in distributed data management systems. In contrast to process-oriented or transaction-oriented system designs, dataoriented architectures are based on data locality and function shipping. The tight coupling of data and processing thereon is implemented in different systems in a variety of application scenarios such as data analysis, database-as-a-service, and data management on multiprocessor systems. Data-oriented systems, i.e., systems that implement a data-oriented architecture, bundle data and operations together in tasks which are processed locally on the nodes of the distributed system. Allocation strategies, i.e., methods that decide the mapping from tasks to nodes, are core components in data-oriented systems. Good allocation strategies can lead to balanced systems while bad allocation strategies cause skew in the load and therefore suboptimal application performance and infrastructure utilization. Optimal allocation strategies are hard to find given the complexity of the systems, the complicated interactions of tasks, and the huge solution space. To ensure the scalability of dataoriented systems and to keep them manageable with hundreds of thousands of tasks, thousands of nodes, and dynamic workloads, fast and reliable allocation strategies are mandatory. In this thesis, we develop novel allocation strategies for data-oriented systems based on graph partitioning algorithms. Therefore, we show that systems from different application scenarios with different abstraction levels can be generalized to generic infrastructure and workload descriptions. We use weighted graph representations to model infrastructures with bounded and unbounded, i.e., overcommited, resources and possibly non-linear performance characteristics. Based on our generalized infrastructure and workload model, we formalize the allocation problem, which seeks valid and balanced allocations that minimize communication. Our allocation strategies partition the workload graph using solution heuristics that work with single and multiple vertex weights. Novel extensions to these solution heuristics can be used to balance penalized and secondary graph partition weights. These extensions enable the allocation strategies to handle infrastructures with non-linear performance behavior. On top of the basic algorithms, we propose methods to incorporate heterogeneous infrastructures and to react to changing workloads and infrastructures by incrementally updating the partitioning. We evaluate all components of our allocation strategy algorithms and show their applicability and scalability with synthetic workload graphs. In end-to-end– performance experiments in two actual data-oriented systems, a database-as-aservice system and a database management system for multiprocessor systems, we prove that our allocation strategies outperform alternative state-of-the-art methods.",data oriented architecture,183
d202d37f5d90cb7fbb7dff2d454fcad944a3176e,filtered,semantic_scholar,GeoInfo,38353,semantic_scholar,local spatial data infrastructures based on a service-oriented architecture,https://www.semanticscholar.org/paper/d202d37f5d90cb7fbb7dff2d454fcad944a3176e,"Sharing geographic information is an essential activity which has been sought since the early days of GIS, mostly due to the cost of information collection and maintenance. Having once depended on the establishment of data transfer standards, sharing initiatives gradually evolved towards the creation of clearinghouses, Web resources that centralize links to various GI sources, but are still data-oriented. The current focus on spatial data infrastructures changes that, by establishing a service-oriented view, thus allowing for the creation of shared, distributed, and interoperable environments through Web services. This paper explores, in a preliminary fashion, such an architecture as applied to distributed geographic applications, focusing on the potential for local services and local uses, and proposing specialized services deemed essential for urban-scale applications.",data oriented architecture,184
b51a5d61dc40f45443ae3995490679d4f96a1383,filtered,semantic_scholar,SIGMOD '11,40544,semantic_scholar,a data-oriented transaction execution engine and supporting tools,https://www.semanticscholar.org/paper/b51a5d61dc40f45443ae3995490679d4f96a1383,"Conventional OLTP systems assign each transaction to a worker thread and that thread accesses data, depending on what the transaction dictates. This thread-to-transaction work assignment policy leads to unpredictable accesses. The unpredictability forces each thread to enter a large number of critical sections for the completion of even the simplest of the transactions; leading to poor performance and scalability on modern manycore hardware.
 This demonstration highlights the chaotic access patterns of conventional OLTP designs which are the source of scalability problems. Then, it presents a working prototype of a transaction processing engine that follows a non-conventional architecture, called data-oriented or DORA. DORA is designed around the thread-to-data work assignment policy. It distributes the transaction execution to multiple threads and offers predictable accesses. By design, DORA can decentralize the lock management service, and thereby eliminate the critical sections executed inside the lock manager. We explain the design of the system and show that it more efficiently utilizes the abundant processing power of modern hardware, always contrasting it against the conventional execution. In addition, we present different components of the system, such as a dynamic load balancer. Finally, we present a set of tools that enable the development of applications that use DORA.",data oriented architecture,185
bd6d3585fea44c2812e16047fcb28d38ae438682,filtered,semantic_scholar,IEEE Communications Surveys & Tutorials,42370,semantic_scholar,control-data separation architecture for cellular radio access networks: a survey and outlook,https://www.semanticscholar.org/paper/bd6d3585fea44c2812e16047fcb28d38ae438682,"Conventional cellular systems are designed to ensure ubiquitous coverage with an always present wireless channel irrespective of the spatial and temporal demand of service. This approach raises several problems due to the tight coupling between network and data access points, as well as the paradigm shift towards data-oriented services, heterogeneous deployments and network densification. A logical separation between control and data planes is seen as a promising solution that could overcome these issues, by providing data services under the umbrella of a coverage layer. This article presents a holistic survey of existing literature on the control-data separation architecture (CDSA) for cellular radio access networks. As a starting point, we discuss the fundamentals, concepts, and general structure of the CDSA. Then, we point out limitations of the conventional architecture in futuristic deployment scenarios. In addition, we present and critically discuss the work that has been done to investigate potential benefits of the CDSA, as well as its technical challenges and enabling technologies. Finally, an overview of standardisation proposals related to this research vision is provided.",data oriented architecture,186
0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,filtered,semantic_scholar,J. Database Manag.,36892,semantic_scholar,a metadata oriented architecture for building datawarehouse,https://www.semanticscholar.org/paper/0afcaac22b73e8653d80b6f18d3e4a7265c8d9c3,"Data warehouse is an intelligent store of data that can aggregate vast amounts of information. A metadata is critical for implementing data warehouse. Therefore, integrating data warehouse with its metadata offers a new opportunity to create a more adaptive information system. This paper proposes a metadata-oriented data warehouse architecture that consists of seven components: legacy system, extracting software, operational data store, data warehouse, data mart, application, and metadata. A taxonomy for dataflow and metaflow is proposed for better understanding of the architecture. In addition, a metadata schema is built within the framework of the seven components. The architecture with its metadata component is applied to a real-life data warehouse for a large medical center in order to illustrate its practical usefulness.",data oriented architecture,187
a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,filtered,semantic_scholar,2019 IEEE/CVF International Conference on Computer Vision (ICCV),43466,semantic_scholar,auto-fpn: automatic network architecture adaptation for object detection beyond classification,https://www.semanticscholar.org/paper/a3b0009cd0dc71a557fb92b748f4f56411b7e2fe,"Abstract Neural architecture search (NAS) has shown great potential in automating the manual process of designing a good CNN architecture for image classification. In this paper, we study NAS for object detection, a core computer vision task that classifies and localizes object instances in an image. Existing works focus on transferring the searched architecture from classification task (ImageNet) to the detector backbone, while the rest of the architecture of the detector remains unchanged. However, this pipeline is not task-specific or data-oriented network search which cannot guarantee optimal adaptation to any dataset. Therefore, we propose an architecture search framework named Auto-FPN specifically designed for detection beyond simply searching a classification backbone. Specifically, we propose two auto search modules for detection: Auto-fusion to search a better fusion of the multi-level features; Auto-head to search a better structure for classification and bounding-box(bbox) regression. Instead of searching for one repeatable cell structure, we relax the constraint and allow different cells. The search space of both modules covers many popular designs of detectors and allows efficient gradient-based architecture search with resource constraint (2 days for COCO on 8 GPU cards). Extensive experiments on Pascal VOC, COCO, BDD, VisualGenome and ADE demonstrate the effectiveness of the proposed method, e.g. achieving around 5% improvement than FPN in terms of mAP while requiring around 50% fewer parameters on the searched modules.",data oriented architecture,188
a323992739aaa0e477c206fdcad9f7cb87139360,filtered,semantic_scholar,IEEE Transactions on Nanotechnology,42005,semantic_scholar,an energy-efficient nonvolatile in-memory computing architecture for extreme learning machine by domain-wall nanowire devices,https://www.semanticscholar.org/paper/a323992739aaa0e477c206fdcad9f7cb87139360,"The data-oriented applications have introduced increased demands on memory capacity and bandwidth, which raises the need to rethink the architecture of the current computing platforms. The logic-in-memory architecture is highly promising as future logic-memory integration paradigm for high throughput data-driven applications. From memory technology aspect, as one recently introduced nonvolatile memory device, domain-wall nanowire (or race-track) not only shows potential as future power efficient memory, but also computing capacity by its unique physics of spintronics. This paper explores a novel distributed in-memory computing architecture where most logic functions are executed within the memory, which significantly alleviates the bandwidth congestion issue and improves the energy efficiency. The proposed distributed in-memory computing architecture is purely built by domain-wall nanowire, i.e., both memory and logic are implemented by domain-wall nanowire devices. As a case study, neural network-based image resolution enhancement algorithm, called DW-NN, is examined within the proposed architecture. We show that all operations involved in machine learning on neural network can be mapped to a logic-in-memory architecture by nonvolatile domain-wall nanowire. Domain-wall nanowire-based logic is customized for in machine learning within image data storage. As such, both neural network training and processing can be performed locally within the memory. The experimental results show that the domain-wall memory can reduce 92% leakage power and 16% dynamic power compared to main memory implemented by DRAM; and domain-wall logic can reduce 31% both dynamic and 65% leakage power under the similar performance compared to CMOS transistor-based logic. And system throughput in DW-NN is improved by 11.6x and the energy efficiency is improved by 56x when compared to conventional image processing system.",data oriented architecture,189
e7eacfd126dfe09f26fbac0f52cd290bb6684c43,filtered,semantic_scholar,MidSens '12,40909,semantic_scholar,enabling the usage of sensor networks with service-oriented architectures,https://www.semanticscholar.org/paper/e7eacfd126dfe09f26fbac0f52cd290bb6684c43,"Closing the gap between device-oriented sensor networks and data-oriented applications is a serious challenge. We present a novel platform which enables the seamless integration of sensor networks with a Service-Oriented Architecture approach. The platform hides the device-specific details from the applications and transforms data into a device-independent format. Thereby the system provides a mechanism to create a variety of end-user applications on top of the platform, which are independent from the device-specific details. We present an in-depth description of the architecture of our platform, and a full implementation and evaluation of it in a residential energy management setting.",data oriented architecture,190
e0b54bc395fccf323645a4839d04b646431eb369,filtered,semantic_scholar,IEEE Transactions on Circuits and Systems II: Express Briefs,42005,semantic_scholar,a fast integral image computing hardware architecture with high power and area efficiency,https://www.semanticscholar.org/paper/e0b54bc395fccf323645a4839d04b646431eb369,"Integral image computing is an important part of many vision applications and is characterized by intensive computation and frequent memory accessing. This brief proposes an approach for fast integral image computing with high area and power efficiency. For the data flow of the integral image computation a dual-direction data-oriented integral image computing mechanism is proposed to improve the processing efficiency, and then a pipelined parallel architecture is designed to support this mechanism. The parallelism and time complexity of the approach are analyzed and the hardware implementation cost of the proposed architecture is also presented. Compared with the state-of-the-art methods this architecture achieves the highest processing speed with comparatively low logic resources and power consumption.",data oriented architecture,191
a312fd2a6feffb5bd907a08548a359f071b1e2fe,filtered,semantic_scholar,SIGCOMM '09,39814,semantic_scholar,lipsin: line speed publish/subscribe inter-networking,https://www.semanticscholar.org/paper/a312fd2a6feffb5bd907a08548a359f071b1e2fe,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures.
 In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks.",data oriented architecture,192
501c680ea3bf5e809dd8f23fd5dc17d3f8ec0ac0,filtered,semantic_scholar,NDM '15,42005,semantic_scholar,managing scientific data with named data networking,https://www.semanticscholar.org/paper/501c680ea3bf5e809dd8f23fd5dc17d3f8ec0ac0,"Many scientific domains, such as climate science and High Energy Physics (HEP), have data management requirements that are not well supported by the IP network architecture. Named Data Networking (NDN) is a new network architecture whose service model is better aligned with the needs of data-oriented applications. NDN provides features such as best-location retrieval, caching, load sharing, and transparent failover that would otherwise be painstakingly (re-)implemented by each application using point-to-point semantics in an IP network.
 We present the first scientific data management application designed and implemented on top of NDN. We use this application to manage climate and HEP data over a dedicated, high-performance, testbed. Our application has two main components: a UI for dataset discovery queries and a federation of synchronized name catalogs. We show how NDN primitives can be used to implement common data management operations such as publishing, search, efficient retrieval, and publication access control.",data oriented architecture,193
70e6fa53b806b17d603bdc7d47a7d615d7834670,filtered,semantic_scholar,2011 IEEE Third International Conference on Cloud Computing Technology and Science,40544,semantic_scholar,a cloud environment for data-intensive storage services,https://www.semanticscholar.org/paper/70e6fa53b806b17d603bdc7d47a7d615d7834670,"The emergence of cloud environments has made feasible the delivery of Internet-scale services by addressing a number of challenges such as live migration, fault tolerance and quality of service. However, current approaches do not tackle key issues related to cloud storage, which are of increasing importance given the enormous amount of data being produced in today's rich digital environment (e.g. by smart phones, social networks, sensors, user generated content). In this paper we present the architecture of a scalable and flexible cloud environment addressing the challenge of providing data-intensive storage cloud services through raising the abstraction level of storage, enabling data mobility across providers, allowing computational and content-centric access to storage and deploying new data-oriented mechanisms for QoS and security guarantees. We also demonstrate the added value and effectiveness of the proposed architecture through two real-life application scenarios from the healthcare and media domains.",data oriented architecture,194
c7f42b0f6dc0e7f593035327822dafe6c5605e4a,filtered,semantic_scholar,CoNEXT '08,39448,semantic_scholar,towards a new generation of information-oriented internetworking architectures,https://www.semanticscholar.org/paper/c7f42b0f6dc0e7f593035327822dafe6c5605e4a,"In response to the limitations of the Internet architecture when used for applications for which it was not originally designed, a series of clean slate efforts have emerged to shape the so-called future Internet. Recently, visionary voices have advised a shift in the networking problem under research, moving from seamless host-reachability to internetworking of information. We contribute to the healthy debate on future Internet design and discuss ongoing information oriented efforts. Inspired by recent works in Bloom-filterlike data structures, we propose the SPSwitch as a novel switching engine to make wire speed forwarding decisions on flat information labels. We address part of the scalability issues in a data-oriented forwarding layer by trading overdeliveries for state reduction and line speed operations.",data oriented architecture,195
bb4b9316c514860dbfd54bbd50baec757e37b83d,filtered,semantic_scholar,,40909,semantic_scholar,data as a service (daas) in cloud computing,https://www.semanticscholar.org/paper/bb4b9316c514860dbfd54bbd50baec757e37b83d,"Data has become the enabling technology for many of the recent innovations. ""More data trumps smarter algorithms"" has been the mantra behind this revolution in computing. Given the rate at which the data is produced, there is need for scalable solutions to extract information out of them. Allowing the data to be stored in the cloud and be accessed without geographical and scalability limitations will remove many bottlenecks in bringing data-oriented innovations. Current cloud architecture solves the issues of accessibility and scalability, but poses several new challenges such as automatic management of the service, pricing the data, and security of the data. This talk will include several techniques to address these challenges using automatic physical design, servicebased pricing, and cryptographic mechanisms. Data Information Knowledge Intelligence.",data oriented architecture,196
6c4fca03bf42a507fcf0ef437d89a6e9f9c12b90,filtered,semantic_scholar,The IEEE symposium on Computers and Communications,40179,semantic_scholar,roles and security in a publish/subscribe network architecture,https://www.semanticscholar.org/paper/6c4fca03bf42a507fcf0ef437d89a6e9f9c12b90,"Several publish/subscribe (pub/sub) and data-oriented networking proposals have been presented to overcome limitations of the current message- and host-centric Internet. However, security issues of these solutions have not been addressed comprehensively. In this paper we examine roles of actors comprising an inter-domain pub/sub network, together with security requirements and minimal required trust associations arising from this setting. We then introduce and analyze a security design for a clean-slate pub/sub network architecture that secures both the control and data planes. The solution addresses availability and data integrity while remaining scalable and usable.",data oriented architecture,197
78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,filtered,semantic_scholar,IEEE Communications Magazine,41275,semantic_scholar,on functionality separation for green mobile networks: concept study over lte,https://www.semanticscholar.org/paper/78f3d4f90cf3a094b7bd883d1b6b63b83f65028b,"Traditional wireless networks are designed for ubiquitous network access provision with low-rate voice services, which thus preserve the homogeneous architecture and tight coupling for infrastructures such as base stations. With the traffic explosion and the paradigm shift from voice-oriented services to data-oriented services, traditional homogeneous architecture no longer maintains its optimality, and heterogeneous deployment with flexible network control capability becomes a promising evolution direction. To achieve this goal, in this article, we propose a two-layer network functionality separation scheme, targeting at low control signaling overhead and flexible network reconfiguration for future mobile networks. The proposed scheme is shown to support all kinds of user activities defined in current networks. Moreover, we give two examples to illustrate how the proposed scheme can be applied to multicarrier networks and suggest two important design principles for future green networks. Numerical results show that the proposed scheme achieves significant energy reduction over traditional LTE networks, and can be recommended as a candidate solution for future green mobile networks.",data oriented architecture,198
4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,filtered,semantic_scholar,IEEE Transactions on Industrial Electronics,42005,semantic_scholar,design and optimization of multiclocked embedded systems using formal techniques,https://www.semanticscholar.org/paper/4f762aa3881094a1c4de7fff2dac8d8f3c1106cf,"Today's system-on-chip and distributed systems are commonly equipped with multiple clocks. The key challenge in designing such systems is that two situations have to be captured and evaluated in a single framework. The first is the heterogeneous control-oriented and data-oriented behaviors within one clock domain, and the second is the asynchronous communications between two clock domains. In this paper, we propose to use timed automata and synchronous dataflow to model the dynamic behaviors of the multiclock train-control system, and a multiprocessor architecture for the implementation from our model to the real system. Data-oriented behaviors are captured by synchronous dataflow, control-oriented behaviors are captured by timed automata, and asynchronous communications of the interclock domain can be modeled as an interface timed automaton or a synchronous dataflow module. The behaviors of synchronous dataflow are interpreted by some equivalent timed automata to maintain the semantic consistency of the mixed model. Then, various functional properties that are important to guarantee the correctness of the system can be simulated and verified within the framework. We apply the framework to the design of a control system described in the standard IEC 61 375 and several bugs are detected. The bugs in the standard have been fixed, and the new version has been implemented and used in the real-world subway communication control system.",data oriented architecture,199
ec02fc78f7ec0d9cbef609f4386143eaa84d4ae5,filtered,semantic_scholar,ADMS@VLDB,41640,semantic_scholar,eris: a numa-aware in-memory storage engine for analytical workload,https://www.semanticscholar.org/paper/ec02fc78f7ec0d9cbef609f4386143eaa84d4ae5,"The ever-growing demand for more computing power forces hardware vendors to put an increasing number of multiprocessors into a single server system, which usually exhibits a non-uniform memory access (NUMA). In-memory database systems running on NUMA platforms face several issues such as the increased latency and the decreased bandwidth when accessing remote main memory. To cope with these NUMA-related issues, NUMA-awareness has to be considered as a major design principle for the fundamental architecture of a database system. In this paper we present ERIS, a NUMA-aware inmemory storage engine that is based on a data-oriented architecture. In contrast to existing approaches that focus on transactional workloads on a disk-based DBMS, ERIS aims at tera-scale analytical workloads that are executed entirely in main memory. ERIS uses an adaptive partitioning approach that exploits the topology of the underlying NUMA platform and significantly reduces NUMA-related issues. We evaluate ERIS on widespread standard server systems as well as on a system consisting of 64 multiprocessors and 512 cores. On these platforms, we achieve a more than linear speedup for index lookups and scalable parallel scan operations that are only limited by the available local bandwidth of the multiprocessor. Moreover, we measured a performance gain of up to 200% (index lookups) respectively 660% (column scans) in the memory-bound case compared to a NUMA-agnostic storage subsystem.",data oriented architecture,200
14fb54b6e2515274d82df8a3f15c77904ad66ddf,filtered,semantic_scholar,,34335,semantic_scholar,real-time communication in packet-switched networks,https://www.semanticscholar.org/paper/14fb54b6e2515274d82df8a3f15c77904ad66ddf,"The dramatically increased bandwidths and processing capabilities of future high-speed networks make possible many distributed real-time applications, such as sensor-based applications and multimedia services. Since these applications will have traffic characteristics and performance requirements that differ dramatically from those of current data-oriented applications, new communication network architectures, and protocols will be required. In this paper we discuss the performance requirements and traffic characteristics of various real-time applications, survey recent developments in the areas of network architecture and protocols for supporting real-time services, and develop frameworks in which these, and future, research efforts can be considered. >",data oriented architecture,201
9ea9411fa553275a9f3bc5b1467cebedd5c554a4,filtered,semantic_scholar,IEEE Commun. Mag.,35796,semantic_scholar,a programmable transport architecture with qos guarantees,https://www.semanticscholar.org/paper/9ea9411fa553275a9f3bc5b1467cebedd5c554a4,"The emergence of distributed multimedia applications exhibiting significantly more stringent quality of service requirements than conventional data-oriented applications calls for new transport protocols with different characteristics to coexist and be integrated within single applications. The different delivery requirements posed by these diverse multimedia applications often imply the need for highly customized protocol implementations. Hence, application developers are faced with the threat of code obsolescence caused by the development of even newer delivery techniques. We present an object-oriented transport architecture that allows for dynamically binding a variety of protocol stacks on a per-call basis. By binding protocol stacks together, the special needs of the application can be met without the need to rewrite the code. This differs significantly from the traditional transport architecture which assumes preinstalled transport protocol stacks that cannot be customized. To illustrate some of the advantages provided by the architecture, we describe the transport component of the first reference implementation of the 150 MPEG-4 Delivery Multimedia Integration Framework and demonstrate how quickly it was implemented in our framework.",data oriented architecture,202
1112c1cd0e7b0c96a1f5231bd1767603466d4300,filtered,semantic_scholar,CIDR,38718,semantic_scholar,turning cluster management into data management; a system overview,https://www.semanticscholar.org/paper/1112c1cd0e7b0c96a1f5231bd1767603466d4300,"This paper introduces the CondorJ2 cluster management system. Traditionally, cluster management systems such as Condor employ a process-oriented approach with little or no use of modern database system technology. In contrast, CondorJ2 employs a data-centric, 3-tier web-application architecture for all system functions (e.g., job submission, monitoring and scheduling; node configuration, monitoring and management, etc.) except for job execution. Employing a data-oriented approach allows the core challenge (i.e., managing and coordinating a large set of distributed computing resources) to be transformed from a relatively low-level systems problem into a more abstract, higher-level data management problem. Preliminary results suggest that CondorJ2’s use of standard 3-tier software represents a significant step forward to the design and implementation of large clusters (1,000 to 10,000 nodes).",data oriented architecture,203
ff156dca361d06d6ddc4754fd208d84bfe7d6bb4,filtered,semantic_scholar,,42370,semantic_scholar,information-centric networks (icn),https://www.semanticscholar.org/paper/ff156dca361d06d6ddc4754fd208d84bfe7d6bb4,"During the past decades, serious efforts have been made to propose various architectures for the future Internet. Each of those architectures has one thing in common, i.e., to focus on content delivery rather than on host-centric approaches. However, only few of them gained popularity due to their possible applications being investigated. In this chapter, we describe the overview of various future Internet architectures such as data-oriented networking architecture, content-centric networking, named-data networking, publish/subscribe, and network of information. The main objective of this chapter is to allow our readers to become familiar with the transformation of these architectures.",data oriented architecture,204
96be97fc6ec58a35601ada2e353e17b1afa09335,filtered,semantic_scholar,IEEE J. Sel. Areas Commun.,37622,semantic_scholar,a summary of the hornet project: a next-generation metropolitan area network,https://www.semanticscholar.org/paper/96be97fc6ec58a35601ada2e353e17b1afa09335,"Metropolitan area networks are currently undergoing an evolution aimed at more efficiently transport of data-oriented traffic. However, the incoming generation of metro networks is based on conventional technology, which prevents them scaling cost-effectively to ultrahigh capacities. We have developed a new architecture and set of protocols for the next generation of metro networks. The architecture, named HORNET (hybrid optoelectronic ring network), is a packet-over-wavelength-division multiplexing ring network that utilizes fast-tunable packet transmitters and wavelength routing to enable it to scale cost-effectively to ultrahigh capacities. A control-channel-based media access control (MAC) protocol enables the network nodes to share the bandwidth of the network while preventing collisions. The MAC protocol is designed to transport variable-sized packets and to provide fairness control to all network end users. The efficiency and the fairness of the MAC protocol is demonstrated with custom-designed simulations. The implementation of the MAC protocol and the survivability of the network have been demonstrated in a laboratory experimental testbed. The article summarizes the accomplishments of the HORNET project, including the design, analysis, and demonstration of a metro architecture and a set of protocols. The HORNET architecture is an excellent candidate for next-generation high-capacity metro networks.",data oriented architecture,205
4587979e037cce59feb86f54411c25e949ec555d,filtered,semantic_scholar,2010 IEEE Second International Conference on Cloud Computing Technology and Science,40179,semantic_scholar,dynamic request allocation and scheduling for context aware applications subject to a percentile response time sla in a distributed cloud,https://www.semanticscholar.org/paper/4587979e037cce59feb86f54411c25e949ec555d,"We consider geographically distributed data centers forming a collectively managed cloud computing system, hosting multiple Service Oriented Architecture (SOA) based context aware applications, each subject to Service Level Agreements (SLA). The Service Level Agreements for each context aware application require the response time of a certain percentile of the input requests to be less than a specified value for a profit to be charged by the cloud provider. We present a novel approach of data-oriented dynamic service-request allocation with gi-FIFO scheduling, in each of the geographically distributed data centers, to globally increase the profit charged by the cloud computing system. Our evaluation shows that our dynamic scheme far outperforms the commonly deployed static allocation with either First in First Out (FIFO) or Weighted Round Robin (WRR) scheduling.",data oriented architecture,206
8cc03eadb1c418dd2b927fcb5a3717fad8982033,filtered,semantic_scholar,MIS Q.,40544,semantic_scholar,design and implementation of decision support systems in the public sector,https://www.semanticscholar.org/paper/8cc03eadb1c418dd2b927fcb5a3717fad8982033,"This article examines the implications of utilizing decision support systems (DSS) in the public sector based on a DSS developed and implemented for a community mental health system. The DSS includes a multiple objective (goal programming) allocation model and encompasses a multiple party decision process. The experiences and insights acquired during the development and implementation of this DSS are relevant to public sector decision support in general. The importance of a DSS as a process-support aid rather than a product-oriented aid (i.e., simply providing answers) and the interaction of system architecture and the chosen design strategy are key insights. In particular, the distinction between model-oriented and data-oriented DSS does not appear to be appropriate. The public sector decision maker's concern with issues of equity requires the ability to operate in a higher dimensional framework than the typical spreadsheet model and there is a critical need for communication support.",data oriented architecture,207
ea835ee626baa1d719a54206f4af3f5e6349173e,filtered,semantic_scholar,Third IEEE International Conference on Data Mining,37622,semantic_scholar,a dynamic adaptive self-organising hybrid model for text clustering,https://www.semanticscholar.org/paper/ea835ee626baa1d719a54206f4af3f5e6349173e,"Clustering by document concepts is a powerful way of retrieving information from a large number of documents. This task in general does not make any assumption on the data distribution. For this task we propose a new competitive self-organising (SOM) model, namely the dynamic adaptive self-organising hybrid model (DASH). The features of DASH are a dynamic structure, hierarchical clustering, nonstationary data learning and parameter self-adjustment. All features are data-oriented: DASH adjusts its behaviour not only by modifying its parameters but also by an adaptive structure. The hierarchical growing architecture is a useful facility for such a competitive neural model which is designed for text clustering. We have presented a new type of self-organising dynamic growing neural network which can deal with the nonuniform data distribution and the nonstationary data sets and represent the inner data structure by a hierarchical view.",data oriented architecture,208
911120ae7b436fce58e857b860dfdd04ca1823f7,filtered,semantic_scholar,CoNEXT '08,39448,semantic_scholar,incentive-compatible caching and peering in data-oriented networks,https://www.semanticscholar.org/paper/911120ae7b436fce58e857b860dfdd04ca1823f7,"Several new, data-oriented internetworking architectures have been proposed recently. However, the practical deployability of such designs is an open question. In this paper, we consider data-oriented network designs in the light of the policy and incentive structures of the present internetworking economy. A main observation of our work is that none of the present proposals is both policy-compliant and incentive-compatible with the current internetworking market, which makes their deployment very challenging if not impossible. This difficulty stems from the unfounded implicit assumption that data-oriented routing policies directly reflect the underlying packet-level inter-domain policies. We find that to enable the more effective network utilization promised by data-oriented networking, essential caching incentives need to exist, and that data-oriented peering needs be considered separately from peering for packet forwarding.",data oriented architecture,209
da5b5e36c8b2ee9f1637f1f5ca0f979e3ed40319,filtered,semantic_scholar,2013 IEEE 29th Symposium on Mass Storage Systems and Technologies (MSST),41275,semantic_scholar,enabling cost-effective data processing with smart ssd,https://www.semanticscholar.org/paper/da5b5e36c8b2ee9f1637f1f5ca0f979e3ed40319,"This paper explores the benefits and limitations of in-storage processing on current Solid-State Disk (SSD) architectures. While disk-based in-storage processing has not been widely adopted, due to the characteristics of hard disks, modern SSDs provide high performance on concurrent random writes, and have powerful processors, memory, and multiple I/O channels to flash memory, enabling in-storage processing with almost no hardware changes. In addition, offloading I/O tasks allows a host system to fully utilize devices' internal parallelism without knowing the details of their hardware configurations. To leverage the enhanced data processing capabilities of modern SSDs, we introduce the Smart SSD model, which pairs in-device processing with a powerful host system capable of handling data-oriented tasks without modifying operating system code. By isolating the data traffic within the device, this model promises low energy consumption, high parallelism, low host memory footprint and better performance. To demonstrate these capabilities, we constructed a prototype implementing this model on a real SATA-based SSD. Our system uses an object-based protocol for low-level communication with the host, and extends the Hadoop MapReduce framework to support a Smart SSD. Our experiments show that total energy consumption is reduced by 50% due to the low-power processing inside a Smart SSD. Moreover, a system with a Smart SSD can outperform host-side processing by a factor of two or three by efficiently utilizing internal parallelism when applications have light trafic to the device DRAM under the current architecture.",data oriented architecture,210
72fb63afa01d87aab9b6070ab8b45c2ba308a962,filtered,semantic_scholar,HotNets-X,40544,semantic_scholar,information-centric networking: seeing the forest for the trees,https://www.semanticscholar.org/paper/72fb63afa01d87aab9b6070ab8b45c2ba308a962,"There have been many recent papers on data-oriented or content-centric network architectures. Despite the voluminous literature, surprisingly little clarity is emerging as most papers focus on what differentiates them from other proposals. We begin this paper by identifying the existing commonalities and important differences in these designs, and then discuss some remaining research issues. After our review, we emerge skeptical (but open-minded) about the value of this approach to networking.",data oriented architecture,211
3217ddafee28cd2a7db9cff8aa69051e56373da6,filtered,semantic_scholar,,34700,semantic_scholar,coordination approaches for cim,https://www.semanticscholar.org/paper/3217ddafee28cd2a7db9cff8aa69051e56373da6,"We propose a general architecture for Computer Integrated Manufacturing (CIM) based on the coordination, rather than integration, of component systems. The coordination process is achieved through inter-system dependencies controlled by a central, global coordinator. Coordination, like integration, may be either data- or application-oriented. In the case of data-oriented coordination, multidatabase technologies may be exploited to maintain global data consistency. For application-oriented coordination, the global coordinator uses operational dependencies as a basis for the invocation of methods in remote systems. We examine each of these orientations in detail and then provide a comparison of approaches. Specifically, we describe two prototype systems developed in the context of the CIM/Z project.",data oriented architecture,212
fd5324394d82b42bc33c10725d41ca36d2ef06dd,filtered,semantic_scholar,ESSoS,41275,semantic_scholar,a fully homomorphic crypto-processor design,https://www.semanticscholar.org/paper/fd5324394d82b42bc33c10725d41ca36d2ef06dd,"A KPU is a replacement for a standard CPU that natively runs encrypted machine code on encrypted data in registers and memory --- a 'crypto-processor unit', in other words. Its computations are opaque to an observer with physical access to the processor but remain meaningful to the owner of the computation. In theory, a KPU can be run in simulation and remain as secure (or otherwise) as in hardware. Any block cipher with a block-size of about a word is compatible with this developing technology, the long-term aim of which is to make it safe to entrust data-oriented computation to a remote environment. 
 
Hardware is arranged in a KPU to make the chosen cipher behave as a mathematical homomorphism with respect to computer arithmetic. We describe the architecture formally here and show that 'type-safe' programs run correctly when encrypted.",data oriented architecture,213
5db571319ba286b52ef2da85bca2c5ed2f389140,filtered,semantic_scholar,8th International Conference for Internet Technology and Secured Transactions (ICITST-2013),41275,semantic_scholar,access control enforcement in named data networking,https://www.semanticscholar.org/paper/5db571319ba286b52ef2da85bca2c5ed2f389140,"Named Data Networking (NDN) represents one of the major Information Centric Networking (ICN) candidates for future Internet architectures. It treats data as the central element and it leverages in-network caching. Access control is a fundamental security feature in this project. It limits data access to only authorized entities. However, it can no longer be tied to a content location or to a particular host, since multiple copies of a same data can reside in various network locations. Therefore, a data-oriented access control model must be adopted. In this paper, we propose an encryption-based access control scheme for NDN that allows encrypted content to freely reside anywhere in the network. This proposal represents an enhancement of the solution already implemented in the actual NDN prototype, CCNx. It is based on a new cryptographic model for access rights management and on an adaptation of the naming system. It mitigates identified attacks and it reduces the overhead cost.",data oriented architecture,214
ac3df9cff34e5b9331a114c70d5e308f03370bfd,filtered,semantic_scholar,"2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems",42005,semantic_scholar,a data-oriented method for scheduling dependent tasks on high-density multi-gpu systems,https://www.semanticscholar.org/paper/ac3df9cff34e5b9331a114c70d5e308f03370bfd,"The rapidly-changing computer architectures, though improving the performance of computers, have been challenging the programming environments for efficiently harnessing the potential of novel architectures. In this area, though the high-density multi-GPU architecture enabled unparalleled performance advantage of dense GPUs in a single server, it has increased the difficulty for scheduling diversified and dependent tasks. We therefore propose a data-oriented method for scheduling dependent tasks for this architecture while providing its implementation. In our method, we model a parallel program as a collection of data-dependent tasks for which data dependencies are managed by an expressive matrix. Accordingly, we develop a hierarchical scheduler infrastructure for our model. In this, a top scheduler is built for querying the data-dependency matrix; three downstream schedulers for queuing computation tasks that are exclusively assigned to processor, accelerator or either; and a multitude of bottom schedulers each for providing a processing element with assigned tasks. We experiment our scheduler for examples of Strassen matrix multiplication and Cholesky matrix inversion algorithms on a computer that has 8 Tesla K40 GPUs. The results show that our method is capable of offering the efficient task parallelism while fulfilling the complex task dependencies. When advanced task-oriented schedulers have been widely designed for distributed systems, a lightweight data-driven scheduler could be an alternative and handy approach that can handle the dependent yet diversified tasks of data-intensive applications for the novel high-density multi-accelerator system.",data oriented architecture,215
74a19494211ac2d7e1cec4d6de8652a1b21a44b9,filtered,semantic_scholar,Proceedings 12th International Workshop on Rapid System Prototyping. RSP 2001,36892,semantic_scholar,a dynamically reconfigurable architecture for embedded systems,https://www.semanticscholar.org/paper/74a19494211ac2d7e1cec4d6de8652a1b21a44b9,"The Internet is becoming one of the key features of tomorrow's communication world. The evolution of mobile telephone networks, such as UMTS, will soon allow everyone to be connected everywhere. These new network technologies bring the ability to deal not only with classical voice or text messages, but also with improved content, i.e. multimedia. At the mobile level, this kind of data-oriented content requires highly efficient architectures; and nowadays, embedded system-on-chip solutions are no longer able to manage critical constraints like area, power and data-computing efficiency. In this paper, we propose a new, dynamically reconfigurable network, dedicated to data-oriented applications such as, for instance, one targeted on third-generation networks. Principles, realisations and comparative results are exposed for some classical applications, targeted on different architectures.",data oriented architecture,216
f66df4762da27773e3a6ed820665aa74d4db0e76,filtered,semantic_scholar,2018 IEEE European Symposium on Security and Privacy (EuroS&P),43101,semantic_scholar,security risks in asynchronous web servers: when performance optimizations amplify the impact of data-oriented attacks,https://www.semanticscholar.org/paper/f66df4762da27773e3a6ed820665aa74d4db0e76,"Over the past decade, many innovations have been achieved with respect to improving the responsiveness of highly-trafficked servers. These innovations are fueled by a desire to support complex and data-rich web applications while consuming minimal resources. One of the chief advancements has been the emergence of the asynchronous web server architecture, which is built from the ground up for scalability. While this architecture can offer a significant boost in performance over classic forking servers, it does so at the cost of abandoning memory space isolation between client interactions. This shift in design, that delegates the handling of many unrelated requests within the same process, enables powerful and covert data-oriented attacks that rival complete web server takeover — without ever hijacking the control flow of the server application. To demonstrate the severity of this threat, we present a technique for identifying security-critical web server data by tracing memory accesses committed by the program in generating responses to client requests. We further develop a framework for performing live memory analysis of a running server in order to understand how low-level memory structures can be corrupted for malicious intent. A fundamental goal of our work is to assess the realism of such data-oriented attacks in terms of the types of memory errors that can be leveraged to perform them, and to understand the prominence of these errors in real-world web servers. Our case study on a leading asynchronous architecture, namely Nginx, shows how dataoriented attacks allow an adversary to re-configure an Nginx instance on the fly in order to degrade or disable services (e.g., error reporting, security headers like HSTS, access control), steal sensitive information, as well as distribute arbitrary web content to unsuspecting clients — all by manipulating only a few bytes in memory. Our empirical findings on the susceptibility of modern asynchronous web servers to two wellknown CVEs show that the damage could be severe. To address this threat, we also discuss several potential mitigations. Taken as a whole, our work tells a cautionary tale regarding the risks of blindly pushing forward with performance optimizations.",data oriented architecture,217
0790af19ce0f479f822b890388791cfd3ebfe276,filtered,semantic_scholar,,35796,semantic_scholar,the wasa approach to workflow management for scientific applications,https://www.semanticscholar.org/paper/0790af19ce0f479f822b890388791cfd3ebfe276,"Workflow management has gained increasing attention recently, since it allows one to combine a data-oriented view on applications, which is the traditional one for an information system, with a process-oriented one in which activities and their occurrences over time are modeled and supported properly. While workflow management has mostly been considered in business applications so far, the focus of the WASA project is on scientific applications such as geoprocessing, molecular biology, or laboratory environments. In particular, WASA aims at flexible and platform-independent workflow support, with respect to both specification and execution of workflows. It turns out that the modeling and execution of workflows in traditional and in scientific applications exhibit significant differences. In particular, the need for dynamic modifications of workflow models while workflows are running is an important feature in scientific applications. Observations like these have resulted in a generic WASA architecture, which can be tailored towards various specific application domains. The conceptual design and functionality of a WASA prototype is outlined, in particular that of its core workflow engine, and it is shown how the requirements of flexibility in modeling and executing workflows, imposed by scientific applications, are met by this prototype.",data oriented architecture,218
3c43e848a6cf8f90c17298d6298ce0b58007881e,filtered,semantic_scholar,,40909,semantic_scholar,generic adaptation framework for unifying adaptive web-based systems,https://www.semanticscholar.org/paper/3c43e848a6cf8f90c17298d6298ce0b58007881e,"The Generic Adaptation Framework (GAF) research project first and foremost creates a common formal framework for describing current and future adaptive hypermedia (AHS) and adaptive webbased systems in general. It provides a commonly agreed upon taxonomy and a reference model that encompasses the most general architectures of the present and future, including conventional AHS, and different types of personalization-enabling systems and applications such as recommender systems (RS) personalized web search, semantic web enabled applications used in personalized information delivery, adaptive e-Learning applications and many more. At the same time GAF is trying to bring together two (seemingly not intersecting) views on the adaptation: a classical pre-authored type, with conventional domain and overlay user models and data-driven adaptation which includes a set of data mining, machine learning and information retrieval tools. To bring these research fields together we conducted a number GAF compliance studies including RS, AHS, and other applications combining adaptation, recommendation and search. We also performed a number of real systems’ case-studies to prove the point and perform a detailed analysis and evaluation of the framework. Secondly it introduces a number of new ideas in the field of AH, such as the Generic Adaptation Process (GAP) which aligns with a layered (data-oriented) architecture and serves as a reference adaptation process. This also helps to understand the compliance features mentioned earlier. Besides that GAF deals with important and novel aspects of adaptation enabling and leveraging technologies such as provenance and versioning. The existence of such a reference basis should stimulate AHS research and enable researchers to demonstrate ideas for new adaptation methods much more quickly than if they had to start from scratch. GAF will thus help bootstrap any adaptive web-based system research, design, analysis and evaluation.",data oriented architecture,219
63c7863fcba665bb8b87ee7f204ec79dcd60ba9a,filtered,semantic_scholar,2020 IEEE Symposium on Security and Privacy (SP),43831,semantic_scholar,xmp: selective memory protection for kernel and user space,https://www.semanticscholar.org/paper/63c7863fcba665bb8b87ee7f204ec79dcd60ba9a,"Attackers leverage memory corruption vulnerabilities to establish primitives for reading from or writing to the address space of a vulnerable process. These primitives form the foundation for code-reuse and data-oriented attacks. While various defenses against the former class of attacks have proven effective, mitigation of the latter remains an open problem. In this paper, we identify various shortcomings of the x86 architecture regarding memory isolation, and leverage virtualization to build an effective defense against data-oriented attacks. Our approach, called xMP, provides (in-guest) selective memory protection primitives that allow VMs to isolate sensitive data in user or kernel space in disjoint xMP domains. We interface the Xen altp2m subsystem with the Linux memory management system, lending VMs the flexibility to define custom policies. Contrary to conventional approaches, xMP takes advantage of virtualization extensions, but after initialization, it does not require any hypervisor intervention. To ensure the integrity of in-kernel management information and pointers to sensitive data within isolated domains, xMP protects pointers with HMACs bound to an immutable context, so that integrity validation succeeds only in the right context. We have applied xMP to protect the page tables and process credentials of the Linux kernel, as well as sensitive data in various user-space applications. Overall, our evaluation shows that xMP introduces minimal overhead for real-world workloads and applications, and offers effective protection against data-oriented attacks.",data oriented architecture,220
bdd38349d22ab12ddd44a500d5720853ee17286b,filtered,semantic_scholar,2012 IEEE International Conference on Communications (ICC),40909,semantic_scholar,traffic engineering for information-centric networks,https://www.semanticscholar.org/paper/bdd38349d22ab12ddd44a500d5720853ee17286b,"Information-centric networking (ICN) proposes a networking architecture that uses methodologies such as publish-subscribe to achieve a data-oriented approach as opposed to a destination based approach found in the current Internet. This new architecture brings both new problems to be solved and also natural solutions to existing problems. This paper investigates an intra-domain traffic engineering (TE) problem for an information-centric networking (ICN) architecture where a form of source routing is used as the forwarding mechanism. The TE goal is to maximise the residual capacity in the network so that the load is spread evenly. A network flow approach is used and it is shown that the source routing mechanism allows the traffic to be split across multiple paths in a manner that is difficult to achieve using existing IP or IP/MPLS networks. Allowing splittable flows means that a fully polynomial-time approximation scheme can be used that has superior results when compared to existing constraint based routing schemes for flows that cannot be split. Consequently, this work demonstrates that the ICN architecture can simplify the given TE problem in a natural manner.",data oriented architecture,221
536ab937378e5965f8687b5bf29af2e360aac3bb,filtered,semantic_scholar,2006 ieee/aiaa 25TH Digital Avionics Systems Conference,38718,semantic_scholar,system-wide information management (swim) demonstration security architecture,https://www.semanticscholar.org/paper/536ab937378e5965f8687b5bf29af2e360aac3bb,"System-wide information management (SWIM) is a Federal Aviation Administration (FAA) network-centric environment that facilitates software application integration in the National Airspace System (NAS). Built on a set of five core service types - interfaces, registries, message brokers, information assurance and system management - SWIM accelerates NAS evolution by defining a secure common infrastructure for application integration and a framework for information modeling and exchange. Providing information security in this distributed network-centric environment is a significant challenge. System users must be confident that their critical data is protected. Competing requirements, the transportation of sensitive data and air-to-ground bandwidth constraints mean that a network layer-based approach to security is no longer sufficient. Trusted security at every layer of a network-centric architecture - combined with strong identity management and a data-oriented approach to information assurance - is the key to success. This paper introduces the FAA SWIM demonstration security architecture, and explores some of the methods and mechanisms used to provide end-to-end security, confidentiality, integrity, availability and privacy for NAS applications and their users",data oriented architecture,222
b728578e4b46a145a24cf02a2f5b70c01eb9b78a,filtered,semantic_scholar,FM,38353,semantic_scholar,verification of a signature architecture with hol-z,https://www.semanticscholar.org/paper/b728578e4b46a145a24cf02a2f5b70c01eb9b78a,"We report on a case study in using HOL-Z, an embedding of Z in higher-order logic, to specify and verify a security architecture for administering digital signatures. We have used HOL-Z to formalize and combine both data-oriented and process-oriented architectural views. Afterwards, we formalized temporal requirements in Z and carried out verification in higher-order logic. 
 
The same architecture has been previously verified using the SPIN model checker. Based on this, we provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with rich data. Moreover, our comparison highlights the advantages of this approach and provides evidence that, in the hands of experienced users, theorem proving is neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,223
fee36f1cbb7047ef8519221492a7a3620910d62c,filtered,semantic_scholar,,36161,semantic_scholar,engineering parallel symbolic programs in gph,https://www.semanticscholar.org/paper/fee36f1cbb7047ef8519221492a7a3620910d62c,"We investigate the claim that functional languages offer low-cost parallelism in the context of symbolic programs on modest parallel architectures. In our investigation we present the first comparative study of the construction of large applications in a parallel functional language, in our case in Glasgow Parallel Haskell (GPH). The applications cover a range of application areas, use several parallel programming paradigms, and are measured on two very different parallel architectures. 
 
On the applications level the most significant result is that we are able to achieve modest wall-clock speedups (between factors of 2 and 10) over the optimised sequential versions for all but one of the programs. Speedups are obtained even for programs that were not written with the intention of being parallelised. These gains are achieved with a relatively small programmer-effort. One reason for the relative ease of parallelisation is the use of evaluation strategies, a new parallel programming technique that separates the algorithm from the co-ordination of parallel behaviour. 
 
On the language level we show that the combination of lazy and parallel evaluation is useful for achieving a high level of abstraction. In particular we can describe top-level parallelism, and also preserve module abstraction by describing parallelism over the data structures provided at the module interface (‘data-oriented parallelism’). Furthermore, we find that the determinism of the language is helpful, as is the largely implicit nature of parallelism in GPH. Copyright © 1999 John Wiley & Sons, Ltd.",data oriented architecture,224
f0c611b788794234c65bb32b4f748a17bd6cebbd,filtered,semantic_scholar,,42736,semantic_scholar,digital economy: conceptual architecture of a digital economic sector ecosystem,https://www.semanticscholar.org/paper/f0c611b788794234c65bb32b4f748a17bd6cebbd,"Yury M. Akatkin - Head of Laboratory of Social-Demographic Statistics, Plekhanov Russian University of EconomicsAddress: 36, Stremyanny Lane, Moscow, 117997, Russian FederationE-mail: u.akatkin@semanticpro.orgOleg E. Karpov - Corresponding Member, Russian Academy of Sciences; General Director of Pirogov National Medical-Surgical CenterAddress: 70, Nizhnyaya Pervomaiskaya Street, Moscow, 105203, Russian FederationE-mail: nmhc@mail.ruValery A. Konyavskiy - Head of Information Security Department, Moscow Institute of Physics and TechnologyAddress: 1A, Kerchenskaya Street, Moscow, 117303, Russian FederationE-mail: konyavskiy@gospochta.ruElena D. Yasinovskaya - Senior Researcher, Laboratory of Social-Demographic Statistics, Plekhanov Russian University of EconomicsAddress: 36, Stremyanny Lane, Moscow, 117997, Russian FederationE-mail: elena@semanticpro.org The main objective of digital transformation is to fulfill the needs of a “new digital generation customer” for on-demand delivery, quality and personalization. ”Anything as a service” has become the key principle of the digital paradigm. This is about a data-oriented service which relies on sharing information resources (including public ones) and the requirements for interoperability, security and trust. This paper presents the main approaches to digital transformation based on the example of the most innovatively active sectors such as banking and healthcare. We compare the proprietary development of digital services (products) to the building of a digital sector ecosystem aimed at attracting an unlimited number of participants. We defined the purpose of creating an ecosystem that is to provide the population with digital services formed on demand, in real time, in compliance with legislation and regulations, as well as in the context of maximum trust. We emphasize the role of openness for uniting the efforts of the community interested in the development of a digital industry, extension of public-private partnerships and building a competitive environment in order to ensure the rapid growth of available digital services, as well as to improve their quality. Since the knowledge economy is the basis for the digital economy, the authors consider it especially important to form a semantic core which acts as the carrier of knowledge in a digital sector ecosystem. We confirmed the necessity to implement the semantic core by a brief analysis of modern semantic approaches to standardization of information sharing in the above-mentioned industries, such as FIBO, BIAN (banking), HL7 and UMLS (health). The research carried out allowed the authors to design the conceptual architecture of the ecosystem and to suggest several proposals for digital transformation of an industry. The proposals express the necessity of state support for innovation and providing the conditions for the entry of new digital products based on the following principles: accessibility, timeliness, personalization, adaptability and security.",data oriented architecture,225
449b756485d77d452b0cc0805b1a7a6767d8f525,filtered,semantic_scholar,IEEE Transactions on Industrial Informatics,42736,semantic_scholar,iot-based techniques for online m2m-interactive itemized data registration and offline information traceability in a digital manufacturing system,https://www.semanticscholar.org/paper/449b756485d77d452b0cc0805b1a7a6767d8f525,"The integration of internet-of-things (IoT) technologies in the industry benefits digital manufacturing applications by allowing ubiquitous interaction and collaborative automation between machines. Online data collection and data interaction are critical for real-time decision making and machine collaborations. However, due to the specificity of digital manufacturing applications, the technical gap between IoT techniques and practical machine operation could hinder the efficient data interactions, collaborations between machines, and the effectiveness as well as the accuracy of itemized data collection. This investigation, therefore, identifies some major technical problems and challenges that current IoT-based digital manufacturing is facing, and proposes a method to bridge the technical gap for itemized product management. The highlights of this investigation are: 1) a data-oriented system architecture toward flexible data interaction between machines, 2) a customized machine-to-machine protocol for machine discovery, presence, and messaging, (3) flexible data structure and data presentation for interoperability, and (4) versatile information tracing approaches for product management. The proposed solutions have been implemented in PicknPack digital food manufacturing line, and achieved ubiquitous data interaction, online data collection, and versatile product information tracing methods have shown the feasibility and significance of the presented methods.",data oriented architecture,226
63f8e385951558e9c6b49cb4c83098b09ed704e3,filtered,semantic_scholar,2013 International Conference on Advanced Cloud and Big Data,41275,semantic_scholar,a mechanism of information-centric networking based on data centers,https://www.semanticscholar.org/paper/63f8e385951558e9c6b49cb4c83098b09ed704e3,"Information-centric networking (ICN) aims to make the Internet more data-oriented or content-centric, thus name-based routing and universal caching are used to change the way users requesting and fetching content, as well as to improve network performance. However, current implementation mechanisms define some kinds of ""clean-slate"" architecture and certain brand new technologies need to be designed and implemented. In this paper, some requisites reflecting ICN's essential ingredients are generalized, and based on the OpenFlow and the data center technologies, a mechanism called odICN, which can satisfy those aforementioned requisites, is proposed together with its algorithmic framework. Finally, a prototype of odICN is built to verify its feasibility.",data oriented architecture,227
9703eec800ca2f2cbbcdb8edc565da15ba15af8c,filtered,semantic_scholar,Formal Aspects of Computing,39083,semantic_scholar,verifying a signature architecture: a comparative case study,https://www.semanticscholar.org/paper/9703eec800ca2f2cbbcdb8edc565da15ba15af8c,"We report on a case study in applying different formal methods to model and verify an architecture for administrating digital signatures. The architecture comprises several concurrently executing systems that authenticate users and generate and store digital signatures by passing security relevant data through a tightly controlled interface. The architecture is interesting from a formal-methods perspective as it involves complex operations on data as well as process coordination and hence is a candidate for both data-oriented and process-oriented formal methods.We have built and verified two models of the signature architecture using two representative formal methods. In the first, we specify a data model of the architecture in Z that we extend to a trace model and interactively verify by theorem proving. In the second, we model the architecture as a system of communicating processes that we verify by finite-state model checking. We provide a detailed comparison of these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking). Contrary to common belief, our case study suggests that Z is well suited for temporal reasoning about process models with complex operations on data. Moreover, our comparison highlights the advantages of proving theorems about such models and provides evidence that, in the hands of an experienced user, theorem proving may be neither substantially more time-consuming nor more complex than model checking.",data oriented architecture,228
62bdf319dcb9743d8abe61d5ba3f4e2180092a2e,filtered,semantic_scholar,IEEE Wireless Communications,42005,semantic_scholar,video delivery in heterogenous crans: architectures and strategies,https://www.semanticscholar.org/paper/62bdf319dcb9743d8abe61d5ba3f4e2180092a2e,"Video traffic has become a major part of mobile data traffic, and will keep growing in the coming years. The performance of video delivery is fundamentally constrained by the structure of the underlying wireless networks. The recently proposed heterogeneous cloud access networks have been widely recognized as an inevitable evolution trend of the current cellular system toward the future 5G system, where multiple hybrid radio access technologies coexist to provide flexible access for mobile users. As a key enabling functional block for high-performance video delivery, a powerful centralized baseband processing unit pool is adopted to control all the radio access technologies, and possibly facilitate the video encoding and transmission, which opens up the potential to achieve higher throughput, lower traffic delay, and greater robustness compared to its basic baseband processing unit counterpart without central control functions. However, such a centralized control framework also raises many new research challenges to be addressed. In this article, we provide an overview of the state-of-the-art video delivery architectures and video packet transmission strategies in heterogeneous cloud radio access networks, with highlights on the networking architectures, transmission strategies, performance analysis, and design challenges. This article also sheds some light on the design principles for future big-data-oriented wireless networks.",data oriented architecture,229
12dce201e344849e31e8ccbfab114108f046c243,filtered,semantic_scholar,Proceedings Tenth IEEE International Workshop on Rapid System Prototyping. Shortening the Path from Specification to Prototype (Cat. No.PR00246),36161,semantic_scholar,mixed abstraction level hardware synthesis from sdl for rapid prototyping,https://www.semanticscholar.org/paper/12dce201e344849e31e8ccbfab114108f046c243,"SDL is currently gaining interest as a system level specification language for HW/SW codesign. Automated synthesis of SDL in hardware so far had problems with its efficiency. The investigations on the resource usage of SDL-to-VHDL designs presented in this paper identify two key challenges: minimizing the overhead introduced by SDL process infrastructure, and choosing the appropriate synthesis method. This paper presents a framework for SDL hardware synthesis where VHDL code generation, high-level synthesis and RT-level synthesis are combined. A configurable run-time environment implements services like data handling and message passing in efficient, hand-coded library components, which take into account properties of the target architecture. For these components RT-level synthesis was found to be suitable. The behavior of each SDL process on the other hand is freely specified by the system designer. Depending on the type of application, i.e. complex data-oriented or control-oriented either high-level synthesis, RT-level synthesis, or a combination of both can prove to be optimal.",data oriented architecture,230
38450d945f8ca0fd66a088bb042ed30ed3b3ee84,filtered,semantic_scholar,Int. J. Distributed Sens. Networks,41275,semantic_scholar,integrating sensor networks for energy monitoring with service-oriented architectures,https://www.semanticscholar.org/paper/38450d945f8ca0fd66a088bb042ed30ed3b3ee84,"More accurate predictions of energy consumption are a strong motivator for utility providers to deploy a smart grid infrastructure. However, measurements which only reflect the consumption of a household lose the details associated with the behaviour of individual devices. Finding a flexible and efficient way to process these readings is essential. Using standard application techniques to integrate device-oriented sensor networks and data-oriented applications is a serious challenge due to the architectural gap between the different approaches. Additionally, this device-level information should be shared with the end-users in a trusted manner to increase their energy awareness. We propose a novel platform for the smart grid which enables the seamless integration of sensor networks with a service-oriented architecture approach. The platform hides the device-specific details from the applications and transforms data into a device-independent format. Specifically, we present an in-depth description of the architecture of our platform and a full implementation and evaluation of it in a live residential energy management deployment.",data oriented architecture,231
aa7ca35bd3a85a1afa99783835d019f486511657,filtered,semantic_scholar,,35065,semantic_scholar,residential data services via hybrid fiber-coax local access networks,https://www.semanticscholar.org/paper/aa7ca35bd3a85a1afa99783835d019f486511657,"The deployment of two-way broadband hybrid fiber-coax (HFC) local access networks will enable a wide variety of new communication services for consumers and small businesses. Interactive television, video-on-demand, video telephony, and other services focused on TV and video have attracted much attention. Broadband local access networks also offer compelling data-oriented services that support computers and other devices in homes and small businesses. This paper gives an overview of these new residential data services and applications, the technical challenges involved in their delivery, and architectures and key components of the required networking infrastructure.",data oriented architecture,232
cdb52713b40d7864cbe48af444db56af8f3201dd,filtered,semantic_scholar,International Conference on Internet Computing,37622,semantic_scholar,"an architecture for efficient, flexible enterprise system integration",https://www.semanticscholar.org/paper/cdb52713b40d7864cbe48af444db56af8f3201dd,"Integrating complex enterprise systems is challenging and reliability and performance of the integrated systems can be problematic when using typical solutions of distributed transactions or on-demand message-based querying. We describe a data-oriented approach for enterprise system integration that uses information brokering. A broker application isolates the interactions between a local enterprise application server and a wide variety of remote systems, performing data acquisition, storage, transformation, update and status management. We describe a prototype book brokering system developed using Java 2 Enterprise Edition, CORBA, Java Messaging Service and Web Services and using our integration strategy. We outline the architecture, design and implementation of this prototype and summarise our experiences with this information integration technique.",data oriented architecture,233
8c4150135d16aaba51db505d8281171a7a20f42e,filtered,semantic_scholar,Enterp. Inf. Syst.,42370,semantic_scholar,a new practice-driven approach to develop software in a cyber-physical system environment,https://www.semanticscholar.org/paper/8c4150135d16aaba51db505d8281171a7a20f42e,"Cyber-physical system (CPS) is an emerging area, which cannot work efficiently without proper software handling of the data and business logic. Software and middleware is the soul of the CPS. The software development of CPS is a critical issue because of its complicity in a large scale realistic system. Furthermore, object-oriented approach (OOA) is often used to develop CPS software, which needs some improvements according to the characteristics of CPS. To develop software in a CPS environment, a new systematic approach is proposed in this paper. It comes from practice, and has been evolved from software companies. It consists of (A) Requirement analysis in event-oriented way, (B) architecture design in data-oriented way, (C) detailed design and coding in object-oriented way and (D) testing in event-oriented way. It is a new approach based on OOA; the difference when compared with OOA is that the proposed approach has different emphases and measures in every stage. It is more accord with the characteristics of event-driven CPS. In CPS software development, one should focus on the events more than the functions or objects. A case study of a smart home system is designed to reveal the effectiveness of the approach. It shows that the approach is also easy to be operated in the practice owing to some simplifications. The running result illustrates the validity of this approach.",data oriented architecture,234
0e3bd3672a1964062c528fea878f9771c850f2b9,filtered,semantic_scholar,,40179,semantic_scholar,design and implementation of an efficient data stream processing system,https://www.semanticscholar.org/paper/0e3bd3672a1964062c528fea878f9771c850f2b9,"In standard database scenarios, an end-user assumes that all data (e.g., sensor readings) is stored in a database. Therefore, one can simply submit any arbitrary complex processing in the form of SQL queries or stored procedures to a database server. Data stream oriented applications are typically dealing with huge volumes of data. Storing data and performing off-line processing on this huge dataset can be costly, time consuming and impractical. This work describes our research results while designing and implementing an efficient data management system for online and off-line processing of data streams in the field of environmental monitoring. Our target data sources are wireless sensor networks. Although our focus is on a specific application domain, the results of this thesis are designed in a generic way, so that they can be applied to wide variety of data stream oriented applications. This thesis starts by first presenting the state-of-the-art in data stream processing research specifically window processing concepts, continuous queries, stream filtering query languages and in-network data processing (particular focus on TinyOS-based approaches). We present key existing data stream processing engines, their internal architecture and how they are compared to our platform, namely Global Sensor Network (GSN) middleware. GSN middleware enables fast and flexible deployment and interconnection of sensor networks. It provides simple and uniform access to a comprehensive set of heterogeneous technologies. Additionally, GSN offers zero-programming deployment and data-oriented integration of sensor networks and supports dynamic re-configuration and adaptation at runtime. We present the virtual sensor concept, which offers a high-level view of arbitrary stream data sources, its powerful declarative specification and query tools. Furthermore, we describe design, conceptual, architectural and optimization decisions of GSN platform in detail. In order to achieve high efficiency while processing large volumes of streaming data using window-based continuous queries, we present a set of optimization algorithms and techniques to intelligently group and process different types of continuous queries. While adapting GSN to large scale sensor network deployments, we have encountered several performance bottlenecks. One of the challenges we faced was related to scalable delivery of streaming data for high data rate streams. We found out that we could dramatically improve the performance of a query processor by performing simple grouping of user queries hence sharing both the processing and memory costs among similar queries. Moreover, we encountered a similar performance issue while scheduling continuous queries. Problem of efficiently scheduling the execution of continuous queries with window and sliding parameters is not addressed in depth in literature. This problem becomes severe when one considers large volumes of high data rate streams. In these cases, an efficient query scheduler not only increases the performance at least by an order of magnitude but also, decreases the response time and memory requirements. Finally, we present how our GSN platform can get integrated with an external data sharing and visualization framework namely Microsoft's SenseWeb platform. Microsoft's SenseWeb platform, provides a sensor network data gathering and visualization infrastructure which is globally accessible to the end users. This integration (which is initiated by the Swiss Experiment project and demanded by GSN users) not only shows the scalability of GSN platform when combined with optimized algorithms, but also demonstrates its flexibility.",data oriented architecture,235
5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,filtered,semantic_scholar,ICON 2012,40909,semantic_scholar,application design over named data networking with its features in mind,https://www.semanticscholar.org/paper/5b56f11758fa7e40ef6a3ebf9d7bc8eeff5079fe,"Designed around host-reachability, today’s Internet architecture faces many limitations while serving data-oriented applications, which produce most traffic load to the Internet. Many clean-slate designs of the content/data oriented network have emerged to adapt to these needs. Named Data Networking (also known as CCN) is one of these designs to address these limitations from the fundamental level by building network architecture around named data. In this paper, we identify five key features crucial to application design over Named Data Networking and take the voice conference system as an example to show how this features impact the application design significantly in detail. We identify three major challenges facing current voice conference system and illustrate how NDN could help to solve these challenges. A NDN-based design of voice conference system is presented along with discussing its reliability and congestion control. Keywords-Named Data Networking; Application Design;",data oriented architecture,236
b43f67bc15fd25112aaa9d7378f4952af41206a3,filtered,semantic_scholar,ISPRS Int. J. Geo Inf.,43466,semantic_scholar,interactive and online buffer-overlay analytics of large-scale spatial data,https://www.semanticscholar.org/paper/b43f67bc15fd25112aaa9d7378f4952af41206a3,"Buffer and overlay analysis are fundamental operations which are widely used in Geographic Information Systems (GIS) for resource allocation, land planning, and other relevant fields. Real-time buffer and overlay analysis for large-scale spatial data remains a challenging problem because the computational scales of conventional data-oriented methods expand rapidly with data volumes. In this paper, we present HiBO, a visualization-oriented buffer-overlay analysis model which is less sensitive to data volumes. In HiBO, the core task is to determine the value of pixels for display. Therefore, we introduce an efficient spatial-index-based buffer generation method and an effective set-transformation-based overlay optimization method. Moreover, we propose a fully optimized hybrid-parallel processing architecture to ensure the real-time capability of HiBO. Experiments on real-world datasets show that our approach is capable of handling ten-million-scale spatial data in real time. An online demonstration of HiBO is provided (http://www.higis.org.cn: 8080/hibo).",data oriented architecture,237
7da24e5d96d353e9fcb32247006bf2a9b468ba8e,filtered,semantic_scholar,Inf. Syst. E Bus. Manag.,41275,semantic_scholar,an integrated e-service model for electronic medical records,https://www.semanticscholar.org/paper/7da24e5d96d353e9fcb32247006bf2a9b468ba8e,"In this paper, we discuss the critical issues with the implementation of electronic medical records and argue that the emerging e-services will not fully resolve the issues if they do not work together. To meet the challenge, we propose an integrated e-service model consisting of both process- and data-oriented grids that glue together distributed electronic medical services, records, and application services. We also provide an implementation architecture and prototype that validates the model.",data oriented architecture,238
08eeaab633644ab8d362d57563443bd671963c0c,filtered,semantic_scholar,"2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)",43101,semantic_scholar,tmdfi: tagged memory assisted for fine-grained data-flow integrity towards embedded systems against software exploitation,https://www.semanticscholar.org/paper/08eeaab633644ab8d362d57563443bd671963c0c,"Memory corruption vulnerabilities are main causes of quite a few modern software attacks. Classical Data-flow integrity, which is originally implemented purely on soft-ware platforms, can perform a good security effect against memory corruption attacks, particularly the newly proposed data-oriented programming attacks. However, it introduces high space and time overheads. To tackle these limitations of DFI, in this paper we present tagged memory supported data-flow integrity, TMDFI, a hardware data-flow integrity implementation to enable fine-grained DFI checks with reduced time and space overheads. Our hardware DFI proposal is based on lowRISC, an existing open-source tagged memory architecture targeting a RISC-V core. The tag fields are enlarged and adopted to keep the identifiers for run-time DFI enforcement. We modified the low-RISC architecture by adding a new instruction that performs multiple tags checking simultaneously and changing some native tag manipulation features. We tested our prototype on an RTL emulator. The result shows that the reduction of run-time overhead of a full inter-procedural DFI enforcement is from 104% to 39% and the space overhead shrinks from 50% to 12.5%.",data oriented architecture,239
102b85595c9d0ffddf74517124ad3e9dca61b271,filtered,semantic_scholar,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),43831,semantic_scholar,making iot data ready for smart city applications,https://www.semanticscholar.org/paper/102b85595c9d0ffddf74517124ad3e9dca61b271,"Modern smart city projects are evolving to the next level of data-centric situation awareness and decision makings, thereby requiring much intensive data integration over various data sources made from city space. In order to satisfy a variety of data demands for diverse smart city applications, we have been developing an integrated IoT data service, IoTDA, to provide essential data-oriented services from data collecting to deep learning based data analysis. In this paper, we introduce the overall architecture and functions of the service platform and explain how the platform will be used with a case study of road surface analysis. In particular, we examine how our data service can be connected to public smart city applications and present the common direction that these types of urban data services should provide for advanced city services.",data oriented architecture,240
007351f71380494eefea410bacbe4fc5cfbc8d85,filtered,semantic_scholar,,40544,semantic_scholar,poor man's content centric networking (with tcp),https://www.semanticscholar.org/paper/007351f71380494eefea410bacbe4fc5cfbc8d85,"A number of different architectures have been proposed in support of data-oriented or information-centric networking. Besides a similar visions, they share the need for designing a new networking architecture. We present an incrementally deployable approach to content-centric networking based upon TCP. Content-aware senders cooperate with probabilistically operating routers for scalable content delivery (to unmodified clients), effectively supporting opportunistic caching for time-shifted access as well as de-facto synchronous multicast delivery. Our approach is application protocol-independent and provides support beyond HTTP caching or managed CDNs. We present our protocol design along with a Linux-based implementation and some initial feasibility checks.",data oriented architecture,241
328fb04c4cfe6a90de32041c31810c6d8908e439,filtered,semantic_scholar,IEEE Transactions on Circuits and Systems for Video Technology,40544,semantic_scholar,communication mechanisms and middleware for distributed video surveillance,https://www.semanticscholar.org/paper/328fb04c4cfe6a90de32041c31810c6d8908e439,"A new generation of advanced surveillance systems is being conceived as a collection of multisensor components such as video, audio, and mobile robots interacting in a cooperating manner to enhance situation awareness capabilities to assist surveillance personnel. The prominent issues that these systems face are the improvement of existing intelligent video surveillance systems, the inclusion of wireless networks, the use of low power sensors, the design architecture, the communication between different components, the fusion of data emerging from different type of sensors, the location of personnel (providers and consumers), and the scalability of the system. This paper focuses on the aspects pertaining to real-time distributed architecture and scalability. For example, to meet real-time requirements, these systems need to process data streams in concurrent environments, designed by taking into account scheduling and synchronization. This paper proposes a framework for the design of visual surveillance systems based on components derived from the principles of real-time networks/data-oriented requirements implementation scheme. It also proposes the implementation of these components using the well-known middleware technology common object request broker architecture. Results using this architecture for video surveillance are presented through an implemented prototype.",data oriented architecture,242
80d92bea0bc32f7734df9ccdbb7ae31d85f77bfa,filtered,semantic_scholar,2013 IFIP Networking Conference,41275,semantic_scholar,lessons from the past: why data-driven states harm future information-centric networking,https://www.semanticscholar.org/paper/80d92bea0bc32f7734df9ccdbb7ae31d85f77bfa,"Information-centric networking (ICN) raises data objects to first class routable entities in the network and changes the Internet paradigm from host-centric connectivity to data-oriented publish/subscribe. We revisit the data-centric paradigm from the perspective of security and resilience and question its applicability in an open, widely distributed routing and forwarding service. Current concepts of content routing are built on data-driven protocol events and thereby introduce a strong coupling of the control to the data plane in the underlying routing infrastructure. In this paper, we explore the vulnerability of the distribution backbone. Based on a straight-forward analytical model we show that local systems cannot be protected from the threats of data-driven state management on an Internet scale. By practical evaluations using the example of the CCNx implementation, we further analyze threats to stability and performance of a data-driven infrastructure that refrains from separating the control from the data plane. We identify intrinsic attack vectors, as well as possibilities and limitations to mitigate them. Our overall findings suggest that major architectural refinements are required prior to global ICN deployment in the real world.",data oriented architecture,243
72ce5e9265b4b5c3b4be020cea8ee70b2541526d,filtered,semantic_scholar,CCS,42370,semantic_scholar,"""the web/local"" boundary is fuzzy: a security study of chrome's process-based sandboxing",https://www.semanticscholar.org/paper/72ce5e9265b4b5c3b4be020cea8ee70b2541526d,"Process-based isolation, suggested by several research prototypes, is a cornerstone of modern browser security architectures. Google Chrome is the first commercial browser that adopts this architecture. Unlike several research prototypes, Chrome's process-based design does not isolate different web origins, but primarily promises to protect ""the local system"" from ""the web"". However, as billions of users now use web-based cloud services (e.g., Dropbox and Google Drive), which are integrated into the local system, the premise that browsers can effectively isolate the web from the local system has become questionable. In this paper, we argue that, if the process-based isolation disregards the same-origin policy as one of its goals, then its promise of maintaining the ""web/local system (local)"" separation is doubtful. Specifically, we show that existing memory vulnerabilities in Chrome's renderer can be used as a stepping-stone to drop executables/scripts in the local file system, install unwanted applications and misuse system sensors. These attacks are purely data-oriented and do not alter any control flow or import foreign code. Thus, such attacks bypass binary-level protection mechanisms, including ASLR and in-memory partitioning. Finally, we discuss various full defenses and present a possible way to mitigate the attacks presented.",data oriented architecture,244
4da301bdd08146959f5939f76ba0e189e6d6e300,filtered,semantic_scholar,,41640,semantic_scholar,blaze: building a foundation for array-oriented computing in python,https://www.semanticscholar.org/paper/4da301bdd08146959f5939f76ba0e189e6d6e300,"We present the motivation and architecture of Blaze, a library for cross-backend data-oriented computation. Blaze provides a standard interface to connect users familiar with NumPy and Pandas to other data analytics libraries like SQLAlchemy and Spark. We motivate the use of these projects through Blaze and discuss the benefits of standard interfaces on top of an increasingly varied software ecosystem. We give an overview of the Blaze architecture and then demonstrate its use on a typical problem. We use the abstract nature of Blaze to quickly benchmark and compare the performance ofnature of Blaze to quickly benchmark and compare the performance of a variety of backends on a standard problem.",data oriented architecture,245
633e38c9b0b59ce507edda0ea8c44b4177f32844,filtered,semantic_scholar,2013 22nd International Conference on Computer Communication and Networks (ICCCN),41275,semantic_scholar,architectural blueprints of a unified sensing platform for the internet of things,https://www.semanticscholar.org/paper/633e38c9b0b59ce507edda0ea8c44b4177f32844,"The Internet of Things (IoT) is understood as a major embodiment of the convergence between device-oriented sensor networks and data-oriented applications that is facilitated through the Internet portfolio of technologies. From an architecture perspective, the wide range of operational parameters entailed by multiple application domains myriads of combinations of sensors and applications is the most significant challenge brought on by the IoT vision. To this end, the design blueprint of a platform that enables the seamless integration of multiple dissimilar devices and their efficient use by independently contributed applications is an essential architecture concern. Herein we address this concern by introducing a Unified Sensing Platform (USP) designed to accommodate an open set of sensor types and to expose their functional capabilities to applications in an efficient, reusable and context-aware way.",data oriented architecture,246
6046882af878f9743b6767522c1461beedbee1b3,filtered,semantic_scholar,Electron. Commun. Eur. Assoc. Softw. Sci. Technol.,40179,semantic_scholar,modelling feedback control loops for self-adaptive systems,https://www.semanticscholar.org/paper/6046882af878f9743b6767522c1461beedbee1b3,"Feedback Control Loops(FCLs) are the heart of any self-adaptive sys- tem. Existing engineering approaches for building self-adaptive systems mask FCL by providing abstraction layers that hide the application c omplexity. In this paper, we investigate a model-driven approach for the engineering of FCLs whose archi- tecture is based on the Service Component Architecture(SCA) model. Our proposal consists in exploiting the data streaming model, to specify the characteristics of the control policies, and to generate FCLs of self-adaptive systems deployed in large- scale environment. We argue that the use of a data-oriented model for designing self-adaptive systems significantly increases FCL visibil ity.",data oriented architecture,247
f9a46a8dcdd92bfb4f43d419b69b5dc6b1eaff73,filtered,semantic_scholar,,36526,semantic_scholar,varlet: human-centered tool support for database reengineering,https://www.semanticscholar.org/paper/f9a46a8dcdd92bfb4f43d419b69b5dc6b1eaff73,"Software evolution and maintenance problems might be caused by all kinds of ne w or changed requirements. However, McCabe [McC98] has identified a number of requirements, which are currently of special importance because they are responsible for significant mass changes in today’s business software. Among these central requirements are the Year-2000 problem [Mar97a], the Euro-conversion problem [Gro98], and the ability to compete on a global, electronic mark et. The primary concern of all these requirements is the issue of ho w b usiness data should adequately be represented in softw are systems. The addressed problems range from simple questions, e.g., for the number of digits that are necessary to represent a date (Y ear-2000 problem), up to complex architectural decisions, e.g., ho w to federate data maintained by diverse (formerly autonomous) information systems and integrate these systems with the Web to facilitate electronic commerce. If a legacy software system (LSS) has to be adapted to one of these requirements, a conceptual documentation of its data structure (DS) is thus often a necessary prerequisite to achie ve the maintenance goal. Moreover, a conceptual DS is an excellent starting point for the migration to modern programming languages, as the y are usually data-oriented [GK93]. This is because the conceptual DS reflects major b usiness rules but is fairly independent from procedural application code.",data oriented architecture,248
48d9424e505f7be05ff74d68229fcf96c00929e0,filtered,semantic_scholar,Bell Labs Technical Journal,36526,semantic_scholar,the enhanced service manager: a service management system for next-generation networks,https://www.semanticscholar.org/paper/48d9424e505f7be05ff74d68229fcf96c00929e0,"In this paper, we describe a service management product, the Enhanced Service Manager (eSM), that provides not only fast service development and easy maintenance but also performance, reliability, and Web-enabled provisioning. Competition is fierce in the business world, especially in telecommunications. Being first to offer a service is typically a key decision-making factor for service providers in selecting an operations support system product to manage their services. Furthermore, we have seen the operations network landscape evolving from switch-based to intelligent network-oriented services and from circuit-based to more data-oriented networks. This paper illustrates how open architecture elements such as Common Object Request Broker Architecture (CORBA∗), Extensible Markup Language (XML), and Java∗/JavaServer Pages∗ (JSP∗) technology have been woven with off-the-shelf components into a product designed to meet current business needs. We discuss our architectural approach as well as a future direction.",data oriented architecture,249
98dd6400d25ba55c5de74689bfd7056300155b76,filtered,semantic_scholar,"2014 IEEE 10th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",41640,semantic_scholar,integration between terrestrial and satellite networks: the ppdr-tc vision,https://www.semanticscholar.org/paper/98dd6400d25ba55c5de74689bfd7056300155b76,"Wireless communication technologies are critical for public protection and disaster relief (PPDR) professionals during the emergency operations that follow natural or man-made disasters, scenarios in which commercial terrestrial networks often fail to provide the necessary support. The reason is threefold: they simply get disrupted by the disaster, they cannot sustain the sudden surge of network demand or they fail to deliver the necessary bandwidth and/or other QoS guarantees. In every PPDR operation reliable voice communications are critical, especially in the very early stages of the response; nevertheless, there is an increasing demand from the PPDR community for a wider range of data-centric services. While current technologies used for PPDR operations provide a rich set of voice-centric services, they are unable to sustain high-bandwidth data-oriented applications. As the PPDR-TC EU consortium, we propose a hybrid approach to tackle the question of determining the future architecture for Pan-European PPDR networks based on the integration of Terrestrial and Satellite technologies, presenting our first simulation results on the integration of LTE and Satellite Networks.",data oriented architecture,250
eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,filtered,semantic_scholar,2009 Seventh Annual Communication Networks and Services Research Conference,39814,semantic_scholar,optical access-metro network architecture based on passive access and burst-mode transmission,https://www.semanticscholar.org/paper/eb2fa3a58216f038c23e75c4fd42aa0eb25a17cf,"A network architecture that integrates several WDM PON access segments in a metropolitan area network and uses optical circuit/burst switching is presented here. This architecture targets the delivery of very high speed end to end optical communications between the edge nodes connecting the end users. The combination of circuit switching and burst transmission allows the simultaneous delivery of real-time applications (VoIP, Video) and other data-oriented applications (Internet, peer-to-peer). In the proposed architecture there is a clear separation of the functions in data plane and a control plane. A centralized control entity manages the overall architecture. A dedicated aggregation node acts as a gateway to external networks. After a presentation of the proposed network architecture, this paper focuses on the performance evaluation of the control plane using simulation. Our results show that the queuing delay remains acceptable even under heavy traffic loads.",data oriented architecture,251
f925f3d29d9161514719651dd16a7310e051d56b,filtered,semantic_scholar,2005 Asia-Pacific Conference on Communications,38353,semantic_scholar,a conceptual architecture for adaptation in remote desktop systems driven by the user perception of multimedia,https://www.semanticscholar.org/paper/f925f3d29d9161514719651dd16a7310e051d56b,Current thin-client remote desktop systems were designed for data-oriented applications over low-quality LAN links and they do not provide satisfactory end-user performance in enterprise environment for more and more popular graphical and multimedia applications. To improve perception of those applications in thin-client environment we propose architecture of a server-side quality of service (QoS) management component responsible for mapping application QoS requirements into network QoS. We analyze how service differentiation and traffic management techniques combined with user perception monitoring can be used in order to adjust network level resource allocation when performance of multimedia applications in remote desktop environment is not meeting user requirements. Our objective is to provide QoS-aware remote desktop systems which will be able to manage available resources in intelligent manner and meet end-user performance expectations,data oriented architecture,252
13acc27d419769500af8c3b0d04ad065402f816e,filtered,semantic_scholar,ISPRS Int. J. Geo Inf.,43101,semantic_scholar,hibuffer: buffer analysis of 10-million-scale spatial data in real time,https://www.semanticscholar.org/paper/13acc27d419769500af8c3b0d04ad065402f816e,"Buffer analysis, a fundamental function in a geographic information system (GIS), identifies areas by the surrounding geographic features within a given distance. Real-time buffer analysis for large-scale spatial data remains a challenging problem since the computational scales of conventional data-oriented methods expand rapidly with increasing data volume. In this paper, we introduce HiBuffer, a visualization-oriented model for real-time buffer analysis. An efficient buffer generation method is proposed which introduces spatial indexes and a corresponding query strategy. Buffer results are organized into a tile-pyramid structure to enable stepless zooming. Moreover, a fully optimized hybrid parallel processing architecture is proposed for the real-time buffer analysis of large-scale spatial data. Experiments using real-world datasets show that our approach can reduce computation time by up to several orders of magnitude while preserving superior visualization effects. Additional experiments were conducted to analyze the influence of spatial data density, buffer radius, and request rate on HiBuffer performance, and the results demonstrate the adaptability and stability of HiBuffer. The parallel scalability of HiBuffer was also tested, showing that HiBuffer achieves high performance of parallel acceleration. Experimental results verify that HiBuffer is capable of handling 10-million-scale data.",data oriented architecture,253
dc9df4822e7e894c8da4b936599be6cffb17ea29,filtered,semantic_scholar,,35796,semantic_scholar,hoss: an environment to support structural computing,https://www.semanticscholar.org/paper/dc9df4822e7e894c8da4b936599be6cffb17ea29,"There have been two distinct trends in hypermedia work over the last decade. One has concerned the construction of increasingly more powerful infrastructure for the support of open hypermedia navigation systems, while the other has concerned the application of hypermedia technologies and concepts to increasingly diverse domains. This dissertation addresses how these trends can be merged, resulting in a framework for design of powerful, general infrastructure. 
An examination of the domains to which hypermedia concepts have been applied yields to the conclusion that all rely on general structure and general structural computation. A philosophy of computation is presented called structural computing that stresses the primacy of these concepts. Without such a philosophy, structure is seen as an ad hoc functionality to be added over data-oriented programs. Different structure-oriented domains are seen as special cases of navigational hypertext, with a corresponding confusion of basic terminologies. 
An analysis of the historical development of hypermedia systems leads to the conclusion that current open hypermedia systems can be modified in a straightforward way to support structural computing by opening the link server layer in traditional hypermedia architectures. The resultant generalized link server is called a structure processor (Sproc). Different Sprocs encapsulate tailoring and extension of the structure and structural computation models provided by the structure store of the system. 
A conceptual architecture for an environment to support structural computing (named HOSS) is presented. This architecture is divided into two parts. The operating system layer describes the basic services available to all HOSS programs. The computing environment layer consists of an open set of programs that run address specific structural computing domains. A prototypic implementation of the operating system layer and several example computing environment layer programs is described, which provides a proof of concept of the structural computing environment architecture presented. The sample programs substantiate the claims that such an environment can support the design and implementation of a wide variety of structural computing programs. 
The dissertation concludes with an evaluation of the philosophy of structural computing and the design and implementation of HOSS, a description of directions for possible future work, and conclusions.",data oriented architecture,254
6de34e4976ac5e1382d41a5e2f05b13eac8c4ec0,filtered,semantic_scholar,Applied Sciences,43101,semantic_scholar,a big data and time series analysis technology-based multi-agent system for smart tourism,https://www.semanticscholar.org/paper/6de34e4976ac5e1382d41a5e2f05b13eac8c4ec0,"This study focuses on presenting a development trend from the perspective of data-oriented evidence, especially open data and technologies, as those numbers can verify and prove current technology trends and user information requirements. According to the practical progress of Dr. What-Info I and II, this paper continues to develop Dr. What-Info III. Moreover, big data technology, the MapReduce paralleled decrement mechanism of the cloud information agent CEOntoIAS, which is supported by a Hadoop-like framework, Software R, and time series analysis are adopted to enhance the precision, reliability, and integrity of cloud information. Furthermore, the proposed system app receives a collective satisfaction score of 80% in terms of Quesenbery’s 5Es and Nielsen ratings. In addition, the verification results of the interface design show that the human-machine interface of our proposed system can meet important design preferences and provide approximately optimal balance. The top-n experiment shows that the top-5 recommendations would be better for solving the traditional tradeoff between output quality and processing time. Finally, the system effectiveness experiments indicate that the proposed system receives an overall up-to-standard function rate of 87.5%, and such recommendations provide this system with high information correctness and user satisfaction. Although there is plenty of room for improvement in experience, the feasibility of this service architecture has been proven.",data oriented architecture,255
3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,filtered,semantic_scholar,EMISA,38718,semantic_scholar,challenges and solutions in planning information systems for networked value constellations,https://www.semanticscholar.org/paper/3f7a73dc3a943a6f3e3ff8662b1e1509219fa06f,"Nowadays businesses often decide to form networked value constellations in order to satisfy complex customer needs. To fulfill the value-based requirements of an e-Business idea and to realize the coordination of such a multi-actor network an adequate underlying information systems architecture has to be conceptualized. This paper discusses the applicability of classical information system planning approaches, such as Information Engineering to cross-organizational settings expressed
through value-based requirements. On the basis of this analysis several requirements for the enhancement and adaptation of Information Engineering-like methodologies
for e-Business ideas are defined for the purpose of enabling alignment between a value-based business context and the information systems architecture in a networked environment.
The paper proposes a way to derive data-orientation from value-orientation,
i.e. an enterprise model from a value model. This in turn enables afterwards the
straightforward use of traditional data-oriented techniques for value-based business
models.",data oriented architecture,256
3e40b11fef094fde5e02abfad618797658e2d867,filtered,semantic_scholar,DATA,42005,semantic_scholar,decision support system for implementing data quality projects,https://www.semanticscholar.org/paper/3e40b11fef094fde5e02abfad618797658e2d867,"The new data-oriented shape of organizations inevitably imposes the need for the improvement of their data quality (DQ). In fact, growing data quality initiatives are offering increased monetary and non-monetary benefits for organizations. These benefits include increased customer satisfaction, reduced operating costs and increased revenues. However, regardless of the numerous initiatives, there is still no globally accepted approach for evaluating data quality projects in order to build the optimal business cases taking into account the benefits and the costs. This paper presents a model to clearly identify the opportunities for increased monetary and non-monetary benefits from improved data quality within an Enterprise Architecture context. The aim of this paper is to measure, in a quantitative manner, how key business processes help to execute an organization’s strategy and then to qualify the benefits as well as the complexity of improving data, that are consumed and produced by these processes. These findings will allow to select data quality improvement projects, based on the latter’s benefits to the organization and their costs of implementation. To facilitate the understanding of this approach, a Java EE Web application is developed and presented here.",data oriented architecture,257
4a39c8e47874299701c26305206d08fdb38fac0a,filtered,semantic_scholar,IEEE Communications Letters,42736,semantic_scholar,broadcast-based content delivery in information-centric hybrid multihop wireless networks,https://www.semanticscholar.org/paper/4a39c8e47874299701c26305206d08fdb38fac0a,"Information-centric networking is a “data-oriented” architecture for Future Internet. Since unicast routing cannot exploit the natural broadcast property of wireless networks and unicast paths may be broken down frequently due to node mobility, broadcast transmission is applied for content delivery in information-centric multihop wireless networks. It will face two key challenges: which nodes that receive the broadcasted packet should forward it, and how to avoid multiple nodes simultaneously transmitting it. In this letter, we solve these two issues by taking node mobility and available link capacity into account. A mobility-based forward node selection algorithm is proposed, which tends to select the less mobility nodes as the forward ones. An available link capacity-based forwarding scheme is proposed, which tends to select forward nodes with larger available link capacities to forward packets. Simulation results demonstrate the effectiveness of the proposed mechanism.",data oriented architecture,258
b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,filtered,semantic_scholar,Defense + Security,42370,semantic_scholar,icrowd: agent-based behavior modeling and crowd simulator,https://www.semanticscholar.org/paper/b9d34cbbce5e0d84c77a2cf4d5383fccf6b336c1,"Initially designed in the context of the TASS (Total Airport Security System) FP-7 project, the Crowd Simulation platform developed by the Integrated Systems Lab of the Institute of Informatics and Telecommunications at N.C.S.R. Demokritos, has evolved into a complete domain-independent agent-based behavior simulator with an emphasis on crowd behavior and building evacuation simulation. Under continuous development, it reﬂects an eﬀort to implement a modern, multithreaded, data-oriented simulation engine employing latest state-of-the-art programming technologies and paradigms. It is based on an extensible architecture that separates core services from the individual layers of agent behavior, oﬀering a concrete simulation kernel designed for high-performance and stability. Its primary goal is to deliver an abstract platform to facilitate implementation of several Agent-Based Simulation solutions with applicability in several domains of knowledge, such as: (i) Crowd behavior simulation during [in/out] door evacuation. (ii) Non-Player Character AI for Game-oriented applications and Gamiﬁcation activities. (iii) Vessel traﬃc modeling and simulation for Maritime Security and Surveillance applications. (iv) Urban and Highway Traﬃc and Transportation Simulations. (v) Social Behavior Simulation and Modeling.",data oriented architecture,259
54aea761600684eea98b8d38c1ce972ba1f38888,filtered,semantic_scholar,Euro-Par,42736,semantic_scholar,partitioning strategy selection for in-memory graph pattern matching on multiprocessor systems,https://www.semanticscholar.org/paper/54aea761600684eea98b8d38c1ce972ba1f38888,"Pattern matching on large graphs is the foundation for a variety of application domains. The continuously increasing size of the underlying graphs requires highly parallel in-memory graph processing engines that need to consider non-uniform memory access (NUMA) and concurrency issues to scale up on modern multiprocessor systems. To tackle these aspects, a fine-grained graph partitioning becomes increasingly important. Hence, we present a classification of graph partitioning strategies and evaluate representative algorithms on medium and large-scale NUMA systems in this paper. As a scalable pattern matching processing infrastructure, we leverage a data-oriented architecture that preserves data locality and minimizes concurrency-related bottlenecks on NUMA systems. Our in-depth evaluation reveals that the optimal partitioning strategy depends on a variety of factors and consequently, we derive a set of indicators for selecting the optimal partitioning strategy suitable for a given graph and workload.",data oriented architecture,260
5321e75d0367f2422b569ff42e6ec06ee80f31a8,filtered,semantic_scholar,2012 IEEE International Conference on Communications (ICC),40909,semantic_scholar,performance evaluation of partial deployment of breadcrumbs in content oriented networks,https://www.semanticscholar.org/paper/5321e75d0367f2422b569ff42e6ec06ee80f31a8,"In recent years, much work has been devoted to developing protocols and architectures for supporting the growing trend of data-oriented services. One drawback of many of these proposals is the need to upgrade or replace all the routers in order for the new systems to work. Among the few systems that allow for gradual deployment is the recently-proposed Breadcrumbs technique for distributed coordination among caches in a cache network. Breadcrumbs uses information collected locally at each cache during past downloads to support in-network guiding of current requests to desired content. Specifically, during content download a series of short-term pointers, called breadcrumbs, is set up along the download path. Future requests for this content are initially routed towards the server which holds (a copy of) this content. However, if this route leads the request to a Breadcrumbs-supporting router, this router re-directs the request in the direction of the latest downloaded, using the aforementioned pointers. Thus, content requests are initially forwarded by a location ID (e.g., IP address), but encountering a breadcrumb entry can cause a shift over to content-based routing. This property enables the Breadcrumbs system to be deployed gradually, since it only enhances the existing location-based routing mechanism (i.e. IP-based routing). In this paper we evaluate the performance of a network where Breadcrumbs is only partially deployed. Our simulation results show Breadcrumbs performs poorly when sparsely deployed. However, if an overlay of Breadcrumbs-supporting routers is setup, system performance is greatly improved. We believe that the reduced load on servers achieved with even a limited deployment of Breadcrumbs-supporting routers, combined with the flexibility of being able to deploy the system gradually, should motivate further investigation and eventual deployment of Breadcrumbs.",data oriented architecture,261
d20ee34db8deda89ad3c93786a3bcf780d67d608,filtered,semantic_scholar,,38353,semantic_scholar,specifying and verifying hysteresis signature system with hol-z,https://www.semanticscholar.org/paper/d20ee34db8deda89ad3c93786a3bcf780d67d608,"We report on a case-study in using the data-oriented modeling language Z to formalize a security architecture for administering digital signatures and its architectural security requirements. Within an embedding of Z in the higher-order logic Isabelle/HOL, we provide formal machine-checked proofs of the correctness of the architecture with respect to its requirements. A formalization and verification of the same architecture has been previously carried out using the process-oriented modeling language PROMELA and the SPIN model checker. We use this as a basis for comparing these two different approaches to formalization (infinite state with rich data types versus finite state) and verification (theorem proving versus model checking).",data oriented architecture,262
2cfdabf9a66841e368c45e15d9f65e1f576bb7c1,filtered,semantic_scholar,,37257,semantic_scholar,formal reasoning about real-time components on a data-oriented architecture,https://www.semanticscholar.org/paper/2cfdabf9a66841e368c45e15d9f65e1f576bb7c1,"We investigate an approach towards formal reasoning about component-based software architecture. In this paper we develop specification schemes for real-time applications which interact via the data-oriented software architecture SPLICE. Composition of these applications requires not only knowledge about the component specifications, but also information about key parameters of the underlying communication mechanism. We formulate a proof scheme for the interaction of data-oriented components, and illustrate its use with an example of a flight-tracking-anddisplay system.",data oriented architecture,263
92229332f42836d60c1977fd26dfff630853d401,filtered,semantic_scholar,,35796,semantic_scholar,"requirement capture, formal description and verification of an invoicing system",https://www.semanticscholar.org/paper/92229332f42836d60c1977fd26dfff630853d401,"The Invoicing case study is a typical business system proposed by Henri Habrias as a common example for a contest on the capacity of particular formal methods to capture requirements from the client. For this, the case study is informally described by half a page of English text. In this report, we use the formal description technique LOTOS for requirement capture, formal description and verification of the Invoicing case study. First, we analyse and interpret the informal requirements of the case study using the LOTOS approach for description of systems. This leads to a set of twenty questions about the informal description. By answering to these questions, we obtain a high-level specification architecture that can be formalised. Then, we present the formal description of the case study in LOTOS and, for comparison, in E-LOTOS, the new version of LOTOS currently being standardized. Since LOTOS allows a balance to be struck between process-oriented and data-oriented modeling, descriptions in both styles are given. After that, we verify the LOTOS descriptions by model-checking using the CADP (CAESAR/ALDEBARAN) toolbox. The underlying Labelled Transition System (LTS) models corresponding to various scenarios are generated using the CAESAR compiler. We push further the analysis of the case study by formalizing in temporal logic six properties of the system. We verify these properties on the LTS models using the XTL model-checker. Finally, we study the equivalence of the process-oriented and data-oriented descriptions using the ALDEBARAN tool.",data oriented architecture,264
7261028c80d1ac82828f26c46318557a50c42176,filtered,semantic_scholar,,39083,semantic_scholar,biofederator: a data federation system for bioinformatics on the web,https://www.semanticscholar.org/paper/7261028c80d1ac82828f26c46318557a50c42176,"A problem facing many bioinformatics researchers today is the aggregation and analysis of vast amounts of data produced by large scale projects from various laboratories around the world. Depositing such data into centralized web-based repositories (e.g. NCBI, UCSCGenome Browser) is the common approach. However, the distributed nature of the data, its growth rate, and increased collaborative needs represent real challenges calling for novel decentralized web architectures. The BioFederator is a web services-based data federation architecture for bioinformatics applications. Based on collaborations with bioinformatics researchers, several domainspecific data federation challenges and needs are identified. The BioFederator addresses such challenges and provides an architecture that incorporates a series of utility services. These address issues like automatic workflow composition, domain semantics, and the distributed nature of the data. It also incorporates a series of data-oriented services that facilitate the actual integration of data. The BioFederator is deployed on a grid environment over the web. The proposed design, services, and usage scenarios are discussed in detail. We demonstrate how our architecture can be leveraged for a real-world bioinformatics problem involving tissue specificity of gene expression.",data oriented architecture,265
52c5ec6acd2dfb2194ec655bd695474f76876754,filtered,semantic_scholar,,37622,semantic_scholar,when theory meets practice: building traffic control systems made easy,https://www.semanticscholar.org/paper/52c5ec6acd2dfb2194ec655bd695474f76876754,"Two separate road developments in traffic management in the Netherlands have been the Motorway Traffic Control Architecture (MTCA) and the implementation of data-oriented middleware by Trinite in the first Traffic Management Centre in the Netherlands. The move towards integration in different systems at the traffic management level is described. The principles behind the MTCA are outlined. The architecture had to offer a framework for existing and future traffic control (TC) measures, to adopt an infrastruture-oriented approach and the different parts had to be integrated. Measures are controlled by so-called Traffic Controls, software components that are based on the composite design pattern. The programmable distributed architecture developed by Trinite is the platform on which Traffic Controls are realised in the software. The implementation of an infrastructural system with Traffic Controls involves determining the information needs, adding information elements and adding functionality.",data oriented architecture,266
ea3dcf5053cde3f444d270b8dc29a0eeac585621,filtered,semantic_scholar,ArXiv,42736,semantic_scholar,hardscope: thwarting dop with hardware-assisted run-time scope enforcement,https://www.semanticscholar.org/paper/ea3dcf5053cde3f444d270b8dc29a0eeac585621,"Widespread use of memory unsafe programming languages (e.g., C 
and C++) leaves many systems vulnerable to memory corruption 
attacks. A variety of defenses have been proposed to mitigate attacks 
that exploit memory errors to hijack the control flow of the code 
at run-time, e.g., (fine-grained) randomization or Control Flow Integrity. However, recent work on data-oriented programming (DOP) 
demonstrated highly expressive (Turing-complete) attacks, even in 
the presence of these state-of-the-art defenses. Although multiple 
real-world DOP attacks have been demonstrated, no efficient defenses are yet available. We propose run-time scope enforcement 
(RSE), a novel approach designed to efficiently mitigate all currently 
known DOP attacks by enforcing compile-time memory safety constraints (e.g., variable visibility rules) at run-time. We present HardScope, a proof-of-concept implementation of hardware-assisted 
RSE for the new RISC-V open instruction set architecture. We 
discuss our systematic empirical evaluation of HardScope which 
demonstrates that it can mitigate all currently known DOP attacks, 
and has a real-world performance overhead of 3.2% in embedded 
benchmarks.",data oriented architecture,267
c641fb970edff6345974c540394e94e2e58e6f67,filtered,semantic_scholar,,41640,semantic_scholar,high-performance big data management across cloud data centers,https://www.semanticscholar.org/paper/c641fb970edff6345974c540394e94e2e58e6f67,"The easily-accessible computation power offered by cloud infrastructures coupled with the revolution of Big Data are expanding the scale and speed at which data analysis is performed. The cloud resources for computation and storage are spread among globally distributed data centers. Enabling fast data transfers in such scenarios becomes particularly important for scientific applications for which moving the processing close to data is rather expensive or not feasible (e.g. genome mapping, high-energy physics simulations, large sensors network). Analyzing how clouds can become “Big Data - friendly”, and what are the best options to provide data-oriented cloud services to address applications needs are the key goals of this thesis. In this talk, we present our contributions for providing high performance data management for applications running across multiple cloud data centers. We start by focusing on the scalability aspects of single-site processing and show how the MapReduce model can be extended across multi-sites. Next, we present a transfer service architecture that enables configurable cost-performance optimizations for inter-site transfers. This transfer scheme is then leveraged in the context of real-time streaming across cloud data centers. Finally, we investigate the viability of leveraging this data movement solution as a cloud-provided service, following a Transfer-as-a-Service paradigm based on a flexible pricing scheme.",data oriented architecture,268
f6b19b56439769bb7a1e0d7c4660393fceac5d9f,filtered,semantic_scholar,SSDBM,39448,semantic_scholar,ivip - a scientific workflow system to support experts in spatial planning of crop production,https://www.semanticscholar.org/paper/f6b19b56439769bb7a1e0d7c4660393fceac5d9f,"Decision making for crop production planning is essentially driven by location-based or more precisely by space-oriented information. Therefore, farmers and regional experts in the field mostly rely on new spatial-data-oriented decision making tools. IVIP is a prototype for a Web-based Spatial Decision Support System (WSDSS) demonstrating the benefits of location-based decision making using digitalized geographic information about ground allocation and soil quality. We present how the library of potential models for the IVIP WSDSS has been realized by extending the Scientific Workflow Management System Kepler that assists the collaboration of agricultural experts and computer scientists during model development. We first describe the requirements of our WSDSS, and then give a short introduction to the Kepler platform and explain in detail which extensions have been realized: cascading client-server architecture, spatial operations support, and WSDL interface. Finally, we illustrate how the biomass yield model has been modeled in our system.",data oriented architecture,269
23ac46cc5175021e9b65b869150fab041de93606,filtered,semantic_scholar,ArXiv,41275,semantic_scholar,a practical approach to ontology-enabled control systems for astronomical instrumentation,https://www.semanticscholar.org/paper/23ac46cc5175021e9b65b869150fab041de93606,"Even though modern service-oriented and data-oriented architectures promise to deliver loosely coupled control systems, they are inherently brittle as they commonly depend on a priori agreed interfaces and data models. At the same time, the Semantic Web and a whole set of accompanying standards and tools are emerging, advocating ontologies as the basis for knowledge exchange. In this paper we aim to identify a number of key ideas from the myriad of knowledge-based practices that can readily be implemented by control systems today. We demonstrate with a practical example (a three-channel imager for the Mercator Telescope) how ontologies developed in the Web Ontology Language (OWL) can serve as a meta-model for our instrument, covering as many engineering aspects of the project as needed. We show how a concrete system model can be built on top of this meta-model via a set of Domain Specific Languages (DSLs), supporting both formal verification and the generation of software and documentation artifacts. Finally we reason how the available semantics can be exposed at run-time by adding a ""semantic layer"" that can be browsed, queried, monitored etc. by any OPC UA-enabled client.",data oriented architecture,270
ca56089de18fc6b2ad67408dfdf1411bbce37c1a,filtered,semantic_scholar,,36161,semantic_scholar,software architecture of the u-70 accelerator complex new control system,https://www.semanticscholar.org/paper/ca56089de18fc6b2ad67408dfdf1411bbce37c1a,"The software of the new control system of the 70GeV accelerator complex is built around the distributed real time DBMS SSUDA with emphasis on control of technological process, not equipment. SSUDA was designed to store current states of dynamic parameters and supports 3-D tables. The tables are distributed around all levels of the CS, including equipment controllers. So, DB access protocols are used to access ECs. There are only two data-oriented atomic objects that applications deal with: vector and structure. All tasks interact exclusively through DBs and each task belongs to one of three weakly related types: data processing, hardware I/O and manmachine interface. The organization of parameter value storage is standardized, so data processing and I/O applications are highly unified. Only the console program serves the MMI for all tasks that are solved by operators and accelerator physicists.",data oriented architecture,271
30de295c1412f57fc92e3b3a1bbc7bd71f0ebfee,filtered,semantic_scholar,ICSOC Workshops,40544,semantic_scholar,data flow-oriented process mining to support security audits,https://www.semanticscholar.org/paper/30de295c1412f57fc92e3b3a1bbc7bd71f0ebfee,"The automated execution of dynamically-evolving business processes in service-oriented architectures requires audit methods to assert that they fulfill required security properties. Process mining techniques can provide models for the actual process behavior, but mostly disregard the dynamics of processes running in highly flexible environments and neglect the data flow perspective. This research plan is on novel data-oriented mining techniques to tackle these shortcomings in order to support effective security audits.",data oriented architecture,272
26c3b18f7a5ee7adee14245654e887d728a8570b,filtered,semantic_scholar,,43101,semantic_scholar,on efficient data exchange in multicore architectures,https://www.semanticscholar.org/paper/26c3b18f7a5ee7adee14245654e887d728a8570b,"In contemporary multicore architectures, three trends can be observed: (i) A growing number of cores, (ii) shared memory as the primary means of communication and data exchange and (iii) high diversity between platform architectures. Still, these platforms are typically programmed manually on a core-by-core basis; the most helpful tool that is widely accepted are library implementations of frequently used algorithms. This complicated task of multicore programming will grow further in complexity with the increasing numbers of cores. In addition, the constant change in architecture designs and thus in platform-specific programming demands will continue to make it laborious to migrate existing code to new platforms. State-of-the-art methods of automatic multicore code generation only partially meet the requirements of modern multicore platforms. They typically have a high overhead for different threads when growing numbers of cores and thus shrinking thread granularities demand the opposite. Also, they typically use message passing models for implementing data exchange when memory sharing should be the natural mode of data exchange. As a result, they often fail to produce efficient code, especially when large data throughput is required. This thesis proposes a data-oriented approach to multicore programming. It shows how dividing a program into discrete tasks with clearly specified inputs and outputs helps to formalise the problem of optimising high data throughput applications for a large range of multicore architectures, at the same time enabling an efficient, low-overhead implementation. In detail, its contributions are as follows. • Inefficiencies in existing programming models are demonstrated for the cases of the CAL actor language and Kahn process networks. Methods are shown to reduce these inefficiencies. • Ladybirds, a specificationmodel and language for parallel programs is presented. A Ladybirds program consists of a tasks with clearly defined inputs and outputs and of dependencies between them. It is explained how Ladybirds aims at execution efficiency also in the domains of data placement and transport and what steps are necessary to get from a Ladybirds specification to executable program code.The examples of comfortable debugging and ofminimising state retention overhead for transient systems underline the usability and versatility of Ladybirds. • An optimisation method for Ladybirds programs on the Kalray MPPA platform is presented. It tries to place data on different memory banks such as to avoid access conflicts. Afterwards, the Ladybirds optimisation problem for",data oriented architecture,273
d581245d95ee49532968413a9a4a695634cd3744,filtered,semantic_scholar,SECRYPT,44197,semantic_scholar,a unified model to detect information flow and access control violations in software architectures,https://www.semanticscholar.org/paper/d581245d95ee49532968413a9a4a695634cd3744,"Software architectures allow identifying confidentiality issues early and in a cost-efficient way. Information Flow (IF) and Access Control (AC) are established confidentiality mechanisms, so modeling and analysis approaches should support them. Because confidentiality issues often trace back to data usage, data-oriented approaches are promising. However, we could not identify a data-oriented approach handling both, IF and AC. Therefore, we present a unified data-oriented modeling and analysis approach supporting both, IF and AC, within the same model in this paper. We demonstrate the integration into an existing architectural description language and evaluate the resulting expressiveness and accuracy by a case study considering 22 cases.",data oriented architecture,274
d4d7701d4fdebddccef04ba1a2715820fffdfb10,filtered,semantic_scholar,Workshop on Information Integration on the Web,36892,semantic_scholar,"data-driven, xml-based web management in highly personalized environments",https://www.semanticscholar.org/paper/d4d7701d4fdebddccef04ba1a2715820fffdfb10,"In the domain of XML-based Web applications, sets of XML documents derived from heterogeneous data sources are to be managed. The deployment o XML offers a single and common data model which allows these sets to consider under a data-oriented perspective and to compose their elements to a single, logica XML document. The introduction of a logical representation of the underlying data by a so-called unified view enables comprehensive personalization and customization, because the document structure as well as its graphical presentation can be changed and adapted independently. The intention of this paper is to discuss the idea of building the unified view. Therefore, an overview of the corresponding architecture is given and basic strategies for the building process are presented.",data oriented architecture,275
d61555ba40f6c5a3f7bf36333534c1e28f8f62d9,filtered,semantic_scholar,ICA3PP,39814,semantic_scholar,a software transactional memory service for grids,https://www.semanticscholar.org/paper/d61555ba40f6c5a3f7bf36333534c1e28f8f62d9,"In-memory data sharing for grids allow location-transparent access to data stored in volatile memory. Existing Grid middlewares typ- ically support only explicit data transfer between Grid nodes. We be- lieve that Grid systems benefit from complementing traditional message- passing techniques with a data-oriented sharing technique. The latter includes automatic replica management, data consistency, and location- transparent access. As a proof of concept, we are implementing a POSIX- compatible object sharing service as part of the EU-funded XtreemOS project, which builds a Linux-based Grid operating system. In this paper we describe the software architecture of the object sharing service and design decisions including transactional consistency and peer-to-peer net- work structure. We also present preliminary evaluation results analyzing lower-bound transaction-overhead using a parallel raytracing application.",data oriented architecture,276
60881ba191ac396c88bf081b940b547c51d1b5b0,filtered,semantic_scholar,,36161,semantic_scholar,a scalable service architecture for computer-telephony integration,https://www.semanticscholar.org/paper/60881ba191ac396c88bf081b940b547c51d1b5b0,"The convergence of traditional voice-oriented telecommunications networks and data-oriented computer communications networks is yielding new challenges for building systems equally adept at handling voice and data applications. While there is much discussion about packetized voice over IP networks, a little explored opportunity is the ability to more easily deploy innovative new services based on the Internet’s client-server paradigm and the ease with which software agents can be introduced and migrated around the network. We discuss our new architecture for middleware services that more effectively enables the integration of telephone and data application. This horizontally-integrated architecture supports competition between interchangeable service implementations, based upon features, cost, etc. It is characterized by pervasive and seamless access across multiple cascaded networks. We describe our experiences in integrating an Internet-based core with cellular and other access networks, and our analysis of IP performance in this testbed using a graphical multi-layer protocol analysis tool. Based on our architecture, we have developed prototype converged applications for voice-actuated room control and personal “universal in-box” information management.",data oriented architecture,277
7e9647ea45c28306b39c64d04acbdad35654f720,filtered,semantic_scholar,"2009 Third International Conference on Emerging Security Information, Systems and Technologies",39814,semantic_scholar,runtime protection via dataflow flattening,https://www.semanticscholar.org/paper/7e9647ea45c28306b39c64d04acbdad35654f720,"Software running on an open architecture, such as the PC, is vulnerable to inspection and modification. Since software may process valuable or sensitive information, many defenses against data analysis and modification have been proposed. This paper complements existing work and focuses on hiding data location throughout program execution. To achieve this, we combine three techniques: (i) periodic reordering of the heap, (ii) migrating local variables from the stack to the heap and (iii) pointer scrambling. By essentially flattening the dataflow graph of the program, the techniques serve to complicate static dataflow analysis and dynamic data tracking. Our methodology can be viewed as a data-oriented analogue of control-flow flattening techniques. Dataflow flattening is useful in practical scenarios like DRM, information-flow protection, and exploit resistance. Our prototype implementation compiles C programs into a binary for which every access to the heap is redirected through a memory management unit. Stack-based variables may be migrated to the heap, while pointer accesses and arithmetic may be scrambled and redirected. We evaluate our approach experimentally on the SPEC CPU2006 benchmark suite.",data oriented architecture,278
c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,filtered,semantic_scholar,"2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools",39814,semantic_scholar,run-time reconfigurable array using magnetic ram,https://www.semanticscholar.org/paper/c4a6463cec7b29136a9f858d7bbb8e6a98772fa6,"This paper presents the implementation of a coarse-grained Magnetic RAM based Reconfigurable Array. The Reconfigurable Array architecture is organized as a one- dimensional array of programmable ALU, with the configura- tion bits stored in magnetic random-access memories. The use of MRAM technology to implement run-time reconfigurable hardware devices is a very promising technological solution because MRAM can provide non-volatility with cell areas and access speeds comparable to those of SRAM, and with lower process complexity than flash memory. This type of coarse- grained array, where each reconfigurable element computes on 4-bit or larger input words, is more suitable to execute data-oriented algorithms and is more able to exploit larger amounts of operation-level parallelism than common fine- grained architectures. By substantially reducing the overhead for configurability, this coarse-grain architecture is also more apt to efficiently exploit run-time reconfiguration and therefore to take advantage of multi-context MRAM-based configuration memories. Keywords-reconfigurable array; MRAM; programmable fab- rics;",data oriented architecture,279
826ac2113812ee288da45f585759f81318ce4c85,filtered,semantic_scholar,,42736,semantic_scholar,information management for enabling systems medicine,https://www.semanticscholar.org/paper/826ac2113812ee288da45f585759f81318ce4c85,"Abstract Systems medicine is a data-oriented approach in research and clinical practice to support study and treatment of complex diseases. It relies on well-defined information management processes providing comprehensive and up to date information as basis for electronic decision support. The authors suggest a three-layer information technology (IT) architecture for systems medicine and a cyclic data management approach including a knowledge base that is dynamically updated by extract, transform, and load (ETL) procedures. Decision support is suggested as case-based and rule-based components. Results are presented via a user interface to acknowledging clinical requirements in terms of time and complexity. The systems medicine application was implemented as a prototype.",data oriented architecture,280
61f0f98f644912b1c71d137a829db60782eebd63,filtered,semantic_scholar,IEEE Access,43831,semantic_scholar,cyber physical and social networks in iov (cpsn-iov): a multimodal architecture in edge-based networks for optimal route selection using 5g technologies,https://www.semanticscholar.org/paper/61f0f98f644912b1c71d137a829db60782eebd63,"Humans are blessed with the intelligence to create links, develop semantic metaphors and models for reasoning; construct rules for decision making; and to form bounded loops for interaction, socialization and knowledge sharing. But machines are inadequate with these extraordinary abilities rather, numerous algorithms and mathematical models can be used to connect physical resources with cyberspaces to control objects and, develop cognitive learning for optimal decision making. Connected users and devices in closed virtual and physical proximity give direction towards the plethora of real-world applications for physical, social and, cyber computing. Because of the increase in social media networking and 5G communication links offer real-time crowdsourcing and sensing as a complementary base for information. Proceeding this idea, in this study we have proposed Cyber-Physical and Social Networks (CPSN) for two fundamental operations in IoV (Internet of Vehicles) as CPSN-IoV; (1) to define conceptual architecture of CPSN-IoV for data-oriented network for smart infrastructure and, (2) to create the significant virtual space where the instances of smart vehicles, devices, and things will have meaningful links with the real world objects where, CPSN-IoV will evolve, emerge, compete, and collaborate with all connected objects to strengthen the decision making process. To investigate the potential impact of our proposed study, we have simulated the taxicab trajectory data of the urban city of Portugal in OMNeT++ for the in-depth understanding of road topology, connected vehicles and things, and their traffic trends; and users’ social media streams in respective edge for efficient route planning. The results of simulation demonstrate that our proposed framework has the ability to achieve human-machine intellectual association for managing the smart environment.",data oriented architecture,281
1d750ce96c2cda75c18b2c7bafb4f56f4e9dc36d,filtered,semantic_scholar,Conf. Computing Frontiers,42370,semantic_scholar,from flops to bytes: disruptive change in high-performance computing towards the post-moore era,https://www.semanticscholar.org/paper/1d750ce96c2cda75c18b2c7bafb4f56f4e9dc36d,"Slowdown and inevitable end in exponential scaling of processor performance, the end of the so-called ""Moore's Law"" is predicted to occur around 2025--2030 timeframe. Because CMOS semiconductor voltage is also approaching its limits, this means that logic transistor power will become constant, and as a result, the system FLOPS will cease to improve, resulting in serious consequences for IT in general, especially supercomputing. Existing attempts to overcome the end of Moore's law are rather limited in their future outlook or applicability. We claim that data-oriented parameters, such as bandwidth and capacity, or BYTES, are the new parameters that will allow continued performance gains for periods even after computing performance or FLOPS ceases to improve, due to continued advances in storage device technologies and optics, and manufacturing technologies including 3-D packaging. Such transition from FLOPS to BYTES will lead to disruptive changes in the overall systems from applications, algorithms, software to architecture, as to what parameter to optimize for, in order to achieve continued performance growth over time. We are launching a new set of research efforts to investigate and devise new technologies to enable such disruptive changes from FLOPS to BYTES in the Post-Moore era, focusing on HPC, where there is extreme sensitivity to performance, and expect the results to disseminate to the rest of IT.",data oriented architecture,282
141ac67c51134b03e993dca1a4e038266c6a45aa,filtered,semantic_scholar,WABBWUAS@UMAP,40179,semantic_scholar,generic adaptation process,https://www.semanticscholar.org/paper/141ac67c51134b03e993dca1a4e038266c6a45aa,Adaptive Hypermedia Systems (AHS) have long been mainly represented by domain- or application-specific systems. Few reference models exist and they provide only a brief overview of how to describe and organize the ‘adaptation process’ in a generic way. In this paper we consider the process aspects of AHS from the very first classical ‘user modelling-adaptation’ loop to a generic detailed flowchart of the adaptation in AHS.We introduce a Generic Adaptation Process and by aligning it with a layered (data-oriented) AHS architecture we show that it can serve as the process part of a new reference model for AHS.,data oriented architecture,283
74a462a4e6426679aa9f2f0c172e28c0bb064258,filtered,semantic_scholar,ACM Multimedia,43831,semantic_scholar,pose-native network architecture search for multi-person human pose estimation,https://www.semanticscholar.org/paper/74a462a4e6426679aa9f2f0c172e28c0bb064258,"Multi-person pose estimation has achieved great progress in recent years, even though, the precise prediction for occluded and invisible hard keypoints remains challenging. Most of the human pose estimation networks are equipped with an image classification-based pose encoder for feature extraction and a handcrafted pose decoder for high-resolution representations. However, the pose encoder might be sub-optimal because of the gap between image classification and pose estimation. The widely used multi-scale feature fusion in pose decoder is still coarse and cannot provide sufficient high-resolution details for hard keypoints. Neural Architecture Search (NAS) has shown great potential in many visual tasks to automatically search efficient networks. In this work, we present the Pose-native Network Architecture Search (PoseNAS) to simultaneously design a better pose encoder and pose decoder for pose estimation. Specifically, we directly search a data-oriented pose encoder with stacked searchable cells, which can provide an optimum feature extractor for the pose specific task. In the pose decoder, we exploit scale-adaptive fusion cells to promote rich information exchange across the multi-scale feature maps. Meanwhile, the pose decoder adopts a Fusion-and-Enhancement manner to progressively boost the high-resolution representations that are non-trivial for the precious prediction of hard keypoints. With the exquisitely designed search space and search strategy, PoseNAS can simultaneously search all modules in an end-to-end manner. PoseNAS achieves state-of-the-art performance on three public datasets, MPII, COCO, and PoseTrack, with small-scale parameters compared with the existing methods. Our best model obtains 76.7% mAP and 75.9% mAP on the COCO validation set and test set with only 33.6M parameters. Code and implementation are available at https://github.com/for-code0216/PoseNAS.",data oriented architecture,284
92d394435385cfd3baedd18054b87f29455154d1,filtered,semantic_scholar,ArXiv,41640,semantic_scholar,time series data mining for the gaia variability analysis,https://www.semanticscholar.org/paper/92d394435385cfd3baedd18054b87f29455154d1,"Gaia is an ESA cornerstone mission, which was successfully launched December 2013 and commenced operations in July 2014. Within the Gaia Data Processing and Analysis consortium, Coordination Unit 7 (CU7) is responsible for the variability analysis of over a billion celestial sources and nearly 4 billion associated time series (photometric, spectrophotometric, and spectroscopic), encoding information in over 800 billion observations during the 5 years of the mission, resulting in a petabyte scale analytical problem. In this article, we briefly describe the solutions we developed to address the challenges of time series variability analysis: from the structure for a distributed data-oriented scientific collaboration to architectural choices and specific components used. Our approach is based on Open Source components with a distributed, partitioned database as the core to handle incrementally: ingestion, distributed processing, analysis, results and export in a constrained time window.",data oriented architecture,285
f4dda7d65b3b3c21beb58483c712911945649b33,filtered,semantic_scholar,ICN,43831,semantic_scholar,toward a restful information-centric web of things: a deeper look at data orientation in coap,https://www.semanticscholar.org/paper/f4dda7d65b3b3c21beb58483c712911945649b33,"The information-centric networking (ICN) paradigm offers replication of autonomously verifiable content throughout a network, in which content is bound to names instead of hosts. This has proven beneficial in particular for the constrained IoT. Several approaches, the most prominent of which being Named Data Networking, propose access to named content directly on the network layer. Independently, the IETF CoAP protocol group started to develop mechanisms that support autonomous content processing and in-network storage. In this paper, we explore the emerging CoAP protocol building blocks and how they contribute to an information-centric network architecture for a data-oriented RESTful Web of Things. We discuss design options and measure characteristic performances of different network configurations, which deploy CoAP proxies and OSCORE content object security, and compare with NDN. Our findings indicate an almost continuous design space ranging from plain CoAP at the one end to NDN on the other. On both ends---ICN and CoAP---we identify protocol features and aspects whose mutual transfer potentially improves design and operation of the other.",data oriented architecture,286
5bebd0d71a010e6a9b1b1de6cbcac9a59483aa35,filtered,semantic_scholar,,35065,semantic_scholar,a data model for architecture independent parallel programming,https://www.semanticscholar.org/paper/5bebd0d71a010e6a9b1b1de6cbcac9a59483aa35,"This paper presents a common data model for both shared and distributed parallel programming. Our model aims at parallel application programming, especially in th e field of data parallelism. We introduce coordinators shared objects which automatically perform synchronization in shared memory programming and remote communication in distributed programming. Programming with coordinators allows a static definition of dynamic access properties (shared access patterns) in a declarative manner. Thus, there is no need for explicit use of synchronization or communication primitiv es in order to get well defined and efficient parallel programs. In contrast, declarativity allows to think in abstract coor dination categories. Our paradigm is named Declarative Imperative Parallel Programming due to this fact and due to our commitment to imperative applications, mainly from the field of scientific computing, image processing, simulation and optimization. 1. The DIPP programming model Ideally, explicit parallel programming should be uniform for shared and distributed platforms. One way to achieve this is to give the programmer the illusion of shared memory even on distributed platforms[18]. While we think that this might be exactly what a programmer wants we must acknowledge that this goal is not reached yet. The performance issue implies some sort of discrimination of local from non-local data for distributed platforms. We believe that the process model can be uniform without any impact on performance. We propose such a model (a workpool model) in [13]. The aim of this paper is to show that even the data model can benefit from an uniform approach allowing architecture invariant programmin g without too much loss of performance. The relationship between our data model and the workpool is described in [14]. The main property of the approach presented in this paper is a paradigm which makes explicit synchronization or remote communication obsolete without performance degradation1. We introducecoordinators, a means for declaratively specifying the dynamic access properties of objects to be used by more than one process. The access properties directly correspond to algorithmic patterns typically found i data parallel algorithms such as fan-in or fan-out. In the context of message passing we have the related term broadcast. These all are specific cases of access patterns which can be defined by coordinators. The automatic coordination behavior of a system that implements coordinators can be derived from the specified patterns. Since coordinators are a declarative means to be used in imperative programming the programming model is named Declarative Imperative Parallel Programming. Imperativity is one of the properties which make coordinators different from other implicit synchronization paradigms such as futures [10]. See the discussion of related work for details. Coordinators are objects that may be accessed by more than one process in a coordinated fashion. In shared memory programming they might be named selfsynchronized objects. In distributed programming the term self-distributing might be in order. Accesses to coordinators may trigger synchronization or remote communication actions. We discriminate writing accesses (producers) from reading accesses (consumers). Note, that we do not support general producer-consumer aspects like buffering. In contras t, coordinators are a means for synchronized control allowing a tight coupling between producer and consumer. We 1Notice that we are concerned with application programming; we do not claim that our model does away with explicit synchroniza tion or coordination for parallel system programming such as operati ng systems or databases. specify access properties in a declarative manner: Access patterns are declared separately for reading and writing. The parallel semantics is defined by switching between a writableand areadablestate of a coordinator. The patterns statically describe the conditions which trigger the state switches. These conditions are defined in terms of “who reads or writes an object how many times”. Inappropriate (premature) accesses are delayed until the state switches. This behavior is implemented by implicit synchronization or communication, depending on the underlying architecture. 1.1. Dynamic behavior of coordinators The basic assumption about accesses to coordinators is that writing accesses are distinguished from reading accesses. In imperative programs, switches between writable and readabletypically occur repeatedly inside loops. In functional programs there is exactly one switch from writable to readable. 2 In the following, we informally describe the dynamic behavior of coordinators. Two state semantics Coordinators exhibit a two state semantics: A coordinator is initially in thewritablestate. After construction of the first value it switches to the readable state. After the last read access the coordinator switches t o thewritable state again, thus allowing multiple updates of objects. Depending on the access patterns defined for each state (see section 1.2), the switches may be triggered by dif ferent actions. Blocking If a coordinator is accessed and its state does not correspond to the access kind (i.e. a read access while the coordinator is writable and vice versa) the access is automatically blocked. Blocking lasts at least until the stat e has switched (e.g. by completion of some other accesses). By defining the switch conditions between the two states, the access patterns also determine blocking conditions. Computational steps Our focus is on iteratively writing and reading objects inside some loop or recursion. All such activities within one iteration are referred to as a computational step. More accurately, we define a computational stepwith respect to a coordinator as (dynamically) starting in the writable state and ending when this state is reached again, i.e. a computational step consists of a write phase and aread phase .3 2Readers familiar withfuturesor I-structuresmight see some relationship to these. 3In the functional world, the whole lifetime of a variable is a computational step. The semantics of coordinators is defined by their behavior during one computational step. In general, different co ordinators will carry out different computational steps. 1.2. De ning access patterns Every coordinator reveals a specific access pattern with respect to both phases of a computational step. The access patterns must be specified by the user separately for both phases. Access patterns correspond to algorithmic pat terns as they typically occur in “data-oriented” parallel a lgorithms (e.g. in numerical computation). We have defined the following patterns: each(<process group >,<no of accesses >) each(<process group >) arbitrary(<no of accesses >) arbitrary() The main patternseach and arbitrary differ in the mode of cooperation between the involved processes while their shapes denote the events that trigger a state change. Theeach pattern is used for a homogeneous group of processes <process group >, when the overall task within the write or read phase of a computational step can be defined by specifying the task of every single process within the phase. The intended standard way to specify such a task is to declare how many times the process will access the coordinator within the phase. To do so the each pattern is used with a<no of accesses > specification ( <no of accesses > will be 1 in many cases). This pattern fits for most algorithms that work on regular data (like arrays) in a regular fashion. If the number of accesses cannot be given, each process has to state explicitly that its task within a phase is finished by invoking the coordinator method procReady(<phase>). This method is parameterized with the phase, since it must be synchronized with concurrent accesses. Thus, a call to procReady is a further potential blocking situation. The state change is triggered as soon as each process has finished its task. In order to get a proper definition of this switch condition we require an invariable line-up of the pro cess group (except for an initial phase, see [13]). In contrast, thearbitrary pattern is used if an arbitrary, possibly varying number of possibly inhomogeneous processes share the coordinator. Within this cooperation mode, we can provide only global switch conditions: In the arbitrary pattern a<no of accesses > specification refers to the overall number of accesses, i.e. the state of the coordinator switches after exactly <no of accesses > accesses, no matter which processes were involved. Again, if the number of accesses cannot be given the state switch has to be triggered explicitly. In contrast to theeach pattern this is done by only one process, using the coordinator method switch(<phase>). It can be concluded that this pattern is appropriate e.g. for a farm work model where a centralized master controls the work of several slave processes. 1.3. A short example We illustrate the use of coordinators in a small example, using aC++ like notation enhanced with simple syntactic extensions. Our example implements a producer-consumer scenario where an integer variable sharedInt is repeatedly written by a single producer and subsequently read by nProcs different consumers. We ensure that each value written by the producer is read exactly once by each consumer, by simply definingsharedInt as a coordinator:",data oriented architecture,287
44c75858494b9aecb62b9c50fe4cea48a7e045d1,filtered,semantic_scholar,"CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.",37622,semantic_scholar,a method to find unique sequences on distributed genomic databases,https://www.semanticscholar.org/paper/44c75858494b9aecb62b9c50fe4cea48a7e045d1,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled. Hence, it becomes feasible to analyze the entire genomic information all at once. On the other hand, the quantity of the genomic information stocked on databases is increasing day after day. In order to process the whole information, we have to develop an effective method to deal with lots of data. Therefore, it is indispensable not only to make an effective and rapid algorithm but also to use high-speed computer resource so as to analyze the biological information. For this purpose, as one of the most promised computing environments, the grid computing architecture has appeared recently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11]. In the field of bioinformatics, it is important to find unique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found they can be useful for target specific probes/primers design, gene sequence comparison and so on. In this paper, we propose a method to discover unique sequences from among genomic databases located in a distributed environment. Next, we implement this method upon the European Data Grid and show the calculation results for E. coli genomes.",data oriented architecture,288
9796741f06dc309163ba99993d9ef31295ec86a8,filtered,semantic_scholar,IEEE Trans. Knowl. Data Eng.,37257,semantic_scholar,practical data-oriented microaggregation for statistical disclosure control,https://www.semanticscholar.org/paper/9796741f06dc309163ba99993d9ef31295ec86a8,"Microaggregation is a statistical disclosure control technique for microdata disseminated in statistical databases. Raw microdata (i.e., individual records or data vectors) are grouped into small aggregates prior to publication. Each aggregate should contain at least k data vectors to prevent disclosure of individual information, where k is a constant value preset by the data protector. No exact polynomial algorithms are known to date to microaggregate optimally, i.e., with minimal variability loss. Methods in the literature rank data and partition them into groups of fixed-size; in the multivariate case, ranking is performed by projecting data vectors onto a single axis. In this paper, candidate optimal solutions to the multivariate and univariate microaggregation problems are characterized. In the univariate case, two heuristics based on hierarchical clustering and genetic algorithms are introduced which are data-oriented in that they try to preserve natural data aggregates. In the multivariate case, fixed-size and hierarchical clustering microaggregation algorithms are presented which do not require data to be projected onto a single dimension; such methods clearly reduce variability loss as compared to conventional multivariate microaggregation on projected data.",data oriented architecture,289
59bb50285c3e3807a03617b98aac00233cc5ce28,filtered,semantic_scholar,2010 IFIP Wireless Days,40179,semantic_scholar,a software radio architecture for the baseband level of the multi-standard user terminal: design methodology and computational assessment,https://www.semanticscholar.org/paper/59bb50285c3e3807a03617b98aac00233cc5ce28,In this paper we present a design methodology and system prototyping for the baseband level of the Software Defined Radio (SDR)-based portable multi-standard terminal. The SDR-based architecture consists of three main layers denoted as: i) Upper Layer to provide communication with an end user and a network; ii) Middle Layer to establish the required protocol configuration; and iii) Bottom Layer to execute the protocol algorithm. Main concern was based on the examination of the SDR-based module behavior in the heterogeneous environment. As a case study we have chosen two different wireless communication standards: data-oriented WiMAX (IEEE 802.16d) and voice-oriented UMTS (release 1999). The simulation of the digital signal processing for both standards was performed in the MATLAB environment. The goal is to achieve and to verify the given system configuration depending on the environment characteristics. For this reason we show that SDR-based module can recognize the required protocol configuration and tune the system accordingly.,data oriented architecture,290
85c91ea5de453ba5bfb10ec4c895a775422358df,filtered,semantic_scholar,"5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007)",39083,semantic_scholar,requirements specification: what strategy under what conditions,https://www.semanticscholar.org/paper/85c91ea5de453ba5bfb10ec4c895a775422358df,"There are several strategies/philosophies of IS development (structured, data-oriented, object-oriented, service- oriented, and agile programming). Their application was to a high degree implied by technological conditions. The strategies have been determining the information systems architecture and the tools and methods of requirement specification. Due the success of new strategies the older ones are improperly considered to be obsolete. There are discussed the conditions under which the application of a particular strategy is not only feasible but optimal and when and how different strategies are to be combined. All the strategies except the service-oriented one are suited to the development of application more or less from scratch. The application has a programmed number of threads. The current largest information systems like the systems supporting e-government or global enterprises must have service- oriented architecture of a specific form - software confederations. Confederation-oriented strategy is different from the other strategies but it can (should) be combined with them. The main differences are in the use of legacy systems and software standards.",data oriented architecture,291
dea31cbcf29a62120d437208a754455acb8bc82b,filtered,semantic_scholar,PeerJ Comput. Sci.,44197,semantic_scholar,distributed in-memory data management for workflow executions,https://www.semanticscholar.org/paper/dea31cbcf29a62120d437208a754455acb8bc82b,"Complex scientific experiments from various domains are typically modeled as workflows and executed on large-scale machines using a Parallel Workflow Management System (WMS). Since such executions usually last for hours or days, some WMSs provide user steering support, i.e., they allow users to run data analyses and, depending on the results, adapt the workflows at runtime. A challenge in the parallel execution control design is to manage workflow data for efficient executions while enabling user steering support. Data access for high scalability is typically transaction-oriented, while for data analysis, it is online analytical-oriented so that managing such hybrid workloads makes the challenge even harder. In this work, we present SchalaDB, an architecture with a set of design principles and techniques based on distributed in-memory data management for efficient workflow execution control and user steering. We propose a distributed data design for scalable workflow task scheduling and high availability driven by a parallel and distributed in-memory DBMS. To evaluate our proposal, we develop d-Chiron, a WMS designed according to SchalaDB’s principles. We carry out an extensive experimental evaluation on an HPC cluster with up to 960 computing cores. Among other analyses, we show that even when running data analyses for user steering, SchalaDB’s overhead is negligible for workloads composed of hundreds of concurrent tasks on shared data. Our results encourage workflow engine developers to follow a parallel and distributed data-oriented approach not only for scheduling and monitoring but also for user steering.",data oriented architecture,292
4545c290e77387c305da61557ada3f512dfedbb1,filtered,semantic_scholar,,39083,semantic_scholar,study on application of pdm technology in reliability design and analysis of mechanisms,https://www.semanticscholar.org/paper/4545c290e77387c305da61557ada3f512dfedbb1,"The multidisciplinary tools integration is one of the key technical problems in the Virtual Prototyping design and simulation of the complex product. In this paper,a service-oriented,better opening,standard-based and plug-and-play multidisciplinary tools integration platform for mechanism reliability design and analysis is presented,and the architectures of design and analysis of mechanism reliability based on PDM technology are given. What is discussed is the model data-oriented integration of management to realize the integration of CAD/CAE and PDM both in design and collaborative simulation periods. At last,an application example in space rendezvous mechanism is briefly introduced to indicate methods of integration design and analysis of mechanism reliability and how to realize PDM based collaborative modeling and analysis of mechanism reliability by using application packaging.",data oriented architecture,293
f1782bbad00979a37b68b55388e82f3dbc0a6edf,filtered,semantic_scholar,2008 IEEE Aerospace Conference,39448,semantic_scholar,iknow mission: payload design for in orbit test of w band technology,https://www.semanticscholar.org/paper/f1782bbad00979a37b68b55388e82f3dbc0a6edf,"This paper presents the payload design for an in orbit test of W band technology called IKNOW mission (In orbit Key-test and validatioN Of W band). The increasing demand for frequency bands with large bandwidth availability to satisfy satellite communications applications requirements renders mandatory the need to explore higher and higher frequency ranges. W band (75-110 GHz) could represent the answer to these needs due to the large bandwidth availability, allowing to propose many innovative services that need high-volume transfers. Therefore, the exploitation of W band is foreseen in order to meet the high-quality data transmission for a large number of end users and data-oriented services. The IKNOW mission is a demonstrative experiment foreseen within the phase A2 of the WAVE (W band analysis and verification) project, a study funded by the Italian Space Agency (ASI), which aims at designing and developing W band payloads for telecommunication applications. This paper will be focused on the characterization of the IKNOW mission within the WAVE project devoted to carry out a preliminary channel propagation assessment. Specifically, special attention will be paid to the payload design, particularly critical from the technological point of view at these high frequencies. The basic idea is to develop the receiving/transmitting chain using MMIC devices, in order to fit cost, power and weight constraints, typically limited for a spacecraft. Technological critical items will be highlighted, focusing on the present state of the art and presenting some architectural choices. Moreover, some simulations based on ADS software will be reported in order to simulate the performance of the identified payload configuration.",data oriented architecture,294
00a97b3ca5c924b9350a6199f67bcf76c21bbdbd,filtered,semantic_scholar,2007 International Conference on Service Systems and Service Management,39083,semantic_scholar,electronic medical records: a vision for medical data and service grids,https://www.semanticscholar.org/paper/00a97b3ca5c924b9350a6199f67bcf76c21bbdbd,"In this paper, we propose an integrated e-service model for implementing electronic medical records (EMR). We discuss technical and economic issues associated with EMR and argue that the emerging e-services will not fully resolve the issues if they do not work together. To meet the challenge, we propose an integrated e-service framework consisting of both process-and data-oriented grids that glue together distributed electronic medical services and records, and application services that provide readily available solutions. We suggest an implementation architecture that extends the open systems interconnectivity model and improves existing e-service architectures. The proposed e-services framework would help deliver e-health applications effectively at a time when such applications are being considered as an effective means of delivering healthcare information, products, and services.",data oriented architecture,295
ca0f0c24c1c983f919165bad4cbe5d8449335f14,filtered,semantic_scholar,IEEE Access,43831,semantic_scholar,a parallel-computing algorithm for high-energy physics particle tracking and decoding using gpu architectures,https://www.semanticscholar.org/paper/ca0f0c24c1c983f919165bad4cbe5d8449335f14,"Real-time data processing is one of the central processes of particle physics experiments which require large computing resources. The LHCb (Large Hadron Collider beauty) experiment will be upgraded to cope with a particle bunch collision rate of 30 million times per second, producing <inline-formula> <tex-math notation=""LaTeX"">$10^{9}$ </tex-math></inline-formula> particles/s. 40 Tbits/s need to be processed in real-time to make filtering decisions to store data. This poses a computing challenge that requires exploration of modern hardware and software solutions. We present <italic>Compass</italic>, a particle tracking algorithm and a parallel raw input decoding optimized for GPUs. It is designed for highly parallel architectures, data-oriented, and optimized for fast and localized data access. Our algorithm is configurable, and we explore the trade-off in computing and physics performance of various configurations. A CPU implementation that delivers the same physics performance as our GPU implementation is presented. We discuss the achieved physics performance and validate it with Monte Carlo simulated data. We show a computing performance analysis comparing consumer and server-grade GPUs, and a CPU. We show the feasibility of using a full GPU decoding and particle tracking algorithm for high-throughput particle trajectories reconstruction, where our algorithm improves the throughput up to <inline-formula> <tex-math notation=""LaTeX"">$7.4\times $ </tex-math></inline-formula> compared to the LHCb baseline.",data oriented architecture,296
545dd0b8ca355777446acbc6811ba75c56eae1c9,filtered,semantic_scholar,IEEE Internet Comput.,35431,semantic_scholar,architecture perspective: the right user interface,https://www.semanticscholar.org/paper/545dd0b8ca355777446acbc6811ba75c56eae1c9,The Internet revolution was largely due to a killer interface based on HTML. Now intranets are poised to trigger the next paradigm in Web interfaces. Industrial applications in particular require a shift in orientation from pushing data to users to presenting them with sophisticated process-based interfaces. The specific theme of this paper is process-oriented user interfaces as opposed to data-oriented interfaces.,data oriented architecture,297
a96539c753dd3b547cd5a3f390b6678b63c0d648,filtered,semantic_scholar,2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS),44197,semantic_scholar,iot microservice architecture for iotaas device users,https://www.semanticscholar.org/paper/a96539c753dd3b547cd5a3f390b6678b63c0d648,"Scaling up the Internet of Things (IoT) as a service (IoTaaS) is still facing many challenges including the demand of IoTass users to gain a more privilege access on IoT device to configure necessary parameters such as data rate and actuator rotation speed for custom object tracking methods. To address this challenge, this paper aims to propose a micro service architecture of IoT, particularly to provide configurable IoT device platform. Compared to previous works focusing on data-oriented high-level architecture of IoT solution, the proposed architecture provides a solution for IoT device users and, hence, this study is critical to extend the capabilities of IoTaaS.",data oriented architecture,298
00c4a804484051d385c992e2221bc406a54aa598,filtered,semantic_scholar,Int. J. Digit. Libr. Syst.,40544,semantic_scholar,a presentation-preserved compositional approach for integrating heterogeneous systems: using e-learning as an example,https://www.semanticscholar.org/paper/00c4a804484051d385c992e2221bc406a54aa598,"In traditional SCW environments, related web services are integrated into business processes. Web service still brings less than expected benefits to small corporations and end-users for two reasons: 1 the web service only focuses on data level and is difficult to implement the presentation-centric business contexts. 2 The small corporations and end-users usually do not have enough IT competences to write a client or user interface to interact with web services. In order to solve these problems, the author proposes a presentation-preserved compositional approach for service-oriented architecture PCSOA, which extends the existing data-oriented compositional approaches for web services to provide a more flexible methodology to orchestrate both data level and presentation level services during the workflow integration. A prototype is also built to validate the feasibility of the approach.",data oriented architecture,299
f3b58a7c7cd9356cdbb55b4fc42f22b44b9e2849,filtered,semantic_scholar,CIKM 2014,41640,semantic_scholar,proceedings of the first international workshop on privacy and secuirty of big data,https://www.semanticscholar.org/paper/f3b58a7c7cd9356cdbb55b4fc42f22b44b9e2849,"The 1st International Workshop on Privacy and Security of Big Data (PSBD 2014) focuses the attention on privacy and security research issues in the context of Big Data, a vibrant and challenging research context which is playing a leading role in the Database research community. Indeed, while Big Data is gaining the attention from the research community, also driven by some relevant technological innovations (like Clouds) as well as novel paradigms (like social networks), the issues of privacy and security of Big Data represent a fundamental problem in this research context, due to the fact Big Data are typically published online for supporting knowledge management and fruition processes and, in addition to this, such data are usually handled by multiple owners, with possible secure multi-part computation issues. Some of the hot topics in the context privacy and security of Big Data include: (i) privacy and security of Big Data integration and exchange; (ii) privacy and security of Big Data in data-intensive Cloud computing; (iii) system architectures in support of privacy and security of Big Data, e.g., GPUs: (iv) privacy and security issues of Big Data querying and analysis. These topics are first-class aspects to be addressed and investigated by PSBD 2014. 
 
These proceedings contain the papers selected for presentation at the workshop. We received 12 submissions from countries in North America, Europe and Asia. After careful review, the program committee selected 5 papers for presentation at the workshop. The accepted papers were presented in 2 sessions: scalable privacy-preserving and security-control methods for Big Data processing, user-oriented and data-oriented privacy methods for Big Data processing. A panel discussed advanced aspects of privacy and security of Big Data. We hope that these proceedings will serve as a valuable reference for researchers and practitioners focusing on privacy and security of Big Data.",data oriented architecture,300
350f27ef714c25235870a50015837790cafb1147,filtered,semantic_scholar,2010 International Conference On Computer Design and Applications,40179,semantic_scholar,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://www.semanticscholar.org/paper/350f27ef714c25235870a50015837790cafb1147,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,301
57a6b0c5114b217606c2f710a6746e1a05db18a9,filtered,semantic_scholar,ADBIS,42736,semantic_scholar,asynchronous graph pattern matching on multiprocessor systems,https://www.semanticscholar.org/paper/57a6b0c5114b217606c2f710a6746e1a05db18a9,"Pattern matching on large graphs is the foundation for a variety of application domains. Strict latency requirements and continuously increasing graph sizes demand the usage of highly parallel in-memory graph processing engines that need to consider non-uniform memory access (NUMA) and concurrency issues to scale up on modern multiprocessor systems. To tackle these aspects, graph partitioning becomes increasingly important. Hence, we present a technique to process graph pattern matching on NUMA systems in this paper. As a scalable pattern matching processing infrastructure, we leverage a data-oriented architecture that preserves data locality and minimizes concurrency-related bottlenecks on NUMA systems. We show in detail, how graph pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,302
fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,filtered,semantic_scholar,,43101,semantic_scholar,a research on the security of wisdom campus based on geospatial big data,https://www.semanticscholar.org/paper/fbe0457533ac791b6d3ed90c337bb74b79dbcb2e,"Wang Haiying School of Land and Resource China West Normal University Nanchong, China e-mail: wanghaiying8228@163.com Abstract— There are some difficulties in wisdom campus, such as geospatial big data sharing, function expansion, data management, analysis and mining geospatial big data for a characteristic, especially the problem of data security can't guarantee cause prominent attention increasingly. In this article we put forward a data-oriented software architecture which is designed by the ideology of orienting data and data as kernel, solve the problem of traditional software architecture broaden the campus space data research, develop the application of wisdom campus.",data oriented architecture,303
442567e7d47373f6d305a249b7ae05b81d15782e,filtered,semantic_scholar,"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",43466,semantic_scholar,consideration and research on data architecture for the future cyber society,https://www.semanticscholar.org/paper/442567e7d47373f6d305a249b7ae05b81d15782e,"The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.",data oriented architecture,304
daa1b2301e42c75fb98ef23f2a69f2bfec8fd780,filtered,semantic_scholar,ArXiv,44197,semantic_scholar,workflows community summit: advancing the state-of-the-art of scientific workflows management systems research and development,https://www.semanticscholar.org/paper/daa1b2301e42c75fb98ef23f2a69f2bfec8fd780,"Scientific workflows are a cornerstone of modern scientific computing, and they have underpinned some of the most significant discoveries of the last decade. Many of these workflows have high computational, storage, and/or communication demands, and thus must execute on a wide range of large-scale platforms, from large clouds to upcoming exascale HPC platforms. Workflows will play a crucial role in the data-oriented and post-Moore's computing landscape as they democratize the application of cutting-edge research techniques, computationally intensive methods, and use of new computing platforms. As workflows continue to be adopted by scientific projects and user communities, they are becoming more complex. Workflows are increasingly composed of tasks that perform computations such as short machine learning inference, multi-node simulations, long-running machine learning model training, amongst others, and thus increasingly rely on heterogeneous architectures that include CPUs but also GPUs and accelerators. The workflow management system (WMS) technology landscape is currently segmented and presents significant barriers to entry due to the hundreds of seemingly comparable, yet incompatible, systems that exist. Another fundamental problem is that there are conflicting theoretical bases and abstractions for a WMS. Systems that use the same underlying abstractions can likely be translated between, which is not the case for systems that use different abstractions. More information: https://workflowsri.org/summits/technical",data oriented architecture,305
21e1af9f96fa81391e3accec650e1e4de0851916,filtered,semantic_scholar,International Symposium on Multispectral Image Processing and Pattern Recognition,42005,semantic_scholar,an on-demand provision model for geospatial multisource information with active self-adaption services,https://www.semanticscholar.org/paper/21e1af9f96fa81391e3accec650e1e4de0851916,"Location-related data are playing an increasingly irreplaceable role in business, government and scientific research. At the same time, the amount and types of data are rapidly increasing. It is a challenge how to quickly find required information from this rapidly growing volume of data, as well as how to efficiently provide different levels of geospatial data to users. This paper puts forward a data-oriented access model for geographic information science data. First, we analyze the features of GIS data including traditional types such as vector and raster data and new types such as Volunteered Geographic Information (VGI). Taking into account these analyses, a classification scheme for geographic data is proposed and TRAFIE is introduced to describe the establishment of a multi-level model for geographic data. Based on this model, a multi-level, scalable access system for geospatial information is put forward. Users can select different levels of data according to their concrete application needs. Pull-based and push-based data access mechanisms based on this model are presented. A Service Oriented Architecture (SOA) was chosen for the data processing. The model of this study has been described by providing decision-making process of government departments with a simulation of fire disaster data collection. The use case shows this data model and the data provision system is flexible and has good adaptability.",data oriented architecture,306
d907ba410e13d3d5c31bbbcb4f192275dce295ec,filtered,semantic_scholar,2019 2nd International Conference on Hot Information-Centric Networking (HotICN),43466,semantic_scholar,cdac: a collaborative data access control scheme in named data networking,https://www.semanticscholar.org/paper/d907ba410e13d3d5c31bbbcb4f192275dce295ec,"Named Data Networking (NDN) shifts networking paradigm from host-oriented to data-oriented and supports in-network caching. However, in-network caching brings about some new security issues (e.g., the separation of ownership and management of data). In native NDN architecture, consumers' requests are usually authenticated by a content producer, which results in highly computation overhead and unnecessary network delay. Moreover, in such a scenario where the connection between content producer and network is intermittent, encrypted contents cached in routers fail to be accessed by consumers due to lacking of content producer's permission. In this paper, we propose a collaborative data access control scheme for NDN, called CDAC, in which data access control is performed at cached-enabled routers rather than single content producer. In addition, enhanced secret sharing method is applied to achieve data access control in the situation where the connection between content producer and network is intermittent. We also use two-variable one-way function to reduce the computation overhead caused by consumer's revocation. Through reasonable security analysis and the comparison with preliminary works, the CDAC scheme achieves the expected design goals. The experimental results demonstrate that our scheme is efficient for N DN architecture, and introduces slight delay for contents securely retrieval.",data oriented architecture,307
92eca9bc0df78e4e3d4daef20c7219e4b01e0c74,filtered,semantic_scholar,,34335,semantic_scholar,"database issues for data visualization: ieee visualization '93 workshop, san jose, california, usa, october 26, 1993 : proceedings",https://www.semanticscholar.org/paper/92eca9bc0df78e4e3d4daef20c7219e4b01e0c74,"Workshop description.- Workshop participants.- Database issues for data visualization: Developing a data model.- Database issues for data visualization: System integration issues.- Database issues for data visualization: Interaction, user interfaces, and presentation.- The VIS-AD data model: Integrating metadata and polymorphic display with a scientific programming language.- An extended schema model for scientific data.- Data integration for visualization systems.- Inherent logical structure of computational data: Its role in storage and retrieval strategies to support user queries.- Database management for data visualization.- Data exploration interactions and the ExBase system.- Database requirements for supporting end-user visualizations.- A system architecture for data-oriented visualization.- A Hyperspectral Image Data Exploration Workbench for environmental science applications.- Design of a 3D user interface to a database.- Visualizing reference databases.- A 3D based user interface for information retrieval systems.- Using visualization to support data mining of large existing databases.",data oriented architecture,308
01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,filtered,semantic_scholar,,43101,semantic_scholar,research on digital power grid information integration solution,https://www.semanticscholar.org/paper/01f3201db7bf10339ea6c2e62f34d7ccf18e3ca5,"Information integration is an important part of the digital grid architecture. The purpose is to solve the information interaction obstacles between heterogeneous systems on the basis of making full use of the old system. This paper analyzes the development stage of digital power grid information integration from the perspective of information integration, and points out that the information integration of current digital power grid is mainly data-oriented integration. Based on the characteristics of digital power grid information integration, this paper puts forward a digital power grid information Integration solution combining horizontal information integration and vertical information integration, designs the overall architecture of digital power grid information integration, and elaborates the horizontal integration and vertical integration respectively.",data oriented architecture,309
5420d66a752c1eb434633e1e96f9f2c9743a5c69,filtered,semantic_scholar,Proceedings of NOMS '94 - IEEE Network Operations and Management Symposium,34335,semantic_scholar,information engineering architecture for strategic network operations and management platforms,https://www.semanticscholar.org/paper/5420d66a752c1eb434633e1e96f9f2c9743a5c69,"Today's telecommunications industry in Japan is not merely a business for an equipment infrastructure. Service providers are fiercely competing to improve customer satisfaction: providing services more quickly, notifying customers of exact recovery times, and supplying advanced new services. To improve customer satisfaction, all network operations and management (O&M) activities from customer services to administration have to flow smoothly and in cooperation with each other. A major factor in achieving this is an efficient information flow. An important aspect in this flow is that information must be readily available at any time and any place. To achieve global availability, the meaning, representation, and structure of the information must be systematized and standardized at an enterprise level and represented specifically at the local processing level. It is therefore necessary to construct O&M systems by using methodologies based on an information(data-) oriented perspective. An O&M system so constructed can be characterized as a strategic information system (SIS). Traditionally, O&M systems have been based on a process-oriented perspective and have been isolated from the flow of information. This paper describes the information engineering architecture we have developed for constructing a strategic network operation platform as an SIS. We have designed part of an information model based on this architecture and are studying the operation platform construction. 268 0-7803-181 1-0/94$04.00019941EEE Operation Systems: Present and Future Basic Structure of Process1 Qriented Operation Systems-df I .~.~..""-.,"""".~~.~.. .. .. ~ ......~... (Information L ,-.-.. ... .. ...-.. .. .""........"".. . .......-... . .."".....-,. Basic Structure of Data-oriente>j Platforms Application Platforms Presentation I [Data Communication Network) In&ormutton Resources Encupsuluted wtdh Merhods 1 Information Resource Platforms Traditional O&M systems focus on operating and managing the equipment and the network; they are developed by using methodologies based on a process-oriented perspective. Their data modeling and standardization are therefore done independently, so their data naming and data coding are not consistent. Information flows among these systems by means of paper and floppy disks, leading to duplicate data input, data transformation, and data inconsistency. The O&Ms are becoming strategic, advanced, and commercialized. For example, customers will be able to control their own networks, or they can let the service provider do it for them. To achieve strategic and advanced O&M, several O&M systems are needed and information must flow among them. In traditional vertically-structured systems, it is difficult to simplify data flow management, maintain data quality, and reduce data transformation costs. It is necessary to construct an information infrastructure which does not limit processing and managing data flows. The information needed by any O&M system must be immediately available, so information must be able to easily and quickly flow to all related O&M systems. From the view that ""Information is a final product which is gained by processing data"", it is necessary to construct O&M systems by using methodologies based on an information(data-) oriented perspective. We have developed a horizontally-structured O&M systems environment based on a data-oriented perspective. We call it an operation platform.",data oriented architecture,310
41869028b49ed2aac17ae9aede4f482ce7c6372c,filtered,semantic_scholar,,35796,semantic_scholar,evaluation results nlp components ovis2,https://www.semanticscholar.org/paper/41869028b49ed2aac17ae9aede4f482ce7c6372c,"The NWO Priority Programme Language and Speech Technology is a research programme aiming at the development of spoken language information systems. Its immediate goal is to develop a demonstrator of a public transport information system, which operates over ordinary telephone lines. This demonstrator is called OVIS, Openbaar Vervoer Informatie Systeem (Public Transport Information System). The language of the system is Dutch. In this Programme, two alternative natural language processing modules are developed in parallel: a ‘grammar-based’ (conventional, rule-based) module and a ‘data-oriented’ (statistical, probabilistic, DOP) module. Both of these modules fit into the system architecture of OVIS. For detailed descriptions of these modules, the reader is refered to (van Noord et al., 1996), (van Noord et al., 1996) and (van Noord et al., 1997) for the grammar-based NLP module. The DOP approach is documented in (Scha et al., 1996), (Sima’an, 1997b), (Bod and Scha, 1997). In order to compare both NLP modules, a formal evaluation has been carried out. This evaluation was planned originally for the beginning of 1997. Because the design of the update language (the interface between NLP and the pragmatic component and dialog manager) took more time than foreseen, and because the (semantic) annotation of corpus material has been available only since May 1997, this formal evaluation could only start in february 1998. The evaluation procedure is described in (van Noord, 1997), and summarized here in section 2. The methods implemented in Groningen and Amsterdam are described in somewhat more detail in section 3. Some characteristics of the test set are provided in section 4. The results of the evaluation are presented in section 5.",data oriented architecture,311
fd4cbfabe49082a784e60ea60359c9483af8c216,filtered,semantic_scholar,22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC),42736,semantic_scholar,identity-based proxy signature multiple-file pdp for mobile cloud computing,https://www.semanticscholar.org/paper/fd4cbfabe49082a784e60ea60359c9483af8c216,"Provable Data Possession (PDP) schemes which are vital to data-oriented mobile cloud computing security architecture enable users to check the integrity of their data in the cloud efficiently. Due to the limitation of storage space and computing power of the mobile terminals, a new identity-based proxy signature multiple-file data integrity verification scheme called Identity-Based Proxy Signature Multiple-File PDP(IBPS-MPDP) for mobile cloud computing is proposed. In this paper, by using identity-based proxy signature, the system does not need to take the additional overhead to manage the public key certifications and the mobile users do not need to take additional cost to authenticate others' certificates yet. Allotting the heavy proxy signature tasks to the proxy sign party to implement to reduce the mobile terminal users' computing pressures. Adopting the aggregate signature to diminish the communication overhead of cloud and mobile users. The security of the scheme is proved in the random oracle model.",data oriented architecture,312
cddb42247b854abce14ee1e059f332f42be54c5d,filtered,semantic_scholar,2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP),42005,semantic_scholar,rapid customization of image processors using halide,https://www.semanticscholar.org/paper/cddb42247b854abce14ee1e059f332f42be54c5d,"Image processing applications typically involve data-oriented kernels with limited control divergence. In order to efficiently exploit the data level parallelism, image processors include SIMD instructions and other parallel computation resources. Generic processors that can be purchased off-the-shelf are adequate for most of the use scenarios of image processing. However, especially with embedded mobile devices, they might not be optimal for the algorithm, the environment, or the energy budget at hand. Such cases call for programmable customized architectures with just enough hardware resources to ensure the high priority applications reach their real time goals with minimal overheads. In order to maintain high engineer productivity, implementing image algorithms for customized processors should be as easy as with standard processors. This is emphasized at the processor co-design time; because the program is used to drive the processor design space exploration towards an optimized architecture, assembly programming is not feasible due to the required porting effort whenever the architecture is modified. In this paper we propose an image processor customization flow that exploits the domain-specific Halide language as an input to a processor co-design environment. In addition to efficiently exploiting standard resources in the customized processors, the flow provides an easy way to invoke special instructions from Halide programs. We validate the performance benefits of custom operations using example filters described with the Halide language.",data oriented architecture,313
de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,filtered,semantic_scholar,2017 International Carnahan Conference on Security Technology (ICCST),42736,semantic_scholar,"encrypted computing: speed, security and provable obfuscation against insiders",https://www.semanticscholar.org/paper/de0c291d6c16ee7e3b2774f30ba3ee488cea0d82,"Over the past few years we have articulated theory that describes ‘encrypted computing’, in which data remains in encrypted form while being worked on inside a processor, by virtue of a modified arithmetic. The last two years have seen research and development on a standards-compliant processor that shows that near-conventional speeds are attainable via this approach. Benchmark performance with the US AES-128 flagship encryption and a 1GHz clock is now equivalent to a 433MHz classic Pentium, and most block encryptions fit in AES's place. This summary article details how user data is protected by a system based on the processor from being read or interfered with by the computer operator, for those computing paradigms that entail trust in data-oriented computation in remote locations where it may be accessible to powerful and dishonest insiders. We combine: (i) the processor that runs encrypted; (ii) a slightly modified conventional machine code instruction set architecture with which security is achievable; (iii) an ‘obfuscating’ compiler that takes advantage of its possibilities, forming a three-point system that provably provides cryptographic ‘semantic security’ for user data against the operator and system insiders.",data oriented architecture,314
bf25baf2eac5677cad335addbfab8b1c51ee360e,filtered,semantic_scholar,,37622,semantic_scholar,a method to find uniq e sequences on distrib ted genomic databases,https://www.semanticscholar.org/paper/bf25baf2eac5677cad335addbfab8b1c51ee360e,"Thanks to the development of genetic engineering, various kinds of genomic information are being unveiled.Hence, it becomes feasible to analyze the entire genomicinformation all at once. On the other hand, the quantity ofthe genomic information stocked on databases is increasingday after day. In order to process the whole information, wehave to develop an effective method to deal with lots of data.Therefore, it is indis ensable not only to make an effectiveand rapid algorithm but also to use high-speed computerresource so as to analyze the biological information. Forthis purpose, as one of the most promised computing environments, the grid computing architecture has appearedrecently. The European Data Grid (EDG) is one of the data-oriented grid computing environments [11].In the field of bioinformatics, it is important to findunique sequences to succeed in molecular biological experiments [6]. Once unique sequences have been found, theycan be useful for target specific probes/primers design, genesequence comparison and so on. In this paper, we propose amethod to discover unique sequences from among genomicdatabases located in a distributed environment. Next, weimplement this method upon the European Data Grid andshow the calculation results for E. coli genomes.",data oriented architecture,315
5e2ae9b3af8a65e329467b57ea1874659de584e6,filtered,semantic_scholar,2020 3rd International Conference on Hot Information-Centric Networking (HotICN),43831,semantic_scholar,hierarchical identity-based security mechanism using blockchain in named data networking,https://www.semanticscholar.org/paper/5e2ae9b3af8a65e329467b57ea1874659de584e6,"Named Data Networking (NDN) with the data-centric design has been viewed as a promising future Internet architecture. It requires a new security model orienting data but not host. In this paper, a Hierarchical Identity-based Security Mechanism by Blockchain (HISM-B) is to be proposed for NDN networks. It could satisfy the two assumptions specified in the NDN testbed to maintain the data-oriented authentication. At one hand, the hierarchical identity-based cryptology is used to bind the data name with the public key and then two signatures are encapsulated in the data packet so that the data source authentication and the integrity of data packet can be supported. At the other hand, a blockchain is employed to manage public keys for different domains to avoid catastrophes due to a single node failure. The validation result shows that the proposed HISM-B is safe.",data oriented architecture,316
e585a4d141b078b4fffcdb6355a24770c28bbfd2,filtered,semantic_scholar,,39814,semantic_scholar,data-oriented internet routing architecture,https://www.semanticscholar.org/paper/e585a4d141b078b4fffcdb6355a24770c28bbfd2,"This paper proposes a data-oriented routing architecture(DORA) which inherently supports endpoints mobility,data replication and migration.DORA routes directly on nodes and data's flat names,which gets rid of IP addresses and Reference Resolution Server(RRS) such as DNS.It takes data and service as first class objects like endpoints while considering endpoints as aggregations of data and service logically.This model provides an extendable,secure framework for future Internet with simple routing mechanism.",data oriented architecture,317
88af34df634edebdfe39871f82166e61ad0a4835,filtered,semantic_scholar,,40179,semantic_scholar,electronic communications of the easst volume 28 ( 2010 ) proceedings of the third international discotec workshop on context-aware adaptation mechanisms for pervasive and ubiquitous services ( campus 2010 ) modelling feedback control loops for self-adaptive systems,https://www.semanticscholar.org/paper/88af34df634edebdfe39871f82166e61ad0a4835,"Feedback Control Loops (FCLs) are the heart of any self-adaptive system. Existing engineering approaches for building self-ad aptive systems mask FCL by providing abstraction layers that hide the application c mplexity. In this paper, we investigate a model-driven approach for the engineering of FCLs whose architecture is based on the Service Component Architecture (SCA) model. Our proposal consists in exploiting the data streaming model, to specify the characteristics of the control policies, and to generate FCLs of self-adaptive sys tem deployed in largescale environment. We argue that the use of a data-oriented m odel for designing self-adaptive systems significantly increases FCL visibil ity.",data oriented architecture,318
05fbbfb5cdab641e15c49690064b9aa1728bd2c3,filtered,semantic_scholar,,42005,semantic_scholar,non-volatile in-memory computing,https://www.semanticscholar.org/paper/05fbbfb5cdab641e15c49690064b9aa1728bd2c3,"The analysis of big-data at exa-scale (1018 bytes or flops) has called for an urgent need to re-examine the existing hardware platform that can support intensive data-oriented computing. A big-data-driven application requires huge bandwidth and yet able to ensure low-power density. For example, web-searching application involves crawling, comparing, ranking, and paging of billions of web-pages with extensive memory access. The existing memory technologies have critical challenges of scaling at nano-scale due to process variation, leakage current and I/O access limitations. Recently, the emerging non-volatile memory (NVM) technologies such as resistive-RAM (ReRAM), spintransfer torque RAM (STT-RAM), domain-wall nanowire racetrack memory etc., have all shown significantly reduced standby power and increased integration density, not forgetting the close-to DRAM/SRAM access speed. Therefore, they are considered as promising candidates of universal memory for future big-data applications. The primary challenge to validate a hybrid design with both CMOS and nonvolatile devices is the lack of design platform that can validate the large-scale NVM circuit and system design accurately and efficiently. In addition, due to the use of non-electrical states of emerging NVM devices, new cells structures and their agreeing circuits for both read and write operations are needed to harness non-volatile memory with unique operations. For example, the transistor-free crossbar array that associates with NVM is different from conventional access transistor based memory structure. What is more, leveraging the NVM for computing, one also needs to examine the potential logic-inmemory computing architecture with significantly improved bandwidth and reduced power. In order to tackle above challenges ranging from device to system levels, this PhD thesis has explored the development of NVM design platform to support designs of non-volatile memories, readout and logic circuit designs, as well as the in-memory computing architecture. For the NVM design platform, the target is to perform accurate yet efficient circuit level simulation. The previous approaches either ignore dynamic effect without considering non-volatile states for dynamic behavior, or need equivalent circuits with high complexity to curve-fit non-linearity of those devices. We proposed a SPICE simulaiii tor named NVM-SPICE. This tool takes advantages of its new modified nodal analysis (MNA) framework, which can effectively support the non-electrical state variables of emerging non-volatile devices, such as ReRAM and spintronics devices. Due to the physics based modeling approach, NVM-SPICE is able to perform hybrid NVM/CMOS circuits efficiently and accurately. Compared to the equivalent circuit model based approach, the NVM-SPICE simulator exhibits more than 117x faster simulation speed for spintronics category devices and 40x faster speed for RRAM category devices. For NVM in-memory architecture, both memory elements and logic elements are implemented by emerging spintronics devices, which leads to a system purely composed of non-volatile devices. The detailed non-volatile memory and logic circuits are explored within the NVM-SPICE platform. In addition, logic is built inside the memory so that the I/O workload can be alleviated. Applications such as data retention, encryption, machine learning that play critical roles for big-data computing are explored within the non-volatile in-memory architecture. The evaluation results show that the purely non-volatile memory based platforms with in-memory architecture greatly contribute to power efficiency and throughput improvement for big-data oriented applications, and thus are potential candidates to be next generation information and communication technology.",data oriented architecture,319
c78864537e89a1cfb3d1c0c86d1c0798f06957c3,filtered,semantic_scholar,Euro-Par Workshops,42736,semantic_scholar,on the effects of data-aware allocation on fully distributed storage systems for exascale,https://www.semanticscholar.org/paper/c78864537e89a1cfb3d1c0c86d1c0798f06957c3,"The convergence between computing- and data-centric workloads and platforms is imposing new challenges on how to best use the resources of modern computing systems. In this paper we show the need of enhancing system schedulers to differentiate between compute- and data-oriented applications to minimise interferences between storage and application traffic. These interferences can be especially harmful in systems featuring fully distributed storage systems together with unified interconnects, such as our custom-made architecture ExaNeSt. We analyse several data-aware allocation strategies, and found that such strategies are essential to maintain performance in distributed storage systems.",data oriented architecture,320
f16778cf55577077edc2105942cfd1f3107b27e6,filtered,semantic_scholar,MobiSys 2007,39083,semantic_scholar,programming and securing service-oriented wireless sensor networks,https://www.semanticscholar.org/paper/f16778cf55577077edc2105942cfd1f3107b27e6,"Our demonstrator shows the implementation of a Serviceoriented Architecture (SoA) for wireless sensor-actuator networks (WSAN). It demonstrates the feasibility of our serviceoriented system in a real-world, resource-restricted WSAN based on off-the-shelf MICAz motes running the operation system TinyOS. In contrast to data-oriented approaches our service-oriented system does not only provide ”traditional” uni-directional data transfer (from sensor nodes to a base station), but also enables autonomous collaboration of sensor nodes. The nodes collaborate in the sense that the input of several sensors is used to trigger actuators, which in turn affect the sensor readings etc. For demonstration purposes we built an intelligent greenhouse that autonomously adapts its ambience in order to cultivate plants according to their individual and collective needs (see Figure 1). E.g., the lighting of the greenhouse is adapted considering all plants’ needs and the sunlight. For visualization we constructed a miniature version of the greenhouse with several plants. The greenhouse itself as well as the plants within are all equipped with various sensors and actuators in order to measure and modify the plants’ ecosystem (i.e. light and soil humidity). We also simulate external influence on the ecosystem, such as the influence of the sun on the greenhouse’s light control. Protocol details of our service-oriented system can be observed via a couple of PDAs connected to the sensor nodes. These PDAs allow for inspecting and changing the internal state of sensor nodes. Hence, attendees of the demonstration can use these PDAs to interact with the WSAN. We show two fundamental aspects of our Service-oriented Architecture in the demonstration: • Service description and execution: The intelligent greenhouse application is composed of services. The services are described and executed by Talassa (Tasking Language for Service-oriented Sensor-Actuator Networks [1]). • Secure lookup of available services: Services are stored in a distributed service directory, SCAN (Secure Content Addressable Network [2]). As this is a security critical component of our architecture, SCAN has been designed to provide secure service discovery. Talassa is a description language for distributed WSAN applications based on services. An application consists of a number of atomic services, which perform either basic hardware interaction or influence the control flow of other services. A virtual machine on each sensor node executes any of the above mentioned service types and provides inter-service new plant “sun”",data oriented architecture,321
359cd4a6c9c23c6b5b2669c434dcab262f59f9e2,filtered,semantic_scholar,,39448,semantic_scholar,a data-oriented software architecture for telemetry,https://www.semanticscholar.org/paper/359cd4a6c9c23c6b5b2669c434dcab262f59f9e2,"Building modern telemetry systems is fraught with challenges involving subsystem integration, the role and management of data, scalability issues, disparate technologies, concerns about costeffectiveness and more. This article addresses today’s challenges with a solution based on adopting a data-oriented architecture and relying on a standards-based, integrated highperformance middleware platform with standards-based programmable components. Key to the solution is integrating around the system information model instead of the application or technology infrastructure. A standards-based middleware infrastructure that breaks away from traditional assumptions is at the core of this approach. The article also presents successful applications of data-oriented architecture using standards-based middleware.",data oriented architecture,322
99b369f722dd4e7c21d173d1281de767993de7e2,filtered,semantic_scholar,2012 IEEE 28th International Conference on Data Engineering,40909,semantic_scholar,provenance-based debugging and drill-down in data-oriented workflows,https://www.semanticscholar.org/paper/99b369f722dd4e7c21d173d1281de767993de7e2,"Panda (for Provenance and Data), a system for data-oriented workflows that supports debugging and drill-down using logical provenance-provenance information stored at the processing-node level is demonstrated. In this demonstration, Panda is used to integrate, process, and analyze actual education data from multiple sources.",data oriented architecture,323
70804d851dfe5995fce4eb99c065c0af481c8ce4,filtered,semantic_scholar,2013 IEEE 29th International Conference on Data Engineering (ICDE),41275,semantic_scholar,logical provenance in data-oriented workflows?,https://www.semanticscholar.org/paper/70804d851dfe5995fce4eb99c065c0af481c8ce4,"We consider the problem of defining, generating, and tracing provenance in data-oriented workflows, in which input data sets are processed by a graph of transformations to produce output results. We first give a new general definition of provenance for general transformations, introducing the notions of correctness, precision, and minimality. We then determine when properties such as correctness and minimality carry over from the individual transformations' provenance to the workflow provenance. We describe a simple logical-provenance specification language consisting of attribute mappings and filters. We provide an algorithm for provenance tracing in workflows where logical provenance for each transformation is specified using our language. We consider logical provenance in the relational setting, observing that for a class of Select-Project-Join (SPJ) transformations, logical provenance specifications encode minimal provenance. We have built a prototype system supporting the features and algorithms presented in the paper, and we report a few preliminary experimental results.",data oriented architecture,324
47963243de795b321fe10edb46a3a9d1931960ec,filtered,semantic_scholar,,35796,semantic_scholar,toward an exemplar-based computational model for cognitive grammar,https://www.semanticscholar.org/paper/47963243de795b321fe10edb46a3a9d1931960ec,"An exemplar-based computational framework is presented which is compatible with Cognitive Grammar. In an exemplar-based approach, language acquisition is modeled as the incremental, data-oriented storage of experiential patterns, and language performance as the extrapolation of information from those stored patterns on the basis of a language-independent information-theoretic similarity metric. We show that this simple architecture works for many aspects of phonological, morphological, and morphosyntactic acquisition and processing. Furthermore, we sketch how the approach may also work for syntactic processing. A central insight of the approach, based on the results of computational modeling experiments, is that abstraction of representations is not only unnecessary to achieve generalization (i.e. to make the system productive, and to make it gòbeyond' the learned patterns), but even harmful, and that useful language-independent metrics can be found for deening similarity in the context of language processing. In the generative tradition, generality is achieved by means of abstraction, and the representations of choice to describe these abstractions are rules. This implies that redundancy and the storage of individual instances are to be avoided, except for exceptions to the generalizations expressed in rules. In Langacker, 1991 (Chapter 10), this methodology is critically examined, and cognitive grammar is described as an alternative usage-based model of language structure. In the latter, bottom-up, approach, patterns (rules, generalizations) and (redundant) instantiations of those rules are assumed to co-exist in the grammar, describing phenomena at all levels of generality, from exceptionless regularities to idiosyncratic exceptions. Rules are presumed to be necessary for the computation of novel instantiations. In the remainder of this paper we will introduce an exemplar-based approach to language acquisition and processing. The approach is in large part compatible with Lan-gacker's usage-based model, but is more radical in its ""maximalism"": language knowledge is supposed to consist only of ""instantiations"" (exemplars); there is no role for explicit abstractions corresponding to (sub)regularities. We will argue on the basis of computational modeling experiments that the adoption of abstractions (rules, patterns), taken as necessary for explaining generalization and productivity in both the generative and the cognitive grammar approach, is misguided. Furthermore, the exemplar-based approach contributes to making cognitive grammar ideas more concrete by providing computational operationalisations of both acquisition and processing in such a framework.",data oriented architecture,325
ce7bfaf9f4ca87e9fe236484972a0b64922b654d,filtered,semantic_scholar,"Proceedings 2002 Design, Automation and Test in Europe Conference and Exhibition",37257,semantic_scholar,highly scalable dynamically reconfigurable systolic ring-architecture for dsp applications,https://www.semanticscholar.org/paper/ce7bfaf9f4ca87e9fe236484972a0b64922b654d,"New parallel execution based machine paradigms must be considered. Thanks to their high level of flexibility structurally programmable architectures are potentially interesting candidates to overcome classical CPUs limitations. Based on a parallel execution model, we present in this paper a new dynamically reconfigurable architecture, dedicated to data oriented applications acceleration. Principles, realizations and comparative results will be exposed for some classical applications, targeted on different architectures.",data oriented architecture,326
f1d7ddb9bc63fee86bfece409732bd977899b254,filtered,semantic_scholar,CFI,40909,semantic_scholar,on adapting http protocol to content centric networking,https://www.semanticscholar.org/paper/f1d7ddb9bc63fee86bfece409732bd977899b254,"Designed around host-reachability, today's Internet architecture faces many limitations while serving content-oriented applications which generate most traffic load to the Internet. CCN (Content Centric Networking) [1] is one of the most important proposals for future Internet architecture, which aims to build a content/data oriented network to solve these limitations. On the other hand, HTTP is the most important protocol to deploy new services and applications on current TCP/IP-based Internet. In this paper, we attempt to run HTTP protocol on CCN and combine the two by stitching them semantically on their content-oriented features, such as content caching. We expect that this combination can be leveraged to build CCN testbed with real HTTP traffic which is vital to validation and redesigning of specific mechanisms of CCN and to finding a transition way of CCN in which great incentive is provided for service providers in the economic ecosystem of content distribution. We designed and implemented a HTTP-CCN gateway to transform HTTP request and HTTP response into CCN Interest and Data respectively. We illustrate how to semantically map HTTP caching to CCN caching, which is one of the most attractive properties of CCN. We also discuss how to achieve transparent caching with CCN and find out that it is nontrivial to achieve complete transparency of caching with CCN given no cooperation with CDNs and content providers.",data oriented architecture,327
9a441988271473b1a5d3205331cbd6dff3502f95,filtered,semantic_scholar,,42736,semantic_scholar,"wireless sensor network based smart grid communications: cyber attacks, intrusion detection system and topology control",https://www.semanticscholar.org/paper/9a441988271473b1a5d3205331cbd6dff3502f95,"The existing power grid is going through a massive transformation. Smart grid technology is a radical approach for improvisation in prevailing power grid. Integration of electrical and communication infrastructure is inevitable for the deployment of Smart grid network. Smart grid technology is characterized by full duplex communication, automatic metering infrastructure, renewable energy integration, distribution automation and complete monitoring and control of entire power grid. Wireless sensor networks (WSNs) are small micro electrical mechanical systems that are deployed to collect and communicate the data from surroundings. WSNs can be used for monitoring and control of smart grid assets. Security of wireless sensor based communication network is a major concern for researchers and developers. The limited processing capabilities of wireless sensor networks make them more vulnerable to cyber-attacks. The countermeasures against cyber-attacks must be less complex with an ability to offer confidentiality, data readiness and integrity. The address oriented design and development approach for usual communication network requires a paradigm shift to design data oriented WSN architecture. WSN security is an inevitable part of smart grid cyber security. This paper is expected to serve as a comprehensive assessment and analysis of communication standards, cyber security issues and solutions for WSN based smart grid infrastructure.",data oriented architecture,328
2a3dc2175ab29ae1ff34837eac2865553f66e1fc,filtered,semantic_scholar,FPL,36892,semantic_scholar,the systolic ring: a dynamically reconfigurable architecture for embedded systems,https://www.semanticscholar.org/paper/2a3dc2175ab29ae1ff34837eac2865553f66e1fc,"Internet is becoming one of the key features of tomorrow's communication world. The evolution of mobile phones networks, such as UMTS will soon allow everyone to be connected, everywhere. These new network technologies bring the ability to deal not only with classical voice or text messages, but also with improved content: multimedia. At the mobile level, this kind of data oriented content requires highly efficient architectures; and nowadays mobile system-on-chip solutions will no longer be able to manage the critical constraints like area, power and data computing efficiency. In this paper we will propose a new dynamically reconfigurable network, dedicated to data oriented applications such as the one allowed on third generation networks. Principles, realizations and comparative results will be exposed for some classical applications targeted on different architectures.",data oriented architecture,329
85d191b722bf7e0724cb431d7bef69d1cad8b54a,filtered,semantic_scholar,China Communications,42736,semantic_scholar,"digital rights management: model, technology and application",https://www.semanticscholar.org/paper/85d191b722bf7e0724cb431d7bef69d1cad8b54a,"with rapid achievement of current information technology and computing ability and applications, much more digital content such as films, cartoons, design drawings, office documents and software source codes are produced in daily work, however to protect the content being copying, shared or deliberately stolen by inside or outside, digital rights management (DRM) became more and more important for digital content protection. In this paper, we studied various DRM model, technology and application, and first proposed DRM Security Infrastructure (DSI), in which we defined encryption, hash, signature algorithm, watermarking algorithms, authentication, usage control, trusted counter, conditional trace, secure payment, and based on the DSI we then proposed a whole classification approach and architecture of all kinds of DRMs, in which we proposed 6 typical classes of copyrights and content protection DRMs architecture: (1) Software-oriented DRM,(2) eBook-oriented DRM, (3) Video-oriented DRM, (4)Image-Oriented DRM (5) Unstructured data oriented DRM, (6) Text-oriented DRM. Based on the above DSI, we then proposed a dynamic DRM model selection method for various DRM application, which can be adapted dynamically for different technology of different applications, which can provide a whole solution for variant DRM development in a rapid and customized mode. The proposed DRM method, technology and application in this paper provided a common, flexible and extendable solution for variant DRM scenes, and can support rapid and customized development. Moreover, we proposed an opinion that the future life will enter into a new era that the content usage and consumption will not again adopt DRM technology rather than with law, liberty and morality.",data oriented architecture,330
522f493d89ff29bde79d6b5ec87e09983f9a1573,filtered,semantic_scholar,,37622,semantic_scholar,an abstract modeling approach towards system-level design-space exploration,https://www.semanticscholar.org/paper/522f493d89ff29bde79d6b5ec87e09983f9a1573,"Integration of increasingly complex systems on a chip augments the need of system-level methods for specification and design. In the earliest phases of the design process important design decisions can be taken on the basis of a fast exploration of the design space. This paper describes an abstract modeling approach towards system-level design-space exploration, which is formal and flexible. It uses a uniform system model that contains both functional and architectural information. Disjunct, parameterizable resources represent the real-time behavior of the target architecture. Due to the expressiveness of the modeling language (POOSL), control as well as data oriented behavior can be specified in the functional part of the system model. Well-founded design decisions can be taken as a result of performance estimations that are based on Markov theory.",data oriented architecture,331
e4313c807b2de4d0d1c4078cb2bebdd6a4576022,filtered,semantic_scholar,Wirel. Pers. Commun.,38353,semantic_scholar,analysis of sub-carrier multiplexed radio over fiber link for the simultaneous support of wlan and wcdma systems,https://www.semanticscholar.org/paper/e4313c807b2de4d0d1c4078cb2bebdd6a4576022,"The present third generation (3G) wireless technology can provide data oriented applications. However, the bit rate is limited to around 2 Mbps with limited mobility. Today, more applications demand high data rate and reasonable mobility. Therefore, by integrating 3G cellular system and wireless local area network (WLAN), there is a potential to push the data rate higher. This integration means 3G cellular users can enjoy high data rate at a location that is within WLAN coverage area. Similarly, WLAN users also can have data services as long as they are under the coverage of the 3G cellular system. The 3G cellular system has a much larger coverage than the WLAN. In this paper, we present the first step toward an integration of the two systems. This paper presents a fiber-wireless architecture that simultaneously supports the wideband code division multiple access (WCDMA) system and the IEEE 802.11b WLAN. Our approach uses sub-carrier multiplexed (SCM) architecture to combine and transmit 2.4 GHz WLAN and 1.9 GHz WCDMA signals through an optical fiber from a central base station (CBS) to a radio access point (RAP, single antenna unit). After the fiber, the signals continue to propagate through the air interface to respective mobile stations. The WLAN access point is also located at the CBS. For the SCM architecture, we investigate three areas: i) the signal to noise ratio of the uplink and the downlink, ii) the cell coverage area for the WCDMA and WLAN systems, and iii) the throughput of the IEEE 802.11b WLAN. Our results show that with up to 2.5 km cell radius, better than 18 dB SNR is possible with 5 km fiber link for WLAN system. Simultaneously, the WCDMA system has at least 18 dB SNR for a cell coverage radius of 8 km. These numbers depend on the relative RF power of each system in the fiber.",data oriented architecture,332
3fa248cfa1491c657bb5f32f237fac4a6a882bfe,filtered,semantic_scholar,,34335,semantic_scholar,communications architecture: towards a more robust understanding of information flows and emergent patterns of communication in organizations,https://www.semanticscholar.org/paper/3fa248cfa1491c657bb5f32f237fac4a6a882bfe,"With the proliferation of telecommunications technologies, the information-based communication infrastructure is becoming an increasingly critical organization resource. In order effectively to channel limited resources (skills, capital, technology) to the most strategically critical communication needs of the organization, the development of business driven planning methodologies which result in a well-defined architecture (blueprint) of organizational communication processes are needed. Unfortunately, while architectural issues are of utmost importance today, researchers have focused almost exclusively on data oriented models. This study attempts to expand this view and provide a holistic representation of information architecture. With the perspective provided by this definitional framework, two methods for development of communications architecture are discussed and evaluated: (1) a flow based approach; and (2) network analysis. Network analysis in particular shows great promise in constructing robust representations of organizational communication processes.",data oriented architecture,333
072c3011c75630fb4a49aa6171533f631747fe0b,filtered,semantic_scholar,,33604,semantic_scholar,a mathematical model of cpu,https://www.semanticscholar.org/paper/072c3011c75630fb4a49aa6171533f631747fe0b,"This paper is based on a previous work of the first author [12] in which a mathematical model of the computer has been presented. The model deals with random access memory, such as RASP of C. C. Elgot and A. Robinson [11], however, it allows for a more realistic modeling of real computers. This new model of computers has been named by the author (Y. Nakamura, [12]) Architecture Model for Instructions (AMI). It is more developed than previous models, both in the description of hardware (e.g., the concept of the program counter, the structure of memory) as well as in the description of instructions (instruction codes, addresses). The structure of AMI over an arbitrary collection of mathematical domains N consists of: a non-empty set of objects, the instruction counter, a non-empty set of objects called instruction locations, a non-empty set of instruction codes, an instruction code for halting, a set of instructions that are ordered pairs with the first element being an instruction code and the second a finite sequence in which members are either objects of the AMI or elements of one of the domains included in N, a function that assigns to every object of AMI its kind that is either an instruction or an instruction location or an element of N, a function that assigns to every instruction its execution that is again a function mapping states of AMI into the set of states. By a state of AMI we mean a function that assigns to every object of AMI an element of the same kind. In this paper we develop the theory of AMI. Some properties of AMI are introduced ensuring it to have some properties of real computers: a von Neumann AMI, in which only addresses to instruction locations are stored in the program counter, data oriented, those in which instructions cannot be stored in data locations, halting, in which the execution of the halt instruction is the identity mapping of the states of an AMI, steady programmed, the condition in which the contents of the instruction locations do not change during execution,",data oriented architecture,334
407ebbe7b9a024c71d459a370deaf614455e3c8e,filtered,semantic_scholar,,42736,semantic_scholar,named data networking in vanet: a survey,https://www.semanticscholar.org/paper/407ebbe7b9a024c71d459a370deaf614455e3c8e,"Named Data Networking is futuristic data oriented communication model, currently applied to different area of networking. VANET is one area of networking, that named data networking applied on it, to overcome the problem of classically TCP/IP based architecture. As VANET has become a likely area in wireless communication, which can provide a lot of service: traffic efficiency, road safety, and driving comfort. So, Named data networking architecture provide a lot purpose for VANET such as in network caching, security and efficient data distribution between vehicles due to caching capabilities in NDN, this feature make VANET more efficient than TCP/IP network. In existing IP based internet architecture the end points identified by IP addresses but in NDN contents are named with human readable names that provide VANET to retrieve data by sending content name without knowing the location of the provider. This paper also present some research challenge in the VANET via NDN. Keywords— NDN, VANET, Caching, ICN.",data oriented architecture,335
c23d90df3f71a8621b9a56482e4e5232f3c86de8,filtered,semantic_scholar,2017 International Conference On Smart Technologies For Smart Nation (SmartTechCon),42736,semantic_scholar,ddos attack mitigation and resource provisioning in cloud using fog computing,https://www.semanticscholar.org/paper/c23d90df3f71a8621b9a56482e4e5232f3c86de8,"Security and reliability are essential in cloud computing environment. Researchers are exploring all features of cloud from scheduling policies, cloud network architecture, virtualization, I/O efficiency, hypervisor performance scalability, data confidentiality and data integrity of data oriented applications. Therefore, the need to secure cloud has become inevitable. Nowadays, one of the biggest challenges faced by cloud users and cloud service providers is DDoS attack. Distributed denial-of-service attack [3] compromises the availability of the system services. In the cloud, DDoS attacks target the services offered by the cloud, reducing their ability to provide optimal use of the network resources. Furthermore, this resource exhaustion by illegitimate traffic results in large billing for customers for the services they never used also known as EDoS (Economic Denial of Sustainability) attack. Fog computing [6] is an intermediate layer between cloud and users. It is similar to the cloud and can provide services like computation, data, networking, and storage between end users and cloud servers and hence fog can provide defense against DDoS even before it reaches the cloud. Therefore, saving cloud resources and providing faster response time. This paper proposes a framework for DDoS attack detection and efficient resource provisioning in a cloud environment with the help of Fog computing by using an efficient algorithm to service cloud request effectively by intermediate fog servers. Hence, provide quick response time and efficient utilization of resources.",data oriented architecture,336
71486129fd8ca17e9ae2fbdef984f82dac85d1c3,filtered,semantic_scholar,,34335,semantic_scholar,analyzing and tuning memory performance in sequential and parallel programs,https://www.semanticscholar.org/paper/71486129fd8ca17e9ae2fbdef984f82dac85d1c3,"Recent architecture and technology trends have led to a significant gap between processor and main memory speeds. Responding to this gap, architects have introduced cache memories that are placed between processors and memories to mask high latencies. If cache misses are common, however, memory stalls can still significantly degrade execution time. To help identify and fix such memory bottlenecks, this work presents techniques to efficiently collect detailed information about program memory performance and effectively organize the data collected. These techniques help guide programmers or compilers to memory bottlenecks. They apply to both sequential and parallel applications and are embodied in the MemSpy performance monitoring system. 
Experiences performance tuning several programs have driven this research, leading to the following conclusions. First, this thesis contends that the natural interrelationship between program memory bottlenecks and program data structures mandates the use of data oriented statistics, a novel approach that associates program performance information with application data structures. Data oriented statistics, viewed alone or paired with traditional code oriented statistics, offer a powerful, new dimension for performance analysis. The dissertation develops techniques for aggregating statistics on similarly-used data structures and for extracting intuitive source-code names for statistics. 
Second, this thesis also argues that detailed statistics on the frequency and causes of cache misses are crucial in understanding memory bottlenecks. Common memory performance bugs are most easily distinguished by noting the causes of their resulting cache misses. Offering such information, MemSpy's performance profiles have been invaluable in analyzing memory bottlenecks in several applications. 
Third, since collecting such detailed information seems, at first glance, to require large execution time slowdowns, this dissertation also evaluates techniques to improve the performance of MemSpy's simulation-based monitoring. The first optimization, hit bypassing, improves simulation performance by specializing processing of cache hits. The second optimization, reference trace sampling, improves performance by simulating only sampled portions out of the full reference trace. Together, these optimizations reduce simulation time by nearly an order of magnitude. Overall, having used MemSpy to tune several applications, these experiences demonstrate that MemSpy generates effective memory performance profiles, at speeds competitive with previous, less detailed approaches.",data oriented architecture,337
e37dc12244835202a18918a0cd811fc5599a4580,filtered,semantic_scholar,PEARC,42736,semantic_scholar,spark on the arc: big data analytics frameworks on hpc clusters,https://www.semanticscholar.org/paper/e37dc12244835202a18918a0cd811fc5599a4580,"In this paper we document our approach to overcoming service discovery and configuration of Apache Hadoop and Spark frameworks with dynamic resource allocations in a batch oriented Advanced Research Computing (ARC) High Performance Computing (HPC) environment. ARC efforts have produced a wide variety of HPC architectures. A common HPC architectural pattern is multi-node compute clusters with low-latency, high-performance interconnect fabrics and shared central storage. This pattern enables processing of workloads with high data co-dependency, frequently solved with message passing interface (MPI) programming models, and then executed as batch jobs. Unfortunately, many HPC programming paradigms are not well suited to big data workloads which are often easily separable. Our approach lowers barriers of entry to HPC environments by enabling end users to utilize Apache Hadoop and Spark frameworks that support big data oriented programming paradigms appropriate for separable workloads in batch oriented HPC environments.",data oriented architecture,338
8d5c20a21b6506f41224ea5a48981635da0604d5,filtered,semantic_scholar,VLSI-SOC,36892,semantic_scholar,dynamically reconfigurable architectures for digital signal processing applications,https://www.semanticscholar.org/paper/8d5c20a21b6506f41224ea5a48981635da0604d5,"Tomorrow’s pocket devices will all have Internet-based communication capabilities. The advent of mobile phones, PDAs (Pocket Data Assistant) and pocketPC’s joint to the newcomer’s third generation wireless networks such as UMTS will soon allow everyone to be connected, everywhere. In this competitive marketplace where many similar products compete for the consumer attention, performances level is a very important criterion.Videoconferencing, digital music broadcast, speech recognition are a few example of the new features allowed by the new third generation networks. This kind of multimedia, data oriented content requires highly efficient architectures; and nowadays mobile system-on-chip solution will no longer be able to deal with the critical constraints like area, power, and data computing efficiency. In this paper we will propose a new dynamically reconfigurable network, dedicated to data oriented applications such as the one targeted on third generation networks. Principles, realisations and comparative results will be exposed for some classical applications, targeted on different architectures.",data oriented architecture,339
354cc746560319b71c63ef2d994a095e72ddc5da,filtered,semantic_scholar,,40909,semantic_scholar,development a prototype of academic performance among university students,https://www.semanticscholar.org/paper/354cc746560319b71c63ef2d994a095e72ddc5da,"In the modern world the power of communication through internet has been dramatically increased. New technology with new concept is well envisioned to effect the end users in the form of providing data oriented services. Through an effective management of information the accuracy of the information would be increased which will increase the academic performance of the university students. Usually the new WAP technology is very popularly used by the architecture students to make the work effective. Two surveys were conducted to know the students limitations for the performance and to know the system usability which could improve academic performance. The development of the project is based on the SDLC in Object-Oriented approaches and takes UML as the modeling system while the development of the system uses WAPTOR and mobile explorer language. Due to the time constraint, this project does not fully complete its functionality as shown in the prototype. Therefore, it is recommended that future research to be carried out in order to enhance and expand the service of the application by taking this prototype as a starting point of the development.",data oriented architecture,340
9f61bfc639881db910df322ea15c25ab7cbb7d5f,filtered,semantic_scholar,ICDCN,41640,semantic_scholar,towards a new internetworking architecture: a new deployment approach for information centric networks,https://www.semanticscholar.org/paper/9f61bfc639881db910df322ea15c25ab7cbb7d5f,"New research efforts are trying to evolve the current Internet. With satisfying communication hardware, the intent is to switch to data oriented networks. In this new vision, data will be the heart of the architecture and protocols have to be changed to deal with this concept. Promising ideas are proposed up in order to develop clean slate design solutions. However, these propositions encounter many deployment problems. In this paper, we propose new approach based on Bloom Filter to cope with storage space problem in Data Oriented Networking Architecture DONA.",data oriented architecture,341
01d8df8f4964dc0dc8cbcb7d559459cce29010ea,filtered,semantic_scholar,Open Distributed Processing,34335,semantic_scholar,"open distributed processing, ii: proceedings of the ifip tc6/wg6.1 international conference on open distributed processing, berlin, germany, 13-16 september 1993",https://www.semanticscholar.org/paper/01d8df8f4964dc0dc8cbcb7d559459cce29010ea,"Opening of the ICODP'93 conference welcome speech of the president of the Technical University of Berlin message from the Berlin senate of economics and technology message from the German institute for standards. Part 1 Tutorials: reference model of open distributed processing - a tutorial, K.A. Raymond an ODP-oriented framework for European services in telemedicine, D. Lutzeback and B. Mahr. Part 2 Invited presentation: ODP-trader, M.Y. Bearman does midware provide an adequate distributed application environment?, J. Slonim et al medical applications of ODP, H. Hansen and R.D. Kutsche data oriented approach to business information modelling, R. Hotaka and M. Bjorn service engineering in RACE and its relation to ODP, M. Campolargo the challenges of CSCW for open distributed processing, G.S. Blair and T. Rodden. Part 3 Reviewed papers - session on trader: object trading in open systems, A. Goscinski and Y. Ni broadening the user environment with implicit trading, L. Kutvonen and P. Kutvonen a type management system for an ODP trader, J. Indulska et al contexts, views and rules - an integrated approach to trader contexts, K.A. Raymond and M.Y. Bearman. Part 4 Session on distributed systems: HARNESS - an evolving standard for distributed processing, A. Balis et al a distributed object-oriented platform based on DCE and C(++), P.G. Bosco et al is DCE a support environment for ODP?, A.D. Beitz et al. Part 5 Session on multimedia and quality of service: distributed application performance metrics and management, J.A. Rolia a language for the specification of interactive and distributed multimedia applications, P.F. Pinto and P.F. Linington distributed multimedia systems quality of service in ODP framework of abstraction - a first study, L. Fedaoui et al. Part 6 Session on distributed applications: home automation systems - ODP in the kitchen?, A. Munro federating expert systems in an ODP environment, N. Sharma ODP - a framework for defining service management reference configurations, L. Strick et al. Part 7 Session on design and modelling: new economic-driven aspects of the ODP enterprise specification and related quality of service issues, Z. Milosevic et al co-operation support for an open service market, M. Merz and W. Lamersdorf an object-oriented approach to the formal specification of ODP trader, J.S. Dong and R. Duke an improved model for transactional operations in RM-ODP, A. Berry and K.A. Raymond. Part 8 Workshops: architectural semantics in ODP, chair - C.A. Vissers the role of ODP in medical applications, chair - M. Gerenth and B. Mahr object management architecture, chair - J. Slitz.",data oriented architecture,342
b1ba63a67004633da7f3a7b635324f0eba90afdc,filtered,semantic_scholar,,40544,semantic_scholar,research on service-oriented geospatial information sharing mechanism and technical architecture,https://www.semanticscholar.org/paper/b1ba63a67004633da7f3a7b635324f0eba90afdc,"SOA is providing conceptual design pattern for service-oriented distributed systems, and Web service is one of standards-based implementation of SOA technologies, deployed on the Web as an object or component. Survey the whole paper, get two points. First of all, it compares the spatial data oriented sharing with the spatial information service oriented sharing on technology and feature, and analysis of the service-oriented spatial information sharing mechanism and the implementation of ideas; Secondly, it frames a service-based geospatial information sharing platform, expounding the key technology and organizing way of spatial information based on Web Service. Offer solutions for GIS data integration and spatial information sharing that platform-crossed and sector-crossed.",data oriented architecture,343
2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,filtered,semantic_scholar,,38353,semantic_scholar,model checking circus,https://www.semanticscholar.org/paper/2e33065f8eb82609bbb1deb7e76ca373a3a1b5d2,"As software complexity increases, so does the need for precision. For some areas, such as high-integrity and safety-critical domains, this precision is imperative rather than optional. To address this issue, both academia and industry have been applying formal methods and formal verification techniques, where model checking and theorem proving are the most successful. Model checking is a verification technique that exhaustively searches the state space of a system represented by some formal notation. It became a successful technique applied by both academia and industry, due to its high level of automation and the ability to provide counter-examples as a debugging device in the case of failure. The difficulty of applying this technique is the state explosion problem that often happens in software verification, hence making such technique unsuitable for representation by computer. In order to finitely represent infinite state systems to be analysed by computer, one needs to resort to the more powerful technique of theorem proving. It allows precise description with less compromise on the state representation, as it uses symbols and quantifiers rather than actual values. The problem is that the higher the expressiveness of a notation, the lower the level of automation that it supports and greater the demand for user expertise and interactivity. The maturity of these techniques, as well as the wide availability of tools, pushed the demand for more expressive techniques with powerful automation tool support. Thus, combination of formalisms and their tools have become a topic of great interest in current research in formal methods. The combination of formalisms usually involve blending mature techniques that cover different aspects of software development in a common semantical framework. For instance, combining data oriented languages, such as Z and B, with behaviour oriented languages, such as CCS and CSP has been the focus of considerable research. The next step in this direction is to provide tool support for these combined languages. The combination of model checking and theorem proving have become the state-of-the-art in terms of tool development for formal verification techniques, as it combines expressiveness with high levels of automation. In this thesis, our main goal is to provide model checking support with integrated theorem proving for Circus, a concurrent language for refinement that combines Z, CSP, and the refinement calculus. Its semantic model is based on Hoare and He’s Unifying Theories of Programming (UTP), which provides an integrated theoretical framework for development and extension of different programming paradigms. From the partnership of our research group with QinetiQ Malvern, it is clear that there is demand for integrated formalisms and respective tool support. Our aim is to provide tool support for Circus, in order to allow its use in real applications, where we are able to formally specify different aspects of systems including, but not limited to, data and behaviour. As Circus is based in UTP, it is possible to integrate other aspects, such as mobility, and real-time, and research in these fronts is well advanced. To fulfill our goal, we provided an operational semantics for model checking Circus, which enables the representation of Circus programs as automata, as well as a search algorithm enabling us to establish refinement between two programs. Throughout the development process, we have decided to take our own medicine and use formal specification and verification, in order to increase the levels of integrity of our tools and techniques. The semantics and the underlying automata theory has been formally defined and mechanised in the Z/Eves theorem prover. Next, we proposed a model checking architecture, which integrates theorem proving facilities, and is implemented as a model checker prototype in Java. This architecture has been formally defined in Circus itself, and we augmented the Java code with JML annotations and assertions representing our findings from the formal specification. Finally, from the abstract Circus specification of the model checker architecture, we calculated a sequential refinement search algorithm using Circus refinement laws, where generated proof obligations have been discharged using Z/Eves again. This effort gave rise to a prototype model checking tool for Circus, which integrates refinement model checking with theorem proving in an extensible framework compliant with the Z Standard.",data oriented architecture,344
8d6f619df7eec8409c63e50d1a491697efd8c92f,filtered,semantic_scholar,CLOSER,40544,semantic_scholar,a collaborative resource-based cloud architecture for freight logistics,https://www.semanticscholar.org/paper/8d6f619df7eec8409c63e50d1a491697efd8c92f,"Collaborative Cloud is the set of Cloud infrastructure, processes and standards, that allows companies to expose data and information as virtual resources, and manage them in collaboration with their partners and customers. The concept of Collaborative Cloud is realised with technologies such as global identifiers, data oriented services and content based messaging. The paper illustrates the application of Collaborative Cloud to a shipping logistics business to government (B2G) scenario called Single Window.",data oriented architecture,345
b27747686819c89faa029ac1b4dc483797211406,filtered,semantic_scholar,Proceedings of the 1994 IEEE International Conference on Robotics and Automation,34335,semantic_scholar,a parallel simulation of multiple mobile robots using the doris design method,https://www.semanticscholar.org/paper/b27747686819c89faa029ac1b4dc483797211406,"This paper introduces the data oriented requirements implementation scheme (DORIS) design strategy and the data interaction architecture demonstrator (DIADEM), by describing their use for a multiple-robot workspace simulation. The design process, the hardware and the software for the DIADEM are outlined, followed by a discussion of the design used for the simulation.<<ETX>>",data oriented architecture,346
4679087942b944a1463b6305dd355d0b2322c78e,filtered,semantic_scholar,2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA),43831,semantic_scholar,big data oriented light-load embedded performance modeling,https://www.semanticscholar.org/paper/4679087942b944a1463b6305dd355d0b2322c78e,"With increasing development of big data, the performance assessment and optimization face with a big challenge. The traditional methods widely use delivery-testinganalysis-solving (DTAS) ring. In big data area, big data environment is necessary for the testing phase in DTAS, which results in the big cost in both time and hardware. This paper proposes the big data oriented light-load embedded performance modeling. It ascertains the performance criteria to set the Capacity and Performance (C&P) factors. These factors will be embedded into the software with an on-off switch during the architecture, design and developing phases before DTAS phase. After the software coding done with embedded C&P factors, a small traffic load is run to collect the C&P data. The collected data will be used for the performance bottleneck finding, performance optimization, and forecasting the capacity and performance for various customers’ scenarios. Since the data easily help locate the issue, the required running traffic is small, and the problem solving is done before the traditional DTAS, this study is more suitable for the big data application. It can save more than 50% of time, decrease the software development efforts, and reduce the lab resources occupation. Finally, the proposed method is employed in the real prototype of an Internet of Things application, obtains the better capacity and performance, and the experiment data verify its effectiveness.",data oriented architecture,347
96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,filtered,semantic_scholar,Proceedings 11th International Workshop on Database and Expert Systems Applications,36526,semantic_scholar,an object-based architecture for wap-compliant applications,https://www.semanticscholar.org/paper/96b4e7bfd88d4fc1bf36da5d31b86770e8fb4293,"The Wireless Application Protocol (WAP) is an emerging standard for the deployment of data oriented applications in wireless environments. Although some components of the WAP suite have been developed, it lacks a complete general architecture integrating software components of both the Internet and wireless contexts in a transparent way. The paper presents a general architectural framework to develop and deploy portable applications and services accessible by WAP-compliant mobile terminals, extending end-to-end services between terminal and business applications. Moreover, a technique to handle client disconnection is presented.",data oriented architecture,348
9ac1afce90ae30e267a928f4a203c0f3e0972edb,filtered,semantic_scholar,,37987,semantic_scholar,compound data oriented processing in usagi ipv6 stack,https://www.semanticscholar.org/paper/9ac1afce90ae30e267a928f4a203c0f3e0972edb,"IPv6 has been attracting much attention as a drastic countermeasure for severe shortage of addresses on the Internet. Linux, one of operating systems, also supports IPv6. However, the quality of the protocol stack was not so good. In this study, we worked out an architectural design for this basic software in Linux. Specifically, we introduce compound data oriented processing in network stack, which simplifies data object management and relationship between object. We show the quantitative research shows that the quality of protocol stack of IPv6 has been greatly improved. key words: IPv6, Linux, Compound Data Oriented Processing",data oriented architecture,349
769159b55700871db1e514b15f7636e750a1d985,filtered,semantic_scholar,2014 IEEE 17th International Conference on Computational Science and Engineering,41640,semantic_scholar,exploring the benefits of introducing network coding into named data networking,https://www.semanticscholar.org/paper/769159b55700871db1e514b15f7636e750a1d985,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,350
98412aed33ea771756e73d8fb9a3b1b13c96a5c5,filtered,semantic_scholar,,40179,semantic_scholar,construction of fishery scientific data sharing platform,https://www.semanticscholar.org/paper/98412aed33ea771756e73d8fb9a3b1b13c96a5c5,"According to the national requirement for scientific data sharing buildings,we presents a comprehensive exposition of the design concept and key technologies research methods of the sharing platform of fishery scientific data which have base on the results of the fishery scientific data features and user requirements analysis.The research includes the architecture of fishery scientific data standard,metadata design,database design,network sharing platform development and the architecture of personalized service.The study has put forward constructive ideas about platform building which of data mining and data oriented services,also has importance signification for enhancing the fisheries information service.",data oriented architecture,351
2378a6fe57d15f89a526eeb91c46b6cc231b729b,filtered,semantic_scholar,2015 7th Conference on Information and Knowledge Technology (IKT),42005,semantic_scholar,otanes: a live tv simulator for content-centric networking,https://www.semanticscholar.org/paper/2378a6fe57d15f89a526eeb91c46b6cc231b729b,"The tremendous growth of the Internet traffic and the rapid changes that have occurred in the way people using it to access massive contents, instruct the research community to data oriented networks. Over the last few years, various data oriented network architectures have emerged to fulfill the demand for a more scalable content distribution. Content-Centric Networking (CCN) is an architecture that has attracted a good consideration. A significant portion of Internet traffic growth relates to diverse types of multimedia applications, including live TV. In fact, delivering television services over the existing Internet protocol (IPTV) has been commercialized for more than a decade. Emigrating to the new network generation requires well analysis of the current applications. Nevertheless, CCN still suffers from the shortage of suitable simulators. We have developed a new modular, component based CCN simulator specifically optimized for live TV modeling. We have published it as an open source utility. In this paper, we present our simulator and evaluate its capabilities on the simulation of live video streaming over CCN.",data oriented architecture,352
b1ce5d71d5db3dc8ef91d12f9743474955c5edc5,filtered,semantic_scholar,Proceedings of NOMS '96 - IEEE Network Operations and Management Symposium,35065,semantic_scholar,transactional workflow for telecommunication service management,https://www.semanticscholar.org/paper/b1ce5d71d5db3dc8ef91d12f9743474955c5edc5,"Summary form only given. As workflow management systems become more complex and critical to an organisation's performance, there is an opportunity for a new generation of workflow management products to be developed that would greatly increase the scope of target application areas. The key areas of extensions to workflow management systems include the use of transactional semantics to increase reliability. Traditional transaction processing technology cannot be used directly for workflow management since applications in workflow management are different from the data oriented applications, such as funds transfer in banking applications. Customised workflow definition and management capability is required to capture business requirements and rules. This paper discusses the requirements and characteristics of transactional workflow management, examines applications of transactional workflow for telecommunication service management, and addresses architectural issues of transactional workflow and its role in the telecommunication service management platform.",data oriented architecture,353
4b85ebe746b3a66663af789f9eda8ec3b2016741,filtered,semantic_scholar,SCOPES,43466,semantic_scholar,towards efficient code generation for exposed datapath architectures,https://www.semanticscholar.org/paper/4b85ebe746b3a66663af789f9eda8ec3b2016741,Coarse-grained reconfigurable architectures and other exposed datapath architectures such as transport-triggered architectures come with a high energy efficiency promise for accelerating data oriented workloads. Their main drawback results from the push of complexity from the architecture to the programmer; compiler techniques that allow starting from a higher-level programming language and generate code efficiently to such architectures robustly is still an open research area. In this article we survey the known main sources of challenges and outline a generic processor architecture template that covers the most common architecture variations along with a proposal for a common code generation framework for such challenging architectures.,data oriented architecture,354
de54590c4894018552b7d8f99a092ea2150a200a,filtered,semantic_scholar,,41275,semantic_scholar,research status and prospect of condition-based maintenance decision-making,https://www.semanticscholar.org/paper/de54590c4894018552b7d8f99a092ea2150a200a,"Research status about three key contents of condition-based maintenance decision-making is analyzed based on open architecture of CBM(Condition Based Maintenance).The application methodologies of weights for multi-attributed features are analyzed when it's referred to condition evaluation.When it comes to condition prediction,predicting methods are analyzed separately according to varied descriptions of condition.Optimal modeling methods for CBM decision-making are analyzed based on their theoretical foundations.It is put forward that dynamic decision-making for CBM,condition description modeling based on multi information and data oriented decision making should be further researched based on results from analysis of current research status.",data oriented architecture,355
9b0cb4dcad5b0f2ec385af15a030dbbf97e86c4c,filtered,semantic_scholar,,38718,semantic_scholar,a study on the distribution of massive image data for mobile gis,https://www.semanticscholar.org/paper/9b0cb4dcad5b0f2ec385af15a030dbbf97e86c4c,"This paper studies and implements the architecture and key technologies of the distribution of massive image data oriented to the mobile GIS in low-bandwidth.According to the characteristics of massive image data and mobile internet,the paper studies several technologies,such as index of massive image data,multi-cache strategy and multi-server cluster technology.At last,it realizes the distribution of massive image data for mobile GIS.",data oriented architecture,356
1ee9b2571008acac45a7f27b205df71b6cbf756a,filtered,semantic_scholar,2019 IEEE Global Communications Conference (GLOBECOM),43466,semantic_scholar,mc-track: a cloud based data oriented vehicular tracking system with adaptive security,https://www.semanticscholar.org/paper/1ee9b2571008acac45a7f27b205df71b6cbf756a,"In this paper, we propose Mc-Track, a new secure data oriented Cloud based vehicular tracking system. We introduced in Mc-Track an adaptive approach which consists in selection of security level according to data kinds. The architecture of the Mc-Track is composed of three levels: the vehicular network, the Cloud service, and proxies called Tracking Authorities, in charge of performing Attribute Based Encryption (ABE). We provided selective encryption and adaptive security in the Tracking Authority (TA), using the machine learning classifier k-Nearest Neighbours (k-NN). We conducted experimental study to evaluate the efficiency of the proposed k-NN classifier in selective encryption and adaptive security. So we compared the accuracy of the predictions of k-NN classifier to the accuracy of predictions using Support Vector Machine (SVM) classifier. Experimental results, has shown that the k-NN classifier is more accurate than SVM classifier.",data oriented architecture,357
968aa7cb0256cdc9d03cc586ac3a793335f4fd42,filtered,semantic_scholar,2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS),43101,semantic_scholar,ndn producer mobility management based on echo state network: a lightweight machine learning approach,https://www.semanticscholar.org/paper/968aa7cb0256cdc9d03cc586ac3a793335f4fd42,"NDN is one of promising underlying network architectures that supporting 5G because of its characteristics such as decoupling senders and receivers, hop by hop transmission, in-network caching, etc. However, it still faces challenges in producer mobility management like the triangle routing problem (non-optimal routing path) and global centralization of the home agent, causing a poor scalability in large network scales and long handover delay. In this paper, we propose the ESN - PBA, a NDN producer mobility management scheme using the ESN in prediction to realize a lightweight machine learning based seamless handover algorithm. Better than the existing fixed and post-adjustment management schemes of producer mobility management, the ESN-PBA can perceive nodes movements heuristically and pre-configure the adjustment in advance to reduce overall processing overhead. In addition, with fine-grained home router status feedbacks and NDN content data oriented philosophy, the training process of normal machine learning method can be mutually enhanced. The experimental results in ndnSIM show that, in the case of successful prediction, the effect of seamless handover can be achieved straightly on the fly. In order to improve the hit rate of cache, we take advantage of NDN's multipath forwarding support, the utilization of ESN prediction of multiple candidates and synchronous forwarding. Compared with PIT-based approach and DNS-based approach, the handover delay of ESN-PBA reduces by 66.7% and 75% respectively. Besides, its handover overhead reduces by 38.4 %, compared with DNS-based approach.",data oriented architecture,358
23b7e84458336bb222c84a1bc3c31f3fd5933243,filtered,semantic_scholar,,40179,semantic_scholar,research on content-oriented networking platform in future internet,https://www.semanticscholar.org/paper/23b7e84458336bb222c84a1bc3c31f3fd5933243,"major foreseeable future Internet is expected to growth multimedia data, such as audio and video data traffic, so that data oriented networking is emerging as the future Internet architecture. In this extended paper, we propose the content-oriented networking platform to exploit content networking service under current Internet. The platform consists of major three parts. First is a content network domain, where is located in edge network between access network and core network. Second is content- aware agent to support Internet connectivity. Last is a content directory service. In this study, we describe research issues related in three major parts, and show content downloading time to compare time overhead cause to relay agents located in middle in the platform by using simulation. And we also introduce a prototype for content-aware agent based on NetFPGA with OpenFlow. The platform will be studied continuously.",data oriented architecture,359
04887833a763e3025714350a9ec3b547be731214,filtered,semantic_scholar,Wirel. Pers. Commun.,42736,semantic_scholar,trends in the evolution of voice services: a comprehensive survey,https://www.semanticscholar.org/paper/04887833a763e3025714350a9ec3b547be731214,"Mobile network operators are increasingly striving to substitute legacy telecommunication technologies in their networks with the contemporary ones. Modern, future-proof architecture that provides better service quality, requires easier and cheaper maintenance, and consequently brings greater financial benefits is the main driving force for that action. In this moment, Long Term Evolution (LTE) deployment is a goal most mobile network operators are aspiring to. This paper describes presently ongoing changes in the mobile communication networks from the perspective of voice services they provide. Namely, LTE network is, so far, mainly recognized as a “data oriented” network. Having in mind enormous mobile data traffic increase, deployment of that kind of network is fully understandable and justified. However, voice services are still important part of telecommunications’ market offer. So, the above mentioned changes are leading not only toward satisfaction of growing needs regarding mobile data traffic, but also toward utilization of LTE network attributes for the purposes of voice communication. Complete transformation of mobile networks architecture and evolution of traditional voice communication will occur in the process. So far, that evolution has resulted with development of a mechanism know as voice over LTE. However, the mentioned changes are coming gradually and will take a certain time to be fully accomplished. In the meantime, some transition solutions are defined and deployed, in order to enable uninterrupted provisioning of voice services. Their description is included in the paper as well. At the end, relevant forecasts of several network parameters have been discussed.",data oriented architecture,360
c456b6d3246ae83dd76d50bcdbf8b12364e06df1,filtered,semantic_scholar,2019 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS),43466,semantic_scholar,an efficient routing strategy for information centric networks,https://www.semanticscholar.org/paper/c456b6d3246ae83dd76d50bcdbf8b12364e06df1,"Information Centric Network (ICN) focuses on shifting the current architecture of internet from host oriented to data oriented. It emphasizes on the location of contents rather than producer of the same. ICN accomplishes it's objectives by supporting caching of content at internal nodes in the network. It also focuses on proper routing of content requests towards a suitable data source for efficient and timely delivery. Hence, routing and caching are two prominent areas of research in ICN. In this paper, a dynamic routing mechanism is proposed that utilizes the concept of likelihood time and betweenness centrality. In order to improve content retrieval latency, the content requests are routed to the nearest content locations, determined by the likelihood time of requested content and betweenness centrality of a node in the network. The routing strategy of the proposed scheme extends native Dijkstra's algorithm and works with the available caching mechanism. The performance of the proposed strategy is evaluated through exhaustive simulations in ndnSIM-2.0, which is a ns-3 driven NDN simulator. The observed simulation results depict that in realistically simulated network topology, the new protocol shows 5-8% of performance improvement over existing ICN routing strategy in terms of cache hit ratio, latency and packet overhead.",data oriented architecture,361
fd849f027691c327b3819c08f15182f869ed0049,filtered,semantic_scholar,1988 IEEE 5th International Symposium on Spread Spectrum Techniques and Applications - Proceedings. Spread Technology to Africa (Cat. No.98TH8333),35796,semantic_scholar,umts-air interface to meet future perspectives,https://www.semanticscholar.org/paper/fd849f027691c327b3819c08f15182f869ed0049,"Summary form only given. The third generation ""UMTS"" will provide wideband multimedia capabilities over mobile communication networks realising a range of new and innovative services, including interactive video, Internet/intarnet and other high speed data services. This leading to cellular network architectures that are to deliver infinite applications and infinite content of cost-effective mobile non-voice and voice services. This means more IP-optimised network and a change from a voice oriented to a data oriented platform. Faced with unprecedented growth in data volumes, the cellular air interface standards will have to support the demands of data rates of 144 kbits per second, portable data rates of 384 kbits per second and in-building fixed rate of 2 Mbits per second using WB-CDMA and TD-CDMA.",data oriented architecture,362
5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,filtered,semantic_scholar,,40179,semantic_scholar,software design and class diagrams,https://www.semanticscholar.org/paper/5a620d4c0ecfa1cfe05c756b3d8ab3f7f431a731,"ion • ignoring detail to get the high level structure right Decomposition and Modularization • big systems are composed from small components Encapsulation/information hiding • the ability to hide detail (linked to abstraction) Defined interfaces • separable from implementation Evaluation of structure • Coupling: How interlinked a component is • Cohesion: How coherent a component is © 2004-2007 SEOC Lecture Note 04 5 Architecture and Structure Architectural structures and viewpoints Architectural styles Design patterns • small-scale patterns to guide the designer Families and frameworks • component sets and ways of plugging them together • software product lines Architectural design Architectural structures and viewpoints deal with system facets (e.g., physical view, functional or logical view, security view, etc.) separately. Depending on the architectural emphasis, there are different styles, for example, Three-tier architecture for a distributed system (interface, middleware, back-end database), Blackboard, Layered architectures, Model-View-Controller, Time-triggered and so forth. Architectural Design supports stakeholder communication, system analysis and large-scale reuse. It is possible to distinguish diverse design strategies: function oriented (sees the design of the functions as primary), data oriented (sees the data as the primary structured element and drives design from there), object oriented (sees objects as the primary element of design). There is no clear distinction between Sub-systems and modules. Intuitively, sub-systems are independent and composed of modules, have defined interfaces for communication with other sub-systems. Modules are system components and provide/make use of service(s) to/provided by other modules. The system architecture affects the quality attributes (e.g., performance, security, availability, modifiability, portability, reusability, testability, maintainability, etc.) of a system. It supports quality analysis (e.g., reviewing techniques, static analysis, simulation, performance analysis, prototyping, etc.). It allows to define (predictive) measures (i.e., metrics) on the design, but they are usually very dependent on the process in use. The software architecture is the fundamental framework for structuring the system. Different architectural models (e.g., system organizational models, modular decomposition models and control models) may be developed. Design decisions enhance system attributes like, for instance, performance (e.g., localize operations to minimize sub-system communication), security (e.g., use a layered architecture with critical assets in inner layers), safety (e.g., isolate safety-critical components), availability (e.g., include redundant components in the architecture) and maintainability (e.g., use fine-grain self-contained components). Readings • P. Kruchten, H. Obbink, J. Stafford. The Past, Present and Future of Software Architecture. IEEE Software, March/April 2006. © 2004-2007 SEOC Lecture Note 04 6 Architecture Models A static structural model that shows the subsystems or components that are to be developed as separate units. A dynamic process model that shows how the system is organized into processes at run-time. This may be different from the static model. An interface model that defines the services offered by each sub-system through their public interface. A relationship model that shows relationships such as data flow between the sub-systems. Comparing Architecture Design Notations • Modeling Components: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Connectors: Interface, Types, Semantics, Constraints, Evolution, Non-functional Properties • Modeling Configurations: Understandable Specifications, Compositionality (and Conposability), Refinement and Traceability, Heterogeneity, Scalability, Evolvability, Dynamism, Constraints, Non-functional Properties UML Design Notations • Static Notations: Class and object diagrams, Component diagrams, Deployment diagrams, CRC Cards • Dynamic Notations: Activity diagrams, Communication diagrams, Statecharts, Sequence diagrams What are the Architect’s Duties? • Get it Defined, documented and communicated, Act as the emissary of the architecture, Maintain morale • Make sure everyone is using it (correctly), management understands it, the software and system architectures are in synchronization, the right modeling is being done, to know that quality attributes are going to be met, the architecture is not only the right one for operations, but also for deployment and maintenance • Identify architecture timely stages that support the overall organization progress, suitable tools and design environments, (and interact) with stakeholders • Resolve disputes and make tradeoffs, technical problems • Manage risk identification and risk mitigation strategies associated with the architecture, understand and plan for evolution © 2004-2007 SEOC Lecture Note 04 7 Class Diagrams Support architectural design • Provide a structural view of systems Represent the basics of Object-Oriented systems • identify what classes there are, how they interrelate and how they interact • Capture the static structure of Object-Oriented systems how systems are structured rather than how they behave Constrain interactions and collaborations that support functional requirements • Link to Requirements",data oriented architecture,363
e6937bb8e048376916a77a5ee6aa7d52ab568c6a,filtered,semantic_scholar,International Journal of Trend in Scientific Research and Development,43466,semantic_scholar,smart grid communication protocols,https://www.semanticscholar.org/paper/e6937bb8e048376916a77a5ee6aa7d52ab568c6a,"Present power grids are getting replaced by smart grids, mainly for improving performance of existing power grid. Integration of electrical, electronics and computer science have led this technology more popular. Smart grid technology is characterized by full duplex communication, automatic metering infrastructure, renewable energy integration, distribution automation and complete monitoring and control of entire power grid. Wireless sensor networks (WSNs) are small micro electrical mechanical systems that are deployed to collect and communicate the data from surroundings. Security of wireless sensor based communication network is a major concern for researchers and developers. The address oriented design and development approach for usual communication network requires a paradigm shift to design data oriented WSN architecture. This paper is presents different communication protocols used in smart grid technology.",data oriented architecture,364
8e572fed5fc239d796dcb44633897ebf6fb40887,filtered,semantic_scholar,2005 IEEE International Conference on Cluster Computing,38353,semantic_scholar,ibrix file system: architecture and design,https://www.semanticscholar.org/paper/8e572fed5fc239d796dcb44633897ebf6fb40887,"Summary form only given. Recently, there have been significant advances in file system technology in the form of cluster, distributed and/or parallel file systems in an attempt to break the I/O bottleneck plaguing the effective utilization of clusters of commodity computers. Successes have been achieved in scaling performance when defined as bandwidth, as typified by sequential access of large files using large I/O sizes. Applications with such access patterns does not represent all application classes to which cluster computing is being applied as a potential solution, the balance being those that access small and medium sized files in a random or sequential manner using small I/O sizes. Specifically, these access patterns perform as many and often more ""metadata"" operations on the file system as data reads or writes. Since metadata operations are at the heart of a file system and impact its integrity, scaling throughput or metadata performance through concurrency across many servers poses the most difficult technical challenge in file system design. This poster will present details about the fundamentally new architecture for constructing parallel file systems called segmented file system that scales linearly for both data and metadata oriented applications. Performance results will be presented with the IBRIX Fusion product (http:Wwww.ibrix.com) based on this architecture using micro benchmarks as well as real applications demonstrating the general-purpose scalability of this architecture. The poster will also show typical I/O cluster offerings from Dell that use IBRIX, using large cluster installations at universities and research labs as an example",data oriented architecture,365
f323b4f434bdfc48836d8eebd5cf267c9258aa09,filtered,semantic_scholar,BDCA'17,42736,semantic_scholar,exploiting open data to improve the business intelligence & business discovery experience,https://www.semanticscholar.org/paper/f323b4f434bdfc48836d8eebd5cf267c9258aa09,"The extent to which data mining tools are able to make efficient use of an open data oriented strategy in a smart city is limited. In a sense that it is not fully automated, incompatible or has to be supervised. These sets of tools may offer the possibility to import a dataset in a certain predefined standardized format, still, they do not make it a part of their workflow and algorithms in a fully unsupervised manner (i.e without ongoing human guidance). In a departure from previous research works, in this paper, we present a middleware architecture that exploits open data as background knowledge by acting as a bridge between data mining tools and open data resources.",data oriented architecture,366
