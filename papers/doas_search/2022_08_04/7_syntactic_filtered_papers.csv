doi,url,title,abstract,publisher,publication_date,database,query_name,query_value,id,type,status
053166fe63e374e2244a2b0d5e8d8738654077fe,https://www.semanticscholar.org/paper/053166fe63e374e2244a2b0d5e8d8738654077fe,Anomaly Detection in Smart Grids using Machine Learning,"Smart grid data can be analyzed for detecting abnormalities in many different areas such as cybersecurity, fault detection, electricity theft, etc. There is a strong case for the use of machine learning in anomaly detection. The raw grid data requires feature extraction. Anomalies can be defined as instances or changes in the smart grid data that are out of character concerning the average trend. A typical grid architecture results can vary significantly, depending on trends or changes in power, voltage, current, or consumption. This paper develops an anomaly detection model for a real-world smart grid system implemented on a hardware-based testbed. By detecting abnormal activities, one can improve the system behavior in data communication flow. It will also identify if there are parameter changes that indicate the presence of cyber-attacks. Our proposed anomaly detection model is build based on Isolation Forest (IF) to isolate outliers from standard observations through multiple decision trees. The performance of the proposed detection method was verified using the simulation results on a hardware-based testbed. Feature selection was optimized by principal component analysis and the model was further analyzed for performance with dickey-fuller test.",IECON 2021 â€“ 47th Annual Conference of the IEEE Industrial Electronics Society,2021,semantic_scholar,citation,citation,1,filtered,unknown
0727c772d0f0389c29d3269ee4e4dc9cb2b1d568,https://www.semanticscholar.org/paper/0727c772d0f0389c29d3269ee4e4dc9cb2b1d568,CNN-Based Fall Detection Strategy with Edge Computing Scheduling in Smart Cities,"The livelihood problem, especially the medical wisdom, has played an important role during the process of the building of smart cities. For the medical wisdom, the fall detection has attracted the considerable attention from the global researchers and medical institutions. It is very difficult for the traditional fall detection strategies to realize the intelligent detection with the following three reasons: (i) the data collection cannot reach the real-time level; (ii) the adopted detection methods cannot satisfy the enough stability; and (iii) the computation overhead of collection device is very high, which causes the barely satisfactory detection effect. Therefore, this paper proposes Convolutional Neural Network (CNN)-based fall detection strategy with edge computing consideration, where the global network view ability of Software-Defined Networking (SDN) is used to collect the generated data from smartphone. Meanwhile, on one hand, the edge computing is exploited to put some computation tasks at the edge server by the scheduling technique. On the other hand, CNN is equipped with both edge server and smartphone, and it is leveraged to train the related data and further give the guidance of fall detection. The experimental results show that the novel fall detection strategy has a more accurate rate, transmission delay, and stability than two cutting-edge strategies.",Electronics,2020,semantic_scholar,citation,citation,2,filtered,unknown
043454093561e9d4880a095a4cfe83c7ea74dab2,https://www.semanticscholar.org/paper/043454093561e9d4880a095a4cfe83c7ea74dab2,Work-in-Progress: Making Machine Learning Real-Time Predictable,"Machine learning (ML) on edge computing devices is becoming popular in the industry as a means to make control systems more intelligent and autonomous. The new trend is to utilize embedded edge devices, as they boast higher computational power and larger memories than before, to perform ML tasks that had previously been limited to cloud-hosted deployments. In this work, we assess the real-time predictability and consider data privacy concerns by comparing traditional cloud services with edge-based ones for certain data analytics tasks. We identify the subset of ML problems appropriate for edge devices by investigating if they result in real-time predictable services for a set of widely used ML libraries. We specifically enhance the Caffe library to make it more suitable for real-time predictability. We then deploy ML models with high accuracy scores on an embedded system, exposing it to industry sensor data from the field, to demonstrates its efficacy and suitability for real-time processing.",2018 IEEE Real-Time Systems Symposium (RTSS),2018,semantic_scholar,citation,citation,3,filtered,unknown
0435b4bfb15fe8df5c41db25984d913caebb1502,https://www.semanticscholar.org/paper/0435b4bfb15fe8df5c41db25984d913caebb1502,Predictive Maintenance using Machine Learning on Industrial Water Pumps,"â€“ To help the industry, detect critical problems in production or maintenance devices, Predictive Maintenance or Predictive Preservation are combined with the Internet of Things (IoT). We propose in this research paper a system architecture model for detecting early water pump system failures by utilizing prevailing measurements captured by the monitored controlled devices. In the tentative portion, we have worked on real measured datasets, events, and failures from the water pumps sector. There are different preservation approaches or tactics that are being used to keep the effectiveness of the industries. For any specific industry, preservation disturbs the value of product works. To avoid shocking or later breakdown, the preservation methods ought to be deliberate in such a mode that the preservation tasked to decrease the conservation costs and the time required to implement them properly. This research study describes the deployment of a keen and Machine Learning architecture system for Predictive Maintenance or Preventive preservation, based on the Random Forest method in an Industry sector, that considers IoT (Internet of Things) and Machine Learning(ML) technologies to support the real-time statistics, an online collection of data, and analysis for detecting machine breakdowns sooner, allowing the real-time monitoring on the data, visualization of the statistics and schedule of preservation interventions to mitigate the existence of such failures in the water pumps. The deployed system architecture also integrates Machine Learning techniques to provision the technicians during the execution of preservation interventions..",International Journal of Innovations in Engineering and Science,2022,semantic_scholar,citation,citation,4,filtered,unknown
0a2d88440f10f0c8d5478f47bf99f4162911b618,https://www.semanticscholar.org/paper/0a2d88440f10f0c8d5478f47bf99f4162911b618,PREDICTIVE MAINTENANCE USING MACHINE LEARNING ON WATER PUMP,"Predictive Preservation or maintenance is used in conjunction with the Internet of Things to assist the industry in detecting important faults in production or maintenance devices. In this study, we offer a system architecture model for detecting early water pump system failures based on data acquired by monitored controlled devices. We worked on real measured statistics, events, and failures from the water pumps sector in the tentative portion. Different preservation measures or tactics are being tried to maintain the industries' effectiveness. Preservation disrupts the value of goods works in any sector. To avoid being shocked or later breaking down, preservation procedures should be planned in such a way that the preservation task is reduced in both cost and time. This research study describes the implementation of a keen and Machine Learning architecture system for Predictive Maintenance or Preventive Preservation, based on the Random Forest method in an Industry sector, that considers the Internet of Things and Machine Learning (ML) technologies to support real-time statistics, an online collection of data, and analysis for detecting machine breakdowns sooner, allowing real-time monitoring on the data, visualization of the data, and analysis for detecting machine breakdowns earlier.",,2022,semantic_scholar,citation,citation,5,filtered,unknown
74772776c2d99f8a1e70f59523ee4de24d47501f,https://www.semanticscholar.org/paper/74772776c2d99f8a1e70f59523ee4de24d47501f,Deep-Graph-Based Reinforcement Learning for Joint Cruise Control and Task Offloading for Aerial Edge Internet of Things (EdgeIoT),"This article puts forth an aerial edge Internet of Things (EdgeIoT) system, where an unmanned aerial vehicle (UAV) is employed as a mobile-edge server to process mission-critical computation tasks of ground Internet of Things (IoT) devices. When the UAV schedules an IoT device to offload its computation task, the tasks buffered at the other unselected devices could be outdated and have to be canceled. We investigate a new joint optimization of UAV cruise control and task offloading allocation, which maximizes tasks offloaded to the UAV, subject to the IoT deviceâ€™s computation capacity and battery budget, and the UAVâ€™s speed limit. Since the optimization contains a large solution space while the instantaneous network states are unknown to the UAV, we propose a new deep-graph-based reinforcement learning framework. An advantage actorâ€“critic (A2C) structure is developed to train the real-time continuous actions of the UAV in terms of the flight speed, heading, and the offloading schedule of the IoT device. By exploring hidden representations resulting from the network feature correlation, our framework takes advantage of graph neural networks (GNNs) to supervise the training of UAVâ€™s actions in A2C. The proposed graph neural network-enabled A2C (GNN-A2C) framework is implemented with Google Tensorflow. The performance analysis shows that GNN-A2C achieves fast convergence and reduces considerably the task missing rate in aerial EdgeIoT.",IEEE Internet of Things Journal,2022,semantic_scholar,citation,citation,6,filtered,unknown
982248098bd6b1be2d72369ae3d083f551eefced,https://www.semanticscholar.org/paper/982248098bd6b1be2d72369ae3d083f551eefced,"Modeling Live Video Streaming: Real-Time Classification, QoE Inference, and Field Evaluation","Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and videoon-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two. In this paper, we design, build, and deploy ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics. Our contributions are four-fold: (1) We analyze about 23,000 video streams from Twitch and YouTube, and identify key features in their traffic profile that differentiate live and on-demand streaming. We release our traffic traces as open data to the public; (2) We develop an LSTM-based binary classifier model that distinguishes live from on-demand streams in real-time with over 95% accuracy across providers; (3) We develop a method that estimates QoE metrics of live streaming flows in terms of resolution and buffer stall events with overall accuracies of 93% and 90%, respectively; and (4) Finally, we prototype our solution, train it in the lab, and deploy it in a live ISP network serving more than 7,000 subscribers. Measurements from the field show that 99.8% of Twitch videos are streamed live, while this measure is only 2.3% for YouTube. Further, during peak hours as many as 15% of live video streams are played at low-definition resolution and about 7% of them experience a buffer stall. Our method provides ISPs with fine-grained visibility into live video streams, enabling them to measure and improve user experience.",ArXiv,2021,semantic_scholar,citation,citation,7,filtered,unknown
9f4722294a2c99f18dec9e24446c283f7edb6920,https://www.semanticscholar.org/paper/9f4722294a2c99f18dec9e24446c283f7edb6920,Managing IoT Cyber-Security Using Programmable Telemetry and Machine Learning,"Cyber-security risks for Internet of Things (IoT) devices sourced from a diversity of vendors and deployed in large numbers, are growing rapidly. Therefore, management of these devices is becoming increasingly important to network operators. Existing network monitoring technologies perform traffic analysis using specialized acceleration on network switches, or full inspection of packets in software, which can be complex, expensive, inflexible, and unscalable. In this paper, we use SDN paradigm combined with machine learning to leverage the benefits of programmable flow-based telemetry with flexible data-driven models to manage IoT devices based on their network activity. Our contributions are three-fold: (1) We analyze traffic traces of 17 real consumer IoT devices collected in our lab over a six-month period and identify a set of traffic flows (per-device) whose time-series attributes computed at multiple timescales (from a minute to an hour) characterize the network behavior of various IoT device types, and their operating states (i.e., booting, actively interacted with user, or being idle); (2) We develop a multi-stage architecture of inference models that use flow-level attributes to automatically distinguish IoT devices from non-IoTs, classify individual types of IoT devices, and identify their states during normal operations. We train our models and validate their efficacy using real traffic traces; and (3) We quantify the trade-off between performance and cost of our solution, and demonstrate how our monitoring scheme can be used in operation for detecting behavioral changes (firmware upgrade or cyber attacks).",IEEE Transactions on Network and Service Management,2020,semantic_scholar,citation,citation,8,filtered,unknown
d28f3595f430a79c73fd524398ac7fe712c447ac,https://www.semanticscholar.org/paper/d28f3595f430a79c73fd524398ac7fe712c447ac,IoT Behavioral Monitoring via Network Traffic Analysis,"Smart homes, enterprises, and cities are increasingly being equipped with a plethora of Internet of Things (IoT), ranging from smart-lights to security cameras. While IoT networks have the potential to benefit our lives, they create privacy and security challenges not seen with traditional IT networks. Due to the lack of visibility, operators of such smart environments are not often aware of their IoT assets, let alone whether each IoT device is functioning properly safe from cyber-attacks. This thesis is the culmination of our efforts to develop techniques to profile the network behavioral pattern of IoTs, automate IoT classification, deduce their operating context, and detect anomalous behavior indicative of cyber-attacks. 
We begin this thesis by surveying IoT ecosystem, while reviewing current approaches to vulnerability assessments, intrusion detection, and behavioral monitoring. For our first contribution, we collect traffic traces and characterize the network behavior of IoT devices via attributes from traffic patterns. We develop a robust machine learning-based inference engine trained with these attributes and demonstrate real-time classification of 28 IoT devices with over 99% accuracy. Our second contribution enhances the classification by reducing the cost of attribute extraction while also identifying IoT device states. Prototype implementation and evaluation demonstrate the ability of our supervised machine learning method to detect behavioral changes for five IoT devices. Our third and final contribution develops a modularized unsupervised inference engine that dynamically accommodates the addition of new IoT devices and/or updates to existing ones, without requiring system-wide retraining of the model. We demonstrate via experiments that our model can automatically detect attacks and firmware changes in ten IoT devices with over 94% accuracy.",ArXiv,2020,semantic_scholar,citation,citation,9,filtered,unknown
e089c880d56950c0fffa04db8e07ab609e495f62,https://www.semanticscholar.org/paper/e089c880d56950c0fffa04db8e07ab609e495f62,Drain Structural Defect Detection and Mapping Using AI-Enabled Reconfigurable Robot Raptor and IoRT Framework,"Human visual inspection of drains is laborious, time-consuming, and prone to accidents. This work presents an AI-enabled robot-assisted remote drain inspection and mapping framework using our in-house developed reconfigurable robot Raptor. The four-layer IoRT serves as a bridge between the users and the robots, through which seamless information sharing takes place. The Faster RCNN ResNet50, Faster RCNN ResNet101, and Faster RCNN Inception-ResNet-v2 deep learning frameworks were trained using a transfer learning scheme with six typical concrete defect classes and deployed in an IoRT framework remote defect detection task. The efficiency of the trained CNN algorithm and drain inspection robot Raptor was evaluated through various real-time drain inspection field trials using the SLAM technique. The experimental results indicate that robotâ€™s maneuverability was stable, and its mapping and localization were also accurate in different drain types. Finally, for effective drain maintenance, the SLAM-based defect map was generated by fusing defect detection results in the lidar-SLAM map.",Sensors,2021,semantic_scholar,citation,citation,10,filtered,unknown
7ef8118665186657fccff43e9146319abae82f24,https://www.semanticscholar.org/paper/7ef8118665186657fccff43e9146319abae82f24,Deep Learning for Real Time Satellite Pose Estimation on Low Power Edge TPU,"â€” Pose estimation of an uncooperative space resident object is a key asset towards autonomy in close proximity operations. In this context monocular cameras are a valuable solution because of their low system requirements. However, the associated image processing algorithms are either too computationally expen-sive for real time on-board implementation, or not enough accurate. In this paper we propose a pose estimation software exploiting neural network architectures which can be scaled to different accuracy-latency trade-offs. We designed our pipeline to be compatible with Edge Tensor Processing Units to show how low power machine learning accelerators could enable Artificial Intelligence exploitation in space. The neural networks were tested both on the benchmark Spacecraft Pose Estimation Dataset, and on the pur-posely developed Cosmo Photorealistic Dataset, which depicts a COSMO-SkyMed satellite in a variety of random poses and steerable solar panels orientations. The lightest version of our architecture achieves state-of-the-art accuracy on both datasets but at a fraction of networks complexity, running at 7.7 frames per second on a Coral Dev Board Mini consuming just 2.2W.",ArXiv,2022,semantic_scholar,citation,citation,11,filtered,unknown
69a299e2ef87279f4227f07b33807bcbc37925ed,https://www.semanticscholar.org/paper/69a299e2ef87279f4227f07b33807bcbc37925ed,XOR Binary Gravitational Search Algorithm with Repository: Industry 4.0 Applications,"Industry 4.0 is the fourth generation of industry which will theoretically revolutionize manufacturing methods through the integration of machine learning and artificial intelligence approaches on the factory floor to obtain robustness and speed-up process changes. In particular, the use of the digital twin in a manufacturing environment makes it possible to test such approaches in a timely manner using a realistic 3D environment that limits incurring safety issues and danger of damage to resources. To obtain superior performance in an Industry 4.0 setup, a modified version of a binary gravitational search algorithm is introduced which benefits from an exclusive or (XOR) operator and a repository to improve the exploration property of the algorithm. Mathematical analysis of the proposed optimization approach is performed which resulted in two theorems which show that the proposed modification to the velocity vector can direct particles to the best particles. The use of repository in this algorithm provides a guideline to direct the particles to the best solutions more rapidly. The proposed algorithm is evaluated on some benchmark optimization problems covering a diverse range of functions including unimodal and multimodal as well as those which suffer from multiple local minima. The proposed algorithm is compared against several existing binary optimization algorithms including existing versions of a binary gravitational search algorithm, improved binary optimization, binary particle swarm optimization, binary grey wolf optimization and binary dragonfly optimization. To show that the proposed approach is an effective method to deal with real world binary optimization problems raised in an Industry 4.0 environment, it is then applied to optimize the assembly task of an industrial robot assembling an industrial calculator. The optimal movements obtained are then implemented on a real robot. Furthermore, the digital twin of a universal robot is developed, and its path planning is done in the presence of obstacles using the proposed optimization algorithm. The obtained path is then inspected by human expert and validated. It is shown that the proposed approach can effectively solve such optimization problems which arises in Industry 4.0 environment.",Applied Sciences,2020,semantic_scholar,citation,citation,12,filtered,unknown
1777b30b4065931998ccfebe1dd7e2c759a32f5a,https://www.semanticscholar.org/paper/1777b30b4065931998ccfebe1dd7e2c759a32f5a,Enhancement of COVID-19 Detection by Unravelling its Structure and Selecting the Optimal Attributes,"According to the current unprecedented pandemic, we realise that we cannot respond to every contagion novel virus as fast as possible, either by vaccination or medication. Therefore, it is paramount for the sustainable development of antiviral urban ecosystems to promote early detection, control, and prevention of an outbreak. The structure of an antivirus-based multi-generational smart-city framework could be crucial to a post-COVID-19 urban environment. Humanitarian efforts in the pandemic's framework deployed novel technological solutions based on the Internet of Things (IoT), Machine Learning, Cloud Computing and Artificial Intelligence (AI). We aim to contribute by improving real-time detection using data mining in collaboration with machine learning techniques through our research work. Initially, for detection, we propose an innovative system that could detect in real-time virus propagation based on the density of the airborne COVID-19 molecules-the proposal based on the detection through the isothermal amplification RT-Lamp [1]. We also propose real-time detection by spark-induced plasma spectroscopy during the internal airborne transmission process [17]. The novelty of this research work, called characteristic subset selection, is based on identifying irrelevant data. By deducting the unrelated information dimension, machine learning algorithms would operate more efficiently. Therefore, it optimises data mining and classification in high-dimensional medical data analysis, particularly in effectively detecting COVID-19. It can play an essential role in providing timely detection with critical attributes and high accuracy. We elaborate the teaching-learning method optimisation to achieve the optimal set of features for the detection.",2021 IEEE Global Communications Conference (GLOBECOM),2021,semantic_scholar,citation,citation,13,filtered,unknown
f7ff0b0d9271f52fc29567d62d67540a43a92f9b,https://www.semanticscholar.org/paper/f7ff0b0d9271f52fc29567d62d67540a43a92f9b,The Trip to The Enterprise Gourmet Data Product Marketplace through a Self-service Data Platform,"Data Analytics provides core business reporting needs in many software companies, acts as a source of truth for key information, and enables building advanced solutions, e.g., predictive models, machine learning, real-time recommendations, to grow the business. Typically, companies ingest data to data lakes, have elaborate ETL/ELT processes, and consume the data. Organizations have challenges in becoming data-driven at scale, with centralized teams and modules acting as bottlenecks, responsible for many aspects such as data governance, ingestion, or engineering. Placing the tools in the hands of developers and empowering engineers across all business domains truly unlocks the ability for a company to become data-driven, at scale, both in culture and practice. A self-service, multi-tenant, API-first, and scalable data platform is the foundational requirement in creating an enterprise data marketplace, which enables the creation, publishing, and exchange of data products. Such a marketplace enables the exploration and discovery of data products, further providing highlevel data governance and oversight on marketplace contents. In this paper, we describe our way to the gourmet data product marketplace. We cover the design principles, the implementation details, technology choices, and the journey to build an enterprise data platform that meets the above characteristics. The platform consists of ingestion, streaming, storage, transformation, schema generation, fail-safe, data sharing, access management, PII data automatic identification, self-service storage optimization recommendations, and CI/CD integration. We then show how the platform enables and operates the data marketplace, facilitating the exchange of stable data products across users and tenants. We motivate and show how we run scalable decentralized data governance. All of this is built and run for Cimpress Technology (CT), which operates the Mass Customization Platform for Cimpress and its businesses. The CT data platform serves 1000s of users from different platform participants, with data sourced from heterogeneous sources. Data is ingested at a rate of well over 1000 individual messages per second and serves more than 100k analytical queries daily.",ArXiv,2021,semantic_scholar,citation,citation,14,filtered,unknown
15de03bee8e1d382ca7b39d5af6dd85a70f5c6d1,https://www.semanticscholar.org/paper/15de03bee8e1d382ca7b39d5af6dd85a70f5c6d1,Solar irradiance forecasting by machine learning for solar car races,"Solar car race competitions offer realistic conditions to test and demonstrate the state-of-the-art technologies in multidisciplinary fields. In such races the solar panels mounted on the car produce the energy required to power the vehicle. A simulator runs during the race determines the optimal race speed based on the predicted availability of solar energy and other parameters as well as road conditions. The accuracy of the forecasts, especially the solar irradiance forecasts, has a significant impact on the race strategy. Here we report on the experience of providing irradiance forecasts for two races run by the University of Michigan Solar Car Team at the Bridgestone World Solar Challenge 2015 in Australia and at the American Solar Challenge 2016 from Ohio to South Dakota. The probabilistic forecasts of hourly solar irradiance generated from machine learning algorithms were deployed to optimally decide on the race strategy. This work showcases an example of real time decision making based on insights derived from machine learning utilizing big geospatial data â€” weather models and measurement data from weather station networks.",2016 IEEE International Conference on Big Data (Big Data),2016,semantic_scholar,citation,citation,15,filtered,unknown
6d9cd2d863d33b57b9bf435605a4e149d13e6d39,https://www.semanticscholar.org/paper/6d9cd2d863d33b57b9bf435605a4e149d13e6d39,ML4IoT: A Framework to Orchestrate Machine Learning Workflows on Internet of Things Data,"Internet of Things (IoT) applications generate vast amounts of real-time data. Temporal analysis of these data series to discover behavioural patterns may lead to qualified knowledge affecting a broad range of industries. Hence, the use of machine learning (ML) algorithms over IoT data has the potential to improve safety, economy, and performance in critical processes. However, creating ML workflows at scale is a challenging task that depends upon both production and specialized skills. Such tasks require investigation, understanding, selection, and implementation of specific ML workflows, which often lead to bottlenecks, production issues, and code management complexity and even then may not have a final desirable outcome. This paper proposes the Machine Learning Framework for IoT data (ML4IoT), which is designed to orchestrate ML workflows, particularly on large volumes of data series. The ML4IoT framework enables the implementation of several types of ML models, each one with a different workflow. These models can be easily configured and used through a simple pipeline. ML4IoT has been designed to use container-based components to enable training and deployment of various ML models in parallel. The results obtained suggest that the proposed framework can manage real-world IoT heterogeneous data by providing elasticity, robustness, and performance.",IEEE Access,2019,semantic_scholar,citation,citation,16,filtered,unknown
f22f3d344654c2cbf28329a0359790c2be2b8f3e,https://www.semanticscholar.org/paper/f22f3d344654c2cbf28329a0359790c2be2b8f3e,"Bighead: A Framework-Agnostic, End-to-End Machine Learning Platform","With the increasing need to build systems and products powered by machine learning inside organizations, it is critical to have a platform that provides machine learning practitioners with a unified environment to easily prototype, deploy, and maintain their models at scale. However, due to the diversity of machine learning libraries, the inconsistency between environments, and various scalability requirement, there is no existing work to date that addresses all of these challenges. Here, we introduce Bighead, a framework-agnostic, end-to-end platform for machine learning. It offers a seamless user experience requiring only minimal efforts that span feature set management, prototyping, training, batch (offline) inference, real-time (online) inference, evaluation, and model lifecycle management. In contrast to existing platforms, it is designed to be highly versatile and extensible, and supports all major machine learning frameworks, rather than focusing on one particular framework. It ensures consistency across different environments and stages of the model lifecycle, as well as across data sources and transformations. It scales horizontally and elastically in response to the workload such as dataset size and throughput. Its components include a feature management framework, a model development toolkit, a lifecycle management service with UI, an offline training and inference engine, an online inference service, an interactive prototyping environment, and a Docker image customization tool. It is the first platform to offer a feature management component that is a general-purpose aggregation framework with lambda architecture and temporal joins. Bighead is deployed and widely adopted at Airbnb, and has enabled the data science and engineering teams to develop and deploy machine learning models in a timely and reliable manner. Bighead has shortened the time to deploy a new model from months to days, ensured the stability of the models in production, facilitated adoption of cutting-edge models, and enabled advanced machine learning based product features of the Airbnb platform. We present two use cases of productionizing models of computer vision and natural language processing.",2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA),2019,semantic_scholar,citation,citation,17,filtered,unknown
23308e0337ed1d9fce809eb84cf80c1fbc6ca7aa,https://www.semanticscholar.org/paper/23308e0337ed1d9fce809eb84cf80c1fbc6ca7aa,Assessing the ability of deep learning techniques to perform real-time identification of shark species in live streaming video from drones,"Over the last five years remotely piloted drones have become the tool of choice to spot potentially dangerous sharks in New South Wales, Australia. They have proven to be a more effective, accessible and cheaper solution compared to crewed aircraft. However, the ability to reliably detect and identify marine fauna is closely tied to pilot skill, experience and level of fatigue. Modern computer vision technology offers the possibility of improving detection reliability and even automating the surveillance process in the future. In this work we investigate the ability of commodity deep learning algorithms to detect marine objects in video footage from drones, with a focus on distinguishing between shark species. This study was enabled by the large archive of video footage gathered during the NSW Department of Primary Industries Drone Trials since 2016. We used this data to train two neural networks, based on the ResNet-50 and MobileNet V1 architectures, to detect and identify ten classes of marine object in 1080p resolution video footage. Both networks are capable of reliably detecting dangerous sharks: 80% accuracy for RetinaNet-50 and 78% for MobileNet V1 when tested on a challenging external dataset, which compares well to human observers. The object detection models correctly detect and localise most objects, produce few false-positive detections and can successfully distinguish between species of marine fauna in good conditions. We find that shallower network architectures, like MobileNet V1, tend to perform slightly worse on smaller objects, so care is needed when selecting a network to match deployment needs. We show that inherent biases in the training set have the largest effect on reliability. Some of these biases can be mitigated by pre-processing the data prior to training, however, this requires a large store of high resolution images that supports augmentation. A key finding is that models need to be carefully tuned for new locations and water conditions. Finally, we built an Android mobile application to run inference on real-time streaming video and demonstrated a working prototype during fields trials run in partnership with Surf Life Saving NSW.",Frontiers in Marine Science,2022,semantic_scholar,citation,citation,18,filtered,unknown
916812d2a8156b53e367c843a7510bace3cfcdcc,https://www.semanticscholar.org/paper/916812d2a8156b53e367c843a7510bace3cfcdcc,Intelligent Video Ingestion for Real-time Traffic Monitoring,"As an indispensable part of modern critical infrastructures, cameras deployed at strategic places and prime junctions in an intelligent transportation system can help operators in observing traffic flow, identifying any emergency situation, or making decisions regarding road congestion without arriving on the scene. However, these cameras are usually equipped with heterogeneous and turbulent networks, making the real-time smooth playback of traffic monitoring videos with high quality a grand challenge. In this article, we propose a lightweight Deep Reinforcement Learning-based approach, namely, sRC-C (smart bitRate Control with a Continuous action space), to enhance the quality of real-time traffic monitoring by adjusting the video bitrate adaptively. Distinguished from the existing bitrate adjusting approaches, sRC-C can overcome the bias incurred by deterministic discretization of candidate bitrates by adjusting the video bitrate with more fine-grained control from a continuous action space, thus significantly improving the Quality-of-Service (QoS). With carefully designed state space and neural network model, sRC-C can be implemented on cameras with scarce resources to support real-time live video streaming with low inference time. Extensive experiments show that sRC-C can reduce the frame loss counts and hold time by 24% and 15.5%, respectively, even with comparable bandwidth utilization. Meanwhile, compared to the-state-of-art approaches, sRC-C can improve the QoS by 30.4%.",ACM Trans. Sens. Networks,2022,semantic_scholar,citation,citation,19,filtered,unknown
0ba972a4a73ab7878cc676b3d5cc2033755774c6,https://www.semanticscholar.org/paper/0ba972a4a73ab7878cc676b3d5cc2033755774c6,Fault Prediction in SOA-Based Systems Using Deep Learning Techniques,"Fault prediction in Service Oriented Architecture (SOA) based systems is one of the important tasks to minimize the computation cost and time of the software system development. Predicting the faults and discovering their locations in the early stage of the system development lifecycle makes maintenance processes easy and improves the resource utilization. In this paper, the authors proposed the fault prediction model for SOA-based systems by utilizing the deep learning techniques. Twenty-one source code metrics are applied to different web services projects. The web services datasets are constructed by injecting the faults into it, and metrics are extracted for both faulty and nonfaulty data for training and testing purpose. Moreover, different deep learning techniques are inspected for fault prediction of web services and performance of different methods are compared by using standard performance measures. From the experimental results, it is observed that deep learning techniques provide effective results and applicable to the real-world SOA-based systems.",Int. J. Web Serv. Res.,2020,semantic_scholar,citation,citation,20,filtered,unknown
