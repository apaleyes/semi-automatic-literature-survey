paperId,url,title,abstract,venue,year,externalIds.DOI,database,query_name,query_value
1d3539a8d94bd3ab78993d7cc584efc06ed0e460,https://www.semanticscholar.org/paper/1d3539a8d94bd3ab78993d7cc584efc06ed0e460,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",NeurIPS Datasets and Benchmarks,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,https://www.semanticscholar.org/paper/ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,Challenges and Opportunities for Unikernels in Machine Learning Inference,"Machine Learning has become a value creator for many new and old businesses. However, efficient realworld machine learning deployments are still a challenge. Traditional Machine Learning deployments suffer from efficient resource utilization and achieving predictable latency. They cannot be treated in the same manner as other application server deployments. Unikernels are a method to specialize application deployment and performance to suit the needs of the application. Traditionally, building or porting applications to unikernels have been challenging. However, recent work has been into simplifying the development of unikernels. Real-world Unikernels as of now are only for specializing applications that run on the CPU. We survey machine learning practitioners and find out that the majority of machine learning practitioners are using the CPU for machine learning deployments, thus, creating an opportunity for unikernels to optimize the performance of these applications. We compare the architecture of two unikernels: nanos and Unikraft. We benchmarked scikit-learn, a popular machine library, inside a unikernel and found that it only offered a 1% advantage over a traditional deployment. However, our testing could not include more innovative systems like Unikraft due to their immaturity and inability to run machine learning libraries. We include a dependency analysis of three popular machine learning libraries Tensorflow Lite, PyTorch and ONNX, to help pave the way for building machine learning applications as Unikraft unikernels.","2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",2021,10.1109/icrito51393.2021.9596080,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
b14558c0b727af0ac9086f463b6030b9072dbe16,https://www.semanticscholar.org/paper/b14558c0b727af0ac9086f463b6030b9072dbe16,Methods for Automatic Machine-Learning Workflow Analysis,,ECML/PKDD,2021,10.1007/978-3-030-86517-7_4,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
56e63ffea11c875f7eee257798e18cd04e453b6c,https://www.semanticscholar.org/paper/56e63ffea11c875f7eee257798e18cd04e453b6c,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
19552c33b6144ba9cf02b52310cfdccdc66b14f2,https://www.semanticscholar.org/paper/19552c33b6144ba9cf02b52310cfdccdc66b14f2,Empirical observation of negligible fairness-accuracy trade-offs in machine learning for public policy,,Nat. Mach. Intell.,2020,10.1038/s42256-021-00396-x,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
b14692c1e0658dd1d814c737171ce714b1588360,https://www.semanticscholar.org/paper/b14692c1e0658dd1d814c737171ce714b1588360,An Intelligent UAV Deployment Scheme for Load Balance in Small Cell Networks Using Machine Learning,"In wireless networks, network load can be highly unbalanced due to the mobility of user equipments (UEs). Unmanned Aerial Vehicles (UAVs) supported base station with the advantage of flexible deployment, ubiquitous wireless coverage and high speed data rate, is a promising approach to handle with the foregoing problem. However, how to achieve cost-effective UAV deployment in an autonomous and dynamic manner is a significant challenge. Facing this problem, we propose a novel UAV base station intelligent deployment scheme based on machine learning and evaluate its performance on a realworld dataset. First, we conduct data preprocessing to process, clean, and transform raw data into formatted data. Missing values are filled by Conditional Mean Imputation (CMI) method and outliers are corrected by pauta criterion. Then, we use hybrid approach which contains ARIMA model and XGBoost model. Linear predictions are carried out by ARIMA model and later nonlinear model XGBoost are applied on residue of ARIMA. Resultant prediction is obtained by adding linear and nonlinear prediction, hybrid model is estimated by Root Mean Square Error (RMSE) and R2 score. Finally, according to predicted results, UAV base stations can be deployed to cater for dynamically changing demands in the hotspot areas and achieve cost-effective deployment. Simulation results show that the propose scheme is superior to other benchmark schemes in load balancing.",2019 IEEE Wireless Communications and Networking Conference (WCNC),2019,10.1109/WCNC.2019.8885648,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
650387bc1ad4ac0a2730303b366749bd3021c779,https://www.semanticscholar.org/paper/650387bc1ad4ac0a2730303b366749bd3021c779,Advanced attack and defense techniques in machine learning systems,"The security of machine learning systems has become a great concern in many realworld applications involving adversaries, including spam filtering, malware detection and e-commerce. There is an increasing trend of study on the security of machine learning systems but the current research is still far from satisfactory. Towards building secure machine learning systems, the first step is to study their vulnerability, which turns out to be very challenging due to the variety and complexity of machine learning systems. Combating adversaries in machine learning systems is even more challenging due to the strategic behavior of the adversaries. This thesis studies both the adversarial threats and the defenses in real-world machine learning systems. Regarding the adversarial threats, we begin by studying label contamination attacks, which is an important type of data poisoning attacks. Then we generalize the conventional data poisoning attacks on single-task learning models to multi-task learning models. Regarding defending against real-world attacks, we first study the spear phishing attacks in email systems and propose a framework for optimizing the personalized email filtering thresholds to mitigate such attacks. Then, we study the fraud transactions in ecommerce systems and propose a deep reinforcement learning based impression allocation mechanism for combating fraudulent sellers. The specific contributions of this thesis are listed below. First, regarding the label contamination attacks, we develop a Projected Gradient Ascent (PGA) algorithm to compute attacks on a family of empirical risk minimizations and show that an attack on one victim model can also be effective on other victim models. This makes it possible that the attacker designs an attack against a substitute model and transfers it to a black-box victim model. Based on the observation of the transferability, we develop a defense algorithm to identify the data points that are most likely to be attacked. Empirical studies show that PGA significantly outperforms existing baselines and linear learning models are better substitute models than nonlinear ones. Second, in the study of data poisoning attacks on muti-task learning models, we formulate the problem of computing optimal poisoning attacks on Multi-Task Relationship Learning (MTRL) as a bilevel program that is adaptive to arbitrary choice of target tasks and attacking tasks. We propose an efficient algorithm called PATOM for computing optimal attack strategies. PATOM leverages the optimality conditions of the subproblem of MTRL to compute the implicit gradients of the upper level objective function. Experimental results on real-world datasets show that MTRL models are very sensitive to poisoning attacks and the attacker can significantly degrade the performance of target tasks, by either directly poisoning the target tasks or indirectly poisoning the related tasks exploiting the task relatedness. We also found that the tasks being attacked are always strongly correlated, which provides a clue for defending against such attacks. Third, on defending against spear phishing email attacks, we consider two important extensions of the previous threat models. First, we consider the cases where multiple users provide access to the same information or credential. Second, we consider attackers who make sequential attack plans based on the outcome of previous attacks. Our analysis starts from scenarios where there is only one credential and then extends to more general scenarios with multiple credentials. For single-credential scenarios, we demonstrate that the optimal defense strategy can be found by solving a binary combinatorial optimization problem called PEDS. For multiple-credential scenarios, we formulate it as a bilevel optimization problem for finding the optimal defense strategy and then reduce it to a single level optimization problem called PEMS using complementary slackness conditions. Experimental results show that both PEDS and PEMS lead to significant higher defender utilities than two existing benchmarks in different parameter settings. Also, both PEDS and PEMS are more robust than the existing benchmarks considering uncertainties. Fourth, on combating fraudulent sellers in e-commerce platforms, we focus on improving the platform’s impression allocation mechanism to maximize its profit and reduce the sellers’ fraudulent behaviors simultaneously. First, we learn a seller behavior model to predict the sellers’ fraudulent behaviors from the real-world data provided by one of the largest e-commerce company in the world. Then, we formulate the platform’s impression allocation problem as a continuous Markov Decision Process (MDP) with unbounded action space. In order to make the action executable in practice and facilitate learning, we propose a novel deep reinforcement learning algorithm DDPG-ANP that introduces an action norm penalty to the reward function. Experimental results show that our algorithm significantly outperforms existing baselines in terms of scalability and solution quality.",,2018,10.32657/10220/47390,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
26937db6917952a9c13bfe152eddd7defc08e695,https://www.semanticscholar.org/paper/26937db6917952a9c13bfe152eddd7defc08e695,Guest Editorial: Special Issue on Machine Learning Implementations,,J. Signal Process. Syst.,2019,10.1007/s11265-018-1432-1,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
15c8125c49001952d25af8d7bcb74ac992affa92,https://www.semanticscholar.org/paper/15c8125c49001952d25af8d7bcb74ac992affa92,Predictive Model for Multiclass Classification of E-Commerce Data: An Azure Machine Learning Approach,"Electronics Commerce (E-Com) is one among the various business methodologies that addresses the growing requirement of business organizations, and customers. The Ecommerce industry is one of the world's leading and growing industries with market worth around $22.1 trillion globally. Through E-Com, companies are developing the competence in business domain. The business giants like Amazon, Flipkart, etc. utilizing Machine Learning (ML) potential to make matchless competitiveness in the market through data analytics and business intelligence. ML has empowered businesses by analyze the data collected through various sources including social media reviews. Data scientists are in huge demand in E-Commerce market researches because predictive data analytics based on ML can enhance sale prospects and discover the reasons of customer churn, by analyzing customer’s reviews and click-through actions, preferences and past purchase history, in real-time. Massive increase in the volume, variety and velocity of data generated through various businesses or E-Commerce platforms pose a huge computational and storage challenge for data analysis and intelligence tasks. Addressing the computational and storage needs for business intelligence tasks, cloud computing paradigm is evolved. The data and computation can be distributed to any Cloud computing environment with minimal effort nowadays. Also, Cloud computing paradigm turned out to be valuable alternatives to speed-up machine learning platforms. The work, first discusses the ‘E-Commerce advantages’, ‘Importance of Machine Learning in E-Commerce Domain’, ‘Cloud Computing and Need of Cloud platforms for Machine Learning tasks’. Also, the background for ‘E-Commerce Product Data Classification Task’ ‘is established. Introduction to multiclass classification and the literature survey for various classification tasks is presented. Finally, a Predictive Model for E-commerce Data Classification Task is proposed and deployed over Microsoft Azure Cloud. The proposed model predicts the Product Class from a large product dataset released by a well-known e-commerce company for a competition. The proposed model is build using ‘Neural Network’ (Multiclass) and R-Script module for better convergence. The obtained results are compared with benchmark model “Multiclass Logistic Regression” and evaluation is done on basis of prediction accuracy. Proposed work also demonstrates the use of one of the foremost cloud environments for machine learning. The results attained by the proposed model are promising and the paper also mentioned the future research work in the field.",,2017,10.5120/IJCA2017914447,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
5994ea254d8e60e9b240cf0c3824b3e5f40df85a,https://www.semanticscholar.org/paper/5994ea254d8e60e9b240cf0c3824b3e5f40df85a,Machine Learning for Indoor Localization Using Mobile Phone-Based Sensors,"In this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies. We consider a realworld environment, collect a large dataset of 3110 datapoints, and examine the performance of a substantial number of machine learning algorithms in localizing a mobile device. We have found algorithms that give a mean error as accurate as 0.76 meters, outperforming other indoor localization systems reported in the literature. We also propose a hybrid instance-based approach that results in a speed increase by a factor of ten with no loss of accuracy in a live deployment over standard instance-based methods, allowing for fast and accurate localization. Further, we determine how smaller datasets collected with less density affect accuracy of localization, important for use in real-world environments. Finally, we demonstrate that these approaches are appropriate for real-world deployment by evaluating their performance in an online, in-motion experiment.",ArXiv,2015,10.1109/CCNC.2016.7444919,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
fbbee5da12c0e0f15813254b9ffca18e339d3546,https://www.semanticscholar.org/paper/fbbee5da12c0e0f15813254b9ffca18e339d3546,10 - Machine learning for future intelligent air quality networks,"During the last few years, machine learning emerged as a very effective tool for data analysis and sematic value extraction from the large amount of data generated from deployed chemical multisensors devices. Many works have now highlighted the potential impact on multisensor device calibration, drift counteraction, data assimilation, optimal deployment of these classes of algorithms. Unlike 5 years ago, the huge amount of available data make possible to confirm this potential on realworld long-term deployments. This work analyze the literature produced by EuNetAir partners extracting the lessons cooperatively learnt about their impact and propose a novel architecture for future intelligent air quality networks based on the machine learning emerging paradigm.",,2016,10.5162/6EuNetAir2016/10,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,https://www.semanticscholar.org/paper/c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,"Tambe , Developing the Science and Applications of Security Games : Machine Learning , Uncertainty and Preference Elicitation in Game Theory for Security","Having successfully founded the research area of security games, which has led to real-world applications in scheduling the deployment of limited resources (patrols, checkpoints, inspections, etc.), we now provide fundamental advances by incorporating machine learning to enhance realworld security applications, new models of opportunistic security games, robust methods for handling uncertainty, and novel techniques for preference elicitation techniques.",,2015,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
362edc0f31ca39ad58d473a3872715a04fe516ed,https://www.semanticscholar.org/paper/362edc0f31ca39ad58d473a3872715a04fe516ed,Fair Policy Learning,"Ensuring machine learning algorithms deployed in the real world do not result in unexpected unfairness or social implications is becoming increasingly important. However, there exists a clear gap in literature for a measure of fairness that can detect discrimination against multiple sensitive attributes while also handling continuous or discrete outcomes. In this thesis, we propose a fairness measure, Fair-COCCO, based on the conditional cross-covariance operator on reproducing kernel Hilbert Spaces. This novel method generalise to the majority of existing fairness notions and naturally extends to settings with continuous outcomes and multidimensional sensitive attributes. Additionally, we demonstrate how the proposed measure can be readily implemented in stochastic gradient optimisation for fair policy learning in supervised learning settings. Empirical evaluations of Fair-COCCO on synthetic and realworld experiments reveal favourable comparisons to state-of-the-art techniques in balancing predictive power and fairness. We also see much potential in applying machine learning to analyse fairness in observed behaviour, especially in complex and high-dimensional real-world environments. To that end, we propose the first known definition of fairness for sequences of decisions and showcase how Fair-COCCO can be applied to quantify fairness in these problems. Building off these definitions, we turn to learning fair policies in real-world conditions, where learning is constrained to be performed offline. We propose Fair-PoLe, a novel inverse reinforcement learning that operates completely offline and is computationally efficient and functionally expressive when compared to existing methods. We illustrate the potential for Fair-PoLe to learn policies that balance imitation of expert policies with fair outcomes on the challenging problem of sepsis treatment.",,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
0966363ea46368f297999b026c827f0f5ea7fcc9,https://www.semanticscholar.org/paper/0966363ea46368f297999b026c827f0f5ea7fcc9,Efficient Machine-Type Communication Using Multi-Metric Context-Awareness for Cars Used as Mobile Sensors in Upcoming 5G Networks,"Upcoming 5G-based communication networks will be confronted with huge increases in the amount of transmitted sensor data related to massive deployments of static and mobile Internet of Things (IoT) systems. Cars acting as mobile sensors will become important data sources for cloud-based applications like predictive maintenance and dynamic traffic forecast. Due to the limitation of available communication resources, it is expected that the grows in Machine-Type Communication (MTC) will cause severe interference with Human-to-human (H2H) communication. Consequently, more efficient transmission methods are highly required. In this paper, we present a probabilistic scheme for efficient transmission of vehicular sensor data which leverages favorable channel conditions and avoids transmissions when they are expected to be highly resource-consuming. Multiple variants of the proposed scheme are evaluated in comprehensive realworld experiments. Through machine learning based combination of multiple context metrics, the proposed scheme is able to achieve up to 164% higher average data rate values for sensor applications with soft deadline requirements compared to regular periodic transmission.",2018 IEEE 87th Vehicular Technology Conference (VTC Spring),2018,10.1109/VTCSpring.2018.8417753,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
114aa720872462b0ca1b97bfdec0ebd56c36fd0a,https://www.semanticscholar.org/paper/114aa720872462b0ca1b97bfdec0ebd56c36fd0a,Towards Understanding and Mitigating Social Biases in Language Models,"Warning: this paper contains model outputs that may be offensive or upsetting. As machine learning methods are deployed in realworld settings such as healthcare, legal systems, and social science, it is crucial to recognize how they shape social biases and stereotypes in these sensitive decision-making processes. Among such real-world deployments are large-scale pretrained language models (LMs) that can be potentially dangerous in manifesting undesirable representational biases harmful biases resulting from stereotyping that propagate negative generalizations involving gender, race, religion, and other social constructs. As a step towards improving the fairness of LMs, we carefully define several sources of representational biases before proposing new benchmarks and metrics to measure them. With these tools, we propose steps towards mitigating social biases during text generation. Our empirical results and human evaluation demonstrate effectiveness in mitigating bias while retaining crucial contextual information for highfidelity text generation, thereby pushing forward the performance-fairness Pareto frontier.",ICML,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,https://www.semanticscholar.org/paper/ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale,"The ever-growing demand and complexity of machine learning are putting pressure on hyper-parameter tuning systems: while the evaluation cost of models continues to increase, the scalability of state-of-the-arts starts to become a crucial bottleneck. In this paper, inspired by our experience when deploying hyper-parameter tuning in a real-world application in production and the limitations of existing systems, we propose Hyper-Tune, an efficient and robust distributed hyper-parameter tuning framework. Compared with existing systems, Hyper-Tune highlights multiple system optimizations, including (1) automatic resource allocation, (2) asynchronous scheduling, and (3) multi-fidelity optimizer. We conduct extensive evaluations on benchmark datasets and a large-scale realworld dataset in production. Empirically, with the aid of these optimizations, Hyper-Tune outperforms competitive hyper-parameter tuning systems on a wide range of scenarios, including XGBoost, CNN, RNN, and some architectural hyper-parameters for neural networks. Compared with the state-of-the-art BOHB and A-BOHB, Hyper-Tune achieves up to 11.2× and 5.1× speedups, respectively. PVLDB Reference Format: Yang Li, Yu Shen, Huaijun Jiang, Wentao Zhang, Jixiang Li, Ji Liu, Ce Zhang, and Bin Cui. Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale. PVLDB, 14(1): XXX-XXX, 2020. doi:XX.XX/XXX.XX PVLDB Availability Tag: The source code of this research paper has been made publicly available at https://github.com/PKU-DAIR/HyperTune.",Proc. VLDB Endow.,2022,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
dba3478cb46874a97e301deb0f20f7692c1f1ae9,https://www.semanticscholar.org/paper/dba3478cb46874a97e301deb0f20f7692c1f1ae9,PenDer: Incorporating Shape Constraints via Penalized Derivatives,"When deploying machine learning models in the real-world, system designers may wish that models exhibit certain shape behavior, i.e., model outputs follow a particular shape with respect to input features. Trends such as monotonicity, convexity, diminishing or accelerating returns are some of the desired shapes. Presence of these shapes makes the model more interpretable for the system designers, and adequately fair for the customers. We notice that many such common shapes are related to derivatives, and propose a new approach, PenDer (Penalizing Derivatives), which incorporates these shape constraints by penalizing the derivatives. We further present an Augmented Lagrangian Method (ALM) to learn the joint unconstrained objective function. Experiments on three realworld datasets illustrate that even though both PenDer and state-of-the-art Lattice models achieve similar conformance to shape, PenDer captures better sensitivity of prediction with respect to intended features. We also demonstrate that PenDer achieves better test performance than Lattice while enforcing more desirable shape behavior.",AAAI,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
d3ac65b10af091759863b8e2c488036bf52a2ce6,https://www.semanticscholar.org/paper/d3ac65b10af091759863b8e2c488036bf52a2ce6,DAG Card is the new Model Card,"With the progressive commoditization of modeling capabilities, data-centric AI recognizes that what happens before and after training becomes crucial for realworld deployments. Following the intuition behind Model Cards, we propose DAG Cards as a form of documentation encompassing the tenets of a data-centric point of view. We argue that Machine Learning pipelines (rather than models) are the most appropriate level of documentation for many practical use cases, and we share with the community an open implementation to generate cards from code.",ArXiv,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,https://www.semanticscholar.org/paper/7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,Exploring the Use of Synthetic Gradients for Distributed Deep Learning across Cloud and Edge Resources,"With the explosive growth of data, largely contributed by the rapidly and widely deployed smart devices on the edge, we need to rethink the training paradigm for learning on such realworld data. The conventional cloud-only approach can hardly keep up with the computational demand from these deep learning tasks; and the traditional back propagation based training method also makes it difficult to scale out the training. Fortunately, the continuous advancement in System on Chip (SoC) hardware is transforming edge devices into capable computing platforms, and can potentially be exploited to address these challenges. These observations have motivated this paper’s study on the use of synthetic gradients for distributed training cross cloud and edge devices. We employ synthetic gradients into various neural network models to comprehensively evaluate its feasibility in terms of accuracy and convergence speed. We distribute the training of the various layers of a model using synthetic gradients, and evaluate its effectiveness on the edge by using resource-limited containers to emulate edge devices. The evaluation result shows that the synthetic gradient approach can achieve comparable accuracy compared to the conventional back propagation, for an eight-layer model with both fully-connected and convolutional layers. For a more complex model (VGG16), the training suffers from some accuracy degradation (up to 15%). But it achieves 11% improvement in training speed when the layers of a model are decoupled and trained on separate resource-limited containers, compared to the training of the whole model using the conventional method on the physical machine.",HotEdge,2019,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
f02f6e666aef6b0675cc4a189f9962b716c17487,https://www.semanticscholar.org/paper/f02f6e666aef6b0675cc4a189f9962b716c17487,FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled Data,"Supervised machine learning classifiers have been widely used for attack detection, but their training requires abundant high-quality labels. Unfortunately, high-quality labels are difficult to obtain in practice due to the high cost of data labeling and the constant evolution of attackers. Without such labels, it is challenging to train and deploy targeted countermeasures. In this paper, we propose FARE, a clustering method to enable fine-grained attack categorization under low-quality labels. We focus on two common issues in data labels: 1) missing labels for certain attack classes or families; and 2) only having coarsegrained labels available for different attack types. The core idea of FARE is to take full advantage of the limited labels while using the underlying data distribution to consolidate the lowquality labels. We design an ensemble model to fuse the results of multiple unsupervised learning algorithms with the given labels to mitigate the negative impact of missing classes and coarsegrained labels. We then train an input transformation network to map the input data into a low-dimensional latent space for fine-grained clustering. Using two security datasets (Android malware and network intrusion traces), we show that FARE significantly outperforms the state-of-the-art (semi-)supervised learning methods in clustering quality/correctness. Further, we perform an initial deployment of FARE by working with a large e-commerce service to detect fraudulent accounts. With realworld A/B tests and manual investigation, we demonstrate the effectiveness of FARE to catch previously-unseen frauds.",NDSS,2021,10.14722/NDSS.2021.24403,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,https://www.semanticscholar.org/paper/0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,Using system context information to complement weakly labeled data,"Real-world datasets collected with sensor networks often contain incomplete and uncertain labels as well as artefacts arising from the system environment. Complete and reliable labeling is often infeasible for large-scale and long-term sensor network deployments due to the labor and time overhead, limited availability of experts and missing ground truth. In addition, if the machine learning method used for analysis is sensitive to certain features of a deployment, labeling and learning needs to be repeated for every new deployment. To address these challenges, we propose to make use of system context information formalized in an information graph and embed it in the learning process via contrastive learning. Based on realworld data we show that this approach leads to an increased accuracy in case of weakly labeled data and leads to an increased robustness and transferability of the classifier to new sensor locations.",ArXiv,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
3352eb2b731571ca9ba85e671a214b2e2467d8d9,https://www.semanticscholar.org/paper/3352eb2b731571ca9ba85e671a214b2e2467d8d9,Online and Scalable Model Selection with Multi-Armed Bandits,"Many online applications running on live traffic are powered by machine learning models, for which training, validation, and hyperparameter tuning are conducted on historical data. However, it is common for models demonstrating strong performance in offline analysis to yield poorer performance when deployed online. This problem is a consequence of the difficulty of training on historical data in non-stationary environments. Moreover, the machine learning metrics used for model selection may not sufficiently correlate with real-world business metrics used to determine the success of the applications being tested. These problems are particularly prominent in the Real-Time Bidding (RTB) domain, in which ML models power bidding strategies, and a change in models will likely affect performance of the advertising campaigns. In this work, we present Automatic Model Selector (AMS), a system for scalable online selection of RTB bidding strategies based on realworld performance metrics. AMS employs Multi-Armed Bandits (MAB) to near-simultaneously run and evaluate multiple models against live traffic, allocating the most traffic to the bestperforming models while decreasing traffic to those with poorer online performance, thereby minimizing the impact of inferior models on overall campaign performance. The reliance on offline data is avoided, instead making model selections on a case-by-case basis according to actionable business goals. AMS allows new models to be safely introduced into live campaigns as soon as they are developed, minimizing the risk to overall performance. In livetraffic tests on multiple ad campaigns, the AMS system proved highly effective at improving ad campaign performance.",ArXiv,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
34c59ec266e2f1798918d765c2a2519a2b8d03d2,https://www.semanticscholar.org/paper/34c59ec266e2f1798918d765c2a2519a2b8d03d2,ReLink: Complete-Link Industrial Record Linkage Over Hybrid Feature Spaces,"Record Linkage (ReL) is the task of identifying records from a pair of databases referring to the same realworld entity. This has many applications in organisations of all sizes where related data often exist in silos leading to inefficiency in data engineering and analytics applications as well as ineffectiveness of business applications (e.g., unable to personalise marketing campaigns).State-of-the-art (SOTA) machine learning and deep learning based ReL techniques use adaptive similarity measures and learn their relative contributions based on labeled data. However, we report here that they do not work with similar efficacy on industrial data owing to its fundamental differences such as magnitude of schema heterogeneity, need for leveraging structure of the data, lack of training data etc. Through our proposed system ‘ReLink’, we carefully mitigate these challenges and demonstrate that it not only significantly outperforms SOTA baselines on industrial datasets but also on majority of research benchmarks. ReLink introduces the notion of complete-linkage over attributes as well as uses hybrid feature spaces on lexical and semantic similarity measures using pre-trained models such as BERT. Going beyond empirical demonstration, we provide insights and prescriptive guidance on choice of ReL techniques in industrial settings from our observations and lessons learnt from the experience of transferring and deploying for real use-cases in a large financial services organization.",2021 IEEE 37th International Conference on Data Engineering (ICDE),2021,10.1109/ICDE51399.2021.00293,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
320e3a66dbc51a1331f65b5ac42b937a39d5e051,https://www.semanticscholar.org/paper/320e3a66dbc51a1331f65b5ac42b937a39d5e051,Physical Activity Recognition With Statistical-Deep Fusion Model Using Multiple Sensory Data for Smart Health,"Nowadays, enhancing the living standard with smart healthcare via the Internet of Things is one of the most critical goals of smart cities, in which artificial intelligence plays as the core technology. Many smart services, deployed according to wearable sensor-based physical activity recognition, have been able to early detect unhealthy daily behaviors and further medical risks. Numerous approaches have studied shallow handcrafted features coupled with traditional machine learning (ML) techniques, which find it difficult to model real-world activities. In this work, by revealing deep features from deep convolutional neural networks (DCNNs) in fusion with conventional handcrafted features, we learn an intermediate fusion framework of human activity recognition (HAR). According to transforming the raw signal value to pixel intensity value, segmentation data acquired from a multisensor system are encoded to an activity image for deep model learning. Formulated by several novel residual triple convolutional blocks, the proposed DCNN allows extracting multiscale spatiotemporal signal-level and sensor-level correlations simultaneously from the activity image. In the fusion model, the hybrid feature merged from the handcrafted and deep features is learned by a multiclass support vector machine (SVM) classifier. Based on several experiments of performance evaluation, our fusion approach for activity recognition has achieved the accuracy over 96.0% on three public benchmark data sets, including Daily and Sport Activities, Daily Life Activities, and RealWorld. Furthermore, the method outperforms several state-of-the-art HAR approaches and demonstrates the superiority of the proposed intermediate fusion model in multisensor systems.",IEEE Internet of Things Journal,2021,10.1109/JIOT.2020.3013272,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
de3259f91d4ae41430b9a2da536b761e483d5bf6,https://www.semanticscholar.org/paper/de3259f91d4ae41430b9a2da536b761e483d5bf6,Auto Content Moderation in C2C e-Commerce,"Consumer-to-consumer (C2C) e-Commerce is a large and growing industry with millions of monthly active users. In this paper, we propose auto content moderation for C2C eCommerce to moderate items using Machine Learning (ML). We will also discuss practical knowledge gained from our auto content moderation system. The system has been deployed to production at Mercari since late 2017 and has significantly reduced the operation cost in detecting items violating our policies. This system has increased coverage by 554.8 % over a rule-based approach.",OpML,2020,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
06d5581ec3f28166cdba265f7da8655eef706d23,https://www.semanticscholar.org/paper/06d5581ec3f28166cdba265f7da8655eef706d23,A machine-learned proactive moderation system for auction fraud detection,"Online auction and shopping are gaining popularity with the growth of web-based eCommerce. Criminals are also taking advantage of these opportunities to conduct fraudulent activities against honest parties with the purpose of deception and illegal profit. In practice, proactive moderation systems are deployed to detect suspicious events for further inspection by human experts. Motivated by real-world applications in commercial auction sites in Asia, we develop various advanced machine learning techniques in the proactive moderation system. Our proposed system is formulated as optimizing bounded generalized linear models in multi-instance learning problems, with intrinsic bias in selective labeling and massive unlabeled samples. In both offline evaluations and online bucket tests, the proposed system significantly outperforms the rule-based system on various metrics, including area under ROC (AUC), loss rate of labeled frauds and customer complaints. We also show that the metrics of loss rates are more effective than AUC in our cases.",CIKM '11,2011,10.1145/2063576.2064002,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
69f91edaf5abc963a9b9b121d1f8bc851333e133,https://www.semanticscholar.org/paper/69f91edaf5abc963a9b9b121d1f8bc851333e133,Active Learning in the Era of Big Data,"Active learning methods automatically adapt data collection by selecting the most informative samples in order to accelerate machine learning. Because of this, real-world testing and comparing active learning algorithms requires collecting new datasets (adaptively), rather than simply applying algorithms to benchmark datasets, as is the norm in (passive) machine learning research. To facilitate the development, testing and deployment of active learning for real applications, we have built an open-source software system for large-scale active learning research and experimentation. The system, called NEXT, provides a unique platform for realworld, reproducible active learning research. This paper details the challenges of building the system and demonstrates its capabilities with several experiments. The results show how experimentation can help expose strengths and weaknesses of active learning algorithms, in sometimes unexpected and enlightening ways.",,2015,10.2172/1225849,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
6af4abe9f3360b2817db4a655e1d3486754ba6b0,https://www.semanticscholar.org/paper/6af4abe9f3360b2817db4a655e1d3486754ba6b0,Large-scale learning for media understanding,,EURASIP J. Image Video Process.,2015,10.1186/S13640-015-0080-7,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
10bbc5556fe6b79b18bb986af5e601b7ac7ab114,https://www.semanticscholar.org/paper/10bbc5556fe6b79b18bb986af5e601b7ac7ab114,LTF: A Label Transformation Framework for Correcting Target Shift,"Distribution shift is a major obstacle to the deployment of current deep learning models on realworld problems. Let Y be the target (label) and X the predictors (features). We focus on one type of distribution shift, target shift, where the marginal distribution of the target variable PY changes but the conditional distribution PX|Y does not. Existing methods estimate the density ratio between the sourceand target-domain label distributions by density matching. However, these methods are either computationally infeasible for large-scale data or restricted to shift correction for discrete labels. In this paper, we propose an end-to-end Label Transformation Framework (LTF) for correcting target shift, which implicitly models the shift of PY and the conditional distribution PX|Y using neural networks. Thanks to the flexibility of deep networks, our framework can handle continuous, discrete, and even multidimensional labels in a unified way and is scalable to large data. Moreover, for high dimensional X , such as images, we find that the redundant information in X severely degrades the estimation accuracy. To remedy this issue, we propose to match the distribution implied by our generative model and the target-domain distribution in a low-dimensional feature space that discards information irrelevant to Y . Both theoretical and empirical studies demonstrate the superiority of our method over previous approaches. UBTECH Sydney AI Centre, School of Computer Science, Faculty of Engineering, The University of Sydney, Darlington, NSW 2008, Australia School of Mathematics and Statistics, The University of Melbourne Department of Philosophy, Carnegie Mellon University. Correspondence to: Jiaxian Guo <jguo5934@uni.sydney.edu.au>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).",,2020,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
a6c7b3c141f6c604e08fee902fa268665b8a4221,https://www.semanticscholar.org/paper/a6c7b3c141f6c604e08fee902fa268665b8a4221,Simple linear classifiers via discrete optimization: learning certifiably optimal scoring systems for decision-making and risk assessment,"Scoring systems are linear classification models that let users make quick predictions by adding, subtracting, and multiplying a few small numbers. These models are widely used in applications where humans have traditionally made decisions because they are easy to understand and validate. In spite of extensive deployment, many scoring systems are still built using ad hoc approaches that combine statistical techniques, heuristics, and expert judgement. Such approaches impose steep trade-offs with performance, making it difficult for practitioners to build scoring systems that will be used and accepted. In this dissertation, we present two new machine learning methods to learn scoring systems from data: Supersparse Linear Integer Models (SLIM) for decision-making applications; and Risk-calibrated Supersparse Linear Integer Models (RiskSLIM) for risk assessment applications. Both SLIM and RiskSLIM solve discrete optimization problems to learn scoring systems that are fully optimized for feature selection, small integer coefficients, and operational constraints. We formulate these problems as integer programming problems and develop specialized algorithms to recover certifiably optimal solutions with an integer programming solver. We illustrate the benefits of this approach by building scoring systems for realworld problems such as recidivism prediction, sleep apnea screening, ICU seizure prediction, and adult ADHD diagnosis. Our results show that a discrete optimization approach can learn simple models that perform well in comparison to the state-ofthe-art, but that are far easier to customize, understand, and validate. Thesis Supervisor: Cynthia Rudin Title: Associate Professor of Computer Science Duke University",,2017,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
6a2a534a9d01b76ecb5caba20032022a904cb50d,https://www.semanticscholar.org/paper/6a2a534a9d01b76ecb5caba20032022a904cb50d,COSMIC Semantic Segmentation Framework,"Deep space missions such as the Mars Reconnaissance Orbiter collect more data than can be sent back to Earth due to limited communications bandwidth. Machine learning algorithms can be deployed on board orbiters to prioritize the downlink of scientifically interesting images, such as those including fresh impact craters, recurring slope lineae, or dust devils. However, basic machine learning research is necessary to boost realworld performance, and numerous possible convolutional neural network architectures must be evaluated in terms of accuracy and compute requirements. A framework is designed to reduce redundant development, to standardize the algorithm testing process, and to allow developers to focus on the implementation details of novel machine learning algorithms. Three convolutional neural network implementations are included with the framework, pending use in future research. 1Content-based Onboard Summarization to Monitor Infrequent Change 2CL #18-465",,2019,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
7f5000f69c30d34f6c1a4ba14d8dbfd0fe5254d2,https://www.semanticscholar.org/paper/7f5000f69c30d34f6c1a4ba14d8dbfd0fe5254d2,"Big Data Analytics Using Splunk: Deriving Operational Intelligence from Social Media, Machine Data, Existing Data Warehouses, and Other Real-Time Streaming Sources","Big Data Analytics Using Splunk is a hands-on book showing how to process and derive business value from big data in real time. Examples in the book draw from social media sources such as Twitter (tweets) and Foursquare (check-ins). You also learn to draw from machine data, enabling you to analyze, say, web server log files and patterns of user access in real time, as the access is occurring. Gone are the days when you need be caught out by shifting public opinion or sudden changes in customer behavior. Splunks easy to use engine helps you recognize and react in real time, as events are occurring. Splunk is a powerful, yet simple analytical tool fast gaining traction in the fields of big data and operational intelligence. Using Splunk, you can monitor data in real time, or mine your data after the fact. Splunks stunning visualizations aid in locating the needle of value in a haystack of a data. Geolocation support spreads your data across a map, allowing you to drill down to geographic areas of interest. Alerts can run in the background and trigger to warn you of shifts or events as they are taking place. With Splunk you can immediately recognize and react to changing trends and shifting public opinion as expressed through social media, and to new patterns of eCommerce and customer behavior. The ability to immediately recognize and react to changing trends provides a tremendous advantage in todays fast-paced world of Internet business. Big Data Analytics Using Splunk opens the door to an exciting world of real-time operational intelligence. Built around hands-on projects Shows how to mine social media Opens the door to real-time operational intelligenceWhat youll learn Monitor and mine social media for trends affecting your business Know how you are perceived, and when that perception is rising or falling Detect changing customer behavior from mining your operational data Collect and analyze in real time, or from historical files Apply basic analytical metrics to better understand your data Create compelling visualizations and easily communicate your findings Who this book is for Big Data Analytics Using Splunk is for those who are interested in exploring the heaps of data they have available, but dont know where to start. It is for the people who have knowledge of the data they want to analyze and are developers or SQL programmers at a level anywhere between beginners and intermediate. Expert developers also benefit from learning how to use such a simple and powerful tool as Splunk. Table of Contents Part I: Splunk's Basic Operation: Getting to Know Splunk Part I: Splunk's Basic Operation: Getting Data into Splunk Part I: Splunk's Basic Operation: Processing and Analysing the Data Part I: Splunk's Basic Operation: Visualizing the Results Part I: Splunk's Basic Operation: Defining Alerts. Part I: Splunk's Basic Operation: Web SiteMonitoring Part I: Splunk's Basic Operation: Using Log Files to Create Advanced Analytics Part II: Airline On-Time Performance Project: On-Time Project Description Part II: Airline On-Time Performance Project: Getting Flight Data Into Splunk Part II: Airline On-Time Performance Project: Analyzing Airlines, Airports, Flights, and Delays Part II: Airline On-Time Performance Project: Analyzing a Specific Flight over Time Part III: Social Media: Analyzing Twitter Data Part III: Social Media: Analyzing Foursquare Check-Ins Part III: Social Media: Sentiment Analysis Part IV: Architecture and Deployment: Distributed Topologies Part IV: Architecture and Deployment: High Availability Appendix A: The Performance of Splunk Appendix B: Related Applications",,2013,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,https://www.semanticscholar.org/paper/8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,Multi Uav Cooperative Surveillance With Spatio Temporal,"Deep Learning for Unmanned SystemsMultiple Heterogeneous Unmanned Aerial VehiclesAdvanced Mobile RoboticsSafe Robot Navigation Among Moving and Steady ObstaclesComputer Safety, Reliability, and SecurityAdvances in Swarm IntelligenceHolonic and Multi-Agent Systems for ManufacturingAdvances in Artificial Intelligence and Applied Cognitive ComputingUnmanned Aircraft SystemsIntelligent Computing Theories and ApplicationAutonomous Airborne Wireless NetworksAd Hoc NetworksEnabling Blockchain Technology for Secure Networking and CommunicationsUAV Sensors for Environmental MonitoringUnmanned Aerial Vehicles: Breakthroughs in Research and PracticeComputational Collective IntelligenceTime-Critical Cooperative Control of Autonomous Air VehiclesAdvances in Cooperative Control and OptimizationCooperative Robots and Sensor Networks 2015Artificial Intelligence and SecurityPRICAI 2016: Trends in Artificial IntelligenceClosing the Gap Between Research and Field Applications for Multi-UAV Cooperative MissionsMulti-rotor Platform Based UAV SystemsProceedings of the Future Technologies Conference (FTC) 2020, Volume 1Unmanned Aerial SystemsAdvanced Distributed Consensus for Multiagent SystemsCooperative Control of MultiAgent SystemsMulti-UAV Planning and Task AllocationMobile Internet SecurityCooperative Control of Multiple Unmanned Aerial Vehicles with Application to Forest Fire Detection and FightingMulti UAV Systems with Motion and Communication ConstraintsIntelligent Autonomy of UAVsIntelligent and Fuzzy Techniques in Big Data Analytics and Decision MakingIntelligent Autonomy of UAVsUAV Cooperative Decision and ControlCooperative Localization and NavigationAdvances in Guidance, Navigation and ControlMachine Learning and Intelligent CommunicationsUnmanned Aerial VehiclesThe Cognitive Approach in Cloud Computing and Internet of Things Technologies for Surveillance Tracking Systems Ad hoc networks, which include a variety of autonomous networks for specific purposes, promise a broad range of civilian, commercial, and military applications. These networks were originally envisioned as collections of autonomous mobile or stationary nodes that dynamically auto-configure themselves into a wireless network without relying on any existing network infrastructure or centralized administration. With the significant advances in the last decade, the concept of ad hoc networks now covers an even broader scope, referring to the many types of autonomous wireless networks designed and deployed for a specific task or function, such as wireless sensor networks, vehicular networks, home networks, and so on. In contrast to the traditional wireless networking paradigm, such networks are all characterized by sporadic connections, highly error-prone communications, distributed autonomous operation, and fragile multi-hop relay paths. The new wireless networking paradigm necessitates reexamination of many established concepts and protocols, and calls for developing a new understanding of fundamental problems such as interference, mobility, connectivity, capacity, and security, among others. While it is essential to advance theoretical research on fundamental and practical research on efficient policies, algorithms and protocols, it is also critical to develop useful applications, experimental prototypes, and real-world deployments to achieve an immediate impact on society for the success of this wireless networking paradigm.A comprehensive review of the state of the art in the control of multi-agent systems theory and applications The superiority of multi-agent systems over single agents for the control of unmanned air, water and ground vehicles has been clearly demonstrated in a wide range of application areas. Their large-scale spatial distribution, robustness, high scalability and low cost enable multi-agent systems to achieve tasks that could not successfully be performed by even the most sophisticated single agent systems. Cooperative Control of Multi-Agent Systems: Theory and Applications provides a wide-ranging review of the latest developments in the cooperative control of multi-agent systems theory and applications. The applications described are mainly in the areas of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Throughout, the authors link basic theory to multi-agent cooperative control practice — illustrated within the context of highly-realistic scenarios of high-level missions — without losing site of the mathematical background needed to provide performance guarantees under general working conditions. Many of the problems and solutions considered involve combinations of both types of vehicles. Topics explored include target assignment, target tracking, consensus, stochastic game theory-based framework, event-triggered control, topology design and identification, coordination under uncertainty and coverage control. Establishes a bridge between fundamental cooperative control theory and specific problems of interest in a wide range of applications areas Includes example applications from the fields of space exploration, radiation shielding, site clearance, tracking/classification, surveillance, search-and-rescue and more Features detailed presentations of specific algorithms and application frameworks with relevant commercial and military applications Provides a comprehensive look at the latest developments in this rapidly evolving field, while offering informed speculation on future directions for collective control systems The use of multi-agent system technologies in both everyday commercial use and national defense is certain to increase tremendously in the years ahead, making this book a valuable resource for researchers, engineers, and applied mathematicians working in systems and controls, as well as advanced undergraduates and graduate students interested in those areas.Time-Critical Cooperative Control of Autonomous Air Vehicles presents, in an easy-to-read style, the latest research conducted in the industry, while also introducing a set of novel ideas that illuminate a new approach to problem-solving. The book is virtually self-contained, giving the reader a complete, integrated presentation of the different concepts, mathematical tools, and control solutions needed to tackle and solve a number of problems concerning time-critical cooperative control of UAVs. By including case studies of fixed-wing and multirotor UAVs, the book effectively broadens the scope of application of the methodologies developed. This theoretical presentation is complemented with the results of flight tests with real UAVs, and is an ideal reference for researchers and practitioners from academia, research labs, commercial companies, government workers, and those in the international aerospace industry. Addresses important topics related to time-critical cooperative control of UAVs Describes solutions to the problems rooted in solid dynamical systems theory Applies the solutions developed to fixed-wing and multirotor UAVs Includes the results of field tests with both classes of UAVsThis book provides the state-of-the-art intelligent methods and techniques for solving realworld problems along with a vision of the future research. The fifth 2020 Future Technologies Conference was organized virtually and received a total of 590 submissions from academic pioneering researchers, scientists, industrial engineers, and students from all over the world. The submitted papers covered a wide range of important topics including but not limited to computing, electronics, artificial intelligence, robotics, security and communications and their applications to the real world. After a double-blind peer review process, 210 submissions (including 6 poster papers) have been selected to be included in these proceedings. One of the meaningful and valuable dimensions of this conference is the way it brings together a large group of technology geniuses in one venue to not only present breakthrough research in future technologies, but also to promote discussions and debate of relevant issues, challenges, opportunities and research findings. The authors hope that readers find the book interesting, exciting and inspiringAdvanced Distributed Consensus for Multiagent Systems contributes to the further development of advanced distributed consensus methods for different classes of multiagent methods. The book expands the field of coordinated multiagent dynamic systems, including discussions on swarms, multi-vehicle and swarm robotics. In addition, it addresses advanced distributed methods for the important topic of multiagent systems, with a goal of providing a high-level treatment of consensus to different versions while preserving systematic analysis of the material and providing an accounting to math development in a unified way. This book is suitable for graduate courses in electrical, mechanical and computer science departments. Consensus control in multiagent systems is becoming increasingly popular among researchers due to its applicability in analyzing and designing coordination behaviors among agents in multiagent frameworks. Multiagent systems have been a fascinating subject amongst researchers as their practical applications span multiple fields ranging from robotics, control theory, systems biology, evolutionary biology, power systems, social and political systems to mention a few. Gathers together the theoretical preliminaries and fundamental issues related to multiagent systems and controls Provides coherent results on adopting a multiagent framework for critically examining problems in smart microgrid systems Presents advanced analysis of multiagent systems under cyberphysical attacks and develops resilient control strategies to guarantee safe operationComplete with online files and updates, this cutting-edge text looks at the next generation of unmanned flying machines. Aerial robots can be considered as an evolution of the Unmanned Aerial Vehicl",,2021,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
aa30901b02e9923851d507e1f2726bcf9ef1b068,https://www.semanticscholar.org/paper/aa30901b02e9923851d507e1f2726bcf9ef1b068,OccuSpace: Towards a Robust Occupancy Prediction System for Activity Based Workplace,"Workplace occupancy detection is becoming increasingly important in large Activity Based Work (ABW) environments as it helps building and office management understand the utilisation and potential benefits of shared workplace. However, existing sensor-based technologies detect workstation occupancy in indoor spaces require extensive installation of hardware and maintenance incurring ongoing costs. Moreover, accuracy can depend on the specific seating styles of workers since the sensors are usually placed under the table or overhead. In this research, we provide a robust system called OccuSpace to predict occupancy of different atomic zones in large ABW environments. Unlike fixed sensors, OccuSpace uses statistical features engineered from Received Signal Strength Indicator (RSSI) of Bluetooth card beacons carried by workers while they are within the ABW environment. These features are used to train state-of-the-art machine learning algorithms for prediction task. We setup the experiment by deploying our system in a realworld open office environment. The experimental results show that OccuSpace is able to achieve a high accuracy for workplace occupancy prediction.",2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),2019,10.1109/PERCOMW.2019.8730762,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
f984227f8186fc4de590b6371184a772eed3bb79,https://www.semanticscholar.org/paper/f984227f8186fc4de590b6371184a772eed3bb79,Hands-on Exercises and Assignments on Google Cloud Platform,"It has been challenging for instructors in the MIS/IST discipline to engage students by using a lectureonly teaching technique. This paper presents a set of nifty assignments that consist of the instructor-led hands-on exercises and the take-home individual assignments in an introductory MIS course. Students were instructed to use an online tool to exchange encrypted messages and use Google Cloud Platform (GCP) to deploy virtual machines running PrestaShop, an eCommerce application. The results of a student survey showed that the assignments were fun, relevant, useful, and helpful in improving the students’ engagement and learning.",AMCIS,2018,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
22301300c381e0f3a4dbb67e72622d9546f38037,https://www.semanticscholar.org/paper/22301300c381e0f3a4dbb67e72622d9546f38037,FEATURE SELECTION USING MODIFIED ANT COLONY OPTIMIZATION APPROACH ( FS-MACO ) BASED FIVE LAYERED ARTIFICIAL NEURAL NETWORK FOR CROSS DOMAIN OPINION MINING,"Web mining and web usage mining are attracting many researchers to propose new ideas, models, deploying machine learning algorithms and more. Internet usage expands its wings to almost all kind of applications which includes e-commerce. E-commerce facilitates the consumers/customers to buy the products online and at the same time, web analytics helps the website administrators to identify which products sell more. Opinion mining is the key to analytics in many decision-making tasks in the ecommerce arena. This research work aims to propose feature election using modified ant colony optimization approach (FS-MACO) based five layered artificial neural networks for cross-domain opinion mining. Dataset is obtained which consists of reviews about products such as books, DVDs, electronics and kitchen appliances. The features are identified by making use of modified ACO and opinion mining is performed by using ANN. Accuracy and F-measure are the metrics chosen for the evaluating the performance of the proposed work. Comparison of domain-specific and domain – dependent words are presented. Results portray that the proposed work outperforms better than that of the existing work in terms of the chosen performance metrics.",,2018,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
a812368fe1d4a186322bf72a6d07e1cf60067234,https://www.semanticscholar.org/paper/a812368fe1d4a186322bf72a6d07e1cf60067234,Gaussian processes for modeling of facial expressions,"Automated analysis of facial expressions has been gaining significant attention over the past years. This stems from the fact that it constitutes the primal step toward developing some of the next-generation computer technologies that can make an impact in many domains, ranging from medical imaging and health assessment to marketing and education. No matter the target application, the need to deploy systems under demanding, realworld conditions that can generalize well across the population is urgent. Hence, careful consideration of numerous factors has to be taken prior to designing such a system. The work presented in this thesis focuses on tackling two important problems in automated analysis of facial expressions: (i) view-invariant facial expression analysis; (ii) modeling of the structural patterns in the face, in terms of well coordinated facial muscle movements. Driven by the necessity for efficient and accurate inference mechanisms we explore machine learning techniques based on the probabilistic framework of Gaussian processes (GPs). Our ultimate goal is to design powerful models that can efficiently handle imagery with spontaneously displayed facial expressions, and explain in detail the complex configurations behind the human face in real-world situations. To effectively decouple the head pose and expression in the presence of large outof-plane head rotations we introduce a manifold learning approach based on multi-view learning strategies. Contrary to the majority of existing methods that typically treat the numerous poses as individual problems, in this model we first learn a discriminative manifold shared by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Hence, the pose normalization problem is solved by aligning the facial expressions from different poses in a common latent space. We demonstrate that the recovered manifold can efficiently generalize to various poses and expressions even from a small amount of training data, while also being largely robust to corrupted image features due to illumination variations. State-of-the-art performance is achieved in the task of facial expression classification of basic emotions. The methods that we propose for learning the structure in the configuration of the muscle movements represent some of the first attempts in the field of analysis and intensity estimation of facial expressions. In these models, we extend our multi-view approach to exploit relationships not only in the input features but also in the multi-output labels. The structure of the outputs is imposed into the recovered manifold either from heuristically defined hard constraints, or in an auto-encoded manner, where the structure is learned automatically from the input data. The resulting models are proven to be robust to data with imbalanced expression categories, due to our proposed Bayesian learning of the target manifold. We also propose a novel regression approach based on product of GP experts where we take into account people’s individual expressiveness in order to adapt the learned models on each subject. We demonstrate the superior performance of our proposed models on the task of facial expression recognition and intensity estimation.",,2016,10.25560/44106,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,https://www.semanticscholar.org/paper/cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,Comparing Human-Robot Proxemics between Virtual Reality and the Real World,"Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of Human-Robot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. Comparing Human-Robot Proxemics between Virtual Reality and the Real World Rui Li KTH Royal Institute of Technology Stockholm, Sweden Rui3@kth.se ABSTRACT Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other.Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. INTRODUCTION Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI) [1][2][3][4]. VR has been used to test teleoperation and collect demonstration data to train machine learning algorithms, which showcased the effectiveness of learning visuomotor skills using data collected by consumer-grade devices [1]. VR teleoperation systems were proposed to crowdsource robotic demonstrations at scale [2]. A VR simulation framework was also proposed to replace the physical robot, as VR can enable high level abstraction in embodiment and multimodal interaction [3]. VR has also been used as a rapid prototyping tool to design in-vehicle interactions and interfaces for self-driving cars, which showed the evocation to genuine responses from test participants [4]. Compared to other HRI experiment methods, VR as an emerging interactive media provides unique advantages. VR HRI has the potential of having higher immersion and fidelity than picture based HRI, video-based HRI and simulated HRI. In situations where the perception of the robot is challenging, compared to on-screen viewing, VR display showed significant improvement on collaborative tasks [5]. When comparing VR HRI to the physical, realworld interaction (Live HRI), there is a trade-off between the two. VR experiences still cannot replace physical experiences due to system limitation, and limited interaction modalities etc. [6]. For example, system limitations such as limited field of view and low display resolution could reduce immersion and presence of the VR experience, resulting in different behaviors from Live experiments. Limited interaction modalities, such as the absence of touch, means that the participant could not feel the robot or even go through the robot, which could potentially break the entire interaction. Figure 1: Photograph of the Live experiment setting However, with the help of the distribution of consumer-grade VR devices and online crowdsourcing platforms, VR HRI has the potential to gain massive data for training robotic behavior and studying HRI related issues. Data collection through VR can also reduce noise and improve the data quality [1], which help to ease data processing and algorithm training. Furthermore, VR HRI experiments can test concepts and interactions without physical robots, making it more resource efficient and less expensive than Live HRI. Less hardware also means that the experiment will be less cumbersome to set up, easier to be reproduced and to ensure experiment quality. In this study, HRI Proxemics (the preferred personal space between a human and a robot) was compared to give a better justification and more basic understanding of the relationship between Live and VR. Proxemics preferences rely on lower level intuition [7], therefore, reflect the differences in the perceptions between Live and VR better. Compared to other HRI subject such as conversational (audio) or gaze behavior (visual), which are more modality dependent, proxemics can give a comprehensive understanding of the human responses. In addition, variations of modalities in VR can greatly influence human perception. For example, a higher visual familiarity of the physical environment in VR can decrease the effect of distance distortion [8]. Auditory inputs play another important role in VR, the addition of spatial sound can increase the sense of presence in VR and provide sound localization [9]. Thus, this work also compares VR settings with variance in modalities to evaluate the impacts of visual familiarity and spatial sound on VR HRI experiments. A 2 x 3 mixed design experiment was conducted to evaluate the differences between Live and VR HRI, as well as the influence of visual familiarity and spatial sound in VR. For the Live HRI, the pepper robot from Softbank Robotics was used (Figure 1). In the VR HRI, a 3D model of the same robot was used. To measure visual familiarity, the VR scene was created in Blender based on a 3D scan of the physical lab. The spatial sound was created by enabling the movement of the physical robot, due to the difficulties of engineering spatial sound. The interaction was implemented in Unity. As an objective measurement for proxemics preference, the minimum comfort distance (MCD) was measured. In addition, for the psychological perception of the experience, the feeling of presence was measured with the SUS questionnaire. For the perception of the robot, two relevant factors, competence and discomfort was measured with the ROSAS questionnaire.",,2018,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
59e10d1d4cd454635914cfd0ac5160a318fd0473,https://www.semanticscholar.org/paper/59e10d1d4cd454635914cfd0ac5160a318fd0473,UB09 Session 9,"In the domain of Wireless Sensor Networks (WSN), providing an effective security solution to protect the motes and their communications is challenging. Due to the hard constraints on performance, storage and energy consumption, normal network-security related techniques cannot be applied. Focusing on the ""Intrusion Detection"" problem, we propose a realworld application of our WSN Intrusion Detection System (WIDS). WIDS exploits the Weak Process Models to classify potential security issues in the WSN and to notify the operators when an attack tentative is detected. In this demonstration, we show how our IDS works, how it detects some basic attacks and how the IDS can evolve to fullfil the needs of secure WSN deployments. Download Paper (PDF) UB09.2 RESCUE: EDA TOOLSET FOR INTERDEPENDENT ASPECTS OF RELIABILITY, SECURITY AND QUALITY IN NANOELECTRONIC SYSTEMS DESIGN Authors: Cemil Cem Gürsoy1, Guilherme Cardoso Medeiros2, Junchao Chen3, Nevin George4, Josie Esteban Rodriguez Condia5, Thomas Lange6, Aleksa Damljanovic5, Raphael Segabinazzi Ferreira4, Aneesh Balakrishnan6, Xinhui Anna Lai1, Shayesteh Masoumian7, Dmytro Petryk3, Troya Cagil Koylu2, Felipe Augusto da Silva8, Ahmet Cagri Bagbaba8 and Maksim Jenihhin1 1Tallinn University of Technology, EE; 2Delft University of Technology, NL; 3IHP, DE; 4BTU Cottbus-Senftenberg, DE; 5Politecnico di Torino, IT; 6IROC Technologies, FR; 7Intrinsic ID B.V., NL; 8Cadence Design Systems GmbH, DE Abstract The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF)The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF) UB09.3 ASAM: AUTOMATIC SYNTHESIS OF ALGORITHMS ON MULTI CHIP/FPGA WITH COMMUNICATION CONSTRAINTS Authors: Amir Masoud Gharehbaghi, Tomohiro Maruoka, Yukio Miyasaka, Akihiro Goda, Amir Masoud Gharehbaghi and Masahiro Fujita, The University of Tokyo, JP Abstract Mapping of large systems/computations on multiple chips/multiple cores needs sophisticated compilation methods. In this demonstration, we present our compiler tools for multi-chip and multi-core systems that considers communication architecture and the related constraints for optimal mapping. Specifically, we demonstrate compilation methods for multi-chip connected with ring topology, and multi-core connected with mesh topology, assuming fine-grained reconfigurable cores, as well as generalization techniques for large problems size as convolutional neural networks. We will demonstrate our mappings methods starting from data-flow graphs (DFGs) and equations, specifically with applications to convolutional neural networks (CNNs) for convolution layers as well as fully connected layers. Download Paper (PDF) UB09.4 HEPSYCODE-MC: ELECTRONIC SYSTEM-LEVEL METHODOLOGY FOR HW/SW CO-DESIGN OF MIXED-CRITICALITY EMBEDDED SYSTEMS Authors: Luigi Pomante1, Vittoriano Muttillo1, Marco Santic1 and Emilio Incerto2 1Università degli Studi dell'Aquila DEWS, IT; 2IMT Lucca, IT Abstract Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF)Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF) UB09.5 CS: CRAZYSQUARE Authors: Federica Caruso1, Federica Caruso1, Tania Di Mascio1, Alessandro D'Errico1, Marco Pennese2, Luigi Pomante1, Claudia Rinaldi1 and Marco Santic1 1University of L'Aquila, IT; 2Ministry of Education, IT Abstract CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF)CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF) UB09.6 LABSMILING: A SAAS FRAMEWORK, COMPOSED OF A NUMBER OF REMOTELY ACCESSIBLE TESTBEDS AND RELATED SW TOOLS, FOR ANALYSIS, DESIGN AND MANAGEMENT OF LOW DATA-RATE WIRELESS PERSONAL AREA NETWORKS BASED ON IEEE 802.15.4 Authors: Carlo Centofanti, Luigi Pomante, Marco Santic and Walter Tiberti, University of L'Aquila, IT Abstract Low data-rate wireless personal area networks (LR-WPANs) are constantly increasing their presence in the fields of IoT, wearable, home automation, health monitoring. The development, deployment and testing of SW based on IEEE 802.15.4 standard (and derivations, e.g. 15.4e), require the exploitation of a testbed as the network grows in complexity and heterogeneity. This demo shows LabSmiling: a SaaS framework which connects testbeds deployed in a real-world-environment and the related SW tools that make available a meaningful (but still scalable) number of physical devices (sensor nodes) to developers. It provides a comforta",,2019,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,https://www.semanticscholar.org/paper/3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,Visual Model Interpretation for Epidemiological Cohort Studies,"Epidemiological cohort studies investigate the cause and development of diseases in human populations. Conventional analyses are challenged by recently increasing study sizes, which is why the incorporation of machine learning gains popularity. State-of-the-art classifiers are however often hard to interpret – an important requirement in medical applications. This thesis addresses the gap between predictive power and interpretability in the context of cohort study analysis. Main contribution is the development of an interactive visual interface for the interpretation and comparison of probabilistic classifiers. It supports the analysis of important features at both global and individual level, computation of partial dependence, and iterative construction of meaningful feature groups. To analyse the longitudinal influence of features, the user can modify the feature set by removing a feature or replacing its value by a previous examination record. The developed visual interface is evaluated in two case studies in order to test its effectiveness for the generation and validation of research hypotheses. The case studies include a realworld epidemiological cohort study and synthetic data. The results indicate the interface’s usefulness for epidemiological research, but also reveal necessary further work for the deployment into a productive environment.",,2018,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
d91b1b996678425418321d9de5b251778eb506d7,https://www.semanticscholar.org/paper/d91b1b996678425418321d9de5b251778eb506d7,Knowledge engineering with semantic web technologies for decision support systems based on psychological models of expertise,"Machines that provide decision support have traditionally used either a representation of human expertise or used mathematical algorithms. Each approach has its own limitations. This study helps to combine both types of decision support system for a single system. However, the focus is on how the machines can formalise and manipulate the human representation of expertise rather than on data processing or machine learning algorithms. It will be based on a system that represents human expertise in a psychological format. The particular decision support system for testing the approach is based on a psychological model of classification that is called the Galatean model of classification. The simple classification problems only require one XML structure to represent each class and the objects to be assigned to it. However, when the classification system is implemented as a decision support system within more complex realworld domains, there may be many variations of the class specification for different types of object to be assigned to the class in different circumstances and by different types of user making the classification decision. All these XML structures will be related to each other in formal ways, based on the original class specification, but managing their relationships and evolution becomes very difficult when the specifications for the XML variants are text-based documents. For dealing with these complexities a knowledge representation needs to be in a format that can be easily understood by human users as well as supporting ongoing knowledge engineering, including evolution and consistency of knowledge. The aim is to explore how semantic web technologies can be employed to help the knowledge engineering process for decision support systems based on human expertise, but deployed in complex domains with variable circumstances. The research evaluated OWL as a suitable vehicle for representing psychological expertise. The task was to see how well it can provide a machine formalism for the knowledge without losing its psychological validity or transparency: that is, the ability of end users to understand the knowledge representation intuitively despite its OWL format. The OWL Galatea model is designed in this study to help in automatic knowledge maintenance, reducing the replication of knowledge with variant uncertainties and support in knowledge engineering processes. The OWL-based approaches used in this model also aid in the adaptive knowledge management. An adaptive assessment questionnaire is an example of it, which is dynamically derived using the users age as the seed for creating the alternative questionnaires. The credibility of the OWL Galatea model is tested by applying it on two extremely different assessment domains (i.e. GRiST and ADVANCE). The conclusions are that OWLbased specifications provide the complementary structures for managing complex knowledge based on human expertise without impeding the end users’ understanding of the knowledgebase. The generic classification model is applicable to many domains and the accompanying OWL specification facilitates its implementations.",,2016,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
3af91b1be29551c1cf19866f47e7035b7e139343,https://www.semanticscholar.org/paper/3af91b1be29551c1cf19866f47e7035b7e139343,Objective Image Quality Assessment: Facing The Real-World Challenges,"There has been a growing interest in recent years in the development of objective image quality assessment (IQA) models, whose roles are not only to monitor image quality degradations and benchmark image processing systems, but also to optimize various image and video processing algorithms and systems. While the past achievement is worth celebrating, a number of major challenges remain when we apply existing IQA models in realworld applications. These include obvious ones such as the challenges to largely reduce the complexity of existing IQA algorithms and to make them easy-to-use and easy-to-understand. There are also challenges regarding the applicability of existing IQA models in many real-world problems where image quality needs to be evaluated and compared across dimensionality, across viewing environment, and across the form of representations − specific examples include quality assessment for image resizing, color-togray image conversion, multi-exposure image fusion, image retargeting, and high dynamic range image tone mapping. Here we will first elaborate these challenges, and then concentrate on a specific one, namely the generalization challenge, which we believe is a more fundamental issue in the development, validation and application of IQA models. Specifically, the challenge is about the generalization capability of existing IQA models, which achieve superior quality prediction performance in lab testing environment using a limited number of subject-rated test images, but the performance may not extend to the real-world where we are working with images of a much greater diversity in terms of content and complexity. We will discuss some principle ideas and related work that might help us meet the challenges in the future. Introduction Over the past decades, a growing number of researchers and engineers in the image processing community have started to realize the importance of image/video quality assessment (IQA/VQA) [40, 29, 4]. This is not surprising because no matter what image/video processing problems we are working on, the same issues repeatedly come up − How should we evaluate the images generated from our algorithms/systems? How do we know our algorithm/system is creating an improvement between the input and output images, and by how much? How can we know one algorithm/system performs better than another, and by how much? What should be the quality criterion for which the design of our algorithms/systems should be optimized? Since the human eyes are the ultimate receivers in most image processing applications, human subjective visual testing would be a reliable solution. However, with the exponential increase of the volume of image/video data being generated daily, it becomes impossible to address these quality issues in a timely manner by subjective visual testing, which is slow, cumbersome and expensive. Instead, only trusted objective IQA models may potentially meet these needs. In academia, objective IQA has been a hot research topic, especially in the past 15 years [35, 4, 29]. First, the commonly used numerical disotrtion/quality measures in the past − the mean squared error (MSE) and the peak signal-to-noise ratio (PSNR) − have been shown to correlate poorly with perceived image quality [28, 30]. Second, a large number of perceptually more meaningful IQA models have been proposed, including full-reference (where a perfect quality reference image is available when evaluating a distorted image) [35, 4, 29], no-reference (where the reference image is not accessible) [34, 24, 31], and reduced-reference (where only partial information about the reference image is available) models [39, 36, 31, 29]. Third, several design principles have been discovered and repeatedly demonstrated to be useful in the design and improvement of IQA models. These include psychophysical and physiological visibility models [35, 4], the structural similarity (SSIM) approaches [28, 32, 33, 20, 49], the natural scene statistics (NSS) and information theoretic approaches [36, 39, 21, 31], the visual saliency based approaches [50], and the machine learning based approaches [6]. Fourth, a number of subject-rated image quality databases have been created and made publicly available [22, 7, 8, 17, 16, 47]. They provide a common benchmark platform for the evaluation and comparison of IQA models, among which several algorithms have achieved high correlations with the subjective mean opinion scores (MOSs) of the test images [23, 38, 33, 49]. In the video delivery industry, perceptual objective IQA methods such as the SSIM algorithm have been incorporated into many practical hardware and software systems to monitor image/video quality degradations and to test/compare image/video encoders and transcoders [27, 25, 26]. The wide use of SSIM has resulted in a Primetime Engineering Emmy Award given by the Academy of Television Arts and Sciences [1]. The remarkable development and successful deployment of modern IQA methods are definitely worth celebrating. Nevertheless, this does not necessarily mean that the existing IQA models have already met the real-world challenges. Otherwise, they should have made a much stronger impact and become a gamechanging factor in the industry. Using the video delivery industry as an example, even now most practitioners are still equating bitrate with quality in the practical design of video delivery architectures. However, using the same bitrate to encode different video content could result in dramatically different visual quality. Clearly, the perceptual quality of the video itself, which is presumably the ultimate evaluation criterion of the whole video delivery system, has not been placed at the driver’s seat. While it is understandable that quality degradation is inevitable at many stages in the video delivery chain due to practical constraints, the real concern here is that there is no existing protocol to monitor and control such quality degradation. As a result, various tricks have been used to manipulate the video content and network resources are allocated in suboptimal ways, leaving the creative intent of the content producers unprotected. While it is certain that the industry needs to be better informed about the great potentials of making the best use of IQA/VQA models, we believe that an equally important aspect that slows down the process is that the existing IQA/VQA models still do not meet many real-world challenges. In the following sections, we will elaborate some of these challenges and then focus on a specific one, namely the generalization challenge. We wish our discussions on some fundamental ideas could provide some useful insights for the future development of IQA models that may meet these real-world challenges. The Real-World Challenges Here we make a list of real-world challenges, many of which are described in more details through examples of practical scenarios. 1. It is highly desirable to reduce the complexity of the IQA/VQA algorithms so that they can be computed in realtime or in an even faster speed. This is especially useful in time-sensitive applications such as live broadcasting and videoconferencing. Many existing models are far from meeting this challenge. 2. It is essential to make the IQA/VQA scores easy-to-use and easy-to-understand. For example, the raw SSIM score does not have an explicit perceptual meaning, making it difficult to determine what level of SSIM index can warrant an excellent video quality and how much improvement in the SSIM index is sufficient to create visible quality improvement. Mapping the raw scores into a perceptually linear domain that is easily linked to human expressions about image quality is desirable. 3. The same video stream shown on different display devices could result in very different perceptual quality. For example, a strongly compressed video that exhibits very annoying artifacts on a large TV could appear to have fine quality when viewed on the screen of a smartphone. The quality may also change significantly when the video is watched on the same TV but at two different viewing distances, one at the default distance and the other at a very close distance. However, existing IQA/VQA models give the same score based on the video stream only, completely ignorant of the viewing device and viewing condition. 4. In a video-on-demand application, a high-quality highresolution (e.g., 4K) source video may be encoded into multiple video streams of different resolutions (e.g., 1080p, 720p, 360p, 240p, etc.) and different bit rates, aiming for satisfying a variety of user needs. In order to measure the quality of the encoded videos, most existing VQA models cannot be computed because the source (reference) and test videos have different spatial resolutions. 5. An image or video may need to be displayed on a screen that has a spatial resolution higher than that of the image resolution. As a result, spatial interpolation is performed. Again, most existing VQA models are not applicable because the reference and test images have different spatial resolutions. 6. An image or video of imperfect quality (e.g., being compressed at an earlier stage) is received and then transcoded to multiple images or videos with different bitrates and resolutions. Most existing IQA/VQA models are not applicable not only because they do not allow for cross-resolution quality assessment, but also because they assume the original reference image/video to have perfect quality, which is not the case here. How to carry out “degraded reference” IQA/VQA is a major challenge. 7. A high dynamic range (HDR) image (e.g., the pixels are in 10 or more bit depths) is tone mapped to a standard dynamic range (SDR) image (8 bits per pixel) in order to be visualized on an SDR display. There is certainly information loss that we would like to capture. However, most existing IQA models do not apply because they cannot compare images/videos with different dynamic ranges.",IQSP,2016,10.2352/ISSN.2470-1173.2016.13.IQSP-205,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
8f2a47cd8a04aa7985d36c1106b01f35290be30f,https://www.semanticscholar.org/paper/8f2a47cd8a04aa7985d36c1106b01f35290be30f,Development of 80- and 100- Mile Work Day Cycles Representative of Commercial Pickup and Delivery Operation,"When developing and designing new technology for integrated vehicle systems deployment, standard cycles have long existed for chassis dynamometer testing and tuning of the powertrain. However, to this day with recent developments and advancements in plug-in hybrid and battery electric vehicle technology, no true “work day” cycles exist with which to tune and measure energy storage control and thermal management systems. To address these issues and in support of development of a range-extended pickup and delivery Class 6 commercial vehicle, researchers at the National Renewable Energy Laboratory in collaboration with Cummins analyzed 78,000 days of operational data captured from more than 260 vehicles operating across the United States to characterize the typical daily performance requirements associated with Class 6 commercial pickup and delivery operation. In total, over 2.5 million miles of realworld vehicle operation were condensed into a pair of duty cycles, an 80-mile cycle and a 100-mile cycle representative of the daily operation of U.S. class 3-6 commercial pickup and delivery trucks. Using novel machine learning clustering methods combined with mileage-based weighting, these composite representative cycles correspond to 90th and 95th percentiles for daily vehicle miles traveled by the vehicles observed. In addition to including vehicle speed vs time drive cycles, in an effort to better represent the environmental factors encountered by pickup and delivery vehicles operating across the United States, a nationally representative grade profile and key status information were also appended to the speed vs. time profiles to produce a “work day” cycle that captures the effects of vehicle dynamics, geography, and driver behavior which can be used for future design, development, and validation of technology. Introduction Under DOE-FOA-0001349 FY15 Award for Mediumand Heavy-Duty Vehicle Powertrain Electrification, Cummins and PACCAR jointly proposed the development of a range-extending plug-in hybrid electric Class 6 pickup and delivery truck. The goal of this project is to demonstrate an electrified vehicle that would deliver a minimum of 50% reduction in fuel consumption across a range of representative drive cycles. In addition to achieving the 50% fuel reduction target, the vehicle also needs to demonstrate as good or better drivability and performance while still meeting emissions requirements when compared to existing conventionally fueled baseline vehicles. Most existing duty cycles used to test conventional internal combustion powered vehicles are of a limited time duration. For example, the Hybrid Truck Utility Forum Class 6 Pickup and Delivery cycle is slightly more than one hour. When testing a system using only fuel as its energy source, this is acceptable; a onehour duty cycle can be used to represent the vehicle operation for the entire work day (e.g., fuel consumption in the middle of the day is very similar to fuel consumption at the end of the day). However, with plug-in electric vehicles, the system (battery characteristics and thermal management systems) may operate differently throughout the work day (especially near the end of the day). For example, the available battery energy may be completely spent prior to the completion of the route. A short duty cycle cannot simply be extrapolated. Evaluating the vehicle over the entire work day also provides the ability to interject appropriate stops that are typical of the Class 6-7 pickup and delivery application. These stops can range from several minutes to much longer and can have significant thermal effect on the vehicle and powertrain systems. These stops may also have a large impact on overall duty cycle mileage (and other duty cycle characteristics such as average speed) as the stops may account for roughly half of the work day. As part of the research and development team, the National Renewable Energy Laboratory (NREL) was been NREL/CP-5400-70943. Posted with permission. Presented at WCX 18: SAE World Congress Experience, 10-12 April 2018, Detroit, Michigan.",,2018,10.4271/2018-01-1192,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
cce600d54ef32b3f6312b9166da097e0f9eded8a,https://www.semanticscholar.org/paper/cce600d54ef32b3f6312b9166da097e0f9eded8a,Designing a Visual Analytics System for Industry-Scale Deep Neural Network Models,"The complexity of industry-scale deep learning models and datasets pose unique design, visualization, and system challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have designed, developed, and deployed ACTIVIS, a visual analytics system for interpreting industry-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both instanceand subset-level. ACTIVIS has been deployed on Facebook’s machine learning platform. This article is a summary for the VAST’17 paper (TVCG track) ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models [2]. 1 DESIGNING FOR INDUSTRY-SCALE MODELS Despite the increasing interest in developing visualization tools for deep learning interpretation [5–7], the complexity of large-scale models and datasets used in industry pose unique design challenges that are inadequately addressed by existing work. For example, while most existing visualization tools target image datasets, deep learning tasks in industry often involve different types of data, including text and numerical data. Furthermore, in designing tools for realworld deployment, it is a high priority that the tools be flexible and scalable, adapting to the wide variety of models and datasets used. These observations motivate us to design and develop ACTIVIS [2], a visual analytics system for deep neural network models, now deployed on Facebook’s machine learning platform. Since the ACTIVIS project started in April 2016, we have conducted participatory design sessions with over 15 Facebook engineers, researchers, and data scientists across multiple teams to learn about their visual analytics needs. We identified six key design challenges — for data, model, and analytics — that have not been adequately addressed by existing deep learning visualization tools. The challenges include the need to support: (1) diverse input data sources, (2) high data volume, (3) complex model architecture, (4) a great variety of models, (5) diverse subset definitions for analytics, and (6) both instanceand subset-level analyses. These challenges shape the main design goals of ACTIVIS. 2 ACTIVIS CONTRIBUTIONS ACTIVIS’s main contributions include: • A novel visual representation that unifies instanceand subsetlevel inspections of neuron activation, facilitating comparison of activation patterns for multiple instances. *e-mail: kahng@gatech.edu †e-mail: mortimer@fb.com ‡e-mail: adityakalro@fb.com §e-mail: polo@gatech.edu • An interface that tightly integrates an overview of graph-structured complex models and local inspection of neuron activations, allowing users to explore the model at different levels of abstraction. • A deployed system scaling to large datasets and models. • Case studies with Facebook engineers and data scientists that highlight how ACTIVIS helps them with their work. ACTIVIS’s multiple coordinated views help users get a high-level overview of the model from which the user can drill down to perform localized inspection of activations. ACTIVIS visualizes how neurons are activated by user-specified instances or instance subsets, to help users understand how a model derives its predictions. The subsets can be flexibly defined using data attributes, features, or output results, enabling model inspection from multiple angles. While many existing deep learning visualization tools support instancelevel exploration [6, 7], ACTIVIS is the first tool that simultaneously supports instanceand subset-level exploration. Both exploration strategies are common and effective, and they offer complementary analytics benefits. Instance-based analysis instructs how individual instances contribute to a model’s accuracy, but it is tedious to inspect many instances one by one. Subset-based analysis leverages input features or instance subsets to help reveal relationships between data attributes and machine learning algorithms’ outputs [3]. It is especially beneficial when dealing with huge datasets in industry, which may consist of millions or billions of data points. By exploring instance subsets and enabling their comparison with individual instances, users can learn how them models respond to many different slices of the data. We refer our readers to the longer version of our ACTIVIS [2] VAST’17 paper published in IEEE Transactions on Visualization and Computer Graphics.",,2017,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
d64a7ff179c4c6f579c2509eef46df37c022942e,https://www.semanticscholar.org/paper/d64a7ff179c4c6f579c2509eef46df37c022942e,QUAESTUS – A Top-N Recommender System with Ranking Matrix Factorization,"The last decade has seen rapid strides being taken in the field of recommender systems, which has been driven by both consumer demand for personalization as well as academic interest in implementing more accurate and optimized versions of recommender systems. In this paper we have discussed our implementation of Quaestus, a top-n item-based collaborative filtering recommender system with ranked matrix factorization (for relevance based sorting) which we have tested on an e-commerce dataset. We have used sentiment analysis to understand the polarity of reviews and thus extracting a score out of it, which in collaboration with the product rating (which was available on a scale of 1 to 5) has helped build a more robust recommender system. We have deployed Quaestus on an e-commerce website that we have built. The paper describes the phases of implementation and shows the method to deploy our model to the website that we have created. The results after experiments have shown that our model fares better than other algorithms with which we have compared our model. General Terms Recommender System, Natural Language Processing, ECommerce Platform, Web Scraping, Machine Learning, NLP, ML.",,2018,10.5120/ijca2018917135,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
3a9dbcbd447262bebf322781082e9913d802e871,https://www.semanticscholar.org/paper/3a9dbcbd447262bebf322781082e9913d802e871,"HcBench: Methodology, development, and characterization of a customer usage representative big data/Hadoop benchmark","Big Data analytics using Map-Reduce over Hadoop has become a leading edge paradigm for distributed programming over large server clusters. The Hadoop platform is used extensively for interactive and batch analytics in ecommerce, telecom, media, retail, social networking, and being actively evaluated for use in other areas. However, to date no industry standard or customer representative benchmarks exist to measure and evaluate the true performance of a Hadoop cluster. Current Hadoop micro-benchmarks such as HiBench-2, GridMix-3, Terasort, etc. are narrow functional slices of applications that customers run to evaluate their Hadoop clusters. However, these benchmarks fail to capture the real usages and performance in a datacenter environment. Given that typical datacenter deployments of Hadoop process a wide variety of analytic interactive and query jobs in addition to batch transform jobs under strict Service Level Agreement (SLA) requirements, performance benchmarks used to evaluate clusters must capture the effects of concurrently running such diverse job types in production environments. In this paper, we present the methodology and the development of a customer datacenter usage representative Hadoop benchmark ""HcBench"" which includes a mix of large number of customer representative interactive, query, machine learning, and transform jobs, a variety of data sizes, and includes compute, storage 110, and network intensive jobs, with inter-job arrival times as in a typical datacenter environment. We present the details of this benchmark and discuss application level, server and cluster level performance characterization collected on an Intel Sandy Bridge Xeon Processor Hadoop cluster.",2013 IEEE International Symposium on Workload Characterization (IISWC),2013,10.1109/IISWC.2013.6704672,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
ea89d5ab69627a9361a340d43866cc0950a50fa1,https://www.semanticscholar.org/paper/ea89d5ab69627a9361a340d43866cc0950a50fa1,Distributed Learning Algorithms for Sensor Networks,"Wireless sensor networks have received significant attention in the last decade owing to their widespread use not only in monitoring the physical world but also in surveillance. The energy and communication constraints of sensor nodes, coupled with distributed processing of sensed signals, lead to challenges in developing effective methods to perform desired inference tasks such as object detection or classification. Further, the lack of well-calibrated sensors is a major obstacle for the rapid deployment of sensor networks. This dissertation develops gossip-based learning algorithms for distributed signal processing in sensor networks. In gossip-based algorithms, sensor nodes share information with local neighbors to converge upon common knowledge about the sensed environment. Gossip-based methods allow for manageable communication among energy-constrained nodes and also accommodate changing network communication topologies. We consider three related problems and develop gossip-based processing solutions. We first consider the problem of joint signature estimation and node calibration using distributed measurements over a large-scale sensor network. We develop a new Distributed Signature Learning and Node Calibration algorithm, called D-SLANC, which estimates the signature of a commonly-sensed source signal and simultaneously estimates calibration parameters local to each sensor node. The approach we take is ii to model the sensor network as a connected graph and make use of the gossip-based distributed consensus to update the estimates at each iteration of the algorithm. We prove convergence of the algorithm to the centralized data pooling solution. We also compare its performance with the Cramér-Rao bound (CRB), and study the scaling performance of both the CRB and the D-SLANC algorithm. Secondly, we develop a gossip-based algorithm for distributed `1-optimization in a large-scale sensor network setting. Specifically, we consider sensor nodes which can measure only a part of the entire measurement vector. We formulate the `1optimization problem as quadratic optimization and develop a distributed, gossipbased algorithm using the projected-gradient approach. We analyze the performance of the proposed algorithm using synthetic data and compare it with a standard `1 solver. Third, we consider the problem of distributed classifier learning in a large-scale sensor network setting. We adopt a machine learning approach to the problem and develop a distributed, gossip-based algorithm that learns the optimal (large-margin) hyperplane separating the two classes, using the projected-gradient approach. We illustrate the performance of the proposed algorithm using both synthetic and realworld datasets.",,2010,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
6f070c05dbd342d3906ee2fbdd2c3529ed558851,https://www.semanticscholar.org/paper/6f070c05dbd342d3906ee2fbdd2c3529ed558851,Designing and evaluating techniques to mitigate misinformation spread on microblogging web services,"Online social media is a powerful platform for dissemination of information during important realworld events. Beyond the challenges of volume, variety and velocity of content generated on online social media, veracity poses a much greater challenge for effective utilization of this content by citizens, organizations, and authorities. Veracity of information refers to the trustworthiness / credibility / accuracy / completeness of the content. Over last few years social media has also been used to disseminate misinformation in the form of rumors, hoaxes, fake images, and videos. We aim to address this challenge of veracity or trustworthiness of content posted on social media. The spread of such untrustworthy content online has caused the loss of money, infrastructure and threat to human lives in the offline world. We focus our work on Twitter, which is one of the most popular microblogging web service today. We provide an in-depth analysis of misinformation spread on Twitter during real-world events. We propose and evaluate automated techniques to mitigate misinformation spread in real-time. The main contributions of this work are: (i) we analyzed how true versus false content is propagated through the Twitter network, with the purpose of assessing the reliability of Twitter as an information source during real-world events; (ii) we showed the effectiveness of automated techniques to detect misinformation on Twitter using a combination of content, meta-data, network, user profile and temporal features; (iii) we developed and deployed a novel framework for providing indication of trustworthiness / credibility of tweets posted during events. We evaluated the effectiveness of this real-time system with a live deployment used by real Twitter users. First, we analyzed Twitter data for 25+ global events from 2011-2014 for the spread of fake images, rumors, and untrustworthy content. Some of the prominent events analyzed by us are: Mumbai blasts (2011), England Riots (2011), Hurricane Sandy (2012), Boston Marathon Blasts (2013), Polar Vortex (2014). We identified tens of thousands of tweets containing fake images, rumors, fake websites, and by malicious user profiles for these events. We performed an in-depth characterization study of how this false versus the true data is introduced and disseminated in the Twitter network. Second, we showed how features of meta-data, network, event and temporat from user-generated content can be used effectively to detect misinformation and predict its propagation during realworld events. Third, we proposed and evaluated an automated methodology for assessing credibility of information in tweets using supervised machine learning and relevance feedback approach. We developed and deployed a real-time version in TweetCred, a system that assigns a credibility score to tweets. TweetCred, available as a browser plug-in, has been installed and used by 1,808 real Twitter users. During ten months of its deployment, the credibility score for about 12 million tweets was computed, allowing us to evaluate TweetCred in terms of accuracy, performance, effectiveness and usability. The system TweetCred built as part of this thesis work is used effectively by emergency responders, firefighters, journalists and general users to obtain credible content from Twitter. This thesis work has shown that measuring credibility of the Twitter content is possible using semi-automated techniques, and the results can be valuable to the real-world users. The insights obtained from this research and deployment provide a basis for building more sophisticated technology to tackle similar problems on different social media.",,2015,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
4867a63e5edd7ee10f28067d6dd5b07d69321de7,https://www.semanticscholar.org/paper/4867a63e5edd7ee10f28067d6dd5b07d69321de7,Thesis Title: A Framework for Improving the Performance of Signature-based Network Intrusion Detection Systems,"Network Intrusion detection systems (NIDSs) have been widely deployed in different network environments (e.g., banks, schools) to defend against a variety of network attacks (e.g., Trojans, worms). Generally, a network intrusion detection system can be classified into two categories: signature-based NIDS and anomaly-based NIDS. In realworld applications, the signature-based NIDS is more prevalent than the anomaly-based detection as the false alarm rate of the former is much lower than the latter. However, we identify three major issues that can greatly affect the performance of a signature-based NIDS. Expensive signature matching. The traditional signature matching in a signature-based NIDS is too expensive that the computing burden is at least linear to the size of an incoming string. Therefore, the operational burden of a signature-based NIDS could be significantly increased in a large-scale network environment. Overhead network packets. In a large-scale network environment, a signature-based NIDS usually has to drop lots of network packets since the number of incoming packets exceeds its maximum processing capability. Massive false alarms. Although the false alarm rate of a signature-based NIDS is much smaller than that of an anomaly-based NIDS. The number of false alarms generated by a signature-based NIDS can still increase the difficulty in analyzing true alarms and adversely affect the analysis results. To mitigate the above issues, in this thesis, we propose several approaches in improving the performance of a signature-based NIDS such as Snort in the following three aspects: Signature matching improvement.We design an exclusive signature matching scheme to help perform a more efficient signature matching with the purpose of enhancing the performance of signature matching in a heavy traffic environment. Network packet filtration and reduction. To mitigate this issue, we advocate the method of constructing a packet filter such as blacklist-based packet filter, list-based packet filter and trust-based packet filter to help filter out target network packets for a signature-based NIDS such as Snort in terms of IP reputation. This packet filter can be deployed in front of a signature-based NIDS and reduce its workload in an intensive traffic network. False alarm reduction. To resolve this issue, we design several false alarm filters such as machine-learning based false alarm filters, alarm filters using knowledge-based alert verification and context-based alarm filters to help reduce false alarms (or non-critical alarms) that are generated by a signature-based NIDS. A Framework. In addition, we further propose a framework by combining the above work to overall improve the performance of a signature-based NIDS such as Snort. As a case study of the framework, we implement an enhanced filter mechanism (shortly EFM) that consists of three major components: a context-aware blacklist-based packet filter, an exclusive signature matching component and a KNN-based false alarm filter. In particular, the component of context-aware blacklist-based packet filter is responsible for filtering out network packets in terms of IP reputation. The exclusive signature matching component is implemented in the context-aware blacklist-based packet filter and aims to speed up the signature matching. At last, the component of KNN-based false alarm filter is responsible for filtering out false alarms which are produced by the context-aware blacklist-based packet filter and the NIDS. In the evaluation, the experimental results demonstrate that our framework is promising and by deploying with the EFM, the performance of a signature-based NIDS such as Snort can be improved in the aspects of network packet filtration, signature matching improvement and false alarm reduction.",,2013,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
4c4731ac80af584457d806d48b27a337d1f740eb,https://www.semanticscholar.org/paper/4c4731ac80af584457d806d48b27a337d1f740eb,Distributed Anomaly Detection and Prevention for Virtual Platforms,"An increasing number of applications are being hosted on cloud based platforms. Cloud platforms are serving as a general computing facility and applications being hosted on these platforms range from simple multi-tier web applications to complex social networking, eCommerce and Big Data applications. High availability, performance and auto-scaling are key requirements of Cloud based applications. Cloud platforms serve these requirements using dynamic provisioning of resources in on-demand, multi-tenant fashion. 
A key challenge for cloud service providers is to ensure the Quality of Service (QoS), as a user / customer requires more explicit guarantees of QoS for provisioning of services. Cloud service performance problems can directly lead to extensive financial loses. Thus, control and verification of QoS become a vital concern for any production level deployment. Therefore, it is crucial to address performance as a managed objective. The success of cloud services depends critically on automated problem diagnostics and predictive analytics enabling organizations to manage their performance proactively. Moreover, effective and advance monitoring is equally important for performance management support in clouds. In this thesis, we explore the key techniques for developing monitoring and performance management systems to achieve robust cloud systems. At first, two case studies are presented as a motivation for the need of a scalable monitoring and analytics framework. It includes a case study on performance issues of a software service, which is hosted on a virtualized platform. In the second case study, cloud services are analyzed that are offered by a large IT service provider. A generalization of case studies forms the basis for the requirement specifications which are used for state-of-the-art analysis. Although, some solutions for particular challenges have already been provided, a scalable approach for performance problem diagnosis and prediction is still missing. For addressing this issue, a distributed scalable monitoring and analytics framework is presented in the first part of this thesis. We conducted a thorough analysis of technologies to be used by our framework. The framework makes use of existing monitoring and analytics technologies. However, we develop custom collectors to retrieve data non-intrusively from different layers of cloud. In addition, we develop the analytics subscriber and publisher components to retrieve service related events from different APIs and sends alerts to the SLA Management component for taking corrective measures. Further, we implemented an Open Cloud Computing Interface (OCCI) monitoring extension using OCCI Mixin mechanism.  
To deal with performance problem diagnosis, a novel distributed parallel approach for performance anomaly detection is presented. First all anomalous metrics are found from a distributed database of time-series for a particular window. For comparative analysis three light-weight statistical anomaly detection techniques are selected. We extend these techniques to work with MapReduce paradigm and assess and compare the methods in terms of precision, recall, execution time, speedup and scale up. Next, we correlate the anomalous metrics with the target SLO in order to locate the suspicious metrics. We implemented and evaluated our approach on a production Cloud encompassing Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) service models. Experimental results confirm that our approach is efficient and effective in capturing the metrics causing performance anomalies. 
Finally, we present the design and implementation of an online anomaly prediction system for cloud computing infrastructures. We further present an experimental evaluation of a set of anomaly prediction methods that aim at predicting upcoming periods of high utilization or poor performance with enough lead time to enable the appropriate scheduling, scaling, and migration of virtual resources. Using real data sets gathered from Cloud platforms of a university data center, we compare several approaches ranging from time-series (e.g. auto regression (AR)) to statistical classification methods (e.g. Bayesian classifier). We observe that linear time-series models, especially AR models, are most likely suitable to model QoS measures and forecast their future values. Moreover, linear time-series models can be integrated with Machine Learning (ML) methods to improve proactive QoS management.",,2015,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,https://www.semanticscholar.org/paper/88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,Human Activity Inference via physical sensing in support of Industrial Equipment Maintenance,"The paper describes an active research project at Intel’s High Volume Manufacturing (HVM) facility located at Leixlip, Co. Kildare, Ireland. The project explores the practical aspects of deploying RFID transponders, subtle sensing platforms and machine learning based inferencing in a harsh, realworld environment. The key features of the sensing platform, the data collection process and the translation of data into information using visualization and inferencing techniques are described.",,2006,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
a5d85748055ff954e38c4c1f24138d614d4323fa,https://www.semanticscholar.org/paper/a5d85748055ff954e38c4c1f24138d614d4323fa,SmartDashCam: Automatic Live Calibration for DashCams,"Dashboard camera installations are becoming increasingly common due to various Advanced Driver Assistance Systems (ADAS) based services provided by them. Though deployed primarily for crash recordings, calibrating these cameras can allow them to measure real-world distances, which can enable a broad spectrum of ADAS applications such as lane-detection, safe driving distance estimation, collision prediction, and collision prevention Today, dashboard camera calibration is a tedious manual process that requires a trained professional who needs to use a known pattern (e.g., chessboard-like) at a calibrated distance. In this paper, we propose SmartDash-Cam, a system for automatic and live calibration of dashboard cameras which always ensures highly accurate calibration values. Smart-DashCam leverages collecting images of a large number of vehicles appearing in front of the camera and using their coarse geometric shapes to derive the calibration parameters. In sharp contrast to the manual process we are proposing the use of a large amount of data and machine learning techniques to arrive at calibration accuracies that are comparable to the manual process. SmartDashCam implemented using commodity dashboard cameras estimates realworld distances with mean errors of 5.7 % which closely rivals the 4.1% mean error obtained from traditional manual calibration using known patterns.",2019 18th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN),2019,10.1145/3302506.3310397,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
972b20f1a231cb991f43b5a8dc99b8892c6a3db9,https://www.semanticscholar.org/paper/972b20f1a231cb991f43b5a8dc99b8892c6a3db9,Stress Detection for Keystroke Dynamics,"Background. Stress can profoundly affect human behavior. Critical-infrastructure operators (e.g., at nuclear power plants) may make more errors when overstressed; malicious insiders may experience stress while engaging in rogue behavior; and chronic stress has deleterious effects on mental and physical health. If stress could be detected unobtrusively, without requiring special equipment, remedies to these situations could be undertaken. In this study a common computer keyboard and everyday typing are the primary instruments for detecting stress. Aim. The goal of this dissertation is to detect stress via keystroke dynamics – the analysis of a user’s typing rhythms – and to detect the changes to those rhythms concomitant with stress. Additionally, we pinpoint markers for stress (e.g., a 10% increase in typing speed), analogous to the antigens used as markers for blood type. We seek markers that are universal across all typists, as well as markers that apply only to groups or clusters of typists, or even only to individual typists. Data. Five types of data were collected from 116 subjects: (1) demographic data, which can reveal factors (e.g., gender) that influence subjects’ reactions to stress; (2) psychological data, which capture a subject’s general susceptibility to stress and anxiety, as well as his/her current stress state; (3) physiological data (e.g., heart-rate variability and blood pressure) that permit an objective and independent assessment of a subject’s stress level; (4) self-report data, consisting of subjective self-reports regarding the subject’s stress, anxiety, and workload levels; and (5) typing data from subjects, in both neutral and stressed states, measured in terms of keystroke timings – hold and latency times – and typographical errors. Differences in typing rhythms between neutral and stressed states were examined to seek specific markers for stress. Method. An ABA, single-subject design was used, in which subjects act as their own controls. Each subject provided 80 typing samples in each of three conditions: (A) baseline/neutral, (B) induced stress, and (A) post-stress return/recovery-to-baseline. Physiological measures were analyzed to ascertain the subject’s stress level when providing each sample. Typing data were analyzed, using a variety of statistical and machine learning techniques, to elucidate markers of stress. Clustering techniques (e.g., K-means) were also employed to detect groups of users whose responses to stress are similar. Results. Our stressor paradigm was effective for all 116 subjects, as confirmed through analysis of physiological and self-report data. We were able to identify markers for stress within each subject; i.e., we can discriminate between neutral and stressed typing when examining any subject individually. However, despite our best attempts, and the use of state-of-the-art machine learning techniques, we were not able to identify universal markers for stress, across subjects, nor were we able to identify clusters of subjects whose stress responses were similar. Subjects’ stress responses, in typing data, appear to be highly individualized. Consequently, effective deployment in a realworld environment may require an approach similar to that taken in personalized medicine.",,2018,10.1184/R1/6723227.V3,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,https://www.semanticscholar.org/paper/4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,Implementing Operational Analytics using Big Data Technologies to Detect and Predict Sensor Anomalies,"Operational analytics when combined with Big Data technologies and predictive techniques have been shown to be valuable in detecting mission critical sensor anomalies that might be missed by conventional analytical techniques. Our approach helps analysts and leaders make informed and rapid decisions by analyzing large volumes of complex data in near real-time and presenting it in a manner that facilitates decision making. It provides cost savings by being able to alert and predict when sensor degradations pass a critical threshold and impact mission operations. Operational analytics, which uses Big Data tools and technologies, can process very large data sets containing a variety of data types to uncover hidden patterns, unknown correlations, and other relevant information. When combined with predictive techniques, it provides a mechanism to monitor and visualize these data sets and provide insight into degradations encountered in large sensor systems such as the space surveillance network. In this study, data from a notional sensor is simulated and we use big data technologies, predictive algorithms and operational analytics to process the data and predict sensor degradations. This study uses data products that would commonly be analyzed at a site. This study builds on a big data architecture that has previously been proven valuable in detecting anomalies. This paper outlines our methodology of implementing an operational analytic solution through data discovery, learning and training of data modeling and predictive techniques, and deployment. Through this methodology, we implement a functional architecture focused on exploring available big data sets and determine practical analytic, visualization, and predictive technologies. APPROACH This study developed an operational analytics implementation that uses Big Data technologies and machine learning algorithms to determine and predict sensor anomalies. A previous study [1] showed that Big Data Analytics can uncover anomalies that may be missed through conventional analyses. This study enhances that effort and shows a methodology to implement operational analytics that can be applied toward common solutions for data analysis. Our operational analytics implementation relies on continuous learning from historical data to analyze data in the stream of real-time operations. In the previous study, where data was identified that can be used to uncover anomalies, this implementation extends that approach and now identifies trends and correlations that reveal anomalies that can be missed by traditional analytic techniques with limited datasets. This study adopted a three-step methodology to implementing operational analytics – Discovery, Modeling and Operations as shown in Fig. 1. Copyright © 2016 Advanced Maui Optical and Space Surveillance Technologies Conference (AMOS) – www.amostech.com Fig. 1. Operational Implementation Approach Fig. 1 shows the three steps to implement operational analytics and the continuous feedback between learning and operational deployment. The following sections will elaborate on the methodology employed as applied to a realworld problem of analyzing large datasets such as would be encountered at an operational site.",,2016,,semantic_scholar,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
