contentType,identifier,title,publicationName,doi,publisher,publicationDate,abstract,url,database,query_name,query_value
Chapter ConferencePaper,doi:10.1007/978-981-19-2065-3_68,Application of Ontologies in the Enterprise—Overview and Critical Analysis,Proceedings of the Third International Conference on Information Management and Machine Intelligence,10.1007/978-981-19-2065-3_68,Springer,2023-01-01,"For many years, it was claimed that semantics should provide foundation of knowledge management in the enterprise. Today, it is easy to realize that this vision did not materialize. The aim of this work is to critically analyse the state of the art of use of semantic technologies in the enterprise and an attempt at diagnosing key problem(s).",http://dx.doi.org/10.1007/978-981-19-2065-3_68,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10209-022-00903-w,A systematic literature review of mobile application usability: addressing the design perspective,Universal Access in the Information Society,10.1007/s10209-022-00903-w,Springer,2022-08-02,"Advances in mobile technologies and wireless Internet services have accelerated the growth of the mobile app market. To nurture such growth, the usability of mobile apps must be addressed as a priority. Indeed, the unique characteristics of mobile phones, such as the screen size, connectivity, processing capabilities, and context of use, require a high level of usability for mobile apps. Mobile app usability requirements vary with the category of the app. However, mobile app usability is not well understood, and this may lead to the ineffective design of mobile apps and may thus influence users’ acceptance of mobile apps. This study systematically reviews and discusses mobile app usability. It identifies and interprets the relationships among the usability principles, attributes, and design features with the objective of informing mobile app usability design. It also identifies and discusses a set of common usability design features in mobile app design and a set of usability design features that are required in specific mobile app categories.",http://dx.doi.org/10.1007/s10209-022-00903-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-022-04844-8,Reconceptualizing cybersecurity awareness capability in the data-driven digital economy,Annals of Operations Research,10.1007/s10479-022-04844-8,Springer,2022-08-02,"Data breaches have become a formidable challenge for business operations in the twenty-first century. The emergence of big data in the ever-growing digital economy has created the necessity to secure critical organizational information. The lack of cybersecurity awareness exposes organizations to potential cyber threats. Thus, this research aims to identify the various dimensions of cybersecurity awareness capabilities. Drawing on the dynamic capabilities framework, the findings of the study show personnel (knowledge, attitude and learning), management (training, culture and strategic orientation) and infrastructure capabilities (technology and data governance) as thematic dimensions to tackle cybersecurity awareness challenges.",http://dx.doi.org/10.1007/s10479-022-04844-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-022-09658-2,"A Contemporary Survey on IoT Based Smart Cities: Architecture, Applications, and Open Issues",Wireless Personal Communications,10.1007/s11277-022-09658-2,Springer,2022-08-01,"Internet of Things (IoT) is one of the emerging technologies, which is widely used across the globe. As the idea of a smart city was founded, IoT has been acknowledged as the key foundation in smart city paradigms. Technology makes a person smart, and to make the world smart, we have to make the country smart. To make the country smart, we have to make cities smart and to make smart cities, we have to be smart. In short, to create a smart environment, one must be equipped and familiar with the current trends. The integration of various smart devices and systems facilitates IoT for a smart city. The interdependent and interwoven nature of smart cities puts notable legislative, socioeconomic, and technical challenges for integrators, organizations, and designers committed to administrating these novel entities. The goal of this paper is to illustrate a contemporary survey of IoT-based smart cities with their potential, current trends and developments, amenity architecture, application area, real-world involvement, and open challenges. In addition, key elements with potential implementation constraints and integration of various IoT-based application areas that play a key role in building a smarter city have also been discussed. This extensive study contributes a useful panorama on various key points and gives a critical direction for forthcoming investigations. This study will also provide a reference point for practitioners and academics in the near future.",http://dx.doi.org/10.1007/s11277-022-09658-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-022-04469-5,On the performance evaluation of object classification models in low altitude aerial data,The Journal of Supercomputing,10.1007/s11227-022-04469-5,Springer,2022-08-01,"This paper compares the classification performance of machine learning classifiers vs. deep learning-based handcrafted models and various pretrained deep networks. The proposed study performs a comprehensive analysis of object classification techniques implemented on low-altitude UAV datasets using various machine and deep learning models. Multiple UAV object classification is performed through widely deployed machine learning-based classifiers such as K nearest neighbor, decision trees, naïve Bayes, random forest, a deep handcrafted model based on convolutional layers, and pretrained deep models. The best result obtained using random forest classifiers on the UAV dataset is 90%. The handcrafted deep model's accuracy score suggests the efficacy of deep models over machine learning-based classifiers in low-altitude aerial images. This model attains 92.48% accuracy, which is a significant improvement over machine learning-based classifiers. Thereafter, we analyze several pretrained deep learning models, such as VGG-D, InceptionV3, DenseNet, Inception-ResNetV4, and Xception. The experimental assessment demonstrates nearly 100% accuracy values using pretrained VGG16- and VGG19-based deep networks. This paper provides a compilation of machine learning-based classifiers and pretrained deep learning models and a comprehensive classification report for the respective performance measures.",http://dx.doi.org/10.1007/s11227-022-04469-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-021-00681-6,Predicting temporary deal success with social media timing signals,Journal of Intelligent Information Systems,10.1007/s10844-021-00681-6,Springer,2022-08-01,"Temporary deals such as flash sales nowadays are popular strategies in retail business for cleaning out excessive inventories. It is known that the success of a temporary deal is related to product quality, promotion, and discount rates. In this paper, we look at another more obscure factor, that is the timing in the market, and we argue that such timing can be learned from social media. For example, the trending of words “summer” and “ice cream” in social media may indicate successful sales of air conditioners. We propose an approach to detect emerging words in social media as timing signals, and associate them with successful temporary deals. More specifically, the words that tend to emerge just before successful deals are considered as effective timing signals. We obtain a real-world temporary deal dataset from an industry partner and collect a social media datasets from Twitter for experiments. With experimental evaluation, we show and discuss the discovered timing signals. Furthermore, we propose a prediction framework and show that using social media timing signals can achieve better accuracy for predicting temporary deal success, comparing to internal deal information.",http://dx.doi.org/10.1007/s10844-021-00681-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-022-07062-3,Analyzing the interactions among factors affecting cloud adoption for software testing: a two-stage ISM-ANN approach,Soft Computing,10.1007/s00500-022-07062-3,Springer,2022-08-01,"To reduce costs and improve organizational efficiency, the adoption of innovative services such as Cloud services is the current trend in today’s highly competitive global business venture. The aim of the study is to guide the software development organization for Cloud-based testing adoption. Therefore, the objective is to develop a two-stage Interpretive Structural Model (ISM) and Artificial Neural Network (ANN)-based approach, for analyzing the factors influencing cloud adoption for software testing. This study first identifies the determinants and predictors of Cloud adoption for software testing through systematic literature (SLR) and empirical survey. Based on the collected data, an ANN was incorporated to weight the nonlinear effect of the predictors. Then, based on the results of empirical survey; a panel of ten experts was selected, to explore the multifaceted interrelationships among the influential factors (IFs) through SM. To provide a concise understanding of the facts, Cross-Impact Matrix Multiplication Applied to the Classification (MICMAC) was used for factors classification. To achieve our objective, through SLR this study identifies 70 IFs. To offer a brief understanding of the issue, we distributed the identified IFs into ten predictors and analyzed their nonlinear effect on the predictors through ANN. Based on the ANN outcomes, the foremost significant independent variable in predicting CCA intention of CC are perceived business concerns (100%), followed by feasibility planning and risk analysis (84.4%), perceived level of trust (76.1%). Finally, the key 44 factors, identified through panel review, were priorities through ISM and were distributed into four Quadrants using MICMAC approach. Some studies in the form of survey have been conducted to examine the IFs affecting CCA. However, no attempt was made to explore the multifaceted interrelationships among them. This study concludes that software testing should be carried out in the Cloud",http://dx.doi.org/10.1007/s00500-022-07062-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07163-y,A fuzzy approach for multi criteria decision making in diet plan ranking system using cuckoo optimization,Neural Computing and Applications,10.1007/s00521-022-07163-y,Springer,2022-08-01,"In recent days, people have easily adapted to unhealthy diets due to their busy lifestyles. Inappropriate and unhealthy food intake leads to various health problems. As a result of poor health and lack of information about a healthy diet, people depend on medicines rather than concentrating on improving their food intake. Due to the wide range of dietary advice, it is difficult to choose the appropriate diet plan that satisfies their personalized nutritional needs. The proposed system ranks the diet plan by considering personal information like age, gender, height, weight, pressure and heart rate. Various diet plans like intermittent fasting, plant-based diets, low-carb diets, paleo diet, low-fat diets, Mediterranean diet, DASH diet, vegan diet, gluten-free diet, GM diet and egg diet are considered. Multi-criteria decision-making methods such as fuzzy AHP and fuzzy TOPSIS are also applied for the decision-making process to rank the best diet plan. Fuzzy AHP is used for weight generation, which is given to the cuckoo algorithm for optimization, and then, the fuzzy TOPSIS method helps in ranking the diet plan. Personal information is considered as criteria, and the diet plans are considered as alternatives for the decision-making process.",http://dx.doi.org/10.1007/s00521-022-07163-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-022-00572-w,"It is not (only) about privacy: How multi-party computation redefines control, trust, and risk in data sharing",Electronic Markets,10.1007/s12525-022-00572-w,Springer,2022-07-30,"Firms are often reluctant to share data because of mistrust, concerns over control, and other risks. Multi-party computation (MPC) is a new technique to compute meaningful insights without having to transfer data. This paper investigates if MPC affects known antecedents for data sharing decisions: control, trust, and risks. Through 23 qualitative interviews in the automotive industry, we find that MPC (1) enables new ways of technology-based control, (2) reduces the need for inter-organizational trust, and (3) prevents losing competitive advantage due to data leakage. However, MPC also creates the need to trust technology and introduces new risks of data misuse. These impacts arise if firms perceive benefits from sharing data, have high organizational readiness, and perceive data as non-sensitive. Our findings show that known antecedents of data sharing should be specified differently with MPC in place. Furthermore, we suggest reframing MPC as a data collaboration technology beyond enhancing privacy.",http://dx.doi.org/10.1007/s12525-022-00572-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40708-022-00164-6,Machine learning-based ABA treatment recommendation and personalization for autism spectrum disorder: an exploratory study,Brain Informatics,10.1186/s40708-022-00164-6,Springer,2022-07-25,"Autism spectrum is a brain development condition that impairs an individual’s capacity to communicate socially and manifests through strict routines and obsessive–compulsive behavior. Applied behavior analysis (ABA) is the gold-standard treatment for autism spectrum disorder (ASD). However, as the number of ASD cases increases, there is a substantial shortage of licensed ABA practitioners, limiting the timely formulation, revision, and implementation of treatment plans and goals. Additionally, the subjectivity of the clinician and a lack of data-driven decision-making affect treatment quality. We address these obstacles by applying two machine learning algorithms to recommend and personalize ABA treatment goals for 29 study participants with ASD. The patient similarity and collaborative filtering methods predicted ABA treatment with an average accuracy of 81–84%, with a normalized discounted cumulative gain of 79–81% (NDCG) compared to clinician-prepared ABA treatment recommendations. Additionally, we assess the two models’ treatment efficacy (TE) by measuring the percentage of recommended treatment goals mastered by the study participants. The proposed treatment recommendation and personalization strategy are generalizable to other intervention methods in addition to ABA and for other brain disorders. This study was registered as a clinical trial on November 5, 2020 with trial registration number CTRI/2020/11/028933.",http://dx.doi.org/10.1186/s40708-022-00164-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-022-10314-0,How to Maximize Clicks for Display Advertisement in Digital Marketing? A Reinforcement Learning Approach,Information Systems Frontiers,10.1007/s10796-022-10314-0,Springer,2022-07-21,"One of the core challenges in digital marketing is that the business conditions continuously change, which impacts the reception of campaigns. A winning campaign strategy can become unfavored over time, while an old strategy can gain new traction. In data driven digital marketing and web analytics, A/B testing is the prevalent method of comparing digital campaigns, choosing the winning ad, and deciding targeting strategy. A/B testing is suitable when testing variations on similar solutions and having one or more metrics that are clear indicators of success or failure. However, when faced with a complex problem or working on future topics, A/B testing fails to deliver and achieving long-term impact from experimentation is demanding and resource intensive. This study proposes a reinforcement learning based model and demonstrates its application to digital marketing campaigns. We argue and validate with actual-world data that reinforcement learning can help overcome some of the critical challenges that A/B testing, and popular Machine Learning methods currently used in digital marketing campaigns face. We demonstrate the effectiveness of the proposed technique on real actual data for a digital marketing campaign collected from a firm.",http://dx.doi.org/10.1007/s10796-022-10314-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10603-022-09522-7,"Rocking the Boat: Loot Boxes in Online Digital Games, the Regulatory Challenge, and the EU’s Unfair Commercial Practices Directive",Journal of Consumer Policy,10.1007/s10603-022-09522-7,Springer,2022-07-21,"The loot box, a feature of online video games, contains randomised virtual items of importance to gameplay. Comparisons are drawn between chance-based loot boxes and the legal and psychological definitions of gambling, leading to concerns that the format may be an unregulated form of quasi-gambling. Globally, several jurisdictions have intervened to control the loot box, some applying national gambling laws, while others have implemented more general rules, an alternative described as “consumer protection”. In 2020, a study commissioned on behalf of the EU Parliament recommended that loot boxes and in-game purchasing systems be regulated from a “consumer protection” perspective. This paper questions firstly whether the debate on product-specific rules for loot box games was conducted in reverse, commencing with a set of potential solutions, while research on harms is still at an early stage. It interrogates the “consumer protection” route, critiquing proposals that borrow from the conceptually and structurally distinct areas of gambling law and consumer protection law, without first resolving the tensions between them. The paper proposes that an alternative paradigm of “player protection” may be the better route towards solving the regulatory puzzle of loot boxes. The paper secondly argues for the EU and its Member States to adopt an interim approach, relying on existing legislation to tackle immediate concerns and facilitate testing of remedial measures, but which leaves the door ajar to alternative options, including regulation under national gambling law frameworks. It examines the UCPD as an immediate solution and considers how the updated UCPD Guidance addresses questions of potentially exploitative game design.",http://dx.doi.org/10.1007/s10603-022-09522-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-022-01711-7,CDARL: a contrastive discriminator-augmented reinforcement learning framework for sequential recommendations,Knowledge and Information Systems,10.1007/s10115-022-01711-7,Springer,2022-07-15,"Sequential recommendations play a crucial role in many real-world applications. Due to the sequential nature, reinforcement learning has been employed to iteratively produce recommendations based on an observed stream of user behavior. In this setting, a recommendation agent interacts with the environments (users) by sequentially recommending items (actions) to maximize users’ overall long-term cumulative rewards. However, most reinforcement learning-based recommendation models only focus on extrinsic rewards based on user feedback, leading to sub-optimal policies if user-item interactions are sparse and fail to obtain the dynamic rewards based on the users’ preferences. As a remedy, we propose a dynamic intrinsic reward signal integrated with a contrastive discriminator-augmented reinforcement learning framework. Concretely, our framework contains two modules: (1) a contrastive learning module is employed to learn the representation of item sequences; (2) an intrinsic reward learning function to imitate the user’s internal dynamics. Furthermore, we combine static extrinsic reward and dynamic intrinsic reward to train a sequential recommender system based on double Q-learning. We integrate our framework with five representative sequential recommendation models. Specifically, our framework augments these recommendation models with two output layers: the supervised layer that applies cross-entropy loss to perform ranking and the other for reinforcement learning. Experimental results on two real-world datasets demonstrate that the proposed framework outperforms several sequential recommendation baselines and exploration with intrinsic reward baselines.",http://dx.doi.org/10.1007/s10115-022-01711-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-022-10229-x,Evaluating conversational recommender systems,Artificial Intelligence Review,10.1007/s10462-022-10229-x,Springer,2022-07-12,"Conversational recommender systems aim to interactively support online users in their information search and decision-making processes in an intuitive way. With the latest advances in voice-controlled devices, natural language processing, and AI in general, such systems received increased attention in recent years. Technically, conversational recommenders are usually complex multi-component applications and often consist of multiple machine learning models and a natural language user interface. Evaluating such a complex system in a holistic way can therefore be challenging, as it requires (i) the assessment of the quality of the different learning components, and (ii) the quality perception of the system as a whole by users. Thus, a mixed methods approach is often required, which may combine objective (computational) and subjective (perception-oriented) evaluation techniques. In this paper, we review common evaluation approaches for conversational recommender systems, identify possible limitations, and outline future directions towards more holistic evaluation practices.",http://dx.doi.org/10.1007/s10462-022-10229-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-022-00558-8,Developing design principles to standardize e-commerce ecosystems,Electronic Markets,10.1007/s12525-022-00558-8,Springer,2022-07-09,"Platform ecosystems have captured a variety of markets, enabling coordination, transactions, and value co-creation between independent actors. A focal platform constitutes the central nexus of e-commerce ecosystems and fosters the interaction among ecosystem participants through their boundary resources. Standardizing these interfaces simplifies ecosystem entry for developers and increases the number of participants propelling the network effects, and thus the overall value of the ecosystem. Currently, there is a lack of prescriptive design knowledge guiding platform owners in designing successful e-commerce ecosystems. Addressing this issue, we followed a dual approach, reporting on a systematic literature review in which we identified design requirements and complemented these with a multiple-case study on selected e-commerce ecosystems. Aggregating the requirements resulted in six meta-requirements and 19 design principles that foster the standardization of focal e-commerce platforms. Our design principles simplify the development of complements and enable multi-homing for developers due to possible standardization across ecosystems.",http://dx.doi.org/10.1007/s12525-022-00558-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-022-09761-4,Machine Learning for Smart Agriculture and Precision Farming: Towards Making the Fields Talk,Archives of Computational Methods in Engineering,10.1007/s11831-022-09761-4,Springer,2022-07-05,"In almost every sector, data-driven business, the digitization of the data has generated a data tsunami. In addition, man-to-machine digital data handling has magnified the information wave by a large magnitude. There has been a pronounced increase in digital applications in agricultural management, which has impinged on information and communication technology (ICT) to provide benefits for both producers and consumers as well as leading to technological solutions being pushed into a rural setting. This paper showcases the potential ICT technologies in traditional agriculture, as well as the issues to be encountered when they are applied to farming practices. The challenges of robotics, IoT devices, and machine learning, as well as the roles of machine learning, artificial intelligence, and sensors used in agriculture, are all described in detail. In addition, drones are under consideration for conducting crop surveillance as well as for managing crop yield optimization. Additionally, whenever appropriate, global and state-of-the-art IoT-based farming systems and platforms are mentioned. We perform a detailed study of the recent literature in each field of our work. From this extensive review, we conclude that the current and future trends of artificial intelligence (AI) and identify current and upcoming research challenges on AI in agriculture.",http://dx.doi.org/10.1007/s11831-022-09761-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-022-04838-6,Deep-learning model using hybrid adaptive trend estimated series for modelling and forecasting sales,Annals of Operations Research,10.1007/s10479-022-04838-6,Springer,2022-07-01,"Existing sales forecasting models are not comprehensive and flexible enough to consider dynamic changes and nonlinearities in sales time-series at the store and product levels. To capture different big data characteristics in sales forecasting data, such as seasonal and trend variations, this study develops a hybrid model combining adaptive trend estimated series (ATES) with a deep neural network model. ATES is first used to model seasonal effects and incorporate holiday, weekend, and marketing effects on sales. The deep neural network model is then proposed to model residuals by capturing complex high-level spatiotemporal features from the data. The proposed hybrid model is equipped with a feature-extraction component that automatically detects the patterns and trends in time-series, which makes the forecasting model robust against noise and time-series length. To validate the proposed hybrid model, a large volume of sales data is processed with a three-dimensional data model to effectively support business decisions at the product-specific store level. To demonstrate the effectiveness of the proposed model, a comparative analysis is performed with several state-of-the-art sales forecasting methods. Here, we show that the proposed hybrid model outperforms existing models for forecasting horizons ranging from one to 12 months.",http://dx.doi.org/10.1007/s10479-022-04838-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07059-x,Deep GraphSAGE-based recommendation system: jumping knowledge connections with ordinal aggregation network,Neural Computing and Applications,10.1007/s00521-022-07059-x,Springer,2022-07-01,"Recommendation systems have become based on graph neural networks (GNN) as many fields, and this is due to the advantages that represent this kind of neural networks compared to the classical ones; notably, the representation of concrete realities by taking the relationships between data into consideration and understanding them in a better way. In this paper, we have proposed an item-based recommender system using a deep GraphSAGE model, which learns item embeddings from the user–item matrix and uses them for recommending items that are similar to the ones that users have interacted with before. Furthermore, we have discussed the common problems that usually arise when using deep GNN-based architectures, and which can negatively affect the performance of our recommender system, in particular, the over-smoothing problem. To this end, we have integrated the Jumping Knowledge connections (JK) strategy in our system, using a new method called Ordinal Aggregation Network (OAN) as a layer aggregator to tackle this kind of problem. To evaluate the recommendations, we have used the required metrics that are designated for this purpose: Hits@n and NDCG@n, and we have also measured the duration of training of every model. The experimental results that we have made show that our method has improved the performance of a recommender system concretely and efficiently compared to other aggregation methods. In addition, they have suggested that deep GraphSAGE with Jumping Knowledge connections (JK) would be empirically promising.",http://dx.doi.org/10.1007/s00521-022-07059-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-022-07178-6,Knowledge transfer learning from multiple user activities to improve personalized recommendation,Soft Computing,10.1007/s00500-022-07178-6,Springer,2022-07-01,"Representation learning has attracted growing attention in recommendation system. In addition, deep learning has been adopted to build a representation generator based on content data (e.g., reviews, descriptions), and has been verified to be an excellent method for recommendation system. However, the content data may not be sufficient to capture the hidden features of user behavior patterns. We argue that the underlying information in behavior patterns can characterize users, by generating specific representation from user activities. In this paper, we propose a deep transfer learning-based recommendation model (DeepTransferR), which conducts knowledge transfer from multiple user activities. We adopt attention network to migrate the behavior pattern from auxiliary activities, and to generate personalized representations for users. In DeepTransferR, we set up an independent predictor for each user activity. We then define a weighted loss function to model knowledge interaction by incorporating the independent loss in each activity predictor. Experiments have been conducted on real-world datasets, and the results show that the proposed model outperforms the state-of-the-art methods in not only recommendation performance, but also convergence and robustness in sparse-data and cold-start environments.",http://dx.doi.org/10.1007/s00500-022-07178-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01496-x,Artificial intelligence and work: a critical review of recent research from the social sciences,AI & SOCIETY,10.1007/s00146-022-01496-x,Springer,2022-06-28,"This review seeks to present a comprehensive picture of recent discussions in the social sciences of the anticipated impact of AI on the world of work. Issues covered include: technological unemployment, algorithmic management, platform work and the politics of AI work. The review identifies the major disciplinary and methodological perspectives on AI’s impact on work, and the obstacles they face in making predictions. Two parameters influencing the development and deployment of AI in the economy are highlighted: the capitalist imperative and nationalistic pressures.",http://dx.doi.org/10.1007/s00146-022-01496-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03646-8,Clustering for smart cities in the internet of things: a review,Cluster Computing,10.1007/s10586-022-03646-8,Springer,2022-06-27,"Nowadays, internet of things (IoT) applications, especially in smart cities, are fast developing. Clustering is a promising solution for handling IoT issues such as energy efficiency, scalability, robustness, mobility, load balancing, and so on. The clustering method, which can be applied in IoT, groups sensor nodes into clusters with one node operating as the cluster head. This paper intends to determine the usage of clustering in IoT as a case study for smart cities. Furthermore, this study discusses clustering algorithms on IoT, open issues, and future challenges of clustering in the context of the smart city, and also existing research papers selected by the systematic literature review technique published between 2017 and 2021. Also, we provide a technical taxonomy for clustering categorization in IoT, which includes algorithm, architecture, and application. According to the statistical analysis of 51 chosen research articles in the domain of clustering in IoT, the results show that the number of clusters has a high percentage of 24%, the energy factor has 23%, the execution time factor has 18%, the accuracy has 14%, the delay has 9%, the lifetime has 6%, and throughput has 6%.",http://dx.doi.org/10.1007/s10586-022-03646-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03644-w,"Federated recommenders: methods, challenges and future",Cluster Computing,10.1007/s10586-022-03644-w,Springer,2022-06-25,"Abstract Web users are flooded with information on the internet, and they feel overwhelmed by the different choices they have to make online daily. Recommender systems come to their rescue by suggesting products best aligned with their interests. To achieve this, traditional recommenders transfer users’ personal data from the client to the server and dig for information about the user’s interests and tastes. Moving data to the cloud violates the user confidentiality requirement and poses severe threats to user privacy and security. Moreover, with the tremendous increase in data size, it is no longer possible to collect and process massive data in the cloud. With the emergence of federated learning, numerous innovative recommender models are devised to solve these issues. In these models, the user data never leaves the client-side, and only the inferred results are sent back to the server for aggregating and updating the master model. Hence, the federated recommenders preserve user privacy and save the hassle of transferring enormous data to the cloud. This paper meticulously studies the recently proposed federated recommenders and classifies them based on the enhancements introduced in the prediction model, security scheme, or optimization technique. We identify the challenges faced by current federated recommenders and observe that most issues are inherently due to various aspects of federated learning, such as heterogeneous and non-IID data, malicious users, distributed framework, and non-reliable edge devices. While some emerge due to the coupling of the recommendation process in the federated paradigm. This research summarizes the current limitations, highlights the areas that need improvements, and presents future paths. In short, it paves the way for the development of robust federated recommenders that can handle the challenges of federated learning and, at the same time, generate high-quality recommendations.",http://dx.doi.org/10.1007/s10586-022-03644-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03807-7,Vote-based integration of review spam detection algorithms,Applied Intelligence,10.1007/s10489-022-03807-7,Springer,2022-06-17,"Due to the growth of online review data, detecting fake or fraudulent reviews is becoming an urgent issue. One barrier to effective detection of fake reviews/reviewers is the great difficulty of collecting ground-truth data—fake reviews are hard to judge, even by human experts. As researchers propose a large number of methods to detect review spam from a variety of perspectives, e.g., text-based or behavior-based, there is a need to combine these methods to improve the overall detection performance. In this paper, we raise the important question of how to integrate multiple ranking lists generated by different types of review spam detection algorithms into an overall ranking list. To address this problem, we propose a novel unsupervised integration model, namely SpamVote , that combines multiple ranking lists together by voting. In view of the diversity of review spam strategies, we model the fitness of a particular algorithm to detect a specific item as latent, and learn the latent variables from the ranking data. Extensive experiments on real-world datasets with various kinds of algorithms show that the integrated ranking list created by SpamVote outperforms the voting lists with a large probability.",http://dx.doi.org/10.1007/s10489-022-03807-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03769-w,GRFlift: uplift modeling for multi-treatment within GMV constraints,Applied Intelligence,10.1007/s10489-022-03769-w,Springer,2022-06-16,"As a primary goal of predictive analytics, uplift modeling is used to estimate what impact a specific action or treatment will have on an outcome. In convention, the treatment is evaluated as a success once the buyer has purchased following the treatment, regardless of the kinds of treatments and the corresponding cost. Obviously, it cannot be classified as a binary classification problem. Therefore, we extend the ordinary uplift model to support multi-treatments tasks. In order to reconcile this aspect of interpretability with tree-based models, we use random forest (RF) as our base model. We present Gross Merchandise Value (GMV)-based RF for uplift modeling ( G R F l i f t ): an uplift model, where typical commercial evaluation GMV is designed as novel tree splitting criteria to directly quantify the uplift achievement. A targeted regularization term is also designed to adjust the splitting distribution differences. The splitting process proposed in the model achieves the goal of maximizing profit while showing the optimal treatment assignment. The performance of our method is confirmed by the industrial data, synthetic data, and observation data. Consequently, distributing different moderate treatments to different users can achieve obvious attraction and avoid unnecessary investment.",http://dx.doi.org/10.1007/s10489-022-03769-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10270-022-01014-z,Semi-automatic service value network modeling approach based on external public data,Software and Systems Modeling,10.1007/s10270-022-01014-z,Springer,2022-06-14,"Various emerging IT technologies are widely used in the service industry. Thus, an increasing number of new service models have also emerged, including the Internet of Services (IoS). The IoS supports network-based service collaboration and transactions among various service participants from different domains and different organizations, and it is expected to deliver the maximum service value to all stakeholders. To describe the cross-domain, cross-organization, and cross-value chain characteristics of the IoS from a value perspective and support subsequent analysis of the value network and optimization of the IoS, this paper proposes a semi-automatic modeling method for a IoS-oriented value network based on external public data. We first propose an intelligent domain entity recognition algorithm based on multidimensional web data to help value network modelers realize effective and efficient recognition of service participants. Then, based on external news data, an intelligent domain relationship extraction algorithm that combines the Bert + BiLSTM + CRF model with the LightGBM model is proposed to effectively and efficiently identify the value exchange relationships among service participants, thereby forming an IoS-oriented value network model (IVN). Finally, to extend the cross-domain semantics of the IVN and support analysis of the IVN, we present a domain-specific value chain extraction algorithm based on typical patterns to complete the cross-domain semantic annotation of the IVN. The effectiveness and efficiency of the proposed methods and algorithms are validated through experimental analysis and a case study, which can be of great help in IVN modeling.",http://dx.doi.org/10.1007/s10270-022-01014-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03681-3,Preference-corrected multimodal graph convolutional recommendation network,Applied Intelligence,10.1007/s10489-022-03681-3,Springer,2022-06-04,"Users purchase goods to form a user-item interaction graph, where goods are usually displayed in multiple modes. The main role of the recommendation system is to obtain users’ preferences after analyzing users’ purchasing behavior. However, there are some deviations in the interaction between users and items. For example, users buy goods they are not interested in, which directly affects the user’s preference analysis. Most existing models do not focus on analyzing and correcting user preference errors in the user-item relationship graph, which leads to errors. There is little work on the multimodal information of commodities, resulting in the loss of information. In this paper, a preference-corrected multimodal graph convolution recommendation network (PMGCRN) is proposed to provide multimodal recommendation services for users. First, a multichannel network is designed to obtain user preference information under different modes. Then, a positive attention mechanism is proposed to deal with the implicit noise edges that do not match users’ interactions in the user-item graph to correct errors in user preferences. Additionally, the simplified graph convolution network acts on the structural information of the user-item bipartite graph as an additional channel to enhance the robustness of the model. Finally, a self-attention mechanism and layer-by-layer superposition are applied to obtain multilevel modal and structural information, respectively, so that valuable information can be obtained by the fusion matrix. Experiments show that our proposed PMGCRN outperforms other baselines on all three datasets, MovieLens, Amazon - Sports and Outdoors, and Douban.",http://dx.doi.org/10.1007/s10489-022-03681-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12599-021-00716-w,The Cost of Fairness in AI: Evidence from E-Commerce,Business & Information Systems Engineering,10.1007/s12599-021-00716-w,Springer,2022-06-01,"Contemporary information systems make widespread use of artificial intelligence (AI). While AI offers various benefits, it can also be subject to systematic errors, whereby people from certain groups (defined by gender, age, or other sensitive attributes) experience disparate outcomes. In many AI applications, disparate outcomes confront businesses and organizations with legal and reputational risks. To address these, technologies for so-called “AI fairness” have been developed, by which AI is adapted such that mathematical constraints for fairness are fulfilled. However, the financial costs of AI fairness are unclear. Therefore, the authors develop AI fairness for a real-world use case from e-commerce, where coupons are allocated according to clickstream sessions. In their setting, the authors find that AI fairness successfully manages to adhere to fairness requirements, while reducing the overall prediction performance only slightly. However, they find that AI fairness also results in an increase in financial cost. Thus, in this way the paper’s findings contribute to designing information systems on the basis of AI fairness.",http://dx.doi.org/10.1007/s12599-021-00716-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1057/s41270-021-00116-9,Trends and patterns in digital marketing research: bibliometric analysis,Journal of Marketing Analytics,10.1057/s41270-021-00116-9,Springer,2022-06-01,"In today’s digital era, the importance of digital marketing has increased from one year to another as a way of providing novel properties for informing, engaging, and selling services and products to clients. The research’s aim is to investigate trends and patterns in the area of digital marketing research from 1979 to June 2020 through a bibliometric analysis technique. A total of 924 articles published were obtained from the Scopus database for the analysis. In this paper, we examine variant bar charts including the year of publication, writer, publication, keyword, and country to provide more insights. Results indicated that digital marketing research steadily increased during the study period and the maximum publications occurred in the year 2019 that reach to 163 documents. The trend of publications is still growing. The top 20 documents based on the times cited per year (TCpY) were qualitatively analyzed. The largest number of multiple (MCP) and single (SCP) publications was from the USA, followed by the UK and China. The top 20 most repeated authors’ keywords out of 1909 with their trends illustrated. The “real-time bidding”, “machine learning”, “big data”, “social media marketing”, and “influencer marketing” are the emerging keywords in the digital Marketing area. This bibliometric study generally provides the whole image of the field and suggests that researchers focus on novel areas to add new findings and knowledge in the literature if they conduct digital marketing research.",http://dx.doi.org/10.1057/s41270-021-00116-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-021-09659-7,A Systematic Literature Review of Blockchain Technology for Smart Villages,Archives of Computational Methods in Engineering,10.1007/s11831-021-09659-7,Springer,2022-06-01,"According to the United Nations, Sustainable Development Goals are framed for improving rural health, hunger, poverty issues, environmental conditions, and illiteracy globally. With the upcoming technology, there have been many advances in the lifestyle of people all around the world. Comparatively, more emphasis has been given to the development of urban areas than rural. The sustainable development of a country depends on the growth of its rural areas. Countless technological and theoretical models, projects, and frameworks have been proposed and implemented to help overcome sundry issues and challenges faced by rural people in quotidian life. New technological methods are deemed to be the future of livability, therefore; a technologically advanced solution for sustainable rural development is called for. Blockchain Technology is the next step for innovation and development and it has far many applications in sustainable rural development that are yet to be discovered. The objective of this paper is to explicitly review research conducted in rural development to fill the undone work in the future with better research ideas, to make rural areas a livable and advanced place while also maintaining their integrity leading to sustainable development. To conduct such a review, a systematic research methodology is applied following regulations in the conduction of standardized but explorative analysis. Within the timeline of 2010–2021, 112 papers are carefully selected to perform the systematic review. This review will provide a comprehensible as well as concise research compendium for all applications proposed, implemented, and possible in the future to realize the concept of smart villages for the development of rural areas using blockchain technology. Graphic Abstract ",http://dx.doi.org/10.1007/s11831-021-09659-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-021-10098-w,"Federated learning attack surface: taxonomy, cyber defences, challenges, and future directions",Artificial Intelligence Review,10.1007/s10462-021-10098-w,Springer,2022-06-01,"Federated learning (FL) has received a great deal of research attention in the context of privacy protection restrictions. By jointly training deep learning models, a variety of training tasks can be competently performed with the help of invited participants. However, FL is concerned with a large number of attacks involving privacy and security aspects. This paper shows a federated learning workflow process and how a malicious client can exploit vulnerabilities in the FL system to attack the system. A systematic survey of existing research on the taxonomy of federated learning attack surface and the classification is presented. As with the FL attack surface, attackers compromise security, privacy, gain free incentives and abuse the Confidentiality, Integrity, and Availability (CIA) security triad. In addition, state-of-the-art defensive approaches against FL attacks are elaborated which help to protect and minimize the likelihood of attacks. FL models and tools for privacy attacks are explained, along with their best aspects and drawbacks. Finally, technical challenges and possible research guidelines are discussed as future work to build robust FL systems.",http://dx.doi.org/10.1007/s10462-021-10098-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11135-021-01177-9,Using text mining algorithms in identifying emerging trends for recommender systems,Quality & Quantity,10.1007/s11135-021-01177-9,Springer,2022-06-01,"Recommendation systems as the main e-commerce tools play an important role in business survival. Therefore, recommender systems and their challenges are a concern for scholars and professionals. Since this kind of system offers appropriate suggestions to online users using their interests and preferences, a lack of information about users and their purchase histories has negative impacts on the performance of recommender systems. This issue is known as “cold start problem” including cold-start user as well as cold start item and occurs when a new user logs in or an item is registered newly in a system. To deal with this problem, a lot of scientists have started studying and have done great researches annually. The first and most important step to optimize recommender systems is to have enough knowledge about previous studies and their proposed methods and algorithms using a review of these researches. Collecting and reading each of these articles is a difficult and time-consuming process. Accordingly, in this paper, we analyze the textual data collected from the best journal articles addressing the challenges of recommender systems to identify new and emerging fields in this area. This research can pave the way for future researchers of this field to develop more and more recommendation systems. The way to conduct this research is to first extract valid scientific articles in the domain of recommender systems challenges from the reputable scientific databases, the web of science. Then, using different text mining algorithms on keywords, titles, and abstracts of these articles, identification of emerging topics in this field is achieved.",http://dx.doi.org/10.1007/s11135-021-01177-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11544-1,A trust-worthy approach to recommend movies for communities,Multimedia Tools and Applications,10.1007/s11042-021-11544-1,Springer,2022-06-01,"Trustworthy recommendation of a movie is a highly complex task for the entertainment industry wherein trust is s a crucial metric of recommendation systems. It depends upon various factors, such as preferences, reviews, emotions, promotions and sentiments. However, these factors are specific to individuals and may vary from person to person. Additionally, the data collected for movie recommendations suffer from data sparsity and cold start problems. Previous studies on movie recommendations have failed to be trustworthy because their performance is greatly affected by fake ratings, data sparsity, and cold start problems. Also, the existing models of Recommender Systems (RS) do not consider the trust score and the user’s rating criterion. Keeping this in view, in this paper, the rating and ranking criteria with a trust score of different users is incorporated into the proposed machine learning-based RS models to ensure the trustworthiness of the system. In particular, one can notice that the most relevant viewers have the same taste and preferences. So, the bipartite relationship between the movie and the viewer has been interpreted through the inversion similarity concept which is used to design an efficient and trustworthy movie recommendation model for a community of viewers. The proposed model uses a learning algorithm to measure the trust score of recommendations and also performs cluster analysis to identify the groups having similar behavior in their communities. The information extracted from the cluster analysis identifies the user’s pattern of movie watching and predicts their movie selection behavior. We have performed extensive experiments to find and compare the performance of the proposed models with other existing models. The results of the experiments demonstrated the better performance of proposed models and supported the claim.",http://dx.doi.org/10.1007/s11042-021-11544-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s42254-022-00441-7,Scientific machine learning benchmarks,Nature Reviews Physics,10.1038/s42254-022-00441-7,Nature,2022-06-01,"Deep learning has transformed the use of machine learning technologies for the analysis of large experimental datasets. In science, such datasets are typically generated by large-scale experimental facilities, and machine learning focuses on the identification of patterns, trends and anomalies to extract meaningful scientific insights from the data. In upcoming experimental facilities, such as the Extreme Photonics Application Centre (EPAC) in the UK or the international Square Kilometre Array (SKA), the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis. However, at present, identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is a challenge due to the potential applicability of many different machine learning frameworks, computer architectures and machine learning models. Historically, for modelling and simulation on high-performance computing systems, these issues have been addressed through benchmarking computer applications, algorithms and architectures. Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to open, curated scientific datasets is a new challenge for both scientists and computer scientists. Here, we introduce the concept of machine learning benchmarks for science and review existing approaches. As an example, we describe the SciMLBench suite of scientific machine learning benchmarks. Finding the most appropriate machine learning algorithm for the analysis of any given scientific dataset is currently challenging, but new machine learning benchmarks for science are being developed to help.",http://dx.doi.org/10.1038/s42254-022-00441-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13198-021-01484-2,Classification of limb movements using different predictive analysis algorithms,International Journal of System Assurance Engineering and Management,10.1007/s13198-021-01484-2,Springer,2022-06-01,"Monitoring and preventing diseases and infections are a significant challenge in the current state of our healthcare systems, given how it affects the patient mortality rates. Data analysis can aid in promoting these activities by recognizing risk factors and predicting the occurrence of any disease or infection. Predictive analysis algorithms provide useful tools for processing and analyzing the data. Furthermore, analyzing the body movements can assist in administering various rehabilitation processes and help regain the damaged or deteriorated motor skills of human beings. In this work, with the use of the Scatter Parameters (S 11 and S 21 ), we can identify the different human hand movements which are used in the kinesiotherapy process. For this work, a dataset is used, where the Transmission and Reflection coefficients of on-body Wireless Body Area Network (WBAN) antennas for each hand movement are depicted to exhibit unique channel functionalities with respect to frequency. This work focuses on the study of the classification of different limb movements by means of different predictive analysis algorithms. The goal of this work is to analyze and compare the results of these different predictive models to find the most accurate model for the purpose of classification. The classification accuracy of human hand movements comes out to be 85% when classifying using S 11 parameters, and an accuracy of 99% when classifying using S 21 parameters.",http://dx.doi.org/10.1007/s13198-021-01484-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02922-1,Discovery of closed high utility itemsets using a fast nature-inspired ant colony algorithm,Applied Intelligence,10.1007/s10489-021-02922-1,Springer,2022-06-01,"Mining high utility itemset (HUIM) from an extensive database is a crucial descriptive task in data mining, which considers both the quantity and unit profit factor in revealing the ultimately profitable items. However, it may discover a vast number of HUIs which can be challenging to interpret by a user and also reduce the efficiency of the mining process. A solution to this problem is to mine a Closed high utility itemset, a more compact and lossless form of HUIs. In this paper, a fast nature-inspired meta-heuristic approach CHUI-AC (Closed high utility itemset mining using ant colony algorithm) has been introduced to mine CHUIs. This is the first work on mining CHUI using a nature-inspired ant colony algorithm. CHUI-AC maps the feasible solution space to a directed graph with quadratic space complexity to guide the searching efficiently. Several experiments on real-world datasets show that the proposed algorithm outrun the state-of-the-art algorithms in terms of execution time and rate of convergence. Moreover, the scalability experiments demonstrate that CHUI-AC is linearly scalable with respect to the number of transaction and number of items.",http://dx.doi.org/10.1007/s10489-021-02922-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03572-9,Dynamic QoS/QoE-aware reliable service composition framework for edge intelligence,Cluster Computing,10.1007/s10586-022-03572-9,Springer,2022-06-01,"Edge intelligence has become popular recently since it brings smartness and copes with some shortcomings of conventional technologies such as cloud computing, Internet of Things (IoT), and centralized AI adoptions. However, although utilizing edge intelligence contributes to providing smart systems such as automated driving systems, smart cities, and connected healthcare systems, it is not free from limitations. There exist various challenges in integrating AI and edge computing, one of which is addressed in this paper. Our main focus is to handle the adoption of AI methods on resource-constrained edge devices. In this regard, we introduce the concept of Edge devices as a Service (EdaaS) and propose a quality of service (QoS) and quality of experience (QoE)-aware dynamic and reliable framework for AI subtasks composition. The proposed framework is evaluated utilizing three well-known meta-heuristics in terms of various metrics for a connected healthcare application scenario. The experimental results confirm the applicability of the proposed framework. Moreover, the results reveal that black widow optimization (BWO) can handle the issue more efficiently compared to particle swarm optimization (PSO) and simulated annealing (SA). The overall efficiency of BWO over PSO is 95%, and BWO outperforms SA with 100% efficiency. It means that BWO prevails SA and PSO in all and 95% of the experiments, respectively.",http://dx.doi.org/10.1007/s10586-022-03572-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42786-021-00036-3,Casper: a blockchain-based system for efficient and secure customer credential verification,Journal of Banking and Financial Technology,10.1007/s42786-021-00036-3,Springer,2022-06-01,"Customer credential verification is an ongoing activity at financial institutions. Know Your Customer is one such periodic verification activity. Often, organizations store the collected customer credentials on centralized storage platforms (e.g., cloud storage and central servers) which could result in major privacy breaches. In addition, when a customer has accounts at multiple institutions, this process is repeated at each of the institutions, resulting in wasted resources and inconvenience to the customer. In this paper, we describe Casper, a blockchain and self-sovereign identity-based digital identity platform, to address these issues. Unlike traditional identity systems, here the actual identity credentials of customers are stored on their own mobile wallet applications. The system only stores the proofs of the credentials on its blockchain-based decentralized storage system. Casper employs Zero-Knowledge Proof mechanisms to verify the identity information from the credential proofs. As a proof of concept, we have employed Casper in a banking environment. Preliminary evaluation studies show the system to be scalable and being capable of yielding high transaction throughput.",http://dx.doi.org/10.1007/s42786-021-00036-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-022-09569-1,Blockchain for sustainable supply chain management: trends and ways forward,Electronic Commerce Research,10.1007/s10660-022-09569-1,Springer,2022-05-27,"Blockchain operates on a highly secured framework, and its decentralized consensus has benefits for supply chain sustainability. Scholars have recognized the growing importance of sustainability in supply chains and studied the potential of blockchain for sustainable supply chain management. However, no study has taken stock of high-quality research in this area. To address this gap, this paper aims to provide a state-of-the-art overview of high-quality research on blockchain for sustainable supply chain management. To do so, this paper conducts a systematic literature review using a bibliometric analysis of 146 high-quality articles on blockchain for sustainable supply chain management that have been published in journals ranked “A*”, “A”, and “B” by the Australian Business Deans Council and retrieved from the Scopus database. In doing so, this paper unpacks the most prominent journals, authors, institutions, and countries that have contributed to three major themes in the field, namely blockchain for sustainable business activities, decision support systems using blockchain, and blockchain for intelligent transportation system. This paper also reveals the use of blockchain for sustainable supply chain management across four major sectors, namely food, healthcare, manufacturing, and infrastructure, and concludes with suggestions for future research in each sector.",http://dx.doi.org/10.1007/s10660-022-09569-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-022-00873-8,The effect of marketing department power on investor responses to announcements of AI-embedded new product innovations,Journal of the Academy of Marketing Science,10.1007/s11747-022-00873-8,Springer,2022-05-23,"Even as more companies integrate artificial intelligence (AI) into their new products and services, little research outlines the strategic implications of such AI adoption. Therefore, the present study investigates how investors respond to announcements of new product innovations integrated with AI by non-software firms (AI-NPIs), with the prediction that they respond favorably if the firms feature a marketing department with substantial power; such firms likely possess the marketing resources and assets needed to ensure the success of AI-NPIs. An event study with a sample of 341 announcements by 77 S&P 500 firms between 2009–2018 supports this prediction. Furthermore, the relationship between marketing department power and investor response intensifies when the announcement (1) occurs in later innovation stages, (2) involves the sourcing of external innovation assets, and (3) refers to more complex innovations. These findings have both theoretical and managerial implications.",http://dx.doi.org/10.1007/s11747-022-00873-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07289-z,Information flow-based second-order cone programming model for big data using rough concept lattice,Neural Computing and Applications,10.1007/s00521-022-07289-z,Springer,2022-05-11,"The purpose of this paper is to study the rough concept lattice and use the information flow to construct a second-order cone programming model for big data. Through the construction of the model, attribute reduction is performed on the original data of the noise in the formal background. Then, construct the concept lattice according to the reduced formal background, and then analyze the big data in the form of information flow. Then, based on the advantages of the β-upper and lower distribution reduction algorithms of the variable-precision rough set, combine the rough concept. The characteristics of the background of the lattice form, the second-order cone thought method theory is applied, and then a second-order cone calculation model is constructed. The rough concept lattice is applied to the processing of big data, and then it is analyzed and researched through concrete examples. The time required in traditional mode is between 118.3 min and 123.6 min, while the time required for second-order cone and concept lattice fitting is 92.4 min and 98.5 min. Experimental data show that the rough concept lattice uses information flow to construct a second-order cone programming model for big data, which results in a greatly reduced number of nodes in the rough concept lattice and an enhanced anti-noise capability of the system, which saves data statistics and calculation time. The traditional concept lattice algorithm can be traced back to the purification of the formal background, and the purification of the formal background can simplify the concept connotation and study attribute reduction from the perspective of lattice isomorphism. Experimental data show that the rough concept lattice uses information flow to construct a second-order cone programming model for big data, which greatly guarantees the integrity and security of the data by about 15%, and saves 20% of the data processing time compared with traditional and algorithms. It has guiding significance for the efficient and secure development of big data in the future. In this paper, data feature mining and information flow model construction are carried out, the power spectral density feature extraction of big data is carried out from a large number of noisy and fuzzy data, and the second-order cone programming model of big data information flow is carried out by rough concept lattice method.",http://dx.doi.org/10.1007/s00521-022-07289-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03585-4,An enhanced smart card and dynamic ID based remote multi-server user authentication scheme,Cluster Computing,10.1007/s10586-022-03585-4,Springer,2022-05-11,"Organizations often use smart card-based user authentication for remote access. The research community has put forward dynamic identity based remote user authentication schemes for distributed multi-server environment to safeguard the connection between user and server. Recently, Qiu et al. proposed an efficient smart card based remote user authentication scheme for the multi-server environment, in which they uphold their scheme provides mutual authentication and key agreement, user-anonymity, resistance against various kind of attacks. This paper will manifest that if the adversary is successful in stealing a smart card, then their schemes are vulnerable to masquerade attack, server spoofing attack, and password guessing attack. We overcome their flaws and propose an enhanced anonymous scheme where whenever the user wants to log into a server, the user identity is changed dynamically before login. And also, the scheme resists all possible attacks. We compared our scheme with respect to the related scheme, used BAN logic for verification of correctness of mutual key agreement and AVISPA to prove scheme is safe. We have provided formal security proofs for our scheme.",http://dx.doi.org/10.1007/s10586-022-03585-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-022-04484-6,An efficient system using implicit feedback and lifelong learning approach to improve recommendation,The Journal of Supercomputing,10.1007/s11227-022-04484-6,Springer,2022-05-06,"This paper presents a new technique for contextual item-to-item Collaborative Filtering-based Recommender System, an improved version popularised by e-commerce giant Amazon two decades back. The concept is based on items also-viewed under the same browsing session. Users’ browsing patterns, locations, and timestamps are considered as the context and latent factors for each user. The algorithm computes recommendations based on users’ implicit endorsements by clicks . The algorithm does not enforce the user to log in to provide recommendations and is capable of providing accurate recommendations for non-logged-in users and with a setting where the system is unaware of users’ preferences and profile data (non-logged-in users). This research takes the cue from human lifelong incremental learning experience applied to machine learning on a large volume of the data pool. First, all historical data is gathered from collectable sources in a distributed manner through big data tools. Then, a long-running batch job creates the initial model and saves it to Hadoop Distributed File System (HDFS). An ever-running streaming job loads the model from HDFS and builds on top of it in an incremental fashion. At the architectural level, this resembles the big data mix processing Lambda Architecture . The recommendation is computed based on a proposed equation for a weighted sum between near real-time and historical batch data. Real-time and batch processing engines act as autonomous Multi-agent systems in collaboration. We propose an ensemble method for batch-stream the recommendation engine. We introduce a novel Lifelong Learning Model for recommendation through Multi-agent Lambda Architecture. The recommender system incrementally updates its model on streaming datasets to improve over time.",http://dx.doi.org/10.1007/s11227-022-04484-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1057/s41264-022-00161-0,The transformative potential of banking service domains with the emergence of FinTechs,Journal of Financial Services Marketing,10.1057/s41264-022-00161-0,Springer,2022-05-05,"Most activities of FinTech companies in the real world are limited to a variety of banking services such as payment and funds transfer, while the scope of banking services is much broader than the current activities of FinTech companies. In recent years, extensive research has also been conducted on how FinTech companies contribute to the provision of banking services. The present study identifies ideas for new and innovative areas of FinTech companies’ activity by reviewing the relevant literature. These areas are categorized using the Banking Industry Architecture Network (BIAN) service landscape and are identified and described through thematic analysis. The outcome of this study is a model which reveals that the main service domains belong to the “banking operations and execution,” “sales and services,” “risk and compliance,” “business support,” and “reference data.” According to the findings of the present research, FinTech companies have the capability to provide banking services in 22 domains out of 36 BIAN domains. Theoretical contributions and comparative analysis are discussed.",http://dx.doi.org/10.1057/s41264-022-00161-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-022-04689-1,"Smart supply chain management in Industry 4.0: the review, research agenda and strategies in North America",Annals of Operations Research,10.1007/s10479-022-04689-1,Springer,2022-05-02,"The emerging information and communication technologies (ICT) related to Industry 4.0 play a critical role to enhance supply chain performance. Employing the smart technologies has led to so-called smart supply chains. Understanding how Industry 4.0 and related ICT affect smart supply chains and how smart supply chains evolve with the support of the advanced technologies are vital to practical and academic communities. Existing review works on smart supply chains with ICT mainly rely on the academic literature alone. This paper presents an integrated approach to explore the effects of Industry 4.0 and related ICT on smart supply chains, by combining introduction of the current national strategies in North America, the research status analysis on ICT assisted supply chains from the major North American national research councils, and a systematic literature review of the subject. Besides, we introduce a smart supply chain hierarchical framework with multi-level intelligence. Furthermore, the challenges faced by supply chains under Industry 4.0 and future research directions are discussed as well.",http://dx.doi.org/10.1007/s10479-022-04689-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07251-z,Heterogeneous graph convolutional network pre-training as side information for improving recommendation,Neural Computing and Applications,10.1007/s00521-022-07251-z,Springer,2022-05-02,"For the recommendation domain, most of the existing integrated graph neural network (GNN)-based architectures have still much focused on encoding the associated extra side information in forms of heterogeneous information network (HIN). Then, it is simultaneously utilized in multiple fine-tuning processes to effectively learn preferences from user–item interaction data which might require tremendous computational efforts. In addition, these approaches have also failed to incorporate with previous learnt and transferable knowledge from pre-trained models to better fine-tune for recommendation task. To meet these challenges, in this paper we propose a novel heterogeneous graph neural architecture, named: PreHIN4Rec. The proposed PreHIN4Rec is considered as the graph pre-training approach for leveraging the performance of recommendation task in both accuracy and scalability aspects. In general, our proposed PreHIN4Rec is designed to efficiently preserve both heterogeneous schematic and local structural latent features of user–item interactions in forms of HINs. It can effectively support to better fine-tune for achieving remarkable improvements in recommendation tasks through integrating with existing recommendation frameworks. The extensive experiments in benchmark datasets demonstrate the effectiveness of our proposed PreHIN4Rec model in comparing with recent state-of-the-art GNN-based recommendation baselines.",http://dx.doi.org/10.1007/s00521-022-07251-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-022-08761-9,Towards big industrial data mining through explainable automated machine learning,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-022-08761-9,Springer,2022-05-01,"Industrial systems resources are capable of producing large amount of data. These data are often in heterogeneous formats and distributed, yet they provide means to mine the information which can allow the deployment of intelligent management tools for production activities. For this purpose, it is necessary to be able to implement knowledge extraction and prediction processes using Artificial Intelligence (AI) models, but the selection and configuration of intended AI models tend to be increasingly complex for a non-expert user. In this paper, we present an approach and a software platform that may allow industrial actors, who are usually not familiar with AI, to select and configure algorithms optimally adapted to their needs. Hence, the approach is essentially based on automated machine learning. The resulting platform effectively enables a better choice among the combination of AI algorithms and hyper-parameters configurations. It also makes it possible to provide features of explainability of the resulting algorithms and models, thus increasing the acceptability of these models in practicing community of the users. The proposed approach has been applied in the field of predictive maintenance. Current tests are based on the analysis of more than 360 databases from the subjected field.",http://dx.doi.org/10.1007/s00170-022-08761-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-022-01031-4,SSLE: A framework for evaluating the “Filter Bubble” effect on the news aggregator and recommenders,World Wide Web,10.1007/s11280-022-01031-4,Springer,2022-05-01,"Recommendation algorithms are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user. The algorithm-driven recommenders become indispensable and supersede search engines as the most important information dissemination channel. On one hand, it becomes an integral component in the existing social media, e.g. Weibo, Twitter, etc. On the other hand, news aggregators and recommenders have proliferated and gained an increasing market share. As a result, the previous studies usually study the “filter bubbles” phenomenon in the context where the social filtering dominates the dissemination of information. However, less attention is paid to the news aggregators and recommenders where algorithm-driven technological filtering dominates. Therefore, in the previous research, “filter bubbles” are usually equated with the community structure, but lack of the detailed analysis of the content agglomeration through the users’ interaction with the platforms. Based on these concerns, we propose a four-phase (“Selection”, “Setup”, “Link”, and “Evaluation”) skeletal solution framework targeted at exploiting the filter bubble effect of the personalized news aggregation and recommendation system. Furthermore, we illustrate the effectiveness of the proposed framework with a case study in three top Chinese news aggregators, i.e. Toutiao, Baidu News, and Tencent News. The results show that the users are narrowed into one or a limited number of topics over time. The phenomenon of the narrowed topics is deemed as the emergence of the “filter bubbles”. We also observe that the filter bubbles demonstrate different convergence degrees as user’s individual preference varies.",http://dx.doi.org/10.1007/s11280-022-01031-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40537-022-00603-5,NLP-based platform as a service: a brief review,Journal of Big Data,10.1186/s40537-022-00603-5,Springer,2022-04-28,"Natural language processing (NLP) refers to the field of study that focuses on the interactions between human language and computers. It has recently gained much attention for analyzing human language computationally and has spread its applications for various tasks such as machine translation, information extraction, summarization, question answering, and others. With the rapid growth of cloud computing services, merging NLP in the cloud is a significant benefit. It allows researchers to conduct NLP-related experiments on large amounts of data handled by big data techniques while harnessing the cloud’s vast, on-demand computing power. However, it has not sufficiently spread its tools and applications as a service in the cloud and there is little literature available that discusses the scope of interdisciplinary work. NLP, cloud Computing, and big data are vast domains and contain their challenges and potentials. By overcoming those challenges and integrating these fields, great potential for NLP and its applications can be unleashed. This paper presents a survey of NLP in cloud computing with a key focus on the comparison of cloud-based NLP services, challenges of NLP and big data while emphasizing the necessity of viable cloud-based NLP services. In the first part of this paper, an overview of NLP is presented by discussing different levels of NLP and components of natural language generation (NLG), followed by the applications of NLP. In the second part, the concept of cloud computing is discussed that highlights the architectural layers and deployment models of cloud computing and cloud-hosted NLP services. In the third part, the field of big data in the cloud is discussed with an emphasis on NLP. Furthermore, information extraction via NLP techniques within big data is introduced.",http://dx.doi.org/10.1186/s40537-022-00603-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10723-022-09603-4,Scalable Virtual Machine Migration using Reinforcement Learning,Journal of Grid Computing,10.1007/s10723-022-09603-4,Springer,2022-04-28,"Heuristic approaches require fixed knowledge of how resource allocation should be carried out, and this can be limiting when managing variable cloud workloads. Solutions based on Reinforcement Learning (RL) have been presented to manage cloud infrastructure, however, these tend to be centralized and suffer in their ability to maintain Quality of Service (QoS) for data centres with thousands of nodes. To address this, we propose a reinforcement learning management policy, which can run decentralized, and achieve fast convergence towards efficient resource allocation, resulting in lower SLA violations compared to centralized architectures. To address some of the common challenges in applying RL to cloud resource management, such as slow learning and state/action management, we use parallel learning and reduction of the state/action space. We apply a decision making approach to optimize the migration of a VM and choose a target node to host the VM in such a way that brings response time within SLA level. We have also demonstrate unique, multi-level reinforcement learning cooperation, that further reduces SLA violations. We use simulation to evaluate and demonstrate our proposal in practice, and compare the results obtained with an established heuristic, demonstrating significant improvement to SLA violations and higher scalability.",http://dx.doi.org/10.1007/s10723-022-09603-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-022-00698-5,Approaches and algorithms to mitigate cold start problems in recommender systems: a systematic literature review,Journal of Intelligent Information Systems,10.1007/s10844-022-00698-5,Springer,2022-04-23,"Cold Start problems in recommender systems pose various challenges in the adoption and use of recommender systems, especially for new item uptake and new user engagement. This restricts organizations to realize the business value of recommender systems as they have to incur marketing and operations costs to engage new users and promote new items. Owing to this, several studies have been done by recommender systems researchers to address the cold start problems. However, there has been very limited recent research done on collating these approaches and algorithms. To address this gap, the paper conducts a systematic literature review of various strategies and approaches proposed by researchers in the last decade, from January 2010 to December 2021, and synthesizes the same into two categories: data-driven strategies and approach-driven strategies. Furthermore, the approach-driven strategies are categorized into five main clusters based on deep learning, matrix factorization, hybrid approaches, or other novel approaches in collaborative filtering and content-based algorithms. The scope of this study is limited to a systematic literature review and it does not include an experimental study to benchmark and recommend the best approaches and their context of use in cold start scenarios.",http://dx.doi.org/10.1007/s10844-022-00698-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-022-00698-5,Approaches and algorithms to mitigate cold start problems in recommender systems: a systematic literature review,Journal of Intelligent Information Systems,10.1007/s10844-022-00698-5,Springer,2022-04-23,"Cold Start problems in recommender systems pose various challenges in the adoption and use of recommender systems, especially for new item uptake and new user engagement. This restricts organizations to realize the business value of recommender systems as they have to incur marketing and operations costs to engage new users and promote new items. Owing to this, several studies have been done by recommender systems researchers to address the cold start problems. However, there has been very limited recent research done on collating these approaches and algorithms. To address this gap, the paper conducts a systematic literature review of various strategies and approaches proposed by researchers in the last decade, from January 2010 to December 2021, and synthesizes the same into two categories: data-driven strategies and approach-driven strategies. Furthermore, the approach-driven strategies are categorized into five main clusters based on deep learning, matrix factorization, hybrid approaches, or other novel approaches in collaborative filtering and content-based algorithms. The scope of this study is limited to a systematic literature review and it does not include an experimental study to benchmark and recommend the best approaches and their context of use in cold start scenarios.",http://dx.doi.org/10.1007/s10844-022-00698-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-022-10188-3,"Deep Neuro-Fuzzy System application trends, challenges, and future perspectives: a systematic survey",Artificial Intelligence Review,10.1007/s10462-022-10188-3,Springer,2022-04-13,"Deep neural networks (DNN) have remarkably progressed in applications involving large and complex datasets but have been criticized as a black-box. This downside has recently become a motivation for the research community to pursue the ideas of hybrid approaches, resulting in novel hybrid systems classified as deep neuro-fuzzy systems (DNFS). Studies regarding the implementation of DNFS have rapidly increased in the domains of computing, healthcare, transportation, and finance with high interpretability and reasonable accuracy. However, relatively few survey studies have been found in the literature to provide a comprehensive insight into this domain. Therefore, this study aims to perform a systematic review to evaluate the current progress, trends, arising issues, research gaps, challenges, and future scope related to DNFS studies. A study mapping process was prepared to guide a systematic search for publications related to DNFS published between 2015 and 2020 using five established scientific directories. As a result, a total of 105 studies were identified and critically analyzed to address research questions with the objectives: (i) to understand the concept of DNFS; (ii) to find out DNFS optimization methods; (iii) to visualize the intensity of work carried out in DNFS domain; and (iv) to highlight DNFS application subjects and domains. We believe that this study provides up-to-date guidance for future research in the DNFS domain, allowing for more effective advancement in techniques and processes. The analysis made in this review proves that DNFS-based research is actively growing with a substantial implementation and application scope in the future.",http://dx.doi.org/10.1007/s10462-022-10188-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01437-8,Dismantling AI capitalism: the commons as an alternative to the power concentration of Big Tech,AI & SOCIETY,10.1007/s00146-022-01437-8,Springer,2022-04-09,"This article discusses the political economy of AI capitalism. It considers AI as a General Purpose Technology (GPT) and argues we need to investigate the power concentration of Big Tech. AI capitalism is characterised by the commodification of data, data extraction and a concentration in hiring of AI talent and compute capacity. This is behind Big Tech’s unstoppable drive for growth, which leads to monopolisation and enclosure under the winner takes all principle. If we consider AI as a GPT—technologies that alter society’s economic and social structures—we need to come up with alternatives in terms of ownership and governance. The commons is proposed as an alternative for thinking about how to organise AI development and how to distribute the value that can be derived from it. Using the commons framework is also a way of giving society a more prominent role in the debate about what we expect from AI and how we should approach it.",http://dx.doi.org/10.1007/s00146-022-01437-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-022-06160-5,Heterogeneous graph embedding with single-level aggregation and infomax encoding,Machine Learning,10.1007/s10994-022-06160-5,Springer,2022-04-05,"There has been an increasing interest in developing embedding methods for heterogeneous graph-structured data. The state-of-the-art approaches often adopt a bi-level aggregation scheme, where the first level aggregates information of neighbors belonging to the same type or group, and the second level employs the averaging or attention mechanism to aggregate the outputs of the first level. We find that bi-level aggregation may suffer from a down-weighting issue and overlook individual node information, especially when there is an imbalance in the number of different typed relations. We develop a new simple yet effective single-level aggregation scheme with infomax encoding, named HIME, for unsupervised heterogeneous graph embedding. Our single-level aggregation scheme performs relation-specific transformation to obtain homogeneous embeddings before aggregating information from multiple typed neighbors. Thus, it emphasizes each neighbor’s equal contribution and does not suffer from the down-weighting issue. Extensive experiments demonstrate that HIME consistently outperforms the state-of-the-art approaches in link prediction, node classification, and node clustering tasks.",http://dx.doi.org/10.1007/s10994-022-06160-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10798-020-09638-2,A computational model for subjective evaluation of novelty in descriptive aptitude,International Journal of Technology and Design Education,10.1007/s10798-020-09638-2,Springer,2022-04-01,"Evaluating novelty in design education is subjective and generally depends on expert’s referential metrics. Presently, practitioners in this field perform subjective evaluation of answers of prospective students, but many a time, humans are prone to errors when associated with repetitive tasks on large-scale. Therefore, this paper attempts to automate the process of evaluating novelty by a proposed computational model. The present study explores design aptitude to evaluate novelty in solutions provided by students in an examination. Mixed-methods research is conducted based on structured questionnaire and analysis to investigate features of subjective evaluation of novelty practiced for evaluation in design education. The survey resulted in features that closely resemble human evaluation strategies for evaluating novelty from descriptive solutions. Further, a computational model is proposed, designed, and implemented that evaluates novelty. Scores are generated for each feature by unsupervised learning techniques, eventually calculating novelty score by a scoring function. This model suggests unambiguous scores to solutions, which might help in a consistent selection of students aspiring admission to design schools. This study attempts to reduce pain points of educational practitioners by offering a voluntary automated technique for subjective evaluation and optimize trustworthiness of students in examination process. In future, this model can be extended for evaluating any other domain of interest.",http://dx.doi.org/10.1007/s10798-020-09638-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40319-022-01177-8,Pricing Algorithms as Collusive Devices,IIC - International Review of Intellectual Property and Competition Law,10.1007/s40319-022-01177-8,Springer,2022-04-01,"This article undertakes a critical review of the prospect that reinforced-learning, or more loosely described machine-based, pricing algorithms will lead to widespread collusion without human involvement. There is no evidence, no antitrust case, and no strong theoretical and practical reasons for this belief. Notwithstanding this dearth of evidence, legal commentators continue to insist that algorithmic collusion poses a significant threat and that there is a “gap” in antitrust laws that needs to be filled. However, a reasonable assessment suggests that EU antitrust law and its enforcement are adaptable enough to deal with the cases that may arise.",http://dx.doi.org/10.1007/s40319-022-01177-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03512-z,Task scheduling algorithms for energy optimization in cloud environment: a comprehensive review,Cluster Computing,10.1007/s10586-021-03512-z,Springer,2022-04-01,"Cloud computing is very popular because of its unique features such as scalability, elasticity, on-demand service, and security. A large number of tasks are performed simultaneously in a cloud system, and an effective task scheduler is needed to achieve better efficiency of the cloud system. Task scheduling algorithm should determine a sequence of execution of tasks to meet the requirements of the user in terms of Quality of Service (QoS) factors (e.g., execution time and cost). The key issue in recent task scheduling is energy efficiency since it reduces cost and satisfies the standard parameter in green computing. The most important aim of this paper is a comparative analysis of 67 scheduling methods in the cloud system to minimize energy consumption during task scheduling. This work allows the reader to choose the right scheduling algorithm that optimizes energy properly, given the existing problems and limitations. In addition, we have divided the algorithms into three categories: heuristic-based task scheduling, meta-heuristic-based task scheduling, and other task scheduling algorithms. The advantages and disadvantages of the proposed algorithms are also described, and finally, future research areas and further developments in this field are presented.",http://dx.doi.org/10.1007/s10586-021-03512-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-021-09288-0,Journey of Artificial Intelligence,Wireless Personal Communications,10.1007/s11277-021-09288-0,Springer,2022-04-01,"Everywhere we look today, we observe Artificial Intelligence (AI), but this has not always been the case. Even though the applications of AI have become mainline during the last decades, it has quite an interesting history and has not been called AI until in the 1950s. Long before, already in the 17th century some mathematicians and natural philosophers started discussing about automating the process of thinking. Since then, these ideas grew slowly and were considered quite controversial. With the introduction of computers in the previous century, more people began to look into the ideas of automating thinking. Since then the AI field has seen various ups and downs, but as recent as the beginning of this century there has been a huge increase in interest due to the availability of a lot of metadata. This paper presents the most important achievements of AI from the beginning till now.",http://dx.doi.org/10.1007/s11277-021-09288-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-021-09308-z,Decades of Internet of Things Towards Twenty-first Century: A Research-Based Introspective,Wireless Personal Communications,10.1007/s11277-021-09308-z,Springer,2022-04-01,"Internet connects people to people, people to machine, and machine to machine for a life of serendipity through a Cloud. Internet of Things networks objects or people and integrates them with software to collect and exchange data. The Internet of things (IoT) influences our lives based on how we ruminate, respond, and anticipate. IoT 2021 heralds from the fringes to the data ecosystem and panaches a comfort zone. IoT is overwhelmingly embraced by businessmen and consumers due to increased productivity and convenience. Internet of Things facilitates intelligent device control with cloud vendors like Amazon and Google using artificial intelligence for data analytics, and with digital assistants like Alexa and Siri providing a voice user interface. Smart IoT is all about duplex connecting, processing, and implementing. Centralized IoT architecture is vulnerable to cyber-attacks. With Block Chain, it is possible to maintain transparency and security of the transaction's data. Robotic Process Automation (RPA) using bots has automated laborious tasks in 2019. Embedded Internet using Facial Recognition could reduce the coronavirus pandemic crisis by making a paradigm shift from fingerprint sensors to facial recognition. Security concerns are addressed with micro-segmentation approaches. IoT, an incredible vision of the future makes systems adaptive with customized features, responsive with increased efficiency, and procurable with optimized cost. This research delivers a comprehensive insight into the technical perspectives of IoT, focusing on interoperability, flexibility, scalability, mobility, security, transparency, standardization, and low energy. A smart classroom is implemented based on the concepts of IoT.",http://dx.doi.org/10.1007/s11277-021-09308-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-022-09319-w,Personality-targeted persuasive gamified systems: exploring the impact of application domain on the effectiveness of behaviour change strategies,User Modeling and User-Adapted Interaction,10.1007/s11257-022-09319-w,Springer,2022-04-01,"Persuasive gamified systems for health are interventions that promote behaviour change using various persuasive strategies. While research has shown that these strategies are effective at motivating behaviour change, there is little knowledge on whether and how the effectiveness of these strategies vary across multiple domains for people of distinct personality traits. To bridge this gap, we conducted a quantitative study with 568 participants to investigate (a) whether the effectiveness of the persuasive strategies implemented vary within each domain (b) whether the effectiveness of various strategies vary across two distinct domains, (c) how people belonging to different personality traits respond to these strategies, and (d) if people high in a personality trait would be influenced by a persuasive strategy within one domain and not in the other. Our results show that there are significant differences in the effectiveness of various strategies across domains and that people’s personality plays a significant role in the perceived persuasiveness of different strategies both within and across distinct domains. The Reward strategy (which involves incentivizing users for achieving specific milestones towards the desired behaviour) and the Competition strategy (which involves allowing users to compete with each other to perform the desired behaviour) were effective for promoting healthy eating but not for smoking cessation for people high in Conscientiousness . We provide design suggestions for developing persuasive gamified interventions for health targeting distinct domains and tailored to individuals depending on their personalities.",http://dx.doi.org/10.1007/s11257-022-09319-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-04235-z,OFP-TM: an online VM failure prediction and tolerance model towards high availability of cloud computing environments,The Journal of Supercomputing,10.1007/s11227-021-04235-z,Springer,2022-04-01,"The indispensable collaboration of cloud computing in every digital service has raised its resource usage exponentially. The ever-growing demand of cloud resources evades service availability leading to critical challenges such as cloud outages, SLA violation, and excessive power consumption. Previous approaches have addressed this problem by utilizing multiple cloud platforms or running multiple replicas of a Virtual Machine (VM) resulting into high operational cost. This paper has addressed this alarming problem from a different perspective by proposing a novel $$\mathbb {O}$$ O nline virtual machine $$\mathbb {F}$$ F ailure $$\mathbb {P}$$ P rediction and $$\mathbb {T}$$ T olerance $$\mathbb {M}$$ M odel (OFP-TM) with high availability awareness embedded in physical machines as well as virtual machines. The failure-prone VMs are estimated in real-time based on their future resource usage by developing an ensemble approach-based resource predictor. These VMs are assigned to a failure tolerance unit comprising of a resource provision matrix and Selection Box (S-Box) mechanism which triggers the migration of failure-prone VMs and handle any outage beforehand while maintaining the desired level of availability for cloud users. The proposed model is evaluated and compared against existing related approaches by simulating cloud environment and executing several experiments using a real-world workload Google Cluster dataset. Consequently, it has been concluded that OFP-TM improves availability and scales down the number of live VM migrations up to 33.5% and 83.3%, respectively, over without OFP-TM.",http://dx.doi.org/10.1007/s11227-021-04235-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10055-022-00642-6,Real-time camera-based eye gaze tracking using convolutional neural network: a case study on social media website,Virtual Reality,10.1007/s10055-022-00642-6,Springer,2022-03-30,"Eye gaze tracking plays an important role in various fields including, human computer interaction, virtual and augmented reality and in identifying effective marketing solutions in affective manner. This paper addresses real-time eye gaze estimation problem using low resolution ordinary camera available in almost every desktop environment as opposed to gaze tracking technologies requiring costly equipment and infrared light sources. In this research, a camera based non-invasive technique has been proposed for tracking and recording gaze points. Further, the proposed framework was used to analyze gaze behavior of users on advertisements displayed on social media website. Eye gaze fixations data of 32 participants were recorded, and gaze patterns were plotted using Heat maps. In addition, the gaze driven interface was designed for virtual interaction tasks to assess the performance, and usability of our proposed framework.",http://dx.doi.org/10.1007/s10055-022-00642-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-021-03512-2,Design of a NLP-empowered finance fraud awareness model: the anti-fraud chatbot for fraud detection and fraud classification as an instance,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-03512-2,Springer,2022-03-21,"Advanced technologies, Internet of things and fundamental information communication technology frameworks in particular, facilitate information sharing. One simple click-on end device can make every tool accessible to users; however, whether correct information is received remains to be an open question. Incorrect information that bundles the factors of fake, malicious, or fraudulent information, whether deliberately or not, may worsen misunderstandings. To avoid these cases escalating to the level of crime, a universal financial fraud-awareness model was designed in this study. The model first targets accurate fraud detection and classification using the natural language processing technique. An anti-fraud chatbot is then implemented as an instance of the model and deployed on a widely used social network service, namely LINE. This implementation aims to manage finance-fraud cases and provide anti-fraud suggestions to deal with foreseeable fraud events. Statistics of the comparison between Word2vec, ELMO, BERT, and DistilBERT on the five-strong conventional machine-learning models and the models of artificial neural networks indicate that the proposed model can achieve an accuracy of over 98% while detecting potential finance-fraud cases. In addition, the more efficient models by DistilBERT with a support vector machine or a random forest have lower resource-computation cost and faster execution time in real applications.",http://dx.doi.org/10.1007/s12652-021-03512-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03568-5,"Big data analytics for data-driven industry: a review of data sources, tools, challenges, solutions, and research directions",Cluster Computing,10.1007/s10586-022-03568-5,Springer,2022-03-12,"The study of big data analytics (BDA) methods for the data-driven industries is gaining research attention and implementation in today’s industrial activities, business intelligence, and rapidly changing the perception of industrial revolutions. The uniqueness of big data and BDA has created unprecedented new research calls to solve data generation, storage, visualization, and processing challenges. There are significant gaps in knowledge for researchers and practitioners on the right information and BDA tools to extract knowledge in large significant industrial data that could help to handle big data formats. Notwithstanding various research efforts and scholarly studies that have been proposed recently on big data analytic processes for industrial performance improvements. Comprehensive review and systematic data-driven analysis, comparison, and rigorous evaluation of methods, data sources, applications, major challenges, and appropriate solutions are still lacking. To fill this gap, this paper makes the following contributions: presents an all-inclusive survey of current trends of BDA tools, methods, their strengths, and weaknesses. Identify and discuss data sources and real-life applications where BDA have potential impacts. Other main contributions of this paper include the identification of BDA challenges and solutions, and future research prospects that require further attention by researchers. This study provides an insightful recommendation that could assist researchers, industrial practitioners, big data providers, and governments in the area of BDA on the challenges of the current BDA methods, and solutions that would alleviate these challenges.",http://dx.doi.org/10.1007/s10586-022-03568-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00520-0,IIoT platforms’ architectural features – a taxonomy and five prevalent archetypes,Electronic Markets,10.1007/s12525-021-00520-0,Springer,2022-03-09,"In the industrial Internet of Things (IIoT), digital platforms have recently received significant attention. Although IIoT platforms revolve around similar business objectives, they address various use cases and, thus, differ considerably in their architectural setup. While research has already investigated IIoT platforms from a business or design perspective, little is known about their underlying technology stack and its implications. To unveil different IIoT platform configurations and better understand their architectural design, we systematically develop and validate a taxonomy of IIoT platforms’ architectural features based on related literature, real-world cases, and expert interviews. On this foundation, we identify and discuss five IIoT platform archetypes (Allrounder, Device Controller, Data Hub, Service Enabler, Connector). Our findings contribute to the descriptive knowledge in this ambiguous research field while also elucidating the interplay of IIoT platforms’ architectural setup and their purpose. From a managerial viewpoint, our results may guide practitioners in comparing and selecting a suitable IIoT platform.",http://dx.doi.org/10.1007/s12525-021-00520-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12599-022-00743-1,Intelligent Assistants,Business & Information Systems Engineering,10.1007/s12599-022-00743-1,Springer,2022-03-07,"Intelligent assistants are an increasingly commonplace class of information systems spanning a broad range of form and complexity. But what characterizes an intelligent assistant, and how do we design better assistants? In the paper, the authors contribute to scientific research in the domain of intelligent assistants in three steps, each building on the previous. First, they investigate the historical context of assistance as human work. By examining qualitative studies regarding the work of human assistants, the authors inductively derive concepts crucial to modeling the context of assistance. This analysis informs the second step, in which they develop a conceptual typology of intelligent assistants using 111 published articles. This typology explicates the characteristics (what or how) of intelligent assistants and their use context (who or which). In the third and final step, the authors utilize this typology to shed light on historical trends and patterns in design and evaluation of intelligent assistants, reflect on missed opportunities, and discuss avenues for further exploration.",http://dx.doi.org/10.1007/s12599-022-00743-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10234-5,Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection,Information Systems Frontiers,10.1007/s10796-021-10234-5,Springer,2022-03-02,"Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high.",http://dx.doi.org/10.1007/s10796-021-10234-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-022-01653-0,NAG: neural feature aggregation framework for credit card fraud detection,Knowledge and Information Systems,10.1007/s10115-022-01653-0,Springer,2022-03-01,"The state-of-the-art feature-engineering method for fraud classification of electronic payments uses manually engineered feature aggregates, i.e., descriptive statistics of the transaction history. However, this approach has limitations, primarily that of being dependent on expensive human expert knowledge. There have been attempts to replace manual aggregation through automatic feature extraction approaches. They, however, do not consider the specific structure of the manual aggregates. In this paper, we define the novel Neural Aggregate Generator (NAG), a neural network-based feature extraction module that learns feature aggregates end-to-end on the fraud classification task. In contrast to other automatic feature extraction approaches, the network architecture of the NAG closely mimics the structure of feature aggregates. Furthermore, the NAG extends learnable aggregates over traditional ones through soft feature value matching and relative weighting of the importance of different feature constraints. We provide a proof to show the modeling capabilities of the NAG. We compare the performance of the NAG to the state-of-the-art approaches on a real-world dataset with millions of transactions. More precisely, we show that features generated with the NAG lead to improved results over manual aggregates for fraud classification, thus demonstrating its viability to replace them. Moreover, we compare the NAG to other end-to-end approaches such as the LSTM or a generic CNN. Here we also observe improved results. We perform a robust evaluation of the NAG through a parameter budget study, an analysis of the impact of different sequence lengths and also the predictions across days. Unlike the LSTM or the CNN, our approach also provides further interpretability through the inspection of its parameters.",http://dx.doi.org/10.1007/s10115-022-01653-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01154-8,The ethics of algorithms: key problems and solutions,AI & SOCIETY,10.1007/s00146-021-01154-8,Springer,2022-03-01,"Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2), 2016). The goals are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms.",http://dx.doi.org/10.1007/s00146-021-01154-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00519-7,Cognitive automation,Electronic Markets,10.1007/s12525-021-00519-7,Springer,2022-03-01,"Facilitated by AI technology, the phenomenon of cognitive automation extends the scope of deterministic business process automation (BPA) through the probabilistic automation of knowledge and service work. By transforming work systems through cognitive automation, organizations are provided with vast strategic opportunities to gain business value. However, research lacks a unified conceptual lens on cognitive automation, which hinders scientific progress. Thus, based on a Systematic Literature Review, we describe the fundamentals of cognitive automation and provide an integrated conceptualization. We provide an overview of the major BPA approaches such as workflow management, robotic process automation, and Machine Learning-facilitated BPA while emphasizing their complementary relationships. Furthermore, we show how the phenomenon of cognitive automation can be instantiated by Machine Learning-facilitated BPA systems that operate along the spectrum of lightweight and heavyweight IT implementations in larger IS ecosystems. Based on this, we describe the relevance and opportunities of cognitive automation in Information Systems research.",http://dx.doi.org/10.1007/s12525-021-00519-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40012-022-00348-9,Privacy and data protection in the enterprise world,CSI Transactions on ICT,10.1007/s40012-022-00348-9,Springer,2022-03-01,"Enterprise systems are becoming more complex with an interconnected network of large heterogeneous devices. These systems generate, process and store large volumes of data (including Personally Identifiable Information (PII)). Securing such a large infrastructure from adversaries is a humongous task for enterprise organizations. Adversaries can exploit the inherent vulnerabilities in the enterprise systems and mount various attacks such as ransomware, malware, phishing, and so on, with goals to steal the data, take control of the system, etc., thus causing huge financial and reputation loss. Further, with stringent privacy regulations such as GDPR, organizations can end up with large penalty payouts to local Governments and their affected people due to data breaches. Thus, to safeguard enterprise systems from data breaches, organizations deploy Data Leakage Prevention (DLP) systems with encryption and authentication mechanisms. While these techniques provide privacy and protection of data at-rest and in-transit scenarios, for data in use scenarios, data leakage is still possible (Since data needs to be available in plaintext form for several applications, the attacker can steal the data by exploiting the vulnerability in the access control system, authentication, or other vulnerabilities during the run-time execution of the application). Hence, in this paper, we discuss various challenges encountered by organizations in enabling privacy and data protection for data in-use. Next, we discuss how privacy enabled computation techniques such as Fully Homomorphic Encryption and Secure Multiparty Computation can be used to provide data in-use protection along with their pros and cons in real life deployment scenarios.",http://dx.doi.org/10.1007/s40012-022-00348-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11187-022-00609-6,Topic-based classification and identification of global trends for startup companies,Small Business Economics,10.1007/s11187-022-00609-6,Springer,2022-03-01,"To foresee global economic trends, one needs to understand the present startup companies that soon may become new market leaders. In this paper, we explore textual descriptions of more than 250 thousand startups in the Crunchbase database. We analyze the 2009–2019 period by using topic modeling. We propose a novel classification of startup companies free from expert bias that contains 38 topics and quantifies the weight of each of these topics for all the startups. Taking the year of establishment and geographical location of the startups into account, we measure which topics were increasing or decreasing their share over time, and which of them were predominantly present in Europe, North America, or other regions. We find that the share of startups focused on data analytics, social platforms, and financial transfers, and time management has risen, while an opposite trend is observed for mobile gaming, online news, and online social networks as well as legal and professional services. We also identify strong regional differences in topic distribution, suggesting certain concentration of the startups. For example, sustainable agriculture is presented stronger in South America and Africa, while pharmaceutics, in North America and Europe. Furthermore, we explore which pairs of topics tend to co-occur more often together, quantify how multisectoral the startups are, and which startup classes attract more investments. Finally, we compare our classification to the one existing in the Crunchbase database, demonstrating how we improve it. We propose a novel classification of more than 250 thousand startups registered in the Crunchbase database based on machine learning algorithms and free from expert bias. We find that the share of startups focused on data analytics, social platforms, and financial transfers, and time management has risen, while an opposite trend is observed for mobile gaming, online news, and online social networks as well as legal and professional services. We also identify strong regional differences in class distribution, suggesting, for example, sustainable agriculture being present stronger in South America and Africa, while pharmaceutics, in North America and Europe. Our classification can improve analysis of the Crunchbase data further promoting the popularity of the platform, while the trends identified will be useful for investors and policy makers. Last not least, this paper presents the first application of topic modeling to startup companies, providing thus a new direction for academic research.",http://dx.doi.org/10.1007/s11187-022-00609-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41403-022-00322-6,The Role of Emerging Technologies to Fight Against COVID-19 Pandemic: An Exploratory Review,Transactions of the Indian National Academy of Engineering,10.1007/s41403-022-00322-6,Springer,2022-03-01,"Since the end of the year 2019, the whole world is experiencing a global emergency due to the COVID-19 pandemic. The major sectors including industry, economics, education have been affected. Ongoing pandemics confined us to avoid mass gathering and rigorously maintain social distancing to mitigate the spreading of this infectious disease. In this situation emerging technologies including the internet of things (IoT), Artificial Intelligence (AI) is playing a very important role in various fields such as healthcare, economics, educational system, and others to monitoring or tackle the impact of COVID-19 pandemic. Several papers discussed the impact of IoT on the COVID-19 pandemic in various aspects. However, the challenges and designing issues towards the implementation of IoT-based monitoring systems are not deeply investigated. Alongside, the adaptation of IoT and other technologies in the post-covid situation is not addressed properly. Our review article provides an up to date extensive survey on how IoT-enabled technologies are helping to combat the pandemic and to manage industry, education, economic, and medical system. As result, the realization is that IoT and other associated technologies have a great impact on virus detection, tracking, and mitigate the spread. In the face of an expeditiously spreading pandemic, the associated designing issues of the IoT-based framework have been looked into as a part of this review. Alongside, this review highlights the major challenges like privacy, security scalability, etc. facing in using such technologies. Finally, we explore ’The New Normal’ and the use of technologies to help in the post-pandemic era.",http://dx.doi.org/10.1007/s41403-022-00322-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40558-022-00222-z,Deep learning model based on expectation-confirmation theory to predict customer satisfaction in hospitality service,Information Technology & Tourism,10.1007/s40558-022-00222-z,Springer,2022-03-01,"Customer satisfaction is one of the most important measures in the hospitality industry. Therefore, several psychological and cognitive theories have been utilized to provide appropriate explanations of customer perception. Owing to recent rapid developments in artificial intelligence and big data, novel methodologies have presented to examine several psychological theories applied in the hospitality industry. Within this framework, this study combines deep learning techniques with the expectation-confirmation theory to elucidate customer satisfaction in hospitality services. Customer hotel review comments, hotel information, and images were employed to predict customer satisfaction with hotel service. The results show that the proposed fused model achieved an accuracy of 83.54%. In addition, the recall value that predicts dissatisfaction improved from 16.46–33.41%. Based on the findings of this study, both academic and managerial implications for the hospitality industry are presented.",http://dx.doi.org/10.1007/s40558-022-00222-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-11929-w,SenDemonNet: sentiment analysis for demonetization tweets using heuristic deep neural network,Multimedia Tools and Applications,10.1007/s11042-022-11929-w,Springer,2022-03-01,"Sentiment analysis is one of the efficient models for extracting opinion mining with identification and classification from unstructured text data such as product reviews or microblogs. It is used to gain feedback from political campaigns, brand reviews, marketing analysis, and customers. The sentiment analysis on Twitter data is a recent research field in the natural processing. The dataset is gathered from the “Twitter” package in R along with Twitter API. The main intent of this paper is to understand the public opinion on the recently implemented demonetization policy using the proposed SenDemonNet. Initially, the tweet preprocessing was done, which is intended for cleaning the text data. Then, the feature extraction is performed by Bag of n-grams, TF-IDF, and the word2vec algorithm. The main objective of this work is a weighted feature selection that is developed by the hybrid Forest–Whale Optimization Algorithm (F-WOA) to get the best classification outcome. With these features, the Heuristic Deep Neural Network (HDNN) is adopted for classification, where the proposed FOA and WOA tune the parameter of DNN for reaching the maximum accuracy rate. From the statistical analysis, the performance of the designed F-WOA-DNN is 1.8%, 1.9%, 1.86%, and 2% enhanced than PSO-DNN, GWO-DNN, WOA-DNN, FOA-DNN, SVM, CNN, LSTM, and DNN respectively. Extensive experimental results show that SenDemonNet outperforms its competitors, producing an impressive increase in the classification accuracy on the benchmark dataset. Graphical abstract Graphical architectural diagram of Sentiment analysis model on demonetization policy in India",http://dx.doi.org/10.1007/s11042-022-11929-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-021-00330-4,Multi-objective Scheduling Policy for Workflow Applications in Cloud Using Hybrid Particle Search and Rescue Algorithm,Service Oriented Computing and Applications,10.1007/s11761-021-00330-4,Springer,2022-03-01,"Cloud has been developed as a prominent distributed computing model over the last few years because of its wide array of resources and services that are virtualized, scalable, and on demand. In a distributed environment, coordination of workflow applications is an accepted NP-complete problem; hence, it is hard to derive exact solutions. Because of its dynamic and heterogeneous properties, this happens to be even more difficult in cloud environment. The intention of this work is to improve multi-objective optimization of scientific workflow scheduling based on proposed multi-objective hybrid particle search optimization algorithm (MOHPSO) in cloud computing platform and to propose an effective framework for workflow execution. For initial stage, fuzzy Manhattan distance-based clustering is performed to cluster the cloud resources. After that, enhanced chaotic neural network technique is applied to encrypt the task details for security purpose. In this article, the recent search and rescue optimization algorithm (SAR) is hybridized with popular particle swarm optimization algorithm (PSO) to enhance the exploration as well as search ability of optimization algorithm to create best schedules for workflow requests in cloud environment. Moreover, the scientific workflows like Epigenomics, Montage, and Cybershake with varying amount of task sizes are utilized to perform the scheduling process. CloudSim tool is utilized for the simulation of workflow scheduling problem in cloud. Performance enhancement of proposed methodology in terms of load balance, makespan, and cost is validated by comparison with various state-of-the-art algorithms. .",http://dx.doi.org/10.1007/s11761-021-00330-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10257-022-00551-w,SLA-aware operational efficiency in AI-enabled service chains: challenges ahead,Information Systems and e-Business Management,10.1007/s10257-022-00551-w,Springer,2022-03-01,"Service providers compose services in service chains that require deep integration of core operational information systems across organizations. Additionally, advanced analytics inform data-driven decision-making in corresponding AI-enabled business processes in today’s complex environments. However, individual partner engagements with service consumers and providers often entail individually negotiated, highly customized Service Level Agreements (SLAs) comprising engagement-specific metrics that semantically differ from general KPIs utilized on a broader operational (i.e., cross-client) level. Furthermore, the number of unique SLAs to be managed increases with the size of such service chains. The resulting complexity pushes large organizations to employ dedicated SLA management systems, but such ‘siloed’ approaches make it difficult to leverage insights from SLA evaluations and predictions for decision-making in core business processes, and vice versa. Consequently, simultaneous optimization for both global operational process efficiency and engagement-specific SLA compliance is hampered. To address these shortcomings, we propose our vision of supplying online, AI-supported SLA analytics to data-driven, intelligent core workflows of the enterprise and discuss current research challenges arising from this vision. Exemplified by two scenarios derived from real use cases in industry and public administration, we demonstrate the need for improved semantic alignment of heavily customized SLAs with AI-enabled operational systems. Moreover, we discuss specific challenges of prescriptive SLA analytics under multi-engagement SLA awareness and how the dual role of AI in such scenarios demands bidirectional data exchange between operational processes and SLA management. Finally, we discuss the implications of federating AI-supported SLA analytics across organizations.",http://dx.doi.org/10.1007/s10257-022-00551-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10288-021-00500-2,Challenges and opportunities in crowdsourced delivery planning and operations,4OR,10.1007/s10288-021-00500-2,Springer,2022-03-01,"How to best deliver goods to consumers has been a logistics question since time immemorial. However, almost all traditional delivery models involved a form of company employees, whether employees of the company manufacturing the goods or whether employees of the company transporting the goods. With the growth of the gig economy, however, a new model not involving company employees has emerged: relying on crowdsourced delivery. Crowdsourced delivery involves enlisting individuals to deliver goods and interacting with these individuals using the internet. In crowdsourced delivery, the interaction with the individuals typically occurs through a platform. Importantly, the crowdsourced couriers are not employed by the platform and this has fundamentally changed the planning and execution of the delivery of goods: the delivery capacity is no longer under (full) control of the company managing the delivery. We present the challenges this introduces, review how the research community has proposed to handle some of these challenges, and elaborate on the challenges that have not yet been addressed.",http://dx.doi.org/10.1007/s10288-021-00500-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-021-09608-4,"A Systematic Survey on CAPTCHA Recognition: Types, Creation and Breaking Techniques",Archives of Computational Methods in Engineering,10.1007/s11831-021-09608-4,Springer,2022-03-01,"CAPTCHA stands for Completely Automated Public Turing Test to Tell Computers and Human Apart. CAPTCHA is used for internet security. A few CAPTCHA schemes are available today like, text-based, audio-based, video/animation-based, puzzle based etc. In this paper, all these types are collaborating at single place to analyze. The main aim of this article is to present a literature to identify and recognize CAPTCHA, its types, the creation and breaking techniques. It is a systematic and complete analysis of all available CAPTCHA types. In this paper, 16 text-based CAPTCHA’s generation methods are discussed with usability and security ranges from 3 to 100 and 65 to 100%, respectively. The security and usability measures are not calculated/sustained using some known English schemes. Out of 16 reviewed CAPTCHAs, 12 are based on English language, 1 on Arabic language, 1 on Chinese language, 1 on Devanagari language and 1 on Gurumukhi script. The designs are made segment proof with overlapping random shapes, overlapping characters, clasping, different colors and different shades. For making recognition proof many techniques are used like image masking, local and global warping; broken characters, random rotation, arcs, jaws, etc. Approximately 50 schemes, especially based on the English language, are successfully broken with a success rate that ranges from 2 to 100%. The techniques that are used to break these schemes include shape context matching, distortion estimation, Log Gabor 2D filter, horizontal and vertical projection (for a segment the letters) are used. For recognition CNN, KNN, DNN and MCDNN are used. Almost 15 images-based CAPTCHAs are discussed that are designed with usability and security range 90–100 and 17–100%, respectively. Out of these 5 schemes are successfully broken with a success rate ranging between 7 and 100%. The K-NN and SVM are mostly used algorithms to recognize the images. Audio based CAPTCHAs (5 designs) are discussed with usability and security range from 68.5 to 100 and 100%, respectively. The broken rate of these audio schemes is also 45–75%. These schemes are broken with SVM and K-NN algorithms. The paper also discusses 4 popular video-based designs that provide usability and security that ranges from 75 to 100 and 98 to 100, respectively. These schemes are also compromised with broken rate 16–10% using SIFT, NN and simple OCR techniques. The paper can be a benchmark to precede any specific research to dive into any one of these types.",http://dx.doi.org/10.1007/s11831-021-09608-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11920-022-01330-7,Commercial Use of Emotion Artificial Intelligence (AI): Implications for Psychiatry,Current Psychiatry Reports,10.1007/s11920-022-01330-7,Springer,2022-03-01,"Purpose of Review Emotion artificial intelligence (AI) is technology for emotion detection and recognition. Emotion AI is expanding rapidly in commercial and government settings outside of medicine, and will increasingly become a routine part of daily life. The goal of this narrative review is to increase awareness both of the widespread use of emotion AI, and of the concerns with commercial use of emotion AI in relation to people with mental illness. Recent Findings This paper discusses emotion AI fundamentals, a general overview of commercial emotion AI outside of medicine, and examples of the use of emotion AI in employee hiring and workplace monitoring. Summary The successful re-integration of patients with mental illness into society must recognize the increasing commercial use of emotion AI. There are concerns that commercial use of emotion AI will increase stigma and discrimination, and have negative consequences in daily life for people with mental illness. Commercial emotion AI algorithm predictions about mental illness should not be treated as medical fact.",http://dx.doi.org/10.1007/s11920-022-01330-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02677-9,A novel POI recommendation model based on joint spatiotemporal effects and four-way interaction,Applied Intelligence,10.1007/s10489-021-02677-9,Springer,2022-03-01,"Point of interest (POI) recommendation is a fundamental task in location-based social networks (LBSN). The increasing proliferation of LBSNs brings about considerable amounts of user-generated check-in data. Such data can significantly contribute to understanding user behaviors, based on which personalized recommendations can be efficiently derived. Spatial and temporal effects are crucial factors in the user’s decision-making for choosing a POI to visit. Most existing methods treat them as two independent features and cannot accurately capture users’ interests. We argue that spatial and temporal effects should be analyzed simultaneously in POI recommendations. To this end, we propose a S patio T emporal heterogeneous information Network (HIN)-based P O I RE commendation model (STORE) to model various heterogeneous context features, e.g., the joint spatiotemporal effects, types of POI, and social relations. Specifically, we defined the spatiotemporal effects entity (St) in HIN to model the joint spatiotemporal effects. Instead of modeling the traditional two-way interaction <user, item>, we further design a four-way neural interaction model <User, Meta-path, St, POI>. In this way, our model can effectively mine and extract useful information from the meta-path-based context and spatiotemporal effects, thereby improving recommendation performance. We conduct extensive experiments on two real-world datasets, and the results demonstrate that the STORE model outperforms the best baseline by about 12% in NDCG@5 and 11% in Rec@5.",http://dx.doi.org/10.1007/s10489-021-02677-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-021-01651-8,An improved item-based collaborative filtering using a modified Bhattacharyya coefficient and user–user similarity as weight,Knowledge and Information Systems,10.1007/s10115-021-01651-8,Springer,2022-03-01,"Item-based filtering technique is a collaborative filtering algorithm for recommendations. Correlation-based similarity measures such as cosine similarity, Pearson correlation, and its variants have inherent limitations on sparse datasets because items may not have enough ratings for predictions. In addition, traditional similarity measures mainly focus on the orientations of the rating vectors, not magnitude, and as a result two rating vectors with different magnitudes but oriented in the same direction, can be exactly similar. Another aspect is that on a set of items, similar users’ may have different rating pattern. In addition, to calculate the similarity between items, ratings of all co-rated users are considered; however, a judicious approach is to consider the similarity between users as a weight to find the similar neighbors of a target item. To mitigate these issues, a modified Bhattacharyya coefficient is proposed in this paper. The proposed similarity measure is used to calculate user–user similarity, which in turn is used as a weight in item-based collaborative filtering. The experimental analysis on the collected MovieLens datasets shows a significant improvement of item-based collaborative filtering, when user–user similarity calculated by the proposed modified similarity measure is used as a weight.",http://dx.doi.org/10.1007/s10115-021-01651-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-022-04547-0,Constraint-based robust planning and scheduling of airport apron operations through simheuristics,Annals of Operations Research,10.1007/s10479-022-04547-0,Springer,2022-02-11,"Scheduling aircraft turnarounds at airports requires the coordination of several organizations, including the airport operator, airlines, and ground service providers. The latter manage the necessary supplies and teams to handle aircraft in between consecutive flights, in an area called the airport ‘apron’. Divergence and conflicting priorities across organizational borders negatively impact the smooth running of operations, and play a major role in departure delays. We provide a novel simulation-optimization approach that allows multiple service providers to build robust plans for their teams independently, whilst supporting overall coordination through central scheduling of all the involved turnaround activities. Simulation is integrated within the optimization process, following simheuristic techniques, which are augmented with an efficient search driving mechanism. Two tailored constraint-based feedback routines are automatically generated from simulation outputs to constrain the search space to solutions more likely to ensure plan robustness. The two simulation components provide constructive feedback on individual routing problems and global turnaround scheduling, respectively. Compared to the state-of-the-art approach for aircraft turnaround scheduling and routing of service teams, our methodology improves the apron’s on-time punctuality, without the need for the involved organizations to share sensitive information. This supports a wider applicability of our approach in a multiple-stakeholder environment.",http://dx.doi.org/10.1007/s10479-022-04547-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10696-021-09439-2,Sparse flexible design: a machine learning approach,Flexible Services and Manufacturing Journal,10.1007/s10696-021-09439-2,Springer,2022-02-10,"For a general production network, state-of-the-art methods for constructing sparse flexible designs are heuristic in nature, typically computing a proxy for the quality of unseen networks and using that estimate in a greedy manner to modify a current design. This paper develops two machine learning-based approaches to constructing sparse flexible designs that leverage a neural network to accurately and quickly predict the performance of large numbers of candidate designs. We demonstrate that our heuristics are competitive with existing approaches and produce high-quality solutions for both balanced and unbalanced networks. Finally, we introduce a novel application of process flexibility in healthcare operations to demonstrate the effectiveness of our approach in a large numerical case study. We study the flexibility of linear accelerators that deliver radiation to treat various types of cancer. We demonstrate how clinical constraints can be easily absorbed into the machine learning subroutine and how our sparse flexible treatment networks meet or beat the performance of those designed by state-of-the-art methods.",http://dx.doi.org/10.1007/s10696-021-09439-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11116-022-10268-x,"How carpool drivers choose their passengers in Nanjing, China: effects of facial attractiveness and credit",Transportation,10.1007/s11116-022-10268-x,Springer,2022-02-08,"Carpooling, as an increasingly popular ridesharing service available in China, offers car access to those who do not own a private vehicle. However, disclosing passengers’ personal information to drivers, especially their photos and gender, may encourage facial discrimination or violent crimes. In this paper, we explore the passenger choice behavior of carpool drivers in China. A stated preference survey was designed to collect drivers’ choices. An ordered choice model considering drivers’ observed taste heterogeneity and random effects within panel data was employed to find the associations between passengers’ personal information and drivers’ choice behavior. Behavioral findings show that carpool drivers’ passenger choice behavior is significantly affected by not only the attributes that are trip specific, but also the characteristics of drivers and passengers, and the interactions among these characteristics. Value of facial attractiveness (VOFA) and value of credit (VOC) are both defined and calculated to show that the charges are less important to carpool drivers in China. We then discuss research questions in depth, i.e., the drivers’ purposes, the implications of drivers’ passenger choices on equality, operational suggestions, and the reflection of discrimination and risk problems on the management of Internet companies, the government regulatory system, and the social ethics concerns.",http://dx.doi.org/10.1007/s11116-022-10268-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-022-10144-1,"A survey on sentiment analysis methods, applications, and challenges",Artificial Intelligence Review,10.1007/s10462-022-10144-1,Springer,2022-02-07,"The rapid growth of Internet-based applications, such as social media platforms and blogs, has resulted in comments and reviews concerning day-to-day activities. Sentiment analysis is the process of gathering and analyzing people’s opinions, thoughts, and impressions regarding various topics, products, subjects, and services. People’s opinions can be beneficial to corporations, governments, and individuals for collecting information and making decisions based on opinion. However, the sentiment analysis and evaluation procedure face numerous challenges. These challenges create impediments to accurately interpreting sentiments and determining the appropriate sentiment polarity. Sentiment analysis identifies and extracts subjective information from the text using natural language processing and text mining. This article discusses a complete overview of the method for completing this task as well as the applications of sentiment analysis. Then, it evaluates, compares, and investigates the approaches used to gain a comprehensive understanding of their advantages and disadvantages. Finally, the challenges of sentiment analysis are examined in order to define future directions.",http://dx.doi.org/10.1007/s10462-022-10144-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-021-01869-4,A General Matrix Factorization Framework for Recommender Systems in Multi-access Edge Computing Network,Mobile Networks and Applications,10.1007/s11036-021-01869-4,Springer,2022-02-04,"Due to the growing number of users and items in recommender system, along with the more complex algorithms for precise recommendation, recommender system in broswer/server architecture will consume more computing cost and more service latency. Besides, the bidirectional transmission of broswer/server architecture requires users to upload necessary user information to the cloud servers. The current manner of recommender systems might cause the leakage of the sensitive information and take the risk of privacy issue. To alleviate the two issues, we integrate the multi-access edge computing network into recommender systems to take fully advantage of base stations and user terminals. Particularlly, we pull the tasks of user-profiles and recommendation algorithms out of the cloud servers and put them to base stations and user terminals. The cloud servers will undertake an independent item-profiles task that will not take any information from users. Considering the differences among user terminals, we propose a general matrix factorization framework that can adopt different matrix factorization-based recommender algorithms with one item-profiles. This framework can allow different terminals to take variety algorithms based on their computing abilities. Experiments are conducted on two real world datasets to validate the proposed methods by comparing them with conventional recommendation methods. Experimental results prove the principle that matrix factorization methods within the proposed framework can enhance the recommendation system’s performance in terms of both prediction and recommendation.",http://dx.doi.org/10.1007/s11036-021-01869-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-022-03707-1,"Security and privacy issues in smart cities/industries: technologies, applications, and challenges",Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-022-03707-1,Springer,2022-02-03,"The development of the Internet of things (IoT) is rapidly growing everywhere in our daily lives. Advanced information and communication technologies play a vital role in the development of smart cities/industries, including buildings, hospitals, transportation, and other related public and private environments. The emerging technologies are converging as a computing paradigm to optimize resource allocation dynamically to improve the quality of services. The deployment of interconnected devices uses heterogeneous networks and powerful data centers to perform ubiquitous sensing, which can collect and transfer real-time data to offer computational intelligence. Moreover, sustainable resources such as devices, networks, and databases are intellectually equipped to standardize governance and service deliveries. The sustainable environment has a network infrastructure to collect, store, and analyze real-time data to provide an efficient decision-making process. IoT-enabled smart sustainable environments integrate advanced technologies to build people-centric smart cities and industries. Most service intelligence and technical schemas are easily accessible and applicable to authorize the scope of civic intelligence. However, the potential issues such as security and privacy are open to deal with the challenges of security requirements. A thematic classification of security and privacy issues is primarily focused on authentication and key management protocols to secure Industrial IoT environments. To highlight the potential visions of the smart cities/industries, in this survey, numerous security threats, techniques, countermeasures, and tools are reviewed to address the key challenges of smart service intelligence within sustainable environments.",http://dx.doi.org/10.1007/s12652-022-03707-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11276-021-02874-x,A survey of application research based on blockchain smart contract,Wireless Networks,10.1007/s11276-021-02874-x,Springer,2022-02-01,"Nowadays, blockchain technology and industry has developed rapidly all over the world, which is inseparable from continuous innovation and improvement on smart contract technology. Therefore, by summarizing the working principle and application research status of blockchain smart contract, this paper analyzes the development and challenges of smart contract. Firstly, we introduce the model and operation principle of blockchain smart contract for the overall architecture, analyze the deployment process of smart contract with Ethereum, Hyperledger Fabric and EOSIO, and make a comparative analysis from the technical level. And taking Byteball, InterValue and IOTA platforms as examples, we introduce the deployment process and application potential for DAG-based blockchain smart contract. Additionally, we also summarize the application research of smart contract for international and Blockchain Oracle, and discuss its innovative application and development trend in the future. Secondly, we introduce the application status of smart contract with Ethereum and Hyperledger Fabric platforms from the aspects of financial transactions, Internet of things, medical applications, and supply chain, and further discuss EOS (enterprise operation system), Blockchain Oracle and other application fields. Furthermore, we introduce the application advantages and challenges to smart contract for industrial Internet from the fields of manufacturing, food industry, industrial Internet of things and industry 4.0. Finally, we discuss the challenges faced by smart contract with technical issues, analyzes the impact on large-scale applications and mining system on the sustainable development of smart contract, and looks forward to the future research direction of blockchain smart contract.",http://dx.doi.org/10.1007/s11276-021-02874-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-021-06104-5,Multi-target prediction for dummies using two-branch neural networks,Machine Learning,10.1007/s10994-021-06104-5,Springer,2022-02-01,"Multi-target prediction (MTP) serves as an umbrella term for machine learning tasks that concern the simultaneous prediction of multiple target variables. Classical instantiations are multi-label classification, multivariate regression, multi-task learning, dyadic prediction, zero-shot learning, network inference, and matrix completion. Despite the significant similarities, all these domains have evolved separately into distinct research areas over the last two decades. This led to the development of a plethora of highly-engineered methods, and created a substantially-high entrance barrier for machine learning practitioners that are not experts in the field. In this work we present a generic deep learning methodology that can be used for a wide range of multi-target prediction problems. We introduce a flexible multi-branch neural network architecture, partially configured via a questionnaire that helps end users to select a suitable MTP problem setting for their needs. Experimental results for a wide range of domains illustrate that the proposed methodology manifests a competitive performance compared to methods from specific MTP domains.",http://dx.doi.org/10.1007/s10994-021-06104-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-03982-3,Kubernetes in IT administration and serverless computing: An empirical study and research challenges,The Journal of Supercomputing,10.1007/s11227-021-03982-3,Springer,2022-02-01,"Today’s industry has gradually realized the importance of lifting efficiency and saving costs during the life-cycle of an application. In particular, we see that most of the cloud-based applications and services often consist of hundreds of micro-services; however, the traditional monolithic pattern is no longer suitable for today’s development life-cycle. This is due to the difficulties of maintenance, scale, load balance, and many other factors associated with it. Consequently, people switch their focus on containerization—a lightweight virtualization technology. The saving grace is that it can use machine resources more efficiently than the virtual machine (VM). In VM, a guest OS is required to simulate on the host machine, whereas containerization enables applications to share a common OS. Furthermore, containerization facilitates users to create, delete, or deploy containers effortlessly. In order to manipulate and manage the multiple containers, the leading Cloud providers introduced the container orchestration platforms, such as Kubernetes, Docker Swarm, Nomad, and many others. In this paper, a rigorous study on Kubernetes from an administrator’s perspective is conducted. In a later stage, serverless computing paradigm was redefined and integrated with Kubernetes to accelerate the development of software applications. Theoretical knowledge and experimental evaluation show that this novel approach can be accommodated by the developers to design software architecture and development more efficiently and effectively by minimizing the cost charged by public cloud providers (such as AWS, GCP, Azure). However, serverless functions are attached with several issues, such as security threats, cold start problem, inadequacy of function debugging, and many other. Consequently, the challenge is to find ways to address these issues. However, there are difficulties and hardships in addressing all the issues altogether. Respectively, in this paper, we simply narrow down our analysis toward the security aspects of serverless. In particular, we quantitatively measure the success probability of attack in serverless (using Attack Tree and Attack–Defense Tree ) with the possible attack scenarios and the related countermeasures. Thereafter, we show how the quantification can reflect toward the end-to-end security enhancement. In fine, this study concludes with research challenges such as the burdensome and error-prone steps of setting the platform, and investigating the existing security vulnerabilities of serverless computing, and possible future directions.",http://dx.doi.org/10.1007/s11227-021-03982-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12664-021-01234-z,"62nd Annual Conference of the Indian Society of Gastroenterology, February 10th – 13th, 2022, Pune",Indian Journal of Gastroenterology,10.1007/s12664-021-01234-z,Springer,2022-02-01,,http://dx.doi.org/10.1007/s12664-021-01234-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10270-021-00905-x,Recommender systems in model-driven engineering,Software and Systems Modeling,10.1007/s10270-021-00905-x,Springer,2022-02-01,"Recommender systems are information filtering systems used in many online applications like music and video broadcasting and e-commerce platforms. They are also increasingly being applied to facilitate software engineering activities. Following this trend, we are witnessing a growing research interest on recommendation approaches that assist with modelling tasks and model-based development processes. In this paper, we report on a systematic mapping review (based on the analysis of 66 papers) that classifies the existing research work on recommender systems for model-driven engineering (MDE). This study aims to serve as a guide for tool builders and researchers in understanding the MDE tasks that might be subject to recommendations, the applicable recommendation techniques and evaluation methods, and the open challenges and opportunities in this field of research.",http://dx.doi.org/10.1007/s10270-021-00905-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40031-021-00632-3,A Review on existing IoT Architecture and Communication Protocols used in Healthcare Monitoring System,Journal of The Institution of Engineers (India): Series B,10.1007/s40031-021-00632-3,Springer,2022-02-01,"Nowadays, due to modernization or advancement in the Internet of Things (IoT) especially in the Healthcare area, we want to take care of our elders with some monitoring equipment, and the Internet of Things can play a significant role in it. The motivation of writing this paper is to collect the information of various existing Internet of Things Architecture and Communication Techniques used in Healthcare Monitoring System to observe that how efficiently, different researchers have used it. So we have studied different real-time health monitoring system based on diseases which are common in elderly people like diabetes, blood pressure, heart disease, sleep apnea, and cancer, etc. In this real-time health monitoring system, researchers introduced many new measures, communication techniques like ZigBee, Long-Range Wide Area Network (LoRawan), Radio Frequency Identification (RFID). Apart from this, it was also observed that remote monitoring system in Healthcare is incomplete without data processing and early prediction in such diseases. Though, Machine learning provides efficient techniques to extract knowledge from diagnostic medical datasets collected from the patients. That is why we highlighted the current role of various Machine Learning algorithms like Support Vector Machine, K-Nearest Neighbor, Random Forest, etc., for processing of Healthcare data and also helpful to predict the output more precisely.",http://dx.doi.org/10.1007/s40031-021-00632-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-021-06147-9,Credit Card Fraud Detection by Modelling Behaviour Pattern using Hybrid Ensemble Model,Arabian Journal for Science and Engineering,10.1007/s13369-021-06147-9,Springer,2022-02-01,"The fraud detection system in banking organisation relies on data-driven approach to identify the fraudulent transactions. In real time, detection of each and every fraudulent transaction becomes a challenging task as financial institutions need aggressive jobs running on the log data to perform a data mining task. This paper introduces a novel model for credit card fraud detection which combines ensemble learning techniques such as boosting and bagging. Our model incorporates the key characteristics of both the techniques by building a hybrid model of bagging and boosting ensemble classifiers. Experimentation on Brazilian bank data and UCSD-FICO data with our model shows sturdiness over the state-of-the-art ones in detecting the unseen fraudulent transactions because the problem of data imbalance was handled by a hybrid strategy. The proposed method outperformed by a margin of 43.35–68.53, 0.695–11.67, 43.34–68.52, 42.57–67.75, 3.5–13.06, 24.58–34.35%, respectively, in terms of true positive rate, false positive rate, true negative rate, false negative rate, detection rate, accuracy and area under the curve from the state-of-the-art-techniques, with a Matthews correlation co-efficient of 1.00. At the same time, the current approach gives an improvement in the range of 0.6–24.74, 0.8–24.80, 10–17.00% in terms of false positive rate, true negative rate and Matthews correlation co-efficient respectively from the state-of-the-art techniques with detection rate of 0.6650 and accuracy of 99.18%, respectively.",http://dx.doi.org/10.1007/s13369-021-06147-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03436-8,Cost-aware job scheduling for cloud instances using deep reinforcement learning,Cluster Computing,10.1007/s10586-021-03436-8,Springer,2022-02-01,"As the services provided by cloud vendors are providing better performance, achieving auto-scaling, load-balancing, and optimized performance along with low infrastructure maintenance, more and more companies migrate their services to the cloud. Since the cloud workload is dynamic and complex, scheduling the jobs submitted by users in an effective way is proving to be a challenging task. Although a lot of advanced job scheduling approaches have been proposed in the past years, almost all of them are designed to handle batch jobs rather than real-time workloads, such as that user requests are submitted at any time with any amount of numbers. In this work, we have proposed a Deep Reinforcement Learning (DRL) based job scheduler that dispatches the jobs in real time to tackle this problem. Specifically, we focus on scheduling user requests in such a way as to provide the quality of service (QoS) to the end-user along with a significant reduction of the cost spent on the execution of jobs on the virtual instances. We have implemented our method by Deep Q-learning Network (DQN) model, and our experimental results demonstrate that our approach can significantly outperform the commonly used real-time scheduling algorithms.",http://dx.doi.org/10.1007/s10586-021-03436-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03431-z,Energy efficiency in cloud computing data center: a survey on hardware technologies,Cluster Computing,10.1007/s10586-021-03431-z,Springer,2022-02-01,"The internet is expanding its viewpoint into each conceivable part of the cutting-edge economy. Unshackled from our web programs today, the internet is characterizing our way of life, regardless of whether it's sitting in front of the TV or driving an independent auto. The enchantment of the internet appears to be relatively unbounded. In any case, with each new spell there comes an ever-increasing amount of data, and interest for computational power. Cloud computing which is an on-request conveyance of computing power, applications, database storage, and other IT assets by means of the Internet has violently expanded our computerized lives. Though, there have been critical improvements as far as accessibility, fluctuation, time and quality in administrations are concerned; the unbounded development of our computerized way of life requires monstrous measures of power, especially for the data centers that fill in as the mind of the advanced economy. Data organizations foresee a decrease in the quantity of data centers, as more businesses close their little data centers and move towards cloud computing. All things considered, the move by clients towards cloud, will increase the general energy utilization significantly, exceeding any energy productivity increase; which has recorded for over 70% of data center development in 2018. Many research advancements are already made in this domain for minimizing the energy utilization of the computing types of gear included; for efficient power energy consumption, decrease of carbon impression and e-squander. These procedures are supporters of green cloud computing, which are focused on planning and advancing energy-proficient activities to contain inordinate energy utilization in data centers. This paper discusses different mechanisms for lowering the power utilization in data centers. It provides in depth detail about the various mechanisms that can be employed at the hardware component level so that the utilization of energy by component can be reduced. Techniques that can be applied at network, cluster of servers’ level along with the various dynamic power management measures that can be employed at the hardware or firmware level and can lead to energy efficient or green data centers are also studied in detail. The paper concludes with the research challenges for building the green data centers.",http://dx.doi.org/10.1007/s10586-021-03431-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03403-3,Adaptive learning style prediction in e-learning environment using levy flight distribution based CNN model,Cluster Computing,10.1007/s10586-021-03403-3,Springer,2022-02-01,"A learning style that focuses on individual learning is one of the most important aspects of any learning environment. Each learner has a unique manner of understanding, retaining, processing, and interpreting new information based on their learning styles. The ability of an e-learning system to automatically determine a student's learning style has become more essential. For learning events, the evolution of e-learning platforms provides students with higher opportunities online. In this paper, we proposed a Convolutional Neural Network-based Levy Flight Distribution (CNN-LFD) algorithm for learning style prediction. An adaptive e-learning system is divided into two sections: automatic learning style prediction and classification based on the number of learning styles included. Initially, the student logs in with their user ID, and the data is saved in the database. The features such as questionnaire score, login credentials (session ID, learner ID, and course ID), and login time (location, session ID) are extracted along with the sequence of the user's learning behavior. After that, the CNN-LFD algorithm predicts the learning styles of the learners namely Active/reflective, Sensing/intuitive, visual/verbal, sequential/global based on the extracted features. The dataset information are gathered from a Massive Open Online Course (MOOC), and the proposed model is built in JAVA software. The experimental results demonstrate higher classification accuracy during learning style prediction. The proposed CNN-LFD algorithm accomplishes 97.09% accuracy, 94.76% specificity, 92.12% sensitivity, and 97.56%, precision values than other methods.",http://dx.doi.org/10.1007/s10586-021-03403-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-022-03695-2,GeoCredit: a novel fog assisted IoT based framework for credit risk assessment with behaviour scoring and geodemographic analysis,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-022-03695-2,Springer,2022-01-29,"Credit risk assessment is the most challenging issue in banks as bad loans apart from reducing profitability also possess risk to the economic growth. Traditional assessment models consider the static and demographic data to predict the likelihood of customer turning to bad debtors. This paper proposes a novel fog assisted IoT based three- tier framework for credit risk assessment that can be deployed for evaluating the risk of both existing borrowers and new applicants. The RFM (Recenecy, Frequency, Monetary) and behavioral data are captured through User Device layer. Real time behaviour score of existing borrowers is computed to find cluster of risky clients who are indulged in hefty spending and possess an unfavorable behaviour. Fog layer sends alert messages to high risky borrowers as well as to the dealing officers in banks. ASW (Average Silhouette Width) metric is utilized to assess quality of clusters. At the cloud layer, heat map analysis is performed to find risky geographical areas where majority of existing borrowers are prone to overspending propensity. The identified (risky/non-risky) region codes are augmented to the demographic details of new loan applicants to classify them as potential High risky/Moderate Risky/Low risky/No Risk. Experimental results reveal that the inclusion of region code enhances accuracy from 0.8867 to 0.9244. AUC (Area under curve) and other vital statistical measures are also elevated. Additionally, Gini Coefficient has been computed for measuring region wise disparity in income and expenditure.",http://dx.doi.org/10.1007/s12652-022-03695-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00778-021-00721-1,A survey on outlier explanations,The VLDB Journal,10.1007/s00778-021-00721-1,Springer,2022-01-26,"While many techniques for outlier detection have been proposed in the literature, the interpretation of detected outliers is often left to users. As a result, it is difficult for users to promptly take appropriate actions concerning the detected outliers. To lessen this difficulty, when outliers are identified, they should be presented together with their explanations. There are survey papers on outlier detection, but none exists for outlier explanations. To fill this gap, in this paper, we present a survey on outlier explanations in which meaningful knowledge is mined from anomalous data to explain them. We define different types of outlier explanations and discuss the challenges in generating each type. We review the existing outlier explanation techniques and discuss how they address the challenges. We also discuss the applications of outlier explanations and review the existing methods used to evaluate outlier explanations. Furthermore, we discuss possible future research directions.",http://dx.doi.org/10.1007/s00778-021-00721-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10922-021-09637-1,Detection and Management of P2P Traffic in Networks using Artificial Neural Networksa,Journal of Network and Systems Management,10.1007/s10922-021-09637-1,Springer,2022-01-20,"Peer-to-Peer (P2P) technology is a popular tool for sharing files and multimedia services on networks. While the technology has been serving a good purpose of facilitating sharing of large volumes of data on networks, in other aspects, it has also become a potential source through which attackers could ride on to launch various malicious attacks on the networks. In networks with limited bandwidth resources, uncontrolled P2P activities may also come with problems of congestion in such networks. As P2P continues to evolve on the internet in more complex forms, the need for dynamic mechanisms with the ability to learn the evolving P2P behavior will be essential for accurate monitoring and detection of the P2P traffic to minimize its effects on networks. Supervised machine learning classifiers have been used in recent times, as potential tools for monitoring and detection of the P2P traffic. Incidentally, the capabilities of such classifiers decline over time due to the changing dynamics of the P2P features, making it necessary for the classifiers to undergo continuous retraining in order to maintain their capability of providing effective detection of new P2P traffic features in real-time operations. This paper presents a hybrid machine-learning framework that combines the capabilities of self-organizing map (SOM) model with a multilayer perceptron (MLP) network to achieve real-time detection of P2P traffic in networks. The SOM model generates sets of clustered features contained in the traffic flows and organizes the features into P2P and non-P2P, which are used for training the MLP model for subsequent detection and control of the P2P traffic. The proposed P2P detection framework was tested using real traffic data from the University of Ghana campus network. The test results revealed an average detection rate of 99.89% of the observed instances of P2P traffic in the experimental data. The good detection rate from the detection framework suggests its capability to serve as a potential tool for dynamic monitoring, detection, and control of P2P traffic to manage bandwidth resources and isolation of undesirable P2P-driven traffic in networks.",http://dx.doi.org/10.1007/s10922-021-09637-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00778-021-00723-z,eRiskCom: an e-commerce risky community detection platform,The VLDB Journal,10.1007/s00778-021-00723-z,Springer,2022-01-17,"In e-commerce scenarios, frauds events such as telecom fraud, insurance fraud, and fraudulent transactions, bring a huge amount of loss to merchants or users. Identification of fraudsters helps regulators take measures for targeted control. Given a set of fraudsters and suspicious users observed from victims’ reports, how can we effectively distinguish risky users closely related to them from the others for further investigation by human experts? Fraudsters take camouflage actions to hide from being discovered; complex features on users are hard to deal with; patterns of fraudsters are sometimes difficult to explain by human knowledge; and real-world applications involve millions of users. All this makes the question hard to answer. To this end, we design eRiskCom, an e-commerce risky community detection platform to detect risky groups containing identified fraudsters and other closely related users. With the hypothesis that users who interact frequently with fraudsters are more likely to come from the same “risky community,” we construct a connected graph expanded from the identified fraudsters and suspicious users. Next, graph partition is employed to get knowledge of assignment of identified users to potential risky communities, followed by pruning to discover the core members of each community. Finally, top- K users with a high risk score in the neighborhood of core members of each potential community form a final risky community. The extensive experiments are conducted to analyze the effect of our platform components on the alignment with requirements of practical scenarios, and experimental results further demonstrate that eRiskCom is effective and easy to deploy for real-world applications.",http://dx.doi.org/10.1007/s00778-021-00723-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-022-01020-4,"Cybersecurity, Data Privacy and Blockchain: A Review",SN Computer Science,10.1007/s42979-022-01020-4,Nature,2022-01-12,"In this paper, we identify and review key challenges to bridge the knowledge-gap between SME’s, companies, organisations, businesses, government institutions and the general public in adopting, promoting and utilising Blockchain technology. The challenges indicated are Cybersecurity and Data privacy in this instance. Additional challenges are set out supported by literature, in researching data security management systems and legal frameworks to ascertaining the types and varieties of valid encryption, data acquisition, policy and outcomes under ISO 27001 and the General Data Protection Regulations. Blockchain, a revolutionary method of storage and immutability, provides a robust storage strategy, and when coupled with a Smart Contract, gives users the ability to form partnerships, share information and consent via a legally-based system of carrying out business transactions in a secure digital domain. Globally, ethical and legal challenges significantly differ; consent and trust in the public and private sectors in deploying such defensive data management strategies, is directly related to the accountability and transparency systems in place to deliver certainty and justice. Therefore, investment and research in these areas is crucial to establishing a dialogue between nations to include health, finance and market strategies that should encompass all levels of society. A framework is proposed with elements to include Big Data, Machine Learning and Visualisation methods and techniques. Through the literature we identify a system necessary in carrying out experiments to detect, capture, process and store data. This includes isolating packet data to inform levels of Cybersecurity and privacy-related activities, and ensuring transparency demonstrated in a secure, smart and effective manner.",http://dx.doi.org/10.1007/s42979-022-01020-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11704-020-0210-y,Efficient and stable quorum-based log replication and replay for modern cluster-databases,Frontiers of Computer Science,10.1007/s11704-020-0210-y,Springer,2022-01-09,"The modern in-memory database (IMDB) can support highly concurrent on-line transaction processing (OLTP) workloads and generate massive transactional logs per second. Quorum-based replication protocols such as Paxos or Raft have been widely used in the distributed databases to offer higher availability and fault-tolerance. However, it is non-trivial to replicate IMDB because high transaction rate has brought new challenges. First, the leader node in quorum replication should have adaptivity by considering various transaction arrival rates and the processing capability of follower nodes. Second, followers are required to replay logs to catch up the state of the leader in the highly concurrent setting to reduce visibility gap. Third, modern databases are often built with a cluster of commodity machines connected by low configuration networks, in which the network anomalies often happen. In this case, the performance would be significantly affected because the follower node falls into the long-duration exception handling process (e.g., fetch lost logs from the leader). To this end, we build QuorumX, an efficient and stable quorum-based replication framework for IMDB under heavy OLTP workloads. QuorumX combines critical path based batching and pipeline batching to provide an adaptive log propagation scheme to obtain a stable and high performance at various settings. Further, we propose a safe and coordination-free log replay scheme to minimize the visibility gap between the leader and follower IMDBs. We further carefully design the process for the follower node in order to alleviate the influence of the unreliable network on the replication performance. Our evaluation results with the YCSB, TPC-C and a realistic microbenchmark demonstrate that QuorumX achieves the performance close to asynchronous primary-backup replication and could always provide a stable service with data consistency and a low-level visibility gap.",http://dx.doi.org/10.1007/s11704-020-0210-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11334-021-00428-0,A Black Swan event-based hybrid model for Indian stock markets’ trends prediction,Innovations in Systems and Software Engineering,10.1007/s11334-021-00428-0,Springer,2022-01-07,"Among all the application areas of the time-series prediction, stock market prediction is the most challenging task due to its dynamic nature, and dependency on many volatile factors. The unpredictable fatal events called Black Swan events also highly influence the stock market. If the successful stock trends prediction is achieved, then the investors can adopt a more appropriate trading strategy, and that can significantly reduce the risk of investment. In this work, a time-efficient hybrid stock trends prediction framework(HSTPF) is proposed to successfully predict the future trends of the stock market even during the periods of Black Swan events. Here, to improve the prediction accuracy of HSTPF, the Black Swan events analysis and features selection operations are performed, and also the performance of various machine learning classifiers are analyzed. A vast number of experiments are conducted on the two real-world stock market datasets S&P BSE SENSEX and Nifty 50, to analyze the performance of the proposed framework. The framework is applied for the single-step and multi-step ahead predictions. The experimental results show that the proposed framework produces over 86% of accuracy, and during the Black Swan events, its accuracy is almost 80% for single-step ahead predictions. For the multi-step ahead of predictions, the HSTPF is produced satisfactory results. The framework also outperforms other existing similar works even during the Black Swan events in terms of prediction accuracy, and its computational time is also very low.",http://dx.doi.org/10.1007/s11334-021-00428-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87790-3_9,Advanced IDSS Topics and Applications,Intelligent Decision Support Systems,10.1007/978-3-030-87790-3_9,Springer,2022-01-01,"In this chapter, some advanced topics in IDSSs and a specific application in the IDSS field are presented. The advanced topics analyzed are the Uncertainty Management problem, the Temporal Reasoning aspects and the Spatial Reasoning management. The advanced application of Intelligent Decision Support Systems is the so-called Recommender Systems . First, the different Uncertainty models proposed in the scientific community are presented. Afterwards, some models are analyzed like the Pure Probabilistic model, the Certainty Factor model, the Bayesian Network model, and the Fuzzy Set Theory / Possibilistic model. Next, the Temporal Reasoning problem is described and some approaches to cope with it are described in detail such as the Dynamic Bayesian Networks ( DBN ), some Temporal Artificial Neural Networks , some Temporal Case-Based Reasoning approaches, and some Incremental Machine Learning techniques, or Data Stream Mining methods. The last advanced topic is the Spatial Reasoning , where the general problem is characterized and most common frameworks both to spatial representation and spatial reasoning are analyszed. In the last subsection, Geographic Information Systems are briefly described. Finally, the last section is devoted to Recommender Systems , a popular application of IDSS to recommend the most useful items to users in a concrete system. Once the general problem of recommendation is formulated, the general architecture of a Recommender System is explained. In addition, the most common recommendation techniques are reviewed, the usual evaluation techniques are described, and some known applications are briefly analyzed. The last part is devoted to explain some trends in Recommender Systems which are currently being addressed by several researchers.",http://dx.doi.org/10.1007/978-3-030-87790-3_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-07127-0_2,Emerging Technologies,Emerging Technologies,10.1007/978-3-031-07127-0_2,Springer,2022-01-01,"This chapter presents brief descriptions and working principles of 34 emerging technologies Emerging technologies which have market diffusion and are commercially available. Emerging technologies Emerging technologies are the ones whose development and application areas are still expanding fast, and their technical and value potential is still largely unrealised. In alphabetical order, the emerging technologies Emerging technologies that we list in this chapter are 3D printing, 5G, advanced materials, artificial intelligence, autonomous things, big data, biometrics, bioplastics, biotech and biomanufacturing, blockchain, carbon capture and storage, cellular agriculture, cloud computing, crowdfunding, cybersecurity, datahubs, digital twins, distributed computing, drones, edge computing, energy storage, flexible electronics and wearables, healthcare analytics, hydrogen, Internet of Behaviours, Internet of Things, natural language processing, quantum computing, recycling, robotic process automation, robotics, soilless farming, spatial computing and wireless power transfer.",http://dx.doi.org/10.1007/978-3-031-07127-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87059-1_4,The Role of Machine Learning Techniques in Internet of Things-Based Cloud Applications,Artificial Intelligence-based Internet of Things Systems,10.1007/978-3-030-87059-1_4,Springer,2022-01-01,"Today’s Machine Learning (ML) in a blend with Internet of Things (IoT)-based cloud applications plays a significant role in our everyday life. As indicated by Gartner’s recent study, there are around 25 billion devices and a gadget interfacing with IoT including wearables and automated vehicles to smart homes and smart cities applications. All such connected (smart) devices generate immense data that needs to be examined and analysed, to ensure that they continually learn from the available datasets and better themselves without any manual interference. This is where the prerequisite for machine learning comes into being. Several ML algorithms and techniques are introduced in a short time to easily evaluate big data measurements, increasing the IoT’s productivity. Similarly, special ML techniques, such as decision trees, clustering and neural and Bayesian networks, allow devices and gadgets to discern trends from various sources in different kinds of datasets and take appropriate decisions based on their analysis. It would really be difficult for smart devices to make smart decisions gradually without including and enforcing ML. The IoT helps to interconnect various hardware devices, such as houses, cars, electronic gadgets and other devices that are integrated with actuators, sensors and software, so that data can be collected and shared. As various organizations understand the progressive capability of the IoT, they have begun finding various obstructions they have to deliver to use it productively. Numerous organizations and businesses use ML to exploit the IoT’s latent capacity. This chapter evaluates the different methods of machine learning that deal with the challenges posed in the handling of IoT data. Note that this big data is generated through the communication of Internet of Things/smart devices, and this data stored at cloud. The taxonomy of machine learning algorithms is described in this chapter, explaining how different techniques are applied to data generated using IoT devices. It will also address the future problems of machine learning for IoT data analytics.",http://dx.doi.org/10.1007/978-3-030-87059-1_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-6265-523-2_3,Disciplines of AI: An Overview of Approaches and Techniques,Law and Artificial Intelligence,10.1007/978-94-6265-523-2_3,Springer,2022-01-01,"This chapter provides an introduction to AI for people without a background in technology. After examining different definitions of AI Definitions of AI and a discussion of the scope of the concept AI, five different disciplines of AI are discussed: Machine Learning Machine learning , Automated Reasoning Automated reasoning , Computer Vision Computer vision , Affective Computing Affective computing and Natural Language Processing Natural language processing . For each discipline of AI, approaches and techniques are discussed.",http://dx.doi.org/10.1007/978-94-6265-523-2_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_8,Session-Based Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_8,Springer,2022-01-01,"Session-based recommendation is concerned with the problem of tailoring item suggestions according to the short-term needs and assumed intents of the user. The input in this recommendation scenario consists of an often very short sequence of user interactions that are observed in an ongoing usage session, and in many cases longer-term preferences of the users are not available. Such problems are highly relevant in practice because (i) recommendations should often be made also to anonymous and first-time users and because (ii) the users’ intents can change from session to session. In this chapter, we first elaborate on practical application scenarios for session-based recommender systems, provide a characterization of the problem class, and outline key challenges. Afterwards, we review technical approaches to session-based recommendation and report common practices of evaluating such systems. The chapter ends with a discussion of open challenges and an outlook on future directions in the area.",http://dx.doi.org/10.1007/978-1-0716-2197-4_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_14,Value and Impact of Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_14,Springer,2022-01-01,"Recommender systems are an integral part of many of today’s major web sites and online services and they widely exert their influence on which content users come across in the online world. From an organizational and economic perspective, recommender systems are designed to increase the quality of matches between users and items or content and this way create value for the different stakeholders. They do so, for instance, by reducing consumers’ information overload or by helping to improve business-oriented performance indicators. However, notwithstanding of the actual achievement of concrete goals or targets, recommender systems have an impact on users’ choice behavior as a matter of principle. In this chapter, we first review the various ways recommender systems create value for different stakeholders and also discuss the possible risks and the potentially negative impacts of using such systems. We particularly focus on the organizational and business-oriented perspective by reporting how practical systems are evaluated and which effects have been observed in real-world deployments. In the final section of this chapter we discuss the limitations of academic research practices and emphasize the need to expand our research approaches to be able to address problems that are highly relevant in practice but still underexplored in academia.",http://dx.doi.org/10.1007/978-1-0716-2197-4_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88241-9_3,"The Impact of AI on Business, Economics and Innovation",Artificial Intelligence for Business,10.1007/978-3-030-88241-9_3,Springer,2022-01-01,"This chapter, based on previous bibliographic review, offers guidance from consultants as well as prior identification of documented professional practices about the current overall impact of Artificial Intelligence (AI) in business, economics and innovation. Consequently, this chapter discusses the role of AI in the future economy considering increases in productivity, innovation and technological maturity. Consequently, attention shall be paid to business-oriented design, AI tools for business processes modelling and the benefits of AI technologies. It will also be shown how business leaders can remain competitive in the new economic environment, developing the required skills for understanding the economic implications of AI, considering the changes that businesses will need to do to address the economic and social implications of large-scale applications of AI. In addition, we highlight the importance; benefits and applications of Machine Learning in business shall be applied. Finally, the conclusions propose a future research agenda for AI for certain industries (Strategy, Relationship Marketing, Servicescape, Customer acceptance, Social acceptance, Management, Workforce and Transhumanism).",http://dx.doi.org/10.1007/978-3-030-88241-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96296-8_12,Customer Journey: Applications of AI and Machine Learning in E-Commerce,"New Realities, Mobile Systems and Applications",10.1007/978-3-030-96296-8_12,Springer,2022-01-01,"In the past decade, ownership and usage of mobile devices has grown in a rapid manner, with users putting trust into these devices for online purchases. Corporations like Booking are reporting a higher number of interactions through mobile devices than on desktops, making these an important medium for online advertising and recommendations used by e-commerce applications. Coupled with the recent advances in artificial intelligence systems and machine learning algorithms, we aim to explore how these developments in the field affect the customer’s journey, taking into account the aforementioned trends, as well as the personal user data that these may require to provide proper results. In this manner, we conduct a systematic literature review, using a transparent and thorough process for searching and analysing the recent bibliography, over the last couple of years, focused on intelligent applications in the customer journey.",http://dx.doi.org/10.1007/978-3-030-96296-8_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-020-03620-w,"Transforming business using digital innovations: the application of AI, blockchain, cloud and data analytics",Annals of Operations Research,10.1007/s10479-020-03620-w,Springer,2022-01-01,"This study explores digital business transformation through the lens of four emerging technology fields: artificial intelligence, blockchain, cloud and data analytics (i.e., ABCD). Specifically, the study investigates the operations and value propositions of these distinct but increasingly converging technologies. Due to the dynamic nature of innovation, the potential of this ABCD hybridization, integration, recombination and convergence has yet to be considered. Using a multidisciplinary approach, the findings of the study show wide-reaching and diverse applications among a variety of vertical sectors, presenting exploratory research avenues for future investigation. The study also highlights the practical implications of these new technologies.",http://dx.doi.org/10.1007/s10479-020-03620-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88678-3_12,"The Future of Marketing: Artificial Intelligence, Virtual Reality, and Neuromarketing",Marketing Communications and Brand Development in Emerging Economies Volume I,10.1007/978-3-030-88678-3_12,Springer,2022-01-01,"The emergence of new technologies is influencing marketing research and business decisions. Specifically, artificial intelligence (AI), virtual reality (VR), and neuropsychological tools are changing the way we collect, store, and analyse marketing data. To realise the benefits of these technologies, which have implications for marketing communications as they facilitate the in-depth understanding of consumer experience, strategic and proactive orientations are required. To this end, this chapter reviews extant literature on AI, VR, and neuromarketing, providing guidance on how future marketing decisions will be made through leveraging these new technology-based tools. With its increasing computer power, AI will support broad marketing applications, such as analysis and targeting of customers for effective decision-making. VR can enhance a customer’s experience through the purchase journey, thus providing ample opportunities for marketers to utilise innovative marketing campaigns. Neuromarketing can capture tacit cognitive and emotional responses to marketing stimuli and enable informed forecasting of consumers’ purchase decisions.",http://dx.doi.org/10.1007/978-3-030-88678-3_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-12597-3_15,Multi-objective Hybrid Autoscaling of Microservices in Kubernetes Clusters,Euro-Par 2022: Parallel Processing,10.1007/978-3-031-12597-3_15,Springer,2022-01-01,"The cloud community has accepted microservices as the dominant architecture for implementing cloud native applications. To efficiently execute microservice-based applications, application owners need to carefully scale the required resources, considering the dynamic workload of individual microservices. The complexity of resource provisioning for such applications highlights the crucial role of autoscaling mechanisms. Kubernetes, the common orchestration framework for microservice-based applications, mainly proposes a horizontal pod autoscaling (HPA) mechanism, which, however, lacks efficiency. To hinder resource wastage and still achieve the requested average response time of microservices, we propose a multi-objective autoscaling mechanism. Based on machine learning techniques, we introduce a toolchain for hybrid autoscaling of microservices in Kubernetes. Comparing several machine learning techniques and also our in-house performance modeling tool, called Extra-P, we propose the most adequate model for solving the problem. Our extensive evaluation on a real-world benchmark application shows a significant reduction of resource consumption while still meeting the average response time specified by the user, which outperforms the results of common HPA in Kubernetes.",http://dx.doi.org/10.1007/978-3-031-12597-3_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88181-8_9,Enabling Technologies of Data-Driven Engineering Design,Data-Driven Engineering Design,10.1007/978-3-030-88181-8_9,Springer,2022-01-01,"This chapter presents a collection of specific technologies that can collectively enable data-driven engineering design. The enabling technologies include sensors, Internet and mobile Internet, Internet of Things, cloud computing, edge computing, blockchain, machine learning, artificial intelligence, big data analytics, virtual reality and augmented reality, digital twin, and so forth. These enabling technologies are presented in correspondence to relevant data operations such as data collection, transmission, computation, analysis, security, and cyber-physical integration. The enabling technologies can be integrated, either vertically or horizontally, towards an integrated system of systems. Multiple specific applications of these enabling technologies are presented as illustrative examples.",http://dx.doi.org/10.1007/978-3-030-88181-8_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6166-2_9,Heterogeneous Graph Representation for Industry Application,Heterogeneous Graph Representation Learning and Applications,10.1007/978-981-16-6166-2_9,Springer,2022-01-01,"Heterogeneous graph (HG) representation is closely related with the real-world applications, as heterogeneous objects and interactions are ubiquitous in many practical systems. HG representation methods deployed in real-world system should consider capturing the complex interactions among objects as well as solving the unique challenges existing in real-world systems, such as large-scale, dynamics, and multi-source information. In this chapter, we focus on summarizing the industrial-level applications with HG representation. Particularly, we introduce several well deployed systems that have demonstrated the success of HG representation techniques in resolving real-world applications, including cash-out user detection, intent recommendation, share recommendation, and friend-enhanced recommendation. For industrial-level applications, we pay more attention on two key components: HG construction with industrial data and graph representation techniques on the HG.",http://dx.doi.org/10.1007/978-981-16-6166-2_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_5,Deep Learning for Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_5,Springer,2022-01-01,"Deep neural networks have been serving as the main driving force for the emergence of cutting-edge applications in many areas including computer vision, speech recognition, natural language processing, etc. In the meantime, deep neural networks based recommender systems have demonstrated impressive abilities in performance improvements, and have led to breakthroughs in some largely underexplored tasks. Examples are recommender systems with integrated multimodal/unstructured data and temporal dynamics. This chapter provides an overview of deep neural networks based recommender systems, with two aims. One is to explain how deep neural networks can be applied to recommendation tasks and the other is to review the recent progress in this field. Specifically, we begin with basic concepts and terminologies about deep neural networks and how they are applied to recommender systems. We then present an overview of the state-of-the-art deep learning based recommendation algorithms, and discuss their strengths and limitations. Finally, we provide an outlook on the future trends and directions which might lead to the next generation of recommender systems.",http://dx.doi.org/10.1007/978-1-0716-2197-4_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-020-03856-6,Artificial intelligence for decision support systems in the field of operations research: review and future scope of research,Annals of Operations Research,10.1007/s10479-020-03856-6,Springer,2022-01-01,"Operations research (OR) has been at the core of decision making since World War II, and today, business interactions on different platforms have changed business dynamics, introducing a high degree of uncertainty. To have a sustainable vision of their business, firms need to have a suitable decision-making process at each stage, including minute details. Our study reviews and investigates the existing research in the field of decision support systems (DSSs) and how artificial intelligence (AI) capabilities have been integrated into OR. The findings of our review show how AI has contributed to decision making in the operations research field. This review presents synergies, differences, and overlaps in AI, DSSs, and OR. Furthermore, a clarification of the literature based on the approaches adopted to develop the DSS is presented along with the underlying theories. The classification has been primarily divided into two categories, i.e. theory building and application-based approaches, along with taxonomies based on the AI, DSS, and OR areas. In this review, past studies were calibrated according to prognostic capability, exploitation of large data sets, number of factors considered, development of learning capability, and validation in the decision-making framework. This paper presents gaps and future research opportunities concerning prediction and learning, decision making and optimization in view of intelligent decision making in today’s era of uncertainty. The theoretical and managerial implications are set forth in the discussion section justifying the research questions.",http://dx.doi.org/10.1007/s10479-020-03856-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-03918-8_11,Artificial Intelligence Based Solutions to Smart Warehouse Development: A Conceptual Framework,The 8th International Conference on Advanced Machine Learning and Technologies and Applications (AMLTA2022),10.1007/978-3-031-03918-8_11,Springer,2022-01-01,"Responding to the vital role and robust development of smart warehouses, in this study, solutions for applying Artificial Intelligence (AI) to smart warehouse development, especially in Vietnam, were analyzed and proposed. The paper has investigated the factors affecting the application of AI for smart warehouse development in Vietnam through SWOT. Solution groups include (1) Investment decision support solutions that limit investment risks through solutions to test innovative approaches and algorithms, (2) Solutions for AI application in smart warehouse development, (3) Solutions to develop AI resources for smart warehouses. Therefore, by using SWOT analysis, this paper aims to generate value strategies AI-based solutions for the smart warehouse to improve the warehouse process efficiencies and strengthen the competitive advantage of the logistics industry in Vietnam.",http://dx.doi.org/10.1007/978-3-031-03918-8_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97719-1_1,"An Approach to the Morphological Quality of Fruits with Applying Deep Learning, A Lustrum of Analysis","Advances and Applications in Computer Science, Electronics, and Industrial Engineering",10.1007/978-3-030-97719-1_1,Springer,2022-01-01,"The agricultural sector plays a key role in current development. The task of fruit classification is vital in the agricultural industry since the current market demands high quality standards in its products. However, the fruit grading adopted by the operating personnel is inefficient, labor intensive and error prone. An automatic classification system with optical image processing helps to analyze images and videos to obtain the valuable information. Thus, this document proposes a review of recent technologies and the theoretical concept that explains the development of artificial vision applying deep learning.",http://dx.doi.org/10.1007/978-3-030-97719-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-95419-2_12,"Recent Advancement and Challenges in Deep Learning, Big Data in Bioinformatics",Blockchain and Deep Learning,10.1007/978-3-030-95419-2_12,Springer,2022-01-01,"More data have been produced in recent years than in the thousands of years of human history. This data represents an important gold mine for policymakers in terms of commercial value and reference material. But much of this value is untapped, worse, wrongly comprehended as long as it is impossible to use the tools needed to process the stunning amount of information. In this book chapter, we will examine how machine learning can give us a glimpse of the patterns in Big Data and obtain key information in all fields of biology, healthcare. An analysis, ineffectiveness storage, and depth of learning algorithms in this field are essential to the electronic equipment which generates an anonymous scale of data referring to diversity and veracity. The architecture of Hadoop-based maps and deep learning algorithms like Convolutional Neural Network, Recurrent Neural Network have transformed the way we analyze massive data. The role, impact, and prospect of deep learning algorithms, reinforcement learning to manage big data in the area of bioinformatics, computer aided drug design, structural biology and computational biology are discussed in this book chapter. In last section author has discussed about the role of deep learning in next generation sequencing, biomedical image processing and drug discovery and molecular modelling and dynamics studies.",http://dx.doi.org/10.1007/978-3-030-95419-2_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-89822-9_74-1,Big Data Applications in Supply Chain Management,The Palgrave Handbook of Supply Chain Management,10.1007/978-3-030-89822-9_74-1,Springer,2022-01-01,"This chapter overviews emerging applications of big data analytics in supply chain management. The academic attention on big data applications and their practitioner uptake is growing. Many recent papers showcase descriptive, predictive, and prescriptive analytics applications where multiple benefits emerge from applying big data analytics to managerial problems. Such benefits include cost reduction, increases in revenues and profits, and minimization of the environmental impact of operations. Current concerns include the transition from traditional to digital supply chains and what can realistically be achieved over the next two decades. While we evidence excellent applications of big data analytics for supply chain planning and management problems, the issue of working in silos persists. For an organization to fully exploit big data applications, data should be perceived as an asset. When deploying novel artificial intelligence algorithms, the explainability of these algorithms should be at the forefront of an implementation strategy. Future research directions should be aimed at devising a connected and coordinated analytics approach that will enable the benefits of big data applications to go beyond what is currently realized.",http://dx.doi.org/10.1007/978-3-030-89822-9_74-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85626-7_18,Evaluation of Neural Fuzzy Inference System and ML Algorithms for Prediction of Nifty Large Cap Companies Based Stock Values,Intelligent and Fuzzy Techniques for Emerging Conditions and Digital Transformation,10.1007/978-3-030-85626-7_18,Springer,2022-01-01,"In this paper, we will evaluate the performance of five machine learning algorithms on large cap ten NIFTY50 companies. Author has implied a 10 year historical dataset that is utilized from yahoo finance and implemented using tensor flow application in google collaborator. Meanwhile, it is very uncertain to refrain from the findings of the concurrent studies to the real–world investing strategies due to lack of predictable results. This paper elaborates the attempt to measure the performance of neural fuzzy inference systems along with five different machine learning algorithms for a 10 year dataset. Several models developed on machine learning concepts were evaluated on a short term dataset that imparted very limited value of prediction accuracy. According to latest research advancement, most researchers focused on in-depth involvement of Machine learning algorithms to elaborate about future stock decisions. The experimental results show that Decision trees algorithm has highest prediction accuracy as compared to other Machine learning Algorithms [ 8 ] Neural Fuzzy Inference System.",http://dx.doi.org/10.1007/978-3-030-85626-7_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_6,Context-Aware Recommender Systems: From Foundations to Recent Developments,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_6,Springer,2022-01-01,"The importance of contextual information has been recognized by researchers and practitioners in many disciplines, including e-commerce, personalization, information retrieval, ubiquitous and mobile computing, data mining, marketing, and management. Prior work has extensively demonstrated that relevant contextual information does matter in recommender systems and that it is important to take this information into account when providing recommendations. We discuss the general notion of context and major approaches to modeling it in recommender systems, including explicit vs. latent and static vs. dynamic approaches. We also discuss three popular algorithmic paradigms—contextual pre-filtering, post-filtering, and modeling—for incorporating contextual information into the recommendation process, and survey the recent advances in contextual modeling that include tensor factorization, deep learning, and reinforcement learning techniques. We also discuss important directions for future research.",http://dx.doi.org/10.1007/978-1-0716-2197-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2422-3_54,Hybrid Prediction Model for the Success of Bank Telemarketing,Intelligent Sustainable Systems,10.1007/978-981-16-2422-3_54,Springer,2022-01-01,"Telemarketing is a technique or system of direct marketing, wherein a businessperson interacts with clients to persuade them to purchase or avail the products and facilities, either by connecting via telephone or through in-person interaction. In the present-day generation, with the humongous acceptance of cellular phones telemarketing has gained popularity as an efficient mode of marketing. In the banking domain, telemarketing is the prime support system to exchange goods and services. Banking products and services promotion to increase the business requires a comprehensive understanding of current market information and the actual client expectations. The present work has investigated traditional data mining and classification approaches which are less accurate. They could not achieve a high customer conversion rate with direct marketing campaigns. The proposed work recommends a machine learning method to foreshow the accomplishments of telemarketing requests for contracting bank term deposits. A Portuguese bank was tagged, considering the impacts of the present economic crisis. The comprehensive set of features linked with bank customer, products and services were inspected. A discussion on four machine learning (ML) models is performed along with the hybrid model, logistic regression ML model (LR), naive Bayes ML model (NB), decision trees ML model (DTs) and support vector machine ML model (SVM). The four ML models were tested and analysed with the proposed hybrid machine learning method (artificial neural network + extreme gradient boosting). The proposed hybrid machine learning method demonstrates the best results.",http://dx.doi.org/10.1007/978-981-16-2422-3_54,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75123-4_12,Smartphone-Based Lifelogging: Toward Realization of Personal Big Data,Information and Knowledge in Internet of Things,10.1007/978-3-030-75123-4_12,Springer,2022-01-01,"The technological advancements have turned smartphones into powerful lifelogging devices. Smartphone-based lifelogging system captures and stores information about peoples’ daily life activities, behaviors, interactions, and contexts into rich personal big data archives. The personal big data is of potential interest to the information sciences researchers and policy and decision makers in governments and organizations because of the availability of information, which would be impossible otherwise. Despite its potential, the smartphone-based lifelogging has been limitedly been explored from the big data perspective. This paper aims to provide a close-up view of the smartphone-based lifelogging as the source of personal big data. First, the smartphone-based lifelogging is reviewed to demonstrate its technological capabilities for personal big data generation and conformance to big data characteristics, alongside key personal big data applications. Second, a generalized architecture is presented for smartphone-based lifelog personal big data systems using big data systems design principals to advance the research in this space. Third, several challenges are highlighted regarding data capture, storage, analysis, visualization, privacy, and security. To address these concerns, several recommendations are suggested to improve personal big data generation, management, and usability.",http://dx.doi.org/10.1007/978-3-030-75123-4_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_1,"Recommender Systems: Techniques, Applications, and Challenges",Recommender Systems Handbook,10.1007/978-1-0716-2197-4_1,Springer,2022-01-01,"Recommender systems (RSs) are software tools and techniques that provide suggestions for items that are most likely of interest to a particular user. In this introductory chapter, we briefly discuss basic RS ideas and concepts. Our main goal is to delineate, in a coherent and structured way, the chapters in this handbook. Additionally, we aim to help the reader navigate the rich and detailed content that this handbook offers.",http://dx.doi.org/10.1007/978-1-0716-2197-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5652-1_6,Building an Enterprise Data Lake for Educational Organizations for Prediction Analytics Using Deep Learning,"Proceedings of International Conference on Deep Learning, Computing and Intelligence",10.1007/978-981-16-5652-1_6,Springer,2022-01-01,"Nowadays, educational institutions are one of the biggest producers of data. The rise of e-Learning contents, digital libraries, webinars, learning management systems, online classes and examinations, video surveillance, sensors, and wearables devices contribute to this data explosion. Learning management systems can index millions of students’ data, their interactions, course registrations, social networks, and their Internet research results. Besides, the potential to learn from this population-scale data is massive. By building analytic dashboards using machine learning and deep learning approaches on these datasets, educational organizations can improve the learning experience, teaching skills, and learning environment and drive better teaching and learning outcomes. Some real-world examples are students’ dropouts, students’ behavior, employee and student's health, prevention fraud data and abuse, etc. In present legacy systems, the data silos from the data warehouse could not handle unstructured data. It increases the complexity and cost of transferring data between multiple disparate data systems. Also, there is a performance bottleneck with data throughput while managing multiple data copies in different locations. This paper aims to store all educational data in a central location and handle all structured and unstructured data without any performance bottlenecks. It is proposed to design an enterprise data lake solution for academic organizations using deep learning to predict the outcomes.",http://dx.doi.org/10.1007/978-981-16-5652-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-64378-5_3,Technology Perspective,Handbook Digital Farming,10.1007/978-3-662-64378-5_3,Springer,2022-01-01,"This chapter starts with a perspective on how the efficient system engineering for automation and autonomous machines will change in the future into the direction of highly automated, flexible equipment systems. It explains various Precision Farming technologies and application scenarios. Further, it highlights the current state of the art and specific challenges of safe object detection and how such systems can be engineered. To address interoperability for Digital Farming solutions, a reference architecture on how to achieve better interoperability is presented. The use of AI in agriculture is outlined by sketching technology and key application scenarios. A view on data sharing in agriculture and relevant technologies such as ontologies and terminologies for describing the data is given. We highlight the role of geo-based data and its farm-specific integration. In the end, a comprehensive outlook on technology developments in various technological areas is provided.",http://dx.doi.org/10.1007/978-3-662-64378-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_29-1,Data Mining and Predictive Analytics for E-tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_29-1,Springer,2022-01-01,"Computers and devices, today ubiquitous in our daily life, foster the generation of vast amounts of data. Turning data into information and knowledge is the core of data mining and predictive analytics. Data mining uses machine learning, statistics, data visualization, databases, and other computer science methods to find patterns in data and extract knowledge from information. While data mining is usually associated with causal-explanatory statistical modeling, predictive analytics is associated with empirical prediction modeling, including the assessment of the quality of the prediction. This chapter intends to offer the readers, even those unfamiliar with this topic, a general overview of the key concepts and potential applications of data mining and predictive analytics and to help them to successfully apply e-tourism concepts in their research projects. As such, the chapter presents the fundamentals and common definitions of/in data mining and predictive analytics, including the types of problems to which it can be applied and the most common methods and techniques employed. The chapter also explains what is known as the life cycle of data mining and predictive analytics projects, describing the tasks that compose the most widely employed process model, both for industry and academia: the Cross-Industry Standard Process for Data Mining, CRISP-DM.",http://dx.doi.org/10.1007/978-3-030-05324-6_29-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-3398-0_18,Deep Learning Techniques for Social Media Analytics,Principles of Social Networking,10.1007/978-981-16-3398-0_18,Springer,2022-01-01,"Machine learning has seized both academia and industry's attention as deep learning (DL) is the frontrunner in data science. In order to construct computational models, DL uses multiple layers to epitomize data theories. A few of the key DL techniques, such as model transfer (MT), convolutional neural networks (CNN), and generative adversarial networks (GAN), have completely altered our understanding of information processing. Indeed, DL's processing power while handling images, text, and speech is truly remarkable. Because of the rapid growth and extensive availability of digitized social media (SM), evaluating these data by employing conventional technologies and tools is complex and unmanageable. These challenges are expected to be well managed through solutions offered by DL methods. Hence, we consider the executed DL methods built-in regard to social media analytics (SMA). However, rather than engaging in technical details, we study domains that pose serious challenges to SM where DL is involved and propose solutions to those challenges. We also present a few case studies.",http://dx.doi.org/10.1007/978-981-16-3398-0_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05544-7_5,Leveraging Human and Machine Capabilities for Analyzing Citizen Contributions in Participatory Urban Planning and Development: A Design-Oriented Approach,"HCI in Business, Government and Organizations",10.1007/978-3-031-05544-7_5,Springer,2022-01-01,"Local authorities are increasingly using online platforms as a means of involving citizens in urban planning and development. However, they encounter several challenges in the analysis and further processing of citizen-generated data when participation occurs on a large scale. Manual evaluation in particular takes individuals to their limits and hampers value extraction, e.g., for better planning and decision-making. To address these challenges, this paper presents a concept and design guidance based on elicited design requirements of an intelligent system that augments officials in data analytical tasks. Therefore, we focus on a hybrid solution to combine the respective strengths of humans and machines in data processing to mutually overcome their respective weaknesses. Particularly, our solution approach integrates human knowledge in the training process for machine learning via a Human-in-the-Loop strategy and simultaneously facilitates participation data analysis performed by officials. Promising initial evaluation results of the prototype indicate the usefulness of the approach.",http://dx.doi.org/10.1007/978-3-031-05544-7_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05643-7_23,A Systematic Review of Artificial Intelligence and Mental Health in the Context of Social Media,Artificial Intelligence in HCI,10.1007/978-3-031-05643-7_23,Springer,2022-01-01,"Objective: We conducted a systematic review on the use of Artificial Intelligence (AI) in the psychology domain within the context of social media’s role on mental health. We identified the types of mental health studies that AI has supported, reviewed the machine learning methods in these studies, and reported on the different approaches for data collection. We provided a critical review of the applicability of these methods in real-world settings. Finally, we discussed the challenges faced in this area of study and provided advice for other researchers interested in solving these issues in the future. Methods: We collected our data from three outlets: ACM, JMIR, and CLPsych. We focused on the studies on the application of AI in clinical psychology in the past six years (2016 to 2021). Results: A total of 37 articles were included in our study for further review. The number of publications increased over time. While CLPsych has the highest number of articles, Reddit was the commonly used social media site for data collection. Suicide was the most mentioned mental disorder mentioned in the studies. SVM was the most frequently used approach when applying AI in mental health studies. Conclusion: Our review of the existing literature identified three issues on the topic. First, social media is underutilized for mental health care. Second, there is a lack of collaboration between seemingly disconnected research communities: i.e., machine learning experts and clinicians. Third, little attention is paid to humans when conducting the research.",http://dx.doi.org/10.1007/978-3-031-05643-7_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6166-2_11,Future Research Directions,Heterogeneous Graph Representation Learning and Applications,10.1007/978-981-16-6166-2_11,Springer,2022-01-01,"Heterogeneous graph (HG) representation has made great progress in recent years, which clearly shows that it is a powerful and promising graph analysis paradigm. However, it is still a young and promising research field. In this chapter, we first make a summarization of this book and then illustrate some advanced topics, including challenging research issues, and explore a series of possible future research directions. One major potential direction is exploring fundamental ways to keep intrinsic structures or properties in HG. And another direction is to integrate the techniques widely used or newly emerged in machine learning to further enhance the applicability of HG on more key fields. We will illustrate more fine-grained potential works along with these two directions.",http://dx.doi.org/10.1007/978-981-16-6166-2_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98167-9_7,Social Economic Impacts for Covid-19 Pandemics Using Machine Learning Based Optimization Algorithm,How COVID-19 is Accelerating the Digital Revolution,10.1007/978-3-030-98167-9_7,Springer,2022-01-01,"As the number of COVID-19 patients grows exponentially, not all cases are likely dealt with by doctors and medical professionals. Researchers will add to the fight against COVID-19 by developing smarter strategies to achieve accelerated control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), virus that causes disease. Proposed method suggests best ways to optimize protection and avoid COVID-19 spread. Big benefit of the hybrid algorithm is that COVID-19 is diagnosed and treated more rapidly. Pandemic diseases possibilities are handling with help of Computational Intelligence, using cases and applications from current COVID-19 pandemic. This work discusses data that can be analyzed based on optimization algorithm which provides betterCOVID-19 detection and diagnosis. This algorithm uses a machine learning model to decide how the hazard function changes concerning characteristics of potential methods to find parameters in optimization of machine learning model, which has in many cases been shown to be accurate for actual clinical datasets.",http://dx.doi.org/10.1007/978-3-030-98167-9_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96504-4_2,Sparta: Heat-Budget-Based Scheduling Framework on IoT Edge Systems,Edge Computing – EDGE 2021,10.1007/978-3-030-96504-4_2,Springer,2022-01-01,"Co-location of processing infrastructure and IoT devices at the edge is used to reduce response latency and long-haul network use for IoT applications. As a result, edge clouds for many applications (e.g. agriculture, ecology, and smart city deployments) must operate in remote, unattended, and environmentally harsh settings, introducing new challenges. One key challenge is heat exposure, which can degrade the performance, reliability, and longevity of electronics. For edge clouds, these problems are exacerbated because they increasingly perform complex workloads, such as machine learning, to affect data-driven actuation and control of devices and systems in the environment. The goal of our work is to protect edge clouds from overheating. To enable this, we develop a heat-budget-based scheduling system, called Sparta, which leverages dynamic voltage and frequency scaling (DVFS) to adaptively control CPU temperature. Sparta takes machine learning applications, datasets, and a temperature threshold as input. It sets the initial frequency of the CPU based on historical data and then dynamically updates it, according to the applications’ execution profile and ambient temperature, to safeguard edge devices. We find that for a suite of machine learning applications and deployment temperatures, Sparta is able to maintain CPU temperature below the threshold 94% of the time while facilitating improvements in execution time by 1.04x − 1.32x over competitive approaches.",http://dx.doi.org/10.1007/978-3-030-96504-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1223-8_2,Overview of Artificial Intelligence in Medicine,Artificial Intelligence in Medicine,10.1007/978-981-19-1223-8_2,Springer,2022-01-01,"Computational intelligence or machine intelligence is generally described as the notion of automated and intelligent machines supporting or replacing human labour. AI has attracted growing research interest and has become increasingly adopted in modelling and solving real-world problems. AI in medicine has attracted increasing attention with significant potential for its adoption, particularly as the gap between increasing expectations of high-quality healthcare, and natural limitations of human physicians in mastering increasingly complex domain knowledge grows. With the assistance of AI, the organisation, retrieval and utilisation of appropriate medical knowledge needed by the practitioner in dealing with complex cases may become much easier. AI may provide appropriate diagnostic, prognostic and therapeutic decisions, and meet requirements for the emerging 4P principles of medicine: predictive, preventive, personalised, and participatory. AI is likely to improve physician efficiency or accuracy, and clinicians will be essential to provide AI with the expert domain knowledge and data necessary for AI training. Further development and deployment of these technologies should also consider acceptance and satisfaction of patients.",http://dx.doi.org/10.1007/978-981-19-1223-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05359-7_22,"Artificial Intelligence in Urban Last Mile Logistics - Status Quo, Potentials and Key Challenges",Dynamics in Logistics,10.1007/978-3-031-05359-7_22,Springer,2022-01-01,"Artificial Intelligence (AI) has the potential to solve the sustainability and service issues of Urban Last Mile Logistics (ULML). High delivery costs, noisy and polluting traffic, bad working conditions and failed delivery attempts could be addressed by measures like AI-based demand forecasting, intelligent tour and route optimization or digital delivery assistance. However, there is little empirical evidence on the extent to which AI can do this. Thus, the purpose of this report is to elaborate the relevance of AI for solving ULML problems by identifying use cases, potentials and challenges of implementing AI in ULML planning and execution. Therefore, we conducted 15 explorative expert interviews with ULML companies and analyzed them using qualitative content analysis to obtain an initial orientation in this new empirical research field. The findings indicate, among others, that the ULML industry is in the very early stages of AI implementation and that there is relevant potential for efficiency and service improvement. However, one of the key challenges is the perceived high level of uncertainty about achieving economic benefits while having high investment and AI operating costs. The practical contribution of this paper is to provide guidance for ULML companies starting AI activities. The scientific contribution is to show the practical need for AI implementation and to derive concrete research needs for the development of suitable AI methods and algorithms.",http://dx.doi.org/10.1007/978-3-031-05359-7_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9756-2_9,Extract It! Product Category Extraction by Transfer Learning,Advances in Computational Intelligence and Communication Technology,10.1007/978-981-16-9756-2_9,Springer,2022-01-01,"The categorization of e-commerce products is salient as its quality directly affects search, recommendations, and related personalized services. Putting the products into the best possible category in a hierarchical manner divided by subcategories is challenging due to the vast range of products creating complexity in product information to select suitable categories. Earlier research proves inefficient with a smaller dataset, so we propose a model to extract the most relevant information from the product description and a pre-trained vocabulary to transform it into subcategories for the prediction of the product category tree. A minute inaccuracy, in this case, can hamper customer satisfaction while searching for the products in the desired categories. To tackle these challenges, we merge the areas of machine learning and deep learning with natural language processing (NLP) to propose a multi-level-based product categorization model. We implemented a selective approach starting with the product name being the node of the tree to recursively form a hierarchical tree structure, searching and extracting subcategories from the product description and a pre-trained vocabulary, which eventually made us predict the most relevant categorization of products. Basically, it is a process of extraction of subcategory levels from the product description and a pre-trained vocabulary built by transfer learning. The proposed model was tested on a Flipkart product dataset containing 20,000 products with several features describing the product. The cosine similarity between the predicted and the given product category tree computed was 0.77, which takes the accuracy to 86%.",http://dx.doi.org/10.1007/978-981-16-9756-2_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-65116-2_4,Product Planning,Software Product Management,10.1007/978-3-662-65116-2_4,Springer,2022-01-01,"Product planning encompasses all topics which deal with the planning and management of the concrete implementation of the product strategy in the ongoing development of a software product. The last few years have brought increased heterogeneity in product planning, from requirements-driven to data-analysis-driven to data-input-driven approaches, each with different applicable techniques. Customer insight is the basis for the main tasks of release planning, roadmapping and product life cycle management.",http://dx.doi.org/10.1007/978-3-662-65116-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9154-6_55,Sentiment Analysis of Twitter Classification by Applying Hybrid-Based Techniques,"Proceedings of the 3rd International Conference on Communication, Devices and Computing",10.1007/978-981-16-9154-6_55,Springer,2022-01-01,"As technology advances, the world is rapidly transmuting as a result of current technologies, and specially, the Internet has grown ingrained in everyone’s lives. The various social networking applications, namely Twitter, Facebook and Google+ are rapidly gaining huge popularity and most pertinently, Twitter has emerged to be the utmost popular platform for the individuals to coin their opinions and share their experiences with regard to various issues related to products and services. This harvesting of opinions by analysing the vast volume of unstructured information which are a result of social media sites is really a very tedious job. Sentiment analysis or opinion mining is a technique that aims to unveil the sentiments of the common people by analysing textual dissection and helps opinion formation regarding diversified areas. Sentiment analysis can assist researchers to gain insight with respect to numerous public issues specifically in marketing, business, products, services, politics, companies, governments etc. Sentiment analysis is a methodology of transforming unstructured data into structured data by classifying text attributes such as sentiment orientation and differentiate them into positive and negative sentiment category and has evolved in popularity as a subject of study in the modern era. The application of machine learning algorithms contribute significantly in the classification of sentiment analysis. This paper proposes both lexicon-based and machine learning techniques and aims to discuss about the current state-of-the-art of sentiment analysis techniques employed in the classification of tweet sentiment orientation and also addresses the challenges that can be employed to enhance the process of analysis, summarizing and classification of opinion mining.",http://dx.doi.org/10.1007/978-981-16-9154-6_55,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96217-3_6,Bionic Banking Project,Beyond Fintech,10.1007/978-3-030-96217-3_6,Springer,2022-01-01,"This chapter considers the project for the bionic transformation. A project is the basis of any innovation, which is critical to overcoming the present economic and financial crisis. Actionable knowledge on how to improve innovation and bring value to the customers and organizations is essential. There have been many attempts to apply methods to the innovation processes with mixed results in the past. This chapter discusses improving innovation processes based on design thinking and integrating digitization into the lean six sigma method. These methods aim to add value to the customers, improve effectiveness, eliminate waste, minimize operating costs, and reduce time-to-market by redesigning the innovation processes and automation. The chapter reports a certain number of cases where these approaches have been very successful in helping the start-to-end innovation processes (from the definition of the value for the customers up to the implementation of a prototype and engineering the delivery processes).",http://dx.doi.org/10.1007/978-3-030-96217-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-99000-8_5,Transforming into Smart Business: The Role of Artificial Intelligence,Future of Organizations and Work After the 4th Industrial Revolution,10.1007/978-3-030-99000-8_5,Springer,2022-01-01,"Artificial Intelligence (AI) is the peak of the fourth industrial revolution, since it is implemented in various business activities such as HR, supply chain management, manufacturing, e-Commerce, marketing, and corporate finance. Several AI tools were presented in this chapter to shed the light on how such technologies can be implemented to improve organizational predictive capability and boost business performance. Thus, organizations are urged to implement AI systems to overcome forceful threats, as AI augments BI to achieve competitive advantages. Unescapably, AI transformation requires changes in both the individual and the collective mindsets in organizations. This chapter proposes an AI business model, named SHAM, to guide organizations in emerging countries towards AI-driven business transformation. Since the current study is descriptive in nature, the SHAM model was built based on an extensive literature review using the Comprehensive Literature Review Meta-Framework of the seven step model (CLR Meta-Framework). The SHAM model adapts the Sense-Think-Act paradigm which is a broad roadmap in robotics research to fit the business context. The Sense step is to conceptualize the organizational direction towards the new AI-driven entity; the Think step is to build a solid strategy for the AI transformation; and the Act step is to implement the strategy to reach the desired smart business. The model is conceived to empower organizations to transform into smart businesses to achieve competitive advantage, adaptation to the environment, and success.",http://dx.doi.org/10.1007/978-3-030-99000-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9873-6_43,Effect of Class Imbalanceness in Credit Card Fraud,Intelligent and Cloud Computing,10.1007/978-981-16-9873-6_43,Springer,2022-01-01,"With the expansion of latest technologies, credit card fraud has increased dramatically, making it the ideal target for fraudsters. As a result, financial institutions must be proactive in identifying and monitoring unethical behavior. Furthermore, the presence of class imbalanceness in the credit card usages poses a high challenge in identifying the genuine patterns. In this article, the authors have performed comprehensive experimental research to address such issues by proposing a novel hybrid fraud detection model that uses the machine learning techniques for identification of forged activities in transactional records. Extensive experiments have been done using a real-world dataset to show the efficiency of the proposed system. The authors have used an oversampling approach to remove the data imbalances present in the dataset. In addition, the efficiency of the proposed model on a balanced dataset over the imbalanced one has been presented.",http://dx.doi.org/10.1007/978-981-16-9873-6_43,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87790-3_7,The Use of Intelligent Models in Decision Support,Intelligent Decision Support Systems,10.1007/978-3-030-87790-3_7,Springer,2022-01-01,"In this chapter, several real case studies of the development of an IDSS are detailed to illustrate the use of both data-driven and model-driven approaches presented in previous Chaps. 5 and 6 .",http://dx.doi.org/10.1007/978-3-030-87790-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-6460-1_41,Inventory Optimization Using Machine Learning Algorithms,Data Intelligence and Cognitive Informatics,10.1007/978-981-16-6460-1_41,Springer,2022-01-01,"Businesses that deal with putrescible products have to maintain their inventories at an optimal level as the shortage of products or excess of products can incur losses; hence, optimization of inventories is a very crucial task in supply chain management. To minimize the effect of surplus as well as shortage on the businesses, inventory optimization management software helps to minimize the loss due to this supply chain problem. Exploration for this study is done using various machine learning algorithms to forecast the quantity required for a supermarket to sustain its future sales for the next day. This study aims to support a retail company in its demand–supply chain, and thus for this study, a public dataset of supermart has been used.",http://dx.doi.org/10.1007/978-981-16-6460-1_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87790-3_4,Intelligent Decision Support Systems,Intelligent Decision Support Systems,10.1007/978-3-030-87790-3_4,Springer,2022-01-01,"In this chapter, the main characteristics of Intelligent Decision Support Systems (IDSS) are described. Starting with a definition of an IDSS, next an introduction to the Artificial Intelligence (AI) field is provided. Main AI paradigms or approaches to solve complex problems are presented. This way the readers can have a better understanding of the AI methods used in Intelligent Decision Support Systems. These methods will be detailed in the next chapters. Next, the different typology of IDSSs according to the nature of the problem at hand is detailed, and possible classification of IDSS regarding the type of knowledge and models used: model-driven IDSSs and data-driven IDSSs . Afterwards, the different conceptual components of an IDSS are described and the main open challenges in IDSS field are explained. The main requirements and considerations prior to the construction of an IDSS are detailed. Next, a proposal for a general architecture for an IDSS is presented, jointly with a design and cognitive-oriented approach for the development process for an IDSS. In addition, some checklist of features to be taken into account for the validation of an IDSS are described, even though this is an open challenge which will be addressed in Chap. 10. Finally, a first real case study of the development of an IDSS is detailed to illustrate the approaches previously presented in this chapter.",http://dx.doi.org/10.1007/978-3-030-87790-3_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6054-2_16,Heterogeneous Graph Neural Networks,"Graph Neural Networks: Foundations, Frontiers, and Applications",10.1007/978-981-16-6054-2_16,Springer,2022-01-01,"Heterogeneous graphs (HGs) also called heterogeneous information networks (HINs) have become ubiquitous in real-world scenarios. Recently, employing graph neural networks (GNNs) to heterogeneous graphs, known as heterogeneous graph neural networks (HGNNs) which aim to learn embedding in low-dimensional space while preserving heterogeneous structure and semantic for downstream tasks, has drawn considerable attention. This chapter will first give a brief review of the recent development on HG embedding, then introduce typical methods from the perspective of shallow and deep models, especially HGNNs. Finally, it will point out future research directions for HGNNs.",http://dx.doi.org/10.1007/978-981-16-6054-2_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2560-3_2,Frontier of Smart Healthcare Engineering Management,Smart Healthcare Engineering Management and Risk Analytics,10.1007/978-981-19-2560-3_2,Springer,2022-01-01,"Through the advancement of a new generation of information and communication technologies, such as 5G, IoMT Internet of Medical Things (IoMT) , machine learning, etc., the scientific community has already extensively explored the possibilities of utilizing such technologies in varied healthcare processes. From the perspective of process management, it could be argued that every single process of the cycle of health is evolving with such trends, from health monitoring and online health consultation to in-hospital diagnosis and surgery, eventually follow-up examinations and rehabilitations. For example, the process of health monitoring and assessment could be enhanced with wearable or non-contact devices to achieve 24/7 monitoring.",http://dx.doi.org/10.1007/978-981-19-2560-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92430-0_1,Introduction to Actionable Knowledge,Relational Calculus for Actionable Knowledge,10.1007/978-3-030-92430-0_1,Springer,2022-01-01,"This chapter presents an introduction to actionable knowledge, its related notions, and to what general context actions are going to take effect? What is actionable knowledge? From what angle, this book is approaching it? Where and how do we position relational calculus with respect to actionable knowledge? The context of Cyber-Physical and Social Systems is briefly described. Important related notions of knowledge, dynamic decision-making, situations and situation awareness, and analytics and information fusion are being introduced. These notions are necessary to position relational calculus in the processes of creating actionable knowledge.",http://dx.doi.org/10.1007/978-3-030-92430-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6054-2_21,Graph Neural Networks in Natural Language Processing,"Graph Neural Networks: Foundations, Frontiers, and Applications",10.1007/978-981-16-6054-2_21,Springer,2022-01-01,"Natural language processing (NLP) and understanding aim to read from unformatted text to accomplish different tasks. While word embeddings learned by deep neural networks are widely used, the underlying linguistic and semantic structures of text pieces cannot be fully exploited in these representations. Graph is a natural way to capture the connections between different text pieces, such as entities, sentences, and documents. To overcome the limits in vector space models, researchers combine deep learning models with graph-structured representations for various tasks in NLP and text mining. Such combinations help to make full use of both the structural information in text and the representation learning ability of deep neural networks. In this chapter, we introduce the various graph representations that are extensively used in NLP, and show how different NLP tasks can be tackled from a graph perspective.We summarize recent research works on graph-based NLP, and discuss two case studies related to graph-based text clustering, matching, and multihop machine reading comprehension in detail. Finally, we provide a synthesis about the important open problems of this subfield.",http://dx.doi.org/10.1007/978-981-16-6054-2_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-09316-6_4,Towards an Approach for Analyzing Dynamic Aspects of Bias and Beyond-Accuracy Measures,Advances in Bias and Fairness in Information Retrieval,10.1007/978-3-031-09316-6_4,Springer,2022-01-01,"The quality of recommender systems has traditionally only been assessed using accuracy measures. Research has shown that accuracy is only one side of the medallion and that we should also consider quality features that go beyond accuracy. Recently, also fairness-related aspects and bias have increasingly been considered as outcome dimensions in this context. While beyond-accuracy measures including diversity, novelty and serendipity and bias in recommendation have been subject to the research discourse, their interrelation and temporal and group dynamics are clearly under-explored. In this position paper, we propose an approach that groups users based on their behaviors and preferences and that addresses beyond-accuracy needs of those groups while controlling for bias. Further, we consider the analysis of long-term dynamics of different interrelated beyond-accuracy measures and bias as crucial research direction since it helps to advance the field and to address societal issues related to recommender systems and personalization.",http://dx.doi.org/10.1007/978-3-031-09316-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97284-4_3,Industry 4.0 and the Emergent Business Models,Digital Business Models for Industry 4.0,10.1007/978-3-030-97284-4_3,Springer,2022-01-01,The current technological disruptions characterizing the present business environment require organizations to embrace change in order to drive innovation. Companies must disrupt their existing business models for the purpose of surviving the digital revolution. Changing customer needs and technological innovations solicit businesses to shift from traditional organizational structures towards advanced and sustainable frameworks. The introduction of determined digital technologies and the implementation of innovative business models enable companies to meet market demand and enhance customer satisfaction through the provision of customized products and services designed to suit the needs of consumers. The distinct categorizations explained throughout Chap. 3 have been developed in order to fulfil specific organizational objectives. Companies must develop proper capabilities for the purpose of leveraging the full potential of strategic and business model innovation. Firms have converted their existing business models in order to deliver value to customers while offering advanced solutions to consumers. Digital technologies serve to achieve business model transformation in order to help companies thrive in the digital era. This chapter delves into six unique frameworks pertaining to a specific classification scheme illustrated throughout. The data-driven business model is described first as it represents the model based on which the remaining are developed. The platform business model follows and then the smart factory business model is presented. The servitization business model is described towards the end of the chapter.,http://dx.doi.org/10.1007/978-3-030-97284-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5301-8_6,A Systematic Review of Adoption of Blockchain and Machine Learning Technology and Its Application,Soft Computing for Security Applications,10.1007/978-981-16-5301-8_6,Springer,2022-01-01,"This research work provides a systematic review on blockchain-based applications present across multiple domains. Also, a comprehensive classification of technology applications across diverse sectors such as healthcare, supply chain, education, automobile industry, etc. has been presented. The twenty-first century has introduced significant innovations and discoveries that have completely changed our lives. In this way, Computers were first introduced followed by the internet, internet of things, and this has recently resulted in the introduction of “Blockchain” technology. This technology is considered as the most important innovation since the internet, and it is also known as the future internet since it creates a decentralized network chain. It has huge potential to impact, disrupt, and change human activities. Also, blockchain becomes an ideal tool for creating a trust-based solution. Nowadays several private, public sector firms, and government organizations are initiating new research work in the blockchain domain. This paper discusses innovative ideas, technologies, and its real-time applications by considering different industries, where blockchain can be applied to create new business opportunities.",http://dx.doi.org/10.1007/978-981-16-5301-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96630-0_11,Explainable Artificial Intelligence for Smart City Application: A Secure and Trusted Platform,Explainable Artificial Intelligence for Cyber Security,10.1007/978-3-030-96630-0_11,Springer,2022-01-01,"Artificial Intelligence (AI) is one of the disruptive technologies that is shaping the future. It has growing applications for data-driven decisions in major smart city solutions, including transportation, education, healthcare, public governance, and power systems. At the same time, it is gaining popularity in protecting critical cyber infrastructure from cyber threats, attacks, damages, or unauthorized access. However, one of the significant issues of those traditional AI technologies (e.g., deep learning) is that the rapid progress in complexity and sophistication propelled and turned out to be uninterpretable black boxes. On many occasions, it is very challenging to understand the decision and bias to control and trust systems’ unexpected or seemingly unpredictable outputs. It is acknowledged that the loss of control over interpretability of decision-making becomes a critical issue for many data-driven automated applications. But how may it affect the system’s security and trustworthiness? This chapter conducts a comprehensive study of machine learning applications in cybersecurity to indicate the need for explainability to address this question. While doing that, this chapter first discusses the black-box problems of AI technologies for Cybersecurity applications in smart city-based solutions. Later, considering the new technological paradigm, Explainable Artificial Intelligence (XAI), this chapter discusses the transition from black-box to white-box. This chapter also discusses the transition requirements concerning the interpretability, transparency, understandability, and Explainability of AI-based technologies in applying different autonomous systems in smart cities. Finally, it has presented some commercial XAI platforms that offer explainability over traditional AI technologies before presenting future challenges and opportunities.",http://dx.doi.org/10.1007/978-3-030-96630-0_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6166-2_6,Emerging Topics of Heterogeneous Graph Representation,Heterogeneous Graph Representation Learning and Applications,10.1007/978-981-16-6166-2_6,Springer,2022-01-01,"Heterogeneous graph (HG) embedding, aiming to project HG into a low-dimensional space, has attracted considerable research attention. We have introduced some kinds of HG embedding methods, and there are also some other essential topics on HG embeddings. In this chapter, we will introduce three novel HG embedding methods. Specifically, to learn semantic-preserving and robust node representations, we study the problem of adversarial learning on HG. Also, we work with large-scale heterogeneous interaction graphs and focus on the problem of importance sampling on HG embedding. Moreover, we explore the intrinsic spaces of HG and propose a hyperbolic space based HG embedding method.",http://dx.doi.org/10.1007/978-981-16-6166-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75729-8_7,Applied Machine Learning in Operations Management,Innovative Technology at the Interface of Finance and Operations,10.1007/978-3-030-75729-8_7,Springer,2022-01-01,"The field of operations management has witnessed a fast-growing trend of data analytics in recent years. In particular, spurred by the increasing availability of data and methodological advancement in machine learning, a large body of recent literature in this field takes advantage of machine learning techniques for analyzing how firms should operate. In this chapter, we review applications of different machine learning methods, including supervised learning, unsupervised learning, and reinforcement learning, in various areas of operations management. We highlight how both supervised and unsupervised learning shape operations management research in both descriptive and prescriptive analyses. We also emphasize how different variants of reinforcement learning are applied in diverse operational decision problems. We then identify several exciting future directions at the intersection of machine learning and operations management.",http://dx.doi.org/10.1007/978-3-030-75729-8_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-021-08977-0,How Blockchain Can Automate KYC: Systematic Review,Wireless Personal Communications,10.1007/s11277-021-08977-0,Springer,2022-01-01,"Since the advent of cryptocurrency, Blockchain has evolved as a promising technology towards diverse application areas such as education, healthcare, supply chain management, etc. Various institutions, essentially, the financial institutions, use traditional Know Your Customer (KYC) for the identity verification of a customer. However, KYC being manual and labor-intensive process, the repetitive task of onboarding different institutions by any customer makes it cost inefficient. With decentralized Blockchain technology, the overall efficiency of KYC can be increased manifold in terms of improved speed, minimum onboard time, reduced risk and total cost involved. In the paper, we conduct a PRISMA guided systematic review on the use of Blockchain technology for KYC and its application areas from 2014 onwards. Lastly, the Blockchain platforms such as Ethereum and Hyperledger along with related case studies have been presented followed by future directions in KYC.",http://dx.doi.org/10.1007/s11277-021-08977-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06374-9_21,A Digital Forensic Readiness Cybercrime Semantic Trigger Process,e-Infrastructure and e-Services for Developing Countries,10.1007/978-3-031-06374-9_21,Springer,2022-01-01,"The recent wave of the global Covid-19 pandemic has led to a surge in text-based non-technical cybercrime attacks within the cyber ecosystem. Information about such cyber-attacks is often in unstructured text data and metadata, a rich source of evidence in a digital forensic investigation. However, such information is usually unavailable during a digital forensic investigation when dealing with the public cloud post-incident. Furthermore, digital investigators are challenged with extracting meaningful semantic content from the raw syntactic and unstructured data. It is partly due to the lack of a structured process for forensic data pre-processing when or if such information is identified. Thus, this study seeks to address the lack of a procedure or technique to extract semantic meaning from text data of a cybercrime attack that could be used as a digital forensic readiness semantics trigger in a cybercrime detection process. For the methodology to address the proposed approach, data science modelling and unsupervised machine learning are used to design a strategy. This method process extracts tokens of cybercrime text data, which are further used to develop an intelligent DFR semantic tool extractor based on natural language patterns from cybercrime text data. The proposed DFR cybercrime semantic trigger process when implemented could be used to create a digital forensic cybercrime language API for all digital forensic investigation systems or tools.",http://dx.doi.org/10.1007/978-3-031-06374-9_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98206-5_11,Robo-Justice,Advanced Artificial Intelligence and Robo-Justice,10.1007/978-3-030-98206-5_11,Springer,2022-01-01,"AI is transforming the way the world innovates and creates demanding extensive investment in the needed digital and physical infrastructure. AI can reproduce physical human processes through machines, making routine tasks more competent. The digital society epitomizes a new society governed via the use of information and communication technologies with the global computer networks. Moreover, a digital society is a society in which digital relations are created encompassing both traditional participants in civil transactions and cyber-physical systems such as AAI entities and robots which means that an AAI-robot will be a fully-fledged participant in public relations. Future AAI decision-making models will be different from current ones having self-consciousness and will be reprogrammed by themselves which means entities with full legal personality. AAI systems will be able to deal with both conscious and unconscious processes alike humans. In a fully developed AAI justice system implemented by AAI technology and not controlled by humans, the whole electronic and virtual system will be served by robo-judges. All human activities will be implemented by AAI entities altering the whole society leading to an AAI society and consequently to an AAI democracy or an AAI-regime. Robo-judges can render AAI e-judgments by applying the appropriate laws and procedures in robo-courts. The development of AAI systems and the emergence of robo-justice via robo-judges eliminate the need for distinguishing courts and arbitral tribunal since the same AAI system will execute the decision-making for all disputes taking into account all the available data.",http://dx.doi.org/10.1007/978-3-030-98206-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98225-6_8,"Digital Transformation, Leadership, and Markets",Blockchain and Other Emerging Technologies for Digital Business Strategies,10.1007/978-3-030-98225-6_8,Springer,2022-01-01,"In the electronic era, the company environments are evolving into an insecure, composite, and indecisive atmosphere. This quick evolution can be blamed upon the rise of technology, competitive market, and legal and regulatory compliances. Teichert (Acta Univ Agriculturae Silviculturae Mendelianae Brunensis 67:1673–1687, [ 1 ]) observe this condition as the reason for forcing the business plans and policies of organizations to adapt to technological innovations. According to Gartner (no date), digital transformation could be termed as the evolution of technology as well as digital optimization including the discovery of advanced digital business models. Gartner also suggests labelling digital transformation as ‘digitization’ since nationalized establishments use the term digital transformation to mention normal IT practices like usage of online services. Vaughan [ 2 ] suggests the main four areas to consider while an organization plan on a digital transformation project as process transformation, business model transformation, domain transformation, cultural/organizational transformation. The benefit of a successful digital transformation according to the author is improved processes, fostering collaborations, broadening service options, and transforming the customer experience.",http://dx.doi.org/10.1007/978-3-030-98225-6_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02351-0,Reinforcement learning infused intelligent framework for semantic web service composition,Applied Intelligence,10.1007/s10489-021-02351-0,Springer,2022-01-01,"Web Services being the predominant aspect of the web, plays an inevitable role in everyday digital life.With an upsurge in web services, the process of combining them to solve a user query has become complicated. Investigators have proposed the usage of various techniques like Artificial Intelligence, Machine Learning and others to solve the problem of service composition which till date has serious unaddressed flaws. This leads to the need of a new intelligent framework capable of reducing the problem dimension which leads to a well structured composition process. This article proposes a novel framework that incorporates the usage of Formal Concept Analysis and Reinforcement Learning to compose the semantic web services thereby providing an efficient solution to the user query. The novelty of the work lies in the usage of Formal Concept Analysis which reduces the complexity of the composition search space thereby making the composition process effective. This article also utilizes the Reinforcement Learning technique with a relatively new reward model which encompasses the semantic input and output to determine the underlying pattern. The proposed framework is tested for the best Reinforcement Learning strategy through rigorous experimentation and the best Reinforcement Learning Algorithm is incorporated into the Intelligent Framework. The novel framework is evaluated using various queries belonging to varied domains to test its reliability and robustness. It is evident from the results that the proposed framework is efficient when compared with the state of art works and is more suitable for real-time service composition.",http://dx.doi.org/10.1007/s10489-021-02351-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-86316-6_9,Industry 4.0: Learning Analytics Using Artificial Intelligence and Advanced Industry Applications,Manage Your Own Learning Analytics,10.1007/978-3-030-86316-6_9,Springer,2022-01-01,"Learning analytics is a crucial factor in measuring the effectiveness of any educational programme. Industry 4.0, mainly artificial intelligence (AI) applications are integrated into the digital pedagogical techniques and the learning analytics that further enhance and develop the online instructional materials. Therefore, it is crucial to explain the usage of those technologies used for the learning analytics associated with the educational system to show the different use of AI. This book chapter explains: the meaning of the learning analytics in Industry 4.0 and education and its affiliated areas; AI and its related areas with examples from state-of-the-art corporate applications and solutions based on AI technologies integrated into the learning analytics.",http://dx.doi.org/10.1007/978-3-030-86316-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-03918-8_46,An Intelligent Algorithmic Approach for Data Collection in a Smart Warehouse Testbed,The 8th International Conference on Advanced Machine Learning and Technologies and Applications (AMLTA2022),10.1007/978-3-031-03918-8_46,Springer,2022-01-01,"In this paper, a smart warehouse testbed was designed and simulated. The system serves two purposes. It simulates a real-world industrial setting and emphasizes the significance of experimental research to assess the feasibility of new ideas in real-world situations. The suggested simulation model has five rack systems with a total capacity of 1000 pallets. An AGV moves in the middle of each rack system, picking up and returning pallets to both sides in the direction of movement. A circulating conveyor system is used in the proposed system to enhance transaction count data to enable intelligent algorithms such as machine learning. Accordingly, each pallet (attached with one RFID tag) is managed by a management code when stored in the warehouse. After taking out, that pallet can be cleared of the old management code, assigned a new code, and returned to the input conveyor of the system. One of the biggest challenges of the proposed system is ensuring the continuous operation at the inlets of the AS/RS AGV’s pallet receiving conveyors. The feasibility was demonstrated by conducting the simulation to build a polynomial regression function from which the value of Tseparator can be attained according to the given set of values (Vconveyor and Tstoring). In addition, when the set of values (Vconveyor, Tstoring, and Tseparator) is known, the time required to store the entire inventory may also be calculated.",http://dx.doi.org/10.1007/978-3-031-03918-8_46,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87664-7_21,Future Trends in Digital Face Manipulation and Detection,Handbook of Digital Face Manipulation and Detection,10.1007/978-3-030-87664-7_21,Springer,2022-01-01,"Recently, digital face manipulation Digital face manipulation  and its detection have sparked large interest in industry and academia around the world. Numerous approaches have been proposed in the literature to create realistic face manipulations Face manipulation , such as DeepFakes DeepFake  and face morphs. To the human eye manipulated images and videos can be almost indistinguishable from real content. Although impressive progress has been reported in the automatic detection of such face manipulations Face manipulation , this research field is often considered to be a cat and mouse game . This chapter briefly discusses the state of the art of digital face manipulation Digital face manipulation  and detection. Issues and challenges that need to be tackled by the research community are summarized, along with future trends in the field.",http://dx.doi.org/10.1007/978-3-030-87664-7_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9247-5_9,DICE: Dynamically Induced Cross Entropy for Robust Learning with Noisy Labels,Cognitive Systems and Information Processing,10.1007/978-981-16-9247-5_9,Springer,2022-01-01,"Image classification has lead to the revolution of artificial intelligence in the past five years. However, image classification algorithms are significantly affected by the inherent variance in sensory input and noise in the labelled data in a real-world situation. Also, the class count of items in the real world is significantly larger than that of the typical experiment setup. How to speedily train/fine-tune a large scale model in giant label space with considerable noise is a recent interest of the machine learning community. This paper proposed a multi-stage training algorithm to fine-tune a pre-trained EfficientNet model on AliProducts large scale product classification dataset, which has a large label space (50030 classes) and severe label noise. Our method can generalize well on such a dataset while keeping the prior knowledge gained in the large-scale pretraining stage. With our novel Dynamically Induced Cross-Entropy(DICE) network loss and several other methods to tackle unbalanced datasets and improve model convergence, the model achieved 76.67% of Top-1 Accuracy and 85.42% of Top-5 accuracy, which are 3.63%/2.9% higher than symmetric cross-entropy and are significantly higher than the usual fine-tuning method with categorical cross-entropy loss(CCE).",http://dx.doi.org/10.1007/978-981-16-9247-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-06458-6_1,Optimization Focused on Parallel Fuzzy Deep Belief Neural Network for Opinion Mining,Business Intelligence,10.1007/978-3-031-06458-6_1,Springer,2022-01-01,"In this work, we propose a new parallel fuzzy deep belief neural network for sentiment analysis. We have applied several preprocessing tasks to enhance data quality and remove noisy data. Then, we have applied a semi-automatic data labeling over the dataset by combining two techniques: Vader lexicon and Mamdani’s fuzzy system. In addition, we have used four extraction techniques, which are: TFIDF (Unigram), TFIDF (Bigram), TFIDF (Trigram) and GloVe in order to represent each tweet by numerical vector. Further, we have implemented three feature selection techniques which are: The mutual information approach, the chi-square method and the ANOVA technique. Finally, we have applied the deep belief network as classifier in order to classify each tweet into a neutral, negative or positive and our hybrid parallel deep-fuzzy belief neural network is deployed in a parallel design employing the Hadoop framework to overcome the issue of long runtime of huge data sets. Also, a comparisons of the proposed model’s effectiveness with other existing models in the literature is carried out and the experimental results shown that our suggested parallel fuzzy model surpasses the baseline models by a considerable margin in terms of recall, runtime, F1 score, accuracy, error rate and precision.",http://dx.doi.org/10.1007/978-3-031-06458-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-021-00987-z,API-GNN: attribute preserving oriented interactive graph neural network,World Wide Web,10.1007/s11280-021-00987-z,Springer,2022-01-01,"Attributed graph embedding aims to learn node representation based on the graph topology and node attributes. The current mainstream GNN-based methods learn the representation of the target node by aggregating the attributes of its neighbor nodes. These methods still face two challenges: (1) In the neighborhood aggregation procedure, the attributes of each node would be propagated to its neighborhoods which may cause disturbance to the original attributes of the target node and cause over-smoothing in GNN iteration. (2) Because the representation of the target node is derived from the attributes and topology of its neighbors, the attributes and topological information of each neighbor have different effects on the representation of the target node. However, this different contribution has not been considered by the existing GNN-based methods. In this paper, we propose a novel GNN model named API-GNN ( A ttribute P reserving Oriented I nteractive G raph N eural N etwork). API-GNN can not only reduce the disturbance of neighborhood aggregation to the original attribute of target node, but also explicitly model the different impacts of attribute and topology on node representation. We conduct experiments on six public real-world datasets to validate API-GNN on node classification and link prediction. Experimental results show that our model outperforms several strong baselines over various graph datasets on multiple graph analysis tasks.",http://dx.doi.org/10.1007/s11280-021-00987-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-84459-2_4,Smart Cities as Identities,"Artificial Intelligence, Machine Learning, and Optimization Tools for Smart Cities",10.1007/978-3-030-84459-2_4,Springer,2022-01-01,"In 2008 bitcoin was born, based on blockchain technology. Soon after various blockchain frameworks came out, offering unparallel security and supporting rule-based logic. At their core two concepts are prominent, identity and rule-based transactions. These two inherent characteristics are cornerstone in any process. Cities can benefit from programmatically facilitating their own internal processes to achieve efficiencies at scale, securing their citizens’ personal data, and eventually creating their own individual identities. It is a long road ahead, where calculated steps must be taken in integrating the promise of blockchain technology in the quest of building the smart cities of tomorrow.",http://dx.doi.org/10.1007/978-3-030-84459-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99739-7_67,Third International Workshop on Algorithmic Bias in Search and Recommendation (BIAS@ECIR2022),Advances in Information Retrieval,10.1007/978-3-030-99739-7_67,Springer,2022-01-01,"Creating search and recommendation algorithms that are efficient and effective has been the main goal for the industry and the academia for years. However, recent research has shown that these algorithms lead to models, trained on historical data, that might exacerbate existing biases and generate potentially negative outcomes. Defining, assessing and mitigating these biases throughout experimental pipelines is hence a core step for devising search and recommendation algorithms that can be responsibly deployed in real-world applications. The Bias 2022 workshop aims to collect novel contributions in this field and offer a common ground for interested researchers and practitioners. The workshop website is available at https://biasinrecsys.github.io/ecir2022/ .",http://dx.doi.org/10.1007/978-3-030-99739-7_67,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83624-5_1,Introduction,Handbook of Fingerprint Recognition,10.1007/978-3-030-83624-5_1,Springer,2022-01-01,"This chapter presents an introduction to biometric and, in particular, fingerprint recognition systems and provides some historical timeline on fingerprints and their adoption in forensic and civilian recognition applications. All the topics that are covered in detail in the successive chapters are surveyed here in brief. The notation and terminology are introduced, and error rates of a biometric system are explained and formalized by defining the main performance metrics. Other relevant topics such as biometric system applications, system integration, and privacy issues are also discussed.",http://dx.doi.org/10.1007/978-3-030-83624-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-78284-9_7,Applying Computation Intelligence for Improved Computer Vision Capabilities,Innovative Trends in Computational Intelligence,10.1007/978-3-030-78284-9_7,Springer,2022-01-01,"While computers remain undoubtedly the most successful innovation of the modern-day world, it has helped us envision new dreams and aspirations which can be fulfilled with computer vision. Its ability of artificially sensing the external world coupled with its precision, accuracy, and quality-driven output has resulted in the use of software to cater to the upcoming and ever-growing needs, reducing human dependence on the tasks by self-maneuvering them. A path-breaking development arose with the attempt to utilize machine learning for recognition of patterns on real-time situations which opened a horizon of new opportunities for human talent to dwell on in the form of computer vision. Computer vision capabilities have set open another arena for development and improvement as well as revenue generation by working on computer vision capabilities; it often comes with its own challenges including difficulty in pattern recognition, efficient handling of variations in pose, illumination, expression, and occlusion. With the upgraded and enhanced techniques along with the implementation of computerized intelligence, efforts are being made to arrive at solutions to minimize the problems associated with computer vision explaining the processes like image segmentation, filtering, pattern recognition, and its applications involving several components such as memory, retrieval, reasoning, recognition, estimation, and coordination along with other senses in a manner that it serves a tool to aid the mankind.",http://dx.doi.org/10.1007/978-3-030-78284-9_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87049-2_30,A Comprehensive Review on Edge Computing: Focusing on Mobile Users,"Advances in Computing, Informatics, Networking and Cybersecurity",10.1007/978-3-030-87049-2_30,Springer,2022-01-01,"During the last decade, evolutions in Information and Communication technologies (ICT) such as cloud computing, wireless networks and mobile computing, have accelerated the proliferation of mobile users and consequently the development of sophisticated, complex and resource-intensive mobile applications, such as speech recognizers, image processors and multimedia services. Running such applications on mobile devices was challenging since mobile computing has inherent problems such as resource scarcity, frequent disconnections and mainly mobility. To address the shortcomings of mobile computing, researchers have used the concept of Cloud Computing (CC) to perform resource-intensive tasks outside mobile devices. This led to mobile and cloud computing convergence and the emergence of a new computing paradigm, the Mobile Cloud Computing (MCC), also called Mobile Cloud , which could effectively alleviate the problems of mobile computing. More sophisticated applications, such as online gaming, augmented reality, and virtual reality, which require broad bandwidth, low response latency and large computational power have emerged. In general, such a system relies on distant cloud services to perform all the data processing tasks, which result in explicit latency. The most promising solution for the requirements of aforesaid applications was the placement of content, compute, and cloud resources on the edge of the network, closer to concentrations of users. Consequently, Edge Computing (EC), which utilizes the proximal computational and networking resources, has arisen. The concept of Edge Computing was introduced, initially in the form of Cloudlets that assist mobile devices to gain computational and storage performance benefits, which later paved the way towards the concepts of Fog computing and Mobile Edge Computing, which essentially has to be referred as Multi-Access Edge Computing (MEC). Thus, mobile cloud has extended its computation model from centralized to distributed, from Internet cloud to edge cloud, and from mobile devices to mobile services. In this survey paper we investigate the pre-existing works in MCC to determine their role in the current trends for edge computing. We provide a holistic overview on the exploitation of EC for the realization of pervasive mobile applications and we briefly present the state-of-the art of edge computing paradigms and the key enabling technologies. We also briefly present how the crowd sourcing was based on the MCC to work efficiently and how MEC enriches the dynamics of crowd sourcing. Finally, we present the open research challenges.",http://dx.doi.org/10.1007/978-3-030-87049-2_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97284-4_4,The Integration of Digital Business Models: The Amazon Case Study,Digital Business Models for Industry 4.0,10.1007/978-3-030-97284-4_4,Springer,2022-01-01,The final chapter involves the description of the Amazon case study. The intention is to reconnect the various categorizations illustrated in the previous chapter to a real-world example for the purpose of presenting a successful case of business disruption as Amazon is known to have disrupted retail. The analysis aims at highlighting the fact that Amazon combines all the business model frameworks described in the preceding chapters as well as investigating their coexistence within a single organization. The present chapter also explains a few methodologies which have been developed in order to guide companies through the process of disrupting their existing business models and facilitating the shift towards an innovative framework. Digital technologies can ease the above-mentioned transition as firms are required to select the technological advancements enabling them to accomplish particular organizational goals.,http://dx.doi.org/10.1007/978-3-030-97284-4_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96569-3_13,Artificial Intelligence in Biomedical Education,Artificial Intelligence for Innovative Healthcare Informatics,10.1007/978-3-030-96569-3_13,Springer,2022-01-01,"Artificial Intelligence is soon going to support changes on a large scale to many professions including biomedical education by providing a wide range of applications in this technical era. Therefore, medical science should be more reformed so that the medical profession will adapt the effective modern ideas of technology. Thus there is an accelerating demand of the researchers to focus more on the transitions of the fundamental medical system to the systematic intelligent system. In this chapter, the authors have given summarized information regarding the various approaches from the intensive survey which may be beneficial for the medical educators, to provide analysis of the accurate diagnosis which can minimize the errors in the health results of the patient’s by avoiding repetitive, and severe effort tasks, therefore, making the treatment of sufferer easy by reducing the medical costs, and minimize the rates of mortality, etc. The discussion of how techniques of AI are being used on tools and equipment of the medical professionals comprises enormous data sets related to the patient’s health, therefore guaranteeing the mastery of empathetic care. The objective of the authors is to assist the researchers to cater the valuable understanding of AI incorporated in numerous categories of the medical field in a single document. They are adhering to the adaptive as well as modified content of AI for assisting the forthcoming researchers to recognize various information gaps and techniques to respond to them in this field.",http://dx.doi.org/10.1007/978-3-030-96569-3_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-981-4585-87-3_37-2,Real-Time Cyber-Physical Systems: State-of-the-Art and Future Trends,Handbook of Real-Time Computing,10.1007/978-981-4585-87-3_37-2,Springer,2022-01-01,"The real-time cyber-physical systems (CPSs) describe a wide range of complex and interdisciplinary engineered systems that integrate real-time embedded computing and control technologies (cyber component) into physical world. To further understand real-time CPSs, this chapter presents a brief survey of the relevant work, exploring the emergence of real-time CPSs, the system requirements, the relation to other research areas, similar and prevalent concepts, and important practical applications. In addition, this chapter lists several important technical challenges and elaborates insightful concepts by utilizing specific applications. Real-time CPSs have various applications spanning different scales due to their very broad research areas. The future and next-generation technologies are anticipated to have a significant impact on real-time CPS applications. Hence, all real-time CPS applications are required to be developed and designed taking into account advanced technologies, essential system requirements, and overall influence on physical world.",http://dx.doi.org/10.1007/978-981-4585-87-3_37-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-981-4585-87-3_37-1,Real-Time Cyber-Physical Systems: State-of-the-Art and Future Trends,Handbook of Real-Time Computing,10.1007/978-981-4585-87-3_37-1,Springer,2022-01-01,"The real-time cyber-physical systems (CPSs) describe a wide range of complex and interdisciplinary engineered systems that integrate real-time embedded computing and control technologies (cyber component) into physical world. To further understand real-time CPSs, this chapter presents a brief survey of the relevant work, exploring the emergence of real-time CPSs, the system requirements, the relation to other research areas, similar and prevalent concepts, and important practical applications. In addition, this chapter lists several important technical challenges and elaborates insightful concepts by utilizing specific applications. Real-time CPSs have various applications spanning different scales due to their very broad research areas. The future and next-generation technologies are anticipated to have a significant impact on real-time CPS applications. Hence, all real-time CPS applications are required to be developed and designed taking into account advanced technologies, essential system requirements, and overall influence on physical world.",http://dx.doi.org/10.1007/978-981-4585-87-3_37-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-09469-9_15,Transfer Learning Architecture Approach for Smart Transportation System,Advanced Informatics for Computing Research,10.1007/978-3-031-09469-9_15,Springer,2022-01-01,"An intelligent and smart transportation system aims at effective transportation and mobility usage in smart cities. In recent years, modern transportation networks have undergone a rapid transformation. This has resulted in a variety of automotive technology advances, including connected vehicles, hybrid vehicles, Hyperloop, self-driving cars and even flying cars, as well as major improvements in global transportation networks. Because of the open existence of smart transportation system as a wireless networking technology, it poses a number of security and privacy challenges. Information and communication technology has long aided transportation productivity and safety in advanced economies. These implementations, on the other hand, have tended to be high-cost, customized infrastructure systems. To address these challenges, a novel machine learning method developed for a transportation system is reused for making it more generic and smart for intelligent carriage. This type of transfer learning enables rapid progress on the task with enhanced results. In this work, together with domain adaptation, a novel weighted average approach is used to build models related to the smart transportation system. A smart system comprising of interconnected sensors along with the gateway devices can lead the way to a more efficient, viable and robust city centers. Finally, in this paper also provides a view of current research in smart transportation system along with future directions.",http://dx.doi.org/10.1007/978-3-031-09469-9_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1740-9_18,Transformation of Medical Imaging Using Artificial Intelligence: Its Impact and Challenges with Future Opportunities,Soft Computing: Theories and Applications,10.1007/978-981-16-1740-9_18,Springer,2022-01-01,"In healthcare sector, the people contemplate the best treatments and services notwithstanding of cost. Even if a huge amount of national budget disburses in this sector but it has not attained the society conjecture. Entire medical statistics are investigated by specialist. The complexities and the minutiae of the images and statistics can only be extrapolated by the specialists which escalate the workload and insistence of the specialists. The circumstances propagate to the need for the automated models for the healthcare systems. Artificial intelligence (AI) is a well-built domain of computer science which is attainable solution to all the real-world complications. Thus, AI can come up with exceptional and accurate solution with inordinate precision for medical imaging. Medical imaging embraces the identification, medicament and surveil the diseases in the particular images of medical fields like CT scan, X-rays, ultrasound images. AI methods can be employed to radiology, pathology, and dermatology for image processing. AI methods like deep neural networks, machine learning algorithms, fuzzy logic are some best solutions for image processing. In this paper, divergent AI techniques with their strength, limitations, and applications are delineate and the paper also provides a cognizance to contemporary approaches that attain optimum results in their respective domains. This paper concluded with the discussion of the barriers which reduced the growth of AI and the future opportunities of AI in the healthcare sector.",http://dx.doi.org/10.1007/978-981-16-1740-9_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-020-03702-9,Appraisals of harms and injustice trigger an eerie feeling that decreases trust in artificial intelligence systems,Annals of Operations Research,10.1007/s10479-020-03702-9,Springer,2022-01-01,"As artificial intelligence (AI) becomes more pervasive, the concern over how users can trust artificial agents is more important than ever before. In this research, we seek to understand the trust formation between humans and artificial agents from the morality and uncanny theory perspective. We conducted three studies to carefully examine the effect of two moral foundations: perceptions of harm and perceptions of injustice, as well as reported wrongdoing on uncanniness and examine the effect of uncanniness on trust in artificial agents. In Study 1, we found perceived injustice was the primary determinant of uncanniness and uncanniness had a negative effect on trust. Studies 2 and 3 extended these findings using two different scenarios of wrongful acts involving an artificial agent. In addition to explaining the contribution of moral appraisals to the feeling of uncanny, the latter studies also uncover substantial contributions of both perceived harm and perceived injustice. The results provide a foundation for establishing trust in artificial agents and designing an AI system by instilling moral values in it.",http://dx.doi.org/10.1007/s10479-020-03702-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82193-7_31,Random Forest Classification with MapReduce in Holonic Multiagent Systems,Intelligent Systems and Applications,10.1007/978-3-030-82193-7_31,Springer,2022-01-01,"Multiagent systems are a dominant field of study within artificial intelligence. Holons are a special kind of agent implementation found in multiagent systems which has not received much attention in recent mainstream AI topics, such as machine learning. Their self-similar structure is both stable and coherent, and likewise consists of one or more holons. This paper studies how holonism, introduced through recursive modelling techniques, benefit multiagent systems. It also expands the scope of multiagent learning applications by proposing a new architecture for executing Decision Tree and Random Forest machine learning models that are both novel in terms of parallelism and extensibility in order to solve classification problems. The models were designed using a structured based approach of computer programs, with a special focus on recursive structures. Results obtained show that when the algorithms are applied in a classification problem domain, the algorithms are able to perform consistent with their expected behaviour.",http://dx.doi.org/10.1007/978-3-030-82193-7_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1496-6_7,Legal Vacuum to Regulate AI,Artificial Intelligence and International Law,10.1007/978-981-19-1496-6_7,Springer,2022-01-01,"In contrast to rapidly developing AI, the international community has been struggling to come to an agreement on how to regulate it. Consequentially, there is a legal vacuum with respect to AI.",http://dx.doi.org/10.1007/978-981-19-1496-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-91149-2_5,Software-Defined Networking-Based Ad hoc Networks Routing Protocols,Software Defined Networking for Ad Hoc Networks,10.1007/978-3-030-91149-2_5,Springer,2022-01-01,"A modern networking structure that employs software-based controllers to control and interact with primary hardware devices for directing the traffic on a network is called software-defined networking (SDN). It differs from the conventional network by creating a centralized control over the routing of data packets. Networks are widely used networks in which spontaneous network connectivity among the nodes is needed for communicating useful information quickly to the target audience. Nodes in ad hoc networks (AHN) down to function in an infrastructure-less environment can form a group among themselves freely and launch wireless multi-hop communication without any centralized access point. Every node can have direct communication among each other and be involved in relying on the data packet. Routing in AHN is difficult and has specific constraints over wireless transmission such as frequently changing topology, self-organizing nature, wireless link fluctuation, and resource constraint nature of nodes. Imposing SDN technology in designing routing protocols for various application needs of upcoming scenarios of AHN is crucial for improved network management and reducing the overall communication cost. SDN-based routing protocols shift the routing choices from basic network elements to the controller. This technique helps to identify the shortest route with minimum latency and to reduce the control packet exchange rapidly. This article first proposes the various network structures that rely on SDN technology for competent message transmission in mobile AHN and then presents a survey on SDN-based network routing protocols from different branches of AHN with the methodology used and advantages and disadvantages of each. This helps the researchers to enhance them further to meet the requirement of various application scenarios.",http://dx.doi.org/10.1007/978-3-030-91149-2_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-63962-8_143-2,Performance Evaluation of Big Data Analysis,Encyclopedia of Big Data Technologies,10.1007/978-3-319-63962-8_143-2,Springer,2022-01-01,NA,http://dx.doi.org/10.1007/978-3-319-63962-8_143-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1866-6_59,Anomaly Detection on System Generated Logs—A Survey Study,Mobile Computing and Sustainable Informatics,10.1007/978-981-16-1866-6_59,Springer,2022-01-01,"Recently, the application and systems are generating huge amounts of log data. With the rise of different applications in different domains that are deployed in every environment, it has become inevitable that a system may run into either functional or performance faults. System analyst and administrators have to look at system log data at the time of fault, and analysing millions of lines of logs manually is an impossible task to find the root cause for any faults. Timely detection of any abnormal behaviour is very important to prevent negative impact on the service, thereby helping to build a secure and trustworthy system. The aim of this survey is to provide a comprehensive overview of recent research in supervised and unsupervised anomaly detection methods. A detailed review on the various adoption methods and data sets on which it has been applied across various application domains are discussed in this paper.",http://dx.doi.org/10.1007/978-981-16-1866-6_59,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_15,Evaluating Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_15,Springer,2022-01-01,"Recommender systems are now popular both commercially and in the research community, where many approaches have been suggested for providing recommendations. In many cases a system designer that wishes to employ a recommendater system must choose between a set of candidate approaches. A first step towards selecting an appropriate algorithm is to decide which properties of the application to focus upon when making this choice. Indeed, recommender systems have a variety of properties that may affect user experience, such as accuracy, robustness, scalability, and so forth. In this paper we discuss how to compare recommenders based on a set of properties that are relevant for the application. We focus on comparative studies, where a few algorithms are compared using some evaluation metric, rather than absolute benchmarking of algorithms. We describe experimental settings appropriate for making choices between algorithms. We review three types of experiments, starting with an offline setting, where recommendation approaches are compared without user interaction, then reviewing user studies, where a small group of subjects experiment with the system and report on the experience, and finally describe large scale online experiments, where real user populations interact with the system. In each of these cases we describe types of questions that can be answered, and suggest protocols for experimentation. We also discuss how to draw trustworthy conclusions from the conducted experiments. We then review a large set of properties, and explain how to evaluate systems given relevant properties. We also survey a large set of evaluation metrics in the context of the property that they evaluate.",http://dx.doi.org/10.1007/978-1-0716-2197-4_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-981-16-2210-6_2,Information and Communication Technology Application in the Asian Tourism Industry,Handbook of Technology Application in Tourism in Asia,10.1007/978-981-16-2210-6_2,Springer,2022-01-01,"Tourism becomes a major player in global trade and also a major income source for several developing countries. Tourism is one industry that has adopted the use of information and communication technology (ICT) in its services realizing its potential in enhancing the business prospects since mid of the last century. It was in 1946 that the first automated booking system was installed by the American Airlines. Since then, the use of ICT in tourism has diversified for providing large source of information to tourists and better and faster service to its customers, improving relationship between distribution channels, and enabling promotion and distribution of products directly to its customers. The advent of information technology during the years has seen tourism industry capitalizing the use of Internet, eBusiness applications, and even artificial intelligence. This has encouraged small players to launch business in tourism and depend on ICT for their product branding and marketing. The tourists themselves have online platforms to review the products and make the best choice of the destinations and packages. Robots have already taken up the role of waiters in hotels in many Asian countries including India. Recognizing the importance of ICT in tourism, the United Nations World Tourism Organization (UNWTO) had chosen the theme for World Tourism Day 2018 as “Tourism and the Digital Transformation.” This paper looks into the historic evolution of ICT in tourism, its application in different areas of the tourism industry especially in the Asian context, barriers in adopting to new technology, and the digital divide in tourism.",http://dx.doi.org/10.1007/978-981-16-2210-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-3398-0_16,Fake News Propagation and Mitigation Techniques: A Survey,Principles of Social Networking,10.1007/978-981-16-3398-0_16,Springer,2022-01-01,"Today, major online social networking websites host millions of user accounts. These websites provide a convenient platform for sharing information and opinions in the form of microblogs. However, the ease of sharing also brings ramifications in the form of fake news, misinformation, and rumors, which has become highly prevalent recently. The impact of fake news dissemination was observed in major political events like the US elections and the Jakarta elections, as well as the distortion of celebrities and companies’ reputation. Researchers have studied the propagation of fake news over social media websites and have proposed various techniques to combat fake news. In this chapter, we discuss propagation models for misinformation and review the fake news mitigation techniques. We also compose a list of datasets used in fake news-related studies. The chapter is concluded with open research questions.",http://dx.doi.org/10.1007/978-981-16-3398-0_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_13,Design and Evaluation of Cross-Domain Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_13,Springer,2022-01-01,"The proliferation of e-commerce sites and online social media has allowed users to provide preference feedback and maintain profiles in multiple systems, reflecting a spectrum of their tastes and interests. Leveraging all the user preferences available in several systems or domains may be beneficial for generating more encompassing user models and better recommendations, e.g., through mitigating the cold-start and sparsity problems, or enabling cross-selling recommendations for items from multiple domains. Cross-domain recommender systems, thus, aim to enhance recommendations in a target domain by exploiting knowledge from source domains. In this chapter, we formalize the cross-domain recommendation problem, unify the perspectives from which it has been addressed, and analytically categorize and describe various recommendation techniques, from the simple legacy ones to the sophisticated ones based on deep-learning.",http://dx.doi.org/10.1007/978-1-0716-2197-4_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97284-4_2,Industry 4.0 and Its Digital Paradigms,Digital Business Models for Industry 4.0,10.1007/978-3-030-97284-4_2,Springer,2022-01-01,"The current technological innovation has contributed to the emergence of multiple digital advances which can support and accelerate the achievement of organizational strategic goals. The digital paradigms characterizing the Fourth Industrial Revolution range from digital manufacturing, involving the application of digital technologies, to manufacturing processes for the purpose of developing smart products and to the application of big data techniques in order to manage large volumes of data and support companies in formulating data-informed decisions. The widespread diffusion of technologies related to Industry 4.0 enables companies to obtain significant advantages. The benefits associated with the introduction and implementation of the aforementioned technological advancements relate to companies operating in multiple industries and include considerable cost reductions, therefore enabling businesses to save time and eliminate sources of waste; enhanced productivity, as a result of efficient resource allocation as well as the predictable and effective management of production processes; and personalized consumer experiences through the development of determined products and services tailored to specific customer needs. The present chapter illustrates the numerous digital technologies characterizing the Fourth Industrial Revolution. A few tables have been developed for the purpose of highlighting the impact of each of the digital-enabling technologies mentioned onto the building blocks constituting the business model canvas. In particular, the operational benefits are listed for each of the above-mentioned digital paradigms in order to describe the effects of such technologies onto the business processes.",http://dx.doi.org/10.1007/978-3-030-97284-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-93119-3_14,Visual Analytics of Hierarchical and Network Timeseries Models,Integrating Artificial Intelligence and Visualization for Visual Knowledge Discovery,10.1007/978-3-030-93119-3_14,Springer,2022-01-01,"Confidence in timeseries models can be gained through visual analytics that represent the many aspects of the models including, the timeseries data (input, predicted, intermediate factors), model structure, model behavior, model sensitivity and model quality in one holistic application. We show examples ranging from simplistic prototypes of financial ratios, to nowcasting and economic forecasting, and massive transaction analysis. The approach is perceptually scalable to the exploration of large-scale structures with millions of nodes by visually representing many node characteristics; on-demand navigation through sub-graphs; hierarchical clustering of nodes; and aggregation of links and nodes. These visual analytics allow expert users to compare the many aspects of the model to their real-world knowledge helping them gain an understanding of the model and ultimately build confidence.",http://dx.doi.org/10.1007/978-3-030-93119-3_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-99000-8_1,Challenges of the Industrial IOT (IIoT) in Higher Education in the Kingdom of Bahrain,Future of Organizations and Work After the 4th Industrial Revolution,10.1007/978-3-030-99000-8_1,Springer,2022-01-01,"The Industrial Internet of Things (IIoT) is a fluid concept that evolves in response to shifts in digital technology, requirements, and markets. Higher education today needs to embrace and learn about the new ways that people, machines, services, and data can interact. Transitioning from higher education to work is a challenge that could be more readily overcome if all parties involved, from individuals to organizations, businesses to governments, collaborated. Because higher education is moving at a snail's pace, all stakeholders must work quickly to prepare for the Industrial Internet of Things. Employers expect critical thinking and analysis, as well as problem-solving and self-management skills like active learning, resilience, stress tolerance, and flexibility, to become more important in the years leading up to 2025. Demand for trained individuals will rise as the IIoT expands. One option to narrow the skills gap is through education, which can include effective skills, re-skilling, and up-skilling programs. Moreover, Higher education must incorporate the latest technologies to adapt to new ways in which people, machines, services, and data interact. Likewise, the training requirements in a variety of sectors must be extensively investigated in order to provide a better environment for Industrial IoT education. Academic and High Vocational Education and Training (HVET) programs, work-based learning, educational virtual and remote laboratories, national and international educational legislation and instruments, extensions, and so on should all be investigated. Curriculum creators and planners at HEIs are currently defying the problems brought by technological development head on. The Kingdom of Bahrain is working hard to develop a knowledge-based, diverse economy in order to provide all citizens with a fair and complete education and to increase lifetime learning possibilities. This aligns with Bahrain’s Economic Vision 2030 objectives.",http://dx.doi.org/10.1007/978-3-030-99000-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0284-0_38,Adoption of Blockchain for Data Privacy in 6G-Envisioned Augmented Reality: Opportunities and Challenges,"Emerging Technologies for Computing, Communication and Smart Cities",10.1007/978-981-19-0284-0_38,Springer,2022-01-01,"The widespread adoption of real-interactivity, fuelled with developments in wireless communication infrastructures, such as sixth generation (6G), made augmented reality (AR) a possibility in a range of vertical applications. AR integrates the digital visuals into a virtual space that emulates the real-world feedback for the user. It supports a range of haptic and interactive communication and thus has attracted the interest of the research community to provide useful AR frameworks. However, as the user-private data is communicated through open channels, it raises privacy and security concerns. In parallel, decentralized computing has shifted resource provisioning to near device interactions that support the real-time connectivity of AR. To preserve privacy and induce trust among AR stakeholders, blockchain (BC)-based AR use cases are presented by researchers. However, the existing surveys have not focused on reference architectures and implementation challenges. Motivated by the research gap, the paper presents a systematic survey of the integration of BC to induce data privacy in AR ecosystems. A comparative analysis is presented, and the potential application of BC-based AR is discussed. A case study on VoRtex enterprise is presented, and a supporting architectural framework is discussed. The survey intends to present the readers deep insights about BC adoption in AR that would motivate industry practitioners, academicians and researchers to propose scalable BC-integrated solutions in AR/VR-based ecosystems.",http://dx.doi.org/10.1007/978-981-19-0284-0_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-5074-1_20,Emerging Technologies and Global Pandemic,Global Pandemic and Human Security,10.1007/978-981-16-5074-1_20,Springer,2022-01-01,"Emerging technologies, often defined as Industry 4.0, have been increasingly altering the development paths of businesses and individuals. As the pandemic continues to remain a part of our reality, we continue to improvise, innovate, and overcome. Technologies we have adapted today, are going to be an integral part of the post-pandemic world as well, this expedited technological adaption beckons the question—when we accepted the thrust of technology to the center of our lives, what the coming years bring forth remains to be seen, now that we as a species we have accepted our technologically interwoven existence. Disruptive technologies include artificial intelligence (AI), Blockchain, 3D printing, augmented reality, etc. While the speed and breadth of the fourth industrial revolution have been and will continue to be remarkable, the COVID-19 pandemic will accelerate innovation and catalyze technological changes already underway paving the way to Society 5.0. Society 5.0 aims to integrate human concerns back into the details of how we think about technologically advanced environments and promote user-friendly technologies for daily living; the initiative has also tried to address the challenges of productivity in an ageing society. This chapter presents examples of how emerging technologies have been employed during the COVID-19 crisis; discusses trends that may heighten the role of emerging technologies in a post-COVID-19 world; and reviews risks to and opportunities of faster adoption of emerging technologies and their implications to human security.",http://dx.doi.org/10.1007/978-981-16-5074-1_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05061-9_38,Social Intelligence Design for Social Computing,"Social Computing and Social Media: Design, User Experience and Impact",10.1007/978-3-031-05061-9_38,Springer,2022-01-01,"Social intelligence Design (SID) is about the impact and significance of technology in our lives, work, home, and on the move. Social Intelligence is defined as the ability of people to relate to, understand and interact effectively with others. The central question is how it can be empowered using emerging technologies. In the information society, new technologies have huge impact on the way people work, interact, and collaborate. They influence the ways they develop personal relationships, as well as enhancing interpersonal communication and professional performance. At the same time, these technologies might amplify miscommunication and bring about new threats and fears. A notorious example is a flaming war, a barrage of postings containing abusive personal attacks, insulting, or chastising replies to other people, which has not been so disastrous before the networked society. Moreover, they provide effective channels for spreading misinformation, catfishing or grooming potential victims, thus amplifying the damaging effects of social misdemeanours. In this paper we address the issues of both beneficial and damaging impacts of emerging technologies on social intelligence and suggest ways of addressing them in the context of social intelligence design (SID). SID is focused not only on the technology design but also on the cognitive, social and organizational context of its use. In this paper we take a holistic approach to emerging technologies inspired by Artificial Intelligence research, bearing in mind their real-life significance [ 1 ].",http://dx.doi.org/10.1007/978-3-031-05061-9_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-04192-1_20,Quality Outlook,From Industry 4.0 to Quality 4.0,10.1007/978-3-031-04192-1_20,Springer,2022-01-01,"Navigating the historical development of quality, from real-world applications and experiences in global industrial production systems and project developmental stages, to how we now know, use, and apply quality in the present age, most certainly reveals its gradual evolution from quality control, through quality assurance, to (total) quality management (T)QM and then quality management system (QMS), as shown in Table 20.1.",http://dx.doi.org/10.1007/978-3-031-04192-1_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-94736-1_11,"Digital Politics, GDPR, and AI","Political, Economic and Legal Effects of Artificial Intelligence",10.1007/978-3-030-94736-1_11,Springer,2022-01-01,"Data conveys noteworthy social, economic, and political power and so unequal control over data is a problem for economic development, human agency, and collective self-determination that must be tackled. AI and big data are driving economic development and social change. AI is a tool of capitalism which alters societies within an environment of technological singularity promoting the expansion of the digital model of economic development. Algorithmic decision-making has to be legitimized as a decisional system. Governing algorithmic decision-making should embrace both individual rights and systemic approaches. Tackling concerns that predictive AI tools are contributing to inequality necessitate broader legal reforms that strengthen employee voice in the workplace. Political effectiveness is increasing as the real information to make intelligent political choice becomes pervasive in society and so greater belief in political effectiveness leads to augmented political participation which means that social networking via AI is a plus in favor of better democracy. The General Data Protection Regulation (GDPR) regulates the processing by an individual, a corporation, or an organization of personal data concerning individuals in the European Union. The borderless character of cyberspace and e-commerce gives the GDPR a wider reach and so this new regulation applies to any processor of EU-citizen data generating vital international inferences, as it regulates many large firms operating and headquartered outside of the EU territories.",http://dx.doi.org/10.1007/978-3-030-94736-1_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82199-9_26,An On-Device Deep Learning Framework to Encourage the Recycling of Waste,Intelligent Systems and Applications,10.1007/978-3-030-82199-9_26,Springer,2022-01-01,"Only 4% of household waste generated in Africa is recycled. Current research uses machine learning models in cloud-based solutions to classify waste. However, in countries with limited internet access, there is a need to increase user engagement in classifying waste using an on-device approach. Developing a machine learning model for a mobile device with limited size and speed is a challenge. This research proposes an on-device deep learning framework to encourage the recycling of household waste. The proposed framework combines an optimal deep learning image classification model and gamification elements. A combination of multiple waste datasets named WasteNet consisting of 33,520 images is used to train the deep learning image classification model using seven classes of recyclable waste namely e-waste, garbage, glass, metal, organic, paper and plastic. Data augmentation and transfer learning techniques are applied to train five models on a mobile device namely, MobileNetV2, VGG19, DenseNet201, ResNet152V2 and InceptionResNetV2. Results of the five models are presented in this paper based on accuracy, loss, latency and size. This research shows promise for InceptionResNetV2, MobileNetV2 and DenseNet201in encouraging householders to engage in recycling waste using gamification on a mobile device.",http://dx.doi.org/10.1007/978-3-030-82199-9_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6054-2_8,Graph Neural Networks: Adversarial Robustness,"Graph Neural Networks: Foundations, Frontiers, and Applications",10.1007/978-981-16-6054-2_8,Springer,2022-01-01,"Graph neural networks have achieved impressive results in various graph learning tasks and they have found their way into many applications such as molecular property prediction, cancer classification, fraud detection, or knowledge graph reasoning. With the increasing number of GNN models deployed in scientific applications, safety-critical environments, or decision-making contexts involving humans, it is crucial to ensure their reliability. In this chapter, we provide an overview of the current research on adversarial robustness of GNNs.We introduce the unique challenges and opportunities that come along with the graph setting and give an overview of works showing the limitations of classic GNNs via adversarial example generation. Building upon these insights we introduce and categorize methods that provide provable robustness guarantees for graph neural networks as well as principles for improving robustness of GNNs. We conclude with a discussion of proper evaluation practices taking robustness into account.",http://dx.doi.org/10.1007/978-981-16-6054-2_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-94590-9_12,Personalized Finance Management for SMEs,Big Data and Artificial Intelligence in Digital Finance,10.1007/978-3-030-94590-9_12,Springer,2022-01-01,"This chapter presents Business Financial Management (BFM) tools for Small Medium Enterprises (SMEs). The presented tools represent a game changer as they shift away from a one-size-fits-all approach to banking services and put emphasis on delivering a personalized SME experience and an improved bank client’s digital experience. An SME customer-centric approach, which ensures that the particularities of the SME are taken care of as much as possible, is presented. Through a comprehensive view of SMEs’ finances and operations, paired with state-of-the-art ML/DL models, the presented BFM tools act as a 24/7 concierge. They also operate as a virtual smart advisor that delivers in a simple, efficient, and engaging way business insights to the SME at the right time, i.e., when needed most. Deeper and better insights that empower SMEs contribute toward SMEs’ financial health and business growth, ultimately resulting in high-performance SMEs.",http://dx.doi.org/10.1007/978-3-030-94590-9_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86165-0_35,Food Detection and Nutritional Recognition System Using Neural Networks,"International Conference on Computing, Communication, Electrical and Biomedical Systems",10.1007/978-3-030-86165-0_35,Springer,2022-01-01,"The purpose of this research paper is to implement a user preference-based recommendation system that not only detects food items but also gives nutritional content of the food specially fruits, diet suggestions for the targeted calorie values, and special diet for diseased persons and also the combination of food that harms the digestive system. The proposed methodology incorporates a model for the food varieties specially fruits using deep learning and convolutional neural networks (CNN). The neural network model takes input as image and text data, analyzes it by using SoftMax activation function it provide multi classification and gives the nutritional values. The methodology uses stochastic gradient descent (SGD)which is a simplified optimization algorithm for large-scale datasets. The output values are displayed through a dedicated website designed to show the nutritional contents, user recommendation diet plan, disease-based diet plan, etc. In addition to this, the proposed paper focuses to help the people to improve their dietary habits and lead to the minimal health risks.",http://dx.doi.org/10.1007/978-3-030-86165-0_35,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11533-4,A hybrid approach for identifying non-human traffic in online digital advertising,Multimedia Tools and Applications,10.1007/s11042-021-11533-4,Springer,2022-01-01,"Click fraud is a serious problem facing online advertising business. The malicious intent of clicking online ads either committed by humans or by non-humans, forced financial losses on advertisers utilizing pay-per-click advertising. Non-human traffic is usually designed to inflate web traffic for fraudulent purposes. In this paper, we demonstrate a hybrid approach consisting of two-level fingerprint applied in two phases to detect illegitimate non-human traffic. The first-level fingerprint is a pattern generated using immutable information about a user navigating a website’s pages. It will be used in the first traffic illegitimacy detection phase to infer rules about illegitimate non-human traffic from a developed ontology about web traffic legitimacy. The second-level fingerprint is generated using behavioral ad click patterns, which will be used in the second detection phase by applying a Machine-Learning (ML) algorithm. To test the proposed approach, a real commercial website for ads, called Waseet.com, was used. The access logs of the website server were utilized for the purpose of this research. The experiments show that our proposed hybrid approach using the ontology of web traffic illegitimacy and the ML k-NN classifier detects around (98.6%) of fake clicks.",http://dx.doi.org/10.1007/s11042-021-11533-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98785-5_1,LogoMotive: Detecting Logos on Websites to Identify Online Scams - A TLD Case Study,Passive and Active Measurement,10.1007/978-3-030-98785-5_1,Springer,2022-01-01,"Logos give a website a familiar feel and promote trust. Scammers take advantage of that by using well-known organizations’ logos on malicious websites. Unsuspecting Internet users see these logos and think they are looking at a government website or legitimate webshop, when it is a phishing site, a counterfeit webshop, or a site set up to spread misinformation. We present the largest logo detection study on websites to date. We analyze 6.2M domain names from the Netherlands ’ country-code top-level domain .nl , in two case studies to detect logo misuse for two organizations: the Dutch national government and Thuiswinkel Waarborg , an organization that issues certified webshop trust marks. We show how we can detect phishing, spear phishing, dormant phishing attacks, and brand misuse. To that end, we developed LogoMotive , an application that crawls domain names, generates screenshots, and detects logos using supervised machine learning. LogoMotive is operational in the .nl registry, and it is generalizable to detect any other logo in any DNS zone to help identify abuse.",http://dx.doi.org/10.1007/978-3-030-98785-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-99000-8_23,The Impact of Major Technologies in Fourth Industrial Revolution,Future of Organizations and Work After the 4th Industrial Revolution,10.1007/978-3-030-99000-8_23,Springer,2022-01-01,"The Fourth Industrial Revolution (4IR) was revealed by researcher, Klaus Schwab, when he was serving as CEO of the World Economic Forum. This term is a title for the exceptional situation in which we live today, from the heavy reliance on various types of technology running our daily lives, such as factories, agriculture and motor vehicles. In addition, Artificial Intelligence (AI) has become a basic concept for public life, factories and life technology. The 4IR was built on the basis of the previous revolution, and the Fifth Industrial Revolution will derive its strength from the one that preceded it. In this research, we will present an analysis of the most important technology features that drive the 4IR, such as AI, big data, the Internet of things, and others. Each unit of this technology has a prominent role in influencing the scientific and industrial environment. Likewise, this technology merges with each other to produce new technology that contributes to solving scientific or industrial problems.",http://dx.doi.org/10.1007/978-3-030-99000-8_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90421-0_3,Digital-Body (Avatar) Library for Textile Industry,Digitizing Production Systems,10.1007/978-3-030-90421-0_3,Springer,2022-01-01,"Personalized garment design and virtual assembly application of a garment is one of the most important goals for almost all textile companies. Aligning the designing of dress on the virtual garment with the feature points of the human body and can be considered as a success factor. For this reason, it is best solution to measure the human body and to find the dimensions and to produce tailor made garment according to sizing of body. Clothing sizes have been a challenge for the apparel industry. This is because, difficulties arising from to find the right size when purchasing an outfit. Customers are often disappointed with their product deliveries, causing them to be disappointed and less likely to buy clothes online. Increased returns and reduced customer loyalty have negative effects on profit margins. Considering the fit dress problem, it is necessary to create a body database that every company can use. The sensible solution of this problem is to create a common digital body library. The aim of Digital-body (avatar) library is an ongoing process from measuring the customer's body to dressing according to the customization garment, and dramatically to reduce return rates due to non-fitting dresses over internet sales. It is needed a redesign for the sizing system, and it will be new paradigm shift in tailor made production for apparel industry system and to thrive the appeal industry. Digital Body Library will affect the dress which every sale in the future.",http://dx.doi.org/10.1007/978-3-030-90421-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95987-6_15,A Novel Dual Prediction Scheme for Data Communication Reduction in IoT-Based Monitoring Systems,IoT as a Service,10.1007/978-3-030-95987-6_15,Springer,2022-01-01,"Internet of things (IoT) based monitoring systems became commonplace. These systems are built upon a large number of devices and sensors. The data collection task of a large number of sensors and devices in an IoT system includes a massive number of data communications. The more the number of devices, the critical is the network bottleneck. In this context, the dual prediction scheme was proposed as a solution for mitigating the large size of communication volumes. The dual prediction scheme consists of a model for predicting future measurements based on historical data. This model is duplicated on both sides, the edge side (i.e., sensor) and the data collection device (i.e., cluster head). The literature includes several works which proposed many dual prediction schemes based on several techniques such as filters and moving average. The literature does not include utilizing the ensemble learning models. This motivates this work to investigate the gradient boosting regression model’s performance compared to the existing solutions. The proposed and state-of-the-art models are evaluated on a realistic dataset. The obtained results show that the proposed model outperforms the existing dual prediction schemes in terms of communication reduction.",http://dx.doi.org/10.1007/978-3-030-95987-6_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70501-5_11,Blockchain Technology: A Boon at the Pandemic Times – A Solution for Global Economy Upliftment with AI and IoT,Blockchain Security in Cloud Computing,10.1007/978-3-030-70501-5_11,Springer,2022-01-01,"Blockchain technology is a potential sector at the foreground, though it is currently in its embryonic form, but will retain itself as an emerging technology at an early stage. Besides blockchain being a trusted, decentralized database, it has its success in many applications across various fields like education, medicine, insurance, finance, energy, environment, supply chain management, and various other associated operations. The work provides a systematic survey of blockchain, how it works, and its characteristics, applications, and challenges. The aim is to investigate how blockchain technology, besides artificial intelligence and the Internet of Things, would be an effective factor to fight the current pandemic scenario. To the end, a brief survey is carried out on how blockchain technology would be fruitful in uplifting the global economy post-COVID, with a summary of the blockchain toolkit by the World Economic Forum.",http://dx.doi.org/10.1007/978-3-030-70501-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-99736-6_18,Ensemble Model Compression for Fast and Energy-Efficient Ranking on FPGAs,Advances in Information Retrieval,10.1007/978-3-030-99736-6_18,Springer,2022-01-01,"We investigate novel SoC-FPGA solutions for fast and energy-efficient ranking based on machine-learned ensembles of decision trees. Since the memory footprint of ranking ensembles limits the effective exploitation of programmable logic for large-scale inference tasks, we investigate binning and quantization techniques to reduce the memory occupation of the learned model and we optimize the state-of-the-art ensemble-traversal algorithm for deployment on low-cost, energy-efficient FPGA devices. The results of the experiments conducted using publicly available Learning-to-Rank datasets, show that our model compression techniques do not impact significantly the accuracy. Moreover, the reduced space requirements allow the models and the logic to be replicated on the FPGA device in order to execute several inference tasks in parallel. We discuss in details the experimental settings and the feasibility of the deployment of the proposed solution in a real setting. The results of the experiments conducted show that our FPGA solution achieves performances at the state of the art and consumes from 9 $$\times $$ × up to 19.8 $$\times $$ × less energy than an equivalent multi-threaded CPU implementation.",http://dx.doi.org/10.1007/978-3-030-99736-6_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-00126-0_5,Enhancing Graph Convolution Network for Novel Recommendation,Database Systems for Advanced Applications,10.1007/978-3-031-00126-0_5,Springer,2022-01-01,"Graph convolution network based recommendation methods have achieved great success. However, existing graph based methods tend to recommend popular items yet neglect tail ones, which are actually the focus of novel recommendation since they can provide more surprises for users and more profits for enterprises. Furthermore, current novelty oriented methods treat all users equally without considering their personal preference on popular or tail items. In this paper, we enhance graph convolution network with novelty-boosted masking mechanism and personalized negative sampling strategy for novel recommendation. Firstly, we alleviate the popularity bias in graph based methods by obliging the learning process to pay more attention to tail items which are assigned to a larger masking probability. Secondly, we empower the novel recommendation methods with users’ personal preference by selecting true negative popular samples. Extensive experimental results on three datasets demonstrate that our method outperforms both graph based and novelty oriented baselines by a large margin in terms of the overall F-measure.",http://dx.doi.org/10.1007/978-3-031-00126-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97652-1_43,"Unveiling a Novel Corporate Structure in World-Class Business, Merging Digital-Physical Environment in Hyper Famili Incorporation",ITNG 2022 19th International Conference on Information Technology-New Generations,10.1007/978-3-030-97652-1_43,Springer,2022-01-01,"In this paper we aim to design a brand new corporate structure which merges Physical and Digital Technology in World-Class Business, whilst utilizing new technologies based on digitalization drivers. We propose a method in which we have introduced a state of the art Organizational structure that surveys our world-class Business Model case studies and all of the mandatory technologies which shape the fundamental framework of such innovative business ecosystems that end up as the most important input for the decision making process in management levels. In the upcoming research we will be comparing this model with other models in different aspects like comparability in utilizing brand new technologies to building up the dominant share of global market.",http://dx.doi.org/10.1007/978-3-030-97652-1_43,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-02447-4_41,OntoKIQE: An Ontology Infused Approach for Knowledge Integrated Query Expansion Using Semantic Intelligence,Digital Technologies and Applications,10.1007/978-3-031-02447-4_41,Springer,2022-01-01,"As the Web 2.0 moves towards the Web 3.0 there is an increasing need for simple and efficient information retrieval techniques. Yielding the users’ required search intent has proved to be an exhaustive and tedious task from just using Mutual Information model (NPMI) and the Pielou’s Evenness Index (PEI), along with Domain Ontology based query term enrichment and Knowledge enrichment of the term pool with the help of Wikidata API. The user input terms, resulting in unreliable and quavering search results. To solve this issue efficiently, we deploy semantically compliant automatic query expansion techniques. The proposed OntoKIQE model is composed of three primary statistical base models namely Bose Einstein-1, Normalized Pointwise Accuracy and Recall percentages of 94.18 and 92.84 respectively have been yielded by the proposed model, being a substantial improvement over the baselined models by enriching the query terms with auxiliary background knowledge and generating ontologies.",http://dx.doi.org/10.1007/978-3-031-02447-4_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-82715-1_2,An Overview of Security and Privacy in Smart Cities,IoT and IoE Driven Smart Cities,10.1007/978-3-030-82715-1_2,Springer,2022-01-01,"In the twenty-first century, so many technological paradigms emerged as the result of the technological advancement of information and communication technology (ICT). Many of the technologies were used as an aid for fulfilling human needs and mitigating many of the problems associated with the environment and making everyone connected. In order to mitigate the problem of rapid urbanization smart city concept has emerged and it is being used to streamline the functions of urban cities and make the lives of citizens more easy and convenient. In a typical smart city context, citizens are already interconnected via smart mobile devices and wearable devices. The hospitals, vehicles, houses, traffic surveillance systems, public places, and other social systems in the city are all connected over the Internet, which is known as the Internet of Things (IoT). This will contribute to unprecedented changes in the condition of life in the city. In public care, public safety, emergency management, and disaster recovery, these pervasive systems which are linked through the Internet can assist citizens with greater benefits. The world is now witnessing a boom of smart cities. Although smart cities have many advantages, such as creating new economic and social possibilities, there are many challenges, such as security and privacy. These security and privacy challenges include unauthorized access to information and attacks that cause physical interruptions in the provision of city services. As all people in the city are linked to each other through the underlying ubiquitous communication technologies in the smart city, security problems can arise as a result of the vulnerabilities present in the city infrastructure, communication networks, and human errors. Different applications used in smart cities can also present new vulnerabilities, so the attackers can gain access to information which is highly confidential. The purpose of this study is to provide an extensive analysis of security and privacy problems in smart cities.",http://dx.doi.org/10.1007/978-3-030-82715-1_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-7440-8_6,Enterprise Data Management,Event- and Data-Centric Enterprise Risk-Adjusted Return Management,10.1007/978-1-4842-7440-8_6,Springer,2022-01-01,"Accounting and risk data have common elements, but there are fundamental differences in their character and usage. This chapter explains enterprise data management by focusing on the data common to both the accounting and the risk management systems.",http://dx.doi.org/10.1007/978-1-4842-7440-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-94736-1_3,Digital Economy and Politics,"Political, Economic and Legal Effects of Artificial Intelligence",10.1007/978-3-030-94736-1_3,Springer,2022-01-01,"MNEs’ activity and FDI arise endogenously in settings characterized by financial differences. Financial globalization allows a better environment where capital will be moved around the world with less possible barriers where productivity will bring higher profit. The digital economy offers consumers access to information formerly inconceivable in any traditional marketplace. FinTech companies are revolutionizing the core structure of the financial industry. Political zest for fintech is the outgrowth of a larger issue because the greater and more valuable use of technology has the prospective to expand access to financial products and services on terms that are more reasonable and so fintech innovation, when regulated properly, creates positive societal results for consumers. ZEKIPR–ZEKEUIPR indexes show that significance of IPRs protection in attracting FDI in a digital Economy.",http://dx.doi.org/10.1007/978-3-030-94736-1_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-8248-3_18,Internet of Things (IoT) for Healthcare Systems: A Comprehensive Survey,Recent Innovations in Computing,10.1007/978-981-16-8248-3_18,Springer,2022-01-01,"Earlier, patients’ and doctors’ interactions were limited, and is impossible to monitor patients’ health continuously and make recommendations accordingly, but it is now possible after the emergence of the Internet of Things (IoT). IoT in healthcare provides interoperability, machine-to-machine (M2M) communication, data exchange that make service delivery effective. It helps patients remotely track their health by using smartwatches, fitness bands, etc. devices, and for doctors to keep track of their health. In this chapter, we first describe the issues by using IoT in different domains then explain its applications in the real world, after that a brief explanation is given for the scope of IoT in healthcare and hospitals. The contribution of several researchers on IoT and its application in the healthcare system and its services is discussed. This survey provides useful information to researchers to identify the main issues and challenges of IoT-based healthcare system and to understand the application of the IoT in a different field and also helps to understand the prior contribution of the IoT in the medical industry.",http://dx.doi.org/10.1007/978-981-16-8248-3_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05544-7_31,Designing a Worker Companion - Design Implications from On-Site and Remote Participatory Design in the Context of Industry 4.0,"HCI in Business, Government and Organizations",10.1007/978-3-031-05544-7_31,Springer,2022-01-01,"The Industry 4.0 paradigm requires not only equipping the shop floor and the workforce with new digital tools, but also ensuring that digital technologies are well accepted and adopted by workers. This is achieved through the active involvement of those who will be affected by these new digital technologies. However, the involvement of end-users and workers in the design process is often confined to test fully developed solutions. Rarely are the workers fully involved in the design process, from preliminary research to the co-design of the proposed technologies. As such, and in order to involve workers on the design of a digital companion for shop floor operators, we applied a Participatory Design approach, with mixed-methods, consisting of fieldwork observations, interviews, and exploratory workshops with workers and other relevant stakeholders in order to understand their needs and desires in the context of Industry 4.0. These activities were conducted remotely and in situ, and aimed to identify issues concerning the worker, the workplace, and concerns regarding their physical and mental well-being. In this paper, we describe the process of designing the worker companion-the methods, main insights from the user research activities, and an initial prototype.",http://dx.doi.org/10.1007/978-3-031-05544-7_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6301-7_3,Security Magnification in Supply Chain Management Using Blockchain Technology,Blockchain Technologies for Sustainability,10.1007/978-981-16-6301-7_3,Springer,2022-01-01,"In supply chain management the necessity for data transparency is very essential as it is key to create trust between retailers and customers. But data managed by centralized controllers face several vulnerabilities and security threats like data breaches, data confidentiality, and many more. Blockchain is a digital and distributed ledger has acquired great popularity in recent years, due to its security, immutability, and transparency in data. It solves many challenges like keeping the data secure by using cryptographic algorithms. It is a decentralized ledger for recording, managing, storing, and transmitting data in a peer-to-peer network. This paper aims to provide a brief survey on the magnification of security in supply chain operations using blockchain, further indicating the challenges encountered during the integration. The work presents a descriptive study of past literature on blockchain for intensifying security in supply chain operations by examining the features provided by blockchain technology. Further, the paper provides an insight into how blockchain is transforming the business by providing safe and automated solutions. Additionally, this paper highlights the motivation behind using blockchain technology in supply chain management. Further, the work investigates how leveraging blockchain can help in overcoming vulnerabilities and avoiding fraudulent activities in the traditional supply chain. Finally, the paper highlights the uses of the blockchain-based business and enumerates the related future research directions.",http://dx.doi.org/10.1007/978-981-16-6301-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7985-8_54,A Review on Distributed Data Vending Through Blockchain,ICCCE 2021,10.1007/978-981-16-7985-8_54,Springer,2022-01-01,"The paradigm of Data vending has been one of the most innovative concept that have been implemented on the distributed system scenario. The Data vending approach is highly beneficial for the purpose of enabling effective and efficient usage of the data throughout the world. But there are a few downsides that have been noticed about the concept of Data vending As the Distributed systems have a lot of sensitive and personally identifiable information, it is problematic to share with untrusted institutions. Therefore, this creates mistrust between the Data vendors and Data Aggregators. To eliminate this effect and provide a solution for this problem, this research article outlines related works on the paradigm of data sharing. The devised approach overcomes the security concerns through the implementation of an effective access control mechanism through the utilization of the Distributed blockchain framework. The technique is designed to implement NLP protocols along with the RCC Encryption algorithm to achieve effective and secure access control mechanism for the Data Vending platform. This approach will be elaborated in the future researches.",http://dx.doi.org/10.1007/978-981-16-7985-8_54,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-87954-9_3,Multi-agent Systems for Distributed Data Mining Techniques: An Overview,Big Data Intelligence for Smart Applications,10.1007/978-3-030-87954-9_3,Springer,2022-01-01,"The term “multi-agent systems” (MAS) refers to a mechanism that is used to create goal-oriented autonomous agents in a shared environment and have communication and coordination capabilities. This goal-oriented mechanism supports distributed data mining (DM) to implement various techniques for distributed clustering, classification, and prediction. Different distributed DM (DDM) techniques, MASs, the advantages of MAS-based DDM, and various MAS-based DDM approaches proposed by researchers are reviewed in this study.",http://dx.doi.org/10.1007/978-3-030-87954-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6054-2_6,Graph Neural Networks: Scalability,"Graph Neural Networks: Foundations, Frontiers, and Applications",10.1007/978-981-16-6054-2_6,Springer,2022-01-01,"Over the past decade, Graph Neural Networks have achieved remarkable success in modeling complex graph data. Nowadays, graph data is increasing exponentially in both magnitude and volume, e.g., a social network can be constituted by billions of users and relationships. Such circumstance leads to a crucial question, how to properly extend the scalability of Graph Neural Networks? There remain two major challenges while scaling the original implementation of GNN to large graphs. First, most of the GNN models usually compute the entire adjacency matrix and node embeddings of the graph, which demands a huge memory space. Second, training GNN requires recursively updating each node in the graph, which becomes infeasible and ineffective for large graphs. Current studies propose to tackle these obstacles mainly from three sampling paradigms: node-wise sampling, which is executed based on the target nodes in the graph; layer-wise sampling, which is implemented on the convolutional layers; and graph-wise sampling, which constructs sub-graphs for the model inference. In this chapter, we will introduce several representative research accordingly.",http://dx.doi.org/10.1007/978-981-16-6054-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-57413-4_3,Field Experiments,Handbook of Market Research,10.1007/978-3-319-57413-4_3,Springer,2022-01-01,"Digitalization of value chains and company processes offers new opportunities to measure and control a firm’s activities and to make a business more efficient by better understanding markets, competitors, and consumers’ behaviors. Among other methodologies, field experiments conducted in online and offline environments are rapidly changing the way companies make business decisions. Simple A/B tests as well as more complex multivariate experiments are increasingly employed by managers to inform their marketing decisions. This chapter explains why field experiments are a reliable way to reveal and to prove that a business action results in a desired outcome and provides guidelines on how to perform such experiments step by step covering issues such as randomization, sample selection, and data analysis. Various practical issues in the design of field experiments are covered with the main focus on causal inference and internal and external validity. We conclude the chapter with a practical case study as well as a brief literature review on recent published articles employing field experiments as a data collection method, providing the reader with a list of examples to consider and to refer to when conducting and designing a field experiment.",http://dx.doi.org/10.1007/978-3-319-57413-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02181-7_3,Multi-Stage Architectures for Reranking,Pretrained Transformers for Text Ranking,10.1007/978-3-031-02181-7_3,Springer,2022-01-01,"The simplest and most straightforward formulation of text ranking is to convert the task into a text classification problem, and then sort the texts to be ranked based on the probability that each item belongs to the desired class. For information access problems, the desired class comprises texts that are relevant to the user’s information need (see Section 2.2), and so we can refer to this approach as relevance classification.",http://dx.doi.org/10.1007/978-3-031-02181-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6166-2_8,Heterogeneous Graph Representation for Text Mining,Heterogeneous Graph Representation Learning and Applications,10.1007/978-981-16-6166-2_8,Springer,2022-01-01,"Heterogeneous graph representation techniques can be applied in many real-world applications. Even the natural languages that are usually modeled as sequential data can also be constructed as a heterogeneous graph by some techniques, so as to widely and accurately capture the complex interactions among the words, entities, topics, instances, and other components of the texts. In this chapter, we focus on summarizing the heterogeneous graph representation applications on text mining. Particularly, we introduce several heterogeneous graph based text mining methods, including HGAT for short text classification, GUND and GNewsRec for news recommendation. In the field of heterogeneous graph representation for text mining, methods mainly contain two key components: heterogeneous graph construction from texts and heterogeneous graph representation algorithm for tasks. We will roughly illustrate heterogeneous graph modeling for text mining tasks from these two points.",http://dx.doi.org/10.1007/978-981-16-6166-2_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11564-x,User encoding for clustering in very sparse recommender systems tasks,Multimedia Tools and Applications,10.1007/s11042-021-11564-x,Springer,2022-01-01,"Recommender Systems are a very useful tool which let companies and service providers focus in the preferences of their customers, helping them to avoid an overwhelming variety of choices. In this context, clustering tools can play an important role to detect groups of customers with similar tastes. Thus, companies can make personalized marketing campaigns, offering to their users new products which have been consumed by other users with comparable preferences. In this paper we present a general framework to cluster users with respect to their tastes when the registers stored about the interactions between users and products are extremely scarce. Commonly, clustering methods employ the values of features describing the samples to be clustered (users in our case), but such features are not always available. We propose some alternative representations for users, in which their tastes are gathered to some extent, so that clustering algorithms can take advantage and make more homogeneous groups in this regard. To illustrate the performance of the whole framework, we tested it on six popular datasets commonly used as a benchmark for recommender systems, as well as on an extremely sparse real-world dataset that records the preferences of readers to click promoted links in digital publications. In the experimental section we compare our proposed representations to other common user encodings. We show that clustering users attending only to their feature values or to the items they have evaluated gives rise to the worst scores in terms of taste homogeneity.",http://dx.doi.org/10.1007/s11042-021-11564-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-82755-7_4,Digital Transformation of Businesses in Times of Global Crisis,Navigating Through the Crisis – A special Issue on the Covid 19 Crises,10.1007/978-3-030-82755-7_4,Springer,2022-01-01,"Our aim is to discuss the acceleration of the implementation of digital transformation based on artificial intelligence and data due to the COVID-19 global pandemic. Given the current global context, businesses are fundamentally reshaping. We have identified that digital transformation of businesses is accelerating. Every aspect of the business is changing starting from how employees work, monitoring supply chains, and continuing to how businesses are changing various processes by using automation on a widespread scale. It is important to mention that while some businesses, mostly those with a business model based on online activities, are thriving in this global crisis because of the increasing number of consumers, several other companies are seeing a decline in customer numbers and business turnover. The decline due to COVID-19 lockdown is not seen only in businesses that offer tangible products but also in the digital business of the sharing economy due to decrease of both demand and offer. Consuming patterns of customers are changing, and now more than ever businesses must harvest the data for getting better insight. Our methodology consisted of academic literature research, data analysis, and case study of relevant businesses.",http://dx.doi.org/10.1007/978-3-030-82755-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1496-6_5,AI’s Implication for International Law,Artificial Intelligence and International Law,10.1007/978-981-19-1496-6_5,Springer,2022-01-01,"There are diverse ripple effects flowing from the advent of AI. To the extent that it affects and changes the entire spectrum and echelon of human society and behavior, it should also bring significant changes to the international community in general and thus to the study and jurisprudence of international law as well. In addition, these significant changes relate to both the present and future of international law. In other words, they affect how current international law is interpreted and applied.",http://dx.doi.org/10.1007/978-981-19-1496-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05643-7_2,Measuring and Predicting Human Trust in Recommendations from an AI Teammate,Artificial Intelligence in HCI,10.1007/978-3-031-05643-7_2,Springer,2022-01-01,"Predicting compliance with AI recommendations and knowing when to intervene are critical facets of human-AI teaming. AIs are typically deployed in settings where their abilities to evaluate decision variables far exceed the abilities of their human counterparts. However, even though AIs excel at weighing multiple issues and computing near optimal solutions with speed and accuracy beyond that of any human, they still make mistakes. Thus, perfect compliance may be undesirable. This means, just as individuals must know when to follow the advice of other people, it is critical for them to know when to adopt the recommendations from their AI. Well-calibrated trust is thought to be a fundamental aspect of this type of knowledge. We compare the ability of a common trust inventory and the ability of a behavioral measure of trust to predict compliance and success in a reconnaissance mission. We interpret the experimental results to suggest that the behavioral measure is a better predictor of overall mission compliance and success. We discuss how this measure could possibly be used in compliance interventions and related open questions.",http://dx.doi.org/10.1007/978-3-031-05643-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05643-7_26,Scene Change Captioning in Real Scenarios,Artificial Intelligence in HCI,10.1007/978-3-031-05643-7_26,Springer,2022-01-01,"This paper discusses the scene change captioning task that describes scene changes using natural language for real scenarios. Most current three-dimensional understanding tasks focus on recognizing static scenes. Despite its importance in a variety of real environment applications, scene change understanding remains less discussed. Existing change understanding methods discussed in robotics focus on change detection and lack the ability to perform detailed recognition of scene changes. Most previous experiments on change captioning methods were conducted on simulation datasets with limited visual complexity, limiting their availability for real scenarios. To solve the above issues, we propose a scene change captioning dataset with scenes photographed using RGB-D cameras. We also propose an automatic simulation dataset generation process, aiming for training models transferring to real scenarios. We conducted experiments with various input modalities and proposed a method that integrates different input modalities using an attention mechanism over modalities and dynamic attention to select related information during the sentence generation process. The experimental results show that models trained on the proposed simulation dataset obtained promising results on real scenario dataset, indicating the proposed dataset generation process’s practicality in real scenarios. The proposed multimodality integrating method can generate change captions with high change type and object attribute accuracy while showing robustness in real scenarios. We hope our work can open a door for future research on scene change understanding in real scenarios.",http://dx.doi.org/10.1007/978-3-031-05643-7_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-90800-3_3,Digitalization in Air Transportation and Reflections on SCRM,Supply Chain Risk Management,10.1007/978-3-030-90800-3_3,Springer,2022-01-01,"Digitalization, which is the absolute necessity of business practices and business models in the twenty-first century, must be optimally reflected in the processes, philosophy, and stakeholder relations of supply chain management (SCM) applications. It is the risk management-based supply chain management system that guides these reflection efforts and provides reasonable assurance regarding the achievement of such optimization.",http://dx.doi.org/10.1007/978-3-030-90800-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04216-4_16,Social CRM as a Business Strategy: Developing the Dynamic Capabilities of Micro and Small Businesses,Business Information Systems Workshops,10.1007/978-3-031-04216-4_16,Springer,2022-01-01,"The global pandemic, caused by the spread of COVID-19, has altered the way people go shopping. In light of this, Social Media channels are an important means of sharing information about goods and services, and different kinds of brands. Since these channels are of considerable market significance, the authors of this paper decided to describe the results of a survey on how to use Social Media to improve customer relationship management processes in 31 companies. The focus was on digital marketing for micro and small businesses. In addition, an in-depth analysis was conducted of four companies, to determine the challenges and strategies in social customer relationship management adopted by micro and small businesses. The results show that this is still a new policy for micro and small companies, but has a great potential to boost sales, enhance customer loyalty and increase brand awareness. The lessons learned can assist policymakers in taking more suitable measures for strengthening this market sector.",http://dx.doi.org/10.1007/978-3-031-04216-4_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-86749-2_17,Secure and Enhanced Crowdfunding Solution Using Blockchain Technology,"Transforming Management with AI, Big-Data, and IoT",10.1007/978-3-030-86749-2_17,Springer,2022-01-01,"In the modern world, online crowdfunding plays an important role where many investors can fund projects presented by various creators. Our project aims to compare the pros and cons of conventional crowdfunding and blockchain crowdfunding. In conventional crowdfunding, one faces many issues such as transparency issues, fraudulent issues, investor abuse etc. However, to overcome these issues, blockchain crowdfunding comes into play. Blockchain crowdfunding helps to overcome the issues faced in conventional crowdfunding. To implement blockchain crowdfunding, we have proposed a model named ‘Block Funding’, which is made using Ethereum smart contracts. It consists of a web app made of React/Next.js and Ethereum smart contracts used in the backend. It primarily focuses on all the basic crowdfunding features as well as voting through blockchain. Moreover, the model is deployed on a Rinkeby test network.",http://dx.doi.org/10.1007/978-3-030-86749-2_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95593-9_23,When Federated Learning Meets Vision: An Outlook on Opportunities and Challenges,Body Area Networks. Smart IoT and Big Data for Intelligent Health Management,10.1007/978-3-030-95593-9_23,Springer,2022-01-01,"The mass adoption of Internet of Things (IoT) devices, and smartphones has given rise to the era of big data and opened up an opportunity to derive data-driven insights. This data deluge drives the need for privacy-aware data computations. In this paper, we highlight the use of an emerging learning paradigm known as federated learning (FL) for vision-aided applications, since it is a privacy preservation mechanism by design. Furthermore, we outline the opportunities, challenges, and future research direction for the FL enabled vision applications.",http://dx.doi.org/10.1007/978-3-030-95593-9_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96648-5_12,Gender Classification Models and Feature Impact for Social Media Author Profiling,Evaluation of Novel Approaches to Software Engineering,10.1007/978-3-030-96648-5_12,Springer,2022-01-01,"Automatic profiling models infer demographic characteristics of social network users from their generated content or interactions. Due to its use in business (targeted advertising, market studies...), automatic user profiling from social networks has become a popular task. Users’ demographic data is also crucial information for more socially concerning tasks, such as automatic early detection of mental disorders. For this type of users’ analysis task, it has been demonstrated that the way users employ language is an essential indicator that contributes to the effectiveness of the models. For this reason, we also believe that considering the usage of the language from both psycho-linguistic and semantic characteristics it is useful for detecting variables such as gender, age, and user’s origin. A proper selection of features will be critical for the performance of retrieval, classification, and decision-making software systems, a proper selection of features will be critical. In this work, we shall discuss gender classification as a part of the automated profiling task. We present an experimental analysis of the performance of existing gender classification models for automated profiling based on external corpus and baselines. We also investigate the role of linguistic characteristics in the model’s classification accuracy and their impact on each gender. Following that analysis, we have developed a feature set for gender classification models in social networks that outperforms existing benchmarks in terms of accuracy.",http://dx.doi.org/10.1007/978-3-030-96648-5_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1076-0_17,"A Systematic Review on Blockchain Technology: Concepts, Applications, and Prospects in Healthcare",Augmented Intelligence in Healthcare: A Pragmatic and Integrated Analysis,10.1007/978-981-19-1076-0_17,Springer,2022-01-01,"Blockchain technology is the “fifth evolution” in the era of computing. The characteristics of blockchain such as immutability, tamper-proof, decentralized, private, and permissioned blockchain have attracted the world's attention. This paper briefs about the core concepts of blockchain, smart contracts, and architecture behind the integration of IoT devices and blockchain. The proposed architecture using the blockchain and Inter Planetary File System (IPFS) improves the way of storing, handling, and sharing medical data and records. A comprehensive study on blockchain-based smart applications across diverse sectors such as financial, manufacturing, supply chain, healthcare sectors is also included in this paper. Finally, the paper also enumerates challenges, limitations, and future trends in the area of blockchain.",http://dx.doi.org/10.1007/978-981-19-1076-0_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66607-1_8,Smart Cities New Paradigm Applications and Challenges,Immersive Technology in Smart Cities,10.1007/978-3-030-66607-1_8,Springer,2022-01-01,"The transition from legacy to intelligent cities requires clear understanding of the cities’ current status and the available technologies of fourth industrial revolutionary that could support the paradigm of smart city. This chapter demonstrates the need for smart cities in our lives and the technologies available that support the applications needed for a smart city. We also discuss how the service demand style evolved from the Push model, where user input or innovations are not considered, into the ecosystem’s service delivery model. The chapter illustrates a proposed model for the smart city where stakeholder collaboration plays a significant role in the delivery and customization of services. The chapter describes the layered model proposed with a focus on infrastructure and the layers of applications. It demonstrates two smart subsystems, the intelligent energy system and the intelligent transport systems, emphasizing on standardization protocols that policymakers and decision makers must deal with. The chapter also discusses the aspects of the smart application for smart cities and the barriers to the transformation program.",http://dx.doi.org/10.1007/978-3-030-66607-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9194-2_2,Internet of Things,Internet of Things and BDS Application,10.1007/978-981-16-9194-2_2,Springer,2022-01-01,"Internet of things (IOT) is a kind of network that collects real-time information through various information sensing devices, connects any real object in the physical world with the Internet according to the pre-defined protocol. IOT carries out information transmission and interaction, to achieve the purpose of intelligent identification, accurate positioning, tracking and control of information.",http://dx.doi.org/10.1007/978-981-16-9194-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-6210-2_16,"Architecture, Security Vulnerabilities, and the Proposed Countermeasures in Agriculture-Internet-of-Things (AIoT) Systems","Internet of Things and Analytics for Agriculture, Volume 3",10.1007/978-981-16-6210-2_16,Springer,2022-01-01,"In recent years, along with the rise in the population, the demand for food has also increased which led to the need for industrialization as well as intensification of agricultural sector. The Internet-of-Things (IoT) has been a promising technology that offers extended solutions towards the development of agriculture. Various research institutions and scientific groups, as well as industries, are trying to cope with the challenges by delivering more and more IoT products for agricultural sector. In this paper, we aim to provide a survey of IoT systems, its enabling technologies, and communication technologies. Moreover, we provide insights into IoT enabled agricultural applications along with its architecture and research challenges. Finally, we discussed the security and privacy issues that occur in agriculture IoT along with some cybersecurity attacks.",http://dx.doi.org/10.1007/978-981-16-6210-2_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98206-5_9,Courts and Arbitration Advancements,Advanced Artificial Intelligence and Robo-Justice,10.1007/978-3-030-98206-5_9,Springer,2022-01-01,"ADR merely institutionalizes a system of multi-party bargaining in which third-party neutrals assist disputants ascertain individual interests. The rapid growth of ODR has precipitated more changes in the administration of justice. Digital systems which process information are powerful but also riskier due to learning ability and robotics. Learning ability signifies the fact that digital systems no longer have to be entirely programmed. The use of artificial intelligence in practice forces interrogates the likelihood of using artificial intelligence in the judiciary. The future of the judiciary depends on the further development of artificial intelligence. The use of various technologies in the judiciary is noticeable to everyone and the judges are assisted by computer programs. While use of AI and algorithms are useful to assist in making reasoned judgments, there is a risk that technology will replace human judgment. The courts are deploying ODR for certain types of cases, such as tax, parking fines, speeding tickets, and small claims. Blockchain technology is improving efficiency in dispute resolution allowing assets to be sent across the world in seconds. the central rationale of online courts is to protect the rights of litigants, advance their user experiences, and help them achieve justice with minimal cost which means that robo-courts utilizing AAI technology will shape an automated decision-making mechanism contributing to a better justice.",http://dx.doi.org/10.1007/978-3-030-98206-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83799-0_2,Basics of Financial Data Analytics,Financial Data Analytics,10.1007/978-3-030-83799-0_2,Springer,2022-01-01,"There is enormous structured and unstructured data generated every moment in the financial sector in the digitalized era. The data can be used to create strategies for related parts of the financial sector. Even though some statistical properties of financial data have been studied using data from various sources for over half a century, the availability of big data in the financial sector and the developed applications of computer-intensive techniques for investigating their properties have opened new horizons to analysts in the sector in the last two decades. Digitization in the financial sector has enabled technology forms of advanced data analytics. In this book, most of these financial data analysis issues are tried to be addressed. This chapter is handled as an introduction to the subject. Therefore, in this chapter, data science, data types, financial time series data properties, data analysis techniques, and data analysis processes are explained. In addition, RStudio has been handled as an introduction here. This chapter covers working with data structure, working with data-frames, importing data from different data sources, data preparation (cleaning data, handling missing data, and manipulation data) using some statistical functions, analyzing financial basic time series characteristics, and data visualization with RStudio.",http://dx.doi.org/10.1007/978-3-030-83799-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_16,Novelty and Diversity in Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_16,Springer,2022-01-01,"Novelty and diversity have been identified, along with accuracy, as prominent properties of useful recommendations. Considerable progress has been made in the field in terms of the definition of methods to enhance such properties, as well as methodologies and metrics to assess how well such methods work. In this chapter we give an overview of the main contributions to this area in the field of recommender systems, and seek to relate them together in a unified view, analyzing the common elements underneath the different forms under which novelty and diversity have been addressed, and identifying connections to closely related work on diversity in other fields.",http://dx.doi.org/10.1007/978-1-0716-2197-4_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9272-7_26,Smart Retailing Technologies Impact in Brand Leadership and Market Performance: A Conceptual Model,Marketing and Smart Technologies,10.1007/978-981-16-9272-7_26,Springer,2022-01-01,"Smart retailing technologies are increasingly available and more present on consumers’ daily lives. They are challenging the decision-making processes and retail companies managers’ decisions. Consumers demand rewarding experiences when they visit brick-and-mortar stores, and retailer brands face a challenge on how quickly these new technologies can be deployed in stores to create value for consumers ahead of competing retailers. Simultaneously is important to ensure results for retailers and to finance the technologies that effectively provide the greatest value. The aim of this study is to develop a conceptual model for analyzing the effects of smart retailing technologies in brick-and-mortar stores on brand leadership perception and retailers’ market performance so that it can be tested in each implementation in retail laboratory and pilot brick-and-mortar stores.",http://dx.doi.org/10.1007/978-981-16-9272-7_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-93499-6_10,"Role, Characteristics and Critical Success Factors of Big Data (BD): Implications for Marketing in Africa",Digital Business in Africa,10.1007/978-3-030-93499-6_10,Springer,2022-01-01,"This chapter focuses on the critical success factors of Big Data solutions in marketing, particularly in assisting decision-making and optimising business processes. In the information age, such solutions may help a company gain a competitive advantage by utilising Big Data to understand customer needs, increase the efficiency of the entire decision-making process, and improve marketing activities. Discussions in this chapter highlight the characteristics of Big Data which include value, variety, volume, variability, veracity, velocity and valence, and the major critical factors of Internet of Things (IoT), statistical applications, business intelligence, amongst others. The application of Big Data in various areas, challenges as well as the benefits to contemporary organisations are  also uncovered . Recommendations are included for effective utilisation and management of big data to improve marketing activities in Africa.",http://dx.doi.org/10.1007/978-3-030-93499-6_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-94736-1_9,Politics and Technology,"Political, Economic and Legal Effects of Artificial Intelligence",10.1007/978-3-030-94736-1_9,Springer,2022-01-01,"Digital technology embeds politics by shaping social outcomes. The upgrading of new computing communication technologies and methods of processing large amounts of data has led to the automation and robotization of innumerable processes involving production. Predictive policing systems present a specifically pointed example of how striving to remain neutral embeds and legitimizes existing political conditions. Moreover, the rapid development of artificial intelligence systems, autonomous digital algorithms, and robotic technologies have transformed the landscape and the specifics of socio-legal and socio-political life of society. AI is a technology with outstanding security and defense applications and so countries protect their citizens, their interests at home and abroad, and their own political stability in the face of possible malicious or fraudulent uses of AI which means that techno-nationalism is present and rapidly gaining more support establishing control mechanisms for policy-based market configuration. AI generates challenges for democratic responsiveness and accountability due to a novel technological dimension and in link with existing transparency and accountability drawbacks.",http://dx.doi.org/10.1007/978-3-030-94736-1_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-85428-7_7,Security and Interoperability Issues with Internet of Things (IoT) in Healthcare Industry: A Survey,Security and Privacy Preserving for IoT and 5G Networks,10.1007/978-3-030-85428-7_7,Springer,2022-01-01,"Recently, public healthcare systems become one of the most pivotal parts in our daily life. Resulting in an insane increase in Medical data like medical images and patient information. Having huge amount of data requires more computational power for efficient data management. In addition, data security, privacy and trustworthy have to be maintained and guaranteed. Most medical information in the last years aggregated data from a lot of devices, smart chips, tiny sensors and wearable devices. Those devices are connected through the internet, thus called Internet of Things (IoT). These devices and objects are considered components of the health care technology. Unfortunately, health technologies still face aplenty of privacy preserving, trust issues and a lot of other security problems when transferred through networks. In this work, we will present a security and privacy mechanisms and tools dealing with patient medical Data (information, images) given from smart devices and sensors upon internet of healthcare things (IoHT). Presenting some of the future security trends to enhancing the trustworthy and satisfaction level for healthcare ecosystems.",http://dx.doi.org/10.1007/978-3-030-85428-7_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-78184-2_5,The New Internet of Value Financial Ecosystem,Enabling the Internet of Value,10.1007/978-3-030-78184-2_5,Springer,2022-01-01,"This chapter examines the new business models that have emerged from within the financial services sector due to the development of the Internet of Value, concentrating on decentralised consensus. The chapter breaks this down by examining new business models that will develop through a decentralised consensus-based on state, procedure, and agency.",http://dx.doi.org/10.1007/978-3-030-78184-2_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5685-9_48,Unstructured Log Analysis for System Anomaly Detection—A Study,Advances in Data Science and Management,10.1007/978-981-16-5685-9_48,Springer,2022-01-01,"Nowadays, with the rapid pace of innovation, a typical production infrastructure is getting huge, complicated and difficult to manage. Hence, incident detection and action have become a challenge to the operations and information security (InfoSec) teams. As we are moving toward deployments of complicated or complex large-scale micro-service architectures, the kind of data generated from all those systems is huge. So, it becomes very difficult to identify if anything goes wrong in underlying systems, i.e., the system is vulnerable to various attacks. Keeping track of the flow of traffic and user activities on a large scale, complicated environment is becoming very costly and unmanageable. Traditional systems and ways are becoming inefficient for zero-day security issues.  So it is highly recommended to develop a system that is capable of raising an alarm for any detected anomaly after performing an automatic analysis of the generated logs. This study is conducted to review the research work on unstructured log analysis for the purpose of monitoring the system and anomaly detection. We have identified the datasets used for this purpose and also pointed out the challenges involved in unstructured data analysis.",http://dx.doi.org/10.1007/978-981-16-5685-9_48,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96772-7_34,Social Recommendation via Graph Attentive Aggregation,"Parallel and Distributed Computing, Applications and Technologies",10.1007/978-3-030-96772-7_34,Springer,2022-01-01,"Recommender systems play an important role in helping users discover items of interest from a large resource collection in various online services. Although deep graph neural network-based collaborative filtering methods have achieved promising performance in recommender systems, they are still some weaknesses. Firstly, existing graph neural network methods only take user-item interactions into account neglecting direct user-user interactions which can be obtained from social networks. Secondly, they treat the observed data uniformly without considering fine-grained differences in importance or relevance in the user-item interactions. In this paper, we propose a novel graph neural network social graph attentive aggregation (SGA) which is suitable for parallel training to boost efficiency which is the common bottleneck for neural network deployed machine learning models. This model obtains user-user collaborative information from social networks and utilizes self-attention mechanism to model the differentiation of importance in the user-item interactions. We conduct experiments on two real-world datasets and the results demonstrate that our method is effective and can be trained in parallel efficiently.",http://dx.doi.org/10.1007/978-3-030-96772-7_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2564-1_4,Spatial Planning of Kattangal Smart Global Economic Community,Smart Master Planning for Cities,10.1007/978-981-19-2564-1_4,Springer,2022-01-01,A master plan is a dynamic long-term document to guide the future growth and development of an area. It is multidisciplinary considering all the aspects that affect the quality of life of people and the interrelationships between them.,http://dx.doi.org/10.1007/978-981-19-2564-1_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0019-8_45,Edge Computing as an Architectural Solution: An Umbrella Review,Edge Analytics,10.1007/978-981-19-0019-8_45,Springer,2022-01-01,"Cloud computing architecture and cloud service applications follow a centralized architecture with bottlenecks in the cloud infrastructure. This infrastructure is significantly affected when services respond to many heterogeneous end devices because of the limitations of bandwidth and the servers’ workload; consequently, it introduces a high latency. The advantages of using content delivery networks are to speed up web performance by caching web content on edge nodes near the user. However, there are challenges with streaming data. Researchers create an intermediary infrastructure to store, secure, and compute end devices’ services became a new concept called edge computing. Edge computing can leverage applications that are sensitive to latency. However, other issues appear, such as security and deployability. This paper reviewed the literature to analyze edge computing as an architectural solution and identify the underlying architectural quality attributes, tactics, and strategies. The performance quality attribute drives the edge architecture, mainly to reduce the latency and jitter concerns. The quality requirements are addressed by caching, migration, and virtualization strategies. However, the solution introduces other quality attribute concerns such as security, deployment, and scalability. This paper is a first approach for unveiling the rationale behind edge computation from an architectural viewpoint.",http://dx.doi.org/10.1007/978-981-19-0019-8_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-03834-1_2,Agricultural Internet of Things,"Sensing, Data Managing, and Control Technologies for Agricultural Systems",10.1007/978-3-031-03834-1_2,Springer,2022-01-01,"Agricultural Internet of Things (IoT) is a highly integrated and comprehensive application of new generation information technology in agriculture, which guides the development of agricultural informatization. Agricultural IoT has changed the traditional agricultural production methods and promoted the transformation of agriculture to digitalization and intelligence. This chapter analyzes the concept and technical system of agricultural IOT and summarizes the basic technology of agricultural IOT perception, communication transmission, and processing. Besides, this chapter introduces several application demonstrations of agricultural IOT, such as agricultural information monitoring, farmland moisture monitoring, aquatic environment monitoring, and agricultural product quality tracing, and finally summarizes and analyzes the main problems in the development of agricultural IoT applications.",http://dx.doi.org/10.1007/978-3-031-03834-1_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98167-9_2,Health Care Digital Revolution During COVID-19,How COVID-19 is Accelerating the Digital Revolution,10.1007/978-3-030-98167-9_2,Springer,2022-01-01,"The digital revolution has had both good and bad effects since the 1980s. COVID-19 was identified only a few weeks after the pandemic began. COVID-19’s rapid spread over the world, combined with the virus’s originality, necessitated novel solutions. Professional communication across numerous platforms is increasingly reliant on social media. The constant flow of new knowledge and novel methods of practice has led to the creation of new digital communication strategies. There are majority of health employee remained sick or self-isolation to physically face COVID-19’s patents, clinical groups describe widespread use of messaging apps for communication, to organize service provision or manage staff rotations. The use of digital solutions has risen to previously unheard-of heights as a result of the lockdown, increasing the possibility of scaling up alternative social and economic methods. However, they provide new technological risks and concerns, placing new expectations on policymakers. Growth in COVID-19 is the digital and technological revolution that has shaped our world over the last century. As healthcare systems around the country prepare for an influx of COVID-19 patients, immediate action is needed to modernize healthcare delivery and scale up our systems by leveraging digital technologies. The COVID-19 pandemic has brought to light the limitations of our current healthcare system’s ability to serve all the world during a crisis. The main goal of this chapter is to concentrate on digital healthcare issues and challenges, as well as to provide limitations and recommendations.",http://dx.doi.org/10.1007/978-3-030-98167-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05675-8_15,Eduino: A Telegram Learning-Based Platform and Chatbot in Higher Education,Learning and Collaboration Technologies. Novel Technological Environments,10.1007/978-3-031-05675-8_15,Springer,2022-01-01,"This paper presents Eduino, a chatbot that is built on the popular social media platform ‘Telegram’ and serves as a learning-based platform conversational agent. Following the methodology of Data Science Research, three iterative stages are carried out for the development. Eduino provides a feature set covering functionality for acquiring lecture notes and course schedules, completion of course related quizzes, and contacting course professors through a conversational messaging interface. The chatbot was evaluated using a usability test and semi-structured interviews. The overall perception from students was positive. Students appreciated the efficiency of acquiring course content in a new novel format and found the experience to be immersive and user friendly.",http://dx.doi.org/10.1007/978-3-031-05675-8_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-021-01248-6,Efficient topology control of blockchain peer to peer network based on SDN paradigm,Peer-to-Peer Networking and Applications,10.1007/s12083-021-01248-6,Springer,2022-01-01,"Blockchain allows to securely store, using cryptography functions, validated transactions and other data across its peer to peer (P2P) network. This P2P network is generated and maintained by the participating peers in a distributed manner through peer discovery, neighbor selection and managing inbound/outbound connections. As these tasks require extra consumption of network bandwidth, energy, memory and CPU usage, resource-limited devices may not support inherent blockchain applications. Further, changes in the topology control functions or reconfiguration should be considered by all peers to fully benefit from the new performance, which can take time. The aim of this paper is to build a blockchain network in a manner that greatly reduce topology control overhead while guaranteeing the properties such as high flexibility, fast reconfigurability, connectivity, small diameter and clustering. For this, we propose to use the Software-Defined Networking (SDN) paradigm to manage the blockchain P2P network. This way, the topology control tasks are moved off the peers to a secure overlay layer composed of multiple servers having synchronized databases. This new layer is responsible for building and managing the topological structure of the P2P network layer based on random r -out digraphs. Next, we mathematically discuss r -out digraphs generation using binomial distribution and preferential attachment models. Then, and in order to reduce the number of connections per peer, we establish lower and minimum upper bounds on outbound and inbound connections respectively that still guarantee the P2P network feasibility and connectivity. Further, we investigate topological properties of blockchain P2P network such as connectivity, diameter and clustering. Finally, we provide extensive simulation and numerical results to verify the efficiency of our approach and illustrate the effects of centralized topology control on network performance.",http://dx.doi.org/10.1007/s12083-021-01248-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92986-2_6,The New Model of Collaboration,How to Save the FMCG Industry,10.1007/978-3-030-92986-2_6,Springer,2022-01-01,"In this chapter Leach challenges us to provide new solutions that can transform the way suppliers and retailers can collaborate together. He provides practical ideas and tools on how this can be achieved across a number of key areas that have emerged from the theory and his own original research. These are real-world proposals that look to step change collaboration and provide an even greater focus on meeting consumer and shopper needs, in order to create value for both suppliers and retailers.",http://dx.doi.org/10.1007/978-3-030-92986-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2568-9_18,Legal Education and Legal Profession During and Beyond COVID-19 Building Bonds Between Academia and Practice,Legal Education and Legal Profession During and After COVID-19,10.1007/978-981-19-2568-9_18,Springer,2022-01-01,"Professor Suzanne Rab, professor of commercial law and practising international barrister and mediator offers a unique perspective on the challenges of digitisation and legal education in a post-COVID-19 world. Operating at the conflation of academia and practice Professor Rab explores the following themes using a blend of case study experience from the UK and from a comparative perspective: (1) the future of legal education in changing times; (2) the practitioner perspective and the digitised courtroom; (3) the academic experience and lived in experiences through COVID-19; (4) the role of online learning; (5) the implications for continuing legal education; (6) blended approaches to executive learning; (7) the impact on specific legal practices areas; (8) diversity and accessibility; (9) new world approaches to assessment of performance; and (10) humanising our legal education for the digital generation.",http://dx.doi.org/10.1007/978-981-19-2568-9_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-11217-1_10,Securing Cookies/Sessions Through Non-fungible Tokens,Database Systems for Advanced Applications. DASFAA 2022 International Workshops,10.1007/978-3-031-11217-1_10,Springer,2022-01-01,"Cookies are used as authentication tokens after successfully validating users by web applications. As they are stored on the client’s side, it makes them vulnerable to hijacking, stealing, and unauthorized distribution. There are methods in the literature that are developed to protect cookies. However, cookie stealing and impersonating is still a widely adopted practice. Session cookies are used so that the user does not have to log in again and again. When an attacker accesses these cookies, he/she can join the user’s active session as well; this phenomenon is called cookie hijacking. Here, we are proposing a model using the concept of blockchain, non-fungible tokens and smart contracts, which prevent the attacker from performing unauthorized tasks even when an individual gets access to the user’s session cookies. The web server uses the unique identification address of the user to generate a session ticket which would represent the ownership of the verified user. Whenever, a request is made, it gets authenticated by the blockchain; thereby making the cookie verification decentralized. This method ultimately aims to prevent unauthorized users from performing tasks through a user’s active session, which will decrease identity stealing and imitation through cookies.",http://dx.doi.org/10.1007/978-3-031-11217-1_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-0716-2197-4_21,Individual and Group Decision Making and Recommender Systems,Recommender Systems Handbook,10.1007/978-1-0716-2197-4_21,Springer,2022-01-01,"Given that an important function of recommender systems is to help people make better choices, people who design and study recommender systems ought to have a good understanding of how people make choices and how human choice can be supported. This chapter uses an accessible summary of what is known about these topics as a framework for discussing the implications of this knowledge for the design of recommender systems. The first half of the chapter focuses on choices made by individuals, providing a compact update of the corresponding chapter in the previous edition of this handbook. The second half of the chapter extends the analysis to choices made by groups and their support by recommender systems for groups. Each half is organized in terms of two previously published models that make the relevant knowledge from psychology and related fields accessible to those who work on recommender systems and other interactive computing technology. The Aspect model distinguishes six choice patterns that together capture the wide variety of ways in which people make choices; the model enables us to identify both familiar and novel ways in which recommender systems can support choice. The Arcades model distinguishes seven high-level choice support strategies ; whereas one of the strategies is already widely used in recommender systems, the other strategies can help round out the choice support that a recommender system offers.",http://dx.doi.org/10.1007/978-1-0716-2197-4_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0898-9_41,Hybrid Deep Learning-Based Music Recommendation System,"Computer Networks, Big Data and IoT",10.1007/978-981-19-0898-9_41,Springer,2022-01-01,"The fundamental objective of musical recommendations is to propose songs that are appropriate to the tastes of the user. In this paper, we have developed, implemented, and analyzed music recommendation systems with variations of music recommendation algorithm using MLP neural network such as content-based model using MLP neural network, collaborative model using MLP neural network, and hybrid model using MLP neural network. We have also looked into the accuracy and precision of all the three algorithms with various activation functions.",http://dx.doi.org/10.1007/978-981-19-0898-9_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88346-1_22,The Singularity: Fiction or Reality?,Technology Roadmapping and Development,10.1007/978-3-030-88346-1_22,Springer,2022-01-01,"In this final chapter, we look toward the more distant future of technology and humanity. We first ask if there are ultimate limits to technology. This brings us to the question of the so-called “singularity,” a prophesized point where technology becomes self-improving and outpaces human capabilities with the potential to render humans obsolete. Whether or not a technological singularity is coming, it is already evident that humans are using technology to augment their own bodies and minds. The future of our species (and our planet) has not yet been written. Different utopian and dystopian futures have been proposed, both in the scientific literature and in the arts. In the end, it is up to us, individuals, firms, and governments to invest in and develop technologies that are deployed in systems for a long-term positive and sustainable future. We conclude by summarizing seven key messages from this book.",http://dx.doi.org/10.1007/978-3-030-88346-1_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-0722-7_4,China’s Authoritarian Governance and AI,Artificial Intelligence with Chinese Characteristics,10.1007/978-981-19-0722-7_4,Springer,2022-01-01,"This chapter studies China’s governance approach to AI and big data-related technologies. It argues that China’s bold use of AI practices in governance represents an attempt not only to build a more efficient and capable government to deliver better public services but also to strengthen state control to ensure the continuation of the authoritarian order. However, despite the immediate benefits offered by AI and big data-related technology, China’s ambitious approach is facing considerable challenges. This chapter suggests that how to (a) deliver strong growth in China’s AI economy, (b) handle the dramatic social transformation to the age of AI and (c) justify legitimacy of its political values embedded in its AI approach, represent three critical tests for China’s governance approach to AI.",http://dx.doi.org/10.1007/978-981-19-0722-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-76653-5_19,Challenges in the Adaptation of IoT Technology,A Fusion of Artificial Intelligence and Internet of Things for Emerging Cyber Systems,10.1007/978-3-030-76653-5_19,Springer,2022-01-01,"At present, The Internet of Things (IoT) and its relevant technologies are moving towards the subsequent step of evolution where almost every object in our vicinity would be integrated with the internet allowing them to communicate and share data. This chapter begins with a brief overview of the core concept of IoT followed by various IoT based smart-environment, applications, and services areas of IoT in the smart environment. Despite the countless possibilities that IoT along with other emerging technologies has to offer, various hindrances will be encountered with such large number of devices connected to each other transmitting sensitive data. Several such challenges faced in the adoption of IoT in areas such as smart city development, smart education, healthcare and medicine sector, manufacturing, smart grid, agronomy and telecommunication are investigated next in this chapter. Blockchain technology is gaining popularity for its decentralization abilities and absence of intermediaries and hence can prove to be a panacea for the concerns related to the adaption of IoT. This chapter introduces the use of blockchain to address these challenges arising due to the centralized structure of IoT and the benefits of integrating blockchain with IoT environment. Keeping in mind the recent developments related to Covid-19 and the vulnerabilities caused henceforth, in the last segment of this chapter, we have briefly reviewed various domains where use of IoT can prove beneficial.",http://dx.doi.org/10.1007/978-3-030-76653-5_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1021-0_9,Application of Soft Computing Techniques in Database Intrusion Detection,"Intelligent Technologies: Concepts, Applications, and Future Directions",10.1007/978-981-19-1021-0_9,Springer,2022-01-01,"With the rapid usage of the Internet and electronic commerce, a concern of safekeeping is a very solemn affair in this contemporary age of information and communication technology. Very enormous amount of hard work and time has been invested by the database research community to accomplish the high-level security and privacy to the database. Database intrusion detection cam makes the database secure by successfully detecting anomalous behavior founded by applications and users. However, it is very tiresome to successfully build the normal behavior of numerous users. The vigorous nature of the attacker is not accurately managed by the traditional methodologies worn in database security. The use of soft computing approaches in database intrusion detection is an alluring concept due to its robustness and low solution cost and better rapport with reality. Additionally, in network security domain, soft computing has already proven to be capable of creating a system capable of detecting and characterizing anomalous behavior which is composed of evolutionary computing tools, artificial neural networks, and fuzzy logic. In this research, a total of five novel approaches have been proposed for detecting intrusive activities in databases effectively by applying various soft computing techniques. The performance comparison of all the five proposed algorithms has been done using several standard performance metrics on a synthetic as well as real biometric data sets. Besides, the results obtained from the comparative analysis with other hard computing-based database intrusion detection system clearly justify the superiority of the proposed systems.",http://dx.doi.org/10.1007/978-981-19-1021-0_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10723-021-09593-9,A Survey on Auction based Approaches for Resource Allocation and Pricing in Emerging Edge Technologies,Journal of Grid Computing,10.1007/s10723-021-09593-9,Springer,2021-12-27,"The advancements in sensing technologies, smart devices, wearable gadgets, and communication paradigm enable the vision of the internet of things, smart city, virtual and augmented reality, pervasive healthcare, to name a few. These applications have strict requirements of low latency delivery, high data rate, and instant response. To support this, various new technologies, such as fog computing, mobile edge computing, cloudlet, Micro, and Nano centers, mini and micro clouds, etc., have emerged. The entire set of emerging edge computing paradigms are commonly referred as ""edge technologies"" in which computational resources and storage are closer to the user/terminal devices somewhere between the device and the cloud data center. The edge technologies aim to deliver computing services with minimal delay by reducing the downward and upward time and data traffic volume. Like cloud service providers, edge service providers are emerging, and a market of edge computing resources has been created. Therefore, Auction theory, a subfield of Economics, is being widely applied for the allocation of resources in emerging edge technologies. This work presents a comprehensive survey on auction-based resource allocation and pricing approaches in emerging edge technologies. An overview of edge technologies and auction theory is given, followed by a thorough review and comparison of the existing auction-based approaches applied in edge technologies for resource allocation and pricing in terms of economic properties. Various open research issues have been deliberated to set the future research direction at the end.",http://dx.doi.org/10.1007/s10723-021-09593-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12528-021-09295-x,IoT text analytics in smart education and beyond,Journal of Computing in Higher Education,10.1007/s12528-021-09295-x,Springer,2021-12-01,"Data Analytics has become an essential part of the Internet of Things (IoT), mainly text analytics-related applications, since they can be utilized to benefit educational institutions, consumers, and enterprises. Text Analytics is excessively used in Smart Education after the emerging technologies such as personal computers, tablets, and even smartphones transformed the education system and improved the teaching methods by helping the teachers to evaluate the students' performance or determine the degree of similarity between a lecturer’s and the students’ posts in the discussion forum, and by collecting the students’ feedback on the teaching method, in order to categorize each feedback into positive or negative, which will help the lecturers in optimizing their way of teaching. In this paper, we highlight the main components of IoT analytics, along with a comprehensive background of text analytics used techniques and applications. This paper provides a comprehensive survey and comparison of the leveraged IoT Text Analytics models and methods in Smart Education and many other applications.",http://dx.doi.org/10.1007/s12528-021-09295-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-021-09573-8,Linking Human And Machine Behavior: A New Approach to Evaluate Training Data Quality for Beneficial Machine Learning,Minds and Machines,10.1007/s11023-021-09573-8,Springer,2021-12-01,"Machine behavior that is based on learning algorithms can be significantly influenced by the exposure to data of different qualities. Up to now, those qualities are solely measured in technical terms, but not in ethical ones, despite the significant role of training and annotation data in supervised machine learning. This is the first study to fill this gap by describing new dimensions of data quality for supervised machine learning applications. Based on the rationale that different social and psychological backgrounds of individuals correlate in practice with different modes of human–computer-interaction, the paper describes from an ethical perspective how varying qualities of behavioral data that individuals leave behind while using digital technologies have socially relevant ramification for the development of machine learning applications. The specific objective of this study is to describe how training data can be selected according to ethical assessments of the behavior it originates from, establishing an innovative filter regime to transition from the big data rationale n  =  all to a more selective way of processing data for training sets in machine learning. The overarching aim of this research is to promote methods for achieving beneficial machine learning applications that could be widely useful for industry as well as academia.",http://dx.doi.org/10.1007/s11023-021-09573-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11356-021-14017-y,Advent of Big Data technology in environment and water management sector,Environmental Science and Pollution Research,10.1007/s11356-021-14017-y,Springer,2021-12-01,"Big Data is on the verge of explosion in terms of popularity in recent decades, and such a trend is not going to stop anytime soon as it has a lot of room to grow. The increased integration of IoT devices, faster access to the Internet, and advances in the computational power of mainstream devices have drastically increased the feasibility for the same while making it more practical to implement gradually. The reach and applicability of Big Data are diversified, yet widespread, and one of its key implementations falls under the environment arena. In an attempt to provide novel Big Data allied solutions in one or more aspects of water management sector, a substantial amount of research work has been carried out in recent years. This paper discusses how Big Data influences the abovementioned arenas and the extent of importance that it has. Several aspects of this field are uprooted, are discussed, and have seen real-world applicability. Various presently deployed applications, in the sub-fields of environment and water management are studied, and given an inclusive review. Finally, the current challenges and limitations pertaining to Big Data are discussed and proper (in theory) solutions are proposed which seem to have promising results. The future scope of Big Data is also considered with its viability taken into consideration. Several assessments and opinions are then cited.",http://dx.doi.org/10.1007/s11356-021-14017-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10619-021-07321-6,Semantic-based Big Data integration framework using scalable distributed ontology matching strategy,Distributed and Parallel Databases,10.1007/s10619-021-07321-6,Springer,2021-12-01,"Nowadays, Big Data management has become a key basis for innovation, productivity growth, and competition. The correlated exploitation of data of this magnitude remains primordial to discover valuable insights and support decision making for domains of major interest. Furthermore, despite the complex aspects of Big Data environments, users are usually looking for a unified and appropriate view of this huge and heterogeneous data, to support the extraction of reliable and consistent knowledge. Thus, Big Data integration mechanisms must be considered to provide a uniform query interface, to mediate across large datasets and provide data scientists with a consistent integrated view suitable for analytical exploitations. Thus, this paper presents a semantic-based Big Data integration framework that relies on large-scale ontology matching and probabilistic-logical based assessment strategies. This framework applies optimization mechanisms and leverages parallel-computing paradigms (Hadoop and MapReduce) using commodity computational resources, to efficiently address the Big Data challenges and aspects. Several experiments were conducted and have proven the efficiency of this framework in terms of accuracy, performance, and scalability.",http://dx.doi.org/10.1007/s10619-021-07321-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-021-01849-8,Tolerance-Oriented Wi-Fi Advertisement Scheduling: A Near Optimal Study on Accumulative User Interests,Mobile Networks and Applications,10.1007/s11036-021-01849-8,Springer,2021-12-01,"While public Wi-Fi hotspots provide ubiquitous Internet access to mobile users, they can also generate revenues for venue owners and mobile advertisers by disseminating advertisements. There have been some research efforts in promoting Wi-Fi monetization from different perspectives, but most of them ignore users’ tolerance towards watching advertisements. Indeed, tolerance plays a fundamental role in Wi-Fi advertising, as it directly influences the effectiveness of advertisements and the long-term profits of advertisers. To address this issue, we study Wi-Fi advertisement scheduling by considering both the tolerance of users in viewing advertisements and resource constraints of Wi-Fi hotspots for broadcasting advertisements. With the goal of maximizing the overall accumulative interests of users, we formulate a mixed integer programming problem for Wi-Fi advertisement scheduling. We prove that the objective function of this problem is monotone and submodular, subject to a knapsack constraint and a partition matroid constraint. On this basis, we solve it by proposing a novel greedy swap algorithm, which has a 1 − e − 2 2 $\frac {{1-{e^{-2}}}}{2}$ -approximation performance guarantee. Through extensive synthetic and trace-driven evaluations, we show that the proposed algorithm effectively improves users’ interests towards different Wi-Fi advertisements and achieves robust results near to the optimal solution.",http://dx.doi.org/10.1007/s11036-021-01849-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40593-021-00260-4,Evaluating a Persuasive Intervention for Engagement in a Large University Class,International Journal of Artificial Intelligence in Education,10.1007/s40593-021-00260-4,Springer,2021-12-01,"Persuasive Technologies (PT) are computational methods, strategies, and design techniques, grounded in social psychology to change user attitudes/behaviours. PTs have been applied in diverse areas, such as eCommerce, health, workplace, vehicles, urban and ambient environments. A kind of PT that has become popular in eLearning is known under the name “Gamification” – introducing game mechanics (such as points, levels, badges, leaderboards) into non-game environments. We implemented three persuasive strategies in an online learning environment supporting a University class to encourage more active engagement of students in their online learning activities. The paper presents a controlled study that shows a positive effect of the persuasive intervention on student engagement, measured by the increase in their online activities. The study results also show that personalizing the persuasive strategies to the receptiveness of individual students amplifies their effect on engagement.",http://dx.doi.org/10.1007/s40593-021-00260-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-021-10063-9,Enjoy your observability: an industrial survey of microservice tracing and analysis,Empirical Software Engineering,10.1007/s10664-021-10063-9,Springer,2021-11-30,"Microservice systems are often deployed in complex cloud-based environments and may involve a large number of service instances being dynamically created and destroyed. It is thus essential to ensure observability to understand these microservice systems’ behaviors and troubleshoot their problems. As an important means to achieve the observability, distributed tracing and analysis is known to be challenging. While many companies have started implementing distributed tracing and analysis for microservice systems, it is not clear whether existing approaches fulfill the required observability. In this article, we present our industrial survey on microservice tracing and analysis through interviewing developers and operation engineers of microservice systems from ten companies. Our survey results offer a number of findings. For example, large microservice systems commonly adopt a tracing and analysis pipeline, and the implementations of the pipeline in different companies reflect different tradeoffs among a variety of concerns. Visualization and statistic-based metrics are the most common means for trace analysis, while more advanced analysis techniques such as machine learning and data mining are seldom used. Microservice tracing and analysis is a new big data problem for software engineering, and its practices breed new challenges and opportunities.",http://dx.doi.org/10.1007/s10664-021-10063-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01310-0,Towards an effective transnational regulation of AI,AI & SOCIETY,10.1007/s00146-021-01310-0,Springer,2021-11-09,"Law and the legal system through which law is effected are very powerful, yet the power of the law has always been limited by the laws of nature, upon which the law has now direct grip. Human law now faces an unprecedented challenge, the emergence of a second limit on its grip, a new “species” of intelligent agents (AI machines) that can perform cognitive tasks that until recently only humans could. What happens, as a matter of law, when another species interacts with us, can be integrated into human minds and bodies, makes “real-world” decisions—not through human proxies, but directly—and does all this “intelligently”, with what one could call autonomous agency or even a “mind” of its own? The article starts from the clear premise that control cannot be exercised directly on AI machines through human law. That control can only be effected through laws that apply to humans. This has several regulatory implications. The article’s first discusses what, in any attempt to regulate AI machines, the law can achieve. Having identified what the law can do, the article then canvases what the law should aim to achieve overall. The article encapsulate its analysis in a list of both doctrinal and normative principles that should underpin any regulation aimed at AI machines. Finally, the article compares three transnational options to implement the proposed regulatory approach.",http://dx.doi.org/10.1007/s00146-021-01310-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-021-09302-7,Algorithmic disclosure rules,Artificial Intelligence and Law,10.1007/s10506-021-09302-7,Springer,2021-11-08,"During the past decade, a small but rapidly growing number of Law&Tech scholars have been applying algorithmic methods in their legal research. This Article does it too, for the sake of saving disclosure regulation failure: a normative strategy that has long been considered dead by legal scholars, but conspicuously abused by rule-makers. Existing proposals to revive disclosure duties, however, either focus on the industry policies (e.g. seeking to reduce consumers’ costs of reading) or on rulemaking (e.g. by simplifying linguistic intricacies). But failure may well depend on both. Therefore, this Article develops a `comprehensive approach', suggesting to use computational tools to cope with linguistic and behavioral failures at both the enactment and implementation phases of disclosure duties, thus filling a void in the Law & Tech scholarship. Specifically, it outlines how algorithmic tools can be used in a holistic manner to address the many failures of disclosures from the rulemaking in parliament to consumer screens. It suggests a multi-layered design where lawmakers deploy three tools in order to produce optimal disclosure rules: machine learning, natural language processing, and behavioral experimentation through regulatory sandboxes. To clarify how and why these tasks should be performed, disclosures in the contexts of online contract terms and privacy online are taken as examples. Because algorithmic rulemaking is frequently met with well-justified skepticism, problems of its compatibility with legitimacy, efficacy and proportionality are also discussed.",http://dx.doi.org/10.1007/s10506-021-09302-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06081-9,Automatic identification of commodity label images using lightweight attention network,Neural Computing and Applications,10.1007/s00521-021-06081-9,Springer,2021-11-01,"Recent research has raised interest in applying image classification techniques to automatically identify the commodity label images for the business automation of retail enterprises. These techniques can help enterprises improve their service efficiency and realize digital transformation. In this work, we developed a lightweight attention network with a small size and comparable precision, namely MS-DenseNet, to identify the commodity label images. MS-DenseNet is based on the recent well-known DenseNet architecture, where we replaced the regular planner convolution in dense blocks with depthwise separable convolution to compress the model size. Further, the SE modules were incorporated in the proposed network to highlight the useful feature channels while suppressing the useless feature channels, which made good use of interdependencies between channels and realized the maximum reuse of inter-channel relations. Besides, the two-stage progressive strategy was adopted in model training. The proposed procedure achieved significant performance gain with an average accuracy of 97.60% on the identification of commodity label images task. Also, it realized a 94.90% average accuracy on public datasets. The experimental findings present a substantial performance compared with existing methods and also demonstrate the effectiveness and extensibility of the proposed procedure. Our code is available at https://github.com/xtu502/Automatic-identification-of-commodity-label-images .",http://dx.doi.org/10.1007/s00521-021-06081-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13042-021-01415-4,Deep transfer learning-based network traffic classification for scarce dataset in 5G IoT systems,International Journal of Machine Learning and Cybernetics,10.1007/s13042-021-01415-4,Springer,2021-11-01,"Internet of Things (IoT) can provide the interconnection and data sharing among devices, vehicles, buildings via various sensors with the development of 5G, and it has been widely used in different services such as e-commerce, heath-care, smart buildings. In the meantime, various cyber-attacks for IoT have increased and caused huge losses. Lots of security mechanisms are rapidly being proposed to prevent the potentially malicious attackers for IoT, in which machine learning especially deep learning (DL) as increasingly popular solution for security has been implemented in intrusion detection system (IDS) and others. However, the lack of enough datasets prevents the application of IDS in 5G IoT system. As one of fundamental components of IDS, network traffic classification shows a discretization, individualization and fine-grained trend which derives the different personalized classification methods for different requirements and scenarios. In this case, the data-driven DL faces the following challenges. First, there are only a few labeled datasets in the various personalized application scenarios, which undoubtedly limits the deployment of DL classification. Second, not all scenarios have rich computing capability for that training a neural network requires lots of computing resources. Therefore, this paper proposes a traffic classification method based on deep transfer learning for 5G IoT scenarios with scarce labeled data and limited computing capability, and trains the classification model by weight transferring and neural network fine-tuning. Different from the previous work that extract artificially designed features, the proposed method retains the end-to-end learning performance of DL and reduces the risk of suffering concept drift to reduce human intervention. Experimental results show that when only 10% of dataset are used to label the data samples, the classification accuracy is close to the results of full training dataset.",http://dx.doi.org/10.1007/s13042-021-01415-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-021-00963-7,Hierarchical neural topic modeling with manifold regularization,World Wide Web,10.1007/s11280-021-00963-7,Springer,2021-11-01,"Topic models have been widely used for learning the latent explainable representation of documents, but most of the existing approaches discover topics in a flat structure. In this study, we propose an effective hierarchical neural topic model with strong interpretability. Unlike the previous neural topic models, we explicitly model the dependency between layers of a network, and then combine latent variables of different layers to reconstruct documents. Utilizing this network structure, our model can extract a tree-shaped topic hierarchy with low redundancy and good explainability by exploiting dependency matrices. Furthermore, we introduce manifold regularization into the proposed method to improve the robustness of topic modeling. Experiments on real-world datasets validate that our model outperforms other topic models in several widely used metrics with much fewer computation costs.",http://dx.doi.org/10.1007/s11280-021-00963-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-021-04339-y,A decision-making algorithm combining the aspect-based sentiment analysis and intuitionistic fuzzy-VIKOR for online hotel reservation,Annals of Operations Research,10.1007/s10479-021-04339-y,Springer,2021-11-01,"In the process of hotel reservation on online traveling platforms, online reviews, as a fundamental source where the actual information of a product can be had access to, have been attached with high importance by customers when they have difficulty making a decision on which hotel to pick. However, with enormous amount of online reviews distributed in diverse online traveling platforms, customers tend to have few patience or time to manually read all these reviews and get the exact information they want. Inspired by the widespread application of aspect-based sentiment analysis in the field of data mining, a bidirectional long short-term memory (Bi-LSTM) and attention mechanism based model to predict multiple attributes of a product from online review texts is proposed. Experimental result shows that such Bi-LSTM with attention mechanism model apparently improves the accuracy of the prediction, compared with single LSTM model. Meanwhile, based on the output of the prediction, we analyze and transfer it into a statistical matrix. With an intuitionistic fuzzy compromise decision-making method VIKOR applied, an overall ranking, according to multiple product attributes can be made, in which way to help customers make decisions. To prove the rationality of the algorithm, online hotel reviews from three stream online travelling platforms are crawled as a case.",http://dx.doi.org/10.1007/s10479-021-04339-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-021-04287-7,Investigation of finance industry on risk awareness model and digital economic growth,Annals of Operations Research,10.1007/s10479-021-04287-7,Springer,2021-10-29,"Financial risk is unintended to lose money on an enterprise or investment. Credit risk, Liquidity risk, and operational risk are some more prevalent and unique financial concerns. This is a form of risk that can lead to a capital loss for stakeholders. Building a company from the bottom up is expensive. Any firm may need to go for cash outside to develop at some time in their lives. Financial hazards occur and influence almost every person in various forms and sizes. Digital Financial Services are financial services that rely on customer distribution and the use of digital technologies. While digital financial inclusion (DFI) is important in stimulating economic growth, there is only relatively little empirical data. But whether digital finance is the solution both the bad and the good results of financial inclusion raise. This essay will investigate the importance of digital financial inclusion, utilizing information and communications technology (DFI-ICT) techniques to promote sustainable growth via economic stability. Fast digital technology is currently being used to deliver financial services considerably reduced cost, thereby enhancing financial inclusion and allowing large-scale economic productivity improvements. Although there has been a broad-ranging mention of the benefits of digital finance—financial services offered through mobile telephones, the internet, or cards—we try to measure the size of the economic effect. The experimental result shows that the classification risk level ratio is achieved to 18.9%, and the error rate of classification of the model is checked.",http://dx.doi.org/10.1007/s10479-021-04287-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00506-y,Creating customer value from data: foundations and archetypes of analytics-based services,Electronic Markets,10.1007/s12525-021-00506-y,Springer,2021-10-27,"The digital transformation offers new opportunities for organizations to expand their existing service portfolio in order to achieve competitive advantages. A popular way to create new customer value is the offer of analytics-based services (ABS)—services that apply analytical methods to data to empower customers to make better decisions and to solve complex problems. However, research still lacks to provide a profound conceptualization of this novel service type. Similarly, actionable insights on how to purposefully establish ABS in the market to enrich the service portfolio remain scarce. We perform a cluster analysis of 105 ABS and triangulate it with a revelatory case study to identify four generic ABS archetypes and to unveil their specific service objectives and characteristics. We also isolate essential factors that shape decision-making regarding the choice of adequate archetypes and subsequent transitions between them. The detailed characterization of different ABS types contributes to a more profound theorizing process on ABS as well as provides a systematization for strategic opportunities to enrich service portfolios in practice.",http://dx.doi.org/10.1007/s12525-021-00506-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-021-09512-w,Research on the positioning method of online community users from the perspective of precision marketing,Electronic Commerce Research,10.1007/s10660-021-09512-w,Springer,2021-10-18,"In precision marketing for online communities, the existing text-based methods of user positioning cannot position new users rapidly, and they have low positioning efficiency when there is a large number of users. This research proposes a systematic method for the positioning of online community users. In this method, text mining and clustering algorithms are combined to cluster users, and then the user clusters are effectively matched with users' basic attributes through a multinomial logistic regression model. By this means, efficient positioning under the circumstances of a rapid increase in new users and a large number of users can be achieved. Calculation results from a real world example show that this method can effectively solve the problems found in traditional user positioning methods and provides a productive new approach to community user positioning. The study also offers suggestions for user classification management from the perspective of precision marketing.",http://dx.doi.org/10.1007/s10660-021-09512-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10878-021-00815-0,Measuring the influence and amplification of users on social network with unsupervised behaviors learning and efficient interaction-based knowledge graph,Journal of Combinatorial Optimization,10.1007/s10878-021-00815-0,Springer,2021-10-11,"This study introduces a metric to measure the influence of users and communities on Social Media Networks. The proposed method is a combination of Knowledge Graph and Deep Learning approaches. Particularly, an effective Knowledge Graph is built to represent the interaction activities of users. Besides, an unsupervised deep learning model based on Variational Graph Autoencoder is also constructed to further learn and explore the behavior of users. This model is inspired by conventional Graph Convolutional layers. It is not only able to learn the attribute of users themselves but also enhanced to automatically extract and learn from the relationships among users. The model is robust to unseen data and takes no labeling effort. To ensure the state of the art and fashionable for this work, the dataset is collected by a designed crawling system. The experiments show significant performance and promising results which are competitive and outperforms some well-known Graph-convolutional-based. The proposed approach is applied to build a management system for an influencer marketing campaign, called ADVO system. The ADVO system can detect emerging influencers for a determined brand to run its campaign, and help the brand to manage its campaign. The proposed method is already applied in practice.",http://dx.doi.org/10.1007/s10878-021-00815-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00778-021-00701-5,"General graph generators: experiments, analyses, and improvements",The VLDB Journal,10.1007/s00778-021-00701-5,Springer,2021-10-07,"Graph simulation is one of the most fundamental problems in graph processing and analytics. It can help users to generate new graphs on different scales to mimic observed real-life graphs in many applications such as social networks, biology networks, and information technology. In this paper, we focus on one of the most important types of graph generators: general graph generators, which aim to reproduce the properties of the observed graphs regardless of the domains. Though a variety of graph generators have been proposed in the literature, there are still several important research gaps in this area. In this paper, we first give an overview of the existing general graph generators, including recently emerged deep learning-based approaches. We classify them into four categories: simple model-based generators, complex model-based generators, autoencoder-based generators, and GAN-based generators. Then we conduct a comprehensive experimental evaluation of 20 representative graph generators based on 17 evaluation metrics and 12 real-life graphs. We provide a general roadmap of recommendations for how to select general graph generators under different settings. Furthermore, we propose a new method that can achieve a good trade-off between simulation quality and efficiency. To help researchers and practitioners apply general graph generators in their applications or make a comprehensive evaluation of their proposed general graph generators, we also implement an end-to-end platform that is publicly available.",http://dx.doi.org/10.1007/s00778-021-00701-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00778-021-00700-6,Fast-adapting and privacy-preserving federated recommender system,The VLDB Journal,10.1007/s00778-021-00700-6,Springer,2021-10-03,"In the mobile Internet era, recommender systems have become an irreplaceable tool to help users discover useful items, thus alleviating the information overload problem. Recent research on deep neural network (DNN)-based recommender systems have made significant progress in improving prediction accuracy, largely attributed to the widely accessible large-scale user data. Such data is commonly collected from users’ personal devices and then centrally stored in the cloud server to facilitate model training. However, with the rising public concerns on user privacy leakage in online platforms, online users are becoming increasingly anxious over abuses of user privacy. Therefore, it is urgent and beneficial to develop a recommender system that can achieve both high prediction accuracy and strong privacy protection. To this end, we propose a DNN-based recommendation model called PrivRec running on the decentralized federated learning (FL) environment, which ensures that a user’s data is fully retained on her/his personal device while contributing to training an accurate model. On the other hand, to better embrace the data heterogeneity (e.g., users’ data vary in scale and quality significantly) in FL, we innovatively introduce a first-order meta-learning method that enables fast on-device personalization with only a few data points. Furthermore, to defend against potential malicious participants that pose serious security threat to other users, we further develop a user-level differentially private model, namely DP-PrivRec, so attackers are unable to identify any arbitrary user from the trained model. To compensate for the loss by adding noise during model updates, we introduce a two-stage training approach. Finally, we conduct extensive experiments on two large-scale datasets in a simulated FL environment, and the results validate the superiority of both PrivRec and DP-PrivRec.",http://dx.doi.org/10.1007/s00778-021-00700-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-021-05856-5,Credit Card Fraud Detection via Integrated Account and Transaction Submodules,Arabian Journal for Science and Engineering,10.1007/s13369-021-05856-5,Springer,2021-10-01,"Globally, credit card fraud is a prevalent dilemma. Credit card fraud detection is a classification problem where one aim is to classify legitimate and fraudulent transactions in an adaptive and an automated manner. This paper proposes to utilize a novel hybrid scheme that integrates two mechanisms: a universal model and a unique model. The universal model is a static mechanism that inspects transactions without regard to the cardholder’s history or any other related transaction. It does so by implementing rules that are obtained via analyzing the complete population. On the other hand, the unique model is a dynamic, behavioral scheme that establishes a separate profile for each respective cardholder. In doing so, the model can establish a specific and accurate system that judges said cardholder’s transactions. It was found that the integration of the two models greatly enhanced the performance of the overall system. The system is inherently capable of handling the class imbalance problem that is usually prevalent in credit card fraud classification. The proposed framework was implemented and tested on a typical dataset. The proposed framework exhibited superior performance when benchmarked with similar frameworks. It showed a very high fraud detection rate, high balanced classification rate, high Matthews’ correlation coefficient and a very minimal false alarm rate.",http://dx.doi.org/10.1007/s13369-021-05856-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11356-021-16025-4,"From outbreak of COVID-19 to launching of vaccination drive: invigorating single-use plastics, mitigation strategies, and way forward",Environmental Science and Pollution Research,10.1007/s11356-021-16025-4,Springer,2021-10-01,"The unforeseen outbreak of the COVID-19 epidemic has significantly stipulated the use of plastics to minimize the exposure and spread of the novel coronavirus. With the onset of the vaccination drive, the issue draws even more attention due to additional demand for vaccine packaging, transport, disposable syringes, and other allied devices scaling up to many million tonnes of plastic. Plastic materials in personal protective equipment (PPE), disposable pharmaceutical devices, and packaging for e-commerce facilities are perceived to be a lifesaver for the frontline healthcare personnel and the general public amidst recurring waves of the pandemic. However, the same material poses a threat as an evil environmental polluter when attributed to its indiscriminate and improper littering as well as mismanagement. The review not only highlights the environmental consequences due to the excessive use of disposable plastics amidst COVID-19 but also recommends mixed approaches to its management by adopting the combined and step-by-step methodology of adequate segregation, sterilization, sanitization activities, technological intervention, and process optimization measures. The overview finally concludes with some crucial way-forward measures and recommendations like the development of bioplastics and focusing on biodegradable/bio-compostable material alternatives to holistically deal with future pandemics. Graphical abstract ",http://dx.doi.org/10.1007/s11356-021-16025-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10791-021-09397-1,Variational Bayesian representation learning for grocery recommendation,Information Retrieval Journal,10.1007/s10791-021-09397-1,Springer,2021-10-01,"Representation learning has been widely applied in real-world recommendation systems to capture the features of both users and items. Existing grocery recommendation methods only represent each user and item by single deterministic points in a low-dimensional continuous space, which limit the expressive ability of their embeddings, resulting in recommendation performance bottlenecks. In addition, existing representation learning methods for grocery recommendation only consider the items (products) as independent entities, neglecting their other valuable side information, such as the textual descriptions and the categorical data of items. In this paper, we propose the Variational Bayesian Context-Aware Representation (VBCAR) model for grocery recommendation. VBCAR is a novel variational Bayesian model that learns distributional representations of users and items by leveraging basket context information from historical interactions. Our VBCAR model is also extendable to leverage side information by encoding contextual features into representations based on the inference encoder. We conduct extensive experiments on three real-world grocery datasets to assess the effectiveness of our model as well as the impact of different construction strategies for item side information. Our results show that our VBCAR model outperforms the current state-of-the-art grocery recommendation models while integrating item side information (especially the categorical features with the textual information of items) results in further significant performance gains. Furthermore, we demonstrate through analysis that our model is able to effectively encode similarities between product types, which we argue is the primary reason for the observed effectiveness gains.",http://dx.doi.org/10.1007/s10791-021-09397-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01285-y,"Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda",AI & SOCIETY,10.1007/s00146-021-01285-y,Springer,2021-09-24,"With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.",http://dx.doi.org/10.1007/s00146-021-01285-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00830-2,Monitoring a CI/CD Workflow Using Process Mining,SN Computer Science,10.1007/s42979-021-00830-2,Nature,2021-09-07,"Process mining (PM) is a unique approach to extract workflow models of actual real-world activities, namely those related to software development. To be efficient and produce more reliable results, its algorithms require structured input data. However, actual real-world data originate from multiple heterogeneous sources; thus, integration and normalization are required preparatory steps before applying PM techniques. This problem is exacerbated by the need of performing this analysis in real time, rather than off-line in a batch-style approach. In this paper, we show how Apache Kafka pipelines can be used to support the integration and normalization of the event logs from multiple sources into data streams that feed the process mining algorithms in real-time. An application to the complex CI/CD pipeline of a major European e-commerce company is presented, showing that these techniques provide means to monitor and have higher observability of development processes.",http://dx.doi.org/10.1007/s42979-021-00830-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-021-05969-w,Partially observable environment estimation with uplift inference for reinforcement learning based recommendation,Machine Learning,10.1007/s10994-021-05969-w,Springer,2021-09-01,"Reinforcement learning (RL) aims at searching the best policy model for decision making, and has been shown powerful for sequential recommendations. The training of the policy by RL, however, is placed in an environment. In many real-world applications, the policy training in the real environment can cause an unbearable cost due to the exploration. Environment estimation from the past data is thus an appealing way to release the power of RL in these applications. The estimation of the environment is, basically, to extract the causal effect model from the data. However, real-world applications are often too complex to offer fully observable environment information. Therefore, quite possibly there are unobserved variables lying behind the data, which can obstruct an effective estimation of the environment. In this paper, by treating the hidden variables as a hidden policy, we propose a partially-observed multi-agent environment estimation (POMEE) approach to learn the partially-observed environment. To make a better extraction of the causal relationship between actions and rewards, we design a deep uplift inference network (DUIN) model to learn the causal effects of different actions. By implementing the environment model in the DUIN structure, we propose a POMEE with uplift inference (POMEE-UI) approach to generate a partially-observed environment with a causal reward mechanism. We analyze the effect of our method in both artificial and real-world environments. We first use an artificial recommender environment, abstracted from a real-world application, to verify the effectiveness of POMEE-UI. We then test POMEE-UI in the real application of Didi Chuxing. Experiment results show that POMEE-UI can effectively estimate the hidden variables, leading to a more reliable virtual environment. The online A/B testing results show that POMEE can derive a well-performing recommender policy in the real-world application.",http://dx.doi.org/10.1007/s10994-021-05969-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00448-x,Towards early purchase intention prediction in online session based retailing systems,Electronic Markets,10.1007/s12525-020-00448-x,Springer,2021-09-01,"Purchase prediction has an important role for decision-makers in e-commerce to improve consumer experience, provide personalised recommendations and increase revenue. Many works investigated purchase prediction for session logs by analysing users’ behaviour to predict purchase intention after a session has ended. In most cases, e-shoppers prefer to be anonymous while browsing the websites and after a session has ended, identifying users and offering discounts can be challenging. Therefore, after a session ends, predicting purchase intention may not be useful for the e-commerce strategists. In this work, we propose and develop an early purchase prediction framework using advanced machine learning models to investigate how early purchase intention in an ongoing session can be predicted. Since users could be anonymous, this could help to give real-time offers and discounts before the session ends. We use dynamically created session features after each interaction in a session, and propose a utility scoring method to evaluate how early machine learning models can predict the probability of purchase intention. The proposed framework is validated with a real-world dataset. Computational experiments show machine learning models can identify purchase intention early with good performance in terms of Area Under Curve (AUC) score which shows success rate of machine learning models on early purchase prediction.",http://dx.doi.org/10.1007/s12525-020-00448-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03265-9,Auto-scaling techniques for IoT-based cloud applications: a review,Cluster Computing,10.1007/s10586-021-03265-9,Springer,2021-09-01,"Cloud and IoT applications have inquiring effects that can strongly influence today’s ever-growing internet life along with necessity to resolve numerous challenges for each application such as scalability, security, privacy, and reliability. During the deployment of IoT-based Cloud applications, the demand for Cloud tenants is dynamic that makes challenging to maintain scalability of the system. Developing an effective scaling technique is not merely a big concern, but how to achieve autonomic scaling results using future load prediction and migration policies is also a crucial phase. Also, to evaluate such auto-scaling strategy, certain Quality of Service (QoS) metrics must be recognized, explored and leveraged to enhance the performance of the system. Therefore, in this paper, a survey of existing auto-scaling, load prediction and VM migration techniques for IoT-based Cloud applications has been carried out along with the evaluation of various QoS parameters. Further, the future trends have also been discussed for performing auto-scaling in a Cloud environment.",http://dx.doi.org/10.1007/s10586-021-03265-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00475-2,Machine learning and deep learning,Electronic Markets,10.1007/s12525-021-00475-2,Springer,2021-09-01,"Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization.",http://dx.doi.org/10.1007/s12525-021-00475-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10618-021-00772-6,Fake review detection on online E-commerce platforms: a systematic literature review,Data Mining and Knowledge Discovery,10.1007/s10618-021-00772-6,Springer,2021-09-01,"The increasing popularity of online review systems motivates malevolent intent in competing sellers and service providers to manipulate consumers by fabricating product/service reviews. Immoral actors use Sybil accounts, bot farms, and purchase authentic accounts to promote products and vilify competitors. Facing the continuous advancement of review spamming techniques, the research community should step back, assess the approaches explored to date to combat fake reviews, and regroup to define new ones. This paper reviews the literature on Fake Review Detection (FRD) on online platforms. It covers both basic research and commercial solutions, and discusses the reasons behind the limited level of success that the current approaches and regulations have had in preventing damage due to deceptive reviews.",http://dx.doi.org/10.1007/s10618-021-00772-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-05926-8,Cyber-attack detection in healthcare using cyber-physical system and machine learning techniques,Soft Computing,10.1007/s00500-021-05926-8,Springer,2021-09-01,"Cyber-physical systems have been extensively utilized in healthcare domains to deliver high-quality patient treatment in multifaceted clinical scenarios. The medical device’ heterogeneity involved in these systems (mobile devices and body sensor nodes) introduces enormous attack surfaces and therefore necessitates effective security solutions for these complex environments. Hence, in this study, the cognitive machine learning assisted Attack Detection Framework has been proposed to share healthcare data securely. The Healthcare Cyber-Physical Systems will be proficient in spreading the collected data to cloud storage. Machine learning models predict cyber-attack behavior, and processing this data can offer healthcare specialists decision support. This proposed approach is based on a patient-centric design that safeguards the information on a trusted device like the end-users mobile phones and end-user control data sharing access. Experimental results demonstrate that our suggested model achieves an attack prediction ratio of 96.5%, an accuracy ratio of 98.2%, an efficiency ratio of 97.8%, less delay of 21.3%, and a communication cost of 18.9% to other existing models.",http://dx.doi.org/10.1007/s00500-021-05926-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-02264-y,A panoramic view and swot analysis of artificial intelligence for achieving the sustainable development goals by 2030: progress and prospects,Applied Intelligence,10.1007/s10489-021-02264-y,Springer,2021-09-01,"The17 Sustainable Development Goals (SDGs) established by the United Nations Agenda 2030 constitute a global blueprint agenda and instrument for peace and prosperity worldwide. Artificial intelligence and other digital technologies that have emerged in the last years, are being currently applied in virtually every area of society, economy and the environment. Hence, it is unsurprising that their current role in the pursuance or hampering of the SDGs has become critical. This study aims at providing a snapshot and comprehensive view of the progress made and prospects in the relationship between artificial intelligence technologies and the SDGs. A comprehensive review of existing literature has been firstly conducted, after which a series SWOT (Strengths, Weaknesses, Opportunities and Threats) analyses have been undertaken to identify the strengths, weaknesses, opportunities and threats inherent to artificial intelligence-driven technologies as facilitators or barriers to each of the SDGs. Based on the results of these analyses, a subsequent broader analysis is provided, from a position vantage, to (i) identify the efforts made in applying AI technologies in SDGs, (ii) pinpoint opportunities for further progress along the current decade, and (iii) distill ongoing challenges and target areas for important advances. The analysis is organized into six categories or perspectives of human needs: life, economic and technological development, social development, equality, resources and natural environment. Finally, a closing discussion is provided about the prospects, key guidelines and lessons learnt that should be adopted for guaranteeing a positive shift of artificial intelligence developments and applications towards fully supporting the SDGs attainment by 2030.",http://dx.doi.org/10.1007/s10489-021-02264-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-05722-4,Density-scaling traffic management for autonomous vehicle environment—predictive learning-based technique,Soft Computing,10.1007/s00500-021-05722-4,Springer,2021-09-01,"In this paper, traffic and vehicle density optimization issues are discussed, and a suitable solution for autonomous driving environments is proposed. The problem of scalable traffic flow management is hindered by the unpredictable vehicle density and its navigation. This problem increases the flow congestion at the intersection during the change of lane in particular. This paper introduces density-scaling traffic management for autonomous vehicle driving scenarios. The proposed technique relies on navigation output and the autonomous vehicles' trajectory decisions for predicting their availability and time duration. The traffic flow is streamlines based on the predictions; the prediction error is mitigated by rescheduling the successive traffic flow. In this process, predictive iterated learning is employed for improving the scalable traffic flows in an intersection. The predictive learning handles navigation assistance output change of trajectory independently and correlates the decisions' match. The process of prediction matching is performed for improving the flow management with the time factor. The traffic management technique is useful in providing latency-less travel and errorless decision and flow complexity and collision probability.",http://dx.doi.org/10.1007/s00500-021-05722-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03294-4,The importance of nature-inspired meta-heuristic algorithms for solving virtual machine consolidation problem in cloud environments,Cluster Computing,10.1007/s10586-021-03294-4,Springer,2021-09-01,"Nowadays, cloud computing is known as an internet-based modern area among emerging technologies that brings up an environment, in which computing resources such as hardware, software, storage, etc. can be rented by cloud users based on a pay per use model. Since the size of cloud computing is widely expanding and the number of cloud users is also increasing day by day, high energy consumption becomes a serious concern in the operation of complex cloud data centers. In this regards, Virtual Machine (VM) consolidation plays a vital role in utilizing cloud resources in an efficient manner. It migrates the running VMs from overloaded Physical Machines (PMs) to other PMs considering multiple factors, such as migration overhead, energy consumption, resource utilization, and migration time. Since the VM consolidation issue is known as an NP-hard problem, various nature‐inspired meta-heuristic algorithms aiming to solve this problem have been utilized in recent years. However, a lack of systematic and detailed survey study in this field is obvious. Therefore, this gap motivated us to provide the current paper aiming to highlight the role of nature-inspired meta-heuristic algorithms in the VM consolidation problem, review the existing approaches, offer a detailed comparison of approaches based on important factors, and finally, outline the future directions.",http://dx.doi.org/10.1007/s10586-021-03294-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40171-021-00272-y,Impact of Big Data and Artificial Intelligence on Industry: Developing a Workforce Roadmap for a Data Driven Economy,Global Journal of Flexible Systems Management,10.1007/s40171-021-00272-y,Springer,2021-09-01,"Big Data and Artificial Intelligence (BD&AI) have become so pervasive, and the opportunities they present so transformative, that they are viewed as essential for competitive growth. Since the number of firms adopting BD&AI technologies is growing exponentially, the demand for BD&AI practitioners is also growing at a rapid rate. However, several studies indicate that there is a BD&AI talent shortage and skills gap between labor market requirements and expertise available in the current workforce. This talent shortage and skills gap are now recognized as a crucial impediment in leveraging BD&AI for economic growth at the local, national, and global levels. This research aims to identify BD&AI workforce trends, gaps, and opportunities by using bibliometric analysis and extracting insights from job posting data. The study team first conducted bibliometric research and built word co-occurrence diagrams using BD&AI related articles published in high-impact journals to determine technological changes impacting various industry domains. The team then collected job postings data and summarized the skill sets required to be competitive in industries driven by BD&AI. Finally, the study team evaluated the curricula of BD&AI programs at various colleges and universities educating the future workforce and conducted a SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis to bridge the gaps between industry needs and academic training. This multi-step research framework forecasts oncoming technological changes in various industry clusters, workforce skills that are and will be needed, and provides recommendations for a workforce development roadmap so that businesses can gain a competitive advantage through the use of BD&AI.",http://dx.doi.org/10.1007/s40171-021-00272-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00443-2,AI and robotics in the European restaurant sector: Assessing potentials for process innovation in a high-contact service industry,Electronic Markets,10.1007/s12525-020-00443-2,Springer,2021-09-01,"The restaurant technology market is rapidly evolving and is transforming the restaurant business as a significant sector of tourism and hospitality. Enabled by artificial intelligence (AI), mobile apps, kiosks and chatbots revolutionize the guest experience and robots automate restaurant operations. Despite the increasing interest, the use of AI and robotics in restaurants is still in its early stage and restaurant managers are seeking guidance to leverage these technologies for service excellence. In this high-contact service sector, emotional skills need to be balanced with the possible automation potentials. The present research analyzes the current state of AI and robotics in the restaurant sector and proposes a systematic identification of process innovation potentials. For this purpose, a market analysis of the European AI and robotics market for restaurant operations is conducted, which yields a first knowledge base for future research and conceptual work. Besides detailed empirical data, a reference process is developed for leveraging new technologies for process innovation.",http://dx.doi.org/10.1007/s12525-020-00443-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10107-x,A Hybrid Approach of Machine Learning and Lexicons to Sentiment Analysis: Enhanced Insights from Twitter Data of Natural Disasters,Information Systems Frontiers,10.1007/s10796-021-10107-x,Springer,2021-09-01,"The success factor of sentimental analysis lies in identifying the most occurring and relevant opinions among users relating to the particular topic. In this paper, we develop a framework to analyze users’ sentiments on Twitter on natural disasters using the data pre-processing techniques and a hybrid of machine learning, statistical modeling, and lexicon-based approach. We choose TF-IDF and K-means for sentiment classification among affinitive and hierarchical clustering. Latent Dirichlet Allocation, a pipeline of Doc2Vec and K-means used to capture themes, then perform multi-level polarity indices classification and its time series analysis. In our study, we draw insights from 243,746 tweets for Kerala’s 2018 natural disasters in India. The key findings of the study are the classification of sentiments based on similarity and polarity indices and identifying themes among the topics discussed on Twitter. We observe different sets of emotions and influencers, among others. Through this case example of Kerala floods, it shows how the government and other organizations could track the positive/negative sentiments concerning time and location; gain a better understanding of the topic of discussion trending among the public, and collaborate with crucial Twitter users/influencers to spread and figure out the gaps in the implementation of schemes in terms of design and execution. This research’s uniqueness is the streamlined and efficient combination of algorithms and techniques embedded in the framework used in achieving the above output, which can be integrated into a platform with GUI for further automation.",http://dx.doi.org/10.1007/s10796-021-10107-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05640-w,A novel context-aware recommender system based on a deep sequential learning approach (CReS),Neural Computing and Applications,10.1007/s00521-020-05640-w,Springer,2021-09-01,"With an increase in online longitudinal users’ interactions, capturing users’ precise preferences and giving accurate recommendations have become an urgent need for all businesses. Existing sequence-aware methods generally exploit a static low-rank vector for acquiring the overall sequential features, and incorporate context information as auxiliary input. As a result, they have a restricted modeling ability for extracting multi-grained sequential behaviors over contextual information. In other words, they poorly capture the hierarchical relationship between context relations and item relations that currently influence users’ preferences in a unified framework. Besides, they usually utilize users’ short-term preferences with either static or irrelevant long-term representation for the prediction. To tackle the above issues, in this paper, we propose a novel C ontext-aware Re commender System Based on a Deep S equential Learning Approach (CReS) to capture users’ dynamic preferences by modeling the hierarchical relationships between contexts and items in a particular session, and for combining users’ short-term sessions with the relevant long-term representations. Specifically, within a certain session, we design a hierarchical attention network between the identified context relations and items relations, namely CReSession. Therefore, with CReSession, we could provide a suitable session representation that mimics the hierarchical user interests on multiple granularities of contextual types and its corresponding items. We then introduce a neural attentive bi-directional GRU network to distill only those highly related to the recent short-term session. Finally, the relevant long-term representations and the short-term session are combined with the sequential residual connection to form the final user representation in a unified manner. With extensive experiments on two real-world datasets, CReS not only achieves significant improvement over the state-of-the-art methods in terms of pre-defined metrics, but also provides an interpretable result regarding why we recommend these items to users.",http://dx.doi.org/10.1007/s00521-020-05640-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-03643-5,An improved privacy-preserving data mining technique using singular value decomposition with three-dimensional rotation data perturbation,The Journal of Supercomputing,10.1007/s11227-021-03643-5,Springer,2021-09-01,"Recent advancements in data mining have given rise to a new channel of research, coined as privacy-preserving data mining (PPDM). PPDM technology allows us to derive useful information from vast amounts of data while protecting privacy of individual records. This paper proposed a methodology based on the machine learning algorithm called singular value decomposition (SVD) and 3D rotation data perturbation (RDP) for preserving privacy of data. Decomposition and dimensionality reduction helps to eliminate sensitive information, and perturbed matrix is generated. The original and perturbed data are classified using different classifiers, and the performance is measured in terms of accuracy rate. Accuracy is the degree of correlation between the absolute observation and the actual observations. Experimental results revealed that the proposed scheme outperforms by achieving excellent accuracy for matrices of different sizes.",http://dx.doi.org/10.1007/s11227-021-03643-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03243-1,A multi-layer trust-based middleware framework for handling interoperability issues in heterogeneous IOTs,Cluster Computing,10.1007/s10586-021-03243-1,Springer,2021-09-01,"Traditional wireless technologies have evolutionary converged to Internet of Thing (IoT) for devices and service interactions. In the past decade, the academia, industry 4.0 and end-user interest has also grown drastically in IoT applications and their services. However, this increase in IoT services demand has witnessed a new challenge of seamless interaction among heterogeneous devices that are varied, diverse and dynamic in nature. In this connection, another challenge is tracing the footprint of these IoT interactions for trust-based interactions, that further becomes complex with the introduction of new applications. For instance, in many situations, IoT services are generally not self-contained and sufficient. They need to coordinate and interact with other IoT services held in the surroundings. The large-scale deployment of IoT based services is not conceivable without addressing interoperability and services coordination related challenges. In this regard, a comprehensive set of tools and techniques associated with IoT heterogeneity and interoperability have been explored. This article proposes a middleware framework to consider IoT heterogeneity and interoperability issues in different service interactions. Later, the article investigates experimentally, the trust measurements among IOTs, their decay, and the effectiveness of dynamic selection of trust parameters along with their thresholds. Appropriateness of time intervals have also been tested in various types of service interactions. To demonstrate middleware applicability, the trust-based algorithm has been applied in a service-oriented environment along with different types of services.",http://dx.doi.org/10.1007/s10586-021-03243-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00472-5,Is a picture worth a thousand views? Measuring the effects of travel photos on user engagement using deep learning algorithms,Electronic Markets,10.1007/s12525-021-00472-5,Springer,2021-09-01,"Travel photos inform and inspire consumers by conveying a first-hand destination experience. Despite the proliferation of consumer-generated travel photos in online travel review sites, deconstructing the effects of photos on consumer engagement remains a challenge to the tourism industry. We provide a framework to process and interpret various photographic elements on user engagement using deep learning algorithms. We posit that a photo can invoke consumers’ subjective interpretations of photos representing authentic, creative, or emotional dimensions of the destination experience. A structured crowdsourced categorization process was deployed to measure the interpretive dimensions of the photos. The objects in photographs are identified using a novel deep learning algorithm for controls. We use narrative framing concepts to theorize their influence on user engagement in an online travel review site setting. Relevant three sets of hypotheses are tested using a large dataset of photo-based travel reviews sampled between 2012 and 2014. A negative zero-inflated binomial regression is used to estimate the effect of subjective interpretation of photos on user engagement, accounting for overdispersed excess zeros associated with count outcomes. Results support the hypotheses. The additional analyses explore other plausible influential attributes to user engagements to complement our main findings. We discuss the theoretical contributions to the online-image-persuasion stream of research and practical implications for online tourist review sites.",http://dx.doi.org/10.1007/s12525-021-00472-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-020-03225-9,Truthful online double auction based dynamic resource provisioning for multi-objective trade-offs in IaaS clouds,Cluster Computing,10.1007/s10586-020-03225-9,Springer,2021-09-01,"Auction designs have recently been adopted for static and dynamic resource provisioning in IaaS clouds, such as Microsoft Azure and Amazon EC2. However, the existing mechanisms are mostly restricted to simple auctions, single-objective, offline setting, one-sided interactions either among cloud users or cloud service providers (CSPs), and possible misreports of cloud user’s private information. This paper proposes a more realistic scenario of online auctioning for IaaS clouds, with the unique characteristics of elasticity for time-varying arrival of cloud user requests under the time-based server maintenance in cloud data centers. We propose an online truthful double auction technique for balancing the multi-objective trade-offs between energy, revenue, and performance in IaaS clouds, consisting of a weighted bipartite matching based winning-bid determination algorithm for resource allocation and a Vickrey–Clarke–Groves (VCG) driven algorithm for payment calculation of winning bids. Through rigorous theoretical analysis and extensive trace-driven simulation studies exploiting Google cluster workload traces, we demonstrate that our mechanism significantly improves the performance while promising truthfulness, heterogeneity, economic efficiency, individual rationality, and has a polynomial-time computational complexity.",http://dx.doi.org/10.1007/s10586-020-03225-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-020-01023-z,A digital rights management system based on a scalable blockchain,Peer-to-Peer Networking and Applications,10.1007/s12083-020-01023-z,Springer,2021-09-01,"Even though the Internet promotes data sharing and transparency, however it does not protect digital content. In today’s digital world, it has become a difficult task to release a DRM (Digital Rights Management) system that can be considered well-protected. Digital content that becomes easily available in open-source environments will in time be worthless to the creator. There may only be a one-time payment to creators upon initial upload to a given platform after which time the rights of the intellectual property are shifted to the platform itself. However, due to the online availability of content, anyone can download content and make copies. The value of digital content slowly decreases, because the value of content can usually be determined through the difficulty of it’s accessibility. There is no way to track the leakage or copyright for the spread of digital material. In this paper, a distributed media transaction framework for DRM is proposed, which is based on the digital watermarking and a scalable blockchain model. In this paper, our focus is on improving the classic blockchain systems to make it suitable for a DRM model. The DRM model in this paper allows only authorized users to use online content and provide original multimedia content. While the digital watermarking is used to reclaim the copyright ownership of offline contents in the event when the contents are leaked.",http://dx.doi.org/10.1007/s12083-020-01023-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00511-w,Optimized intelligent data management framework for a cyber-physical system for computational applications,Complex & Intelligent Systems,10.1007/s40747-021-00511-w,Springer,2021-08-30,"Data management is one obstacle in the production sector to be reconfigured and adapted through optimum parameterization in industry cyber-physical systems. This paper presents an intelligent data management framework for a cyber-physical system (IDMF-CPS) with machine-learning methods. A training approach based on two enhanced training procedures, running concurrently to upgrade the processing and communication strategy and the predictive models, is contained in the suggested reasoning modules. The method described spreads computational and analytical engines in several levels and autonomous modules to enhance intelligence and autonomy for controlling and tracking behavior on the work floor. The appropriateness of the suggested solution is supported by rapid reaction time and a suitable establishment of optimal operating variables for the required quality during macro- and micro-operations.",http://dx.doi.org/10.1007/s40747-021-00511-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00827-x,"Methods, Databases and Recent Advancement of Vision-Based Hand Gesture Recognition for HCI Systems: A Review",SN Computer Science,10.1007/s42979-021-00827-x,Nature,2021-08-29,"Hand gesture recognition is viewed as a significant field of exploration in computer vision with assorted applications in the human–computer communication (HCI) community. The significant utilization of gesture recognition covers spaces like sign language, medical assistance and virtual reality–augmented reality and so on. The underlying undertaking of a hand gesture-based HCI framework is to acquire raw data which can be accomplished fundamentally by two methodologies: sensor based and vision based. The sensor-based methodology requires the utilization of instruments or the sensors to be genuinely joined to the arm/hand of the user to extract information. While vision-based plans require the obtaining of pictures or recordings of the hand gestures through a still/video camera. Here, we will essentially discuss vision-based hand gesture recognition with a little prologue to sensor-based data obtaining strategies. This paper overviews the primary methodologies in vision-based hand gesture recognition for HCI. Major topics include different types of gestures, gesture acquisition systems, major problems of the gesture recognition system, steps in gesture recognition like acquisition, detection and pre-processing, representation and feature extraction, and recognition. Here, we have provided an elaborated list of databases, and also discussed the recent advances and applications of hand gesture-based systems. A detailed discussion is provided on feature extraction and major classifiers in current use including deep learning techniques. Special attention is given to classify the schemes/approaches at various stages of the gesture recognition system for a better understanding of the topic to facilitate further research in this area.",http://dx.doi.org/10.1007/s42979-021-00827-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06378-9,SmartDL: energy-aware decremental learning in a mobile-based federation for geo-spatial system,Neural Computing and Applications,10.1007/s00521-021-06378-9,Springer,2021-08-09,"Federated learning is designed to collaboratively train a shared model based on a large number of mobile devices while preserving data privacy, which has been widely adopted to support different geo-spatial systems. However, two critical issues prevent federated learning to be effectively deployed on resource-constrained devices in large scale. First, federated learning causes high energy consumption which can badly hurt the battery lifetime of mobile devices. Second, leakage of sensitive personal information still occurs during the training process. Thus, a system that can effectively protect the sensitive information while improving the energy efficiency is urgently required for a mobile-based federated learning system. This paper proposes SmartDL, an energy-aware decremental learning framework that well balances the energy efficiency and data privacy in an efficient manner. SmartDL improves the energy efficiency from two levels: (1) global layer, which adopts an optimization approach to select a subset of participating devices with sufficient capacity and maximum reward. (2) local layer, which adopts a novel decremental learning algorithm to actively provides the decremental and incremental updates, and can adaptively tune the local DVFS at the same time. We prototyped SmartDL on physical testbed and evaluated its performance using several learning benchmarks with real-world traces. The evaluation results show that compared with the original federated learning, SmartDL can reduce energy consumption by 75.6–82.4% in different datasets. Moreover, SmartDL achieves a speedup of 2–4 orders of magnitude in model convergence while ensuring the accuracy of the model.",http://dx.doi.org/10.1007/s00521-021-06378-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11423-020-09858-2,"Machine learning for human learners: opportunities, issues, tensions and threats",Educational Technology Research and Development,10.1007/s11423-020-09858-2,Springer,2021-08-01,"Machine learning systems are infiltrating our lives and are beginning to become important in our education systems. This article, developed from a synthesis and analysis of previous research, examines the implications of recent developments in machine learning for human learners and learning. In this article we first compare deep learning in computers and humans to examine their similarities and differences. Deep learning is identified as a sub-set of machine learning, which is itself a component of artificial intelligence. Deep learning often depends on backwards propagation in weighted neural networks, so is non-deterministic—the system adapts and changes through practical experience or training. This adaptive behaviour predicates the need for explainability and accountability in such systems. Accountability is the reverse of explainability. Explainability flows through the system from inputs to output (decision) whereas accountability flows backwards, from a decision to the person taking responsibility for it. Both explainability and accountability should be incorporated in machine learning system design from the outset to meet social, ethical and legislative requirements. For students to be able to understand the nature of the systems that may be supporting their own learning as well as to act as responsible citizens in contemplating the ethical issues that machine learning raises, they need to understand key aspects of machine learning systems and have opportunities to adapt and create such systems. Therefore, some changes are needed to school curricula. The article concludes with recommendations about machine learning for teachers, students, policymakers, developers and researchers.",http://dx.doi.org/10.1007/s11423-020-09858-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05798-x,Multi-disease big data analysis using beetle swarm optimization and an adaptive neuro-fuzzy inference system,Neural Computing and Applications,10.1007/s00521-021-05798-x,Springer,2021-08-01,"Healthcare organizations and Health Monitoring Systems generate large volumes of complex data, which offer the opportunity for innovative investigations in medical decision making. In this paper, we propose a beetle swarm optimization and adaptive neuro-fuzzy inference system (BSO-ANFIS) model for heart disease and multi-disease diagnosis. The main components of our analytics pipeline are the modified crow search algorithm, used for feature extraction, and an ANFIS classification model whose parameters are optimized by means of a BSO algorithm. The accuracy achieved in heart disease detection is $$99.1\%$$ 99.1 % with $$99.37\%$$ 99.37 % precision. In multi-disease classification, the accuracy achieved is $$96.08\%$$ 96.08 % with $$98.63\%$$ 98.63 % precision. The results from both tasks prove the comparative advantage of the proposed BSO-ANFIS algorithm over the competitor models.",http://dx.doi.org/10.1007/s00521-021-05798-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-10965-2,A comprehensive analysis on movie recommendation system employing collaborative filtering,Multimedia Tools and Applications,10.1007/s11042-021-10965-2,Springer,2021-08-01,"Collaborative Filtering (CF) is one of the most extensively used technologies for Recommender Systems (RS), it shows an improved intelligent searching mechanism for recommending personalized items. It effectively makes use of the information retained by the application to find similarities between the sections of the application. Apart from RS, other applications of CF making use of the sensing and monitoring of data are environmental sensing, mineral study, financial services, marketing, and many more. Different industries like Tourism, Television, E-Learning, etc. make use of this technology, software such as Customer Relationship Management also make use of this technology. This paper discusses the prowess CF algorithm and its applications for Movie Recommendation System (MRS). It gives a brief overview of collaborative filtering consisting of two major approaches: user-based approach and Item-based approaches. Further, in model-based filtering methodology, it is discussed how machine learning algorithms can be implemented for movie recommendation purposes and also to predict the ratings of the unrated movies and bifurcate or sort movies as per the user preference. Followed by, it throws some light on the methodologies used in the late past and some of the basic approaches that are taken into consideration to incorporate it into MSR. Additionally, this paper anatomized many of the recent past studies in depth to draw out the essence of the researches and studies, its crucial steps, results, future scope and methodologies, followed and suggested by multiple researchers. Finally, we have discussed various challenges in MRS and probable future developments in this field. It is to be noted that various challenges in the field of CF recommendation systems like cold start, data sparsity, scalability issues, etc. were raised and many approaches tried to tackle these challenges in innovative and novel ways. Conclusively CF algorithm is a highly efficacious technique for the application of MRS and its integration with other techniques will lead students, researchers and enthusiasts to more cogent approaches for MRS.",http://dx.doi.org/10.1007/s11042-021-10965-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05730-3,Making recommendations using transfer learning,Neural Computing and Applications,10.1007/s00521-021-05730-3,Springer,2021-08-01,"Deep learning-based recommender systems have gained much attention due to the advantage of encoding content-based information, such as user textual reviews and item descriptions, images, or videos, without the trouble of manually crafting feature vectors. However, those systems are trained from scratch with randomly initialized parameters, where the training process can take a long time to converge. With the most recent breakthroughs in Natural Language Processing using transfer learning, pre-trained transformer-based models now provide a better foundation for textual information encoding. This inspires us to propose a transformer-based recommender system using transfer learning. As the first core contribution in this work, we apply transfer learning to the system, by fine-tuning the pre-trained transformer models for information encoding. The experiment result shows that the proposed system outperforms several other deep learning-based recommender systems on multiple datasets. As the second core contribution, we propose a novel user vector encoding algorithm that assists all the models to achieve a better performance, when the user content information is not available.",http://dx.doi.org/10.1007/s00521-021-05730-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10168-y,Cognitive Chatbot for Personalised Contextual Customer Service: Behind the Scene and beyond the Hype,Information Systems Frontiers,10.1007/s10796-021-10168-y,Springer,2021-07-09,"With the proliferation of the use of chatbots across industries, business-to-business (B2B) businesses have started using cognitive chatbots for improved customer service which signifies our research. By extending the Technology Acceptance Model and Information Systems Success Model, this study examines personalised contextual customer service using cognitive chatbot. A quantitative research method is applied to the primary data collected from 300 respondents of B2B businesses. The study contributes to the limited research on chatbots and suggests improvement in customer service. The findings provide evidence of high value by customers, particularly while checking for real-time information on reliability and accessibility of products/services. The automated answers to repetitive questions on the recurrent issues create a seamless experience for the customers. This research makes significant theoretical contributions by integrating two models into a simplified model in chatbot literature and manifest that trust affects the willingness to use the cognitive chatbot which drives automation.",http://dx.doi.org/10.1007/s10796-021-10168-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-020-09284-2,Exploring author gender in book rating and recommendation,User Modeling and User-Adapted Interaction,10.1007/s11257-020-09284-2,Springer,2021-07-01,"Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of these patterns reflect important real-world phenomena driving interactions between the various users and items; other patterns may be irrelevant or reflect undesired discrimination, such as discrimination in publishing or purchasing against authors who are women or ethnic minorities. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to one dimension of social concern, namely content creator gender. Using publicly available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms tend to propagate at least some of each user’s tendency to rate or read male or female authors into their resulting recommendations, although they differ in both the strength of this propagation and the variance in the gender balance of the recommendation lists they produce. The data, experimental design, and statistical methods are designed to be reusable for studying potentially discriminatory social dimensions of recommendations in other domains and settings as well.",http://dx.doi.org/10.1007/s11257-020-09284-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-020-09281-5,The effects of controllability and explainability in a social recommender system,User Modeling and User-Adapted Interaction,10.1007/s11257-020-09281-5,Springer,2021-07-01,"In recent years, researchers in the field of recommender systems have explored a range of advanced interfaces to improve user interactions with recommender systems. Some of the major research ideas explored in this new area include the explainability and controllability of recommendations. Controllability enables end users to participate in the recommendation process by providing various kinds of input. Explainability focuses on making the recommendation process and the reasons behind specific recommendation more clear to the users. While each of these approaches contributes to making traditional “black-box” recommendation more attractive and acceptable to end users, little is known about how these approaches work together. In this paper, we investigate the effects of adding user control and visual explanations in a specific context of an interactive hybrid social recommender system. We present Relevance Tuner+ , a hybrid recommender system that allows the users to control the fusion of multiple recommender sources while also offering explanations of both the fusion process and each of the source recommendations. We also report the results of a controlled study ( N  = 50) that explores the impact of controllability and explainability in this context.",http://dx.doi.org/10.1007/s11257-020-09281-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-021-09994-0,MLASP: Machine learning assisted capacity planning,Empirical Software Engineering,10.1007/s10664-021-09994-0,Springer,2021-06-24,"In industrial environments it is critical to find out the capacity of a system and plan for a deployment layout that meets the production traffic demands. The system capacity is influenced by both the performance of the system’s constituting components and the physical environment setup. In a large system, the configuration parameters of individual components give the flexibility to developers and load test engineers to tune system performance without changing the source code. However, due to the large search space, estimating the capacity of the system given different configuration values is a challenging and costly process. In this paper, we propose an approach, called MLASP , that uses machine learning models to predict the system key performance indicators (i.e., KPIs), such as throughput, given a set of features made off configuration parameter values, including server cluster setup, to help engineers in capacity planning for production environments. Under the same load, we evaluate MLASP on two large-scale mission-critical enterprise systems developed by Ericsson and on one open-source system. We find that: 1) MLASP can predict the system throughput with a very high accuracy. The difference between the predicted and the actual throughput is less than 1%; and 2) By using only a small subset of the training data (e.g., 3% of the entire data for the open-source system), MLASP can still predict the throughput accurately. We also document our experience of successfully integrating the approach into an industrial setting. In summary, this paper highlights the benefits and potential of using machine learning models to assist load test engineers in capacity planning.",http://dx.doi.org/10.1007/s10664-021-09994-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40854-021-00261-1,A predictive indicator using lender composition for loan evaluation in P2P lending,Financial Innovation,10.1186/s40854-021-00261-1,Springer,2021-06-22,"Most loan evaluation methods in peer-to-peer (P2P) lending mainly exploit the borrowers’ credit information. However, the present study presents the maturity-based lender composition score, which exploits the investment capability of a group of lenders who fund the same loan, to enhance the P2P loan evaluation. More specifically, we extract lenders’ profiles in terms of performance, risk, and experience by quantifying their investment history and develop our loan evaluation indicator by aggregating the profiles of lenders in the composition. To measure the ability of a lender for continuous improvement in P2P investment, we introduce lender maturity to capture this evolvement and incorporate it into the aggregation process. Our empirical study demonstrates that the maturity-based lender composition score can serve as an effective indicator for identifying loan quality and be included in other commonly used loan evaluation models for accuracy improvement.",http://dx.doi.org/10.1186/s40854-021-00261-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-021-10156-2,Questioning Racial and Gender Bias in AI-based Recommendations: Do Espoused National Cultural Values Matter?,Information Systems Frontiers,10.1007/s10796-021-10156-2,Springer,2021-06-20,"One realm of AI, recommender systems have attracted significant research attention due to concerns about its devastating effects to society’s most vulnerable and marginalised communities. Both media press and academic literature provide compelling evidence that AI-based recommendations help to perpetuate and exacerbate racial and gender biases. Yet, there is limited knowledge about the extent to which individuals might question AI-based recommendations when perceived as biased. To address this gap in knowledge, we investigate the effects of espoused national cultural values on AI questionability, by examining how individuals might question AI-based recommendations due to perceived racial or gender bias. Data collected from 387 survey respondents in the United States indicate that individuals with espoused national cultural values associated to collectivism, masculinity and uncertainty avoidance are more likely to question biased AI-based recommendations. This study advances understanding of how cultural values affect AI questionability due to perceived bias and it contributes to current academic discourse about the need to hold AI accountable.",http://dx.doi.org/10.1007/s10796-021-10156-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12911-021-01553-3,"Medical recommender systems based on continuous-valued logic and multi-criteria decision operators, using interpretable neural networks",BMC Medical Informatics and Decision Making,10.1186/s12911-021-01553-3,BioMed Central,2021-06-11,"Background Out of the pressure of Digital Transformation, the major industrial domains are using advanced and efficient digital technologies to implement processes that are applied on a daily basis. Unfortunately, this still does not happen in the same way in the medical domain. For this reason, doctors usually do not have the time or knowledge to evaluate all alternative treatment options for each patient accurately and individually. However, physicians can reduce their workload by using recommender systems, still having every decision under control. In this way, they also get an insight into how other physicians make treatment decisions in each situation. In this work, we report the development of a novel recommender system that uses predicted outcomes based on continuous-valued logic and multi-criteria decision operators. The advantage of this methodology is that it is transparent, since the model outcomes emulate logical decision processes based on the hierarchy of relevant physiological parameters, and second, it is safer against adversarial attacks than conventional deep learning methods since it drastically reduces the number of trainable parameters. Methods We test our methodology in a patient population with diabetes and heart insufficiency that becomes a therapy (beta-blockers, ACE or Aspirin). The original database (Pakistan database) is publicly available and accessible via the internet. However, to explore methods to protect the patient's identity and guarantee data privacy we implemented a methodology on a variable-by-variable basis by fitting a sequence of regression models and drawing synthetic values from the corresponding predictive distributions using linear regressions and norm rank. Furthermore, we implemented a deep-learning model based on logical gates modeled by perceptrons with fixed weights and biases. While a first trainable layer automatically recognizes a meaningful parameter hierarchy, the implemented Logic-Operator Neuronal Network (LONN) simulates cognitive processes like a rational, logical thinking process, considering that this logic is joined by fuzziness, i.e., logical operations are not exact but essentially fuzzy due to the implemented continuous-valued operators. The predicted outcomes of the model (kind of therapy-ACE, Aspirin or beta-blocker- and expected therapy time of the patient) are then implemented in a recommender system that compares two different models: model 1 trained on a population excluding negative outcomes (patient group 1, with no patient dead and long therapy times) and a model 2 trained on the whole patient population (patient group 2). In this way, we provide a recommendation of the best possible therapy based on the outcome of the model and the confidence of this recommendation when the outcome of model 1 is compared with the outcome of model 2. Results With the applied method for data synthetization, we obtained an error of about 1% for all the relevant parameters. Furthermore, we demonstrate that the LONN models reach an accuracy of about 75%. After comparing the LONN models against conventional deep-learning models we observe that our implemented models are less accurate (accuracy loss of about 8%). However, the loss of accuracy is compensated by the fact that LONN models are transparent and safe because the freezing of training parameters makes them less prone to adversarial attacks. Finally, we predict the best therapy as well as the expected therapy time. We were able to predict individualized therapies, which were classified as optimal (binary value) when the prediction fully matched predictions made with models 1 and 2. The results provided by the recommender system are displayed using a graphical interface. The current is a proof of concept to improve the quality of the disease management, while the methods are continuously visualized to preserve transparency for the customers. Conclusions This work contributes to simplify administrative functions and boost the quality of management of patients improving the quality of healthcare with models that are both transparent and safe. Our methodology can be extended to different clinical scenarios where recommender systems can be applied. The acceptance and further development of the app is one of the next important steps and still requires further development depending on specific requirements of the health management, the physicians or health professionals, and the patent population.",http://dx.doi.org/10.1186/s12911-021-01553-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-021-04149-2,An intelligent payment card fraud detection system,Annals of Operations Research,10.1007/s10479-021-04149-2,Springer,2021-06-08,"Payment cards offer a simple and convenient method for making purchases. Owing to the increase in the usage of payment cards, especially in online purchases, fraud cases are on the rise. The rise creates financial risk and uncertainty, as in the commercial sector, it incurs billions of losses each year. However, real transaction records that can facilitate the development of effective predictive models for fraud detection are difficult to obtain, mainly because of issues related to confidentially of customer information. In this paper, we apply a total of 13 statistical and machine learning models for payment card fraud detection using both publicly available and real transaction records. The results from both original features and aggregated features are analyzed and compared. A statistical hypothesis test is conducted to evaluate whether the aggregated features identified by a genetic algorithm can offer a better discriminative power, as compared with the original features, in fraud detection. The outcomes positively ascertain the effectiveness of using aggregated features for undertaking real-world payment card fraud detection problems.",http://dx.doi.org/10.1007/s10479-021-04149-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-021-04142-9,A review of the role of heuristics in stochastic optimisation: from metaheuristics to learnheuristics,Annals of Operations Research,10.1007/s10479-021-04142-9,Springer,2021-06-08,"In the context of simulation-based optimisation, this paper reviews recent work related to the role of metaheuristics, matheuristics (combinations of exact optimisation methods with metaheuristics), simheuristics (hybridisation of simulation with metaheuristics), biased-randomised heuristics for ‘agile’ optimisation via parallel computing, and learnheuristics (combination of statistical/machine learning with metaheuristics) to deal with NP-hard and large-scale optimisation problems in areas such as transport and logistics, manufacturing and production, smart cities, telecommunication networks, finance and insurance, sustainable energy consumption, health care, military and defence, e-marketing, or bioinformatics. The manuscript provides the main related concepts and updated references that illustrate the applications of these hybrid optimisation–simulation–learning approaches in solving rich and real-life challenges under dynamic and uncertainty scenarios. A numerical analysis is also included to illustrate the benefits that these approaches can offer across different application fields. Finally, this work concludes by highlighting open research lines on the combination of these methodologies to extend the concept of simulation-based optimisation.",http://dx.doi.org/10.1007/s10479-021-04142-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-021-09513-x,ANEGMA: an automated negotiation model for e-markets,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-021-09513-x,Springer,2021-06-07,"We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e-markets. The agent uses an actor-critic architecture with model-free reinforcement learning to learn a strategy expressed as a deep neural network. We pre-train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e-market settings without the need to be pre-programmed. Our experimental evaluation shows that our deep reinforcement learning based agents outperform two existing well-known negotiation strategies in one-to-many concurrent bilateral negotiations for a range of e-market settings.",http://dx.doi.org/10.1007/s10458-021-09513-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-020-00441-4,Trustworthy artificial intelligence,Electronic Markets,10.1007/s12525-020-00441-4,Springer,2021-06-01,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",http://dx.doi.org/10.1007/s12525-020-00441-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-020-09494-2,Toward Smart Logistics: Engineering Insights and Emerging Trends,Archives of Computational Methods in Engineering,10.1007/s11831-020-09494-2,Springer,2021-06-01,"Each day, companies and organizations are facing new challenges. The customer requirements are increasing and global competition is leading to important changes in the industrial world. Against this background, the fourth industrial revolution aims to deal with these challenges. Besides the lack of comparable studies covering the new concepts in logistics, this study intends to study, and clarify diverse approaches in smart logistics frameworks in order to produce a new picture of the state of smart logistics research. The main objective of this paper is to present a coherent and comprehensive vision of current efforts in smart logistics. In particular, we begin by presenting the methodology followed and the bibliometric analysis. We also propose a classification of existing works in the literature dealing with intelligent logistics. Also, we provide an overview of smart logistics technologies and applications presented in the recent literature and provide a summary of related research work. Finally, we identify possible future areas of research.",http://dx.doi.org/10.1007/s11831-020-09494-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-019-09362-7,Cash flow prediction: MLP and LSTM compared to ARIMA and Prophet,Electronic Commerce Research,10.1007/s10660-019-09362-7,Springer,2021-06-01,"Cash flow prediction is important. It can help increase returns and improve the allocation of capital in healthy, mature firms as well as prevent fast-growing firms, or firms in distress, from running out of cash. In this paper, we predict accounts receivable cash flows employing methods applicable to companies with many customers and many transactions such as e-commerce companies, retailers, airlines and public transportation firms with sales in multiple regions and countries. We first discuss “classic” forecasting techniques such as ARIMA and Facebook's™ Prophet before moving on to neural networks with multi-layered perceptrons and, finally, long short-term memory networks, that are particularly useful for time series forecasting but were until now not used for cash flows. Our evaluation demonstrates this range of methods to be of increasing sophistication, flexibility and accuracy. We also introduce a new performance measure, interest opportunity cost, that incorporates interest rates and the cost of capital to optimize the models in a financially meaningful, money-saving, way.",http://dx.doi.org/10.1007/s10660-019-09362-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01851-9,Stratified and time-aware sampling based adaptive ensemble learning for streaming recommendations,Applied Intelligence,10.1007/s10489-020-01851-9,Springer,2021-06-01,"Recommender systems have played an increasingly important role in providing users with tailored suggestions based on their preferences. However, the conventional offline recommender systems cannot handle the ubiquitous data stream well. To address this issue, Streaming Recommender Systems (SRSs) have emerged in recent years, which incrementally train recommendation models on newly received data for effective real-time recommendations. Focusing on new data only benefits addressing concept drift , i.e., the changing user preferences towards items. However, it impedes capturing long-term user preferences . In addition, the commonly existing underload and overload problems should be well tackled for higher accuracy of streaming recommendations. To address these problems, we propose a S tratified and T ime-aware S ampling based A daptive E nsemble L earning framework, called STS-AEL, to improve the accuracy of streaming recommendations. In STS-AEL, we first devise stratified and time-aware sampling to extract representative data from both new data and historical data to address concept drift while capturing long-term user preferences. Also, incorporating the historical data benefits utilizing the idle resources in the underload scenario more effectively. After that, we propose adaptive ensemble learning to efficiently process the overloaded data in parallel with multiple individual recommendation models, and then effectively fuse the results of these models with a sequential adaptive mechanism. Extensive experiments conducted on three real-world datasets demonstrate that STS-AEL, in all the cases, significantly outperforms the state-of-the-art SRSs.",http://dx.doi.org/10.1007/s10489-020-01851-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-020-00308-8,Increasing the availability of IoT applications with reactive microservices,Service Oriented Computing and Applications,10.1007/s11761-020-00308-8,Springer,2021-06-01,"Developing Internet of Things (IoT) applications and fulfilling their Quality-of-Service (QoS) requirements, such as interoperability, scalability, adaptability and reliability, pose multiple challenges. These challenges are imposed mainly by the ultra-large scale of the IoT, the heterogeneous nature of applications and devices and the highly dynamic execution environment. The adoption of the microservices pattern combined with reactive systems principles may contribute to tackle some of these challenges. Therefore, the goal of this work is to propose an architecture based on reactive microservices for the development of IoT applications. The proposed architecture consists of a set of software components, tailored to meet the requirements of IoT applications. In addition, the proposal includes a software platform that materializes several of the architecture components and helps, at runtime, to meet the availability QoS requirement. We applied our proposal in a real-world scenario in the Smart Agriculture domain. The experimental results have shown that our approach improves availability of the IoT application significantly, in comparison to another study.",http://dx.doi.org/10.1007/s11761-020-00308-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-020-03488-4,Mining user–user communities for a weighted bipartite network using spark GraphFrames and Flink Gelly,The Journal of Supercomputing,10.1007/s11227-020-03488-4,Springer,2021-06-01,"Large-scale graph processing is one of the recently developed significant research areas relevant to big data analytics. Distributed graph analytics is useful to see the intuitive insights of node interactions from large-scale network data. Distributed graph computing is an upcoming area in graph data mining that explores crucial node relationships for a given graph dataset. In this paper, we propose a new method to discover top- k user–user communities for a weighted bipartite network by defining a weighted similarity measure. We extend the structural similarity metric, namely Otsuka–Ochiai coefficient , by adding weights of nodes and quantifies the similarity between distinct items of a user–item network. We propose a new method to mine top- k user–user communities based on the similarity of items using a weighted similarity measure. Further, two algorithms, namely TUCSGF, TUCFlink , are presented to mine top- k user–user communities in a distributed approach based on the strength of the item-to-item similarities. Moreover, we execute the TUCSGF algorithm using Apache Spark by utilizing the advantage of Spark GraphFrames to mine top- k user–user communities. Also, we implement the TUCFlink algorithm to mine top- k communities using Apache Flink by utilizing the functionalities of Flink Gelly. Further, we explore two real-world network applications online learning network , chain of hospitals network with various graph methods that are to be applied for both the applications. Furthermore, we systematically perform various experiments concerning execution time, memory consumption, and CPU usage of both TUCSGF, TUCFlink on three distinct datasets. The performance of TUCFLINK is far better than TUCSGF concerning computing time. Applying distributed graph analytics for various complex networks using distributed graph processing tools GraphX, GraphFrames and Gelly provides more intuitive insights about distinct types of node interactions in graph data mining.",http://dx.doi.org/10.1007/s11227-020-03488-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-021-00481-4,Hybrid intelligence in business networks,Electronic Markets,10.1007/s12525-021-00481-4,Springer,2021-06-01,,http://dx.doi.org/10.1007/s12525-021-00481-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11554-020-01003-9,Real-time chinese traffic warning signs recognition based on cascade and CNN,Journal of Real-Time Image Processing,10.1007/s11554-020-01003-9,Springer,2021-06-01,"Warning signs are of great significance to traffic safety. In this paper, a real-time recognition method for Chinese Traffic Warning Signs (CTWS) is proposed. CTWS are all triangles with yellow background, black border and black pattern. Their similarity is conducive to the localization task of object detection but adverse to the classification task of object detection. After analyzing the characteristics of these signs, real-time recognition for CTWS is carried out by employing Cascade classifier and Convolutional Neural Network (CNN). A Cascade classifier with 9 layers is trained with local binary patterns to locate the CTWS in frames. And a 10-layer CNN model is built to determine the specific category of the signs located by the Cascade classifier. We evaluate the method on CCTSDB-based dataset and GTSDB, and experiments show that the proposed method can perform accurate recognition at an average speed of 81.79fps without GPU. Since the proposed method only needs to call CNN that requires vast computing power in a small number of frames containing CTWS while performing real-time recognition, it can effectively save the valuable on-board computing resources compared with other object detection algorithms that is purely based on CNN such as YOLOv3, YOLOv3-tiny and Faster R-CNN.",http://dx.doi.org/10.1007/s11554-020-01003-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06046-y,HTwitt: a hadoop-based platform for analysis and visualization of streaming Twitter data,Neural Computing and Applications,10.1007/s00521-021-06046-y,Springer,2021-05-05,"Twitter produces a massive amount of data due to its popularity that is one of the reasons underlying big data problems. One of those problems is the classification of tweets due to use of sophisticated and complex language, which makes the current tools insufficient. We present our framework HTwitt, built on top of the Hadoop ecosystem, which consists of a MapReduce algorithm and a set of machine learning techniques embedded within a big data analytics platform to efficiently address the following problems: (1) traditional data processing techniques are inadequate to handle big data; (2) data preprocessing needs substantial manual effort; (3) domain knowledge is required before the classification; (4) semantic explanation is ignored. In this work, these challenges are overcome by using different algorithms combined with a Naïve Bayes classifier to ensure reliability and highly precise recommendations in virtualization and cloud environments. These features make HTwitt different from others in terms of having an effective and practical design for text classification in big data analytics. The main contribution of the paper is to propose a framework for building landslide early warning systems by pinpointing useful tweets and visualizing them along with the processed information. We demonstrate the results of the experiments which quantify the levels of overfitting in the training stage of the model using different sizes of real-world datasets in machine learning phases. Our results demonstrate that the proposed system provides high-quality results with a score of nearly 95% and meets the requirement of a Hadoop-based classification system.",http://dx.doi.org/10.1007/s00521-021-06046-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10916-021-01743-6,Effect of AI Explanations on Human Perceptions of Patient-Facing AI-Powered Healthcare Systems,Journal of Medical Systems,10.1007/s10916-021-01743-6,Springer,2021-05-04,"Ongoing research efforts have been examining how to utilize artificial intelligence technology to help healthcare consumers make sense of their clinical data, such as diagnostic radiology reports. How to promote the acceptance of such novel technology is a heated research topic. Recent studies highlight the importance of providing local explanations about AI prediction and model performance to help users determine whether to trust AI’s predictions. Despite some efforts, limited empirical research has been conducted to quantitatively measure how AI explanations impact healthcare consumers’ perceptions of using patient-facing, AI-powered healthcare systems. The aim of this study is to evaluate the effects of different AI explanations on people's perceptions of AI-powered healthcare system. In this work, we designed and deployed a large-scale experiment (N = 3,423) on Amazon Mechanical Turk (MTurk) to evaluate the effects of AI explanations on people's perceptions in the context of comprehending radiology reports. We created four groups based on two factors—the extent of explanations for the prediction (High vs. Low Transparency) and the model performance (Good vs. Weak AI Model)—and randomly assigned participants to one of the four conditions. Participants were instructed to classify a radiology report as describing a normal or abnormal finding, followed by completing a post-study survey to indicate their perceptions of the AI tool. We found that revealing model performance information can promote people's trust and perceived usefulness of system outputs, while providing local explanations for the rationale of a prediction can promote understandability but not necessarily trust. We also found that when model performance is low, the more information the AI system discloses, the less people would trust the system. Lastly, whether human agrees with AI predictions or not and whether the AI prediction is correct or not could also influence the effect of AI explanations. We conclude this paper by discussing implications for designing AI systems for healthcare consumers to interpret diagnostic report.",http://dx.doi.org/10.1007/s10916-021-01743-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-02102-7,Intelligent system for COVID-19 prognosis: a state-of-the-art survey,Applied Intelligence,10.1007/s10489-020-02102-7,Springer,2021-05-01,"This 21st century is notable for experiencing so many disturbances at economic, social, cultural, and political levels in the entire world. The outbreak of novel corona virus 2019 (COVID-19) has been treated as a Public Health crisis of global Concern by the World Health Organization (WHO). Various outbreak models for COVID-19 are being utilized by researchers throughout the world to get well-versed decisions and impose significant control measures. Amid the standard methods for COVID-19 worldwide epidemic prediction, easy statistical, as well as epidemiological methods have got more consideration by researchers and authorities. One main difficulty in controlling the spreading of COVID-19 is the inadequacy and lack of medical tests for detecting as well as identifying a solution. To solve this problem, a few statistical-based advances are being enhanced and turn into a partial resolution up-to some level. To deal with the challenges of the medical field, a broad range of intelligent based methods, frameworks, and equipment have been recommended by Machine Learning (ML) and Deep Learning. As ML and DL have the ability of identifying and predicting patterns in complex large datasets, they are recognized as a suitable procedure for producing effective solutions for the diagnosis of COVID-19. In this paper, a perspective research has been conducted in the applicability of intelligent systems such as ML, DL and others in solving COVID-19 related outbreak issues. The main intention behind this study is (i) to understand the importance of intelligent approaches such as ML and DL for COVID-19 pandemic, (ii) discussing the efficiency and impact of these methods in the prognosis of COVID-19, (iii) the growth in the development of type of ML and advanced ML methods for COVID-19 prognosis,(iv) analyzing the impact of data types and the nature of data along with challenges in processing the data for COVID-19,(v) to focus on some future challenges in COVID-19 prognosis to inspire the researchers for innovating and enhancing their knowledge and research on other impacted sectors due to COVID-19.",http://dx.doi.org/10.1007/s10489-020-02102-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11276-021-02614-1,Efficient autonomic and elastic resource management techniques in cloud environment: taxonomy and analysis,Wireless Networks,10.1007/s11276-021-02614-1,Springer,2021-05-01,"Resource management (RM) is a challenging task in a cloud computing environment where a large number of virtualized, heterogeneous, and distributed resources are hosted in the datacentres. The uncertainty, heterogeneity, and the dynamic nature of such resources affect the efficiency of provisioning, allocation, scheduling, and monitoring tasks of RM. The most existing RM techniques and strategies have insufficiency in handling such cloud resources dynamic behaviour. To resolve these limitations, there is a need for the design and development of intelligent and efficient autonomic RM techniques to ensure the Quality-of-Service (QoS) of cloud-based applications, satisfy the cloud user requirements, and avoid a Service-Level Agreement (SLA) violations. This paper presents a comprehensive review along with a taxonomy of the most recent existing autonomic and elastic RM techniques in a cloud environment. The taxonomy classifies the existing autonomic and elastic RM techniques into different categories based on their design, objective, function, and applications. Moreover, a comparison and qualitative analysis is provided to illustrate their strengths and weaknesses. Finally, the open issues and challenges are highlighted to help researchers in finding significant future research options.",http://dx.doi.org/10.1007/s11276-021-02614-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10551-019-04371-w,Mapping the Ethicality of Algorithmic Pricing: A Review of Dynamic and Personalized Pricing,Journal of Business Ethics,10.1007/s10551-019-04371-w,Springer,2021-05-01,"Firms increasingly deploy algorithmic pricing approaches to determine what to charge for their goods and services. Algorithmic pricing can discriminate prices both dynamically over time and personally depending on individual consumer information. Although legal, the ethicality of such approaches needs to be examined as often they trigger moral concerns and sometimes outrage. In this research paper, we provide an overview and discussion of the ethical challenges germane to algorithmic pricing. As a basis for our discussion, we perform a systematic interpretative review of 315 related articles on dynamic and personalized pricing as well as pricing algorithms in general. We then use this review to define the term algorithmic pricing and map its key elements at the micro-, meso-, and macro levels from a business and marketing ethics perspective. Thus, we can identify morally ambivalent topics that call for deeper exploration by future research.",http://dx.doi.org/10.1007/s10551-019-04371-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-020-10422-6,Phrase-level sentence patterns for estimating positive and negative emotions using Neuro-fuzzy model for information retrieval applications,Multimedia Tools and Applications,10.1007/s11042-020-10422-6,Springer,2021-05-01,"The paper proposes phrase-level emotion patterns using Neuro-Fuzzy model. At the initial stage, the emotional patterns at phrase level are obtained using POS Tags and EMOT Actifiers that results into 16 patterns. These patterns works well with the sentences having single emotion and classifies them into Positive and Negative polarities. However, it is observed that these patterns are unable to define the exact boundary between positive and negative polarities of these sentence patterns. Thus, this issue will affect the classification accuracy due to imprecise boundary between the sentences. Mixed emotions exist in long sentences with multi phrases and therefore the sentences are broken at Phrase-level. The patterns are extracted at phrase-level and converted as fuzzy rules for the classification of mixed emotion patterns. Intensity grades are calculated for the patterns based on the features of phrases and their structure in the sentence. These intensity grades classify the patterns at phrase level into Positive and Negative emotions. Based on the intensity grades, a suitable weighing mechanism is proposed for the multi phrasal sentence structure which decides the degree of Positive and Negative polarities of emotion in a sentence. Higher weighted phrasal pattern decides the Positive and Negative polarities of emotion in a sentence. Proposed approach performs well and achieves good F-Scores compared with other comparative approaches on benchmark datasets.",http://dx.doi.org/10.1007/s11042-020-10422-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11276-021-02594-2,Computational intelligence techniques for automatic detection of Wi-Fi attacks in wireless IoT networks,Wireless Networks,10.1007/s11276-021-02594-2,Springer,2021-05-01,"These days, number of smart products based on Internet-of-Things (IoT) has been increased. These products are unified via various wireless technologies like, Bluetooth, Z-wave, Wi-Fi, Zigbee, etc. While the need on the wireless networks has improved, the assaults against them throughout the time have expanded on top. In order to identify these assaults, an intrusion detection system (IDS) with a prominent precision and low identification time is required. In this work, a machine learning (ML) based wireless intrusion detection system (WIDS) for wireless networks to effectively identify assaults against them has been proposed. A ML prototype has been implemented to categorize the wireless network records into ordinary or one of the particular assault categories. The operation of an IDS is extensively enhanced when the attributes are more discriminative and delegate. Different attribute selection methods have been investigated to identify the best set of attributes for the WIDS. The proposed model is evaluated on aegean wireless intrusion dataset using various parameters like attack detection rate, detection time, precision, F-measure, etc. The experimental evaluation is carried out in the tools like, Weka, Rstudio and Anaconda Navigator Python. Finally, the experimental result shows the best performing ML algorithm with best set of reduced attributes.",http://dx.doi.org/10.1007/s11276-021-02594-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41060-020-00240-2,Data science: a game changer for science and innovation,International Journal of Data Science and Analytics,10.1007/s41060-020-00240-2,Springer,2021-05-01,"This paper shows data science’s potential for disruptive innovation in science, industry, policy, and people’s lives. We present how data science impacts science and society at large in the coming years, including ethical problems in managing human behavior data and considering the quantitative expectations of data science economic impact. We introduce concepts such as open science and e-infrastructure as useful tools for supporting ethical data science and training new generations of data scientists. Finally, this work outlines SoBigData Research Infrastructure as an easy-to-access platform for executing complex data science processes. The services proposed by SoBigData are aimed at using data science to understand the complexity of our contemporary, globally interconnected society.",http://dx.doi.org/10.1007/s41060-020-00240-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-020-09422-4,A Systematic Review of Hidden Markov Models and Their Applications,Archives of Computational Methods in Engineering,10.1007/s11831-020-09422-4,Springer,2021-05-01,"The hidden Markov models are statistical models used in many real-world applications and communities. The use of hidden Markov models has become predominant in the last decades, as evidenced by a large number of published papers. In this survey, 146 papers (101 from Journals and 45 from Conferences/Workshops) from 93 Journals and 44 Conferences/Workshops are considered. The authors evaluate the literature based on hidden Markov model variants that have been applied to various application fields. The paper represents a short but comprehensive description of research on hidden Markov model and its variants for various applications. The paper shows the significant trends in the research on hidden Markov model variants and their applications.",http://dx.doi.org/10.1007/s11831-020-09422-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10551-020-04635-w,New Moralities for New Media? Assessing the Role of Social Media in Acts of Terror and Providing Points of Deliberation for Business Ethics,Journal of Business Ethics,10.1007/s10551-020-04635-w,Springer,2021-05-01,"New media and technologies such as social media and online platforms are disrupting the way businesses are run and how society functions. This article advises that scholars consider the morality of new media as an area of investigation. While prior literature has given much attention to how social media provides benefits, how it affects society generally, and how it can be used efficiently, research on the ethical aspects of new media has received relatively less attention. In an age where matters such as violence, hate crimes, fake news, etc. are increasingly pervasive, we need to address the role of online technology in aiding or limiting such negative acts. In this regard, this article uses the canvas of a terror attack that was facilitated by online technology to bring to light pressing social and ethical issues in the use of new media. I draw upon 264 news articles focusing on the 2019 Christchurch terrorist attacks to piece together how the attack was orchestrated and focus on technology-enabled facets of the event. I stir discussion on the ethical aspects of technology with regard to online discrimination (known as online othering) and highlight business and other stakeholder responsibilities and challenges as technology continues to evolve and pervade our social lives.",http://dx.doi.org/10.1007/s10551-020-04635-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-021-00342-9,"Social media intention mining for sustainable information systems: categories, taxonomy, datasets and challenges",Complex & Intelligent Systems,10.1007/s40747-021-00342-9,Springer,2021-04-05,"Intention mining is a promising research area of data mining that aims to determine end-users’ intentions from their past activities stored in the logs, which note users’ interaction with the system. Search engines are a major source to infer users’ past searching activities to predict their intention, facilitating the vendors and manufacturers to present their products to the user in a promising manner. This area has been consistently getting pertinence with an increasing trend for online purchasing. Noticeable research work has been accomplished in this area for the last two decades. There is no such systematic literature review available that provides a comprehensive review in intension mining domain to the best of our knowledge. This article presents a systematic literature review based on 109 high-quality research papers selected after rigorous screening. The analysis reveals that there exist eight prominent categories of intention. Furthermore, a taxonomy of the approaches and techniques used for intention mining have been discussed in this article. Similarly, six important types of data sets used for this purpose have also been discussed in this work. Lastly, future challenges and research gaps have also been presented for the researchers working in this domain.",http://dx.doi.org/10.1007/s40747-021-00342-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-020-05112-2,Research on Understanding the Effect of Deep Learning on User Preferences,Arabian Journal for Science and Engineering,10.1007/s13369-020-05112-2,Springer,2021-04-01,"Recommender systems are becoming more essential than ever as the data available online is increasing manifold. The increasing data presents us with an opportunity to build complex systems that can model the user interactions more accurately and extract sophisticated features to provide recommendations with better accuracy. To construct these complex models, deep learning is emerging as one of the most powerful tools. It can process large amounts of data to learn the structure and patterns that can be exploited. It has been used in recommender systems to solve cold-start problem, better estimate the interaction functions, and extract deep feature representations, among other facets that plague the traditional recommender systems. As big data is becoming more prevalent, there is a need to use tools that can take advantage of such explosive data. An extensive study on recommender systems using deep learning has been performed in the paper. The literature review spans in-depth analysis and comparative study of the research domain. The paper exhibits a vast range of scope for efficient recommender systems in future.",http://dx.doi.org/10.1007/s13369-020-05112-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-020-00617-6,A machine learning approach for performance-oriented decision support in service-oriented architectures,Journal of Intelligent Information Systems,10.1007/s10844-020-00617-6,Springer,2021-04-01,"Enterprise IT performance can be improved by providing reactive and predictive monitoring tools that anticipate problem detection. It requires advanced approaches for creating more agile, adaptable, sustainable and intelligent information systems. Service-oriented architecture (SOA) has been used in significant performance-based approaches by information system practitioners. Organizations are interested in performance-based decision support along the layers of SOA to maintain their sustainability for service reuse. Reusability is a very important aspect of Service-based systems (SBS) to analyze service or process reuse. This helps in achieving business agility to meet changing marketplace needs. However currently, there are many challenges pertaining tothe complexities of service reuse evolution along SBS. These challenges are related to the sustainability of service behavior during its lifecycle and the limitations of existing monitoring tools. There is a need for a consolidated classified knowledge-based performance profile, analytical assessment, prediction and recommendation. Therefore, this paper provides a semantic performance-oriented decision support system (SPODSS) for SOA. SPODSS provides recommendations for suggesting service reuse during its evolution. SPODSS is supported by five building blocks. These blocks are data, semantic, traces, machine learning, and decision. SPODSS classify data, validate (analytical assessment, traces, semantic enrichment) at different time intervals and increased consumption and prediction based on consolidated results. It handles the dynamic evolution of SBS and new or changed user requirements by ontology development. Finally, SPODSS generates recommendations for atomic service, composite service, and resourceallocation provisioning. To motivate this approach, we illustrate the implementation of the proposed algorithms for all the five blocks by a business process use case and public data set repositories of shared services. Sustainability and adaptability of service-based systems areensured by handling new business requirements, dynamicity issues and ensuring performance. Performance criterion includes functional suitability, time behavior, resource utilization, and reliability in terms of availability, maturity, and risk.",http://dx.doi.org/10.1007/s10844-020-00617-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41870-020-00588-5,"Fog and edge computing: concepts, tools and focus areas",International Journal of Information Technology,10.1007/s41870-020-00588-5,Springer,2021-04-01,"Big data coupled with Internet of Things (IoT) have changed the way organisations perform business. With its panoply of sensors and smart devices, IoT generates large volumes of data that can provide meaningful insights. Cloud platforms are being widely used to perform analytics on data. With the emerging trends in fog and edge computing, data can now be processed and analysed at different layers on the network, near the source where it is generated. Not all data generated by sensors might be meaningful. Therefore, data with less value can be processed at the fog or edge layer, and discarded at source whereas data having more value are transferred to the cloud for further processing. This work highlights the main motivation for fog and edge computing with focus on related network and communication protocols. A comprehensive comparison of existing cloud, fog and edge simulators is also given in terms of parameters, configuration steps and simulation scenarios. Furthermore, several fog and edge tools are summarised and real-world use cases where these tools are being used are presented. Finally, this work provides an in-depth review of the latest fog and edge research works and proposes six main fog and edge focus areas: partitioning and offloading tasks, sustainable energy consumption, edge analytics, edge node security, edge node and data discovery, and quality of service.",http://dx.doi.org/10.1007/s41870-020-00588-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-020-09282-4,Meta-User2Vec model for addressing the user and item cold-start problem in recommender systems,User Modeling and User-Adapted Interaction,10.1007/s11257-020-09282-4,Springer,2021-04-01,"The cold-start scenario is a critical problem for recommendation systems, especially in dynamically changing domains such as online news services. In this research, we aim at addressing the cold-start situation by adapting an unsupervised neural User2Vec method to represent new users and articles in a multidimensional space. Toward this goal, we propose an extension of the Doc2Vec model that is capable of representing users with unknown history by building embeddings of their metadata labels along with item representations. We evaluate our proposed approach with respect to different parameter configurations on three real-world recommendation datasets with different characteristics. Our results show that this approach may be applied as an efficient alternative to the factorization machine-based method when the user and item metadata are used and hence can be applied in the cold-start scenario for both new users and new items. Additionally, as our solution represents the user and item labels in the same vector space, we can analyze the spatial relations among these labels to reveal latent interest features of the audience groups as well as possible data biases and disparities.",http://dx.doi.org/10.1007/s11257-020-09282-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11192-021-03868-4,Tracking developments in artificial intelligence research: constructing and applying a new search strategy,Scientometrics,10.1007/s11192-021-03868-4,Springer,2021-04-01,"Artificial intelligence, as an emerging and multidisciplinary domain of research and innovation, has attracted growing attention in recent years. Delineating the domain composition of artificial intelligence is central to profiling and tracking its development and trajectories. This paper puts forward a bibliometric definition for artificial intelligence which can be readily applied, including by researchers, managers, and policy analysts. Our approach starts with benchmark records of artificial intelligence captured by using a core keyword and specialized journal search. We then extract candidate terms from high frequency keywords of benchmark records, refine keywords and complement with the subject category “artificial intelligence”. We assess our search approach by comparing it with other three recent search strategies of artificial intelligence, using a common source of articles from the Web of Science. Using this source, we then profile patterns of growth and international diffusion of scientific research in artificial intelligence in recent years, identify top research sponsors in funding artificial intelligence and demonstrate how diverse disciplines contribute to the multidisciplinary development of artificial intelligence. We conclude with implications for search strategy development and suggestions of lines for further research.",http://dx.doi.org/10.1007/s11192-021-03868-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-019-09952-8,"Organizing Self-Organizing Systems: A Terminology, Taxonomy, and Reference Model for Entities in Cyber-Physical Production Systems",Information Systems Frontiers,10.1007/s10796-019-09952-8,Springer,2021-04-01,"Ongoing digitalization accelerates the transformation and integration of physical production and traditional computing systems into smart objects and their interconnectivity, forming the Internet of Things. In manufacturing, the cross-linking of embedded systems creates adaptive and self-organizing Cyber-Physical Production Systems (CPPSs). Owing to ever-increasing cross-linking, rapid technological advances, and multifunctionality, the complexity and structural opacity of CPPSs are rapidly increasing. The development of urgently needed modeling approaches for managing such complexity and structural opacity, however, is impeded by a lack of common understanding of CPPSs. Therefore, in this paper, we contribute to a common understanding of CPPSs by defining and classifying CPPS entities and illustrating their relations. More precisely, we present a terminology, a taxonomy, and a reference model for CPPS entities, created and evaluated using an iterative development process. Thereby, we lay the foundation for future CPPS modeling approaches that make CPPS complexity and structural opacity more manageable.",http://dx.doi.org/10.1007/s10796-019-09952-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00540-9,Creative AI Through Evolutionary Computation: Principles and Examples,SN Computer Science,10.1007/s42979-021-00540-9,Nature,2021-03-23,"The main power of artificial intelligence is not in modeling what we already know, but in creating solutions that are new. Such solutions exist in extremely large, high-dimensional, and complex search spaces. Population-based search techniques, i.e. variants of evolutionary computation, are well suited to finding them. These techniques make it possible to find creative solutions to practical problems in the real world, making creative AI through evolutionary computation the likely “next deep learning.”",http://dx.doi.org/10.1007/s42979-021-00540-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-021-00521-y,"Software-Defined Dew, Roof, Fog and Cloud (SD-DRFC) Framework for IoT Ecosystem: The Journey, Novel Framework Architecture, Simulation, and Use Cases",SN Computer Science,10.1007/s42979-021-00521-y,Nature,2021-03-22,"The Internet of Things (IoT) has become one of the most known terms in present times, reaching new levels and setting a trend in the world. Evidently, it is the future of connectivity which has turned physical objects into intelligent objects. Therefore, there has been a growing curiosity in the IoT field and this leads to the concept of IoT ecosystem. But the contemporary fragmented ecosystem of regulations, technologies, and systems slows IoT deployments. Thus, we consider multi-tiered computational infrastructure which would be feasible to provide services from the nearest possible location of end devices. To mitigate multi-tier infrastructure issues, Software-Defined Networking (SDN) steps in. The journey behind SDN-supported multi-tier computational infrastructure can be understood from this paper’s elaborate study. Next, a comparative analysis on dew, roof, fog and cloud is conducted and the impact of internet on these computing paradigms is briefly explained. Then a novel framework termed “SD-DRFC (Software-Defined Dew, Roof, Fog and Cloud computing)” is proposed for today's IoT ecosystem. The role and functionality of each tier of SD-DRFC framework are adequately explained. A use case focused on the SD-DRFC framework is then presented and simulated by utilizing iFogSim simulator. To evaluate the efficiency of the presented SD-DRFC framework, four QoS parameters (Latency, Network Usage, Cost, and Energy Consumption) are considered in this paper. When comparing the simulation results, the presented SD-DRFC framework performs much better than cloud-only implementation. The advantages and suitability of utilizing this proposed framework have been demonstrated by multiple use-cases which range from conceptual visions to existing running systems.",http://dx.doi.org/10.1007/s42979-021-00521-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-021-03979-4,A decision-analytic framework for interpretable recommendation systems with multiple input data sources: a case study for a European e-tailer,Annals of Operations Research,10.1007/s10479-021-03979-4,Springer,2021-03-12,"Recommendation systems help companies construct online personalization strategies for customers who are often overwhelmed by the abundance of product choices available. To extend existing operations research literature on recommendation systems, this article proposes a decision analytic framework for interpretable recommendation systems with multiple input data sources for e-commerce settings. The impact of multiple data sources on recommendation performance is investigated and two hybridization data fusion strategies, i.e., a posteriori weighting and input data source combination using factorization machines are benchmarked. Furthermore, a new importance score mechanism is introduced to provide insight into the input data sources’ and underlying variables’ impact on recommendation performance. The framework is empirically validated on 164,338 customers and 51,367 products across eight real-life data sets with four input data sources (product, customer, raw behavioral, and aggregated behavioral data) obtained from a large European e-commerce company. With this new decision analytic framework, e-commerce companies are able to open their recommendation system’s black box, to identify the most predictive input data sources and the best hybridization strategy for their business context.",http://dx.doi.org/10.1007/s10479-021-03979-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-021-09457-0,Forecasting the nearly unforecastable: why aren’t airline bookings adhering to the prediction algorithm?,Electronic Commerce Research,10.1007/s10660-021-09457-0,Springer,2021-03-01,"Using 27 million flight bookings for 2 years from a major international airline company, we built a Next Likely Destination model to ascertain customers’ next flight booking. The resulting model achieves an 89% predictive accuracy using historical data. A unique aspect of the model is the incorporation of self-competence, where the model defers when it cannot reasonably make a recommendation. We then compare the performance of the Next Likely Destination model in a real-life consumer study with 35,000 actual airline customers. In the user study, the model obtains a 51% predictive accuracy. What happened? The Individual Behavior Framework theory provides insights into possibly explaining this inconsistency in evaluation outcomes. Research results indicate that algorithmic approaches in competitive industries must account for shifting customer preferences, changes to the travel environment, and confounding business effects rather than relying solely on historical data.",http://dx.doi.org/10.1007/s10660-021-09457-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05085-1,Social movie recommender system based on deep autoencoder network using Twitter data,Neural Computing and Applications,10.1007/s00521-020-05085-1,Springer,2021-03-01,"Recommender systems attempt to provide effective suggestions to each user based on their interests and behaviors. These recommendations usually match the personal user preferences and assist them in the decision-making process. With the ever-expanding growth of information on the web, online education systems, e-commerce, and, eventually, the emergence of social networks, the necessity of developing such systems is unavoidable. Collaborative filtering and content-based filtering are among the most important techniques used in recommender systems. Meanwhile, with the significant advances in deep learning in recent years, the use of this technology has been widely observed in recommender systems. In this study, a hybrid social recommender system utilizing a deep autoencoder network is introduced. The proposed approach employs collaborative and content-based filtering, as well as users’ social influence. The social influence of each user is calculated based on his/her social characteristics and behaviors on Twitter. For the evaluation purpose, the required datasets have been collected from MovieTweetings and Open Movie Database. The evaluation results show that the accuracy and effectiveness of the proposed approach have been improved compared to the other state-of-the-art methods.",http://dx.doi.org/10.1007/s00521-020-05085-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-021-00866-7,Semi-supervised collaborative filtering ensemble,World Wide Web,10.1007/s11280-021-00866-7,Springer,2021-03-01,"Collaborative filtering (CF) plays a central role in recommender systems, but often suffers from the data sparsity issue that dramatically degrades the recommendation performance. In this paper, we propose a Semi-Supervised Ensemble Filtering (SSEF) method to improve the recommendation performance by assembling three popular CF techniques in a co-training framework. Concretely, SSEF first initializes three weak predictors with labeled examples by three different CF algorithms independently. Two predictors generated by neighborhood methods are then merged, along with the remaining one generated by latent factor model, serve as two base recommenders, each of which labels the unlabeled examples for the other recommender during the co-training process. To exploit unlabeled data safely, the labeling confidence is estimated by validating the influence of the pseudo-labeled examples on the labeled ones. The final prediction is made by blending the outputs from the three predictors enhanced with unlabeled data. Extensive experiments on three public benchmarks demonstrate the effectiveness of the proposed SSEF by comparing to a number of state-of-the-art CF techniques, including semi-supervised, ensemble, and side-information based solutions.",http://dx.doi.org/10.1007/s11280-021-00866-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00766-020-00329-x,A retrospective on Telos as a metamodeling language for requirements engineering,Requirements Engineering,10.1007/s00766-020-00329-x,Springer,2021-03-01,"Telos is a conceptual modeling language intended to capture software knowledge, such as software system requirements, domain knowledge, architectures, design decisions and more. To accomplish this, Telos was designed to be extensible in the sense that the concepts used to capture software knowledge can be defined in the language itself, instead of being built-in. This extensibility is accomplished through powerful metamodeling features, which proved very useful for interrelating heterogeneous models from requirements, model-driven software engineering, data integration, ontology engineering, cultural informatics and education. We trace the evolution of ideas and research results in the Telos project from its origins in the late eighties. Our account looks at the semantics of Telos, its various implementations and its applications. We also recount related research by other groups and the cross-influences of ideas thereof. We conclude with lessons learnt.",http://dx.doi.org/10.1007/s00766-020-00329-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00371-020-01818-4,Multi-level and multi-perspective visual correlation analysis between general courses and program courses,The Visual Computer,10.1007/s00371-020-01818-4,Springer,2021-03-01,"Exploring the potential impact of important general courses on program-specific courses in universities can help to improve the entire teaching and learning process for an academic major. However, the large number of courses and multiple factors affecting students’ course grades makes it difficult to reveal and analyze the complicated relationship between the two types of courses only from a single perspective or at a single level. Thence, this paper starts with analysis of historical course grades data within an undergraduate program and then presents an interactive visual analytic system, MVCAS, which is designed to demonstrate and explore the various correlations between these two types of courses at different levels and from different perspectives. The major contributions of this work include: (1) a multi-angle preprocessing of course grades data, including decomposition, extraction and conversion; (2) multiple coordinated analysis views which make it possible to effectively explore the overall, categorical and pairwise course correlations and further link courses with students, instructors and semesters together; and (3) a top-down correlation analysis process for general courses and program ones. The effectiveness and usefulness of MVCAS have been preliminarily demonstrated through a case study, in which the field experts use this tool to investigate different levels of correlations between the focused mathematics and program-specific courses in a computer science major comprehensively.",http://dx.doi.org/10.1007/s00371-020-01818-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40747-020-00212-w,Artificial intelligence in recommender systems,Complex & Intelligent Systems,10.1007/s40747-020-00212-w,Springer,2021-02-01,"Recommender systems provide personalized service support to users by learning their previous behaviors and predicting their current preferences for particular products. Artificial intelligence (AI), particularly computational intelligence and machine learning methods and algorithms, has been naturally applied in the development of recommender systems to improve prediction accuracy and solve data sparsity and cold start problems. This position paper systematically discusses the basic methodologies and prevailing techniques in recommender systems and how AI can effectively improve the technological development and application of recommender systems. The paper not only reviews cutting-edge theoretical and practical contributions, but also identifies current research issues and indicates new research directions. It carefully surveys various issues related to recommender systems that use AI, and also reviews the improvements made to these systems through the use of such AI approaches as fuzzy techniques, transfer learning, genetic algorithms, evolutionary algorithms, neural networks and deep learning, and active learning. The observations in this paper will directly support researchers and professionals to better understand current developments and new directions in the field of recommender systems using AI.",http://dx.doi.org/10.1007/s40747-020-00212-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-021-00722-6,Harnessing user’s social influence and IoT data for personalized event recommendation in event-based social networks,Social Network Analysis and Mining,10.1007/s13278-021-00722-6,Springer,2021-01-27,"With the popularization of Internet, newly emerged event-based social networks (EBSNs) have experienced recognition among people for planning, scheduling, and communicating social events. Due to plethora of events occurring over EBSNs and varying user interests and preferences with time, finding appropriate events to attend has become an important challenge in EBSNs. Accurate event recommendation will improve relevance of ESBNs to participants and event organizers. EBSNs have recognized the importance of recommender systems and are actively using different types of recommendation techniques to make suitable suggestions to participants and organizers of events. In this paper, a novel event recommendation system (i.e., IoTCFR- IoT data and collaborative filtering-based recommendation) is proposed. In order to suggest an event where the chance of user’s participation is high, the proposed approach combines IoT data, collaborative filtering (CF) approach, and social influence. Initially, the prediction score for both IoT-based parameters and CF based on social influencers is calculated for each candidate event. Then, the final event with highest prediction score is presented to the user. Furthermore, in order to verify the accuracy of proposed system, several experiments on real-world datasets were conducted. The results clearly indicate that recommendation quality of IoTCFR system is better, when compared to its variants and other baseline methods.",http://dx.doi.org/10.1007/s13278-021-00722-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43546-020-00027-4,Understanding the dynamics emerging from infodemics: a call to action for interdisciplinary research,SN Business & Economics,10.1007/s43546-020-00027-4,Nature,2021-01-11,"Research on infodemics, i.e., the rapid spread of (mis)information related to a hazardous event, such as the COVID-19 pandemic, requires integrating a multiplicity of scientific disciplines. The dynamics emerging from infodemics have the potential to generate complex behavioral patterns. To react appropriately, it is of ultimate importance for the fields of Business and Economics to understand these dynamics. In the short run, they might lead to an adaptation in household spending or to a shift in buying behavior towards online providers. In the long run, changes in investments, consumer behavior, and markets are to be expected. We argue that the dynamics emerge from complex interactions among multiple factors, such as information and misinformation accessible to individuals and the formation and revision of beliefs. (Mis)information accessible to individuals is, amongst others, affected by algorithms specifically designed to provide personalized information, while automated fact-checking algorithms can help reduce the amount of circulating misinformation. The formation and revision of individual (and probably false) beliefs and individual fact-checking and interpretation of information are heavily affected by linguistic patterns inherent to information during pandemics and infodemics and further factors, such as affect, intuition, and motives. We argue that, to get a deep(er) understanding of the dynamics emerging from infodemics, the fields of Business and Economics should integrate the perspectives of Computer Science and Information Systems, (Computational) Linguistics, and Cognitive Science into the wider context of economic systems (e.g., organizations, markets or industries) and propose a way to do so. As research on infodemics is a strongly interdisciplinary field and the integration of the above-mentioned disciplines is a first step towards a holistic approach, we conclude with a call to action which should encourage researchers to collaborate across scientific disciplines and unfold collective creativity, which will substantially advance research on infodemics.",http://dx.doi.org/10.1007/s43546-020-00027-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05667-z,HeteGraph: graph learning in recommender systems via graph convolutional networks,Neural Computing and Applications,10.1007/s00521-020-05667-z,Springer,2021-01-08,"With the explosive growth of online information, many recommendation methods have been proposed. This research direction is boosted with deep learning architectures, especially the recently proposed graph convolutional networks (GCNs). GCNs have shown tremendous potential in graph embedding learning thanks to its inductive inference property. However, most of the existing GCN-based methods focus on solving tasks in the homogeneous graph settings, and none of them considers heterogeneous graph settings. In this paper, we bridge the gap by developing a novel framework called HeteGraph based on the GCN principles. HeteGraph can handle heterogeneous graphs in the recommender systems. Specifically, we propose a sampling technique and a graph convolutional operation to learn high-quality graph’s node embeddings, which differs from the traditional GCN approaches where a full graph adjacency matrix is needed for the embedding learning. We design two models based on the HeteGraph framework to evaluate two important recommendation tasks, namely item rating prediction and diversified item recommendations . Extensive experiments show the encouraging performance of HeteGraph on the first task and the state-of-the-art performance on the second task.",http://dx.doi.org/10.1007/s00521-020-05667-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-45009-0_75,Artificial Intelligence and Machine Learning in Global Healthcare,Handbook of Global Health,10.1007/978-3-030-45009-0_75,Springer,2021-01-01,"Although medicine has been receptive to the benefits of machine learning and artificial intelligence (AI), it has only recently started to adopt this rapidly evolving, disruptive technology, particularly when compared to finance, entertainment, and transport sectors. Machine learning enables the detection of hidden connections and patterns, including outcomes prediction. Data is critical for the development of intelligent models, which harness the potential to improve and redefine disease self-management, treatment, and wellness pathways. The consequences of digital health democratization have significant health and ethical impact. This chapter provides an introduction to machine learning and AI and the development of intelligent healthcare systems. It explores applications of AI in healthcare and how the ubiquity of smartphones and Internet of Things (IoT) has accelerated the global shift from volume-based to value-based healthcare. This chapter will highlight key challenges within machine learning, evaluate machine learning projects, and share examples of best practice healthcare AI. Finally, it will review the ethical concerns surrounding machine learning, including how machines affect human behavior, data ownership, bias, unintended consequences, and the advances that have been made to support the global shift toward value-based population health.",http://dx.doi.org/10.1007/978-3-030-45009-0_75,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-74896-8_2,Phase I: CSDS as an Emerging Profession—Diagnostic Literature Analysis,Cybersecurity Data Science,10.1007/978-3-030-74896-8_2,Springer,2021-01-01,"Due to the nature of cybersecurity data science (CSDS) as a novel field emerging in the midst of rapid technological change, there is a gap in CSDS-focused organizational research. Challenges operationalizing CSDS solutions lead to a call for an increased theoretical focus on organizational problem-solving research. To address this gap, CSDS fits the profile of an organizational problem that is “relatively new or fairly complex,” necessitating an effort to “clarify the relevant background and the reasons for the problem” (Doorewaard and Verschuren 2010).",http://dx.doi.org/10.1007/978-3-030-74896-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-74896-8_4,Phase III: CSDS Gap-Prescriptions—Design Science Problem-Solving,Cybersecurity Data Science,10.1007/978-3-030-74896-8_4,Springer,2021-01-01,"As a capstone to this research inquiry, the final phase frames and advocates design-derived gap-prescriptions. CSDS has thus far been systematically explored through triangulated diagnostic methods as an emerging practitioner discipline. In the preceding phases, practice-oriented diagnostic research has been undertaken, encompassing background analysis ( Phase I ), opinion research ( Phase II ), and gap analysis ( Phase II ). Per guidance from Doorewaard and Verschuren (2010), a design approach is a natural accompaniment to conclude diagnostic analysis in problem-solving research.",http://dx.doi.org/10.1007/978-3-030-74896-8_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88132-0_3,Automated Machine Learning for Multimedia,Automated Machine Learning and Meta-Learning for Multimedia,10.1007/978-3-030-88132-0_3,Springer,2021-01-01,"The term Multimedia has been taking on different meanings from its first advent in 1960s until today’s common usage which refers multimedia to “an electronically delivered combination of media including videos, still images, audios, and texts in such a way that can be accessed interactively”.",http://dx.doi.org/10.1007/978-3-030-88132-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75871-4_8,Platforms for Banking 5.0,Banking 5.0,10.1007/978-3-030-75871-4_8,Springer,2021-01-01,"Banking 5.0 platforms are strategic components that support organizational efficiency, effectiveness, and profitability. They support the creation of new business models, products, and services. Innovative digital platforms in banking 5.0 yield several benefits. They support daily banking and administrative tasks, aid in making complex decisions, and help in managing processes. The platforms’ real goal is to free banking organizations from operational tasks and support their focus on strategic decisions and activities. The leading platforms based on banking 5.0 are artificial intelligence, with its essential components of big data analytics, cognitive solutions, and Robotic process automation (RPA). These platforms can play crucial roles in the banking 5.0 transformation. To implement banking 5.0, it is necessary to digitize banking processes heavily. There are challenges. The chapter analyzes such problems in legacy systems, current cultures, procedures, processes, abilities, and capabilities.",http://dx.doi.org/10.1007/978-3-030-75871-4_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-658-33721-6_7,Data Science and Revenue Management,Airline Revenue Management,10.1007/978-3-658-33721-6_7,Springer,2021-01-01,“Being data-driven” has been touted by management consultants and the business press as a cure-all for business challenges for several years now. But what exactly does it mean? Any modern manager has access to a plethora of reports and dashboards that they happily use to point out their performance or the improvement needs of others.,http://dx.doi.org/10.1007/978-3-658-33721-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-33-6400-4_4,Big Data Classification: Applications and Challenges,Artificial Intelligence and IoT,10.1007/978-981-33-6400-4_4,Springer,2021-01-01,"In the era of Big Data, a massive amount of data is generated and collected, continually, from various sources. To use these data for their optimum value, i.e. to uncover correlations, hidden patterns and other valuable insights, they need to be processed methodically. Classification is an essential aspect of that. Data classification is a process of categorizing data sets by features. It is crucial for knowledge discovery and intelligent decision-making. This chapter provides a comprehensive overview of applications and challenges of Big Data classification. To begin with, the potentials and problems of Big Data are meticulously discussed. Along with mentioning the basics of Big Data classification, several real-world application areas of Big Data classification, including health care, user data analysis, network traffic analysis, etc., are elaborately reviewed. The challenges in Big Data classifications are identified, explicated and surveyed with pertinent details.",http://dx.doi.org/10.1007/978-981-33-6400-4_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-58426-9_8,Platforms for Insurance 4.0,Insurance 4.0,10.1007/978-3-030-58426-9_8,Springer,2021-01-01,"Insurance 4.0 platforms are strategic components to support organizational efficiency, effectiveness, profitability, and to create new business models, products, and services. The use of innovative digital platforms in insurance 4.0 can yield several benefits. They support the daily business and administrative tasks, aid to take complex decision-making, and help in managing processes. The real objective of the platforms is to free insurance organizations from operational tasks and support their focus on strategic decisions and activities. The leading platforms at the basis of insurance 4.0 are the internet of things, with black boxes and similar, the cognitive insurance, with its essential components of big data analytics, artificial intelligence, and RPA—robotic process automation. Blockchain, smart contracts, and mobile Technologies network mobility, mobile can play essential roles in the insurance 4.0 transformation. This chapter confirms that to implement insurance 4.0, it is necessary to digitize insurance processes heavily. There might be challenges in this respect in current cultures, procedures, processes, capacities, and capabilities.",http://dx.doi.org/10.1007/978-3-030-58426-9_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1967-0_12,Graph Computing System and Application Based on Large-Scale Information Network,Space Information Network,10.1007/978-981-16-1967-0_12,Springer,2021-01-01,"Graph computing is more and more widely used in various fields such as spatial information network and social network. However, the existing graph computing systems have some problems like complex programming and steep learning curve. This paper introduces GRAPE, a distributed large-scale GRAPh Engine, which has the unique features of solid theoretical guarantee, ease of use, auto-parallelization and high performance. The paper also introduces several typical scenarios of graph computing, including entity resolution, link prediction, community detection and graph mining of spatial information network. In these scenarios, various problems have been encountered in the existing systems, such as failure to compute over large-scale data due to the high computation complexity, loss of accuracy due to the cropping of original data and too long execution time. In the face of these challenges, GRAPE is easy to support these computing scenarios with a series of technical improvements. With the deployment of GRAPE in Alibaba, both effectiveness and efficiency of graph computing have been greatly improved.",http://dx.doi.org/10.1007/978-981-16-1967-0_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7527-3_69,An Empirical Study on Usability and Security of E-Commerce Websites,Research in Intelligent and Computing in Engineering,10.1007/978-981-15-7527-3_69,Springer,2021-01-01,"Advancement of the World Wide Web and technological improvement has made a huge revolution in the Internet world, especially in the commercial sector. Although the usage of the Internet for commercial purposes was introduced in the 1994, but the prone to use websites for e-commerce has been increased gradually. Nowadays, websites are considered as an integral part of e-commerce. However, the success rate depends on certain quality issues. In this paper, we mainly focus on two important quality factors namely usability and security, which are considered as the backbone of e-commerce websites. This paper identifies out various attributes for estimating the usability and security aspects of e-commerce websites. A comparison study has been conducted on the various usability and evaluation models which help in the identification of an efficient model for assessing and evaluating the usability and security of e-commerce websites.",http://dx.doi.org/10.1007/978-981-15-7527-3_69,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75490-7_2,Deep Reinforcement Learning: A New Frontier in Computer Vision Research,"Vision, Sensing and Analytics: Integrative Approaches",10.1007/978-3-030-75490-7_2,Springer,2021-01-01,"Computer vision has advanced so far that machines now can think and see as we humans do. Especially deep learning has raised the bar of excellence in computer vision. However, the recent emergence of deep reinforcement learning is threatening to soar even greater heights as it combines deep neural networks with reinforcement learning along with numerous added advantages over both. This, being a relatively recent technique, has not yet seen many works, and so its true potential is yet to be unveiled. Thus, this chapter focuses on shedding light on the fundamentals of deep reinforcement learning, starting with the preliminaries followed by the theory and basic algorithms and some of its variations, namely, attention aware deep reinforcement learning, deep progressive reinforcement learning, and multi-agent deep reinforcement learning. This chapter also discusses some existing deep reinforcement learning works regarding computer vision such as image processing and understanding, video captioning and summarization, visual search and tracking, action detection, recognition and prediction, and robotics. This work further aims to elucidate the existing challenges and research prospects of deep reinforcement learning in computer vision. This chapter might be considered a starting point for aspiring researchers looking to apply deep reinforcement learning in computer vision to reach the pinnacle of performance in the field by tapping into the immense potential that deep reinforcement learning is showing.",http://dx.doi.org/10.1007/978-3-030-75490-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65854-0_5,Hidden Feedback Loops in Machine Learning Systems: A Simulation Model and Preliminary Results,Software Quality: Future Perspectives on Software Engineering Quality,10.1007/978-3-030-65854-0_5,Springer,2021-01-01,"In this concept paper, we explore some of the aspects of quality of continuous learning artificial intelligence systems as they interact with and influence their environment. We study an important problem of implicit feedback loops that occurs in recommendation systems, web bulletins and price estimation systems. We demonstrate how feedback loops intervene with user behavior on an exemplary housing prices prediction system. Based on a preliminary model, we highlight sufficient existence conditions when such feedback loops arise and discuss possible solution approaches.",http://dx.doi.org/10.1007/978-3-030-65854-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86523-8_16,Hyper-parameter Optimization for Latent Spaces,Machine Learning and Knowledge Discovery in Databases. Research Track,10.1007/978-3-030-86523-8_16,Springer,2021-01-01,"We present an online optimization method for time-evolving data streams that can automatically adapt the hyper-parameters of an embedding model. More specifically, we employ the Nelder-Mead algorithm, which uses a set of heuristics to produce and exploit several potentially good configurations, from which the best one is selected and deployed. This step is repeated whenever the distribution of the data is changing. We evaluate our approach on streams of real-world as well as synthetic data, where the latter is generated in such way that its characteristics change over time (concept drift). Overall, we achieve good performance in terms of accuracy compared to state-of-the-art AutoML techniques.",http://dx.doi.org/10.1007/978-3-030-86523-8_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_6,A Holistic Framework for AI Systems in Industrial Applications,Innovation Through Information Systems,10.1007/978-3-030-86797-3_6,Springer,2021-01-01,"Although several promising use cases for artificial intelligence (AI) for manufacturing companies have been identified, these are not yet widely used. Existing literature covers a variety of frameworks, methods and processes related to AI systems. However, the application of AI systems in manufacturing companies lacks a uniform understanding of components and functionalities as well as a structured process that supports developers and project managers in planning, implementing, and optimizing AI systems. To close this gap, we develop a generic conceptual model of an AI system for the application in manufacturing systems and a four-phase model to guide developers and project managers through the realization of AI systems.",http://dx.doi.org/10.1007/978-3-030-86797-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-1358-9_11,Efficient Text Autocompletion for Online Services,Frontiers of Digital Transformation,10.1007/978-981-15-1358-9_11,Springer,2021-01-01,"Query autocompletion (QAC) is an important interactive feature that assists users in formulating queries and saving keystrokes. Due to the convenience it brings to users, it has been adopted in many applications, such as Web search engines, integrated development environments (IDEs), and mobile devices. In my previous works, I studied several fundamental problems of QAC and developed novel QAC techniques that deliver high-quality suggestions in an efficient way. The remarkable contribution is the proposal of a novel QAC paradigm through which users may abbreviate keywords by prefixes and do not have to explicitly separate them. Another contribution is to efficiently solve geographical location constraints such as considering Euclidean distances to different locations when completing text queries. Based on the above studies, an overview of novel QAC methods across different application domains is provided in this chapter. By creating a data circulation on various QAC applications, I believe that the proposed methods are practical and easy to use in many real-world scenarios. I illustrate the realized data circulation in Sect.  2 . Contributions to the society are presented in Sect.  3 .",http://dx.doi.org/10.1007/978-981-15-1358-9_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-52067-0_19,"Data Science and AI in IoT Based Smart Healthcare: Issues, Challenges and Case Study",Enabling AI Applications in Data Science,10.1007/978-3-030-52067-0_19,Springer,2021-01-01,"IoT based applications such as smart healthcare, transportation, surveillance etc. lead to more convenient and healthy lifestyle to human being nowadays. Biosensors sense health vitals and send acquired data to cloud server for processing. These huge sensory health data need to be processed and analyzed efficiently and intelligently for knowledge extraction with high accuracy and low resource requirements. Here comes the inevitable role of artificial intelligence, machine learning and deep learning. Here a comprehensive study and analysis on application of IoT and AI in smart healthcare has been done to present recent developments in this emerging research domain supported with few case studies. Issues and challenges in dealing with big health data applying data science and data analytics have also been highlighted. Case studies help to get insight in recent developments on drug discovery, chronic disease prediction such as heart disease, kidney related ailments etc. applying ML, DL.",http://dx.doi.org/10.1007/978-3-030-52067-0_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-67667-4_13,Calibrating User Response Predictions in Online Advertising,Machine Learning and Knowledge Discovery in Databases: Applied Data Science Track,10.1007/978-3-030-67667-4_13,Springer,2021-01-01,"Predicting user response probability such as click-through rate (CTR) and conversion rate (CVR) accurately is essential to online advertising systems. To obtain accurate probability, calibration is usually used to transform predicted probabilities to posterior probabilities. Due to the sparsity and latency of the user response behaviors such as clicks and conversions, traditional calibration methods may not work well in real-world online advertising systems. In this paper, we present a comprehensive calibration solution for online advertising. More specifically, we propose a calibration algorithm to exploit implicit properties of predicted probabilities to reduce negative impacts of the data sparsity problem. To deal with the latency problem in calibrating delayed responses, e.g., conversions, we propose an estimation model to leverage post-click information to approximate the real delayed user responses. We also notice that existing metrics are insufficient to evaluate the calibration performance. Therefore, we present new metrics to measure the calibration performance. Experimental evaluations on both real-world datasets and online advertising systems show that our proposed solution outperforms existing calibration methods and brings significant business values.",http://dx.doi.org/10.1007/978-3-030-67667-4_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8335-3_51,Detecting Organic Audience Involvement on Social Media Platforms for Better Influencer Marketing and Trust-Based E-Commerce Experience,Data Analytics and Management,10.1007/978-981-15-8335-3_51,Springer,2021-01-01,"This study addresses a major problem of online advertisement. Usage of Internet and specifically social media platforms for promoting businesses and services has seen a drastic increase in the recent times. Influencer-based marketing is a major area for promotion. With its major dominance, comes its downsides. This influencer-based model alternatively being referred to as influencer marketing has a major drawback which concerns one of the foremost aspects of digital media, organic and inorganic results. Many of the social media platforms involve inorganic audience which includes fake popularity for the concerned account. This heavily impacts the advertisements business being run on social media and other platforms. This could lead to wrong audience impact involving losses for the business as well as the customers being targeted. In this study, a trust-based model is designed in which the social media platform, Instagram, is checked for fake audience involvement and their consecutive detection for better future impressions. For the detection of inorganic audience involvement, firstly, a study is done regarding the parameters that could assist the detection process. These parameters are further used to generate the nodes of a decision tree. Second of all, the dataset is prepared for the detection process. Machine learning is used to make the predictions on the dataset as with minimum human intervention, it can help automate the entire process and make it much faster than manual detection. Decision tree is then applied to the dataset for building a prediction based model, which is used to predict the occurrence of fake accounts in test dataset. This is followed by the concluding of the result in which prediction has been done. Also, the accuracy of the same has been checked in the conclusion with the help of confusion matrix which turns out to have a good accuracy, thus, successfully concluding the study.",http://dx.doi.org/10.1007/978-981-15-8335-3_51,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72080-3_20,The Usage of Artificial Intelligence in Digital Marketing: A Review,"Applications of Artificial Intelligence in Business, Education and Healthcare",10.1007/978-3-030-72080-3_20,Springer,2021-01-01,"This study aims to investigate the correlation between Artificial Intelligence and digital Marketing Business and to identify the most important applications of artificial Intelligence used in the field of digital marketing by focusing on the fields of marketing and Artificial Intelligence (AI) that meet in the systems that aid in areas such as market forecasting, process automation, and decision-making, as well as increasing the efficiency of tasks that humans usually perform. The Science behind these systems can be explained by neural networks and expert systems, which are computer programs that process inputs and provide valuable outputs for marketers. The study indicated that (AI) systems also stemming from social computing technology can be applied to understand social networks on the Internet. Data mining techniques can be used to analyze different types of social networks. This analysis helps the marketer identify the influencing actors or nodes within the networks. It is the information that can be applied to take a social, cultural marketing approach.",http://dx.doi.org/10.1007/978-3-030-72080-3_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85447-8_23,Gender Bias in AI: Implications for Managerial Practices,Responsible AI and Analytics for an Ethical and Inclusive Digitized Society,10.1007/978-3-030-85447-8_23,Springer,2021-01-01,"Artificial intelligence (AI) applications are widely employed nowadays in almost every industry impacting individuals and society. As many important decisions are now being automated by various AI applications, fairness is fast becoming a vital concern in AI. Moreover, the organizational applications of AI-enabled decision systems have exacerbated this problem by amplifying the pre-existing societal bias and creating new types of biases. Interestingly, the related literature and industry press suggest that AI systems are often biased towards gender. Specifically, AI hiring tools are often biased towards women. Therefore, it is an increasing concern to reconsider the organizational managerial practices for AI-enabled decision systems to bring fairness in decision making. Additionally, organizations should develop fair, ethical internal structures and corporate strategies and governance to manage the gender imbalance in AI recruitment process. Thus, by systematically reviewing and synthesizing the literature, this paper presents a comprehensive overview of the managerial practices taken in relation to gender bias in AI. Our findings indicate that managerial practices include: better fairness governance practices, continuous training on fairness and ethics for all stakeholders, collaborative organizational learning on fairness & demographic characteristics, interdisciplinary approach & understanding of AI ethical principles, Workplace diversity in managerial roles, designing strategies for incorporating algorithmic transparency and accountability & ensuring human in the loop. In this paper, we aim to contribute to the emerging IS literature on AI by presenting a consolidated picture and understanding of this phenomenon. Based on our findings, we indicate direction for future research in IS for the better development and use of AI systems.",http://dx.doi.org/10.1007/978-3-030-85447-8_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81907-1_8,The Ethics of Algorithms: Key Problems and Solutions,"Ethics, Governance, and Policies in Artificial Intelligence",10.1007/978-3-030-81907-1_8,Springer,2021-01-01,"Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2). https://doi.org/10.1177/2053951716679679 , 2016). The golas are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms.",http://dx.doi.org/10.1007/978-3-030-81907-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61641-0_9,Reasoning and Simulation of Mental Attitudes of a Customer,Artificial Intelligence for Customer Relationship Management,10.1007/978-3-030-61641-0_9,Springer,2021-01-01,"In this chapter, we employ logic programming to simulate the mental world. A Theory of Mind engine is introduced that takes an initial mental state and produces the consecutive mental states as plausible to a real-world scenario as possible. We simulate a multiagent decision-making environment taking into account intentions, knowledge and beliefs of itself and others. The simulation results are evaluated with respect to precision, completeness and complexity. Metaprogramming techniques of introspection is outlined for putting a CRM component in “customers’ shoes,” better predicting how she would think and act. We conclude that the Theory of Mind engine is adequate to support a broad range of CRM tasks requiring simulation of human mental attitudes.",http://dx.doi.org/10.1007/978-3-030-61641-0_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64254-9_6,AI Risk Management,Economics and Law of Artificial Intelligence,10.1007/978-3-030-64254-9_6,Springer,2021-01-01,"Artificial intelligence has become a new engine for economic growth and as the central driving force of the new round of industrial reforms, artificial intelligence will further discharge the energy accumulated from prior technological revolutions and industrial alterations by generating new powerful engines to modernize economic activities such as production, distribution, exchange, and consumption. The decentralized nature of blockchain generates, the new concept of a token economy in which the community’s revenue is allocated to the actual content producers and service users who generate value. In addition, Blockchain is a key technology that enables new protocols for the establishment of a token economy in the future, leading to a new economic paradigm. Digital technologies are now turning the world upside down and so an ongoing series of technological developments have transformed economic and social life. The integration of AI agents into society has led to a different manner in which persons interact with each other, along with a new kind of direct interaction presented with AI agents, which are increasingly posed in society.",http://dx.doi.org/10.1007/978-3-030-64254-9_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75521-8_1,Introduction,Explainable Artificial Intelligence Based on Neuro-Fuzzy Modeling with Applications in Finance,10.1007/978-3-030-75521-8_1,Springer,2021-01-01,"This introduction refers to the title of the book. In the first section, the goal of the book is depicted. The second section outlines the most crucial aspect, i.e., explainability. The third tries to answer what is a recommender system, presenting different types of recommenders. Next, the interpretability of recommenders is discussed within the Explainable Artificial Intelligence, including the neuro-fuzzy approach. Finally, the content and main results of the book are described. This chapter can also be treated as a literature review of a few narrow research areas—Explainable Artificial Intelligence, Interpretable Machine Learning and Recommender Systems.",http://dx.doi.org/10.1007/978-3-030-75521-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72929-5_1,Computational Management—An Overview,Computational Management,10.1007/978-3-030-72929-5_1,Springer,2021-01-01,"Nowadays, almost all businesses whether small, medium or large are under the tremendous pressure of global competition. With the emergence of internet and e-commerce, geographical barriers have been almost removed, thus, making customers more demanding. With global competitions, customers are showered with alternative options for even the tiniest product. They can no more be controlled by the take it or leave it approach. They demand highest quality product at lowest possible rate and even within the minimum possible time. Agility and flexibility have become the only survival strategies. Business managers in such scenarios are putting all their effort in resolving market-driven issues by identifying them and responding in a timely manner to convert them into opportunities. Amidst these competitions and demand uncertainties, depending on intuition based decision making approach to face new challenges may lead to destructive consequences. Therefore, in the data and technology driven era, business managers must shift their focus to facts and evidences for making faster and rewarding decisions. In such a scenario, deploying Computational Intelligence techniques is providing promising insights to support business managers in better decision making thus gaining competitive advantages over others. Successful organizations are now making planned efforts in adopting computational intelligence techniques to solve complex business problems in practice. Some of the complex application areas where employing computational intelligence has already been successful include customer relationship management, identifying up-selling and cross-selling opportunities, increasing conversion rate by targeting potential customers, social media analytics, risk mitigation, fraud detection, sentiment analysis, targeting marketing campaigns, product pricing, personnel recruiting, employee retention and financial planning etc. In today’s fast changing uncertain business environment hardly any facet of business is remaining untouched by computational intelligence. Hence, this chapter makes an attempt to discuss the application of computational intelligence techniques in business management. Various underlying principles of computational intelligence are discussed followed by the computational aspects and selective applications.",http://dx.doi.org/10.1007/978-3-030-72929-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-78985-5_5,When Philanthropy Meets Data Science: A Framework for Governance to Achieve Data-Driven Decision-Making for Public Good,Data Science for Social Good,10.1007/978-3-030-78985-5_5,Springer,2021-01-01,"Philanthropy means love for humanity . Today, the term refers to the economic and social sector consisting of private initiatives (in the form of foundations, donations, non-profit organizations and so forth) who devote resources for the public good, that is, to improve the welfare of others in an altruistic way.",http://dx.doi.org/10.1007/978-3-030-78985-5_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-83014-4_7,Catalog Integration of Heterogeneous and Volatile Product Data,Data Management Technologies and Applications,10.1007/978-3-030-83014-4_7,Springer,2021-01-01,"The integration of frequently changing, volatile product data from different manufacturers into a single catalog is a significant challenge for small and medium-sized e-commerce companies. They rely on timely integrating product data to present them aggregated in an online shop without knowing format specifications, concept understanding of manufacturers, and data quality. Furthermore, format, concepts, and data quality may change at any time. Consequently, integrating product catalogs into a single standardized catalog is often a laborious manual task. Current strategies to streamline or automate catalog integration use techniques based on machine learning, word vectorization, or semantic similarity. However, most approaches struggle with low-quality or real-world data. We propose Attribute Label Ranking (ALR) as a recommendation engine to simplify the integration process of previously unknown, proprietary tabular format into a standardized catalog for practitioners. We evaluate ALR by focusing on the impact of different neural network architectures, language features, and semantic similarity. Additionally, we consider metrics for industrial application and present the impact of ALR in production and its limitations.",http://dx.doi.org/10.1007/978-3-030-83014-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-72113-8_2,An E-Commerce Dataset in French for Multi-modal Product Categorization and Cross-Modal Retrieval,Advances in Information Retrieval,10.1007/978-3-030-72113-8_2,Springer,2021-01-01,"A multi-modal dataset of ninety nine thousand product listings are made available from the production catalog of Rakuten France, a major e-commerce platform. Each product in the catalog data contains a textual title, a (possibly empty) textual description and an associated image. The dataset has been released as part of a data challenge hosted by the SIGIR ECom’20 Workshop. Two tasks are proposed, namely a principal large-scale multi-modal classification task and a subsidiary cross-modal retrieval task. This real world dataset contains around 85K products and their corresponding product type categories that are released as training data and around 9.5K and 4.5K products are released as held-out test sets for the multi-modal classification and cross-modal retrieval tasks respectively. The evaluation is run in two phases to measure system performance, first on 10% of the test data, and then on the rest 90% of the test data. The different systems are evaluated using macro-F1 score for the multi-modal classification task and recall@1 for the cross-modal retrieval task. Additionally, a robust baseline system for the multi-modal classification task is proposed. The top performance obtained at the end of the second phase is $$91.44\%$$ 91.44 % macro-F1 and $$34.28\%$$ 34.28 % recall@1 for the two tasks respectively.",http://dx.doi.org/10.1007/978-3-030-72113-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86486-6_24,Dynamic Heterogeneous Graph Embedding via Heterogeneous Hawkes Process,Machine Learning and Knowledge Discovery in Databases. Research Track,10.1007/978-3-030-86486-6_24,Springer,2021-01-01,"Graph embedding, aiming to learn low-dimensional representations of nodes while preserving valuable structure information, has played a key role in graph analysis and inference. However, most existing methods deal with static homogeneous topologies, while graphs in real-world scenarios are gradually generated with different-typed temporal events, containing abundant semantics and dynamics. Limited work has been done for embedding dynamic heterogeneous graphs since it is very challenging to model the complete formation process of heterogeneous events. In this paper, we propose a novel H eterogeneous Hawkes P rocess based dynamic G raph E mbedding ( HPGE ) to handle this problem. HPGE effectively integrates the Hawkes process into graph embedding to capture the excitation of various historical events on the current type-wise events. Specifically, HPGE first designs a heterogeneous conditional intensity to model the base rate and temporal influence caused by heterogeneous historical events. Then the heterogeneous evolved attention mechanism is designed to determine the fine-grained excitation to different-typed current events. Besides, we deploy the temporal importance sampling strategy to sample representative events for efficient excitation propagation. Experimental results demonstrate that HPGE consistently outperforms the state-of-the-art alternatives.",http://dx.doi.org/10.1007/978-3-030-86486-6_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64254-9_10,AI and Legal Issues,Economics and Law of Artificial Intelligence,10.1007/978-3-030-64254-9_10,Springer,2021-01-01,"Al technologies affect the center of private autonomy and its limits, the notion of a contract and its interpretation, the equilibrium of parties’ interests, the structure and means of enforcement, the effectiveness of legal and contractual remedies, and the vital attributes of the legal system of effectiveness, fairness, impartiality, and predictability. The increasing global investments in blockchain technology justify a progressive regulatory adaptation to the altering materiality and so, civil liability and the insurance sector are required to amend and govern an ever-more pressing techno-economic evolution. It is worth noting that adapting existing rules to deal with the technology will need an understanding of the various manners robots and humans respond to legal rules. A robot cannot make an instinctive judgment about the value of a human life. It is argued that the automation of legal services is a manner to enhance access to justice, diminish legal costs, and upgrade the rule of law, which means that these improvements are a democratization of law. There is a shifting role of artificial intelligence in the legal course.",http://dx.doi.org/10.1007/978-3-030-64254-9_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_17,Explaining the Suspicion: Design of an XAI-Based User-Focused Anti-Phishing Measure,Innovation Through Information Systems,10.1007/978-3-030-86797-3_17,Springer,2021-01-01,"Phishing attacks are the primary cause of data and security breaches in businesses, public institutions, and private life. Due to inherent limitations and users’ high susceptibility to increasingly sophisticated phishing attempts, existing anti-phishing measures cannot realize their full potential. Against this background, we utilize methods from the emerging research field of Explainable Artificial Intelligence (XAI) for the design of a user-focused anti-phishing measure. By leveraging the power of state-of-the-art phishing detectors, our approach uncovers the words and phrases in an e-mail most relevant for identifying phishing attempts. We empirically show that our approach reliably extracts segments of text considered relevant for the discrimination between genuine and phishing e-mails. Our work opens up novel prospects for phishing prevention and demonstrates the tremendous potential of XAI methods beyond applications in AI.",http://dx.doi.org/10.1007/978-3-030-86797-3_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0771-4_9,AI & Well-Being: Can AI Make You Happy in the City,Artificial Intelligence in the Gulf,10.1007/978-981-16-0771-4_9,Springer,2021-01-01,"Happiness happiness and well-being have been high goals in society for a long time, and various cultures have interpreted these notions in a variety of ways. These interpretations have led to long-running debates as well as more formal, practical and evidence-based models, such as Smart Dubai’s Dubai ABCDE model of happiness happiness needs (covering people’s needs; Affective, Basic, Cognitive, Deeper and Enabling), as well as larger scales, as described by the Happy Cities Agenda, a model that illustrates the various design actions and enabling themes that promote a happier city that is Socially Smart . However, practitioners have always looked for ways of improving happiness in efficient and consistent ways. To this end, much research has focused on these goals by creating and developing tools, be they social or otherwise, to increase happiness happiness . More recently, information technology technology has helped society in achieving its goals in general, and Artificial Intelligence (AI) is the latest development in this domain, which uses data along with advanced algorithms algorithm in order to make even bigger leaps, by allowing machines to undertake tasks typically requiring human intelligence intelligence . Advances in AI have spanned a wide variety of applications, including well-being, health and wellness. These applications have revealed themselves in various ways, where they are woven into everyday tasks to help people achieve more efficient and better-quality outcomes, or have been embodied by the various robots and devices that are appearing in homes and workplaces. This chapter attempts to make sense of the connections and relationship between these various manifestations and mapping them to the way that happiness happiness and well-being are understood in the various contexts of people’s lives. Drawing on examples from Dubai Dubai , and other global initiatives, this pragmatic approach aims to find the utility of AI towards happier lives from various perspectives, offering directions for further work to ensure a wider coverage for all aspects of well-being.",http://dx.doi.org/10.1007/978-981-16-0771-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71381-2_17,Dimensions of Cybersecurity Risk Management,Advances in Cybersecurity Management,10.1007/978-3-030-71381-2_17,Springer,2021-01-01,"Risk analysis and management are of fundamental importance in cybersecurity. The core elements of risk are threat, vulnerability, and impact. Risk management has a basis in cybersecurity technical policies, procedures, and practices. Dimensions of risk are also at higher levels, with major interconnections in issues of international relations and trade, safety, economic vitality, health, and human life. The work of this paper is focused on risk and closely related concepts. Details and analyses that pertain to security of cyber-physical systems and the role of intrusion detection and machine learning methodologies are included.",http://dx.doi.org/10.1007/978-3-030-71381-2_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6835-4_43,A Review on Social Media Phishing: Factors and Countermeasures,Advances in Cyber Security,10.1007/978-981-33-6835-4_43,Springer,2021-01-01,"With the rapid growth in the number of social media users, the reported cases of phishing attack on social media are also increasing. Phishing is an attack that takes advantage of users’ trust, attempts to deceive the victim into compromising their credentials. This review paper presents the factor that causes social media sites to become the favorite target for cybercriminals to deploy phishing attacks. Apart from that, this paper also studies the countermeasures in protecting social media users from phishing attacks by reviewing existing works to highlight the current issues as well as provide a perspective for future research.",http://dx.doi.org/10.1007/978-981-33-6835-4_43,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-58721-5_24,Clinical Decision-Support Systems,Biomedical Informatics,10.1007/978-3-030-58721-5_24,Springer,2021-01-01,"This chapter discusses information technology that provides health-care workers and patients with situation-specific advice that can inform their decision making. The intricacies of the clinical environment, new legislative mandates, and the increasing complexity of medical practice all escalate the demand for clinical decision-support systems (CDSS) that can deliver tailored information at the right time and in the right context. The chapter describes methods for building CDSSs, which include context-specific information retrieval, grouping information within order sets, learning from data, and the use of declarative knowledge representations. The landscape for deploying CDSS technology is evolving rapidly, and the chapter discusses current standards and challenges for CDSS implementation. It concludes with a presentation of opportunities for future research.",http://dx.doi.org/10.1007/978-3-030-58721-5_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70604-3_6,Federated Learning Systems for Healthcare: Perspective and Recent Progress,Federated Learning Systems,10.1007/978-3-030-70604-3_6,Springer,2021-01-01,"In the medical or healthcare industry, where, the already available information or data is never sufficient, excellence can be performed with the help of Federated Learning (FL) by empowering AI models to learn on private data without conceding privacy. It opened the door for ample research because of its high level of communication efficiency which is linked with distributed training problems. The primary objective of the chapter is to highlight the adaptability and working of the FL techniques in the healthcare system especially in drug development, clinical diagnosis, digital health monitoring, and various disease predictions and detection system. The first section of the chapter is comprised of a background study on an FL framework for healthcare, FL working model in healthcare, and various important benefits of FL. The next section of the chapter described the reported work which highlights different research works in the field of electronic health record systems, drug discovery, and disease prediction systems using the FL model. The final section of the chapter presented the comparative analysis, which shows the comparison between different FL algorithms for different health sectors by using parameters such as accuracy, the area under the curve, precision, recall, and F-score.",http://dx.doi.org/10.1007/978-3-030-70604-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_91-1,IoT and Blockchain-Based Smart Agri-food Supply Chains,Handbook of Smart Cities,10.1007/978-3-030-15145-4_91-1,Springer,2021-01-01,"With the development of the Internet of Things (IoT), connected devices are rapidly penetrating into every aspect of our daily life. Thus, IoT is considered as a key building block for the agri-food supply chain due to its pervasiveness, interoperability, and scalability. In this chapter, we first review IoT and blockchain-based agri-food supply chains and then identify the key building blocks for this type of system. We put the emphasis on core components of IoT and blockchain, as the former lays the foundation for data collection and transmissions, while the latter paves the way for the data transparency and integrity, and more importantly, it lowers the financing cost for all participants of the supply chain.",http://dx.doi.org/10.1007/978-3-030-15145-4_91-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-69698-6_91,IoT and Blockchain-Based Smart Agri-food Supply Chains,Handbook of Smart Cities,10.1007/978-3-030-69698-6_91,Springer,2021-01-01,"With the development of the Internet of Things (IoT), connected devices are rapidly penetrating into every aspect of our daily life. Thus, IoT is considered as a key building block for the agri-food supply chain due to its pervasiveness, interoperability, and scalability. In this chapter, we first review IoT and blockchain-based agri-food supply chains and then identify the key building blocks for this type of system. We put the emphasis on core components of IoT and blockchain, as the former lays the foundation for data collection and transmissions, while the latter paves the way for the data transparency and integrity, and more importantly, it lowers the financing cost for all participants of the supply chain.",http://dx.doi.org/10.1007/978-3-030-69698-6_91,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-73200-4_39,Graph Attention Networks for New Product Sales Forecasting in E-Commerce,Database Systems for Advanced Applications,10.1007/978-3-030-73200-4_39,Springer,2021-01-01,"Aiming to discover competitive new products, sales forecasting has been playing an increasingly important role in real-world E-Commerce systems. Current methods either only utilize historical sales records with time series based models, or train powerful classifiers ( e.g., DNN and GBDT) with subtle feature engineering. Despite effectiveness, they have limited abilities to make prediction for new products due to the sparsity of product-related features. With the observation on real-world data, we find that some additional time series features ( e.g., brand and category) implying product characteristics also play vital roles in new product sales forecasting. Hence, we organize them as a new kind of dense feature called CPV (Category-Property-Value) and propose a Time Series aware Heterogeneous Graph (TSHG) to integrate CPVs and products based time series into a unified framework for fine-grained interaction. Furthermore, we propose a novel Graph Attention Networks based new product Sales Forecasting model (GASF) that jointly exploits high-order structure and time series features derived from THSG for new product sales forecasting with graph attention networks. Moreover, a multi trend attention (MTA) mechanism is also proposed to solve temporal shifting and spatial inconsistency between the time series of products and CPVs. Extensive experiments on an industrial dataset and online system demonstrate the effectiveness of our proposed approaches.",http://dx.doi.org/10.1007/978-3-030-73200-4_39,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-75657-4_17,"Soft Computing Techniques for Medical Diagnosis, Prognosis and Treatment","Advanced Soft Computing Techniques in Data Science, IoT and Cloud Computing",10.1007/978-3-030-75657-4_17,Springer,2021-01-01,"With the rapid advancement in the fields of computation and deep learning, the use cases of artificial intelligence in healthcare are blooming more than any time in history. In past years, it was supposed that only doctors and medical practitioners should handle the decisions in healthcare systems. With the rise of machine learning, the tables have turned and dependency on algorithms to make support systems for healthcare has increased. Various AI predictive models have been built for the prediction of diseases at an early stage. Not only this, but data science is also used in a lot of areas of healthcare ranging from summarization of clinical data to intelligent predictive models. However, the work in developing a decision-support system for healthcare is still in the infancy state. Most of the conventional decision-support systems are based on hard computing which requires exactly state analytic models and does not have any place for approximation and uncertainty. Soft computing, being an approach that imitates the human mind to reason and learns in an environment of uncertainty and impression, helps to provide an optimal solution through its nature of adaptivity and knowledge. Various studies have shown that models which extensively used soft computing methodologies, for example, fuzzy logic, ANN, Genetic Algorithms, etc. were able to present clinical observations and inferences in a way that better helped doctors in decision making. There are various applications in the medical field like summarization of clinical text, activity monitoring, development of adaptive disease management systems where soft computing can be used. The book chapter can discuss the prevailing practices, comparative analysis of the necessity of soft computing over more prevalent hard computing techniques, and future directions for the application of soft computing in the healthcare decision-support system.",http://dx.doi.org/10.1007/978-3-030-75657-4_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71017-0_11,Vulnerability of Virtual Private Networks to Web Fingerprinting Attack,"Advances in Security, Networks, and Internet of Things",10.1007/978-3-030-71017-0_11,Springer,2021-01-01,"Virtual private networks (VPN) are used to maintain secrecy of internet usage. They provide end-to-end encrypted traffic to hide the content and destination details from potential eavesdroppers. Recent studies show that 72% of VPN users apply it to access blocked content or hide identity from government. Concerned government departments and other organizations need to analyze the encrypted traffic of VPN to observe whether people are using blocked content or not. Typical traffic analysis fails in this case as traffic is encrypted and the destination IP address is hidden. However, traffic metadata and some packet attributes, like packet size and time, could be considered as fingerprint of any specific web service. In this paper, we analyze five commonly used VPN services, namely: Psiphone, Softether, HotspotShield, OpenVPN, and AviraPhantom. Our goal is to identify which VPN service is vulnerable to Cai et al. fingerprinting attack, and what types of web services are most appropriate to detect using this attack. The results show that Open VPN is more vulnerable to this attack compared to the other VPNs in this study. The efficiency of the web traffic classification through VPN is also estimated for four different web services with Cai et al. Useful recommendations are provided as a result of this study.",http://dx.doi.org/10.1007/978-3-030-71017-0_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66741-2_9,Image Classification as a Service,Smart Algorithms for Multimedia and Imaging,10.1007/978-3-030-66741-2_9,Springer,2021-01-01,"In this chapter, we discuss a task of building an image classification as a service. We cover all steps of this process starting from ethical considerations, data collection and annotation, metrics and evaluation procedures; we review different model training approaches and model training frameworks. Finally, we describe the model deployment process.",http://dx.doi.org/10.1007/978-3-030-66741-2_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93206-0_13,WADS: A Webshell Attack Defender Assisted by Software-Defined Networks,Information Security Practice and Experience,10.1007/978-3-030-93206-0_13,Springer,2021-01-01,"Webshell is a code execution environment with extensions like php, asp, and jsp, which essence is to help managers of the system manage the web application effortlessly. Therefore, an attacker can use weshell as a backdoor program to control the webserver similarly. Traditional webshell detection mechanisms like rule matching and feature code detection usually suffer from poor generalization capabilities, leading to a higher rate of false negatives. Based on the Machine Learning model N-Gram, TF-IDF to extract the webshell sample features, three Machine Learning algorithms Multilayer Perceptron, XGBoost, and Naive Bayesian, to train the model. Analysis through training and testing, detection accuracy is more than 99% under the experimental environment, which detectable scope includes php, jsp, asp, and others. By combing the Machine Learning webshell detection model with the Software-Defined Networks using the flow table operate method, we implement a dynamic defense solution against webshell attackers, leading attackers to disconnect with the target network.",http://dx.doi.org/10.1007/978-3-030-93206-0_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-44982-7_20-1,Understanding Dialogue for Human Communication,Handbook of Cognitive Mathematics,10.1007/978-3-030-44982-7_20-1,Springer,2021-01-01,"Dialogue is a peculiar activity of humans and a crucial characteristic of human cognition. It is not surprising that dialogue have been investigated, under different perspectives, by linguists, cognitive scientists, and philosophers and, in the last decades, by computer scientists. This chapter shows the progress achieved in computational linguistics to design formal models of dialogues and exploit them in human-machine systems. We highlight that collaborative dialogues follow sequences of turns characterized by speech acts and that they show an internal coherence based on conversational goals. Analysis carried on dialogue collections reveals the importance of modeling mixed-initiative schema, various types of subdialogues, and grounding among interlocutors, as they help to achieve the speakers’ communicative goals. On the computational side, both knowledge-driven and machine learning technologies are nowadays used to model a pipeline of dialogue components, particularly for task-oriented situations, including automatic speech recognition, utterance understanding, dialogue state tracking, dialogue policy making, and response generation. In recent years, research on dialogue systems has moved toward the so-called conversational AI, which takes advantage of the power of neural architectures to induce models from annotated dialogues. Neural models have achieved state-of-the-art performance, and end-to-end solutions are now proposed in place of traditional dialogue pipelines. However, we argue that current models are applied to relatively narrow tasks and still scratch the surface of capturing human collaborative dialogues’ effectiveness and cognitive abilities.",http://dx.doi.org/10.1007/978-3-030-44982-7_20-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85910-7_21,STARdom: An Architecture for Trusted and Secure Human-Centered Manufacturing Systems,Advances in Production Management Systems. Artificial Intelligence for Sustainable and Resilient Production Systems,10.1007/978-3-030-85910-7_21,Springer,2021-01-01,"There is a lack of a single architecture specification that addresses the needs of trusted and secure Artificial Intelligence systems with humans in the loop, such as human-centered manufacturing systems at the core of the evolution towards Industry 5.0. To realize this, we propose an architecture that integrates forecasts, Explainable Artificial Intelligence, supports collecting users’ feedback and uses Active Learning and Simulated Reality to enhance forecasts and provide decision-making recommendations. The architecture security is addressed at all levels. We align the proposed architecture with the Big Data Value Association Reference Architecture Model. We tailor it for the domain of demand forecasting and validate it on a real-world case study.",http://dx.doi.org/10.1007/978-3-030-85910-7_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86230-5_53,Cloud Based Decision Making for Multi-agent Production Systems,Progress in Artificial Intelligence,10.1007/978-3-030-86230-5_53,Springer,2021-01-01,"The use of multi-agent systems (MAS) as a distributed control method for shop-floor manufacturing control applications has been extensively researched. MAS provides new implementation solutions for smart manufacturing requirements such as the high dynamism and flexibility required in modern manufacturing applications. MAS in smart manufacturing is becoming increasingly important to achieve increased automation of machines and other components. Emerging technologies like artificial intelligence, cloud-based infrastructures, and cloud computing can also provide systems with intelligent, autonomous, and more scalable solutions. In the current work, a decision-making framework is proposed based on the combination of MAS cloud computing, agent technology, and machine learning. The framework is demonstrated in a quality control use case with vision inspection and agent-based control. The experiment utilizes a cloud-based machine learning pipeline for part classification and agent technology for routing. The results show the applicability of the framework in real-world scenarios bridging cloud service-oriented architecture with agent technology for production systems.",http://dx.doi.org/10.1007/978-3-030-86230-5_53,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86790-4_28,Explainable Artificial Intelligence (XAI) Supporting Public Administration Processes – On the Potential of XAI in Tax Audit Processes,Innovation Through Information Systems,10.1007/978-3-030-86790-4_28,Springer,2021-01-01,"Artificial Intelligence (AI) can offer significant potential for public administrations which – in Germany – are likely to face considerable skills shortages in the next few years. AI systems can especially support the automation of processes and thus disburden administrative staff. As transparency and fairness play a major role in administrative processes, explainable AI (XAI) approaches are expected to enable a proper usage of AI in public administration. In this article, we investigate the potential of XAI for the support of tax authority processes, especially the selection of tax audit target organizations. We illustrate relevant tax audit scenarios and present the potential of different XAI techniques which we currently develop in these scenarios. It shows that XAI can significantly support tax audit preparations resulting in more efficient processes and a better performance of tax authorities concerning their main responsibilities. A further contribution of this article lies in the exemplary application of XAI usage guidelines in the public administration context.",http://dx.doi.org/10.1007/978-3-030-86790-4_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_85-1,The Voice of Major E-Tourism Players: An Expedia Group Perspective,Handbook of e-Tourism,10.1007/978-3-030-05324-6_85-1,Springer,2021-01-01,"This chapter outlines the approach of Expedia Group, the world’s travel platform, and the role of technology in revolutionizing travel search, discovery, and booking. It covers innovations developed by online travel agencies (OTAs) and the unique challenges and opportunities provided by the breadth and depth of the data that global OTAs leverage to power travelers’ online experiences. The focus is on accommodation, the largest revenue-generating, and most complex tourism segment. The chapter explores specific use cases where data are brought together with leading and innovative machine learning methodologies to improve traveler and supplier experiences. They include recommender systems, machine learning models that help Expedia Group manage the text and image content for over a million properties and revenue management systems for accommodation providers. The chapter concludes with a comment on the Expedia Group COVID-19 response.",http://dx.doi.org/10.1007/978-3-030-05324-6_85-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85469-0_9,Robust and Generalizable Predictive Models for Business Processes,Business Process Management,10.1007/978-3-030-85469-0_9,Springer,2021-01-01,"Machine Learning models, and more recently Deep Learning models have gained popularity for predictive process monitoring. Predicting the process outcome, remaining time to completion, or the next activity of a running process can be crucial to provide decision information and enable timely intervention by case managers. These models fundamentally assume that the process logs used for training and inference follow the same data distribution and patterns. However, many real-world processes can have gradual or sudden changes, and logs themselves may be associated with different versions of process models modified over time, or customized by different departments with different policies. These can introduce spurious biases and correlations in the data, which can influence predictive models during training and adversely impact their accuracy. In this work, we present RoGen, an approach to train robust predictive models that can identify these spurious correlations and generalize to data with differing distributions. We show that our approach can also be adopted by existing predictive models to improve their robustness and generalizability. We evaluate our approach using real-world event logs and show that even in the presence of spurious data correlations, our models remain robust and outperform existing predictive models.",http://dx.doi.org/10.1007/978-3-030-85469-0_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88885-5_24,Property-Directed Verification and Robustness Certification of Recurrent Neural Networks,Automated Technology for Verification and Analysis,10.1007/978-3-030-88885-5_24,Springer,2021-01-01,"This paper presents a property-directed approach to verifying recurrent neural networks (RNNs). To this end, we learn a deterministic finite automaton as a surrogate model from a given RNN using active automata learning. This model may then be analyzed using model checking as a verification technique. The term property-directed reflects the idea that our procedure is guided and controlled by the given property rather than performing the two steps separately. We show that this not only allows us to discover small counterexamples fast, but also to generalize them by pumping towards faulty flows hinting at the underlying error in the RNN. We also show that our method can be efficiently used for adversarial robustness certification of RNNs.",http://dx.doi.org/10.1007/978-3-030-88885-5_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83632-0_1,Digital Business Designs and Platforms,Valuing Digital Business Designs and Platforms,10.1007/978-3-030-83632-0_1,Springer,2021-01-01,"Despite fueling a once-in-a-century downturn of global business activity in spring 2020, the pandemic was more a tailwind than an impediment for the development of digital and platform Business Designs. This chapter introduces a scientific framework for such Business Designs by defining the four mission critical elements of platform firms, by describing five distinct platform patterns and by discussing the financial and strategic characteristics of platforms. Based on this framework, three novel scientific concepts to assess, design, and evaluate platform Business Designs are introduced: The 10C Business Design enables the strategic analysis of existing and innovation of new business models by defining the ten mission-critical architectural cornerstones of a digital firm. The eight platform value levers , as second strategic tool, assess a platform’s strength. The latter is defined by a platform’s scalability , its dominance within a defined ecosystem, and its value creation potential . The Reverse Discounted Cash Flow ( DCF ) pairs strategic diagnostics with financial valuation. It builds upon the well-known Discounted Cash Flow concept of corporate valuation but applies it upside down. The valuation’s origin is the steady-state description of a distinct Business Design embedded in a “picture-of-the-future” scenario.",http://dx.doi.org/10.1007/978-3-030-83632-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0127-9_5,Misbehavior Detection on Blockchain Data,Blockchain Intelligence,10.1007/978-981-16-0127-9_5,Springer,2021-01-01,"The prevalence of misbehaviors has resulted in considerable financial loss and thus has undermined public reputation of cryptocurrency, leading to hindrance to the progress of blockchain technology. To attack on this problem, this chapter discussed about several types of misbehaviors on blockchain and data mining as an approach for identification of misbehavior on blockchain. Two practical data mining models aiming at detecting Ponzi schemes and phishing scams on Ethereum are proposed and detailed evaluations are conducted.",http://dx.doi.org/10.1007/978-981-16-0127-9_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/698_2020_482,Data Science Trends and Opportunities for Smart Water Utilities,ICT for Smart Water Systems: Measurements and Data Science,10.1007/698_2020_482,Springer,2021-01-01,"We are witnessing an industry change which is transitioning to a more intelligent (or smarter) water network. In the UK a 5-year planning period and investment cycle called the Asset Management Plan (AMP) is the regulatory mechanism. This process is used to manage a water utility’s infrastructure and other assets to deliver an agreed standard of service. The challenge of AMP 6 and 7 (to 2025) and beyond is to maximise efficiency by moving from reactive to proactive management. This can be achieved by using data, information and (where possible) control of the system. The more intelligence that is captured, the more that can be learned and understood about the network and subsequently be predicted. Extra data provides new opportunities for asset maintenance and event analytics. Data science is an emerging discipline which combines analysis, programming and business knowledge and uses new and advanced techniques and technologies to work with complex data. The water sector needs to address the issue of ‘big data’ and obtaining ‘signal from the noise’. Primarily, the focus is on data to action by the application of data science. The role of digitalisation for smart water networks is covered in this chapter, exploring issues of IoT, artificial intelligence, blockchain and other novel technologies. Reference to case studies demonstrates the type of applications which will become increasingly common place. Some recommendations based on future possibilities and opportunities are proposed.",http://dx.doi.org/10.1007/698_2020_482,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-020-00849-0,A survey of typical attributed graph queries,World Wide Web,10.1007/s11280-020-00849-0,Springer,2021-01-01,"Graphs are commonly used for representing complex structures such as social relationships, biological interactions, and knowledge bases. In many scenarios, graphs not only represent topological relationships but also store the attributes that denote the semantics associated with their vertices and edges, known as attributed graphs . Attributed graphs can meet demands for a wide range of applications, and thus a variety of queries on attributed graphs have been proposed. However, these diverse types of attributed graph queries have not been systematically investigated yet. In this paper, we provide an extensive survey of several typical types of attributed graph queries. We propose a taxonomy of attributed graph queries based on query inputs and outputs. We summarize the definitions of queries that fall into each category and present a fine-grained classification of queries within each category by analyzing the semantics and algorithmic motivations behind these queries. Moreover, we discuss the insights of how existing studies address the technical challenges of query processing and outline several promising future research directions.",http://dx.doi.org/10.1007/s11280-020-00849-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-84655-8_3,How Fair Is IS Research?,Engineering the Transformation of the Enterprise,10.1007/978-3-030-84655-8_3,Springer,2021-01-01,"While both information systems and machine learning are not neutral, the identification of discrimination is more difficult if a system learns from data and discrimination can be introduced at several stages. Therefore, this article investigates if IS Research has taken up with this topic. A literature analysis is conducted and its discussion shows that technology, organization, and human aspects have to be considered, making it a topic not only for data scientist or computer scientist, but for information systems researchers as well.",http://dx.doi.org/10.1007/978-3-030-84655-8_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-60990-0_21,Reinforcement Learning: An Industrial Perspective,Handbook of Reinforcement Learning and Control,10.1007/978-3-030-60990-0_21,Springer,2021-01-01,"In this chapter, we discuss potential opportunities and challenges associated with applications of reinforcement learning (RL) in the aerospace domain. In particular, we focus on problems related to sensor resource management, autonomous navigation, advanced manufacturing, maintenance, repair and overhaul operations, and human-machine collaboration. We present two detailed RL case studies related to sensor tasking for aerial surveillance and robot control in an additive manufacturing application which utilizes different flavors of RL including the more recent deep RL framework. Finally, we highlight some ongoing research developments which could address key challenges in deploying RL in the aerospace domain.",http://dx.doi.org/10.1007/978-3-030-60990-0_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-4729-1_8,Big Data Analytics and Cybersecurity: Emerging Trends,Big Data Analytics in Cognitive Social Media and Literary Texts,10.1007/978-981-16-4729-1_8,Springer,2021-01-01,"At the current digital age, cybercrimes are increasing vastly. The strategies and tools preventing sophisticated cyberattacks and crimes cause organizations to stay intelligent with developing dangers. Big Data Analytics plays a crucial role when it comes to operational intelligence and security. This chapter aims to present a comprehensive cutting edge of Security Analytics, i.e., its trends, tools, technology, and description. Similarly, the work is engaged in three sorts: supervised, unsupervised, and hybrid approaches. The theoretical model developed in the chapter is based on the three types of machine learning, allowing the P.C. to learn and get to sample information without being customized to predict each conceivable circumstance. A structured work was applied to synthesize the theoretical model. A search of the existing literature is done on different websites, Scopus and Google Scholar, applying a mix of keywords such as Big Data Analytics, cybersecurity, and security analytics. This chapter will put forth the ideas and emerging strategies available to work with Big Data to lay out a future vision. Hence, it aims to persuade the imminent reader about emerging applications/trends of analytics as a cybersecurity solution later.",http://dx.doi.org/10.1007/978-981-16-4729-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_7,Managing Bias in Machine Learning Projects,Innovation Through Information Systems,10.1007/978-3-030-86797-3_7,Springer,2021-01-01,"This paper introduces a framework for managing bias in machine learning (ML) projects. When ML-capabilities are used for decision making, they frequently affect the lives of many people. However, bias can lead to low model performance and misguided business decisions, resulting in fatal financial, social, and reputational impacts. This framework provides an overview of potential biases and corresponding mitigation methods for each phase of the well-established process model CRISP-DM. Eight distinct types of biases and 25 mitigation methods were identified through a literature review and allocated to six phases of the reference model in a synthesized way. Furthermore, some biases are mitigated in different phases as they occur. Our framework helps to create clarity in these multiple relationships, thus assisting project managers in avoiding biased ML-outcomes.",http://dx.doi.org/10.1007/978-3-030-86797-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63089-8_29,Detection of Malicious HTTP Requests Using Header and URL Features,"Proceedings of the Future Technologies Conference (FTC) 2020, Volume 2",10.1007/978-3-030-63089-8_29,Springer,2021-01-01,"Cyber attackers leverage the openness of internet traffic to send specially crafted HyperText Transfer Protocol (HTTP) requests and launch sophisticated attacks for a myriad of purposes including disruption of service, illegal financial gain, and alteration or destruction of confidential medical or personal data. Detection of malicious HTTP requests is therefore essential to counter and prevent web attacks. In this work, we collected web traffic data and used HTTP request header features with supervised machine learning techniques to predict whether a message is likely to be malicious or benign. Our analysis was based on two real world datasets: one collected over a period of 42 days from a low interaction honeypot deployed on a Comcast business class network, and the other collected from a university web server for a similar duration. In our analysis, we observed that: (1) benign and malicious requests differ with respect to their header usage, (2) three specific HTTP headers (i.e., accept - encoding , accept - language , and content - type ) can be used to efficiently classify a request as benign or malicious with 93.6% accuracy, (3) HTTP request line lengths of benign and malicious requests differ, (4) HTTP request line length can be used to efficiently classify a request as benign or malicious with 96.9% accuracy. This implies we can use a relatively simple predictive model with a fast classification time to efficiently and accurately filter out malicious web traffic.",http://dx.doi.org/10.1007/978-3-030-63089-8_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6835-4_45,A Review on Detection of Cross-Site Scripting Attacks (XSS) in Web Security,Advances in Cyber Security,10.1007/978-981-33-6835-4_45,Springer,2021-01-01,"Cybersecurity is one of the pillars of the growth of the digital industry, Industry Revolution 4.0. The network universe has several forms of cyber threats. Web application is the most essential and standard software system allowing human and computer communication. Cross-Site Scripting (XSS) attacks are a prevalent cybersecurity threat. This paper contains the brief emergence of Cross-Site Scripting Attacks (XSS), the key trigger and effects of Cross-Site Scripting Attacks (XSS), the existing Cross-Site Scripting Detection and Prevention Mechanism (XSS), and the analysis of current frameworks. Therefore, the current Cross-Site Scripting (XSS) detection and prevention mechanism would address how to identify the XSS and an overview of the static, dynamic and hybrid research approach utilized in these few decades. Also, the latest methods used to diagnose XSS in these decades will be addressed. The analysis of the benefits and drawbacks of the previously mentioned methods would also be addressed.",http://dx.doi.org/10.1007/978-981-33-6835-4_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_12,"Empirically Exploring the Cause-Effect Relationships of AI Characteristics, Project Management Challenges, and Organizational Change",Innovation Through Information Systems,10.1007/978-3-030-86797-3_12,Springer,2021-01-01,"Artificial Intelligence (AI) provides organizations with vast opportunities of deploying AI for competitive advantage such as improving processes, and creating new or enriched products and services. However, the failure rate of projects on implementing AI in organizations is still high, and prevents organizations from fully seizing the potential that AI exhibits. To contribute to closing this gap, we seize the unique opportunity to gain insights from five organizational cases. In particular, we empirically investigate how the unique characteristics of AI – i.e. experimental character, context sensitivity, black box character, and learning requirements – induce challenges into project management, and how these challenges are addressed in organizational (socio-technical) contexts. This shall provide researchers with an empirical and conceptual foundation for investigating the cause-effect relationships between the characteristics of AI, project management, and organizational change. Practitioners can benchmark their own practices against the insights to increase the success rates of future AI implementations.",http://dx.doi.org/10.1007/978-3-030-86797-3_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-73050-5_55,Analysis of Text Mining Tools in Disease Prediction,Hybrid Intelligent Systems,10.1007/978-3-030-73050-5_55,Springer,2021-01-01,"Due to rapid creation of digital data by Internet of Things devices or smart devices, many new modern mining strategies/techniques require to handle/analyse this large amount of data. Note that more than 90% of today’s data is in present (generated) unstructured or semi-structured data format (most of part of this data is being generated only in the past decade). The discovery of appropriate patterns and trends to analyse the text documents from this large big data (i.e., large volume of data) is a big issue. Text mining is a process of extracting interesting and non- trivial patterns from huge amount of text documents. There exist different techniques and tools to mine the text (also other data format) and discover valuable information for future prediction and decision making process. Basically, there are two terms used in making or extracting some relevant information from a data-set, i.e., prediction modelling, and text mining. Predictive models are often used to detect crimes and identify suspects, after the crime has taken place/to detect an email, how likely that it is spam. Similarly, text mining used in applications like digital libraries, academic research field, life science, social media, business intelligence, etc. Today’s different text mining techniques are available for analysing the text patterns and their mining process, some of them are included here as: document classification (text classification, document standardization), information retrieval (keyword search/querying and indexing), document clustering (phrase clustering), natural language processing (spelling correction, lemmatization, grammatical parsing, and word sense disambiguation), information extraction (relationship extraction/link analysis), and web mining (web link analysis), etc. This article discusses and analyse the text mining techniques and their applications in diverse fields of life. This work discusses about several use-cases, efficient algorithms like apriori algorithm, association rule mining, etc., which is used for frequent item set extraction (information retrieval and information extraction) and rule generation. Also, in result, generated several rules form a collected data-set to predict about a disease (as an example) will be discussed. In last, this work discusses detail descriptions about the terms classification, clustering, regression, association rule mining and outlier detection as a work-flow in analysing the data for producing a decision or making some prediction, also discussing some useful research gaps, challenges, issues (as its concluding remarks).",http://dx.doi.org/10.1007/978-3-030-73050-5_55,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_14,Augmenting Humans in the Loop: Towards an Augmented Reality Object Labeling Application for Crowdsourcing Communities,Innovation Through Information Systems,10.1007/978-3-030-86797-3_14,Springer,2021-01-01,"Convolutional neural networks (CNNs) offer great potential for business applications because they enable real-time object recognition. However, their training requires structured data. Crowdsourcing constitutes a popular approach to obtain large databases of manually-labeled images. Yet, the process of labeling objects is a time-consuming and cost-intensive task. In this context, augmented reality provides promising solutions by allowing an end-to-end process of capturing objects, directly labeling them and immediately embedding the data in training processes. Consequently, this paper deals with the development of an object labeling application for crowdsourcing communities following the design science research paradigm. Based on seven issues and twelve corresponding meta-requirements, we developed an AR-based prototype and evaluated it in two evaluation cycles. The evaluation results reveal that the prototype facilitates the process of object detection, labeling and training of CNNs even for inexperienced participants. Thus, our prototype can help crowdsourcing communities to render labeling tasks more efficient.",http://dx.doi.org/10.1007/978-3-030-86797-3_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-62151-3_10,Revisiting State-of-the-Art Applications of the Blockchain Technology: Analysis of Unresolved Issues and Potential Development,Developments in Information & Knowledge Management for Business Applications,10.1007/978-3-030-62151-3_10,Springer,2021-01-01,"This chapter focuses on state-of-the-art applications of the blockchain technology. The authors provide a comprehensive analysis of the blockchain technology and its applications that are deployed across various domains and research areas. Additionally, the authors identify outstanding issues and propose potential solutions of high relevance and value for academics and practitioners.",http://dx.doi.org/10.1007/978-3-030-62151-3_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66222-6_6,A Concept of Internet of Robotic Things for Smart Automation,Emergence of Cyber Physical System and IoT in Smart Automation and Robotics,10.1007/978-3-030-66222-6_6,Springer,2021-01-01,"A recent evolution in the field of Internet of Things (IoT) is the interdisciplinary domain involving smart automation and robotics implemented by the techniques of Internet of Things (IoT), famously known as Internet of Robotic Things (IoRT). This emerging technology is adopted in various sectors such as health care, manufacturing industries, economic, information technology and several other fields. Persistent sensors and actuators involved in robotics and automation are brought together by the emerging vision of Internet of Robotic Things. The domains of robotics and Internet of Things (IoT) cannot be viewed separately hence integrated together to form the novel domain—Internet of Robotic Things where the technologies of robotics are implemented in the scenarios of IoT. This chapter aims to provide an overview of possible solutions for various issues in smart automation environment and applications of robotics using Internet of Things (IoT). Envisioning dense heterogeneous devices communicating with each other to accomplish various objectives in the field of automation and robotics using Internet of Things (IoT) is the aim of this chapter. This technology can increase efficiency at reduced cost, significantly reducing manual intervention by increasing automation process visioning by SCADA systems. Industrial automation involving Internet of Things (IoT) has the goal of self-configuration, self-organization, self-healing system, scalability with less power consumption compatible to global standards. Involvement of robotics in the field of Internet of Things (IoT) potentially changes the process of production where the operations are performed rapidly in an accurate way leading to tremendous value in the field of automation. These two domains are converged and developed to provide the concept, architecture, involved technologies, challenges and applications and future work in order to cover (Internet of Robotic Things) IoRT comprehensively.",http://dx.doi.org/10.1007/978-3-030-66222-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_62-2,Journeys in the Age of Smart Cities: Some Fresh Perspectives,Handbook of Smart Cities,10.1007/978-3-030-15145-4_62-2,Springer,2021-01-01,"Modern cities are intrinsically multidisciplinary and multicultural places. Inspired by that view, this chapter has invited a cross-disciplinary international team of domain experts to present their differing views (in their distinctive styles) on the current state and future evolution of smart cities. In presenting their views, the experts have adopted the metaphor of a journey, since the people, organizations, and technologies comprising a smart city can be regarded as being on journeys from conception to death, from start-up to bankruptcy, and from innovation to obsolescence. To do this, the chapter begins with a person-centric exploration of smart cities, examining topics such as innovation, entrepreneurship, generational issues, memory, and education before ending with a set of discussions around the key enabling technologies such as artificial intelligence, the Internet of Things, smart transport, mixed reality, and wearables. The chapter concludes by regarding the smart city as a type living laboratory for innovative technology development, reflecting on the expert’s opinions for potential directions of travel that smart city research might take.",http://dx.doi.org/10.1007/978-3-030-15145-4_62-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_62-1,Journeys in the Age of Smart Cities: Some Fresh Perspectives,Handbook of Smart Cities,10.1007/978-3-030-15145-4_62-1,Springer,2021-01-01,"Modern cities are intrinsically multidisciplinary and multicultural places. Inspired by that view, this chapter has invited a cross-disciplinary international team of domain experts to present their differing views (in their distinctive styles) on the current state and future evolution of smart cities. In presenting their views, the experts have adopted the metaphor of a journey, since the people, organizations, and technologies comprising a smart city can be regarded as being on journeys from conception to death, from start-up to bankruptcy, and from innovation to obsolescence. To do this, the chapter begins with a person-centric exploration of smart cities, examining topics such as innovation, entrepreneurship, generational issues, memory, and education before ending with a set of discussions around the key enabling technologies such as artificial intelligence, the Internet of Things, smart transport, mixed reality, and wearables. The chapter concludes by regarding the smart city as a type living laboratory for innovative technology development, reflecting on the expert’s opinions for potential directions of travel that smart city research might take.",http://dx.doi.org/10.1007/978-3-030-15145-4_62-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-69698-6_62,Journeys in the Age of Smart Cities: Some Fresh Perspectives,Handbook of Smart Cities,10.1007/978-3-030-69698-6_62,Springer,2021-01-01,"Modern cities are intrinsically multidisciplinary and multicultural places. Inspired by that view, this chapter has invited a cross-disciplinary international team of domain experts to present their differing views (in their distinctive styles) on the current state and future evolution of smart cities. In presenting their views, the experts have adopted the metaphor of a journey, since the people, organizations, and technologies comprising a smart city can be regarded as being on journeys from conception to death, from start-up to bankruptcy, and from innovation to obsolescence. To do this, the chapter begins with a person-centric exploration of smart cities, examining topics such as innovation, entrepreneurship, generational issues, memory, and education before ending with a set of discussions around the key enabling technologies such as artificial intelligence, the Internet of Things, smart transport, mixed reality, and wearables. The chapter concludes by regarding the smart city as a type living laboratory for innovative technology development, reflecting on the expert’s opinions for potential directions of travel that smart city research might take.",http://dx.doi.org/10.1007/978-3-030-69698-6_62,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-0708-0_27,Crop Yield Estimation Using Machine Learning,Soft Computing and its Engineering Applications,10.1007/978-981-16-0708-0_27,Springer,2021-01-01,"The recent area of interest for computer scientists and data analysts working on precision farming has been the use of machine learning and deep learning algorithms to recommend crops to the farmers and predict yield. Improving crop yields not only helps farmers but also seeks to address global problems such as food shortages. Predictions can be made taking into account forecasts of climate, soil and its mineral content, moisture, crop historic performance, rainfall and others. Crop Data from six states of India for five crops from 2009–2016 has been used for training and validation of different machine learning regression algorithms to produce a comprehensive study of crop yield estimate. The yields are estimated using Linear models, Support Vector Regressor, K Neighbors Regressor, Tree-based models, Ensemble models and Shallow Neural Networks with R-squared score for evaluation. Test accuracy showed promising results in ensemble models and neural networks. Extra Trees Regressor is the best model with Mean Absolute Error of 351.10 and maximum accuracy of 99.95%. This paper aims at providing state of art implementation on machine learning algorithms to facilitate farmers, governments, economists, banks to estimate the crop yields in Indian states based on specific parameters.",http://dx.doi.org/10.1007/978-981-16-0708-0_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-0878-0_59,"Insights into the Advancements of Artificial Intelligence and Machine Learning, the Present State of Art, and Future Prospects: Seven Decades of Digital Revolution",Smart Computing Techniques and Applications,10.1007/978-981-16-0878-0_59,Springer,2021-01-01,"The desire of human intelligence to surpass its potential has triggered the emergence of artificial intelligence and machine learning. Over the last seven decades, these terms have gained much prominence in the digital arena due to its wide adoption of techniques for designing affluent industry-enabled solutions. In this comprehensive survey on artificial intelligence, the authors provide insights from the evolution of machine learning and artificial intelligence to the present state of art and how the technology in future can be exploited to yield solutions to some of the challenging global problems. The discussion centers around successful deployment of diverse use cases for the present state of affairs. The rising interest among researchers and practitioners led to the unfolding of AI into many popular subfields as we know today. Through the course of this research article, the authors provide brief highlights about techniques for supervised as well as unsupervised learning. AI has paved the way to accomplish cutting-edge research in complex competitive domains ranging from autonomous driving, climate change, cyber-physical security systems, to healthcare diagnostics. The study concludes by depicting the growing share in market revenues from artificial intelligence-powered products and the forecasted billions of dollars worth of market shares ahead in the coming decade.",http://dx.doi.org/10.1007/978-981-16-0878-0_59,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5285-4_15,An Analysis of Remotely Triggered Malware Exploits in Content Management System-Based Web Applications,Intelligence in Big Data Technologies—Beyond the Hype,10.1007/978-981-15-5285-4_15,Springer,2021-01-01,"Web content management systems, referred here as CMS, is a customizable software platform on which websites can be easily built. According to Web Technology Surveys, more than 55% of websites on the Internet use any one of the many popular CMS platforms [ 1 ]. Their popularity arises due to ease of use, capability to customize, and ability to abstract complex programming layers into a very simple user interface, especially for a novice user. However, while the user may have very little or no knowledge of the backend database system containing sensitive information, this platform offers itself as an easy target to ever-expanding malware threats. In this paper, we explore and analyze in depth of one such malware, focusing on the origin of the attack, its deployment, its regenerating methods, and the cost of combating and retrieving the compromised data.",http://dx.doi.org/10.1007/978-981-15-5285-4_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-7965-3_7,Building Intelligent Integrated Development Environment for IoT in the Context of Statistical Modeling for Software Source Code,Multimedia Technologies in the Internet of Things Environment,10.1007/978-981-15-7965-3_7,Springer,2021-01-01,"With various challenging areas as the focus in software development, statistical modelling for software source code tries to derive the knowledge hidden in various software artifacts including code and text and help building robust systems which are intelligent. Integrated Development Environment (IDE) is one area of focus in the domain. Since this provides platform for entire software development processes, it plays key role. In this chapter, study of intelligent IDEs is extended to IoT environment context. To begin with, we focus our study on understanding the IDEs and their capability. Exploration will focus on open-source IDE for mobile, and we look for better understanding the landscape so that we can extend the learning to the IoT world. In this work, building low cost IDE for mobile is focused open. Also, interestingly, exploration focuses on open-source components and possibility of putting them together. Then, in next part, we explore the IDE for Internet of things (IoT), with focus on open source ecosystem. In this review, we extend the exploration of IoT in to device management, data management, communication, intelligent data processing, security and privacy, and application deployment areas. This gives a greater insight in to the IoT world to extend the need of intelligent IDEs to IoT world. Then, to get the context of IDE in the machine learning context, we explore the topic of building optimal IDE for feature engineering which is one of the key phases in machine learning life cycle. Since machine learning projects are highly data-oriented eco system, learning of IDE and its insights in this area will provide rich insights in to the main theme of discussion which is intelligent IDE for IoT eco system.",http://dx.doi.org/10.1007/978-981-15-7965-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-6463-5_58,The Role of Artificial Intelligence in Industry 4.0 and Smart City Development,Advances in Civil Engineering and Infrastructural Development,10.1007/978-981-15-6463-5_58,Springer,2021-01-01,"Transition is the reconstruction of the field from new fundamentals which changes the field’s common elementary theoretical concepts along with methods and applications. During transition, there will be the partial overlap between existing and new paradigms due to decisive differences. Artificial intelligence and Internet of things are unlocking the huge opportunities due to its advancements, especially in relation to smart city and its development. Artificial intelligence signifies the era of evolution in science and technology. Nowadays, the tasks which were once performed manually by human beings have been overtaken by artificial intelligence. Sixty-two percentage of enterprises will be using AI by 2018 as conformed by Narrative Science. Many researchers have quoted the opinion that artificial intelligence may have the impact more than Industrial Revolution on overall world. In this paper, it is tried to focus on industrial and economic development trend due to advancements in the urban scenario. It is tried to consolidate the fact knowledge related to technological advancements across the world. The fundamental concepts of artificial intelligence and Internet of things as a game changer are tried to extract in order to understand their suitability for proper implementation of smart city concept.",http://dx.doi.org/10.1007/978-981-15-6463-5_58,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4087-9_3,A Study on Machine Learning-Based Predictive Modelling for Pick Profiling at Distribution Centers,Proceedings of International Conference on Machine Intelligence and Data Science Applications,10.1007/978-981-33-4087-9_3,Springer,2021-01-01,"The devices business is one of the flagship units of Microsoft, and it comprises of all the hardware products offered by the company. The division houses popular products like Surface computers, Xbox gaming consoles, HoloLens VR smart glasses, and a plethora of PC Accessories (mice, keyboards etc.).This wide spectrum of offerings creates growing SKU complexity, a capital intensive supply chain, thus requiring an extensive and efficient distribution center network to provide the right service level for our customers. Operational efficiency, work force, and capacity planning at these distribution centers are critical to optimize service levels, costs, and as a result, high customer satisfaction. These centers have been plagued with recurring workforce shortages during peak seasons and below par SLA fulfilment owing to poor long-term visibility. The current planning process was partner specific, with varied methods and relied solely at using history to predict the future with adjustments made based upon intuition of the future and were essentially disconnected from using financial projections systematically. These projections have high error rates and are quite manual to build. This created a need for Microsoft’s Supply Chain to develop a robust statistics-based fully automated solution to improve pick profile predictions and automate the entire process. In this paper, we propose a multi-model solution, which uses techniques like ARIMA, Holt Winters Forecasting, like modelling, multi-variate linear regression, support vector machine (SVM), polynomial regression, random forest/decision trees in building the prediction models.",http://dx.doi.org/10.1007/978-981-33-4087-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-84529-2_41,Multi-view of Data for Auto Judge Model in Online Dispute Resolution,Intelligent Computing Theories and Application,10.1007/978-3-030-84529-2_41,Springer,2021-01-01,"Online dispute resolution (ODR) is a mechanism of solving legal or business by the online way. It was set to solve problems with less cost of attendant parities, or bring some convenience. ODR involved several information techniques to replace the traditional negotiations. Some problems for ODR as the trust problem on the judgment and the transparence of the whole process could lead negative affect on the application. Efficiency is also a key factor of the ODR system in some scenarios, like online internet courts in China and electronic commerce dispute, where there will be large piles of case generated every minute. The core factor to affect the efficiency and transparency is developing the reliable, trusty automatic judge system. In this paper, we proposed a method to build auto legal judge model from the view of ODR. This research combined information such as past information of case as well as textual evidence of the current transaction in model constructing. Experiment showed our method is effective and can have a promising scalability within the certain extent.",http://dx.doi.org/10.1007/978-3-030-84529-2_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-67490-8_4,Introduction of Blockchain and 5G-Enabled IoT Devices,Blockchain for 5G-Enabled IoT,10.1007/978-3-030-67490-8_4,Springer,2021-01-01,"The Internet of Things (IoT) paradigm has been revolutionized in recent times that handles the diversity of consumer and industrial applications, viz. smart homes, smart cities, smart grids, healthcare, agriculture, smart industries, and many more. The consumer IoT (cIoT) focuses on improving the quality of people’s lives while industrial IoT (iIoT) combines Operational Technology (OT) and Information Technology (IT) together resulting into tremendous growth of industries driven by distinct manufacturing, transportation, logistics, and functionalities. In addition to that, the fifth generation (5G) networks accelerate iIot with a higher transmission speed, a lower latency, an increased number of connected devices, and the possibility of implementing virtual networks (network slicing). The 5G- enabled IoT (5G-IoT) will connect billions of IoT devices communicating with each other in real-time manner without human interventions which leads to the deployment of a gigantic number of devices without worrying about network traffic or network related issues. However, 5G-enabled IoT devices to suffer from privacy and security issues when used with the centralized approach which is more vulnerable to attackers. To resolve the same, Blockchain stands out as a promising technology as it offers a secure, transparent, reliable, and tempered-proof environment for 5G-enabled IoT due to its distributed and peer-to-peer network architecture. Therefore, in this chapter, we introduce the basic architecture and main features of Blockchain along with how Blockchain can be integrated with 5G-enabled IoT. Subsequently, the security requirements to manage 5G-enabled IoT devices are also illustrated. Additionally, the opportunities, applications, issues and challenges, limitations and research directions of Blockchain-based 5G-enabled iIoT are explored that will be helpful to the researchers to dive into the area of IoT and Blockchain.",http://dx.doi.org/10.1007/978-3-030-67490-8_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64448-2_11,Homomorphic Encryption,Emerging Topics in Hardware Security,10.1007/978-3-030-64448-2_11,Springer,2021-01-01,"Out of all the encryption techniques available, homomorphic encryption is distinctive, and often called the Holy Grail of encryption, as it allows the manipulation of encrypted data without the need to decrypt it first. Homomorphic encryption has tremendous potential in cloud-based services such as storage, computation, artificial intelligence, location-based recommendations, etc. as it enables any entity to perform diverse operations (e.g., do search, query or sort, run mathematical functions, etc.) on the data without revealing its original content. Because of the security and privacy concerns, the full potential of cloud computing and cloud-based services is yet to be fully utilized. As full homomorphic encryption enables execution of arbitrary functions on the encrypted data while ensuring robust privacy, it can truly realize the concept of a connected world and internet-of-everything by assuring the corporate as well as the general users that their data will always remain secure and private. Although the idea of full homomorphic encryption was there since 1978, the theoretical demonstration of its practical implementation occurred relatively recently in 2009. The widespread enthusiasm in the research community that has ensued in full homomorphic encryption since then, need to be sustained to make it faster and, therefore, transparent to the regular user. In this chapter, a short review of homomorphic encryption is presented.",http://dx.doi.org/10.1007/978-3-030-64448-2_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-63505-3_8,Paths to Innovation in Supply Chains: The Landscape of Future Research,Next Generation Supply Chains,10.1007/978-3-030-63505-3_8,Springer,2021-01-01,"This chapter presents a Strategic Research and Innovation Agenda for supply chain and it is the result of an intensive work jointly performed involving a wide network of stakeholders from discrete manufacturing, process industry and logistics sector to put forward a vision to strengthen European Supply Chains for the next decade. The work is based on matching visions from literature and from experts with several iterations between desk research and workshops, focus groups and interviews. The result is a detailed analysis of the supply chain strategies identified as most relevant for the next years and definition of the related research and innovation topics as future developments and steps for the full implementation of the strategies, thus proposing innovative and cutting-edge actions to be implemented based on technological development and organisational change.",http://dx.doi.org/10.1007/978-3-030-63505-3_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-69698-6_51,Technology-Led Disruptions and Innovations: The Trends Transforming Urban Mobility,Handbook of Smart Cities,10.1007/978-3-030-69698-6_51,Springer,2021-01-01,"Over the past decade, digital innovations have challenged traditional concepts of urban transport and introduced new opportunities for improving people’s access to services and economic opportunities. In response, cities have redefined their technology roadmaps and business strategies and are increasingly encouraging more collaboration between the public and private sectors. Technology and service-led disruptions are not only impacting private car usage models, they are also enhancing multimodal journey planning and payment options which will drive new mobility initiatives in future cities. From data analytics, through to machine learning, on-demand shared mobility, Blockchain, Fog Computing, and connected vehicles, these technologies are set to transform the landscape of urban transport and reduce dependence on private cars. These technologies offer opportunities to measure and monitor city functions, manage the performance of transport infrastructure, and identify where services need improvements. This chapter discusses the role of disruptive innovations, some established and others emerging, and their impacts on transport operations. The chapter also describes how digitalization of physical assets provides opportunities to enable real-time monitoring and analysis of urban mobility and movement of freight. The chapter draws on practical applications and explains the key behavioral, societal, and technological impacts and benefits. Finally, the chapter provides insights into the potential value derived from typical use cases in smart mobility solutions enabled by technology-led innovations.",http://dx.doi.org/10.1007/978-3-030-69698-6_51,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86800-0_28,A Taxonomy of Industrial IoT Platforms’ Architectural Features,Innovation Through Information Systems,10.1007/978-3-030-86800-0_28,Springer,2021-01-01,"In the industrial Internet of Things (IIoT), the concept of digital platforms has received significant attention. Although IIoT platforms revolve around similar business objectives, they address a variety of use cases and, thus, differ considerably in their architectural setup. While research has already investigated IIoT platforms from a business or design perspective, little is known about their underlying technology stack and its implications. To unveil different IIoT platform configurations and better understand their architectural design, we systematically develop and validate a taxonomy of IIoT platforms’ architectural features based on related literature, real-world cases, and expert interviews. On this foundation, we identify and discuss four IIoT platform archetypes. Our findings contribute to the descriptive knowledge in this ambiguous research field, while also elucidating the interplay of IIoT platforms’ architectural setup and their purpose. From a managerial viewpoint, our results may guide practitioners in comparing and selecting a suitable IIoT platform.",http://dx.doi.org/10.1007/978-3-030-86800-0_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61780-6_2,e-Health: How Evolving Space Technology is Driving Remote Healthcare in Support of SDGs,Space Supporting Africa,10.1007/978-3-030-61780-6_2,Springer,2021-01-01,"e-Health is essentially not about technology, but rather can be seen as the point of convergence where advances in healthcare and ICT technologies translate into practical healthcare for those in need. Good health and wellbeing are essential to the human condition, which is largely dependent on a healthy environment and hence will be affected by unsustainable development practices. When good health is undermined through disease, measures should be in place to restore it, through the availability of quality healthcare; a reality for most in the developed world, less so for a large demographic in the developing world. e-Health is a potential game changer, offering opportunities to these underserviced areas. It is a dynamic discipline and currently a rapidly growing field driven by the very same technologies giving impetus to the Fourth Industrial Revolution. The goal of this chapter is to provide a short exploration of the pertinent technologies required by e-health, past and present, and the opportunities and challenges it presents. Space technology in particular can play a role in eliminating the barriers that are currently preventing e-health from playing a more significant role in a developing region such as sub-Saharan Africa.",http://dx.doi.org/10.1007/978-3-030-61780-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77970-2_46,Dynamic Pricing and Discounts by Means of Interactive Presentation Systems in Stationary Point of Sales,Computational Science – ICCS 2021,10.1007/978-3-030-77970-2_46,Springer,2021-01-01,The main purpose of this article was to create a model and simulate the profitability conditions of an interactive presentation system (IPS) with the recommender system (RS) used in the kiosk. 90 million simulations have been run in Python with SymPy to address the problem of discount recommendation offered to the clients according to their usage of the IPS.,http://dx.doi.org/10.1007/978-3-030-77970-2_46,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-67670-4_20,Why Did My Consumer Shop? Learning an Efficient Distance Metric for Retailer Transaction Data,Machine Learning and Knowledge Discovery in Databases. Applied Data Science and Demo Track,10.1007/978-3-030-67670-4_20,Springer,2021-01-01,"Transaction analysis is an important part in studies aiming to understand consumer behaviour. The first step is defining a proper measure of similarity, or more specifically a distance metric, between transactions. Existing distance metrics on transactional data are built on retailer specific information, such as extensive product hierarchies or a large product catalogue. In this paper we propose a new distance metric that is retailer independent by design, allowing cross-retailer and cross-country analysis. The metric comes with a novel method of finding the importance of categories of products, alternating between unsupervised learning techniques and importance calibration. We test our methodology on a real-world dataset and show how we can identify clusters of consumer behaviour.",http://dx.doi.org/10.1007/978-3-030-67670-4_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87013-3_20,Machine Learning Model for Recommending Suitable Courses of Study to Candidates in Nigerian Universities,Computational Science and Its Applications – ICCSA 2021,10.1007/978-3-030-87013-3_20,Springer,2021-01-01,"The diversity of courses and complications of admission requirements are complex tasks particularly in Nigerian Universities where a number of parameters are used during the admission process. These courses may be wrongly assigned to applicants who have not met the minimum requirements. In a previous related work, a model was developed to address this issue. However, the model considered only seven subjects out of the mandatory nine subjects required of every senior secondary school student to register (O’Level). Such a decision may be to the detriment to the candidates because credits may be required from those subjects that were not considered. This paper tends to enhance the existing model to address all these issues. Grade of nine Secondary school subjects, the aggregate score of Unified Tertiary Matriculation Examination (UTME) and post-UTME, and catchment area are used as parameters in this study. The results were obtained when various reference classifiers were trained and tested using the processed dataset of the O’Level and JAMB results of candidates seeking admission into the university. Individual classifiers namely, Logistic Regression, Naive Bayes, Decision Tree, K-Nearest Neighbor, and Random Forest were trained and evaluated using reference performance metrics namely precision, recall, and f1-score. The resulting best classifier, the Random Forest, has shown to be correct 94.94% of the time and is capable of detecting correctly 94.17% of the classes. Since the precision and recall are similar in value, the f1-score tends to favor this classifier also with a value of 93.19%.",http://dx.doi.org/10.1007/978-3-030-87013-3_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85447-8_54,Developing Machine Learning Model for Predicting Social Media Induced Fake News,Responsible AI and Analytics for an Ethical and Inclusive Digitized Society,10.1007/978-3-030-85447-8_54,Springer,2021-01-01,"Fake news has been associated with major global events such as Covid-19 and the political polarisation of the US presidential election in 2016. This paper investigates how fake news has affected society and advance understanding of the nature of its impact in the future of democratic societies. Taken from large datasets consisting of over 23,000 fake news story words and over 21,000 true news story words we use descriptive and predictive analytics, partly analysing more than 350 words during the selected period of October 2016 to April 2017. The findings show that Trump was the most popular word for both true and fake news. In this study, we compare and contrast the words used and the volume of true versus fake news stories related to the election and the inauguration. This study makes an important contribution as it develops a predictive model that highlights the severity of political polarization and its consequences in democratic societies, which inevitably have implications for inclusive societies in the 21 st century.",http://dx.doi.org/10.1007/978-3-030-85447-8_54,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72331-6_16,"Digital Supply Chain, Smart Operations and Industry 4.0",Global Supply Chain and Operations Management,10.1007/978-3-030-72331-6_16,Springer,2021-01-01,"The supply chain is as good as the digital technology behind it. This chapter is devoted to the digitalization of supply chain and operations management (SCOM). The chapter starts with the concept of SCOM excellence and continues with fundamental definitions of digital supply chains and operations. We define and explain Industry 4.0 principles and technology. Subsequently, digital technology classifications of SCOM are presented in terms of the SCOR model. Decision-making support improvements in the digital SCOM framework are discussed from qualitative and quantitative perspectives.",http://dx.doi.org/10.1007/978-3-030-72331-6_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66633-0_14,Implementation of the Internet of Medical Things (IoMT): Clinical and Policy Implications,Efficient Data Handling for Massive Internet of Medical Things,10.1007/978-3-030-66633-0_14,Springer,2021-01-01,"Recent advances in computing, data storage, and sensors match up to the rate of increase in medical research, venture capital, and private equity investments in healthcare. These, much like the larger healthcare ecosystem, currently work in silos across therapy areas and geographies with minimal integration. Furthermore, they are subjected to less oversight and scrutiny than other clinical interventions such as diagnostics, medical devices, and therapeutic agents. Regulatory and policy interventions are critical to ensure the efficacy and safety of these new solutions including outcome tracking and risk mitigation; clinical standards, regulatory processes, and oversight; managing biases; and accountability and medicolegal liability. Another key component is navigating the complex ecosystem and all its stakeholders. This chapter explores the impact of IoMT on the key stakeholders, patients, physicians, providers, payors, government, and regulators and touches on some of the best practices from across the world.",http://dx.doi.org/10.1007/978-3-030-66633-0_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-5936-2_2,ML and Information Advancement Platform in Intelligent IoT,Computationally Intensive Statistics for Intelligent IoT,10.1007/978-981-16-5936-2_2,Springer,2021-01-01,"Given the prevalence of IoT applications, the scarcity of adaptive learning systems is a deterrent to the multiplication of smart IoT structures. Nothing is examined as to how computers will exchange knowledge independently where the information arrives from various applications. This section, therefore, suggests a paradigm for how nodes will share information independently, produce innovative information, and understand from expertise adaptively, in such a way that they will be relevant through various applications. The structure is drawn from the way how information is acquired and categorized by individuals. To start with, this research discusses the different techniques relevant to IoT smart big data analysis.",http://dx.doi.org/10.1007/978-981-16-5936-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66661-3_11,Legal Tech and Lawtech: Towards a Framework for Technological Trends in the Legal Services Industry,Market Engineering,10.1007/978-3-030-66661-3_11,Springer,2021-01-01,"The use of legal technology (legal tech) and the lawtech ecosystem of legal start-ups has experienced tremendous growth in recent years. To provide a structured approach of analysing IT innovations in the legal sector, we propose a framework for lawtech applications, classifying them into three groups: internal, B2C and B2B applications. In the context of this framework, we examine technological trends in lawtech and their potential to support and transform processes in specific areas of business or personal law. We acknowledge that within lawtech there is a gap between the areas of interest of legal practitioners, IT professionals and academic researchers, and that some areas have received considerable attention by these groups, while other areas have been left relatively unexplored by one or more of these groups. However, the growing interest by legal practitioners in advanced technology such as artificial intelligence (AI) and natural language processing (NLP) is further closing the gap between academic research, IT professionals and legal practice.",http://dx.doi.org/10.1007/978-3-030-66661-3_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_102,HCRDL: A Hybridized Approach for Course Recommendation Using Deep Learning,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_102,Springer,2021-01-01,"Nowadays, the abundant availability of online courses which are powered by well-known Universities puts students in a dilemma in choosing the appropriate course according to their interests. To overcome this situation, Recommender Systems are used to make the job easy for the students to pick courses and pursue it. This paper proposes a hybrid Recommender System which helps in recommending online courses for the students based on their queries and interests. The hybrid model integrates RNN, LSTM, N-Gram, and Jaccard similarity to provide better results in terms of accuracy than the available models. Especially, the usage of RNN and LSTM paved its way for giving better accuracy with the help of Jaccard similarity. The proposed HCRDL model has achieved an average F-Measure of 96.31% and tends to perform better than the other models by attenuating the weakness of the common course recommender models.",http://dx.doi.org/10.1007/978-3-030-71187-0_102,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58703-1_7,Network System’s Vulnerability Quantification Using Multi-layered Fuzzy Logic Based on GQM,National Cyber Summit (NCS) Research Track 2020,10.1007/978-3-030-58703-1_7,Springer,2021-01-01,"Network security is one of the crucial components of an organization’s security system. Much research has been conducted to come up with a clear-cut approach in order to quantify organizations’ network system vulnerabilities. Many security standards such as NIST SP-800 and ISO 27001 with the guidelines and clauses are published with a reasonable outline to pave the ground for a safe track towards secure system design, however, these standards do not clearly show the details of work implementation. In this paper, we apply Fuzzy Logic methodology to quantify each factor and sub-factors derived using Goal Question Metrics in network security. Our procedure follows a bottom-up hierarchy model from the details of a security component to the desired goal in order to address vulnerabilities in a quantified manner in the Department of Transportation. Thus, our approach measures different types of potential vulnerabilities in a network.",http://dx.doi.org/10.1007/978-3-030-58703-1_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72777-2_18,The Intersection of Blockchain and 6G Technologies,6G Mobile Wireless Networks,10.1007/978-3-030-72777-2_18,Springer,2021-01-01,"The fifth generation (5G) wireless networks are on the way to be deployed around the world. The 5G technologies target to support diverse vertical applications by connecting heterogeneous devices and machines with drastic improvements in terms of high quality of service, increased network capacity and enhanced system throughput. However, 5G systems still remain a number of security challenges that have been mentioned by researchers and organizations, including decentralization, transparency, risks of data interoperability, and network privacy vulnerabilities. Furthermore, the conventional techniques may not be sufficient to deal with the security requirements of 5G. As 5G is generally deployed in heterogeneous networks with massive ubiquitous devices, it is quite necessary to provide secure and decentralized solutions. Motivated from these facts, in this paper we provide a state-of-the-art survey on the integration of blockchain with 5G networks and beyond. In this detailed survey, our primary focus is on the extensive discussions on the potential of blockchain for enabling key 5G technologies, including cloud computing, edge computing, Network Function Virtualization, Network Slicing, and D2D communications. We then explore and analyse the opportunities that blockchain potentially empowers important 5G services, ranging from spectrum management, data sharing, network virtualization, resource management to interference management, federated learning, privacy and security provision. The recent advances in the applications of blockchain in 5G Internet of Things are also surveyed in a wide range of popular use-case domains, such as smart healthcare, smart city, smart transportation, smart grid and UAVs. The main findings derived from the comprehensive survey on the cooperated blockchain-5G networks and services are then summarized, and possible research challenges with open issues are also identified. Lastly, we complete this survey by shedding new light on future directions of research on this newly emerging area.",http://dx.doi.org/10.1007/978-3-030-72777-2_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85874-2_29,Worker in the Loop: A Framework for Enabling Human-Robot Collaborative Assembly,Advances in Production Management Systems. Artificial Intelligence for Sustainable and Resilient Production Systems,10.1007/978-3-030-85874-2_29,Springer,2021-01-01,"Industry has taken a big leap forward by placing a human in the center of interest by turning the working areas into a collaborative environment between operators and robots. In this environment, human behavior is a major uncertainty factor that can affect operator’s safety and execution status. Furthermore, the creation of a digital twin including the whole workstation area, the operators and the procedures that take part in there, is a way to design and integrate collaborative systems using a virtual space. This paper aims to overview the current state of the technological trends in human detection, human task monitoring and digital twin integration. Also, the design of the upcoming solution of a case study from the automotive industry will be represented.",http://dx.doi.org/10.1007/978-3-030-85874-2_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86365-4_17,Parameterized Hypercomplex Graph Neural Networks for Graph Classification,Artificial Neural Networks and Machine Learning – ICANN 2021,10.1007/978-3-030-86365-4_17,Springer,2021-01-01,"Despite recent advances in representation learning in hypercomplex (HC) space, this subject is still vastly unexplored in the context of graphs. Motivated by the complex and quaternion algebras, which have been found in several contexts to enable effective representation learning that inherently incorporates a weight-sharing mechanism, we develop graph neural networks that leverage the properties of hypercomplex feature transformation. In particular, in our proposed class of models, the multiplication rule specifying the algebra itself is inferred from the data during training. Given a fixed model architecture, we present empirical evidence that our proposed model incorporates a regularization effect, alleviating the risk of overfitting. We also show that for fixed model capacity, our proposed method outperforms its corresponding real-formulated GNN, providing additional confirmation for the enhanced expressivity of HC embeddings. Finally, we test our proposed hypercomplex GNN on several open graph benchmark datasets and show that our models reach state-of-the-art performance while consuming a much lower memory footprint with 70 $$\%$$ % fewer parameters. Our implementations are available at https://github.com/bayer-science-for-a-better-life/phc-gnn .",http://dx.doi.org/10.1007/978-3-030-86365-4_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-46197-3_20,Yajna and Mantra Science on Healthcare Domain: A Futuristic Scientific Approach with Indian Scenario,Fog Computing for Healthcare 4.0 Environments,10.1007/978-3-030-46197-3_20,Springer,2021-01-01,"There is considerable interest in the knowledge of the bees with the -OM symbol, the word OM is considered the beginning and end of the past and future. OM’s motto is the reality of the world and the human body, a subtle understanding of the mind, emotions, thoughts, and beliefs in our lives. According to Indian philosophy, OM is a spiritual symbol called Atman Brahman (Reality, World, Truth, God, Supreme Spirit, Cosmic Principles, and Knowledge). This research has the symbol of global OM. The purpose of this study was to evaluate the impact of Gayatri Mantra recitation and Om recitation on human health. Gayatri mantra is a highly potential mantra, which is mentioned in Rig Veda. The study/Yagyopathy Experiment was performed on some patients (Male = 4) and (Females = 7) with an age range of 44–70 years. All patients were trained for reciting Gayatri mantra for 3 days. The baseline data were used. The participants participated in Gayatri mantra and Om recitation about 15 min for two consecutive days. The sequence of the session was assigned randomly to the participants. This preliminary study shows that both Gayatri mantras and sitting comfort have led to increased attention, as measured by the stroop task. However, Gayatri’s mantra effect was significantly greater than Om’s recitation. During the meeting on yagyopathy chaired by Shraddhey Dr. Sahab at Shantikunj on 23 Nov 18, Prof. Rohit Rastogi volunteered to experiment its effects on himself. I consulted Dr. Vandana Srivastava and was advised following treatment: yagyopathy twice a day, at sunrise and sunset, with havan samagri for asthma and normal samagri in 3:1 ratio, recitation of Surya Gayatri mantra 24 times and nadi-shodhan pranayama for 30 min. Kwath of mixed hawan samagri twice a day. In order to measure the efficacy of Yagyopathy, I undertook Lung Function Test (LFT) on 18 Dec 18 and started yagyopathy as above instructions (once a day) since 24 Dec 18. Following, three important parameters are measured during LFT: Forced Vital Capacity (FVC): a measure of lung capacity/volume of air can open after Deep inhalation. Forced expiratory volume 1 s (FEV1): Breath measurement. FEV1/FVC: The ratio of lung size (FVC) that expires in seconds. The results obtained after undertaking yagyopathy treatment once a day for approximately 2 1/2 months indicated considerable improvement in lung function parameters. Results can be further improved with increasing treatment doses to twice a day.",http://dx.doi.org/10.1007/978-3-030-46197-3_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-7658-4_4,Social Innovation Business Through Value Co-creation with Customers Powered by Lumada: A Case Study of Hitachi Ltd.,Business Innovation with New ICT in the Asia-Pacific: Case Studies,10.1007/978-981-15-7658-4_4,Springer,2021-01-01,"Hitachi is a unique company which has accumulated manufacturing expertise, ICT and operational technology since its founding more than a century ago. Hitachi is now evolving its Social Innovation Business through digital technology and accelerating collaborative value creation with customers. One of key success factors is Lumada: Hitachi’s IoT core platform providing advanced digital solutions, services, and technologies for turning customers’ data into insights to drive digital innovation. This chapter introduces how Lumada contributes to value co-creation with customers in the era of AI/IoT.",http://dx.doi.org/10.1007/978-981-15-7658-4_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-46197-3_21,"The Interoperability of Fog and IoT in Healthcare Domain: Architecture, Application, and Challenges",Fog Computing for Healthcare 4.0 Environments,10.1007/978-3-030-46197-3_21,Springer,2021-01-01,"The great technological advances and rapid growth in the physical objects being connected to the Internet have led to the emergence of the term “Internet of Things” (IoT). IoT has an impact on almost all areas like construction, business, data analytics, e-commerce, agriculture, transportation, and healthcare. Maintenance of such a system can be done by the cloud computing but due to issues like long processing times, slow responses, and privacy issues, it is not preferred in real-time systems. IoT with its integration with fog computing can resolve problems like slow responses, delays, privacy, and security issues in healthcare systems. This chapter discusses the IoT and fog computing, their architecture, their application domains, and their integration and importance in healthcare. A literature survey involving all the works that include fog and IoT is discussed. Case studies involving fog and IoT in healthcare systems are also presented to provide light on how fog and IoT eliminate pressures on healthcare systems that require real-time processing.",http://dx.doi.org/10.1007/978-3-030-46197-3_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85447-8_7,Adopting Artificial Intelligence in the Saudi Arabian Public Sector: Preliminary Findings,Responsible AI and Analytics for an Ethical and Inclusive Digitized Society,10.1007/978-3-030-85447-8_7,Springer,2021-01-01,"Artificial Intelligence (AI) has received significant attention in recent years, with claims of unlimited potential across sectors and industries. Despite the media hype about AI, there is limited understanding of how governments can utilize AI for the delivery of value to citizens and what are the barriers and trade-offs that need to be addressed to lead to value realization. AI has the potential to bring transformative benefits to society, but first we need to understand the current state of play in the public sector through an appropriate theoretical lens. We adopt the attention-based view of the organization to identify key challenges in terms of organizational attention. This study draws on a single case study in Saudi Arabia to identify key challenges associated with the adoption of AI.",http://dx.doi.org/10.1007/978-3-030-85447-8_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11263-020-01369-0,Scene Text Detection and Recognition: The Deep Learning Era,International Journal of Computer Vision,10.1007/s11263-020-01369-0,Springer,2021-01-01,"With the rise and development of deep learning, computer vision has been tremendously transformed and reshaped. As an important research area in computer vision, scene text detection and recognition has been inevitably influenced by this wave of revolution, consequentially entering the era of deep learning. In recent years, the community has witnessed substantial advancements in mindset, methodology and performance. This survey is aimed at summarizing and analyzing the major changes and significant progresses of scene text detection and recognition in the deep learning era. Through this article, we devote to: (1) introduce new insights and ideas; (2) highlight recent techniques and benchmarks; (3) look ahead into future trends. Specifically, we will emphasize the dramatic differences brought by deep learning and remaining grand challenges. We expect that this review paper would serve as a reference book for researchers in this field. Related resources are also collected in our Github repository ( https://github.com/Jyouhou/SceneTextPapers ).",http://dx.doi.org/10.1007/s11263-020-01369-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5859-7_54,"Crossing the Artificial Intelligence (AI) Chasm, Albeit Using Constrained IoT Edges and Tiny ML, for Creating a Sustainable Food Future",Proceedings of Fifth International Congress on Information and Communication Technology,10.1007/978-981-15-5859-7_54,Springer,2021-01-01,"Big data surrounds us. Every minute, our smartphone collects huge amount of data from geolocations to next clickable item on the e-commerce site. Data has become one of the most important commodities for the individuals and companies. Nevertheless, this data revolution has not touched every economic sector, especially rural economies; e.g., small farmers have largely passed over the data revolution, in the developing countries due to infrastructure and constrained compute environments. Not only this is a huge missed opportunity for the big data companies, but it is one of the significant obstacles in the path toward sustainable food and a huge inhibitor closing economic disparities. The purpose of the paper is to develop a framework to deploy artificial intelligence models in constrained compute environments that enable remote rural areas and small farmers to join the data revolution and start contribution to the digital economy and empower the world through the data to create a sustainable food for our collective future. In a nutshell, close the digital gap by crossing the AI chasm to democratize AI for poor and helpless farmers and help ourselves by creating sustainable food future.",http://dx.doi.org/10.1007/978-981-15-5859-7_54,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-8342-1_6,Opportunities and Challenges for Biometrics,China’s e-Science Blue Book 2020,10.1007/978-981-15-8342-1_6,Springer,2021-01-01,"Biometrics refers to the science and technology of automatic identification achieved by computers through acquiring and analyzing physiological and behavioral characteristics of human body. The purpose of biometrics research is to give computers advanced intelligence to automatically detect, capture, process, analyze, and identify digital biometric signals, that is, make machines “can see and hear”. This is one of the basic functions of machine intelligence as well as one of the most significant challenges in theoretical and applied research human beings face. In conclusion, biometrics research is important in terms of both academic significance and practical value. In recent years biometrics has become an important part of national strategies such as the “Internet + Action Plan” and the “Development Plan on the New Generation of Artificial Intelligence”. At the same time, it has already become a new growth point for strategic high-tech and electronic information industry in the field of national and public security. This paper introduces research progress of several common biometric modalities such as face, iris, fingerprint and gait, summarizes development trends and opportunities of current biometrics technology, and analyzes main challenges on the road to the development of a new generation of biometrics. Finally, this paper provides some suggestions regarding the future development of biometrics.",http://dx.doi.org/10.1007/978-981-15-8342-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_106-1,IT and Well-Being in Travel and Tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_106-1,Springer,2021-01-01,"Accelerating levels of stress and chronic disease have urged travellers to seek products and experiences that promote a holistic healthy living. However, in the context of increasingly integrated online and offline experiences, where technology does not always work in concert with human nature, tourists are facing the challenge of finding about how to best live a connected life. With travel being one of the most stress-inducing experiences we voluntarily subject ourselves to, tourism players are taking advantage of the latest technology to respond to the travellers’ changing needs and values, by designing innovative experiences that promote overall well-being. This chapter provides a review of the existing research on well-being related to the travel and tourism sector, while focusing on the link with technology advancements, especially the dual perspective of unplugging and intense technology use. As in all great technological revolutions, the digital traveller’s life may potentially unveil a dark side. However, the general consensus is that the positives of using technology within the travel and tourism sector will continue to outweigh the negatives. The chapter focuses on highlighting the different types of technology used to support the traveller’s state of well-being, as well as the role and impact of technology in relation to well-being while travelling.",http://dx.doi.org/10.1007/978-3-030-05324-6_106-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71055-2_5,An Architecture for the Development of Distributed Analytics Based on Polystore Events,"Heterogeneous Data Management, Polystores, and Analytics for Healthcare",10.1007/978-3-030-71055-2_5,Springer,2021-01-01,"To balance the requirements for data consistency and availability, organisations increasingly migrate towards hybrid data persistence architectures (called polystores throughout this paper) comprising both relational and NoSQL databases. The EC-funded H2020 TYPHON project offers facilities for designing and deploying such polystores, otherwise a complex, technically challenging and error-prone task. In addition, it is nowadays increasingly important for organisations to be able to extract business intelligence by monitoring data stored in polystores. In this paper, we propose a novel approach that facilitates the extraction of analytics in a distributed manner by monitoring polystore queries as these arrive for execution. Beyond the analytics architecture, we presented a pre-execution authorisation mechanism. We also report on preliminary scalability evaluation experiments which demonstrate the linear scalability of the proposed architecture.",http://dx.doi.org/10.1007/978-3-030-71055-2_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-82318-4_4,"The Future of the Automated City: Social, Technical and Ethical Perspectives",The Automated City,10.1007/978-3-030-82318-4_4,Springer,2021-01-01,"The previous chapter discussed particular issues in relation to Automated Vehicles, urban robots and urban drones. This chapter discusses visions, perspectives and challenges of the Automated City more generally, including aspirational visions of future cities, what must be overcome or addressed towards a favourable notion of the Automated City, and issues of governance, new business models, city transportation, sustainability, real-time tracking, urban edge computing, blockchain, technical challenges of cooperation, and trust, fairness and ethics in relation to AI and algorithms in the city—we elaborate on the last two aspects in more detail.",http://dx.doi.org/10.1007/978-3-030-82318-4_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-78645-8_69,Smart 3D Simulation of Covid-19 for Evaluating the Social Distance Measures,HCI International 2021 - Posters,10.1007/978-3-030-78645-8_69,Springer,2021-01-01,"The aim of this research is to model and simulate the recent and ongoing COVID19 pandemic in terms of virus contagiousness among mixed groups of patients, carriers and unaffected individuals when taking into consideration closed environments (such as malls or schools) which are ideal environments for the spread of COVID19. Machine learning techniques are utilized to model, analysis and predicate the behavior of COVID virus when spreading among human clusters. This prediction model will be used to develop a simulation environment for viewing the propagation of the COVID19 virus under different circumstances related to the type and size of the human gatherings while taking into consideration the spatiotemporal aspects of the crowd. Reinforcement learning techniques is used to train and deploy intelligent human agents that mimic the behavior of humans in real-world setting. By using 3D graphics technology, we are hoping to add a visualization aspect to the simulation to further enhance the usability and engagement level of the simulation, and to provide authorities and non-specialist people with a beneficial experience that aids them in terms of decision-making regarding future spreading of the virus under customizable lockdown scenarios.",http://dx.doi.org/10.1007/978-3-030-78645-8_69,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-67032-0_7,Business Intelligence Technologies,Business Intelligence,10.1007/978-3-030-67032-0_7,Springer,2021-01-01,"As BI technologies are covered in great detail in many sources, this chapter is more of an overview nature. Its goal is to cover the landscape of the most important BI technologies regarding their placement in BI value chain, and to expose their most important benefits and limitations. The technologies reviewed in this chapter are: data collection and storage; multidimensional data analysis and OLAP; self-service tools; business analytics including data mining and Big Data analytics; modeling and simulation; text analytics; presentation and visualization; artificial intelligence (AI) and machine learning (ML); communication and collaboration platforms; and technology deployment issues. The field is developing rapidly, and it is nearly impossible to keep up with the latest innovations in a book that takes time to be published. For example, artificial intelligence technologies currently are experiencing a substantial rise; however, the corresponding paragraph in this chapter is rather brief—there are many sources that can give much more detailed descriptions and explanations. Some of the established BI technologies, however, have firmly found their place in corporate information activities, and the author hopes that their coverage in this book is sufficiently complete.",http://dx.doi.org/10.1007/978-3-030-67032-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72628-7_17,Artificial Intelligence in Computer-Aided Auditing Techniques and Technologies (CAATTs) and an Application Proposal for Auditors,Auditing Ecosystem and Strategic Accounting in the Digital Era,10.1007/978-3-030-72628-7_17,Springer,2021-01-01,"Digital transformation is the modification resulting from new opportunities technological advancements in all areas of life presents. These new technologies are also used in audit activities. These new technologies used in audit activities are called Computer Assisted Audit Tools and Techniques (CAATTs). Those have emerged to help auditors look for irregularities in data files and to enable more analyses to be done in less time with more evidence at a lower risk level. By using CAATTs, the auditor is able to filter, define and create equations, identify gaps, make statistical analysis, identify peer records, classify, sort, summarize, merge, and match. The fact that the auditor reaches the results by analyzing the sample chosen in the audit activities may cause the concerned parties to approach these results with suspicion. Instead of selecting and analyzing samples, using CAATTs, the auditor may also analyze the entire data. Concurrent with new technological developments, the scope of CAATTs applications is also advancing. Artificial Intelligence (AI), as an automated system that can generate algorithms, occupies a center stage in these developments. It is observed that 4 concepts are emphasized for AI. These concepts are acting like human, thinking like human, rational thinking, and rational behavior. These factors facilitated the inclusion of AI in audit activities. The emergence of AI will include human-like activities in the auditing process. In general, it is considered that the technology applied to the audit allows the activities to be carried out more effectively. In reality, there are contradictions about the use of AI in audit activities. Some researchers support the use of this new technology in the auditing process, while others are skeptical. Those, who view the use of AI with skepticism, state that the professional judgment of the auditor can be ignored with the utilization of AI. For this reason, how to limit the use of AI in audit activities is discussed. Firstly, the study explains CAATTs applications and the concept of AI and how AI is included in accounting and auditing activities. Secondly, the advantages and disadvantages of using AI in the auditing processes are evaluated. Lastly, the use of AI and CAATTs in audit process and specific application suggestions for different audit areas are discussed in detail in the context of suggested audit batches.",http://dx.doi.org/10.1007/978-3-030-72628-7_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71704-9_1,Phoenix: A Scalable Streaming Hypergraph Analysis Framework,Advances in Data Science and Information Engineering,10.1007/978-3-030-71704-9_1,Springer,2021-01-01,"We present Phoenix, a scalable hypergraph analytics framework for data analytics and knowledge discovery that was implemented on the leadership class computing platforms at Oak Ridge National Laboratory (ORNL). Our software framework comprises a distributed implementation of a streaming server architecture which acts as a gateway for various hypergraph generators/external sources to connect. Phoenix has the capability to utilize diverse hypergraph generators, including HyGen, a very large-scale hypergraph generator developed by ORNL. Phoenix incorporates specific algorithms for efficient data representation by exploiting hidden structures of the hypergraphs. Our experimental results demonstrate Phoenix’s scalable and stable performance on massively parallel computing platforms. Phoenix’s superior performance is due to the merging of high-performance computing with data analytic.",http://dx.doi.org/10.1007/978-3-030-71704-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-80737-5_9,Big Data and Artificial Intelligence to Support Risk Management: A Systematic Literature Review,"Intellectual Capital, Smart Technologies and Digitalization",10.1007/978-3-030-80737-5_9,Springer,2021-01-01,"The corporate downfalls of the early 2000s, the global financial crisis of the last years, and the recent outbreak of the COVID-19 pandemic have pushed companies into making efforts to improve Risk Management (RM) practices (PwC, 2020). RM covers different applications and technological fields, involves both business and operational aspects, and affects all sectors at various levels and with different magnitudes. From an Information Technology (IT) perspective, RM can have dual value (Sanford & Moosa, 2015): (1) operational RM and (2) data availability to applications, digital services, and lines of business. This last aspect is perhaps the most critical, especially today in the era of big data (BD), where application tasks are increasingly data intensive (Martínez-Rojas et al., 2018). For this reason, it is becoming increasingly important to invest in data to model cross-cutting RM solutions and strategies that find the right support in infrastructure (Dicuonzo et al., 2019; Sundhararajan et al., 2018).",http://dx.doi.org/10.1007/978-3-030-80737-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66661-3_7,"Engineering Energy Markets: The Past, the Present, and the Future",Market Engineering,10.1007/978-3-030-66661-3_7,Springer,2021-01-01,"Since the beginning of the energy sector liberalization, the design of energy markets has become a prominent field of research. Markets nowadays facilitate efficient resource allocation in many fields of energy system operation, such as plant dispatch, control reserve provisioning, delimitation of related carbon emissions, grid congestion management, and, more recently, smart grid concepts and local energy trading. Therefore, good market designs play an important role in enabling the energy transition toward a more sustainable energy supply for all. In this chapter, we retrace how market engineering shaped the development of energy markets and how the research focus shifted from national wholesale markets to more decentralized and location-sensitive concepts.",http://dx.doi.org/10.1007/978-3-030-66661-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5869-6_5,Prosocial or Selfish? Agents with Different Behaviors for Contract Negotiation Using Reinforcement Learning,Advances in Automated Negotiations,10.1007/978-981-15-5869-6_5,Springer,2021-01-01,"We present an effective technique for training deep learning agents capable of negotiating on a set of clauses in a contract agreement using a simple communication protocol. We use Multi-Agent Reinforcement Learning to train both agents simultaneously as they negotiate with each other in the training environment. We also model selfish and prosocial behavior to varying degrees in these agents. Empirical evidence is provided showing consistency in agent behaviors. We further train a meta-agent with a mixture of behaviors by learning an ensemble of different models using reinforcement learning. Finally, to ascertain the deployability of the negotiating agents, we conducted experiments pitting the trained agents against human players. Results demonstrate that the agents are able to hold their own against human players, often emerging as winners in the negotiation. Our experiments demonstrate that the meta-agent is able to reasonably emulate human behavior.",http://dx.doi.org/10.1007/978-981-15-5869-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85447-8_21,Ethics in AI,Responsible AI and Analytics for an Ethical and Inclusive Digitized Society,10.1007/978-3-030-85447-8_21,Springer,2021-01-01,"The launch of various AI systems has been one of the main highlights of the industry. Alongside the enormous and revolutionary benefits, AI can cause numerous problems (usually resulting from poor design) and people have recently started to get serious about researching ways to make AI safer. Many of the AI safety concerns sound like science fiction, problems that might occur with very strong AI systems that are still years away, making these issues difficult to investigate. We don’t know what such potential AI systems would be like, but similar issues exist with AI systems that are currently in progress or even running in the real world. The author addresses the possible implications in this article, outlining some important approaches in terms of software development methodologies and philosophy that we can start working on right now to support us with current AI systems and, hopefully, future systems",http://dx.doi.org/10.1007/978-3-030-85447-8_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74296-6_18,MPIA: Multiple Preferences with Item Attributes for Graph Convolutional Collaborative Filtering,Web Engineering,10.1007/978-3-030-74296-6_18,Springer,2021-01-01,"Personalized recommender systems are playing an increasingly critical role in a variety of online applications. In recent years, advancements in graph-structured deep neural networks have attracted considerable interest and achieved state-of-the-art performance on recommender system benchmarks. However, existing graph-based recommendation methods generally characterize each user with just one representation vector, which is insufficient to convey diverse preferences of users. To address this issue, in this paper, we approach the learning of user representations from a different perspective, by modeling users based on multiple representation embeddings. We propose a Multiple Preferences with Item Attributes for Graph Convolutional Collaborative Filtering (MPIA) framework built upon the message-aggregation concept of graph neural networks, which can generate preference-specific user representations to better model the diverse preferences of users. By taking advantage of graph representation learning techniques, MPIA learns preference-specific embeddings for users and attribute-specific embeddings for items. Moreover, we utilize shared embeddings for user and item representations to obtain the commonalities in multiple networks. Specifically, we construct a user-item bipartite graph for each preference, and enrich the representation of each node with the topological structure and features of its neighbors. We also design a preference-attribute fusion method to acquire more accurate item retrievals for every aspect of interest. Extensive experiments conducted on three real-world datasets demonstrate the effectiveness of the proposed MPIA framework.",http://dx.doi.org/10.1007/978-3-030-74296-6_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86800-0_5,Leveraging the Potentials of Federated AI Ecosystems,Innovation Through Information Systems,10.1007/978-3-030-86800-0_5,Springer,2021-01-01,"Deep learning increasingly receives attention due to its ability to efficiently solve various complex prediction tasks in organizations. It is therefore not surprising that more and more business processes are supported by deep learning. With the proliferation of edge intelligence, this trend will continue and, in parallel, new forms of internal and external cooperation are provided through federated learning. Hence, companies must deal with the potentials and pitfalls of these technologies and decide whether to deploy them or not and how. However, there currently is no domain-spanning decision framework to guide the efficient adoption of these technologies. To this end, the present paper sheds light on this research gap and proposes a research agenda to foster the potentials of value co-creation within federated AI ecosystems.",http://dx.doi.org/10.1007/978-3-030-86800-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-4936-6_9,Performance Improvement of Heterogeneous Cluster of Big Data Using Query Optimization and MapReduce,Information Management and Machine Intelligence,10.1007/978-981-15-4936-6_9,Springer,2021-01-01,"The information volumes are bursting, and more data has been created in the past couple of years than in the past history of the human race. Data is growing faster than ever before and by the year 2020, about 1.7 megabytes of fresh information is going to be created every second for each and every person on Earth. So we need a platform to process the large volume of complex information process hardware as well as software. MapReduce frame has received large popularity because of scalable distributed network atmosphere for productive processing of high scale info from this arrangement of Terabytes or longer. Hadoop, open-source implementation of MapReduce combined with Hadoop distributed file system, is broadly applied to encourage bunch computing tasks demanding non-response period. The recent Hadoop implementation supposes the nodes at the bunch have been homogenous in character. In this paper, we proposed a new algorithm to fix these issues for the commercial as well as non-commercial uses can enable the betterment of the community. We have conducted the experiment to establish that if a procedure is defined to handle the different use case situations, an individual could overall decrease the expense of computing and can benefit on relying on distributed systems for rapid executions.",http://dx.doi.org/10.1007/978-981-15-4936-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-01916-6_1,Introduction,Designing and Building Enterprise Knowledge Graphs,10.1007/978-3-031-01916-6_1,Springer,2021-01-01,"Enterprise data management needs to evolve. Consider the following example: “The Van Buren Bank has felt the effects of deregulation which made the once stable banking industry highly competitive. With the decreased spread between borrowing and lending rates, profits on loans have dwindled, making profit on services to customers critical. In the corporate banking group, account managers who in the past could concentrate only on loan volumes must now focus on customer and product profitability. This means they must make decisions differently and need different kinds of information. For example, if a long-tim customer threatens to take his or her business elsewhere unless he or she is given an unusually low interest loan, the account manager must decide whether this is an otherwise profitable customer in terms of his or her total business with the bank.",http://dx.doi.org/10.1007/978-3-031-01916-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83803-4_6,The Four Paradigm Model in Action,Digital Cultural Transformation,10.1007/978-3-030-83803-4_6,Springer,2021-01-01,"As the sociocultural mindset described by the DTSM appears to be key to achieve a successful DT, it becomes of particular relevance having a tool to verify an institution’s DTSM profile and to measure its areas of strengths and improvement. This chapter puts the conceptual base of the DTSM and FPM into action by introducing the original 12 profile points holistic tool of the FPM Radar and its preparatory step, the FPM Board. The FPM Board is a visualization board of web-content screenshots, to analyse in a strategic-organizational perspective an institution’s transformative ‘sociocultural soul’. Its original, qualitative design-thinking approach allows institutions to run self-analyses and competitive studies across any sector. The FPM Radar is the quantitative side of it, being a grading assessment tool to measure the level of DTSM and a tool to visualize at-a-glance the DTSM profile of an institution. Examples and case studies help illustrating the methodological process, guiding the reader to apply the model.",http://dx.doi.org/10.1007/978-3-030-83803-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86797-3_18,ArgueBot: A Conversational Agent for Adaptive Argumentation Feedback,Innovation Through Information Systems,10.1007/978-3-030-86797-3_18,Springer,2021-01-01,"By combining recent advances in Natural Language Processing and Conversational Agent (CAs), we suggest a new form of human-computer interaction for individuals to receive formative feedback on their argumentation to help them to foster their logical reasoning skills. Hence, we introduce ArgueBot, a conversational agent, that provides adaptive feedback on students’ logical argumentation. We, therefore, 1) leveraged a corpus of argumentative student-written peer-reviews in German, 2) trained, tuned, and benchmarked a model that identifies claims, premises and non-argumentative sections of a given text, and 3) built a conversational feedback tool. We evaluated ArgueBot in a proof-of-concept evaluation with students. The evaluation results regarding technology acceptance, the performance of our trained model, and the qualitative feedback indicate the potential of leveraging recent advances in Natural Language Processing for new human-computer interaction use cases for scalable educational feedback.",http://dx.doi.org/10.1007/978-3-030-86797-3_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-8531-6_7,Deep Learning for Bias Detection: From Inception to Deployment,Data Mining,10.1007/978-981-16-8531-6_7,Springer,2021-01-01,"To create a more inclusive workplace, enterprises are actively investing in identifying and eliminating unconscious bias (e.g., gender, race, age, disability, elitism and religion) across their various functions. We propose a deep learning model with a transfer learning based language model to learn from manually tagged documents for automatically identifying bias in enterprise content. We first pretrain a deep learning-based language-model using Wikipedia, then fine tune the model with a large unlabelled data set related with various types of enterprise content. Finally, a linear layer followed by softmax layer is added at the end of the language model and the model is trained on a labelled bias dataset consisting of enterprise content. The trained model is thoroughly evaluated on independent datasets to ensure a general application. We present the proposed method and its deployment detail in a real-world application.",http://dx.doi.org/10.1007/978-981-16-8531-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77070-9_10,Smart and Intelligent Chatbot Assistance for Future Industry 4.0,Artificial Intelligence for a Sustainable Industry 4.0,10.1007/978-3-030-77070-9_10,Springer,2021-01-01,"Chatbot is an implementation of artificial intelligence (AI) technology that is used to interact with human beings and make them feel like they are talking to the real person, and the chatbot helps them to solve their queries. A chatbot can provide 24 × 7 customer support so that the customer may have a good service experience by any organization. Chatbot helps to resolve the queries and respond to the questions of users. The user is providing the input to the chatbot first, and then, the same input will be processed further; this input can be in the form of text or voice. Therefore, on the basis of the given input and after processing it, the chatbot application will generate the response to the user, and the same response will be the best answer found by the chat application. This response can be in any format like text or a voice output. In this chapter, various approaches of chatbots and how they interact with users are discussed. The proposed approach is also defined using Dialogflow, and it can be accessible through mobile phones, laptops, and portable devices. Chatbots such as Facebook chatbot, WeChat chatbot, Hike chatbot called Natasha, etc. are available in the marker and will respond on the basis of their local databases (DBs). In the proposed method, the focus will be on the scalability, user interactivity, and flexibility of the system, which can be provided by adding both local and Web databases due to which our system will be more fast and accurate. Chatbot uses unification of emerging technologies like machine learning and artificial intelligence. The motive of this chapter is to improve the chatbot system to support and scale businesses and industry domain and maintain relations with customers.",http://dx.doi.org/10.1007/978-3-030-77070-9_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86890-1_6,Analyzing the Security of OTP 2FA in the Face of Malicious Terminals,Information and Communications Security,10.1007/978-3-030-86890-1_6,Springer,2021-01-01,"One Time Password (OTP) is the most prevalent 2FA method among users and service providers worldwide. It is imperative to assess this 2FA scheme’s security from multiple perspectives, considering its ubiquitous presence in the user’s day-to-day activities. In this work, we assess the security of seven commercially deployed OTP-2FA schemes against malware in the terminal attack model without compromising any 2FA device or authentication services. To implement this attack scenario, we develop a combination of attack modules that will capture password and OTP in different ways during the user’s login attempt. At the same time, it would originate a fresh concurrent hidden session from within the terminal or remotely to get possession to the user account without compromising the service or network or any external device. We examine implemented attack against seven different popular public services, which mostly use two variants of OTP-2FA and observed that almost all of them are vulnerable to this attack. Here, the threat model is practical as the attack components can be installed in the user’s terminal without any root/administrator privilege. Moreover, the attack modules require a small number of resources to run. The whole procedure would run from the background that makes the attack very hidden in nature and attain low detectability after examining against prominent anti-malware programs that indicate a real-world threat. Our findings after the analysis of the OTP-2FA schemes indicate that an adversary who can install malware on the user’s terminal can defeat almost all popular and widely used OTP-2FA schemes, which are vital security components of online accounts and secure financial transactions. The result also points out that the OTP-2FA scheme does not add extra security on top of the password in the presence of the malicious program in the terminal.",http://dx.doi.org/10.1007/978-3-030-86890-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66913-3_6,"Digitization: Learnings from Ancient Disruptions, AI and the Digital Trio’s Functional Stage, and AI Superpowers Disrupting Us",AI for the Good,10.1007/978-3-030-66913-3_6,Springer,2021-01-01,"“Digitization,” the buzzword of the 2010s, along with “disruption” characterizes a fundamental change to individuals and societies. Initially in this chapter, a little trust is built up by setting the current digital transformation into a historical context. Examples that show the potential and risks emerging from AI-based applications are discussed. Obviously, disruption is not new and key lessons can be learnt from the past. The “digital trio” (Robot Process Automation, blockchain, and quantum/supercomputing), i.e., digital technologies surrounding and contributing to AI, is explained for non-engineers and the performance is critically reflected. Using openly accessible AI platform Kaggle, a demonstration illustrates the output dependency on both key ingredients for AI: data and algorithms. Readers can immediately recheck calculation results themselves (without any software coding skills required): Based on a test dataset, different AI algorithms are used in an early warning system. It will be shown that even slight variations in the parametrization will lead to significantly different results. Obviously, this indicates a key problem of AI applications discussed as well in Part III, as misalignment on data and algorithms will ultimately lead to biased decisions and hence discrimination. The AI world emerged with an exponential pace. While there is a broad awareness of AI potential, for the last few years there is a clear duopoly on driving the AI agenda. The technologies used, the applications derived, and the impact on individuals’ and social lives will be illustrated by contrasting the two superpowers, the USA and China, in their approach to rule in the digital age. Despite the ethical consequences of the two very different endeavors, the USA with a so-called surveillance capitalism and China with the so-called market Leninism, there are massive implications not only on the social lives but as well on resource consumption, which provokes an exponential increase in energy demand (and with that realistically an increase in CO 2 ) as well as costs.",http://dx.doi.org/10.1007/978-3-030-66913-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-78645-8_6,STEM Excellence and Equity in K-12 Settings: Use of Augmented Reality-Based Educational Experiences to Promote Academic Achievement and Learner Success,HCI International 2021 - Posters,10.1007/978-3-030-78645-8_6,Springer,2021-01-01,"This exploratory paper examines the degree to which Extended Reality (XR) and more specifically, Augmented Reality (AR) technology along with experiential learning pedagogy, can be used to facilitate academic readiness, engagement, and motivation of underserved populations in the STEM fields. We examine the literature and approaches currently being used to help students and other learners gain the technical and behavioral skills needed to succeed in STEM-related courses. We specifically pay attention to studies involving teachers’ use and integration of XR/AR applications and other advanced technology tools and applications, even at the exploratory level, to determine readiness and ease of use of those applications as part of regular school activities. We outline some pedagogically-grounded ideas and suggestions to promote excellence and equity in K-12 STEM education, teacher training, and professional development.",http://dx.doi.org/10.1007/978-3-030-78645-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-72113-8_40,Causality-Aware Neighborhood Methods for Recommender Systems,Advances in Information Retrieval,10.1007/978-3-030-72113-8_40,Springer,2021-01-01,"The business objectives of recommenders, such as increasing sales, are aligned with the causal effect of recommendations. Previous recommenders targeting for the causal effect employ the inverse propensity scoring (IPS) in causal inference. However, IPS is prone to suffer from high variance. The matching estimator is another representative method in causal inference field. It does not use propensity and hence free from the above variance problem. In this work, we unify traditional neighborhood recommendation methods with the matching estimator, and develop robust ranking methods for the causal effect of recommendations. Our experiments demonstrate that the proposed methods outperform various baselines in ranking metrics for the causal effect. The results suggest that the proposed methods can achieve more sales and user engagement than previous recommenders.",http://dx.doi.org/10.1007/978-3-030-72113-8_40,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8731-3_3,"Data Science for Big Data Applications and Services: Data Lake Management, Data Analytics and Visualization","Big Data Analyses, Services, and Smart Data",10.1007/978-981-15-8731-3_3,Springer,2021-01-01,"Huge amounts of useful data are easily generated and gathered currently at a rapid rate from a broad range of rich data sources in numerous applications and services in the real world. Data science applies database techniques, scientific and engineering methods, mathematical and statistical models, data mining algorithms, and/or machine learning tools to manage data, extract the useful information and discover the new knowledge from these big data. This explains why data science for big data applications and services has become a fundamental technology in providing novel solutions in various areas in business, engineering, health, humanities, natural sciences, social sciences, etc. (e.g., healthcare, manufacturing, social life). Usually, data science focuses on big data management, analytics and visualization. Once big data are managed (i.e., captured, curated, managed and processed), big data are analyzed with an aim to discover interesting knowledge and information, which is usually presented in text or table form. Consistent with a proverb that “a picture is worth a thousand words”, big data visualization as well as visual analytics helps to reveal and explain the discovered interesting knowledge and information. In this paper, we present (a) big data management with focus on information fusion and the data lake; (b) big data analytics and mining, with focus on frequent patterns; as well as (c) big data visualization with focus on a few visual analytic systems for visualizing big data and mined frequent patterns. For illustration, we discuss these three aspects of data science on coronavirus disease 2019 (COVID-19) data. This highlights some important aspects of data science for big data analyses, services, and smart data.",http://dx.doi.org/10.1007/978-981-15-8731-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61641-0_1,Chatbots for CRM and Dialogue Management,Artificial Intelligence for Customer Relationship Management,10.1007/978-3-030-61641-0_1,Springer,2021-01-01,"In this chapter, we learn how to manage a dialogue relying on the discourse of its utterances. We show how a dialogue structure can be built from an initial utterance. After that, we introduce an imaginary discourse tree to address the problem of involving background knowledge on demand, answering questions. An approach to dialogue management based on a lattice walk is described. We also propose Doc2Dialogue algorithm of converting a paragraph of text into a hypothetical dialogue based on an analysis of a discourse tree for this paragraph. This technique allows for a substantial extension of chatbot training datasets in an arbitrary domain. We evaluate constructed dialogues and conclude that deploying the proposed algorithm is a key in successful chatbot development in a broad range of domains where manual coding for dialogue management and providing relevant content is not practical.",http://dx.doi.org/10.1007/978-3-030-61641-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-68972-8_5,"Entrepreneurs, Platforms, and International Technology Transformation",Empirical International Entrepreneurship,10.1007/978-3-030-68972-8_5,Springer,2021-01-01,"Platform business models and their underlying technologies are having a transformational impact on the global business landscape. This Schumpeterian disruption is the direct result of international entrepreneurship spanning 40 years from the battle for the industry standard for personal computers in the 1980s to the present day. The chapter analyses the role of entrepreneurs in laying the technological foundations for the growth of the platform business model before undertaking a literature review of business model innovation and the resource-based view (RBV) of technological disruption. This highlights how platform-driven ecosystems have inverted traditional ways of doing business which incumbent firms struggle to emulate. Due to the global nature of the Internet as a technology platform, the chapter will also consider the importance of the born global firm and why traditional one-sided businesses struggle to match the agility and scope of the new age entrepreneurial platform start-ups. This is evidenced by the surge in platform adoption in response to the Covid-19 pandemic.",http://dx.doi.org/10.1007/978-3-030-68972-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4968-1_42,Analytical Study of Security Enhancement Methods on Diverse Cloud Computing Platforms,"Proceedings of International Conference on Computational Intelligence, Data Science and Cloud Computing",10.1007/978-981-33-4968-1_42,Springer,2021-01-01,"Cloud storage is a convenient and virtually limitless storage option for the bulk of data technology is producing in recent times. Data security in cloud is not so robust as data owners need to depend upon the service providers for the safe storage. In this paper, we have identified few broadly used cloud computing paradigms: mobile cloud, cloud-based IoT and multi-tenant cloud. Mobile cloud helps reduce the data storage overhead on the mobile device and give users access to their personal data as and when required through cloud access. Cloud-based IoT helps the network of IoT devices, which is growing exponentially, to create on-demand cloud repositories. Multi-tenant cloud platforms are cloud environment accessed by more than one user. Few recent and related research work which aims at enhanced security from all these three paradigms is discussed and analysed. Encryption and similar network securing methods are used for mobile cloud and cloud-based IoT. For multi-tenant cloud, the objective is to keep the user spaces separate to keep their resources confidential.",http://dx.doi.org/10.1007/978-981-33-4968-1_42,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86800-0_2,Permissioned Blockchain for Data Provenance in Scientific Data Management,Innovation Through Information Systems,10.1007/978-3-030-86800-0_2,Springer,2021-01-01,"In the age of Big Data, the amount of data-driven research activities has increased significantly. However, when it comes to collaborative data processing in scientific workflows, provenance information of the used data is not always accessible. Especially in complex data ecosystems with multiple decentralized data sources, it is hard to keep track of the processing operations once they are completed. When sharing such data between different researchers and other involved parties, poor traceability of processing steps may also obstruct this process. In this paper, we introduce a blockchain based data provenance information system, which enables decentralized sharing of this information. We then integrate this system into the decentralized data sources context and address trust and traceability issues in the network with an identity-based solution. Furthermore, the system’s performance is evaluated, and the concept is examined in a case study on the e-Maritime Integrated Reference Platform (eMIR).",http://dx.doi.org/10.1007/978-3-030-86800-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-92916-9_19,ISLAND: An Interlinked Semantically-Enriched Blockchain Data Framework,"Economics of Grids, Clouds, Systems, and Services",10.1007/978-3-030-92916-9_19,Springer,2021-01-01,"Blockchain is currently one of the most popular technologies, providing privacy, transparency and trust. However, until now, it does not take into consideration the large amount of existing data and standards for decentralized data distribution and processing on the Web, that would leash new opportunities and business innovations for this emerging technology. Moreover, according to the vision of the Semantic Web, a key concept lies on data (semantic) annotations, querying and interlinking. Nevertheless, exporting knowledge resulting from different and possible interlinked blockchain networks, is still a major challenge. To address the aforementioned challenges, we propose ISLAND, a modular framework that is set to expose a unified abstraction layer to any data consumer that aims to infer meaningful knowledge from blockchain generated data, while at the same time enabling the semantic interoperability of them. In addition, a smart manufacturing use case scenario is presented as well as the potential business impacts are discussed.",http://dx.doi.org/10.1007/978-3-030-92916-9_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-64331-0_19,What’s in Score for Website Users: A Data-Driven Long-Term Study on Risk-Based Authentication Characteristics,Financial Cryptography and Data Security,10.1007/978-3-662-64331-0_19,Springer,2021-01-01,"Risk-based authentication (RBA) aims to strengthen password-based authentication rather than replacing it. RBA does this by monitoring and recording additional features during the login process. If feature values at login time differ significantly from those observed before, RBA requests an additional proof of identification. Although RBA is recommended in the NIST digital identity guidelines, it has so far been used almost exclusively by major online services. This is partly due to a lack of open knowledge and implementations that would allow any service provider to roll out RBA protection to its users. To close this gap, we provide a first in-depth analysis of RBA characteristics in a practical deployment. We observed N = 780 users with 247 unique features on a real-world online service for over 1.8 years. Based on our collected data set, we provide (i) a behavior analysis of two RBA implementations that were apparently used by major online services in the wild, (ii) a benchmark of the features to extract a subset that is most suitable for RBA use, (iii) a new feature that has not been used in RBA before, and (iv) factors which have a significant effect on RBA performance. Our results show that RBA needs to be carefully tailored to each online service, as even small configuration adjustments can greatly impact RBA’s security and usability properties. We provide insights on the selection of features, their weightings, and the risk classification in order to benefit from RBA after a minimum number of login attempts.",http://dx.doi.org/10.1007/978-3-662-64331-0_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64998-2_2,Background and Related Work,Internet of Things and Access Control,10.1007/978-3-030-64998-2_2,Springer,2021-01-01,"This chapter presents the background and related work in IoT and access control technology. We intend to present an overview of the state of the art IoT paradigm and, in particular, an examination of the available access control solutions in the existing literature. We also provide insight on IoT security, identity, access right delegation and the notion of trust when building an IoT access control architecture.",http://dx.doi.org/10.1007/978-3-030-64998-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8354-4_42,Medical Chatbot for Novel COVID-19,ICT Analysis and Applications,10.1007/978-981-15-8354-4_42,Springer,2021-01-01,"Conversational agents or more universally known as the chatbot were industrialized to respond to user’s queries in a particular domain. Chatbot would serve as a software delegate which enables a computer to converse with human via natural language. A chatbot is a human-like conversational character (Shaikh et al. Int J Eng Sci Comput 6:3117–3119, 2016 [ 1 ]. This technology was coined in 1960s, with the intention to impersonate a human (how he would reply to a particular situation) so that the user feels that he is talking to a real person and not a machine. Conversational agent that interacts with user’s turn by turn using natural language (Shawar A, Atwell E (2005) ICAME J Int Comput Arch Mod Med English J 29, 5–24, 2005 [ 2 ]). The world of chatbot has seen much of the advance since the invention, and they have progressed from conventional rule-based chatbot to unorthodox AI-based chatbot. The chat agents are expert in their fields [ 3 ]. The prime focus of this paper is to show implementation of a retrieval-based chabot with voice support, and we will investigate other standing chatbot and how it is useful in helping the patients fetching all the necessary details about COVID-19.",http://dx.doi.org/10.1007/978-981-15-8354-4_42,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81961-3_6,"Data Center Architecture, Operation, and Optimization","Future Networks, Services and Management",10.1007/978-3-030-81961-3_6,Springer,2021-01-01,"Modern large-scale data centers are very different than they were just a short time ago, which form the core infrastructure support for the ever-expanding cloud services. In this chapter, we survey representative data center network topologies, highlighting their advantages and disadvantages in terms of network architecture and scalability. Then, the data forwarding and routing schemes that are designed for these topologies are presented and compared based on various criteria. Thereafter, we discuss the traffic optimization techniques that are designed for the efficient operation of data center networks. A full understanding of the state-of-the-art data center networks is beneficial to future network design. We discuss several future trends of data center networks that let network infrastructure meet the ultimate challenges of the upcoming days.",http://dx.doi.org/10.1007/978-3-030-81961-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-68176-0_7,"Data Protection in the Era of Artificial Intelligence: Trends, Existing Solutions and Recommendations for Privacy-Preserving Technologies",The Elements of Big Data Value,10.1007/978-3-030-68176-0_7,Springer,2021-01-01,"This chapter addresses privacy challenges that stem particularly from working with big data. Several classification schemes of such challenges are discussed. The chapter continues by classifying the technological solutions as proposed by current state-of-the-art research projects. Three trends are distinguished: (1) putting the end user of data services back as the central focal point of Privacy-Preserving Technologies, (2) the digitisation and automation of privacy policies in and for big data services and (3) developing secure methods of multi-party computation and analytics, allowing both trusted and non-trusted partners to work together with big data while simultaneously preserving privacy. The chapter ends with three main recommendations: (1) the development of regulatory sandboxes; (2) continued support for research, innovation and deployment of Privacy-Preserving Technologies; and (3) support and contribution to the formation of technical standards for preserving privacy. The findings and recommendations of this chapter in particular demonstrate the role of Privacy-Preserving Technologies as an especially important case of data technologies towards data-driven AI. Privacy-Preserving Technologies constitute an essential element of the AI Innovation Ecosystem Enablers (Data for AI).",http://dx.doi.org/10.1007/978-3-030-68176-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71756-8_19,Digital Dimensions of Industry 4.0: Opportunities for Autonomic Computing and Applications,Autonomic Computing in Cloud Resource Management in Industry 4.0,10.1007/978-3-030-71756-8_19,Springer,2021-01-01,"While walking the path through a fourth industrial revolution, the journey of transformation from the time when human intervention was needed, to the current state where the processes are completely automated and are still continuing to a new horizon. A game-changer adoption of the technology of “autonomic computing” supports industrial systems from deep inside and helps sustain with the ever-increasing complexity of systems, helps in customization to a greater extent, helps to manage the maintenance and reliability of the system that is beyond the limits of just human intervention. With this understanding, our work talks about important digital dimensions of smart manufacturing systems. It develops high-level awareness of technologies and ecosystems of smart manufacturing—Industry 4.0. Furthermore, readers would be able to identify tremendous opportunities for applications of computational intelligence referring to the capabilities and aspects of autonomic computing; those are self-healing, self-configuring, self-optimization, and self-protecting; thus pointers for innovation and applied research",http://dx.doi.org/10.1007/978-3-030-71756-8_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-020-05162-6,An unsupervised detection method for shilling attacks based on deep learning and community detection,Soft Computing,10.1007/s00500-020-05162-6,Springer,2021-01-01,"In the detection methods for shilling attacks, the supervised methods require labeled samples to train the classifiers. Due to lack of the labeled sample profiles in real scenarios, the applicability of supervised detection method is restricted. For unsupervised methods, the prior knowledge is often required to guarantee the detection accuracy. To break the traditional limitations, we present an unsupervised method to detect various shilling profiles from reconstructed user–user graph based on deep learning and community detection. Firstly, we construct the user–user graph, whose edge weight is calculated by the similarity of user’s behaviors. Secondly, the stacked denoising autoencoders are used to extract the robust graph features at different scales with different corruption rates. Based on the features at different scales, we generate multiple clustering results and reconstruct the user–user graph by evidence accumulation method. Thirdly, the community detection is carried out by using the persistence optimization algorithm. Extensive experiments on two datasets illustrate that our proposed method has better performance than some baseline detectors for detecting the simulated attacks and actual attacks.",http://dx.doi.org/10.1007/s00500-020-05162-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1056-1_54,Currency Exchange Prediction for Financial Stock Market: An Extensive Survey,Cognitive Informatics and Soft Computing,10.1007/978-981-16-1056-1_54,Springer,2021-01-01,"Forecasting of the currency exchange price is one of the challenging and famous studies in recent era for the economics and computer science researchers. This study is taken as an exciting topic in international finance sector. The forex market (Forex market, FX, or foreign money marketplace) is an international decentralized market for the buying and selling of currencies. This marketplace determines foreign exchange rates for each forex. It includes all aspects of purchasing, promoting and changing currencies at current or decided expenses. In phrases of buying and selling extent, it’s miles with the aid of a ways the most important market within the world, accompanied by means of the credit score marketplace. In this work an extensive survey has been carried out with the information collected from many reputed journals where the authors has proposed some new approaches for currency exchange prediction, and compared their model with the existing methodologies.",http://dx.doi.org/10.1007/978-981-16-1056-1_54,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71158-0_21,Reducing the Need for Manual Annotated Datasets in Aspect Sentiment Classification by Transfer Learning and Weak-Supervision,Agents and Artificial Intelligence,10.1007/978-3-030-71158-0_21,Springer,2021-01-01,"Users’ opinions can be greatly beneficial in developing and providing products and services and improving marketing techniques for customer recommendation and retention. For this reason, sentiment analysis algorithms that automatically extract sentiment information from customers’ reviews are receiving growing attention from the computer science community. Aspect-based sentiment analysis (ABSA) allows for a more detailed understanding of customer opinions because it enables extracting sentiment polarities along with the sentiment target from sentences. ABSA consists of two steps: Aspect Extraction (AE) that allows recognizing the target sentiment; Aspect Sentiment Classification (ASC) that enables to classify the sentiment polarity. Currently, most diffused sentiment analysis algorithms are based on deep learning. Such algorithms require large labeled datasets that are extremely expensive and time consuming to build. In this paper, we present two approaches based on transfer learning and weak supervision, respectively. Both have the goal of reducing the manual effort needed to build annotated datasets for the ASC problem. In the paper, we describe the two approaches and experimentally compare them.",http://dx.doi.org/10.1007/978-3-030-71158-0_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71352-2_9,Three Quantitative Perspectives,Data Science for Public Policy,10.1007/978-3-030-71352-2_9,Springer,2021-01-01,"Decision making in government can be a risky endeavor: policy makers often face complex questions in which constituents lives and taxpayer funding are at stake. Reducing this risk typically requires the decision makers to (1) sufficiently understand the context of the problem space, (2) conduct rigorous analyses that estimate impacts of similar decisions taken in the past, and (3) build models that identify potential paths forward. These fundamental inputs provide a evidence-based framework for decision making.",http://dx.doi.org/10.1007/978-3-030-71352-2_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86790-4_37,Ethical Design of Conversational Agents: Towards Principles for a Value-Sensitive Design,Innovation Through Information Systems,10.1007/978-3-030-86790-4_37,Springer,2021-01-01,"Conversational Agents (CAs) have become a new paradigm for human-computer interaction. Despite the potential benefits, there are ethical challenges to the widespread use of these agents that may inhibit their use for individual and social goals. However, besides a multitude of behavioral and design-oriented studies on CAs, a distinct ethical perspective falls rather short in the current literature. In this paper, we present the first steps of our design science research project on principles for a value-sensitive design of CAs. Based on theoretical insights from 87 papers and eleven user interviews, we propose preliminary requirements and design principles for a value-sensitive design of CAs. Moreover, we evaluate the preliminary principles with an expert-based evaluation. The evaluation confirms that an ethical approach for design CAs might be promising for certain scenarios.",http://dx.doi.org/10.1007/978-3-030-86790-4_37,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65661-4_11,"Synergy of Internet of Things with Cloud, Artificial Intelligence and Blockchain for Empowering Autonomous Vehicles",Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_11,Springer,2021-01-01,"Out of the advancements in Information Technology, the Internet of Things (IoT) plays an important and major role as it metamorphose the object from real world Scenario to intelligent virtual form. The term Internet of Things is coined from two phrases such as Internet and Thing which states that the physical objects such as computing devices acts through the network of connection. This technological ecosystem allows the object or thing to collect and transfer the data through the internet, without any physical assistance. It includes four major processes such as collect, communicate, analyse and act. The main purpose of IoT is making the human life smart thereby reducing the human effort. The cloud is an environment that seems to be a reinforcement of booming technology. It provides everything as service, right from storage to computing power through internet. It seems to be a flexible computing model that has intensified the growth of information technology. It enchanted the sprout of IoT as it needs more storage for the data that are acquired from the objects. Another booming technology is artificial intelligence where the intelligence of machine is used for enabling smart tasks than using the human intelligence. It is in existence since 1950 s but the resurgence of it happens during twenty-first century with the advances in computing power and storage of voluminous data. The main purpose of AI is to achieve accurate interpretation of voluminous data and extract valuable learning from the data thereby achieving the appropriate goals in a flexible manner. The IoT with this gleaming AI allows the physical objects to collect the valuable data through continuous streaming and allows it to perceive its tasks and domains for greatest chance of prosperous goal achievement. Blockchain is another revolution of the information technology. The blockchain or Distributed Ledger Technology is a promising technology where the digital assets of myriad users are managed by maintaining the transparency and evading the undesirable alterations. It stores and manages the data in the form of multiple blocks with respective cryptographic hashing. It is a distributed and decentralized model where the digital form of transactions are recorded in multiple devices, this allows the system to do any alterations or changes in each and every blocks so as to make changes in the record. This model avoids the precarious changes that may occur in the digital world. The IoT with this blockchain technology or the blockchain of thing may allow the digital environment to create a permanent, verifiable and secure method of managing the valuable data through intelligent machines. It will enable humanless interventions for decision making through proper environment interactions. This chapter elaborates all the four technologies such as IoT, AI, Cloud and Blockchain with regard to the autonomous vehicles. The need for these flickering technologies are explored and exposed so as to understand these technologies. The synergies of IoT with other three technologies are discussed for better understanding and upgradation of the technology. It also scrutinizes the recent developments with all these technological synergies.",http://dx.doi.org/10.1007/978-3-030-65661-4_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5971-6_63,Android App-based Cryptographic End-to-End Verifiable Election System,Intelligent and Cloud Computing,10.1007/978-981-15-5971-6_63,Springer,2021-01-01,"Kumar, Rakesh In this paper, we present the e-voting mechanism through an android application that assures the possibility of an accessible and safe way to acquire votes during an election process. We have described all the associated concepts like survey, methodology, and working mechanism that is required for the presented work. In order to maintain security, encryption and decryption are done through cryptographic techniques. The e-voting mechanism proposed herein is intended to be more accessible and, therefore, more suitable for comparison with other voting systems.",http://dx.doi.org/10.1007/978-981-15-5971-6_63,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-57328-7_11,Blockchain-Based Security Services for Fog Computing,"Fog/Edge Computing For Security, Privacy, and Applications",10.1007/978-3-030-57328-7_11,Springer,2021-01-01,"Fog computing is a paradigm for distributed computing that enables sharing of resources such as computing, storage and network services. Unlike cloud computing, fog computing platforms primarily support non-functional properties such as location awareness, mobility and reduced latency. This emerging paradigm has many potential applications in domains such as smart grids, smart cities, and transport management. Most of these domains collect and monitor personal information through edge devices to offer personalized services. A centralized server either at the level of cloud or fog, has been found ineffective to provide a high degree of security and privacy-preserving services. Blockchain technology supports the development of decentralized applications designed around the principles of immutability, cryptography, consistency preserving consensus protocols and smart contracts. Hence blockchain technology has emerged as a preferred technology in recent times to build trustworthy distributed applications. The chapter describes the potential of blockchain technology to realize security services such as authentication, secured communication, availability, privacy and trust management to support the development of dependable fog services.",http://dx.doi.org/10.1007/978-3-030-57328-7_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-48332-6_3,Agile Visualization in Design Thinking,New Trends in Business Information Systems and Technology,10.1007/978-3-030-48332-6_3,Springer,2021-01-01,"This chapter presents an agile visualization approach that supports one of the most widespread innovation processes: Design Thinking. The approach integrates the pre-defined graphical elements of SAP Scenes to sketch digital scenes for storyboards. Unforeseen scenarios can be created by accommodating new graphical elements and related domain-specific aspects on-the-fly. This fosters problem understanding and ideation, which otherwise would be hindered by the lack of elements. The symbolic artificial intelligence (AI)-based approach ensures the machine-interpretability of the sketched scenes. In turn, the plausibility check of the scenes is automated to help designers creating meaningful storyboards. The plausibility check includes the use of a domain ontology, which is supplied with semantic constraints. The approach is implemented in the prototype AOAME4Scenes, which is used for evaluation.",http://dx.doi.org/10.1007/978-3-030-48332-6_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85910-7_31,Towards Active Learning Based Smart Assistant for Manufacturing,Advances in Production Management Systems. Artificial Intelligence for Sustainable and Resilient Production Systems,10.1007/978-3-030-85910-7_31,Springer,2021-01-01,"Smart assistants in manufacturing can guide and aid on decision-making while also provide means to collect additional insights and information available to the users. A general approach for building a smart assistant that provides users with machine learning forecasts and a sequence of decision-making options is presented in this work. The system provides means for knowledge acquisition by gathering data from users. To minimize interactions and friction with users, we envision active learning can be used to get data labels for most data instances expected to be most informative. The system is demonstrated on a demand forecasting use case in manufacturing. The methodology can be extended to several use cases in manufacturing.",http://dx.doi.org/10.1007/978-3-030-85910-7_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-8983-6_12,Laboratories for Research on Freight Systems and Planning,Urban Informatics,10.1007/978-981-15-8983-6_12,Springer,2021-01-01,"Advancements in information and communication technologies (ICT) and the advent of novel mobility solutions have brought about drastic changes in the urban mobility environment. Pervasive ICT devices acquire new sources of data that can inform detailed transportation simulation models, and are useful in analyzing new policies and technologies. In this context, we developed software laboratories that leverage the latest technological developments and enhance freight research. Future mobility sensing (FMS) is a data-collection platform that integrates tracking devices and mobile apps, a backend with machine-learning technologies and user interfaces to deliver highly accurate and detailed mobility data. The second platform, SimMobility, is an open-source, agent-based urban simulation platform which replicates urban passenger and goods movements in a fully disaggregated manner. The two platforms have been used jointly to advance the state of the art in behavioral modeling for passenger and goods movements. In this chapter, we review recent developments in freight-transportation data-collection techniques, including contributions to transportation modeling, and state-of-the-art transportation models. We then introduce FMS and SimMobility and demonstrate a coordinated application using three examples. Lastly, we highlight potential innovations and future challenges in these research domains.",http://dx.doi.org/10.1007/978-981-15-8983-6_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-51920-9_4,The Role of Artificial Neuron Networks in Intelligent Agriculture (Case Study: Greenhouse),"Artificial Intelligence for Sustainable Development: Theory, Practice and Future Applications",10.1007/978-3-030-51920-9_4,Springer,2021-01-01,"The cultivation under cover of fruits, vegetables, and floral species has developed from the traditional greenhouse to the agro-industrial greenhouse which is currently known for its modernity and its high level of automation (heating, misting system, air conditioning, control, regulation and command, supervision computer, etc.). New techniques have emerged, including the use of devices to control and regulate climatic variables in the greenhouse (temperature, humidity, CO 2 concentration, etc.). In addition, the use of artificial intelligence (AI) such as neural networks and/or fuzzy logic. Currently, the climate computer offers multiple services and makes it possible to solve problems relating to regulation, control, and commands. The main motivation in choosing an order by AI is to improve the performance of internal climate management, to move towards a control-command strategy to achieve a homogeneous calculation structure through a mathematical model of the process to be controlled, usable on the one hand for the synthesis of the controller and on the other hand by the simulation of the performances of the system. It is from this state, that begins this research work in this area include modelization an intelligent controller by the use of fuzzy logic.",http://dx.doi.org/10.1007/978-3-030-51920-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81203-4_11,Intelligent Logistics Systems,Intelligent Logistics Systems for Smart Cities and Communities,10.1007/978-3-030-81203-4_11,Springer,2021-01-01,"In the past few years, the Smart City Smart City concept has developed into one of the fastest growing trends worldwide. Researchers from different disciplines are engaged in in-depth analysis and research on the implementation of various intelligent services in an urban environment. As many cities around the world are joining this trend to become a smart city, it is extremely important to examine the changes that this trend is bringing, considering the well-being of residents and visitors. By building a consistent and coherent model of a smart city, one can predict the impact of these changes on urban lifestyle, allowing for better decisions meeting the requirements of the smart city and its inhabitants. Since in the innovation society the boundaries between cities, suburbs and the countryside should be overcome, smart communities are the more sensible term to use.",http://dx.doi.org/10.1007/978-3-030-81203-4_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-70377-6_15,On the Impact of Big Data Analytics in Decision-Making Processes,EURO Working Group on DSS,10.1007/978-3-030-70377-6_15,Springer,2021-01-01,"We currently live in an era, in which data heavily, constantly, and globally flows into all areas of our activities. This mobile world is based on the concepts of the Internet of Things, which evolved by the digital transformation from Web 2.0 to 4.0, from a people-centric, participative, read-write web to a data-centered, semantic-oriented, and symbiotic web. It connects us at anytime with our conveniences and contacts, feeds our information needs, guides our shopping tendencies, and informs us about businesses and opportunities in a way that otherwise would be difficult to manage, due to the massive amount of data involved. Individuals and mainly organizations have to tackle the problem of how to process large amounts of data in support of their respective needs and operations, aiming at improving their handling and response efficiency. Big Data can be a strategic asset for organizations, but it is only valuable if used constructively and efficiently to deliver appropriate business insights. Moreover, we currently see special needs, like the one with the pandemic outbreak of COVID-19 that affected all the world, in which high-level technology and analytics tools for supporting decision-making have proven to be important allied components on the counter-attack and management of the overall crisis. Novel methods and technologies were required to be developed to enable decision-makers to understand and examine the massive, multidimensional, multi-source, time-varying information stream to make effective decisions, sometimes in time-critical situations. The current work evolves from the need and interest of board members of the EURO Working Group on Decision Support Systems EWG-DSS to tackle these emerging issues related to Big Data and Decision-Making. The authors discuss the importance of having appropriate technologies for Decision-Making and Decision Support Systems to exploit the potentiality of Big Data analytics, so that we can treat crisis management in a more effective way; and organizations can improve their productivity to face increased competition in this new era. Our aim is to unveil the main impacts and challenges posed to decision-makers in organizations, in the new era of Big Data availability. An illustrative conceptual model is introduced to support the Big Data Analytics for Decision-Making in cross-domain applications.",http://dx.doi.org/10.1007/978-3-030-70377-6_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-69265-0_1,"An Overview of Decisions, Performance and Analytics in Supply Chain Management",Supply Chain Management in Manufacturing and Service Systems,10.1007/978-3-030-69265-0_1,Springer,2021-01-01,"Businesses today face major challenges in terms of greater competition and increased customer expectations from the global market. With advances in logistics and information technology, today’s customers are exposed to abundant products and services offered worldwide. Thus, businesses aim for competitive advantage and product/service differentiation to stay relevant and profitable. They strive to build robust supply chains that can help them deliver the right product/service more quickly and economically than their competitors. The focus of this book is to provide an overview on the current trends in supply chains as well as present advanced analytical models to optimize the design, planning and operation of supply chains. This chapter discusses the concept of supply chain management, various levels of supply chain decisions and their impacts, drivers and enablers of a supply chain, types of supply chain, and introduces the role of analytics in supply chain. Further, this chapter also presents relevant case studies to help readers better understand various aspects of supply chain management and their importance. Finally, this chapter links the various supply chain problems addressed in this book to the key decision levels and analytical methods, thereby setting the stage for the readers.",http://dx.doi.org/10.1007/978-3-030-69265-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66218-9_30,Application and Trend with Success Factor Linked to Large Scaled Data: A Case Study,Innovations in Information and Communication Technologies (IICT-2020),10.1007/978-3-030-66218-9_30,Springer,2021-01-01,"It is obvious that the large scaled data can be generated as well as processed by implementing the most effective computational techniques. In this regard, applications inked to operation management, transact generation, health care as well as industrial applications require specific trends and patterns within these large socioeconomic datasets. Sometimes, it can be a point of discussion regarding specifying the parameters associated with the voluminous data to prioritize the granular information about the individual cluster. Also in many cases, emphasis can be given to analyze the social networks and social engagement behaviors of individuals by mapping mobility patterns implementing sensors or mechanisms as well as usage of remote sensors to track all the patterns provisioning the coordination with information communication. In some cases also, based on the web analytics along with machine learning, prediction associated with large scaled data invites the opportunities to new mechanisms with conceptual applications in management sector also. While concentrating on granular data, it is essential to entrust the key sources of the voluminous data whether private, public or self quantified. So adoption of the recent mechanisms can lead to generate ambient data which can partially be emitted to be linked with dynamic networks quantifying the actions and behaviors. It is observed that the size and dimension of data while associated and shared in business and general applications are enhanced immeasurably. The textual data may be structured or unstructured. Similarly, the images and social media sites linked to multiplicity platforms can be generated in voluminous structure to be the evident to strategic technology trends. Considering this trend, partially the machine learning techniques or evolutionary as well as heuristic techniques can be applied to prioritize and focus on the majority of data to overcome the specific challenges.",http://dx.doi.org/10.1007/978-3-030-66218-9_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-33-6811-8_11,Applications of Blockchain Technologies in Health Services: A General Framework for Policymakers,"The Impact of Artificial Intelligence on Governance, Economics and Finance, Volume I",10.1007/978-981-33-6811-8_11,Springer,2021-01-01,"Developments in information and communication technologies lead to radical changes in traditional business models. This transformation process is rapidly changing the principles underpinning existing systems and governance models and makes the traditional role of centralized institutions questionable. Perhaps the newest and most important example of these changes is the “Blockchain” technology. Blockchain claims to provide a deep-rooted solution to the problem of “trust” that exists in traditional commercial relations. Blockchain technology is a technology that does not require a central structure and allows the storage and transmission of commercial or value-containing data (money, identity, valuable papers, etc.) safely and quickly. This contributes to reduced costs, increased efficiency, reduced errors as a result of continuous storage of records in the chain, and the reliability of records kept. Blockchain technology enables it to be implemented in many sectors such as finance, manufacturing, logistics, energy, health care, retail, telecommunications, media, insurance, as well as in public transactions thanks to its technological infrastructure and smart contracts. Due to the cost-cutting effect of blockchain technologies, the use of this technology is of great importance for the health sector and interest in this field is increasing. Blockchain’s applications in the medical field cover a wide range of processes, including electronic health records, health insurance, biomedical research, drug supply, purchasing processes, and medical education. Blockchain networks have many promising uses in the healthcare sector, from increasing transparency in the drug supply chain to creating and sharing unchangeable medical records. In the health sector, blockchain technologies can be used at different stages, from drug and medical product development processes to diagnosis, from the e-prescription process to better preservation and use of patient records.",http://dx.doi.org/10.1007/978-981-33-6811-8_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0757-8_5,Community with a Shared Future for Humanity Based on Sovereignty Blockchain,Sovereignty Blockchain 1.0,10.1007/978-981-16-0757-8_5,Springer,2021-01-01,"The world is changing steadily in a mighty way. The world today is experiencing earth-shaking changes, transformation and adjustment. Multipolarity of the world, economic globalization, social informatization and cultural diversity are developing in depth, and there have been conspicuous characteristics of the accelerated evolution propelled by the tremendous changes of the world, as well as more sources of global turmoil and risks.",http://dx.doi.org/10.1007/978-981-16-0757-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71756-8_4,"Autonomic Computing: Models, Applications, and Brokerage",Autonomic Computing in Cloud Resource Management in Industry 4.0,10.1007/978-3-030-71756-8_4,Springer,2021-01-01,"Autonomic computing is not a core, rather a convergence of numerous concepts and supporting technologies. It is the junction that integrates salient computing domains and subdomains to create a self-driven, self-healing, and self-manageable computing environment. The possible integration, exploration, and hybridization toward the development of the new models and applications are new knowledge contributions. Modeling is a conceptualization of autonomic computing in general and contextualization in specific applications. In the context of cloud-based autonomic computing, a model presents the fact that the operations of the autonomic computing systems are goal-oriented and driven by certain activities and follow certain policies and behavioral aspects, with the existing features. Currently, client organizations or individual clients prefer to use packaged computing products and services over the cloud or distributed systems. This chapter covers how autonomic computing models hold the promising features for s implification, and the ease of computing system management over clouds such as process management, autonomic client migration for load balancing, monitoring, energy efficiency(green), automatic updating of software tools/drivers, predictive warning before failure, error detection and correction, backups, and recovery from sudden disasters. This chapter also covers the possible applications and related issues encountered during adaption and adoption at salient scales and types of organizations. The summarized feature-based comparative analysis of the existing computing and emerging autonomic models are also incorporated. A cloud-based green broker model for cloud service selection is designed and incorporated for the autonomic brokerage of green cloud services. Furthermore, the applications of the autonomic process management architecture to salient applications such as governance, commerce, management, industrial automation, etc. are included.",http://dx.doi.org/10.1007/978-3-030-71756-8_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_68,LWOntoRec: Light Weight Ontology Based Novel Diversified Tag Aware Song Recommendation System,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_68,Springer,2021-01-01,"Web 2.0 contains billions of data in the form of audio, video, and Text. To recommend products or songs to the user, data need to be organized. Tag plays vital role in mapping relationships between objects in social network where it gives contextual information about the products. Good recommender not only suggest relevant items to the user, but recommending unexpected, diversified products will satisfy user. Tradeoff between relevance and novelty will result in good recommendations. Machine learning based approaches need to train large amount of data and must train frequently to inculcate dynamically updated data in social web. So lightweight ontology-based matching will be a best fit to recommendation systems. Our proposed work focuses on automating tag recommendation for the songs.",http://dx.doi.org/10.1007/978-3-030-71187-0_68,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-83301-5_5,Energy Internet of Things,Digitalization of Power Markets and Systems Using Energy Informatics,10.1007/978-3-030-83301-5_5,Springer,2021-01-01,"Prior to and during the commercialization of the Internet in the early 1990s, most of the focus was on supporting end devices that were used by humans. While there were some early experiments on connecting machines to the Internet as end devices, the real growth in communication between two devices had to wait until device miniaturization, low-power electronics, and wireless link technology were far enough along that connectivity could be incorporated into practically any device that needed it. This trend is called the “Internet of Things” (IoT). IoT is a superset of Machine-to-Machine (M2M) communication, encompassing the interconnection of intelligent devices and management platforms through advanced communication technologies developed for the Internet. IoTs connect to the Internet, often through some intermediate network for access control, to transmit data about their state or the state of the environment in which they are embedded and to receive data controlling the device’s state. IoT brings the Internet, data collection, processing, and analytics to the real world of physical objects. This chapter focuses on the energy IoT with trending communication technologies in IoT networks, devices, and sensors, and also discusses IoT applications in the smart grid environment, sometimes called the “Energy of IOT.”",http://dx.doi.org/10.1007/978-3-030-83301-5_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80840-2_1,The Human-Side of Service Engineering: Advancing Technology’s Impact on Service Innovation,Advances in the Human Side of Service Engineering,10.1007/978-3-030-80840-2_1,Springer,2021-01-01,"As advanced Information Technology (IT) drives changes in digital service and service systems across industries, what are the implications for the Human-Side of Service Engineering (HSSE)? This work updates previous HSSE frameworks and extends the boundaries of Service Science, Management, Engineering, and Design (SSMED). Newly included are HSSE areas related to determinants of trust: standards, skills, public sector, privacy, and ethics. All of these are types of shared information resources that influence trust between actors. These updates are needed, as the impact of IT on service systems continues to expand, and AI technologies successfully emulate more human capabilities. The purpose of this paper is to consider possible future directions of HSSE using observations and examples. The paper also presents a discussion of challenges to society and its fundamental values coming from recent advances in AI.",http://dx.doi.org/10.1007/978-3-030-80840-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-67490-8_7,Advance Cloud Data Analytics for 5G Enabled IoT,Blockchain for 5G-Enabled IoT,10.1007/978-3-030-67490-8_7,Springer,2021-01-01,"The mobile cellular networks such as 5G are evolving from the existing 4G networks and will continue to provide better services to the end-users. Over time, the number of Internet of Things (IoT) devices will be linked with the 5G networks to provide support for low latency and ultra-reliable communication. The main drawback is the decision process management and handling vast amounts of data associated with the IoT and 5G based systems. Hence the adoption of Cloud Computing (CC), 5G, and IoT is an important keyword for its implementation. The market interest in the IoT is increased because of the improvements in the 5G and CC technologies. The 5G can cater to present requirements like smart energy applications, etc. and many to come in the future timeline. The 5G users can be categorized into latency calculation, enhanced mobile broadband (eMBB), and critical communications for massive IoT clusters. CC will help to handle the information volumes generated by IoT, as 5G boosts the network capacity. These combinations of technologies such as CC, IoT, and 5G will be a boon to industries such as automotive and mobility, media and content, Public/smart city, healthcare, manufacturing, energy, and utility. The contribution of this chapter is the benefits the 5G enabled IoT system will get by integrating with the Cloud ecosystem. The outcome of the case study reflects the benefits of using the Cloud ecosystem for the 5G based IoT infrastructure for an effective decision-making process via intelligent communication mechanism and handling security in the IoT framework. abstract environment.",http://dx.doi.org/10.1007/978-3-030-67490-8_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71172-6_3,AgriEdge: Edge Intelligent 5G Narrow Band Internet of Drone Things for Agriculture 4.0,IoT-based Intelligent Modelling for Environmental and Ecological Engineering,10.1007/978-3-030-71172-6_3,Springer,2021-01-01,"The previous three industrializations had a major impact on the agricultural sector. There was a transformation from indigenous farming to mechanized farming. With the advent of Industry 4.0, the fourth generation of the Agriculture revolution has taken place with the introduction of precision farming, and the backbone of this revolution is mainly the Internet of Things. Edge Intelligence in combination with Agriculture Big-Data Analysis and modern evolving communication technologies like 5G Narrow Band (NB) IoT is going to play a significant role in the progress of Agriculture 4.0 through real-time applications as a simpler waveform like NB-IoT consumes less power, have high reliability, have wider deployment capability and have lower latency. Energy-efficient and Real-time application of technologies in the agricultural sector is the need of the hour for a smart green industrial revolution through Agriculture 4.0. The induction of Multilingual Voice User Interface control enabled drones in combination with dynamic sensors in 5G era, will prove to be a game-changer in the agricultural sector. Edge Intelligence enabled drones will introduce the concept of ubiquitous computing in the agricultural domain, will be quite beneficial for the farmers as it will provide real-time alerting, monitoring systems in addition to real-time precision farming.",http://dx.doi.org/10.1007/978-3-030-71172-6_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71415-4_1,Introduction,"Geopolitical Risk, Sustainability and “Cross-Border Spillovers” in Emerging Markets, Volume I",10.1007/978-3-030-71415-4_1,Springer,2021-01-01,"This book is the first of a two-volume series, and focuses on Cross-Border Spillovers in Labor, Financial, Commodities and Real Estate markets and associated Economic Psychology issues (primarily Cross-Border Spillovers from developed countries to Emerging market countries; and to a lesser extent, across industries in the same country). During the last twenty years, geopolitical shocks were a major cause of global market volatility and changes in corporate policies of multinational corporations (MNCs), and thus they have major financial, social and economic implications. Hence, International Political Economy (IPE) issues have been a major change element in global capital markets. Economic Recessions, rapidly changing modes of social interactions, environmental damage in several large countries (e.g. China, Brazil, the United States), the global digital economy, the negative effects of online social networks, the European sovereign debt crisis and the Global Financial Crisis of 2007–2015 exposed weaknesses in financial markets (particularly real estate and fixed income markets), social structures and environmental compliance worldwide and has rekindled economists’ and policy-makers’ interest in the relationships among constitutions, financial/banking regulation, the global digital economy, credit expansion and sustainable growth. More than 110 countries created new constitutions or substantially amended their constitutions during 1990–2010 and many of the new constitutions are based on US- and UK-style constitutions. However, despite international coordination, increased automation, growth of the global digital economy and new laws, financial risk regulation remains highly ineffective as manifested by the failures of new financial regulations and government stimulus programs that were implemented or enacted during 2007–2015 in many developed and developing countries.",http://dx.doi.org/10.1007/978-3-030-71415-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-6728-5_6,Top Ten Challenges Facing Autonomous Driving,Autonomous Driving Changes the Future,10.1007/978-981-15-6728-5_6,Springer,2021-01-01,"Despite the continuous development and maturation of the technology, numerous challenges nevertheless impede the practical use of autonomous vehicles. Those challenges may come from legality, privacy, hackers, ethics, business models, etc. Technology always improves, as does human society, though these issues will be addressed over time, the process of change dictates the gradual implementation of roadblocks to success.",http://dx.doi.org/10.1007/978-981-15-6728-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-64884-8_3,Theoretical Diversity in IS Research: A Causal Structure Framework*,Advancing Information Systems Theories,10.1007/978-3-030-64884-8_3,Springer,2021-01-01,"This chapter represents Markus and Rowe’s ( MIS Quarterly, 42 (4), 1255–1280, 2018) causal structure framework of ideal-typical positions on three dimensions: Causal Ontology, Causal Trajectory, and Causal Autonomy. The focus of the Causal Ontology dimension is: Does the theorist conceive of causality as existing in the human mind or in reality? The concern of the Causal Trajectory dimension is: How does the theorist conceive the “social space” related to technology and envision causal movements across it? The remit of the Causal Autonomy dimension is: How does the theorist apportion causal effects for processes or outcomes across human or social actors and technology? The first issue is a critical question for all scientists; the second issue is common to all social scientists; and the third issue is unique to scientists who study sociotechnical phenomena. The positions are illustrated with examples and metaphorical illustrations. The chapter offers a new discussion of the framework’s utility for research design and for promoting theoretical diversity while maintaining mutual intelligibility and coherence of research agenda.",http://dx.doi.org/10.1007/978-3-030-64884-8_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-7026-4_3,The 5G Car,The Future of the Automotive Industry,10.1007/978-1-4842-7026-4_3,Springer,2021-01-01,"With the upgrade of telecommunication technologies, vehicles are bound to evolve toward connectivity scenarios that will enhance our lives, not just in terms of traffic safety but also how cities are re-imagined into urban centers that will improve the lives of citizens, our daily activities, and the flow of life, work, and play.",http://dx.doi.org/10.1007/978-1-4842-7026-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-69128-8_1,Reflections on AI for Humanity: Introduction,Reflections on Artificial Intelligence for Humanity,10.1007/978-3-030-69128-8_1,Springer,2021-01-01,"This chapter briefly surveys the current situation of AI with respect to its human and social effects, and to its risks and challenges. It presents a few global initiatives regarding ethical, social and legal aspects of AI. It introduces the remaining chapters of the book and briefly discusses a global cooperation framework on AI and its governance.",http://dx.doi.org/10.1007/978-3-030-69128-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65173-2_2,How Humans and Machines Interact,Managing Work in the Digital Economy,10.1007/978-3-030-65173-2_2,Springer,2021-01-01,"Connectivity will be virtually comprehensive by 2030. Accordingly, the future priorities of a connected world will concentrate on security, trust, and the integrity of data. The human qualities of creativity, the ability to improvise and cooperate, and resourcefulness open up new possibilities to engage and participate in value creation processes. Not only could new technologies create the need for different goods and services; they could also take over repetitive, physically demanding, and dangerous work. This would allow people to dedicate their time to other endeavors, such as pursuing their interests and doing things that are meaningful to them. Leadership principles will be much affected by the development of future HMI. Technological development can lead to significant increases in productivity, but it will depend on how these gains are distributed between economic and social groups. Even in the year 2030, people will still be superior to machines and use them as tools, not the other way around. Therefore, the tools will develop depending on the goals of the people. If they are aimed at enforcing the superiority of the respective system, the relationship between man and machine in both countries will show considerable differences and will no longer be compatible, but even contrary to each other.",http://dx.doi.org/10.1007/978-3-030-65173-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7961-5_116,IoT Based Automatic Irrigation System Using Wireless Sensor Networks,ICCCE 2020,10.1007/978-981-15-7961-5_116,Springer,2021-01-01,"In ancient times, farmers estimated the maturity of the soil and the reserves to generate revenue. A lower concentration of humidity, water level and certain climatic conditions is becoming increasingly difficult for a farmer. Wireless Sensor Network (WSN) contains different sensor nodes with the option of detection, computer and wireless communication. WSN technology is used to control and monitoring of the environment and soil parameter in the field. WSN used as part of farming for a few reasons, such as indicates high Interpretation, increase the production of harvest, low energy consumption and collection distributed data. Effective management of water plays an important role Agriculture. Shortage of water resources and high pumping costs make good water more critical management. Today is one automatic irrigation system (AIS) used to improving the use of water resources into increase production. This one part of the irrigation system allows development in different places with water deficit. In this way a productive planning of watering system gives the highest efficiency low amount of water.",http://dx.doi.org/10.1007/978-981-15-7961-5_116,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68133-3_19,Graph Analytics to Reason Citations of Prophets in the Holy Quran,Computational Intelligence in Information Systems,10.1007/978-3-030-68133-3_19,Springer,2021-01-01,"Graph Analytics is a recently emerging field that offers sophisticated mechanisms to model, analyse and visualise data in the form of graphs. Citations and valuable information about various prophets have been quoted in several chapters of the Holy Quran in textual form. In this contribution, we aim to model these citation data and information using a novel graph analytics oriented framework. This paper briefly reports our findings on formulating the proposed model, data collection and empirical analysis.",http://dx.doi.org/10.1007/978-3-030-68133-3_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1244-2_24,A Comprehensive Review on Reputation-Based Trust Management Framework for Cyber Physical Systems,International Virtual Conference on Industry 4.0,10.1007/978-981-16-1244-2_24,Springer,2021-01-01,"Wireless sensor networks (WSNs) act as base for all cyber physical systems (CPSs). CPS is composed of physical components like sensors and actuators, software influenced components like controllers. In which, largely used cryptographic mechanism is unsatisfactory to protect sensors which are exposed to physical world. Since sensors are commonly employed in hostile environment for long period of time, where there are possibilities for advisory to harm the sensors physically and acquire cryptographic keys which are in memory of sensors. Hence, a novel reputation trust management mechanism-based framework (NRTF) is designed to monitor the unwanted activities and develop trustworthiness of sensors by examining merits and demerits of various reputation-based trust models. Sadly, existing reputation-based systems for WSN and CPS do not explore healthiness against attacks related to reputation-based mechanism. This paper provides a framework for highly critical CPS by examining state-of-the-art with novelty.",http://dx.doi.org/10.1007/978-981-16-1244-2_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-69143-1_43,"Mobile Application Software Usability Evaluation: Issues, Methods and Future Research Directions",Information and Communication Technology and Applications,10.1007/978-3-030-69143-1_43,Springer,2021-01-01,"Recently, the growth and advancement in mobile technology (such as mobile devices, smartphones, mobile wireless networks) have cushioned everyday lives of peoples across the globe. Interestingly, this can be attributed to the greater ease of developing mobile applications for diverse usages such as healthcare, finance, and agriculture. Another reason for this is that, there is the quest to rollout mobile device tailored application software having lower budget, quicker time of delivery, and top-quality product from the developers and the end-user’s perspectives. The challenges of appropriate designs frameworks; and the understanding of the needs of users (that is, the end users) have persisted long after their eventual rollouts. The concept of mobile app usability and accessibility evaluation were developed to enable developers to ascertain the level of usages and relevance of mobile applications in-use or prior release under diverse criteria such as maintainability, understandability, comprehensibility, as well as parameters specified by Usability Standards of ISO 9241-11 (that is, effectiveness, efficiency, and satisfaction). This study undertakes a systematic literature review (SLR) to discuss the subject of mobile application software usability under the specific scope of issues, methods and future research directions. To achieve these, a total of forty (40) peer-reviewed articles from diverse databases/sources of records were selected. The outcomes of this study revealed that, mobile applications usability evaluations and processes are domain-specific (or locality-dependent). Also, there are no generic approaches identified or developed for performing usability and accessibility of mobile applications due to the non-deterministic nature of the domain, and context-of-use.",http://dx.doi.org/10.1007/978-3-030-69143-1_43,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88361-4_34,BEEO: Semantic Support for Event-Based Data Analytics,The Semantic Web – ISWC 2021,10.1007/978-3-030-88361-4_34,Springer,2021-01-01,"Recent developments in data analysis and machine learning support novel data-driven operations. Event data provide social and environmental context, thus, such data may become essential for the workflow of data analytic pipelines. In this paper, we introduce our Business Event Exchange Ontology ( BEEO ), based on Schema.org that enables data integration and analytics for event data. BEEO is available under Apache 2.0 license on GitHub, and is seeing adoption among both its creator companies and other product and service companies. We present and discuss the ontology development drivers and process, its structure, and its usage in different real use cases. Resource Type : Ontology License : Apache 2.0 DOI : https://doi.org/10.5281/zenodo.4695281 Repository : https://github.com/UNIMIBInside/Business-Event-Exchange-Ontology",http://dx.doi.org/10.1007/978-3-030-88361-4_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91100-3_27,Behavioural User Identification from Clickstream Data for Business Improvement,Artificial Intelligence XXXVIII,10.1007/978-3-030-91100-3_27,Springer,2021-01-01,"One of the key elements for businesses to succeed is to get to know their customers. Traditionally this task has been performed through user studies, however, over the last few years clickstream analysis has been proposed as a potential way of conducting automated behavioural studies at scale. In this paper, we explore the use of a recently-proposed unsupervised data-mining technique to identify common behavioural patterns from a clickstream and use them to automatically group users into clusters. In particular, our goal is to validate the potential of behavioural user identification with respect to a key business-level objective. We consider to which extent it is possible to link overall user in-application behaviour to the completion of a particular business-relevant action. Identifying behavior patterns resulting in such business-relevant actions can enable businesses to make changes to their interface, target relevant user groups or trigger actionable insights, all with the objective of maximizing the likelihood of preferable user actions. We analyzed a realworld dataset from a mobile application deployed on both the iOS and Android platforms for this experiment.",http://dx.doi.org/10.1007/978-3-030-91100-3_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-74644-5_9,Understanding the Factors Influencing Consumers’ Behaviour Towards Autonomous Vehicles Adoption,Introduction to Internet of Things in Management Science and Operations Research,10.1007/978-3-030-74644-5_9,Springer,2021-01-01,"In this study, the key determinants or factors influencing consumers’ behavioural intention to accept autonomous vehicles (AVs) have been explored and tested. Although, there is a plethora of studies in the literature evaluating various technologies, most of the models of technology acceptance and theories selected are applied on barriers of successful IT implementation in organisations or generally on technologies that have long been deployed. There are very few studies conducted on disruptive technologies such as AV. In this paper, this issue has been addressed with the identification of context-related constructs partly retrieved from existing literature, that describe a modelling process for a technology acceptance attempting to explain the main factors influencing people behavioural intention to adopt autonomous vehicle technology. Constructs such as trust, self-efficacy, anxiety, perceived safety and legal regulation have been considered. The main contribution of the study is the detailed exploration on the users’ acceptance of AV. We propose a theoretical model called Autonomous Vehicle Technology Acceptance Model (AVTAM) that gives us a better understanding of what will eventually influence future AV customers. The main findings of this work suggest that users’ safety on the road, the cost associated to the technology and the trust on car manufacturers will play a very important role for large-scale AV adoption.",http://dx.doi.org/10.1007/978-3-030-74644-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-9323-9_5,Transfer Learning for Unseen Slots in End-to-End Dialogue State Tracking,Increasing Naturalness and Flexibility in Spoken Dialogue Interaction,10.1007/978-981-15-9323-9_5,Springer,2021-01-01,"This paper proposes a transfer learning algorithm for end-to-end dialogue state tracking (DST) to handle new slots with a small set of training data, which has not yet been discussed in the literature on conventional approaches. The goal of transfer learning is to improve DST performance for new slots by leveraging slot-independent parameters extracted from DST models for existing slots. An end-to-end DST model is composed of a spoken language understanding module and an update module. We assume that parameters of the update module can be slot-independent. To make the parameters slot-independent, a DST model for each existing slot is trained by sharing the parameters of the update module across all existing slots. The slot-independent parameters are transferred to a DST model for the new slot. Experimental results show that the proposed algorithm achieves 82.5% accuracy on the DSTC2 dataset, outperforming a baseline algorithm by 1.8% when applied to a small set of training data. We also show its potential robustness for the network architecture of update modules.",http://dx.doi.org/10.1007/978-981-15-9323-9_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86475-0_27,Multi-Objective Recommendations and Promotions at TOTAL,Database and Expert Systems Applications,10.1007/978-3-030-86475-0_27,Springer,2021-01-01,"In this paper, we revisit the semantics of recommendations and promotional offers using multi-objective optimization principles. We investigate two formulations of product recommendation that go beyond traditional settings by optimizing simultaneously two conflicting objectives: Budget-Reco optimizes two customer-centric goals, namely utility and budget, and Business-Reco optimizes utility, a customer-centric goal, and profit margin, a business-oriented goal. To capture those objectives, we formulate knapsack problems and propose adaptations of exact and approximate algorithms. We also propose Group-Promo , the problem of generating product promotions that we model as a group discovery problem with multiple objectives and develop a Pareto-based solution. Our experiments on our TOTAL datasets demonstrate the importance of multi-objective optimization in the retail context, as well as the usefulness of our solutions when compared to their exact baselines. The results are valuable to TOTAL’s marketing department that has been improving hand-crafted strategies by launching several promotional campaigns using our algorithms.",http://dx.doi.org/10.1007/978-3-030-86475-0_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93620-4_12,MQTT Protocol Use Cases in the Internet of Things,Big Data Analytics,10.1007/978-3-030-93620-4_12,Springer,2021-01-01,"In the imminent generations, the Internet of Things (IoT) will have a vital role in ‘Networking’. There are a lot of subscribing/publish protocols used in IoT like MQTT, AMQP, XMPP, HTTP etc., but every protocol used here will not have the same features required for the Internet of Things. This paper helps you to find which is the best and efficient protocol through the use cases and the Big Data analysis used in IoT. To choose the best protocol, it should be used in the real-world application and analyzed through some statistical measurements, as like in this study two use cases are taken to experiment with the protocol. Light-weight MQTT (Message queuing telemetry transport) protocol is vastly used in IoT, So MQTT protocol is used to subscribe/publish in these use cases, using the use cases measurements (speed of the transmission of messages and throughput of the message transmission) are measured and the security systems are either explained. Mainly for the use cases like home automation and vehicular network, there are a huge number of resources like sensors are used, these sensors collect massive data, so for storing these massive data big data is used. This paper majorly focuses on the use cases of MQTT protocol in IoT, the advantages of using MQTT protocol and big data analytics used in IoT.",http://dx.doi.org/10.1007/978-3-030-93620-4_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-63376-9_2,Future Internet and Digital Ecosystems,Digital Transformation in the Cultural Heritage Sector,10.1007/978-3-030-63376-9_2,Springer,2021-01-01,"This chapter goes in-depth into the analysis of the new phenomena labelled under the umbrella of “future Internet” and “digital ecosystem”. The Future Internet (FI) is defined as a collection of data communication network technologies in the future. In this chapter the FI is discussed in relation to the Digital Ecosystems i.e. the peer to peer structures of support for a networked architecture and collaborative environment. The debate over the digital ecosystem as a new emerging concept represents a step towards the achievement of a better understanding of how cultural heritage services are being transformed. Here, the attention is not only on the definition of a possible best structure for a networked environment but to the ways in which networked environments evolve along time and with reference to the dimensions, dynamics, and variables that affect their emergence. The chapter proposes a more detailed approach to digital ecosystems in business literature and how they are being shaped into practice, with particular reference to the cultural heritage context.",http://dx.doi.org/10.1007/978-3-030-63376-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-9317-8_5,Role of Cryptography in Network Security,"The ""Essence"" of Network Security: An End-to-End Panorama",10.1007/978-981-15-9317-8_5,Springer,2021-01-01,"Network administrators employ several security mechanisms to protect data in the network from unauthorized access and various threats. The security mechanisms enhance the usability and integrity of the network. The design aspects of the network security mechanism involve both hardware and software technologies. The application domains of security mechanisms cover both public and private computer networks which are used in everyday jobs for conducting transactions and communications among business partners, government agencies, enterprises and individuals. The network security schemes vary depending on the types of the network, that is, public or private, wired or wireless. Data security includes encryption, tokenization, and key management practices in protecting data across all applications and platforms. The antivirus and antimalware software are also part of network security for protection from malware such as spyware, ransomware, trojans, worms, and viruses. Cryptography is an automated mathematical tool that plays a vital role in network security. It assures the confidentiality and integrity of data as well as provides authentication and non-repudiation to the users. This chapter primarily focuses on cryptography techniques and their role in preserving the network security. The cryptography technique consists of encryption and decryption algorithms. The encryption algorithms perform scrambling of ordinary text and generate an unreadable format for the third party known as ciphertext. The original data is restructured by the intended receiver using decryption algorithms. The cryptographic techniques are broadly classified into three categories namely symmetric-key cryptography, asymmetric-key cryptography and authentication. The cryptographic algorithms that are widely accepted are outlined with their relative advantages and disadvantages. Moreover, recent proficient cryptographic algorithms specific to cloud computing, wireless sensor networks and on-chip-networks are thoroughly discussed that provide a clear view about acquiring secure communication in the network using cryptography.",http://dx.doi.org/10.1007/978-981-15-9317-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-80825-9_12,FP-Redemption: Studying Browser Fingerprinting Adoption for the Sake of Web Security,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-030-80825-9_12,Springer,2021-01-01,"Browser fingerprinting has established itself as a stateless technique to identify users on the Web. In particular, it is a highly criticized technique to track users. However, we believe that this identification technique can serve more virtuous purposes, such as bot detection or multi-factor authentication. In this paper, we explore the adoption of browser fingerprinting for security-oriented purposes. More specifically, we study 4 types of web pages that require security mechanisms to process user data: sign-up , sign-in , basket and payment pages. We visited 1, 485 pages on 446 domains and we identified the acquisition of browser fingerprints from 405 pages. By using an existing classification technique, we identified 169 distinct browser fingerprinting scripts included in these pages. By investigating the origins of the browser fingerprinting scripts, we identified 12 security-oriented organizations who collect browser fingerprints on sign-up , sign-in , and payment pages. Finally, we assess the effectiveness of browser fingerprinting against two potential attacks, namely stolen credentials and cookie hijacking. We observe browser fingerprinting being successfully used to enhance web security.",http://dx.doi.org/10.1007/978-3-030-80825-9_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-73280-6_7,A Parallelized Frequent Temporal Pattern Mining Algorithm on a Time Series Database,Intelligent Information and Database Systems,10.1007/978-3-030-73280-6_7,Springer,2021-01-01,"For many years, time series data have been considered as one of the most popular significant data forms in our daily life. Time series exist in many application domains such as finance, medicine, geology, meteorology, and telecommunication. Among the time series mining tasks, frequent temporal pattern discovery is an interesting task because this task brings us a deep insight view of relationships between many objects and events through time. However, it is challenging when a combinatorial explosion occurs with many longer time series. It is more challenging if more informative patterns are required from a time series database. In this paper, we propose a parallel algorithm, called PTP, to cope with the frequent temporal pattern mining task. Our PTP is developed with multithreading on a frequent temporal pattern tree where each branch is processed in parallel. In addition, our PTP maintains the details of each frequent temporal pattern not only from its frequent occurrences in an individual time series but also from its frequent inter-time series associations. As a result, frequent temporal patterns discovered by PTP are more informative with explicit and exact temporal information, showing the relationships among the objects/events corresponding to the time series. Through the experimental results on real time series, PTP outperforms the brute force algorithm and the existing non-parallel algorithm in terms of both time and space. The found frequent temporal patterns can be further analyzed for other tasks such as prediction, classification, and clustering.",http://dx.doi.org/10.1007/978-3-030-73280-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-60425-7_9,Establishing Trustworthy Relationships in Multiparty Industrial Internet of Things Applications,Digital Forensic Investigation of Internet of Things (IoT) Devices,10.1007/978-3-030-60425-7_9,Springer,2021-01-01,"The uptake of smart devices in the manufacturing industry is accelerating as technological advancements enable hardware to become cheaper and more accessible. A primary concern for manufacturing companies, as well as those in the associated logistics supply chains, is how to establish trust between smart devices, such that the delegation of transactional responsibility and accountability, which is required for Industry 4.0, can be facilitated in a secure and sustainable manner. Trustworthy systems enable enhanced manufacturing operations to occur securely, while also providing a robust audit trail of digital evidence to support any future investigations into allegations of system breaches. This chapter examines a specific type of trust relationship that regularly occurs in supply chains—multiparty authentication—and proposes a framework that encompasses both the human and technical factors that must be considered to engender trustworthy relationships between IIoT devices and organisational operations technology.",http://dx.doi.org/10.1007/978-3-030-60425-7_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-74837-1_22,"The Ethics of Web Crawling and Web Scraping in Cybercrime Research: Navigating Issues of Consent, Privacy, and Other Potential Harms Associated with Automated Data Collection",Researching Cybercrimes,10.1007/978-3-030-74837-1_22,Springer,2021-01-01,"The abundance of data easily accessible on the internet has made it an appealing domain for conducting social science research. Because of the volume of data available, automated collection software, such as web crawlers and web scrapers, are increasingly being deployed. Ethical guidelines that have developed over the decades, however, are not always directly applicable to online research. As a result, there can be ambiguity as to when and how informed consent needs to be obtained, how privacy can be protected, and what potential harms websites, their owners, and even researchers could experience, and how to address them. In this chapter, we argue that automated data collection practices need not be unethical, provided special care is taken by researchers to acknowledge and explicitly address the complexities surrounding informed consent, privacy, and a myriad of other risks and potential harms (to subjects, websites, and researchers).",http://dx.doi.org/10.1007/978-3-030-74837-1_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77424-0_7,Popularity-Based Hierarchical Caching for Next Generation Content Delivery Networks,Industrial Networks and Intelligent Systems,10.1007/978-3-030-77424-0_7,Springer,2021-01-01,"More than half of the content over the Internet is carried by content delivery networks (CDNs). CDNs cache popular and most requested contents on the edges of the network. Thus helping to increase Quality of Experience (QoE), e.g., by decreasing time to first byte (TTFB) for different contents. In the present paper, we focus on developing a hierarchical caching structure for CDNs to improve their QoE. We focus on unpopular content here, since it accounts for a big portion of content over the Internet. Our novel data-driven method forms caching clusters or hierarchies to deal with unpopular contents. In order to form our clusters and assign edge servers into these clusters, we consider the pattern in which contents have been requested including the total number of requests, similar objects between two edge servers, and requests for those objects. Using $${tf-idf}$$ t f - i d f method, which is widely used in information retrieval, we find the similarities between requests landed on each of our edge servers and use these similarities to form clusters using the Markov Clustering algorithm. We evaluate our approach using different hierarchical models, and with real-world requests from a large-scale global CDN. We demonstrate that our hierarchical caching approach improves cache hit ratio by $${9.05\%}$$ 9.05 % . Additionally, a $${7.39\%}$$ 7.39 % decrease in TTFB is observed.",http://dx.doi.org/10.1007/978-3-030-77424-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-63967-9_10,FinTech,Financial Services in the Twenty-First Century,10.1007/978-3-030-63967-9_10,Springer,2021-01-01,"Financial innovation arguably started in Mesopotamia where the first books of account were inscribed in clay tablets. The bond market derives from war. Ferguson (2008) states, “The ability to finance war through a market for government debt was … an invention of the Italian Renaissance (Niall Ferguson, The Ascent of Money: A Financial History of the World 70 [Penguin Books 2008]). The joint stock company of the seventeenth century produced the first initial public offering, and established the first stock market, where shares of the United Dutch Chartered East India Company traded in a secondary market. The House of Rothschilds constructed an international finance system in the nineteenth century and used what now is called “big data” to enhance their fortune. Derivatives and securitised financial instruments, which developed in the twentieth century, magnificently illustrate financial innovation. Lewis Ranieri’s mortgage-backed securities (MBSs) left a notable impression in the twenty-first century. However, the term “FinTech” refers to disruptions to the financial services industry following the 2008 financial crisis, and the use of mobile technology. FinTech covers many innovative institutions and markets, for example, neo-banks, use of cryptocurrencies, improved payment systems, and crowdfunding/crowdlending peer-to-peer platforms. Although financial innovation started centuries ago, FinTech is the “next episode” of financial innovation.",http://dx.doi.org/10.1007/978-3-030-63967-9_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-9735-0_3,Wearable Internet of Things for Personalized Healthcare: Study of Trends and Latent Research,Health Informatics: A Computational Perspective in Healthcare,10.1007/978-981-15-9735-0_3,Springer,2021-01-01,"In this age of heterogeneous systems, diverse technologies are integrated to create application-specific solutions. The recent upsurge in acceptance of technologies such as cloud computing and ubiquitous Internet has cleared the path for Internet of Things (IoT). Moreover, the increasing Internet penetration with the rising use of mobile devices has inspired an era of technology that allows interfacing of physical objects and connecting them to Internet for developing applications serving a wide range of purposes. Recent developments in the area of wearable devices has led to the creation of another segment in IoT, which can be conveniently referred to as Wearable Internet of Things (WIoT). Research in this area promises to personalize healthcare in previously unimaginable ways by allowing individual tracking of wellness and health information. This chapter shall cover the different facets of WIoT and ways in which it is a key driving technology behind the concept of personalized healthcare. It shall discuss the theoretical aspects of WIoT, focusing on functionality, design and applicability. Moreover, it shall also elaborate on the role of wearable sensors, big data and cloud computing as enabling technologies for WIoT.",http://dx.doi.org/10.1007/978-981-15-9735-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79457-6_33,WawPart: Workload-Aware Partitioning of Knowledge Graphs,Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices,10.1007/978-3-030-79457-6_33,Springer,2021-01-01,"Large-scale datasets in the form of knowledge graphs are often used in numerous domains, today. A knowledge graph’s size often exceeds the capacity of a single computer system, especially if the graph must be stored in main memory. To overcome this, knowledge graphs can be partitioned into multiple sub-graphs and distributed as shards among many computing nodes. However, performance of many common tasks performed on graphs, such as querying, suffers, as a result. This is due to distributed joins mandated by graph edges crossing (cutting) the partitions. In this paper, we propose a method of knowledge graph partitioning that takes into account a set of queries (workload). The resulting partitioning aims to reduces the number of distributed joins and improve the workload performance. Critical features identified in the query workload and the knowledge graph are used to cluster the queries and then partition the graph. Queries are rewritten to account for the graph partitioning. Our evaluation results demonstrate the performance improvement in workload processing time.",http://dx.doi.org/10.1007/978-3-030-79457-6_33,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-61093-7_15,Autonomous Vehicles as the Ultimate Efficiency Driver in Logistics,Disrupting Logistics,10.1007/978-3-030-61093-7_15,Springer,2021-01-01,"Autonomous vehicles (AV) are seen as the ultimate innovation and efficiency driver in logistics. Though the operation of driverless trucks, drones, and delivery robots appears still quite futuristic, both the technology and applications advance rapidly. This paper describes the status quo, outlines the advantages of AV operations and illustrates the underlying technologies. In addition, it highlights the most promising use cases and applications and lists the startups and technology companies working on the next revolution. The work concludes with 10 hypotheses about how the development of AV will most likely evolve, how the market will be impacted, and how current business models will be disrupted.",http://dx.doi.org/10.1007/978-3-030-61093-7_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71017-0_27,The Organizational Cybersecurity Success Factors: An Exhaustive Literature Review,"Advances in Security, Networks, and Internet of Things",10.1007/978-3-030-71017-0_27,Springer,2021-01-01,"To identify gaps in cybersecurity research, the authors reviewed the secondary literatures of organizational cybersecurity posture, focusing on five factors: technology design, management procedures, organizational structure, legal environment, and human competencies. Their findings show security technology can be improved with advanced technology, usability, and design process. Organizations should employ a unified security platform for all security tools and consider insider threats in the design of cybersecurity-related organizational procedures. Legal literature highlights two major concerns for the future: small and midsized businesses will be major cyberattack victims, and human error is the largest factor in cyberattack success. Given the user as the weakest link of cybersecurity, human-centric technology designers should create human-centric designs in addition to training personnel against cyber incidents.",http://dx.doi.org/10.1007/978-3-030-71017-0_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85899-5_21,A Behavior-Aware Graph Convolution Network Model for Video Recommendation,Web and Big Data,10.1007/978-3-030-85899-5_21,Springer,2021-01-01,"Interactions between users and videos are the major data source of performing video recommendation. Despite lots of existing recommendation methods, user behaviors on videos, which imply the complex relations between users and videos, are still far from being fully explored. In the paper, we present a model named Sagittarius. Sagittarius adopts a graph convolutional neural network to capture the influence between users and videos. In particular, Sagittarius differentiates between different user behaviors by weighting and fuses the semantics of user behaviors into the embeddings of users and videos. Moreover, Sagittarius combines multiple optimization objectives to learn user and video embeddings and then achieves the video recommendation by the learned user and video embeddings. The experimental results on multiple datasets show that Sagittarius outperforms several state-of-the-art models in terms of recall, unique recall and NDCG.",http://dx.doi.org/10.1007/978-3-030-85899-5_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-88040-8_8,A Survey of Challenges Posed by the Dark Web,Artificial Intelligence in Cyber Security: Impact and Implications,10.1007/978-3-030-88040-8_8,Springer,2021-01-01,"The dark nets’ anonymity has provided the organised crime groups, terror groups, and paedophiles alike a place to communicate, recruit, purchase and disseminate illegal materials across the world instantly without much fear of retribution. As the exit nodes of the TOR browser can be set up by anyone across the globe, policing requires a significant degree of both skill and resources. Undercover operations within law enforcement agencies have been largely successful with paedophile rings being disrupted, as well as illicit cryptomarket places being monitored and shut down. However, this activity is incredibly time-consuming and costly. This chapters provides a discussion of some of the existing challenges that the darknet poses to law enforcement and other security agencies.",http://dx.doi.org/10.1007/978-3-030-88040-8_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00138-020-01146-6,Optimal feature level fusion for secured human authentication in multimodal biometric system,Machine Vision and Applications,10.1007/s00138-020-01146-6,Springer,2020-12-21,"The rising demand for high security and reliable authentication schemes, led to the development of the unimodal biometric system so that the multimodal biometric system has emerged. The multimodal biometric system will use more than one biometric trait of an individual for identification and security purpose. Fusion plays a major role in the multimodal biometric system. Several fusion techniques are used in biometric systems. Feature level fusion is a very much popular method as compared to the other fusion techniques. In this fusion, features are extracted from all biometric traits. After that extracted features are combined into a final feature vector of high dimension. In this paper, we introduce a new technique to perform fusion at the feature level by optimal feature level fusion; here the relevant features are selected using an optimization technique. Here, we proposed OGWO for selecting optimal features. Moreover, we suggested the recognition technique. For recognition, we use the multi-kernel support vector machine algorithm. Finally, the performance of our proposed method is evaluated by some evaluation measures. Our recommended method is implemented in the MATLAB platform.",http://dx.doi.org/10.1007/s00138-020-01146-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13677-020-00217-3,A user interest community evolution model based on subgraph matching for social networking in mobile edge computing environments,Journal of Cloud Computing,10.1186/s13677-020-00217-3,Springer,2020-12-14,"With the rapid development of mobile edge computing, mobile social networks are gradually infiltrating into our daily lives, in which the communities are an important part of social networks. Internet of People such as online social networks is the next frontier for the Internet of Things. The combination of social networking and mobile edge computing has an important application value and is the development trend of future networks. However, how to detect evolutionary communities accurately and efficiently in dynamic heterogeneous social networks remains a fundamental problem. In this paper, a novel User Interest Community Evolution (UICE) model based on subgraph matching is proposed for accurately detecting the corresponding communities in the evolution of the user interest community. The community evolutionary events can be quickly captured including forming, dissolving, evolving and so on with the introduction of core subgraph. A variant of subgraph matching, called Subgraph Matching with Dynamic Weight (SMDW), is proposed to solve the problem of updating the core subgraph due to the change of core user’s interest when tracking evolutionary communities. Finally, the experiments based on the real datasets have been designed to evaluate the performance of the proposed model by comparing it with the state-of-art methods in this area and complete data processing through the local edge computing layer. The experimental results demonstrate that the UICE model presented in this paper has achieved better accuracy, higher efficiency and better scalability against existing methods.",http://dx.doi.org/10.1186/s13677-020-00217-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10657-020-09662-6,"AI algorithms, price discrimination and collusion: a technological, economic and legal perspective",European Journal of Law and Economics,10.1007/s10657-020-09662-6,Springer,2020-12-01,"In recent years, important concerns have been raised about the increasing capabilities of pricing algorithms to make use of artificial intelligence (AI) technologies. Two issues have gained particular attention: algorithmic price discrimination (PD) and algorithmic tacit collusion (TC). Although the risks and opportunities of both practices have been explored extensively in the literature, neither has yet been observed in the actual practice. As a result, there remains much confusion as to the ability of algorithms to engage in potentially harmful behavior with respect to price discrimination and collusion. In this article, we embed the economic and legal literature on these topics in a technological grounding to provide a more objective account of the capabilities of current AI technologies to engage in price discrimination and collusion. We argue that attention to these current technological capabilities should more directly inform on-going discussions on the urgency to reform legal rules or enforcement practices governing algorithmic PD and TC.",http://dx.doi.org/10.1007/s10657-020-09662-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-019-09935-9,RecSys Issues Ontology: A Knowledge Classification of Issues for Recommender Systems Researchers,Information Systems Frontiers,10.1007/s10796-019-09935-9,Springer,2020-12-01,"Scholarly research has extensively examined a number of issues and challenges affecting recommender systems (e.g. ‘ cold-start’ , ‘ scrutability’ , ‘ trust’, ‘context’, etc.). However, a comprehensive knowledge classification of the issues involved with recommender systems research has yet to be developed. A holistic knowledge representation of the issues affecting a domain is critical for research advancement. The aim of this study is to advance scholarly research within the domain of recommender systems through formal knowledge classification of issues and their relationships to one another within recommender systems research literature. In this study, we employ a rigorous ontology engineering process for development of a recommender system issues ontology. This ontology provides a formal specification of the issues affecting recommender systems research and development. The ontology answers such questions as, “ What issues are associated with ‘trust’ in recommender systems research?”, “ What are issues associated with improving and evaluating the ‘performance’ of a recommender system?” or “ What ‘contextual’ factors might a recommender systems developer wish to consider in order to improve the relevancy and usefulness of recommendations?” Additionally, as an intermediate representation step in the ontology acquisition process, a concept map of recommender systems issues has been developed to provide conceptual visualization of the issues so that researchers may discern broad themes as well as relationships between concepts. These knowledge representations may aid future researchers wishing to take an integrated approach to addressing the challenges and limitations associated with current recommender systems research.",http://dx.doi.org/10.1007/s10796-019-09935-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-020-03062-w,A comparative study on bio-inspired algorithms for sentiment analysis,Cluster Computing,10.1007/s10586-020-03062-w,Springer,2020-12-01,"Data mining is one of the most explored and ongoing areas of research. Sentiment analysis is a popular application of data mining, where the information regarding the customer's emotions or attitude is extracted by applying various methods or techniques. The earlier work in sentiment analysis deals with supervised, unsupervised machine learning-based approaches and lexicon-based approaches. Nature-inspired algorithms are recently becoming an emerging topic of research for developing new algorithms and for optimizing the results as nature serves as an excellent source of inspiration. These techniques are divided into bio-inspired algorithms, physics–chemistry based algorithms, and others. This survey mainly deals with bio-inspired algorithms, which consist of swarm intelligence based and non-swarm intelligence-based algorithms. We present a comprehensive review of the significant bio-inspired algorithms that are popularly applied in sentiment analysis. We discuss state-of-the-art on these significant algorithms along with a comparative study on these algorithms by reviewing eighty articles from various journals, conferences, book chapters, etc. Finally, this review draws some essential conclusions and identifies some research gaps to motivate researchers in this area.",http://dx.doi.org/10.1007/s10586-020-03062-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13162-020-00179-4,"The changing role of marketing: transformed propositions, processes and partnerships",AMS Review,10.1007/s13162-020-00179-4,Springer,2020-12-01,,http://dx.doi.org/10.1007/s13162-020-00179-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12664-020-01133-9,"61st Annual Conference of Indian Society of Gastroenterology, Virtual Diamond Jubilee ISGCON 2020, 19-20th December 2020",Indian Journal of Gastroenterology,10.1007/s12664-020-01133-9,Springer,2020-12-01,,http://dx.doi.org/10.1007/s12664-020-01133-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11219-019-09492-z,Towards supporting software assurance assessments by detecting security patterns,Software Quality Journal,10.1007/s11219-019-09492-z,Springer,2020-12-01,"Today, many tools exist that attempt to find possible vulnerabilities in Android applications, e.g., FlowDroid, Fortify, or AppScan. However, all these tools aim to detect vulnerabilities or (sometimes) tainted flows and present the reviewer detected possible issues of an analyzed Android application. None of these tools supports the identification of implemented security features in code, although this aspect is also relevant to developers as well as reviewers. To address this open problem, we present a program comprehension approach based on connected object process graphs (COPGs) containing interacting objects described by security patterns in this paper. The feasibility of our approach is evaluated qualitatively with 25 security-critical Android applications from Google Play with almost 7 million lines of code. We currently support 17 security pattern variants with about 199 correctly detected pattern instances in the apps. We also define a benchmark of non-trivial, security-critical Android apps, which can also be used for other security analysis tasks based on the static analysis framework Soot. With this benchmark, our analysis yields a precision of 99% and a recall of 80%. Finally, we discussed our approach and the developed tool with six software security experts from the SAFECode organization to obtain additional feedback.",http://dx.doi.org/10.1007/s11219-019-09492-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-020-00594-w,The contribution of linked open data to augment a traditional data warehouse,Journal of Intelligent Information Systems,10.1007/s10844-020-00594-w,Springer,2020-12-01,"The arrival of Big Data has contributed positively to the evolution of the data warehouse ( DW ) technology. This gives birth of augmented DW s that aim at maximizing the effectiveness of existing ones. Various augmentation scenarios have been proposed and adopted by firms and industry covering several aspects such as new data sources (e.g., Linked Open Data ( LOD ), social, stream and IoT data), data ingestion, advanced deployment infrastructures, programming paradigms, data visualization. These scenarios allow companies reaching valuable decisions. By examining traditional DW s, we realized that they do not fulfill all decision-maker requirements since data sources alimenting a target DW are not rich enough to capture Big Data. The arrival of LOD era is an excellent opportunity to enrich traditional DW s with a new V dimension: Value . In this paper, we first conceptualize the variety of internal and external sources and study its effect on the ETL phase to ease the value capturing. Secondly, a Value-driven approach for the DW design is discussed. Thirdly, three realistic scenarios for integrating LOD in the DW landscape are given. Finally, experiments are conducted showing the added value by augmenting the existing DW environment with LOD .",http://dx.doi.org/10.1007/s10844-020-00594-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-020-04982-w,"EBV: Encoded Binary Vector for Efficient Information Retrieval, Query Processing and Recommendation for Travel and Tourism Domain",Arabian Journal for Science and Engineering,10.1007/s13369-020-04982-w,Springer,2020-12-01,"The rise in business and electronic transactions using the web as a medium has driven the widespread use of recommendation systems across all domains. Recommendation systems generate suggestions for the travel and tourism industry, particularly hotels or services, centered on user interests and preferences. Relevant information collection, organization, processing vast quantities of string data, efficient data retrieval, and computational complexity in handling information overload are key issues to be addressed in a recommendation system. This work proposes a novel approach, using encoded bit vectors, to process information on hotel amenities and features extracted from Tripadvisor. Hotel amenities at different locations are organized and stored, based on the priority of the location, using the most significant bit and least significant bit. The amenities are prioritized dynamically thereafter, based on the location, and unique amenities accorded greater preference than the ones routinely offered at most hotels. Encoded bit vectors are utilized for information retrieval and precise hotel recommendations made, based on user interest rather than the string processing method that is ineffective where scalable data are concerned. Finally, the recommended hotels are ranked with user-centric personalized recommendations. These high-speed, efficient, and scalable algorithms are ideal for incrementally updating data. They also facilitate fast, flawless IR and query processing, along with appropriate hotel recommendations. The theoretical evaluation shows that the proposed method aids quick query processing and retrieval. The experimental assessment shows that hotels recommended by the proposed bit vector recommendation system have a higher accuracy on par with user and expert recommendations.",http://dx.doi.org/10.1007/s13369-020-04982-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-020-07199-0,Reinforcement Learning Based on Contextual Bandits for Personalized Online Learning Recommendation Systems,Wireless Personal Communications,10.1007/s11277-020-07199-0,Springer,2020-12-01,"Personalized online learning has been significantly adopted in recent years and become a potential instructional strategy in online learning. The promising way to provide personalized online learning is personalized recommendation by navigating students to suitable learning contents at the right time. However, this is a nontrivial problem as the learning environments are considered as a high degree of flexibility as students independently learn according to their characteristics, and situations. Existing recommendation methods do not work effectively in such environment. Therefore, our objective of this study is to provide personalized dynamic and continuous recommendation for online learning systems. We propose the method that is based on the contextual bandits and reinforcement learning problems which work effectively in a dynamic environment. Moreover, we propose to use the past student behaviors and current student state as the contextual information to create the policy for the reinforcement agent to make the optimal decision. We deploy real data from an online learning system to evaluate our proposed method. The proposed method is compared with the well-known methods in reinforcement learning problems, i.e. $$\varepsilon$$ ε -greedy, greedy optimistic initial value, and upper bound confidence methods. The results depict that our proposed method significantly performs better than those benchmarking methods in our case test.",http://dx.doi.org/10.1007/s11277-020-07199-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41133-020-00038-8,Research Trends on the Usage of Machine Learning and Artificial Intelligence in Advertising,Augmented Human Research,10.1007/s41133-020-00038-8,Springer,2020-11-25,"Advertising is a way in which a company introduces possible customers to a company’s product/service, the main objective is possibly to convince them to buy their product or use their service. The significance of Advertising is critical for the company, as this alone can make people aware of the company’s product and in doing so can generate a good possibility of it being sold to the customers. It is inevitable for companies to face changes and one such change is the evolution in the way of doing Advertisement. Advertisement is now done with the help of not so newfound helping hand that is Artificial Intelligence and Machine Learning. The answer to the question as to why the change in the process of Advertising is important lies in the before-after statistical observations of companies using this technology. The results themselves are reasonable motivating factors for companies who are yet to acknowledge the change. The serious challenge to this new version of Advertising is to make sure to not allow the usage of it to such a great extent where ordinary person is concerned about his/her privacy. Implementing Advertisements this way, we are quite sure that making laws, enforcing the laws or even having its own governing body can ensure righteous use of deploying this technology. The future of Advertising is going to be even better than before as Artificial Intelligence and Machine Learning will bring more control of Advertising to companies. Summing up, we feel confident that Advertising with Artificial Intelligence and Machine Learning are here for a noticeable and a significant change.",http://dx.doi.org/10.1007/s41133-020-00038-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11301-019-00173-6,Lessons from three decades of IT productivity research: towards a better understanding of IT-induced productivity effects,Management Review Quarterly,10.1007/s11301-019-00173-6,Springer,2020-11-01,"New developments in the fields of artificial intelligence or robotics are receiving considerable attention from businesses, as they promise astonishing gains in process efficiency—sparking a surge of corporate investments in new, digital technologies. Yet, firms did not become per se more productive, as labor productivity growth in various industrial nations has decelerated in recent years. The fact that the adoption of innovative technologies is not accompanied by productivity increases has already been observed during the dawn of the computer age and became known as Solow’s Paradox. Thus, this paper takes stock of what is known about the Solow Paradox, before incorporating the findings into the debate of the current productivity slowdown. Based on an in-depth review of 86 empirical studies at the firm level, this paper uncovers various reasons for the emergence of the Solow Paradox, debates its following reversal marked by the occurrence of excess returns and deduces a model of factors influencing the returns on IT investments. Based on these insights, four overarching explanations of the modern productivity paradox namely adjustment delays, measurement issues, exaggerated expectations and mismanagement are discussed, whereby mismanagement emerges as a currently neglected, but focal issue.",http://dx.doi.org/10.1007/s11301-019-00173-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-020-00904-7,An optimal uplink traffic offloading algorithm via opportunistic communications based on machine learning,Peer-to-Peer Networking and Applications,10.1007/s12083-020-00904-7,Springer,2020-11-01,"Opportunistic communications as an efficient traffic offloading method can be used to offload uplink traffic of cellular networks to Wi-Fi networks. However, because of its contact pattern (contact frequency and contact duration) the offloading method could not ensure the data to be successfully offloaded to Wi-Fi Access Points (APs) within a time constraint. In this paper, we focus on maximizing the probability of offloading data to Wi-Fi APs by fragmenting the data and assigning the fragments to different direct or indirect paths generated by opportunistic contacts. Firstly, we propose two methods based on mobility prediction, which is realized by machine learning, to separately calculate the probability of offloading data to Wi-Fi APs by the direct offloading path considering multiple opportunistic contacts and contact duration, and the probability of indirectly offloading data to Wi-Fi APs by the indirect offloading path. Then, based on the probability calculation methods the offloading probability maximization is formulated as a non-linear integer programming problem, and we propose a distributed heuristic algorithm to solve it considering complexity of the probability calculation and limited computation capacities of devices. Simulation results prove the data offloading probability of our proposed algorithm outperforms other algorithms under different simulation environment.",http://dx.doi.org/10.1007/s12083-020-00904-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-020-00701-3,Social networking mood recognition algorithm for conflict detection and management of Indian educational institutions,Social Network Analysis and Mining,10.1007/s13278-020-00701-3,Springer,2020-11-01,"Conflict detection and management is a much-needed strategy in educational institutions nowadays. The frequency of clashes, protests, strikes and agitations is rising at an alarming level, particularly with the extensive usage of information and communication technology. This unprecedented issue has cobblestone the research problem and the objective of this study. In order to ensure detection of conflicts using a modified Naïve Bayes algorithm that would assess the sentiments and mood recognition from the tweets of the stakeholders with respect to trends leading to clashes, protests, strikes and agitations existing within the educational environment. Consequently, continuous monitoring and surveillance of the social networking platform have been made to understand the mood recognition and assessment from real-time tweets published on Twitter that would be streamed through Twitter Application Program Interface over the user-given text that would serve as an input for developing early conflict detection strategies. Moreover, Stanford parser has been used to extract keywords that would subsequently be deployed over the tweets for the mood detection module to evaluate the keywords using the preprocessed dictionary. Here, the mood detection module extracts various mood states from the given chorus that supplements the current prevailing sentiments of the stakeholders in academic institutions. This extraction would result in devising strategic formulation and implementation of remedial measures for resolving the unrest in an environment. This would culminate in a healthy educational environment that would ultimately result in overall growth, development, harmony and prosperity of the institutions.",http://dx.doi.org/10.1007/s13278-020-00701-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10922-020-09570-9,Performance and Availability Trade-Offs in Fog–Cloud IoT Environments,Journal of Network and Systems Management,10.1007/s10922-020-09570-9,Springer,2020-10-09,"Internet of Things (IoT) is an emerging paradigm that transforms everyday devices (Things) into Internet-connected devices with sensing, processing, and actuation capabilities. These devices have limited storage and processing capacity, so they have been integrated with Cloud computing to overcome these limitations. Cloud computing offers various benefits such as offload data storage and processing burden at the Cloud side. Nevertheless, because Cloud is not an efficient solution for IoT latency-sensitive applications, Fog computing was introduced to address this limitation. Although Fog–Cloud IoT environments have begun to be adopted in the last few years, such environments have not been properly assessed in terms of their capacity to meet the growing demand of IoT devices. In this work, we present a Deterministic and Stochastic Petri Net (DSPN) approach for evaluating Fog–Cloud IoT environments composed of hundreds physical Things. Our approach allows evaluating the trade-offs of many performability metrics (e.g., utilization, response time, throughput, and availability) and, consequently, may help system designers to choose the most suitable Fog–Cloud IoT environment. We demonstrate the feasibility of our approach through a real-world case study. The results revealed that adopting a Fog device can improve availability. However, the performance is only improved in certain conditions like when the environment is not at full capacity.",http://dx.doi.org/10.1007/s10922-020-09570-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-04874-y,Machine learning and data analytics for the IoT,Neural Computing and Applications,10.1007/s00521-020-04874-y,Springer,2020-10-01,"The Internet of Things (IoT) applications have grown in exorbitant numbers, generating a large amount of data required for intelligent data processing. However, the varying IoT infrastructures (i.e., cloud, edge, fog) and the limitations of the IoT application layer protocols in transmitting/receiving messages become the barriers in creating intelligent IoT applications. These barriers prevent current intelligent IoT applications to adaptively learn from other IoT applications. In this paper, we critically review how IoT-generated data are processed for machine learning analysis and highlight the current challenges in furthering intelligent solutions in the IoT environment. Furthermore, we propose a framework to enable IoT applications to adaptively learn from other IoT applications and present a case study in how the framework can be applied to the real studies in the literature. Finally, we discuss the key factors that have an impact on future intelligent applications for the IoT.",http://dx.doi.org/10.1007/s00521-020-04874-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-020-02447-4,An exploratory teaching program in big data analysis for undergraduate students,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-020-02447-4,Springer,2020-10-01,"Many of the world’s biggest discoveries and decisions in science, technology, business, medicine, politics, and society as a whole, are now being made on the basis of analyzing massive datasets. In this paper, exploratory teaching program is proposed. It provides a broad and practical introduction to big data analysis. This exploratory teaching program was designed and given in Department of Computer Engineering at Kocaeli University in the spring semester of 2018–2019. To assess the educational program’s impact on the learning process and to evaluate the acceptance and satisfaction level of students, they answered a questionnaire after finishing the program. According to students’ feedback, the exploratory teaching program is useful for learning how to analyze large datasets and identify patterns that will improve any company’s and organization decision-making process.",http://dx.doi.org/10.1007/s12652-020-02447-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01724-1,Improving graph-based label propagation algorithm with group partition for fraud detection,Applied Intelligence,10.1007/s10489-020-01724-1,Springer,2020-10-01,"Fraudulent user detection is a crucial issue in financial risk management. Due to the lack of labeled data and the reliability of labeling, label propagation algorithms (LPA) are effective solutions in this scenario. Most existing models only propagate the risk probabilities for individual users through feature level, while ignoring the real-world graph structure and the characteristics of gang crime. This paper improves the graph-based LPA through group partition, which can be directly implemented on the graph at hand with full consideration of the group information. The exhaustive experimental results testify the performance of our proposed model KGLPA over other off-the-shelf models and amend the insufficiency of feature-based LPA with higher reliability and stability to improve the detection of fraudulent users and secure the marketing budgets.",http://dx.doi.org/10.1007/s10489-020-01724-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11704-019-9117-x,Proactive planning of bandwidth resource using simulation-based what-if predictions for Web services in the cloud,Frontiers of Computer Science,10.1007/s11704-019-9117-x,Springer,2020-09-29,"Resource planning is becoming an increasingly important and timely problem for cloud users. As more Web services are moved to the cloud, minimizing network usage is often a key driver of cost control. Most existing approaches focus on resources such as CPU, memory, and disk I/O. In particular, CPU receives the most attention from researchers, but the bandwidth is somehow neglected. It is challenging to predict the network throughput of modern Web services, due to the factors of diverse and complex response, evolving Web services, and complex network transportation. In this paper, we propose a methodology of what-if analysis, named Log2Sim, to plan the bandwidth resource of Web services. Log2Sim uses a lightweight workload model to describe user behavior, an automated mining approach to obtain characteristics of workloads and responses from massive Web logs, and traffic-aware simulations to predict the impact on the bandwidth consumption and the response time in changing contexts. We use a real-life Web system and a classic benchmark to evaluate Log2Sim in multiple scenarios. The evaluation result shows that Log2Sim has good performance in the prediction of bandwidth consumption. The average relative error is 2% for the benchmark and 8% for the real-life system. As for the response time, Log2Sim cannot produce accurate predictions for every single service request, but the simulation results always show similar trends on average response time with the increase of workloads in different changing contexts. It can provide sufficient information for the system administrator in proactive bandwidth planning.",http://dx.doi.org/10.1007/s11704-019-9117-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11704-020-9159-0,Information retrieval: a view from the Chinese IR community,Frontiers of Computer Science,10.1007/s11704-020-9159-0,Springer,2020-09-29,"During a two-day strategic workshop in February 2018, 22 information retrieval researchers met to discuss the future challenges and opportunities within the field. The outcome is a list of potential research directions, project ideas, and challenges. This report describes the major conclusions we have obtained during the workshop. A key result is that we need to open our mind to embrace a broader IR field by rethink the definition of information, retrieval, user, system, and evaluation of IR. By providing detailed discussions on these topics, this report is expected to inspire our IR researchers in both academia and industry, and help the future growth of the IR research community.",http://dx.doi.org/10.1007/s11704-020-9159-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-020-2952-7,Graph algorithms: parallelization and scalability,Science China Information Sciences,10.1007/s11432-020-2952-7,Springer,2020-09-21,"For computations on large-scale graphs, one often resorts to parallel algorithms. However, parallel algorithms are difficult to write, debug and analyze. Worse still, it is difficult to make algorithms parallelly scalable, such that the more machines are used, the faster the algorithms run. Indeed, it is not yet known whether any PTIME computational problems admit parallelly scalable algorithms on shared-nothing systems. Is it possible to parallelize sequential graph algorithms and guarantee convergence at the correct results as long as the sequential algorithms are correct? Moreover, does a PTIME parallelly scalable problem exist on shared-nothing systems? This position paper answers both questions in the affirmative.",http://dx.doi.org/10.1007/s11432-020-2952-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-020-09856-1,Data-driven software design with Constraint Oriented Multi-variate Bandit Optimization (COMBO),Empirical Software Engineering,10.1007/s10664-020-09856-1,Springer,2020-09-01,"Context Software design in e-commerce can be improved with user data through controlled experiments (i.e. A/B tests) to better meet user needs. Machine learning-based algorithmic optimization techniques extends the approach to large number of variables to personalize software to different user needs. So far the optimization techniques has only been applied to optimize software of low complexity, such as colors and wordings of text. Objective In this paper, we introduce the COMBO toolkit with capability to model optimization variables and their relationship constraints specified through an embedded domain-specific language. The toolkit generates personalized software configurations for users as they arrive in the system, and the configurations improve over time in in relation to some given metric. COMBO has several implementations of machine learning algorithms and constraint solvers to optimize the model with user data by software developers without deep optimization knowledge. Method The toolkit was validated in a proof-of-concept by implementing two features that are relevant to Apptus, an e-commerce company that develops algorithms for web shops. The algorithmic performance was evaluated in simulations with realistic historic user data. Results The validation shows that the toolkit approach can model and improve relatively complex features with many types of variables and constraints, without causing noticeable delays for users. Conclusions We show that modeling software hierarchies in a formal model facilitates algorithmic optimization of more complex software. In this way, using COMBO, developers can make data-driven and personalized software products.",http://dx.doi.org/10.1007/s10664-020-09856-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-020-00292-z,Could or could not of Grid-Loc: grid BLE structure for indoor localisation system using machine learning,Service Oriented Computing and Applications,10.1007/s11761-020-00292-z,Springer,2020-09-01,"Indoor localisation and its various applications have received significant attention in recent years. The state-of-the-art systems include a large number of complex hardware structures and algorithms making the system not suitable for practical applications. In this paper, we integrate a localisation system that consists of device development, model deployment, data collection and localisation algorithm to explore the localisation accuracy in a special static indoor environment (i.e. a meeting room or a parking lot). Compared with previous studies, the significance of our work is to find out a more convenient and practical way to deploy devices with a simple algorithm (e.g. machine learning algorithm) in such a scenario. Besides, it is meaningful to explore the technology of indoor localisation based on the application scenario. We propose a Grid-Loc system that presents a grid structure of Bluetooth low-energy devices to collect data assisting localisation. The system is easy to deploy for reducing the signal attenuation caused by the objects’ occlusion. Meanwhile, the system applies an algorithm that combines adaptive boosting with a support vector machine algorithm to support the system. In our deployed localisation scenario, we also compare localisation performances for several algorithms; the result shows the Grid-Loc system achieves the accuracy of 91.2%, computing time within 3 s in real time and a low cost. The system is also robust and scalable under the same indoor environments.",http://dx.doi.org/10.1007/s11761-020-00292-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01646-y,A BOA-based adaptive strategy with multi-party perspective for automated multilateral negotiations,Applied Intelligence,10.1007/s10489-020-01646-y,Springer,2020-09-01,"Determining an effective strategy for intelligent agents in multilateral negotiations is a more complicated problem than in bilateral negotiations. In order to achieve an optimal and beneficial agreement the agent needs to consider the behavior and desired utility of more than one opponent, determine a concession tactic based on a smaller agreement space, and use a computationally efficient mechanism for generating optimal offers. However, a mere extension of bilateral negotiation strategies cannot be effective in multilateral negotiations because the nature of most bilateral negotiation strategies is based on interaction with only one opponent and tracking a single behavior during the negotiation process. In this paper, we propose an adaptive approach based on a multi-party perspective to determine multilateral negotiation strategy. The proposed approach applies the BOA framework (Bidding, Opponent model, and Acceptance) and dynamically models the opponents’ preference profiles. In order to estimate the obtainable utility from opponents and help find a good offer, the agent uses an ensemble model made by individual frequency-based opponent models and a different level of attention to each party’s behavior. The proposed approach also implements a bidding strategy which applies the opponents’ desirable utility to adapt the agent’s concession tactic and produce appropriate offers. The results of experimental evaluations on various negotiation scenarios against the state of the art multilateral negotiation strategies show that our proposed strategy can provide superior performance in both individual utility and social welfare and lead to more optimal and fairer agreements.",http://dx.doi.org/10.1007/s10489-020-01646-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-04764-3,Adaptive path finding algorithm in dynamic environment for warehouse robot,Neural Computing and Applications,10.1007/s00521-020-04764-3,Springer,2020-09-01,"Warehouse robots have been widely used by manufacturers and online retailer to automate good delivery process. One of the fundamental components when designing a warehouse robot is path finding algorithm. In the past, many path finding algorithms had been proposed to identify the optimal path and improve the efficiency in different conditions. For example, A* path finding algorithm is developed to obtain the shortest path, while D* obtains a complete coverage path from source to destination. Although these algorithms improved the efficiency in path finding, dynamic obstacle that may exist in warehouse environment was not considered. This paper presents AD* algorithm, a path finding algorithm that works in dynamic environment for warehouse robot. AD* algorithm is able to detect not only static obstacle but also dynamic obstacles while operating in warehouse environment. In dynamic obstacle path prediction, image of the warehouse environment is processed to identify and track obstacles in the path. The image is pre-processed using perspective transformation, dilation and erosion. Once obstacle has been identified using background subtraction, the server will track and predict future path of the dynamic object to avoid the obstacle.",http://dx.doi.org/10.1007/s00521-020-04764-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s41044-020-00045-1,Software architectures for big data: a systematic literature review,Big Data Analytics,10.1186/s41044-020-00045-1,BioMed Central,2020-08-14,"Big Data systems are often composed of information extraction, preprocessing, processing, ingestion and integration, data analysis, interface and visualization components. Different big data systems will have different requirements and as such apply different architecture design configurations. Hence a proper architecture for the big data system is important to achieve the provided requirements. Yet, although many different concerns in big data systems are addressed the notion of architecture seems to be more implicit. In this paper we aim to discuss the software architectures for big data systems considering architectural concerns of the stakeholders aligned with the quality attributes. A systematic literature review method is followed implementing a multiple-phased study selection process screening the literature in significant journals and conference proceedings.",http://dx.doi.org/10.1186/s41044-020-00045-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41598-020-70382-7,Characterization of complex fluvio–deltaic deposits in Northeast China using multi-modal machine learning fusion,Scientific Reports,10.1038/s41598-020-70382-7,Nature,2020-08-07,"Due to the lack of petroleum resources, stratigraphic reservoirs have become an important source of future discoveries. We describe a methodology for predicting reservoir sands from complex reservoir seismic data. Data analysis involves a bio-integrated framework called multi-modal machine learning fusion (MMMLF) based on neural networks. First, acoustic-related seismic attributes from post-stack seismic data were used to characterize the reservoirs. They enhanced the understanding of the structure and spatial distribution of petrophysical properties of lithostratigraphic reservoirs. The attributes were then classified as varied modal inputs into a central fusion engine for prediction. We applied the method to a dataset from Northeast China. Using seismic attributes and rock physics relationships as input data, MMMLF was performed to predict the spatial distribution of lithology in the Upper Guantao substrata. Despite the large scattering in the acoustic-related data properties, the proposed MMMLF methodology predicted the distribution of lithological properties through the gamma ray logs. Moreover, complex stratigraphic traps such as braided fluvial sandstones in the fluvio–deltaic deposits were delineated. These findings can have significant implications for future exploration and production in Northeast China and similar petroleum provinces around the world.",http://dx.doi.org/10.1038/s41598-020-70382-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-020-00254-4,Security and Privacy Issues in Deep Learning: A Brief Review,SN Computer Science,10.1007/s42979-020-00254-4,Nature,2020-08-06,"Nowadays, deep learning is becoming increasingly important in our daily life. The appearance of deep learning in many applications in life relates to prediction and classification such as self-driving, product recommendation, advertisements and healthcare. Therefore, if a deep learning model causes false predictions and misclassification, it can do great harm. This is basically a crucial issue in the deep learning model. In addition, deep learning models use large amounts of data in the training/learning phases, which contain sensitive information. Therefore, when deep learning models are used in real-world applications, it is required to protect the privacy information used in the model. In this article, we carry out a brief review of the threats and defenses methods on security issues for the deep learning models and the privacy of the data used in such models while maintaining their performance and accuracy. Finally, we discuss current challenges and future developments.",http://dx.doi.org/10.1007/s42979-020-00254-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-019-01531-7,Machine learning applied in production planning and control: a state-of-the-art in the era of industry 4.0,Journal of Intelligent Manufacturing,10.1007/s10845-019-01531-7,Springer,2020-08-01,"Because of their cross-functional nature in the company, enhancing Production Planning and Control (PPC) functions can lead to a global improvement of manufacturing systems. With the advent of the Industry 4.0 (I4.0), copious availability of data, high-computing power and large storage capacity have made of Machine Learning (ML) approaches an appealing solution to tackle manufacturing challenges. As such, this paper presents a state-of-the-art of ML-aided PPC (ML-PPC) done through a systematic literature review analyzing 93 recent research application articles. This study has two main objectives: contribute to the definition of a methodology to implement ML-PPC and propose a mapping to classify the scientific literature to identify further research perspectives. To achieve the first objective, ML techniques, tools, activities, and data sources which are required to implement a ML-PPC are reviewed. The second objective is developed through the analysis of the use cases and the addressed characteristics of the I4.0. Results suggest that 75% of the possible research domains in ML-PPC are barely explored or not addressed at all. This lack of research originates from two possible causes: firstly, scientific literature rarely considers customer, environmental, and human-in-the-loop aspects when linking ML to PPC. Secondly, recent applications seldom couple PPC to logistics as well as to design of products and processes. Finally, two key pitfalls are identified in the implementation of ML-PPC models: the complexity of using Internet of Things technologies to collect data and the difficulty of updating the ML model to adapt it to the manufacturing system changes.",http://dx.doi.org/10.1007/s10845-019-01531-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-019-04266-x,PSO-based novel resource scheduling technique to improve QoS parameters in cloud computing,Neural Computing and Applications,10.1007/s00521-019-04266-x,Springer,2020-08-01,"Cloud computing provides infinite resources and various services for the execution of variety of applications to end users, but still it has various challenges that need to be addressed. Objective of cloud users is to select the optimal resource that meets the demand of end users in reasonable cost and time, but sometimes users pay more for short time. Most of the proposed state-of-the-art algorithms try to optimize only one parameter at a time. Therefore, a novel compromise solution is needed to make the balance between conflicting objectives. The main goal of this research paper is to design and develop a task processing framework that has the decision-making capability to select the optimal resource at runtime to process the applications (diverse and complex nature) at virtual machines using modified particle swarm optimization (PSO) algorithm within a user-defined deadline. Proposed algorithm gives non-dominance set of optimal solutions and improves various influential parameters (time, cost, throughput, task acceptance ratio) by series of experiments over various synthetic datasets using Cloudsim tool. Computational results show that proposed algorithm well and substantially outperforms the baseline heuristic and meta-heuristic such as PSO, adaptive PSO, artificial bee colony, BAT algorithm, and improved min–min load-balancing algorithm.",http://dx.doi.org/10.1007/s00521-019-04266-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12599-019-00612-4,Exploring the Relations Between Net Benefits of IT Projects and CIOs’ Perception of Quality of Software Development Disciplines,Business & Information Systems Engineering,10.1007/s12599-019-00612-4,Springer,2020-08-01,"Software development enterprises are under consistent pressure to improve their management techniques and development processes. These are comprised of several software development methodology (SDM) disciplines such as requirements acquisition, design, coding, testing, etc. that must be continuously improved and individually tailored to suit specific software development projects. The paper proposes a methodology that enables the identification of SDM discipline quality categories and the evaluation of SDM disciplines’ net benefits. It advances the evaluation of software process quality from single quality category evaluation to multiple quality categories evaluation as proposed by the Kano model. An exploratory study was conducted to test the proposed methodology. The exploratory study results show that different types of Kano quality are present in individual SDM disciplines and that applications of individual SDM disciplines vary considerably in their relation to net benefits of IT projects. Consequently, software process quality evaluation models should start evaluating multiple categories of quality instead of just one and should not assume that the application of every individual SDM discipline has the same effect on the enterprise’s net benefits.",http://dx.doi.org/10.1007/s12599-019-00612-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-04730-z,Scale-fusion framework for improving video-based person re-identification performance,Neural Computing and Applications,10.1007/s00521-020-04730-z,Springer,2020-08-01,"Video-based person re-identification (re-id), which aims to match people through videos captured by non-overlapping camera views, has attracted lots of research interest recently. In this paper, we first propose a novel hybrid 2D and 3D convolution-based recurrent neural network (HCRN) for video-based person re-id task. Specifically, the 3D convolutional module can explore the local short-term fast-varying motion information, while the recurrent layer can leverage the global long-term spatial–temporal information. Based on HCRN, we design a scale-fusion framework to make full use of features of different scales to further improve the performance of video-based person re-id. More concretely, the scale-fusion framework preserves a complete subnetwork similar to HCRN for each scale to extract features and exchanges information between all subnetworks at several stages of the framework. Besides, we propose a training method called species invasion to further improve the performance of HCRN and scale-fusion framework by utilizing a large amount of unlabeled data. Experimental results on the publicly available PRID 2011, iLIDS-VID and MARS multi-shot pedestrian re-id datasets demonstrate the effectiveness of the proposed HCRN, scale-fusion framework and species invasion training method.",http://dx.doi.org/10.1007/s00521-020-04730-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-019-09915-z,Citizen Science: An Information Quality Research Frontier,Information Systems Frontiers,10.1007/s10796-019-09915-z,Springer,2020-08-01,"The rapid proliferation of online content producing and sharing technologies resulted in an explosion of user-generated content (UGC), which now extends to scientific data. Citizen science, in which ordinary people contribute information for scientific research, epitomizes UGC. Citizen science projects are typically open to everyone, engage diverse audiences, and challenge ordinary people to produce data of highest quality to be usable in science. This also makes citizen science a very exciting area to study both traditional and innovative approaches to information quality management. With this paper we position citizen science as a leading information quality research frontier. We also show how citizen science opens a unique opportunity for the information systems community to contribute to a broad range of disciplines in natural and social sciences and humanities.",http://dx.doi.org/10.1007/s10796-019-09915-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-020-04461-2,"A Survey on Secure Transmission in Internet of Things: Taxonomy, Recent Techniques, Research Requirements, and Challenges",Arabian Journal for Science and Engineering,10.1007/s13369-020-04461-2,Springer,2020-08-01,"Internet of things (IoT) is one of the emerging paradigms in the current era that has attracted many researchers due to its widespread applications. Due to the open nature of the device accessibility and heterogeneity, a rapid increase in connected devices leads to several vulnerabilities and threats in the IoT devices. Hence, security is one of the important concern and main challenge to be addressed for the guaranteed data transmission in IoT environment. In this review work, we analyze the secure transmission of data in IoT and investigate the recent approaches in IoT security and their requirements and open issues. We present a taxonomy model for the secure transmission in IoT security which includes architecture/layers, communication topology, and classification techniques which are categorized under cluster, trust, routing, blockchain, and location-based approaches. First, we briefly discuss the architecture of the IoT ecosystem that consists of three layers namely perception, network, and application layer which support the basic task such as transmission, sensing, and processing. Next, we classify the communication mechanism into different scenarios involved in the various network for the transmission of data in the IoT environment. Then, we investigate the recent approaches for secure communication to overcome certain attacks in IoT and analyze their strength and limitations. Finally, we discuss the security requirements, threats, and vulnerabilities faced by the current IoT system, and numerous open research challenges that are needed to be addressed for the efficient transmission of data as future research directions.",http://dx.doi.org/10.1007/s13369-020-04461-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10640-020-00493-2,Perspectives on the Economics of the Environment in the Shadow of Coronavirus,Environmental and Resource Economics,10.1007/s10640-020-00493-2,Springer,2020-08-01,,http://dx.doi.org/10.1007/s10640-020-00493-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-019-04534-w,A novel recommendation method based on general matrix factorization and artificial neural networks,Neural Computing and Applications,10.1007/s00521-019-04534-w,Springer,2020-08-01,"Collaborative filtering is a successful approach in relevant item or service recommendation provision to users in rich, online domains. This approach has been widely applied in commercial environments with success, especially in online marketing, similar product suggestion and selection and tailor-made consumer suggestions. However, regardless of its market penetration, there are still considerable limitations in terms of accuracy in the proposed recommendations stemming from the high-frequency low-relevance user-item bias, data specificities and individual user patterns and needs that may be hidden in data. We propose a novel recommendation approach that improves accuracy and requires significantly less maintenance compared to traditional collaborative filtering. For the experimental evaluation, we use two real data sets and well-known metrics with the results validating our method. Our proposed method outperforms all the alternative recommendation methods for each of the two data sets and metrics and seems holistically effective against alternatives since it requires fewer settings to be considered without affecting the output.",http://dx.doi.org/10.1007/s00521-019-04534-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-020-00234-8,"GenAtSeq GAN with Heuristic Reforms for Knowledge Centric Network with Browsing Characteristics Learning, Individual Tracking and Malware Detection with Website2Vec",SN Computer Science,10.1007/s42979-020-00234-8,Nature,2020-07-08,"Identification of individuals through the use of electronic footprints can be a security vulnerability and also a blessing in disguise. In this work, we have introduced how we can scale up and enhance representations using the generalized form of GAN architecture, capable of learning from generative features and differences in generalized representation. We applied the architecture for accurate person identification and person tracking using a series of browsing footprint patterns and, at the same time, can easily be extended for detection of anomaly, malware, and other browser-based phishing software activity detection. Our proposed GAN network is characterized for the detection of individuals through dissimilarity between real and generated samples and quantification of detected difference, both of which enhanced learning content. Our contributions are in the architectural definition of Generalized Attentive Sequential Generative Adversarial Network (GenAtSeq-GAN), identification of log characteristics for discrimination, and the procedure for scaling up the detection system. We achieved the effectiveness of 80.7% for GenAtSeq, 46 units higher than the older sequential GAN versions.",http://dx.doi.org/10.1007/s42979-020-00234-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-019-04557-3,"Review of intrusion detection systems based on deep learning techniques: coherent taxonomy, challenges, motivations, recommendations, substantial analysis and future directions",Neural Computing and Applications,10.1007/s00521-019-04557-3,Springer,2020-07-01,"This study reviews and analyses the research landscape for intrusion detection systems (IDSs) based on deep learning (DL) techniques into a coherent taxonomy and identifies the gap in this pivotal research area. The focus is on articles related to the keywords ‘deep learning’, ‘intrusion’ and ‘attack’ and their variations in four major databases, namely Web of Science, ScienceDirect, Scopus and the Institute of Electrical and Electronics Engineers’ Xplore . These databases are sufficiently broad to cover the technical literature. The dataset comprises 68 articles. The largest proportion (72.06%; 49/68) relates to articles that develop an approach for evaluating or identifying intrusion detection techniques using the DL approach. The second largest proportion (22.06%; 15/68) relates to studying/applying articles to the DL area, IDSs or other related issues. The third largest proportion (5.88%; 4/68) discusses frameworks/models for running or adopting IDSs. The basic characteristics of this emerging field are identified from the aspects of motivations, open challenges that impede the technology’s utility, authors’ recommendations and substantial analysis. Then, a result analysis mapping for new directions is discussed. Three phases are designed to meet the demands of detecting distributed denial-of-service attacks with a high accuracy rate. This study provides an extensive resource background for researchers who are interested in IDSs based on DL.",http://dx.doi.org/10.1007/s00521-019-04557-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-019-09246-3,A recommendation approach for user privacy preferences in the fitness domain,User Modeling and User-Adapted Interaction,10.1007/s11257-019-09246-3,Springer,2020-07-01,"Fitness trackers are undoubtedly gaining in popularity. As fitness-related data are persistently captured, stored, and processed by these devices, the need to ensure users’ privacy is becoming increasingly urgent. In this paper, we apply a data-driven approach to the development of privacy-setting recommendations for fitness devices. We first present a fitness data privacy model that we defined to represent users’ privacy preferences in a way that is unambiguous, compliant with the European Union’s General Data Protection Regulation (GDPR), and able to represent both the user and the third party preferences. Our crowdsourced dataset is collected using current scenarios in the fitness domain and used to identify privacy profiles by applying machine learning techniques. We then examine different personal tracking data and user traits which can potentially drive the recommendation of privacy profiles to the users. Finally, a set of privacy-setting recommendation strategies with different guidance styles are designed based on the resulting profiles. Interestingly, our results show several semantic relationships among users’ traits, characteristics, and attitudes that are useful in providing privacy recommendations. Even though several works exist on privacy preference modeling, this paper makes a contribution in modeling privacy preferences for data sharing and processing in the IoT and fitness domain, with specific attention to GDPR compliance. Moreover, the identification of well-identified clusters of preferences and predictors of such clusters is a relevant contribution for user profiling and for the design of interactive recommendation strategies that aim to balance users’ control over their privacy permissions and the simplicity of setting these permissions.",http://dx.doi.org/10.1007/s11257-019-09246-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-019-01439-3,"A RESTful middleware for AI controlled sensors, actuators and smart devices",Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-019-01439-3,Springer,2020-07-01,"The numerous applications of internet of things (IoT) and sensor networks combined with specialized devices used in each has led to a proliferation of domain specific middleware, which in turn creates interoperability issues between the corresponding architectures and the technologies used. But what if we wanted to use a machine learning algorithm to an IoT application so that it adapts intelligently to changes of the environment, or enable a software agent to enrich with artificial intelligence (AI) a smart home consisting of multiple and possibly incompatible technologies? In this work we answer these questions by studying a framework that explores how to simplify the incorporation of AI capabilities to existing sensor-actuator networks or IoT infrastructures making the services offered in such settings smarter. Towards this goal we present eVATAR+, a middleware that implements the interactions within the context of such integrations systematically and transparently from the developers’ perspective. It also provides a simple and easy to use interface for developers to use. eVATAR+ uses JAVA server technologies enhanced by mediator functionality providing interoperability, maintainability and heterogeneity support. We exemplify eVATAR+ with a concrete case study and we evaluate the relative merits of our approach by comparing our work with the current state of the art.",http://dx.doi.org/10.1007/s12652-019-01439-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-020-07251-z,Cloud Integrated IoT Enabled Sensor Network Security: Research Issues and Solutions,Wireless Personal Communications,10.1007/s11277-020-07251-z,Springer,2020-07-01,"Security of cloud computing and Internet of things (IoT) enabled sensor networks are two significant areas of research that have a great impact in developing numerous societal applications such as smart healthcare, smart city, smart agriculture etc. in a secure manner. The devices involved in these technologies are exposed to vulnerabilities since they are distributed in nature and moreover they try to fetch real-time information and forward it to cloud for processing. Cloud computing offers a platform for storing and processing the data sensed and sent by the sensor devices. In the previous literature, many researchers have studied the security issues and challenges of IoT and Cloud separately. Still, there is a gap in the literature and it is required to explore the integrated security issues in the Cloud integrated IoT environment. Analyzing the integrated security issues of the existing technologies is of much importance and novel idea for their successful implementation. In this paper we focused on exploring the vulnerabilities of the integrated environment. In addition, we had presented the security issues and challenges in the cloud and IoT enabled sensor environment.",http://dx.doi.org/10.1007/s11277-020-07251-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41870-020-00492-y,Organizational agility considering enablers and capabilities of agility with RBF neural network approach and multiple regressions,International Journal of Information Technology,10.1007/s41870-020-00492-y,Springer,2020-06-21,"The main purpose of this research is to identify the agility enabler indicators of the organization and the dimensions of agility enabler and how the agility enabler indicators can be used to achieve the agile system. In this study, the RBF neural network model and multiple regression models were used to achieve the ideal level of agility and to analyze the effect of indicators as well as to provide an optimal path to achieve agility. According to the results of the neural network approach, each organization should focus on automation to increase its agility level. Also in output variables, speed, responsiveness and flexibility have the most impact on model inputs. To achieve the agility of the organization, output variables must be upgraded to a certain level, and this upgrade is only possible by increasing the level of input variables. Further, the results of multiple regression showed that the automation and staff variables had the most and technology had the least impacts, respectively. Consequently, in order to reach an acceptable level of the dimensions of agility capabilities, the key variable (s) extracted from the analysis of this research must be identified and we must achieve the desired results by modifying them. In this case, maximum efficiency and upgrading agility level could be achieved by minimal time and cost.",http://dx.doi.org/10.1007/s41870-020-00492-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-019-00351-0,Supporting customer-oriented marketing with artificial intelligence: automatically quantifying customer needs from social media,Electronic Markets,10.1007/s12525-019-00351-0,Springer,2020-06-01,"The elicitation and monitoring of customer needs is an important task for businesses, allowing them to design customer-centric products and services and control marketing activities. While there are different approaches available, most lack in automation, scalability and monitoring capabilities. In this work, we demonstrate the feasibility towards an automated prioritization and quantification of customer needs from social media data. To do so, we apply a supervised machine learning approach on the example of previously labeled Twitter data from the domain of e-mobility. We descriptively code over 1000 German tweets and build eight distinct classification models, so that a resulting artifact can independently determine the probabilities of a tweet containing each of the eight previously defined needs. To increase the scope of application, we deploy the machine learning models as part of a web service for public use. The resulting artifact can provide valuable insights for need elicitation and monitoring when analyzing user-generated content on a large scale.",http://dx.doi.org/10.1007/s12525-019-00351-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-019-00359-6,How affordances of chatbots cross the chasm between social and traditional enterprise systems,Electronic Markets,10.1007/s12525-019-00359-6,Springer,2020-06-01,"Digital and agile companies widely use chatbots in the form of integrations into enterprise messengers such as Slack and Microsoft Teams. However, there is a lack of empirical evidence about their action possibilities (i.e., affordances), for example, to link social interactions with third-party systems and processes. Therefore, we adopt a three-stage process. Grounded in a preliminary study and a qualitative study with 29 interviews from 17 organizations, we inductively derive rich contextual insights of 14 affordances and constraints, which serve as input for a Q-Methodology study that highlights five perceptional differences. We find that actualizing these affordances leads to higher-level affordances of chatbots that augment social information systems with affordances of traditional enterprise systems. Crossing the chasm between these, so far, detached systems contributes a novel perspective on how to balance novel digital with traditional systems, flexibility and malleability with stability and control, exploration with exploitation, and agility with discipline.",http://dx.doi.org/10.1007/s12525-019-00359-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42044-019-00052-z,A comprehensive survey on trajectory-based location prediction,Iran Journal of Computer Science,10.1007/s42044-019-00052-z,Springer,2020-06-01,"Recent explorative growth in telecommunication and telepathy technology has flooded the market with location-based data, which paves the way for location-aware prediction services. These applications have vast domain influence in route navigation, recommendation system, traffic-congestion control, ecological study, climatological forecast, and many more. Research efforts are spent on the put-forward overall picture of location prediction through trajectory data. This survey offers an extensive overview of location prediction enveloping basic definitions and concepts, data sources, approaches, and applications. Moreover, Spatial–Temporal pattern-based prediction models are discussed, highlighting the advantages and disadvantages of each. Sequential, periodic, and frequent pattern mining advances are noted. This paper presents a recent deep learning methodology for extracting features of a large trajectory. Distributive big data models using Hadoop and MapReduce frameworks are recorded. Location prediction using the social media platform is mentioned. Content-based and semantic mining models are studied. Tables and diagrams are displayed to provide at a glance view to facilitate smooth understanding. Furthermore, application and challenges are addressed related to the next location prediction. The overall conclusion of the survey and future directions are also listed.",http://dx.doi.org/10.1007/s42044-019-00052-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12530-019-09302-8,Recommender systems for IoT enabled quantified-self applications,Evolving Systems,10.1007/s12530-019-09302-8,Springer,2020-06-01,"As an emerging trend in big data science, applications based on the Quantified-Self (QS) engage individuals in the self-tracking of any kind of biological, physical, behavioral, or environmental information as individuals or groups. There are new needs and opportunities for recommender systems to develop new models/approaches to support QS application users. Recommender systems can help to more easily identify relevant artifacts for users and thus improve user experiences. Currently recommender systems are widely and effectively used in the e-commerce domain (e.g., online music services, online bookstores). Next-generation QS applications could include more recommender tools for assisting the users of QS systems based on their personal self-tracking data streams from wearable electronics, biosensors, mobile phones, genomic data, and cloud-based services. In this paper, we propose three new recommendation approaches for QS applications: Virtual Coach , Virtual Nurse , and Virtual Sleep Regulator which help QS users to improve their health conditions. Virtual Coach works like a real fitness coach to recommend personalized work-out plans whereas Virtual Nurse considers the medical history and health targets of a user to recommend a suitable physical activity plan. Virtual Sleep Regulator is specifically designed for insomnia (a kind of sleep disorder) patients to improve their sleep quality with the help of recommended physical activity and sleep plans. We explain how these proposed recommender technologies can be applied on the basis of the collected QS data to create qualitative recommendations for user needs. We present example recommendation results of Virtual Sleep Regulator on the basis of the dataset from a real world QS application.",http://dx.doi.org/10.1007/s12530-019-09302-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12599-020-00644-1,Virtual Assistance in Any Context,Business & Information Systems Engineering,10.1007/s12599-020-00644-1,Springer,2020-06-01,"Several domain-specific assistants in the form of chatbots have conquered many commercial and private areas. However, there is still a limited level of systematic knowledge of the distinctive characteristics of design elements for chatbots to facilitate development, adoption, implementation, and further research. To close this gap, the paper outlines a taxonomy of design elements for chatbots with 17 dimensions organized into the perspectives intelligence, interaction and context. The conceptually grounded design elements of the taxonomy are used to analyze 103 chatbots from 23 different application domains. Through a clustering-based approach, five chatbot archetypes that currently exist for domain-specific chatbots are identified. The developed taxonomy provides a structure to differentiate and categorize domain-specific chatbots according to archetypal qualities that guide practitioners when taking design decisions. Moreover, the taxonomy serves academics as a foundation for conducting further research on chatbot design while integrating scientific and practical knowledge.",http://dx.doi.org/10.1007/s12599-020-00644-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-019-02984-4,Service selection mechanisms in the Internet of Things (IoT): a systematic and comprehensive study,Cluster Computing,10.1007/s10586-019-02984-4,Springer,2020-06-01,"Internet of Things (IoT) describes embedded devices (things) with Internet-based connectivity, enabling them to receive and send data through the communication network. In addition, it provides infrastructure to let things have interacted with each other and people. This advantage of the IoT can increase reliability, sustainability, and efficiency by enhanced information access fashion. This technology can be used in various fields, such as environmental monitoring, home, and building automation and smart networks. Furthermore, the main aim of Service-Oriented Architecture (SOA) is to select the best services among a pool of services. These services can be selected statically or dynamically regarding the service functionalities and performance limitations. Since the performance of complex services is very important in many distributed domains. This study aims to systematically review the service selection mechanisms in the IoT. The service selection mechanisms are classified into centralized, decentralized, and hybrid classes. Also, the detailed evaluation of these techniques brings a good suggestion for further studies.",http://dx.doi.org/10.1007/s10586-019-02984-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12544-020-00405-x,Analyzing passenger and freight vehicle movements from automatic-Number plate recognition camera data,European Transport Research Review,10.1186/s12544-020-00405-x,Springer,2020-05-29,"Modern urban-transport planning requires evidence-based insights into current transport flows to better understand the needs and impacts of policymaking. Urban transport includes passenger and freight vehicles, which have different behavior, and the need for such a separation is often ignored in research and practice [ 1 ]. New digital data sources provide an opportunity to better understand urban transport and identify where policy interventions are required. We review the literature on digital counting techniques to monitor transport flows, including loops, Automatic-Number Plate Recognition (ANPR) cameras and floating car data. We further investigate the potential of ANPR cameras, which are widely deployed, and which can be augmented with vehicle category information. This article presents the methodology that we follow for transforming raw augmented ANPR camera data into practical knowledge for city planners. Our is aim is to provide a better understanding of passenger and freight vehicle movements and stops, identifying similarities and differences between vehicle categories. We demonstrate our methodology on a case study for the Mechelen-Willebroek district in Belgium, encompassing augmented data from 122 ANPR cameras for a period of two weeks. Additionally, we also look at the car-reduced zone and how time restrictions affect the different vehicle categories’ actions. The findings are validated with GPS data from heavy-good vehicles in the same period. The potential of augmented ANPR camera data and promising themes and applications of this data source are illustrated through the case study.",http://dx.doi.org/10.1186/s12544-020-00405-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-020-00639-6,A classification approach to link prediction in multiplex online ego-social networks,Social Network Analysis and Mining,10.1007/s13278-020-00639-6,Springer,2020-05-07,"Online social networks are the inseparable element of current modern societies and significantly influence forming and consolidating social relationships. In nature, these networks are multiplex so that multiple links may exist between the same two users across different social networks. In this paper, we study the ego-social features of multiplex links, spanning more than one social networks and apply their structural and interaction features to the problem of link prediction. The link prediction is applied for various cases in social networks such as new recommendations for users, friendship suggestions and fake relations discovery. Most of the real-world social networks promote communications in multi-layers (for example, the platform of multiple social networks). In this work, the problem of link prediction in multiple networks including Twitter (as a microblogging service) and Foursquare (as a place-based social network) has been studied. We consider the users jointly use both social network platforms and develop a classification algorithm for predicting the links. Hereto, the layers structural information is considered to predict the links in Foursquare network. Technically, solving this classification problem is accomplished through defining three sets of features based on nodal structure, ego-paths and meta-paths (SEM-Path). Three classic classifiers such as ID3, SVM and LR are used for the classification problem in the SEM-Path method. Our evaluations show that we can successfully predict links across social networking platforms. In fact, evaluations aim to shed light on the implications of multiplexity for the link generation process. The SVM classifier outperforms other classifiers with an average precision equal to 77.62%. Also, it has almost 1.5% superiority than the meta-path-based algorithm method.",http://dx.doi.org/10.1007/s13278-020-00639-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-019-04391-8,Assessing the quality of mobile graphical user interfaces using multi-objective optimization,Soft Computing,10.1007/s00500-019-04391-8,Springer,2020-05-01,"Aesthetic defects are a violation of quality attributes that are symptoms of bad interface design programming decisions. They lead to deteriorating the perceived usability of mobile user interfaces and negatively impact the User’s eXperience (UX) with the mobile app. Most existing studies relied on a subjective evaluation of aesthetic defects depending on end-users feedback, which makes the manual evaluation of mobile user interfaces human-centric, time-consuming, and error-prone. Therefore, recent studies have dedicated their effort to focus on the definition of mathematical formulas that each targets a specific structural quality of the interface. As the UX is tightly dependent on the user profile, the combination and calibration of quality attributes, formulas, and user’s characteristics, when defining a defect, are not straightforward. In this context, we propose a fully automated framework which combines literature quality attributes with the user’s profile to identify aesthetic defects of MUI. More precisely, we consider the mobile user interface evaluation as a multi-objective optimization problem where the goal is to maximize the number of detected violations while minimizing the detection complexity of detection rules and enhancing the interfaces overall quality in means of guidance and coherence coverage. We conducted a comparative study of several evolutionary algorithms in terms of accurately identifying aesthetic defects. We reported their performance in solving the proposed search-based multi-objective optimization problem. The results confirm the efficiency of the indicator-based evolutionary algorithm in terms of assessing the developers in detecting typical defects and also in generating the most accurate detection rules.",http://dx.doi.org/10.1007/s00500-019-04391-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-019-04247-1,Utilizing data science techniques to analyze skill and demand changes in healthcare occupations: case study on USA and UAE healthcare sector,Soft Computing,10.1007/s00500-019-04247-1,Springer,2020-04-01,"New technologies are emerging on a continual basis with drastic trajectories and wider penetration into the job market. Health care is among the top ten sectors in terms of talent turnover rates. Hence, being proactive—by predicting what skills will be in demand, is essential to be prepared for these changes. To predict such transitions, this paper aims to develop a job analysis system with an example from the healthcare field in two countries; United States of America and United Arab Emirates. This empirical research consists of using data science with the help of multiple techniques. To study changes in job demand, we deployed Latent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA) models; while for the skill changes we used techniques Factor Analysis and Non-Negative Matrix Factorization. Using different heatmaps visualizations of the LSI and LDA weights, results provided significant insights into the skill sets and demand changes in both job markets. The study concludes that low-skilled jobs are constantly being replaced by automated systems, while some of the high skill sets are also at risk.",http://dx.doi.org/10.1007/s00500-019-04247-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-018-0867-z,Organic and dynamic tool for use with knowledge base of AI ethics for promoting engineers’ practice of ethical AI design,AI & SOCIETY,10.1007/s00146-018-0867-z,Springer,2020-03-01,"In recent years, ethical questions related to the development of artificial intelligence (AI) are being increasingly discussed. However, there has not been enough corresponding increase in the research and development associated with AI technology that incorporates with ethical discussion. We therefore implemented an organic and dynamic tool for use with knowledge base of AI ethics for engineers to promote engineers’ practice of ethical AI design to realize further social values. Here, “organic” means that the tool deals with complex relationships among different AI ethics. “Dynamic” means that the tool dynamically adopts new issues and helps engineers think in their own contexts. Data in the knowledge base of the tool is standardized based on the ethical design theory that consists of an extension of the hierarchical representation of artifacts to understand ethical considerations from the perspective of engineering, and a description method to express the design ideas. In addition, we apply the dynamic knowledge management model called knowledge liquidization and crystallization. To discuss the effects, we introduce three cases: a case for the clarification of differences in the structures among AI ethics and design ideas, a case for the presentation of semantic distance among them, and a case for the recommendation of the scenario paths that allow engineers to seamlessly use AI ethics in their own contexts. We discuss the effectiveness of the tool. We also show the probability that engineers can reconstruct AI ethics as a more practical one with professional ethicists.",http://dx.doi.org/10.1007/s00146-018-0867-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-019-09685-9,The state of the art and taxonomy of big data analytics: view from new big data framework,Artificial Intelligence Review,10.1007/s10462-019-09685-9,Springer,2020-02-01,"Big data has become a significant research area due to the birth of enormous data generated from various sources like social media, internet of things and multimedia applications. Big data has played critical role in many decision makings and forecasting domains such as recommendation systems, business analysis, healthcare, web display advertising, clinicians, transportation, fraud detection and tourism marketing. The rapid development of various big data tools such as Hadoop, Storm, Spark, Flink, Kafka and Pig in research and industrial communities has allowed the huge number of data to be distributed, communicated and processed. Big data applications use big data analytics techniques to efficiently analyze large amounts of data. However, choosing the suitable big data tools based on batch and stream data processing and analytics techniques for development a big data system are difficult due to the challenges in processing and applying big data. Practitioners and researchers who are developing big data systems have inadequate information about the current technology and requirement concerning the big data platform. Hence, the strengths and weaknesses of big data technologies and effective solutions for Big Data challenges are needed to be discussed. Hence, due to that, this paper presents a review of the literature that analyzes the use of big data tools and big data analytics techniques in areas like health and medical care, social networking and internet, government and public sector, natural resource management, economic and business sector. The goals of this paper are to (1) understand the trend of big data-related research and current frames of big data technologies; (2) identify trends in the use or research of big data tools based on batch and stream processing and big data analytics techniques; (3) assist and provide new researchers and practitioners to place new research activity in this domain appropriately. The findings of this study will provide insights and knowledge on the existing big data platforms and their application domains, the advantages and disadvantages of big data tools, big data analytics techniques and their use, and new research opportunities in future development of big data systems.",http://dx.doi.org/10.1007/s10462-019-09685-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-018-0528-1,From mobility patterns to behavioural change: leveraging travel behaviour and personality profiles to nudge for sustainable transportation,Journal of Intelligent Information Systems,10.1007/s10844-018-0528-1,Springer,2020-02-01,"Rendering transport behaviours more sustainable is a pressing issue of our times. In this paper, we rely on the deep penetration of mobile phones in order to influence citizens’ behavior through data-driven mobility and persuasive profiles. Our proposed approach aims to nudge users on a personalized level in order to change their mobility behavior and make more sustainable choices. To achieve our goal, first we leverage pervasive mobile sensing to uncover users’ mobility patterns and use of transportation modes. Second, we construct users’ persuadability profiles by considering their personality and mobility behavior. With the use of the aforementioned information we generate personalized interventions that nudge users to adopt sustainable transportation habits. These interventions rely on persuasive technologies and are embedded in a route planning application for smartphones. A pilot study with 30 participants using the system for 6 weeks provided fairly positive evaluation results in terms of the acceptance of our approach and revealed instances of behavioural change.",http://dx.doi.org/10.1007/s10844-018-0528-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-018-1459-y,A mechanism for scheduling multi robot intelligent warehouse system face with dynamic demand,Journal of Intelligent Manufacturing,10.1007/s10845-018-1459-y,Springer,2020-02-01,"Given the evolutionary journey of E-commerce, there have been emerging challenges confronting warehouse logistics, including smaller shipping units, more varieties and batches, and shorter cycles. These challenges are difficult to cope when using conventional scheduling with the robotic approach. Currently, automated storage and retrieval system are becoming preferred for warehouse companies with the help of mobile robots. However, when many orders are received simultaneously, the existing scheduling approach might make unreasonable decisions, leading to delayed packaging of entire orders and reducing the performance of the warehouse. Therefore, this paper addresses this problem and proposes a novel scheduling mechanism for multi-robot and tasks allocation problems which may arise in an intelligent warehouse system. This mechanism proposes into the intelligent warehouse troubled with simultaneous multiple customer demands. The mathematical model for the system is developed by considering a multitask robot facing dynamic customer demand. The proposed model’s approach is based on the particle swarm optimization heuristic. The result for this approach then compared with the genetic algorithm (GA). The simulation results demonstrate that the proposed solution is far superior to that of the GA for multi-robot scheduling and tasks allocation problems in the intelligent warehouse.",http://dx.doi.org/10.1007/s10845-018-1459-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05325-3_75-1,Artificial Intelligence and Machine Learning in Global Healthcare,Handbook of Global Health,10.1007/978-3-030-05325-3_75-1,Springer,2020-01-01,"Although medicine has been receptive to the benefits of machine learning and artificial intelligence (AI), it has only recently started to adopt this rapidly evolving, disruptive technology, particularly when compared to finance, entertainment, and transport sectors. Machine learning enables the detection of hidden connections and patterns, including outcomes prediction. Data is critical for the development of intelligent models, which harness the potential to improve and redefine disease self-management, treatment, and wellness pathways. The consequences of digital health democratization have significant health and ethical impact. This chapter provides an introduction to machine learning and AI and the development of intelligent healthcare systems. It explores applications of AI in healthcare and how the ubiquity of smartphones and Internet of Things (IoT) has accelerated the global shift from volume-based to value-based healthcare. This chapter will highlight key challenges within machine learning, evaluate machine learning projects, and share examples of best practice healthcare AI. Finally, it will review the ethical concerns surrounding machine learning, including how machines affect human behavior, data ownership, bias, unintended consequences, and the advances that have been made to support the global shift toward value-based population health.",http://dx.doi.org/10.1007/978-3-030-05325-3_75-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-39047-1_3,AI—Assisted Chatbot for E-Commerce to Address Selection of Products from Multiple Products,"Internet of Things, Smart Computing and Technology: A Roadmap Ahead",10.1007/978-3-030-39047-1_3,Springer,2020-01-01,"Artificial Intelligence has been used nowadays increasingly to develop and advance numerous fields and industries, including finance, healthcare, education, transportation, and more. Machine Learning is a subset of AI techniques which includes various algorithms that gives machines the ability to learn from data or while interacting with the world without being explicitly programmed. E-commerce websites are trending nowadays due to online shopping makes customer’s life easier. Similar to this, Chatter Robots i.e. Chatbots are providing better customer service through Internet. A chatbot is a computer or software program for simulating intelligent conversations with human using rules or artificial intelligence for machine. Users can interact with the chatbot program via conversational interface through written or spoken text as input. With the help of E-commerce website sellers can reach to larger audience and with the help of chatbots, sales can be increased by personal interaction with the users. Chatbots will welcome a user to conversation, guide to customer to make purchase which will reduce customer’s struggle. Chatbots will ask customers all the relevant questions to find the perfect fit, style, and color for them. Chatbots are the future of marketing and customer support. Chatbots are one such means of technology which helps humans in a lot of ways, by helping them in e-commerce to increase sales whilst providing great customer satisfaction.",http://dx.doi.org/10.1007/978-3-030-39047-1_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-48950-2_17,Strategic Trends for e-Business,Strategies for e-Business,10.1007/978-3-030-48950-2_17,Springer,2020-01-01,"This chapter will provide a landscape of strategic trends for e-business and indicate what will fundamentally change and revolutionize e-business in the future. Businesses should consider how to manage these trends, seizing potential opportunities and devising strategies for next-generation e-business.",http://dx.doi.org/10.1007/978-3-030-48950-2_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58666-9_2,Characterizing Machine Learning Processes: A Maturity Framework,Business Process Management,10.1007/978-3-030-58666-9_2,Springer,2020-01-01,"Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises. For example, existing machine learning processes cannot address how to define business use cases for an AI application, how to convert business requirements from product managers into data requirements for data scientists, and how to continuously improve AI applications in term of accuracy and fairness, how to customize general purpose machine learning models with industry, domain, and use case specific data to make them more accurate for specific situations etc. Making AI work for enterprises requires special considerations, tools, methods and processes. In this paper we present a maturity framework for machine learning model lifecycle management for enterprises. Our framework is a re-interpretation of the software Capability Maturity Model (CMM) for machine learning model development process. We present a set of best practices from authors’ personal experience of building large scale real-world machine learning models to help organizations achieve higher levels of maturity independent of their starting point.",http://dx.doi.org/10.1007/978-3-030-58666-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5741-8_1,Introduction to Cognitive Virtual Bots,Cognitive Virtual Assistants Using Google Dialogflow,10.1007/978-1-4842-5741-8_1,Springer,2020-01-01,The technologies being implemented today are no longer the stuff of science-fiction; virtual reality and much more is now possible.,http://dx.doi.org/10.1007/978-1-4842-5741-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55024-0_4,ADABench - Towards an Industry Standard Benchmark for Advanced Analytics,Performance Evaluation and Benchmarking for the Era of Cloud(s),10.1007/978-3-030-55024-0_4,Springer,2020-01-01,"The digital revolution, rapidly decreasing storage cost, and remarkable results achieved by state of the art machine learning (ML) methods are driving widespread adoption of ML approaches. While notable recent efforts to benchmark ML methods for canonical tasks exist, none of them address the challenges arising with the increasing pervasiveness of end-to-end ML deployments. The challenges involved in successfully applying ML methods in diverse enterprise settings extend far beyond efficient model training. In this paper, we present our work in benchmarking advanced data analytics systems and lay the foundation towards an industry standard machine learning benchmark. Unlike previous approaches, we aim to cover the complete end-to-end ML pipeline for diverse, industry-relevant application domains rather than evaluating only training performance. To this end, we present reference implementations of complete ML pipelines including corresponding metrics and run rules, and evaluate them at different scales in terms of hardware, software, and problem size.",http://dx.doi.org/10.1007/978-3-030-55024-0_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-49724-8_6,A Good Defense Is a Strong DNN: Defending the IoT with Deep Neural Networks,Machine Learning Paradigms,10.1007/978-3-030-49724-8_6,Springer,2020-01-01,"This chapter frames in the realm of Internet of Things (IoT) and provides a new deep learning solution for securing networks connecting IoT devices. In particular, it discusses a comprehensive solution to enhancing IoT defense in the form of a new protocol for IoT security. The need for IoT security solutions was revisited after the recent attacks on 120 million devices. In the current work, deep learning is studied for critical security applications by utilizing snapshots of network traffic taken from a set of nine real-world IoT devices. To that end, a set of learning tools such as Support Vector Machines (SVM), Random Forest and Deep Neural Network (DNN) are tested on a set of real-world data to detect anomalies in the IoT networks. Obtained results provided high accuracy for all tested algorithms. Notably, DNN exhibits the highest coefficient of determination among the tested models, thus, promoting the DNN as a more suitable solution in IoT security applications. Furthermore, the DNN’s learning autonomy feature results in a time efficient real-world algorithm because it skips human intervention.",http://dx.doi.org/10.1007/978-3-030-49724-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59638-5_10,Analysis of Models for Decentralized and Collaborative AI on Blockchain,Blockchain – ICBC 2020,10.1007/978-3-030-59638-5_10,Springer,2020-01-01,"Machine learning has recently enabled large advances in artificial intelligence, but these results can be highly centralized. The large datasets required are generally proprietary; predictions are often sold on a per-query basis; and published models can quickly become out of date without effort to acquire more data and maintain them. Published proposals to provide models and data for free for certain tasks include Microsoft Research’s Decentralized and Collaborative AI on Blockchain. The framework allows participants to collaboratively build a dataset and use smart contracts to share a continuously updated model on a public blockchain. The initial proposal gave an overview of the framework omitting many details of the models used and the incentive mechanisms in real world scenarios. For example, the Self-Assessment incentive mechanism proposed in their work could have problems such as participants losing deposits and the model becoming inaccurate over time if the proper parameters are not set when the framework is configured. In this work, we evaluate the use of several models and configurations in order to propose best practices when using the Self-Assessment incentive mechanism so that models can remain accurate and well-intended participants that submit correct data have the chance to profit. We have analyzed simulations for each of three models: Perceptron, Naïve Bayes, and a Nearest Centroid Classifier, with three different datasets: predicting a sport with user activity from Endomondo, sentiment analysis on movie reviews from IMDB, and determining if a news article is fake. We compare several factors for each dataset when models are hosted in smart contracts on a public blockchain: their accuracy over time, balances of a good and bad user, and transaction costs (or gas) for deploying, updating, collecting refunds, and collecting rewards. A free and open source implementation for the Ethereum blockchain of these models is provided at https://github.com/microsoft/0xDeCA10B .",http://dx.doi.org/10.1007/978-3-030-59638-5_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_25-1,Artificial Intelligence and Machine Learning,Handbook of e-Tourism,10.1007/978-3-030-05324-6_25-1,Springer,2020-01-01,"Thanks to more powerful hardware and a new generation of learning algorithms, artificial intelligence is supporting the automation of a number of tasks and activities that are changing the job landscape as much as they have impacted on our everyday life. The first part of the chapter introduces artificial intelligence from its origins: its definition and its main research and application areas. The nature and the importance of machine learning for artificial intelligence applications are presented in the second part of the chapter. Existing approaches to machine learning are also classified and illustrated. The third part describes artificial intelligence tools and solutions by supported functionalities and automated tasks. Cases of applications in tourism are provided, from the best known and widely adopted, e.g., personal assistants, to the most challenging, i.e., semantic systems. Future trends and risks related to the applications of artificial intelligence are considered in the last part of the chapter.",http://dx.doi.org/10.1007/978-3-030-05324-6_25-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-40783-4_6,A Generic Architectural Framework for Machine Learning on Data Streams,Enterprise Information Systems,10.1007/978-3-030-40783-4_6,Springer,2020-01-01,"In the past years, the importance of processing data streams increased with the emergence of new technologies and application domains. The Internet of Things provides many examples in which processing and analyzing data streams are critical success factors. With the growing amount of data, the usage of machine learning (ML) algorithms has become an essential part of data analysis. However, the high volume and velocity of data presents new challenges, which need to be addressed, e.g. frequent model changes, concept drift or insufficient time to train models. From our point of view, these challenges cannot be tackled alone by using an algorithm-centric approach, i.e. to focus solely on finding appropriate algorithms, and neglecting the structure of the overall processing system. Therefore, we propose a generic architectural framework, which describes common components and their interactions with each other in order to apply ML technologies to streaming data. Furthermore, we implement essential components in two real-world use cases to highlight the feasibility of our approach.",http://dx.doi.org/10.1007/978-3-030-40783-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_22-1,Semantic Web Empowered E-Tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_22-1,Springer,2020-01-01,"Smart speakers such as Alexa and later Google Home have introduced Artificial Intelligence (AI) into millions, soon to be billions of households, making AI an everyday experience. These new communication channels present a new challenge for successful e-Marketing and e-Commerce providers. Data, content, and services are becoming semantically annotated, allowing software agents, so-called bots, to search through the web and understand its content. Nowadays, users typically consult their bot to find, aggregate, and personalize information and to reserve, book, or buy products and services. As a consequence, it is becoming increasingly important for touristic providers of information, products, and services to be prominently visible in these new online channels to ensure their future economic maturity. In our chapter, we survey the methods and tools helping to achieve these goals. The core aim is the development and application of machine-processable (semantic) annotations of content, data, and services, as well as their aggregation in large Knowledge Graphs. It is only through these methods bots are able to answer a question in a knowledgeable way and organize a useful dialogue ( Knowledge Graphs in Use A significantly extended and generalized version of this article will appear as D. Fensel, K. Angele, E. Huaman, E. Kärle, O. Panasiuk, U. Şimşek, I. Toma, J. Umbrich, and A. Wahler: Knowledge Graphs: Methodology, Tools and Selected Use Cases. Springer Nature, 2020.).",http://dx.doi.org/10.1007/978-3-030-05324-6_22-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-32930-3_11,Addressing the Un-Addressed: Opportunities for Rural-Africa,Space Fostering African Societies,10.1007/978-3-030-32930-3_11,Springer,2020-01-01,"In the developed world ownership of a residential address is almost taken for granted, people grow up with the concept, it is used daily in many processes in an almost unconscious way. Mail depends on it to get delivered, so does the courier service delivering e-commerce procured and it provides a pick-up location for a ride sharing service etc. It forms the foundation for legal identification in most developed nations, however for a large portion of the global population it is not the case. Currently development in both terrestrial and space-based information and communications technology (ICT) provides opportunity for potential solutions to provide alternative approaches to mitigate the “address problem”. This work aims to provide a short historical overview of the concept with reference to the postal system, investigates technology options, reviews a number of currently available solutions and proposes another conceptual solution—with a special focus on the rural un-addressed in sub-Saharan Africa. It also aims to create awareness of the highly important role played by physical address systems in modern society by highlighting its economic and societal impact against the background of its contribution to progressing the 2030 UN Sustainable Development Goals.",http://dx.doi.org/10.1007/978-3-030-32930-3_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-36962-0_1,Important Internet Applications of Classification,Classification Methods for Internet Applications,10.1007/978-3-030-36962-0_1,Springer,2020-01-01,"Summary of important internet applications of classification, including: spam filtering, recommender systems, sentiment analysis, example-based search, malware detection and network intrusion detection.",http://dx.doi.org/10.1007/978-3-030-36962-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-39863-7_1,Towards an Architecture for Reliable Capacity Provisioning for Distributed Clouds,Managing Distributed Cloud Applications and Infrastructure,10.1007/978-3-030-39863-7_1,Springer,2020-01-01,"The complexity of computing along the cloud-to-edge continuum presents significant challenges to ICT operations and in particular reliable capacity planning and resource provisioning to meet unpredictable, fluctuating, and mobile demand. This chapter presents a high-level conceptual overview of RECAP—an architectural innovation to support reliable capacity provisioning for distributed clouds—and its operational modes and functional building blocks. In addition, the major design concepts informing its design—namely separation of concerns, model-centricism, modular design, and machine learning and artificial intelligence for IT operations—are also discussed.",http://dx.doi.org/10.1007/978-3-030-39863-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57321-8_18,Scenario-Based Requirements Elicitation for User-Centric Explainable AI,Machine Learning and Knowledge Extraction,10.1007/978-3-030-57321-8_18,Springer,2020-01-01,"Explainable Artificial Intelligence (XAI) develops technical explanation methods and enable interpretability for human stakeholders on why Artificial Intelligence (AI) and machine learning (ML) models provide certain predictions. However, the trust of those stakeholders into AI models and explanations is still an issue, especially domain experts, who are knowledgeable about their domain but not AI inner workings. Social and user-centric XAI research states it is essential to understand the stakeholder’s requirements to provide explanations tailored to their needs, and enhance their trust in working with AI models. Scenario-based design and requirements elicitation can help bridge the gap between social and operational aspects of a stakeholder early before the adoption of information systems and identify its real problem and practices generating user requirements. Nevertheless, it is still rarely explored the adoption of scenarios in XAI, especially in the domain of fraud detection to supporting experts who are about to work with AI models. We demonstrate the usage of scenario-based requirements elicitation for XAI in a fraud detection context, and develop scenarios derived with experts in banking fraud. We discuss how those scenarios can be adopted to identify user or expert requirements for appropriate explanations in his daily operations and to make decisions on reviewing fraudulent cases in banking. The generalizability of the scenarios for further adoption is validated through a systematic literature review in domains of XAI and visual analytics for fraud detection.",http://dx.doi.org/10.1007/978-3-030-57321-8_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-46781-4_3,Easier Crowdsourcing Is Better: Designing Crowdsourcing Systems to Increase Information Quality and User Participation,Design Science Research. Cases,10.1007/978-3-030-46781-4_3,Springer,2020-01-01,"Crowdsourcing promises to expand organizational knowledge and “sensor” networks dramatically, making it possible to engage ordinary people in large-scale data collection, often at much lower cost than that of traditional approaches to gathering data. A major challenge in crowdsourcing is ensuring that the data that crowds provide is of sufficient quality to be usable in organizational decision-making and analysis. We refer to this challenge as the Problem of Crowd Information Quality (Crowd IQ). We need to increase quality while giving contributors the flexibility to contribute data based on their individual perceptions. The design science research project produced several artifacts, including a citizen science information system (NLNature), design principles (guidelines) for the development of crowdsourcing projects, and an instance-based crowdsourcing design theory. We also made several methodological contributions related to the process of design science research and behavioral research in information systems. Over the course of the project, we addressed several challenges in designing crowdsourcing systems, formulating design principles, and conducting rigorous design science research. Specifically, we showed that: design choices can have a sizable impact in the real world; it can be unclear how to implement design principles; and design features that are unrelated to design principles can confound efforts to evaluate artifacts. During the project, we also experienced challenges for which no adequate solution was found, reaffirming that design is an iterative process.",http://dx.doi.org/10.1007/978-3-030-46781-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-34706-2_9,Cloud Cognitive Services Based on Machine Learning Methods in Architecture of Modern Knowledge Management Solutions,Data-Centric Business and Applications,10.1007/978-3-030-34706-2_9,Springer,2020-01-01,"Cognitive Services are cloud computing services available to help developers build intelligent applications based on Machine Learning (ML) methods with pre-trained models as a service. Machine Learning platforms are one of the fastest growing services of the cloud because ML and Artificial Intelligence (AI) platforms are available through diverse delivery models such as cognitive computing, automated machine learning, model management. Cognitive Computing is delivered as a set of APIs. Due to the nature of the technologies involved in ML ecosystems and Knowledge Hierarchy—Data, Information, Knowledge, Wisdom (DIKW) Pyramid, there is a natural overlap of a technologies and Knowledge Management (KM) processes. The modern architecture of software solutions can be developed with the use of a wide technology stack, including cloud computing technologies and Cognitive Services (CS). We can use a wide range of ML tools at all levels of the DIKW pyramid. In this paper, we propose a new CS based approach to build an architecture of Knowledge Management system. We have analyzed the possibilities of using CS at all levels of the DIKW pyramid. We discussed some of the relevant aspects of Cloud CS and ML in Knowledge Management context and possibilities implementation of Cognitive Services on knowledge processing.",http://dx.doi.org/10.1007/978-3-030-34706-2_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49760-6_4,What Are People Doing About XAI User Experience? A Survey on AI Explainability Research and Practice,"Design, User Experience, and Usability. Design for Contemporary Interactive Environments",10.1007/978-3-030-49760-6_4,Springer,2020-01-01,"Explainability is a hot topic nowadays for artificial intelligent (AI) systems. The role of machine learning (ML) models on influencing human decisions shed light on the back-box of computing systems. AI based system are more than just ML models. ML models are one element for the AI explainability’ design and needs to be combined with other elements so it can have significant meaning for people using AI systems. There are different goals and motivations for AI explainability. Regardless the goal for AI explainability, there are more to AI explanation than just ML models or algorithms. The explainability of an AI systems behavior needs to consider different dimensions: 1) who is the receiver of that explanation, 2) why that explanation is needed, and 3) in which context and other situated information the explanation is presented. Considering those three dimensions, the explanation can be effective by fitting the user needs and expectation in the right moment and format. The design of an AI explanation user experience is central for the pressing need from people and the society to understand how an AI system may impact on human decisions. In this paper, we present a literature review on AI explainability research and practices. We first looked at the computer science (CS) community research to identify the main research themes about AI explainability, or “explainable AI”. Then, we focus on Human-Computer Interaction (HCI) research trying to answer three questions about the selected publications: to whom the AI explainability is for (who), which is the purpose of the AI explanation (why), and in which context the AI explanation is presented (what + when).",http://dx.doi.org/10.1007/978-3-030-49760-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-48950-2_11,Choosing the Appropriate e-Business Strategy for Interacting with Users,Strategies for e-Business,10.1007/978-3-030-48950-2_11,Springer,2020-01-01,"This chapter provided an overview of Web 2.0. It discussed why Web 2.0 brings about strategic changes in Internet business models. It explained how advances in network infrastructure and software development led to an increased number of web users and a richer user experience. In this chapter, we take a closer look at how businesses leverage the new technological capabilities of the Internet to involve their customers and website users more deeply in the information sharing and content creation process.",http://dx.doi.org/10.1007/978-3-030-48950-2_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-2109-6_6,Group Behavior Recognition,Human Behavior Analysis: Sensing and Understanding,10.1007/978-981-15-2109-6_6,Springer,2020-01-01,"Compared with individual behavior sensing and understanding, the recognition of group behavior is more challenging. In this chapter, we present some of our recent progress on group behavior sensing and recognition. Specifically, in Sect. 6.1 , we discuss how to recognize the mobility level and structure of groups in the physical world by leveraging mobile devices. Afterwards, we present the recognition of human semantic interactions and group interaction patterns in smart spaces in Sects. 6.2 and 6.3 . Finally, we discuss how we can organize, suggest, or predict group activities by leveraging the power of mobile crowdsensing and mobile social networking in Sects. 6.4 and 6.5 .",http://dx.doi.org/10.1007/978-981-15-2109-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41346-0_1,Chapter 1: Introduction and Overview,Internet of Things: Concepts and System Design,10.1007/978-3-030-41346-0_1,Springer,2020-01-01,"Internet of Things (IoT) systems connect the physical world to the Internet. Basically, IoT works by attaching real-world interfaces to the Internet, such as sensors that provide data and actuators that act upon their surroundings. In effect, IoT systems provide the technology and means to instrument, quantify, and actuate the physical world.",http://dx.doi.org/10.1007/978-3-030-41346-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-01805-3_10,Autonomous Last-Mile Delivery Vehicles in Complex Traffic Environments,Creating Autonomous Vehicle Systems,10.1007/978-3-031-01805-3_10,Springer,2020-01-01,,http://dx.doi.org/10.1007/978-3-031-01805-3_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49576-3_6,Building an Integrated Comment Moderation System – Towards a Semi-automatic Moderation Tool,"Social Computing and Social Media. Participation, User Experience, Consumer Experience, and Applications of Social Computing",10.1007/978-3-030-49576-3_6,Springer,2020-01-01,"The past decade has been characterized by a strong increase in the use of social media and a continuous growth of public online discussion. With the failure of purely manual moderation, platform operators started searching for semi-automated solutions, where the application of Natural Language Processing (NLP) and Machine Learning (ML) techniques is promising. However, this requires huge financial investments for algorithmic implementations, data collection, and model training, which only big players can afford. To support smaller or medium-sized media enterprises (SME), we developed an integrated comment moderation system as an IT platform. This platform acts as a service provider and offers Analytics as a Service (AaaS) to SMEs. Operating such a platform, however, requires a robust technology stack, integrated workflows and well-defined interfaces between all parties. In this paper, we develop and discuss a suitable IT architecture and present a prototypical implementation.",http://dx.doi.org/10.1007/978-3-030-49576-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35975-1_2,Applications of AI and Projections of AI Impact,Artificial Intelligence as a Disruptive Technology,10.1007/978-3-030-35975-1_2,Springer,2020-01-01,There are innumerable uses and applications of AI which are increasing almost on a daily basis. Among the major applications are those in health care where AI can detect malformations including cancer in cells that the most trained radiologist is not able to find; robots and robotics which pose great advantages by working 24/7 and never tiring but also pose a decided threat to job seekers who are not only being replaced but of late are being trained for new skills by robots which replaced them; autonomous vehicles which in time will not require human direction including trucks which will cause major displacements of truck drivers; worker safety whereby AI will increase employer capability of ensuring a safer work environment; voice and image recognition which is already extensively used to assure safety both in the workplace and in other environments; and many other uses.,http://dx.doi.org/10.1007/978-3-030-35975-1_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5316-8_1,Introduction,Industrial Machine Learning,10.1007/978-1-4842-5316-8_1,Springer,2020-01-01,"Industrialized Machine Learning (IML) is evolving as a disruptor in the world around us, and people are finally recognizing the true impact it has already had and will continue to have on our future. Throughout this book, I will share my knowledge and insights acquired from more than ten years of consulting, including setting up three data science teams that design and implementation digital transformations for business and research practices across the world.",http://dx.doi.org/10.1007/978-1-4842-5316-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35291-2_10,"Internet of Things for Sustainability: Perspectives in Privacy, Cybersecurity, and Future Trends",Internet of Things for Sustainable Community Development,10.1007/978-3-030-35291-2_10,Springer,2020-01-01,"In the sustainability IoT, the cybersecurity risks to things, sensors, and monitoring systems are distinct from the conventional networking systems in many aspects. The interaction of sustainability IoT with the physical world phenomena (e.g., weather, climate, water, and oceans) is mostly not found in the modern information technology systems. Accordingly, actuation, the ability of these devices to make changes in real world based on sensing and monitoring, requires special consideration in terms of privacy and security. Moreover, the energy efficiency, safety, power, performance requirements of these device distinguish them from conventional computers systems. In this chapter, the cybersecurity approaches towards sustainability IoT are discussed in detail. The sustainability IoT risk categorization, risk mitigation goals, and implementation aspects are analyzed. The openness paradox and data dichotomy between privacy and sharing is analyzed. Accordingly, the IoT technology and security standard developments activities are highlighted. The perspectives on opportunities and challenges in IoT for sustainability are given. Finally, the chapter concludes with a discussion of sustainability IoT cybersecurity case studies.",http://dx.doi.org/10.1007/978-3-030-35291-2_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-26622-6_1,Introduction to AI and ML,Machine Learning and Artificial Intelligence,10.1007/978-3-030-26622-6_1,Springer,2020-01-01,"In this chapter, I will introduce the concepts of artificial intelligence and machine learning to the user and discuss how these topics have evolved over last several decades. I will also lay the outline of the book and describe how different parts of the book are organized and how they unfold the topics in sequence. This layout will help the user to plan on how to get most out of the book. If he/she wants to focus on only some specific aspect(s), he/she can directly skip to corresponding part in the book. If the user is coming to the book in a fresh perspective, I would advise to go sequentially, however, if the user is already familiar with certain aspects of the area and want to expand the knowledge about specific topics, he/she is free to jump to different parts.",http://dx.doi.org/10.1007/978-3-030-26622-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_71-1,E-Business Models in Tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_71-1,Springer,2020-01-01,"The purpose of this chapter is to reflect on business models employed by online travel service providers since the beginning of online travel until 2019. In lockstep with technological development, this study identified three time periods of development. For each period, we investigate cases that best represent e-business model development. Employing Wirtz’s four business-to-consumer business model subtypes, we found that the commerce-type model (focus on trade transactions) dominated online travel agencies until 2000, while the next period was characterized by the advent of Web 2.0-enabled content-type models (providing online content, specifically user-generated content) and context-type models (aggregation of already existing online content) for information search portals. Finally, the increased complexity of the Internet in the last decade is also captured in multiple online business models, including the connection-type model (establishing real or virtual connections) pursued by platform businesses. The chapter offers avenues for future research that relate to theoretical issues across the three identified periods and an outlook of future tourism business model developments.",http://dx.doi.org/10.1007/978-3-030-05324-6_71-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5328-1_13,Migrating to Snowflake,Jumpstart Snowflake,10.1007/978-1-4842-5328-1_13,Springer,2020-01-01,"Throughout the book you have learned about key concepts of Snowflake, including its architecture and its security capabilities. You have also met some unique Snowflake features. Moreover, you saw how Snowflake can be integrated with third-party tools for ELT/ETL and BI purposes as well as big data and advanced analytics use cases with Spark.",http://dx.doi.org/10.1007/978-1-4842-5328-1_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-31729-4_1,Introduction,Access Control Management in Cloud Environments,10.1007/978-3-030-31729-4_1,Springer,2020-01-01,"This chapter presents the motivation and objectives of this book. There are three sections in the chapter. In the first section, overview and motivation of the book are presented. It consists of Cloud computing, Internet of Things, and access control management. Three technology issues in e-commerce E-commerce with their unsolved problems are introduced in access control management. The objectives and organization of this book are described in the second and third section respectively.",http://dx.doi.org/10.1007/978-3-030-31729-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-14544-6_5,Ubiquitous Manufacturing in the Age of Industry 4.0: A State-of-the-Art Primer,"A Roadmap to Industry 4.0: Smart Production, Sharp Business and Sustainable Development",10.1007/978-3-030-14544-6_5,Springer,2020-01-01,"The industrial revolution has changed the socio-economic civilisation of mankind. It started dating back in the late 1700s and has been in continuous evolution since then. Presently, we are experiencing the latest industrial revolution, known as Industry 4.0. Among others, ubiquitous technologies probably have been the most influential in the implementation of Industry 4.0. This has led to a new manufacturing paradigm known as ubiquitous manufacturing. This chapter presents an in-depth discussion on different aspects of ubiquitous manufacturing. In addition to the history of industrial revolutions and the fundamentals of ubiquitous manufacturing, the topics such as production planning and scheduling, automated material handling system, and dynamic manufacturing are meticulously discussed from the perspective of the real-life scenarios, in the age of ubiquitous manufacturing. The ubiquitous technologies that have enabled ubiquitous manufacturing are reviewed in detail. Several other related and advanced manufacturing technologies such as cloud manufacturing, cloud robotics, global manufacturing, lean manufacturing, agile manufacturing, additive manufacturing, chaordic manufacturing, etc. are duly accentuated. A futuristic view on Industry 5.0 is also presented.",http://dx.doi.org/10.1007/978-3-030-14544-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-1216-2_4,Toxic Comment Detection in Online Discussions,Deep Learning-Based Approaches for Sentiment Analysis,10.1007/978-981-15-1216-2_4,Springer,2020-01-01,"Comment sections of online news platforms are an essential space to express opinions and discuss political topics. In contrast to other online posts, news discussions are related to particular news articles, comments refer to each other, and individual conversations emerge. However, the misuse by spammers, haters, and trolls makes costly content moderation necessary. Sentiment analysis can not only support moderation but also help to understand the dynamics of online discussions. A subtask of content moderation is the identification of toxic comments. To this end, we describe the concept of toxicity and characterize its subclasses. Further, we present various deep learning approaches, including datasets and architectures, tailored to sentiment analysis in online discussions. One way to make these approaches more comprehensible and trustworthy is fine-grained instead of binary comment classification. On the downside, more classes require more training data. Therefore, we propose to augment training data by using transfer learning. We discuss real-world applications, such as semi-automated comment moderation and troll detection. Finally, we outline future challenges and current limitations in light of most recent research publications.",http://dx.doi.org/10.1007/978-981-15-1216-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-3431-7_2,Technology Challenges: Impact Assessment,"Digital Finance, Bits and Bytes",10.1007/978-981-15-3431-7_2,Springer,2020-01-01,"Technology “Disruption” is the main fallout from developments on the technology front. Big Data Analysis, Artificial Intelligence and Machine Learning, and Augmented and Virtual Reality are increasingly being used and are affecting the working of FIs as never before. Cut throat competition from Google, Apple, Facebook, and Amazon as well as midsized tech savvy companies has impacted the profits and have drawn away the customers from the mainstream FIs. Customer attitude toward and expectations from are significantly different and have to be met as soon as possible. Sadly, the customers have lost trust in the FIs. It is not mere technology that they have to worry about but even “cultural” aspects of working.",http://dx.doi.org/10.1007/978-981-15-3431-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-56725-5_3,ResFusion: A Residual Learning Based Fusion Framework for CTR Prediction,Information Retrieval,10.1007/978-3-030-56725-5_3,Springer,2020-01-01,"CTR prediction tasks deal with the problem of evaluating the probability of users clicking on products, and have been widely deployed in many online recommendation and advertising platforms. Mainstream CTR models can be divided into two categories: the traditional machine learning models (e.g., GBDT  [ 7 ]) that learn the linear feature combinations for prediction, and deep learning based algorithms (such as DeepFM  [ 9 ]) for modeling the complex and sparse feature correlations. Some recent works proposed to fuse these two kinds of models for prediction. These fusion models either feed the intermediate results learned by one model into the second category or rely on the ensemble techniques to fuse two independently trained model outputs. In this paper, we propose a residual learning based fusion framework for CTR prediction. The key idea is that, we first train a model (e.g., GBDT), and let the second model (e.g., DeepFM) learn the residual part that can not be accurately predicted by the first model. The soundness of this framework is that: as the prediction power of these two kinds of models is complementary, it is easier to let the second model learn the residual output that can not be well captured by the first model. We show that our proposed framework is flexible and it is easier to train with faster convergence. Extensive experimental results on three real-world datasets show the effectiveness of our proposed framework.",http://dx.doi.org/10.1007/978-3-030-56725-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5316-8_9,Reinforcement Learning: Using Newly Gained Knowledge for Insights,Industrial Machine Learning,10.1007/978-1-4842-5316-8_9,Springer,2020-01-01,In reinforcement learning an action is executed for each data point. The action’s execution generates a reward signal that indicates how good the decision was.,http://dx.doi.org/10.1007/978-1-4842-5316-8_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49282-3_28,iVision: An Assistive System for the Blind Based on Augmented Reality and Machine Learning,Universal Access in Human-Computer Interaction. Design Approaches and Supporting Technologies,10.1007/978-3-030-49282-3_28,Springer,2020-01-01,"In this paper, an assistive system iVision for the blind is proposed, which can solve one of the main problems faced by the visually impaired. We use augmented reality technology to create a three-dimensional model of the surrounding space and machine learning model to find the object of interest in the image taken by the camera. Then we combine these data to get the actual spatial location of the objects. This location information can be used by visually impaired people to search for objects of interest and avoid dangerous obstacle. The system uses speech and audio to feedback the spatial location to the user. Voice user interfaces (VUIs) is designed for iVision which allow the user to interact with a system through voice or speech commands. We verified the usability of the proposed system in evaluation experiments and noted its innovations and limitations.",http://dx.doi.org/10.1007/978-3-030-49282-3_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-37439-6_2,How to Build a Knowledge Graph,Knowledge Graphs,10.1007/978-3-030-37439-6_2,Springer,2020-01-01,"This chapter outlines the state of the art of Knowledge Graph technologies by introducing the process of building a Knowledge Graph Knowledge Graph Maintenance . We define the following major steps of an overall process model: (1) knowledge creation Knowledge Graph Maintenance knowledge creation Knowledge creation , (2) knowledge hosting Knowledge hosting Knowledge Graph Maintenance knowledge hosting , (3) knowledge curation Knowledge Graph Maintenance knowledge curation Knowledge curation , and (4) knowledge deployment Knowledge Graph Maintenance knowledge deployment . We demonstrate the methodology for the knowledge creation Knowledge creation process that creates, extracts, and structures the fact base for a Knowledge Graph. We describe the process of knowledge collection Knowledge collection , storage, and retrieval that implements established knowledge in a graph-based storage system. We analyze existing methods and tools to improve the quality of a large Knowledge Graph. For the Knowledge Curation Knowledge curation process, we establish sub-steps, such as knowledge assessment Knowledge assessment , cleaning, and enrichment. For each of them, we determine various categories and dimensions that have been developed and described in the literature and identify tasks which can be applied (e.g., Knowledge Graph completion and correctness Knowledge assessment correctness , error detection Knowledge cleaning error detection and correction, identifying and resolving duplicates). Finally, we describe the deployment process of a Knowledge Graph based on the following principles: findability, accessibility, interoperability, and reusability.",http://dx.doi.org/10.1007/978-3-030-37439-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60239-0_40,Roda: A Flexible Framework for Real-Time On-demand Data Aggregation,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-60239-0_40,Springer,2020-01-01,"It is critical to aggregate data from multiple sources to support real-time decision making in several fields, such as anti-telecommunications fraud detection. However, as data sources are distributed, heterogeneous and autonomous, it is challenging to ensure that data aggregation satisfies the requirements of real-time, on-demand and flexibility. In this paper, we propose a real-time on-demand data aggregation (Roda) framework, which is designed to be flexible enough to support the dynamic joining of new data sources, the immediate updating of aggregation rules and the quick adaptation to data velocity. We implement a prototype of Roda based on Kafka and Docker using the overlay network technique. To evaluate the effectiveness and performance of Roda, we conduct a series of experiments based on real trace data. The experiment results show that Roda can guarantee data aggregation latency at the millisecond scale, easily achieving our design goals.",http://dx.doi.org/10.1007/978-3-030-60239-0_40,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64849-7_3,Language Model-Driven Chatbot for Business to Address Marketing and Selection of Products,Re-imagining Diffusion and Adoption of Information Technology and Systems: A Continuing Conversation,10.1007/978-3-030-64849-7_3,Springer,2020-01-01,"Artificial Intelligence has been increasingly gaining acceptance across advanced functions in numerous fields and industries. This includes marketing, customer support, and leads generation in healthcare, transportation, education, and off late in e-commerce. Machine learning as a subset of artificial intelligence techniques provides various algorithms that enable machines to learn from historical data and make realtime predictions on numbers and texts. Most of the businesses nowadays are trying to increase their reach and making sure that they are available to cater to the customers when they need help. This also enables the companies to market and respond to the queries of potential customers on a realtime basis. Chatter robots or chatbot is one such application of machine learning which allows the business to provide round the clock support to customers and potential leads for marketing questions. Most of the business fail to venture in the domain of hosting chatbot on the website as they do not have enough conversational data with them to train the machine learning algorithm and wait for years to collect enough sample. With the proposed language model-driven chatbots, businesses starting fresh in the domain of the hosting this application can use the user-generated content on social media to fuel the backend framework for the chatbots and start hosting the application.",http://dx.doi.org/10.1007/978-3-030-64849-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-018-1254-2,Scalability and sparsity issues in recommender datasets: a survey,Knowledge and Information Systems,10.1007/s10115-018-1254-2,Springer,2020-01-01,"Recommender systems have been widely used in various domains including movies, news, music with an aim to provide the most relevant proposals to users from a variety of available options. Recommender systems are designed using techniques from many fields, some of which are: machine learning, information retrieval, data mining, linear algebra and artificial intelligence. Though in-memory nearest-neighbor computation is a typical approach for collaborative filtering due to its high recommendation accuracy; its performance on scalability is still poor given a huge user and item base and availability of only few ratings (i.e., data sparsity) in archetypal merchandising applications. In order to alleviate scalability and sparsity issues in recommender systems, several model-based approaches were proposed in the past. However, if research in recommender system is to achieve its potential, there is a need to understand the prominent techniques used directly to build recommender systems or for preprocessing recommender datasets, along with its strengths and weaknesses. In this work, we present an overview of some of the prominent traditional as well as advanced techniques that can effectively handle data dimensionality and data sparsity. The focus of this survey is to present an overview of the applicability of some advanced techniques, particularly clustering, biclustering, matrix factorization, graph-theoretic, and fuzzy techniques in recommender systems. In addition, it highlights the applicability and recent research works done using each technique.",http://dx.doi.org/10.1007/s10115-018-1254-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5104-1_1,The Problem with Data Science,Practical DataOps,10.1007/978-1-4842-5104-1_1,Springer,2020-01-01,"Before adopting DataOps as a solution, it’s important to understand the problem we’re trying to solve. When you view articles online, hear presentations at conferences, or read of the success of leading data-driven organizations like Facebook, Amazon, Netflix, and Google (FANG) , delivering successful data science seems a simple process. The reality is very different.",http://dx.doi.org/10.1007/978-1-4842-5104-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-34817-5_7,Future Directions,"The Handbook of Global Shadow Banking, Volume II",10.1007/978-3-030-34817-5_7,Springer,2020-01-01,"The final chapter reads like an anthology of open-ended or still-evolving issues. Is more market-based finance the solution and what is the effect of more bank capital on growth, Nijs wonders. To what degree does the growing larger-than-ever global asset management industry pose intrinsic risks, and does securitization, which essentially is a capital reduction tool for banks, really generate enhanced access to capital for small- and medium-sized enterprises? Do we really know what we are doing when juggling ex ante and ex post regulation with macroprudential and monetary policies supported by supervisory frameworks, stress-tests and ongoing data gathering efforts? Do we know how all these simultaneously implemented efforts interact? Nijs gets the impression we are not. Do we really appreciate (or understand) the limits of all these tools against the background of unseen complexity, imperfect contractual relations, limited corporate liability and unparalleled dynamic financial networks? And how much finance do we really need? Does finance crowd out economic growth once it grows too large relative to the economy it is supposed to serve? Balancing liquidity, stability and meeting demand for safe assets in a world with credit-, liquidity- and maturity transformation occurring outside the regulated banking sector might be a stretched ambition. We might collectively be suffering from the neglected risk syndrome, and transforming the shadow banking sector into market-based finance might prove to be an illusion we all will regret one day.",http://dx.doi.org/10.1007/978-3-030-34817-5_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-4584-9_2,Deep Learning Development Status in China,The Development of Deep Learning Technologies,10.1007/978-981-15-4584-9_2,Springer,2020-01-01,"This chapter introduces the deep learning development in China. In the new wave of technological revolution driven by deep learning, China is pioneering in the field of applied technology at “China speed,” but is relatively underdeveloped in fundamental theories and lower level technologies. The chapter addresses the kernel technologies and industrial applications of deep learning in China in detail.",http://dx.doi.org/10.1007/978-981-15-4584-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55218-3_1,Fashion Recommender Systems in Cold Start,Fashion Recommender Systems,10.1007/978-3-030-55218-3_1,Springer,2020-01-01,"With the rapid growth of online market for clothing, footwear, hairstyle, and makeup, consumers are getting increasingly overwhelmed with the volume, velocity and variety of production. Fashion Recommender Systems can tackle choice overload by suggesting the most interesting products to the users. However, recommender systems are unable to generate recommendation unless some information is collected from users. Indeed, there are situations where a recommender system is requested for recommendation while no or little information is provided by users ( Cold Start problem). In this book chapter, we investigate the different scenarios where fashion recommender systems may encounter cold start problem and review approaches that have been proposed to deal with this problem. We further elaborate potential solutions that can be applied to mitigate moderate and severe cases of cold start problem.",http://dx.doi.org/10.1007/978-3-030-55218-3_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49435-3_28,Resource-Based Adaptive Robotic Process Automation,Advanced Information Systems Engineering,10.1007/978-3-030-49435-3_28,Springer,2020-01-01,"Robotic process automation is evolving from robots mimicking human workers in automating information acquisition tasks, to robots performing human decision tasks using machine learning algorithms. In either of these situations, robots or automation agents can have distinct characteristics in their performance, much like human agents. Hence, the execution of an automated task may require adaptations with human participants executing the task when robots fail, to taking a supervisory role or having no involvement. In this paper, we consider different levels of automation, and the corresponding coordination required by resources that include human participants and robots. We capture resource characteristics and define business process constraints that support process adaptations with human-automation coordination. We then use a real-world business process and incorporate automation agents, compute resource characteristics, and use resource-aware constraints to illustrate resource-based process adaptations for its automation.",http://dx.doi.org/10.1007/978-3-030-49435-3_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_110-1,"Impact of Artificial Intelligence in Travel, Tourism, and Hospitality",Handbook of e-Tourism,10.1007/978-3-030-05324-6_110-1,Springer,2020-01-01,"Artificial intelligence (AI) is currently present in almost every area of travel and tourism, appearing in different types of applications such as personalization and recommender systems, robots, conversational systems, smart travel agents, prediction and forecasting systems, language translation applications, and voice recognition and natural language processing systems. Recent improvements in big data, algorithms, and computing power have enabled significant enhancements in AI. In this chapter, we review how AI has changed and is changing the main processes in the tourism industry. We start with the IT foundations of AI that are relevant for travel and tourism and then address the AI systems and applications available in the sector. We then examine hospitality in detail, as a sector in which most of these systems are being implemented. We conclude with the challenges that AI faces in the tourism sector, a research agenda, and draw a scenario of the future of AI in tourism.",http://dx.doi.org/10.1007/978-3-030-05324-6_110-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-48513-9_20,Anomalous Taxi Route Detection System Based on Cloud Services,"Cloud Computing, Smart Grid and Innovative Frontiers in Telecommunications",10.1007/978-3-030-48513-9_20,Springer,2020-01-01,"Machine learning is very popular right now. We can apply the knowledge of machine learning to deal with some problems in our daily life. Taxi service provides a convenient way of transportation, especially for those who travel to an unfamiliar place. But there can be a risk that the passenger gets overcharged on the unnecessary mileages. To help the passenger to determine whether the taxi driver has made a detour, we propose a solution which is a cloud-based system and applies machine learning algorithms to detect anomaly taxi trajectory for the passenger. This paper briefly describes the research on several state-of-art detection methods. It also demonstrates the system architecture design in detail and gives the reader a big picture on what parts of the application have been implemented.",http://dx.doi.org/10.1007/978-3-030-48513-9_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-46133-1_27,Scalable Bid Landscape Forecasting in Real-Time Bidding,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-030-46133-1_27,Springer,2020-01-01,"In programmatic advertising, ad slots are usually sold using second-price (SP) auctions in real-time. The highest bidding advertiser wins but pays only the second highest bid (known as the winning price ). In SP, for a single item, the dominant strategy of each bidder is to bid the true value from the bidder’s perspective. However, in a practical setting, with budget constraints, bidding the true value is a sub-optimal strategy. Hence, to devise an optimal bidding strategy, it is of utmost importance to learn the winning price distribution accurately. Moreover, a demand-side platform (DSP), which bids on behalf of advertisers, observes the winning price if it wins the auction. For losing auctions, DSPs can only treat its bidding price as the lower bound for the unknown winning price. In literature, typically censored regression is used to model such partially observed data. A common assumption in censored regression is that the winning price is drawn from a fixed variance (homoscedastic) uni-modal distribution (most often Gaussian). However, in reality, these assumptions are often violated. We relax these assumptions and propose a heteroscedastic fully parametric censored regression approach, as well as a mixture density censored network. Our approach not only generalizes censored regression but also provides flexibility to model arbitrarily distributed real-world data. Experimental evaluation on the publicly available dataset for winning price estimation demonstrates the effectiveness of our method. Furthermore, we evaluate our algorithm on one of the largest demand-side platform and significant improvement has been achieved in comparison with the baseline solutions.",http://dx.doi.org/10.1007/978-3-030-46133-1_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-3020-3_20,Multi-agent Based Recommender System for Netflix,"Proceedings of International Conference on IoT Inclusive Life (ICIIL 2019), NITTTR Chandigarh, India",10.1007/978-981-15-3020-3_20,Springer,2020-01-01,"The main aim of this work is to build a multi-agent based recommender system that comprises heterogeneous software agents, where various member agents interact among themselves to accomplish various tasks and achieve objectives of the system. The main objectives of this work are: first, it presents some basics of multi-agent based recommender system. Second, it reviews the main research developments and works previously performed in the field of recommender systems with machine learning. Third, it introduces a multi-agent based recommender system framework based on a collaborative approach by considering various agents to recommend movies to users, who have similar interests. Furthermore, the proposed framework has been experimentally assessed by implementing a cosine similarity algorithm to measure user–user similarity based on movie ratings. The multi-agent programming environment NetLogo is used to simulate the results.",http://dx.doi.org/10.1007/978-981-15-3020-3_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35445-9_45,Towards a Quantitative Identification of Mobile Social Media UIDPs’ Visual Features Using a Combination of Digital Image Processing and Machine Learning Techniques,Intuitionistic and Type-2 Fuzzy Logic Enhancements in Neural and Optimization Algorithms: Theory and Applications,10.1007/978-3-030-35445-9_45,Springer,2020-01-01,"User Interface Design Patterns (UIDPs) improve the interaction between users and e-applications through the use of interfaces with a suitable and intuitive navigability without restrictions on the size of the screen to show the content. Nowadays, UIDPs are frequently used in the development of new mobile apps. In fact, mobile apps are ubiquitous: in education through learning platforms; in medicine through health self-care apps and in a social dimension, of course, through social networks. Social media networks have become one of the main channels of communication and dissemination of content; however, surprisingly, UIDPs have not been deeply analyzed in the design and development process of social media apps. In this sense, we propose the use of a combination of digital image processing and machine learning techniques to both quantitatively identify the main visual features of UIDPs in social media apps and assess the goodness of those features for building highly accurate classifiers. Our results suggest that such a combination seems sensible not only for explicitly unveiling patterns shared by different users but also for constructing such kind of classifiers.",http://dx.doi.org/10.1007/978-3-030-35445-9_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-018-9662-y,"Exploring the influential reviewer, review and product determinants for review helpfulness",Artificial Intelligence Review,10.1007/s10462-018-9662-y,Springer,2020-01-01,"Helpfulness of online reviews is a multi-faceted concept. The reviews are usually ranked on the basis of perceived helpful votes and aid in making purchase decisions for online customers. This study extends the prior work done for review helpfulness by considering not only the influential characteristics of reviews but also incorporates influential indicators of reviewer and product category. Influential factor based new features (product, reviewer and review) are proposed to predict the helpfulness of online reviews by using five ML methods. The experimental analysis on a real-life review dataset shows that the hybrid set of proposed features deliver the best predictive performance. In addition, the reviewer and the review category features introduced in this research exhibit better predictive performance as a standalone model. Findings show that reviews which have large number of comments, large values of sentiment and polarity scores receive more helpful votes. The reviewer activity length and recency are statistically significant predictors for helpfulness prediction. In addition, number of question answered, ratio of positive reviews and average rating per review are also significant variables of product type. The findings of this study highlight the number of implications for research and provide new insights to retailers for efficient ranking and organization of consumer reviews for online users.",http://dx.doi.org/10.1007/s10462-018-9662-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54494-2_7,Disruptive Data Applications,Digital Disruption,10.1007/978-3-030-54494-2_7,Springer,2020-01-01,"The combination of ubiquitous high speed connectivity, a plethora of devices to capture vast amounts of data, the secure distribution of such data, Artificial Intelligence (AI) deployed to make sense of data across the ecosystem and automation of many business processes is leading to significant innovation in the application space. New business models are being created, old ones are being tweaked and reworked and previously un-served customers are being delivered products and services, some that they didn’t even know they wanted.",http://dx.doi.org/10.1007/978-3-030-54494-2_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55218-3_2,Enabling Hyper-Personalisation: Automated Ad Creative Generation and Ranking for Fashion e-Commerce,Fashion Recommender Systems,10.1007/978-3-030-55218-3_2,Springer,2020-01-01,"Homepage is the first touch point in the customer’s journey and is one of the prominent channels of revenue for many e-commerce companies. A user’s attention is mostly captured by homepage banner images (also called Ads/Creatives). The set of banners shown and their design, influence the customer’s interest and plays a key role in optimizing the click through rates of the banners. Presently, massive and repetitive effort is put in, to manually create aesthetically pleasing banner images. Due to the large amount of time and effort involved in this process, only a small set of banners are made live at any point. This reduces the number of banners created as well as the degree of personalization that can be achieved. This paper thus presents a method to generate creatives automatically on a large scale in a short duration. The availability of diverse banners generated helps in improving personalization as they can cater to the taste of larger audience. The focus of our paper is on generating a wide variety of homepage banners that can be made as an input for a user-level personalization engine. Following are the main contributions of this paper: (1) We introduce and explain the need for large scale banner generation for e-commerce companies (2) We present on how we utilize existing deep learning based detectors which can automatically annotate the required objects/tags from the image. (3) We also propose a Genetic Algorithm based method to generate an optimal banner layout for the given image content, input components and other design constraints. (4) Further, to aid the process of picking the right set of banners, we designed a ranking method and evaluated multiple models. All our experiments have been performed on data from Myntra ( http://www.myntra.com ), one of the top fashion e-commerce players in India.",http://dx.doi.org/10.1007/978-3-030-55218-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-018-1433-8,Literature review of Industry 4.0 and related technologies,Journal of Intelligent Manufacturing,10.1007/s10845-018-1433-8,Springer,2020-01-01,"Manufacturing industry profoundly impact economic and societal progress. As being a commonly accepted term for research centers and universities, the Industry 4.0 initiative has received a splendid attention of the business and research community. Although the idea is not new and was on the agenda of academic research in many years with different perceptions, the term “Industry 4.0” is just launched and well accepted to some extend not only in academic life but also in the industrial society as well. While academic research focuses on understanding and defining the concept and trying to develop related systems, business models and respective methodologies, industry, on the other hand, focuses its attention on the change of industrial machine suits and intelligent products as well as potential customers on this progress. It is therefore important for the companies to primarily understand the features and content of the Industry 4.0 for potential transformation from machine dominant manufacturing to digital manufacturing. In order to achieve a successful transformation, they should clearly review their positions and respective potentials against basic requirements set forward for Industry 4.0 standard. This will allow them to generate a well-defined road map. There has been several approaches and discussions going on along this line, a several road maps are already proposed. Some of those are reviewed in this paper. However, the literature clearly indicates the lack of respective assessment methodologies. Since the implementation and applications of related theorems and definitions outlined for the 4th industrial revolution is not mature enough for most of the reel life implementations, a systematic approach for making respective assessments and evaluations seems to be urgently required for those who are intending to speed this transformation up. It is now main responsibility of the research community to developed technological infrastructure with physical systems, management models, business models as well as some well-defined Industry 4.0 scenarios in order to make the life for the practitioners easy. It is estimated by the experts that the Industry 4.0 and related progress along this line will have an enormous effect on social life. As outlined in the introduction, some social transformation is also expected. It is assumed that the robots will be more dominant in manufacturing, implanted technologies, cooperating and coordinating machines, self-decision-making systems, autonom problem solvers, learning machines, 3D printing etc. will dominate the production process. Wearable internet, big data analysis, sensor based life, smart city implementations or similar applications will be the main concern of the community. This social transformation will naturally trigger the manufacturing society to improve their manufacturing suits to cope with the customer requirements and sustain competitive advantage. A summary of the potential progress along this line is reviewed in introduction of the paper. It is so obvious that the future manufacturing systems will have a different vision composed of products, intelligence, communications and information network. This will bring about new business models to be dominant in industrial life. Another important issue to take into account is that the time span of this so-called revolution will be so short triggering a continues transformation process to yield some new industrial areas to emerge. This clearly puts a big pressure on manufacturers to learn, understand, design and implement the transformation process. Since the main motivation for finding the best way to follow this transformation, a comprehensive literature review will generate a remarkable support. This paper presents such a review for highlighting the progress and aims to help improve the awareness on the best experiences. It is intended to provide a clear idea for those wishing to generate a road map for digitizing the respective manufacturing suits. By presenting this review it is also intended to provide a hands-on library of Industry 4.0 to both academics as well as industrial practitioners. The top 100 headings, abstracts and key words (i.e. a total of 619 publications of any kind) for each search term were independently analyzed in order to ensure the reliability of the review process. Note that, this exhaustive literature review provides a concrete definition of Industry 4.0 and defines its six design principles such as interoperability, virtualization, local, real-time talent, service orientation and modularity. It seems that these principles have taken the attention of the scientists to carry out more variety of research on the subject and to develop implementable and appropriate scenarios. A comprehensive taxonomy of Industry 4.0 can also be developed through analyzing the results of this review.",http://dx.doi.org/10.1007/s10845-018-1433-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35979-9_4,Platforms for Procurement 4.0,Procurement 4.0 and the Fourth Industrial Revolution,10.1007/978-3-030-35979-9_4,Springer,2020-01-01,"The use of innovative platforms in procurement 4.0 can yield various benefits, including supporting daily business and administrative tasks, aiding in complex decision-making, and helping in managing processes. The real objective of these platforms is to free up procurement and support its focusing on strategic decisions and activities. Procurement 4.0 platforms thus become a strategic interface to support organizational efficiency, effectiveness, and profitability, and to create new business models, products, and services. This chapter confirms that there are still barriers to digitizing procurement processes. Such barriers are found in existing procedures, processes, capacities, and capabilities. Finally, the significance of several enabling platforms to the digitization process is analyzed and a roadmap for a successful digital transformation is presented.",http://dx.doi.org/10.1007/978-3-030-35979-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35032-1_18,Industry4.0,"Analytics for the Sharing Economy: Mathematics, Engineering and Business Perspectives",10.1007/978-3-030-35032-1_18,Springer,2020-01-01,"The fourth industrial revolution is already showing its disruptive potential in many fields, primarily in the manufacturing, logistics and energy sectors. It is expected to revolutionize production processes, business models and IT infrastructures: eventually, the supply chain will turn into more efficient, adaptable and scalable workflows, ultimately driven by a nearly real-time and utterly bespoke demand of new or enhanced products and services. Science is already supporting this transformation, mostly through its recent developments in AI, finally resulting in an exponential availability of approaches, methods and tools to support and boost it. An ever increasing availability of data, coming from different sources, generated by humans and machines are being fruitfully integrated and will ignite the Industry4.0 paradigm. Machines will be smarter, they will make decisions and trade resources and services using virtual currencies in the emerging framework of the Machine Economy.",http://dx.doi.org/10.1007/978-3-030-35032-1_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50334-5_20,Socio-Technical Design of Hybrid Intelligence Systems – The Case of Predictive Maintenance,Artificial Intelligence in HCI,10.1007/978-3-030-50334-5_20,Springer,2020-01-01,"This paper focuses on hybrid intelligence systems since this approach appears as most advanced to deal with the socio-technical challenges of Machine Learning. The analysis starts with a taxonomy being derived from literature that characterizes hybrid intelligence. This taxonomy is contrasted with the application area of predictive maintenance where machine learning could be used to derive warnings from the sensor data of a production plant. Thus, AI would replace the effort of deriving hypotheses based on the experience of the plant operators. The case study on Predictive Maintenance reveals a series of challenges that require keeping the organization and the human and in the loop. To achieve this goal, we derive appropriate design recommendations such as integrated support of communication and coordination, possibilities for intervention.",http://dx.doi.org/10.1007/978-3-030-50334-5_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49904-4_25,End-User Programming Architecture for Physical Movement Assessment: An Interactive Machine Learning Approach,"Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Posture, Motion and Health",10.1007/978-3-030-49904-4_25,Springer,2020-01-01,"In this article, we propose an end-user adaptive architecture for movement assessment from RGB videos. Our method allows physiotherapists to add customized exercises for patients from only a few video training examples. The main idea is to take leverage of Deep learning-based pose estimation frameworks to track in real-time the key-body joints from the image data. Our system mimics the traditional physical rehabilitation process, where the therapist guides patients through demonstrative examples, and the patients repeat these examples while the physiotherapist monitors their movements. We evaluate our proposed method on four physiotherapeutic exercises for shoulder strengthening. Results indicate that our approach contributes both to reduce physiotherapist time needed to train the system, and to automatically assess the patients’ movements without direct monitoring from the physiotherapist.",http://dx.doi.org/10.1007/978-3-030-49904-4_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-0029-9_45,The Internet of Drone Things (IoDT): Future Envision of Smart Drones,First International Conference on Sustainable Technologies for Computational Intelligence,10.1007/978-981-15-0029-9_45,Springer,2020-01-01,"The Internet of Drone Things (IoDT) is envisioned as Future direction of Drones backend via Internet of Things, Smart Computer vision, Cloud Computing, advanced wireless communication, big data, and high-end security techniques. The utilization of drones is increasing in diverse fields from Agriculture to Industry, from Government to private organizations and from Smart Cities to Rural area monitoring. With IoDT based implementations, all the existing sectors will become intelligent and smart for performing Monitoring, surveillance, search and rescue and more. In this paper, we present, a conceptual presentation of new terminology, i.e., Internet of Drone Things (IoDT), along with its related technologies, applications, security issues and real-time implementation of IoDT by taking case studies of Agriculture and Smart Cities.",http://dx.doi.org/10.1007/978-981-15-0029-9_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02175-6_4,Applications of Social Media Text Analysis,Natural Language Processing for Social Media,10.1007/978-3-031-02175-6_4,Springer,2020-01-01,,http://dx.doi.org/10.1007/978-3-031-02175-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-43198-3_7,Measuring the Business Value of Cloud Computing: Emerging Paradigms and Future Directions for Research,Measuring the Business Value of Cloud Computing,10.1007/978-3-030-43198-3_7,Springer,2020-01-01,"Much of the research on measuring the business value of cloud computing examines cloud computing from the perspective of a centralised commodity-based aggregated conceptualisation of cloud computing, largely based on the NIST reference architecture. Advances in new processor architectures and virtualisation combined with the rise of the Internet of Things are not only changing cloud computing but introducing new computing paradigms from the cloud to the edge. These new paradigms present both opportunities and challenges, not least managing complexity several orders of magnitude greater than today. Yet, academic research on measuring the business value of cloud computing is lagging practice and remains far removed from these innovations. New research is required that explores the relationship between investments in new cloud computing paradigms and business value, and the measurement thereof. This chapter explores a selection of these new paradigms, which may provide fruitful research pathways in the future.",http://dx.doi.org/10.1007/978-3-030-43198-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54494-2_5,"Data Integrity, Control and Tokenization",Digital Disruption,10.1007/978-3-030-54494-2_5,Springer,2020-01-01,"Data is the lifeblood within the digital ecosystem and more broadly the economies of the future. Whilst there is increasing focus on data protection (e.g. the EU General Data Protection Regulation ‘GDPR’), the broader role of data in enabling the development and growth of a convergent ecosystem has only recently been brought into sharp focus. Artificial intelligence, virtual reality, augmented reality, as well as many applications used in the digital environment require vast amounts of data inputs (sometime diverse sets of data that may be geographically dispersed) and vast computing resources to process these.",http://dx.doi.org/10.1007/978-3-030-54494-2_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-40783-4_20,CoRP: A Pattern-Based Anomaly Detection in Time-Series,Enterprise Information Systems,10.1007/978-3-030-40783-4_20,Springer,2020-01-01,"Monitoring and analyzing sensor networks is essential for exploring energy consumption in smart buildings or cities. However, the data generated by sensors are affected by various types of anomalies and this makes the analysis tasks more complex. Anomaly detection has been used to find anomalous observations from data. In this paper, we propose a Pattern-based method, for anomaly detection in sensor networks, entitled CoRP “Composition of Remarkable Point” to simultaneously detect different types of anomalies. Our method detects remarkable points in time series based on patterns. Then, it detects anomalies through pattern compositions. We compare our approach to the methods of literature and evaluate them through a series of experiments based on real data and data from a benchmark.",http://dx.doi.org/10.1007/978-3-030-40783-4_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-9364-8_29,Deep Learning Algorithms for Accurate Prediction of Image Description for E-commerce Industry,"Data Management, Analytics and Innovation",10.1007/978-981-13-9364-8_29,Springer,2020-01-01,"Currently, the demand for automation in information technology industry is increasing at rapid rate. Leading companies in artificial intelligence and computer vision have started investing in the research and making new products that can easily do the redundant work done by humans, ultimately increasing the productivity and reducing the cost of doing work. Industrial artificial intelligence can create new business models, can automate the industrial tasks which are redundant and can be easily done by specifically trained machines. The work is experimented with various feature extraction methods, like Visual Geometry Group (VGG-16) and VGG-19, and a smaller proposed five-layer convolution neural network (CNN-5) to generate captions for an image. The performances of these methods are compared using BLEU-1, BLEU-2, BLEU-3 and BLEU-4 scores. Various experiments have been conducted to see the effect of different hyper-parameters, like number of layers, learning rate, dropout, on the model accuracy measured by BLEU score. The effect of the input length (15, 34 and 40) of the sequence of text data on the LSTM network is also being analyzed and reported in the results section. The experiments are conducted on benchmark Flickr-8 K dataset which contains 8000 images and their respective descriptions in a text file. Each image was described by five different people and the text file contains image id and their respective five descriptions for each of the 8000 images.",http://dx.doi.org/10.1007/978-981-13-9364-8_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64694-3_7,CxDev: A Case Study in Domain Engineering for Customer eXperience Management,Reuse in Emerging Software Engineering Practices,10.1007/978-3-030-64694-3_7,Springer,2020-01-01,"Customer experience management (CXM) denotes a set of practices, processes, and tools, that aim at personalizing a customer’s interactions with a company around the customer’s needs and desires [ 18 ]. Marketing specialists have been imagining context-aware CXM applications that exploit the IoT, AI, and cloud computing to provide rich and personalized customer experiences. However, there is no methodology to elicit/specify the requirements for such applications, nor domain level reusable components that can be leveraged to implement such applications. An e-commerce software vendor asked us to do just that, in a domain with a fragmented scientific literature, and with no portfolio of applications to draw upon. In this paper, we describe our domain engineering strategy , present the main elements of the technical approach , and discuss the main difficulties we faced in this domain engineering effort.",http://dx.doi.org/10.1007/978-3-030-64694-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_51-1,Technology-Led Disruptions and Innovations: The Trends Transforming Urban Mobility,Handbook of Smart Cities,10.1007/978-3-030-15145-4_51-1,Springer,2020-01-01,"Over the past decade, digital innovations have challenged traditional concepts of urban transport and introduced new opportunities for improving people’s access to services and economic opportunities. In response, cities have redefined their technology roadmaps and business strategies and are increasingly encouraging more collaboration between the public and private sectors. Technology and service-led disruptions are not only impacting private car usage models, they are also enhancing multimodal journey planning and payment options which will drive new mobility initiatives in future cities. From data analytics, through to machine learning, on-demand shared mobility, Blockchain, Fog Computing, and connected vehicles, these technologies are set to transform the landscape of urban transport and reduce dependence on private cars. These technologies offer opportunities to measure and monitor city functions, manage the performance of transport infrastructure, and identify where services need improvements. This chapter discusses the role of disruptive innovations, some established and others emerging, and their impacts on transport operations. The chapter also describes how digitalization of physical assets provides opportunities to enable real-time monitoring and analysis of urban mobility and movement of freight. The chapter draws on practical applications and explains the key behavioral, societal, and technological impacts and benefits. Finally, the chapter provides insights into the potential value derived from typical use cases in smart mobility solutions enabled by technology-led innovations.",http://dx.doi.org/10.1007/978-3-030-15145-4_51-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-45439-5_43,A Regularised Intent Model for Discovering Multiple Intents in E-Commerce Tail Queries,Advances in Information Retrieval,10.1007/978-3-030-45439-5_43,Springer,2020-01-01,"A substantial portion of the query volume for e-commerce search engines consists of infrequent queries and identifying user intent in such tail queries is critical in retrieving relevant products. The intent of a query is defined as a labelling of its tokens with the product attributes whose values are matched against the query tokens during retrieval. Tail queries in e-commerce search tend to have multiple correct attribute labels for their tokens due to multiple valid matches in the product catalog. In this paper, we propose a latent variable generative model along with a novel data dependent regularisation technique for identifying multiple intents in such queries. We demonstrate the superior performance of our proposed model against several strong baseline models on an editorially labelled data set as well as in a large scale online A/B experiment at Flipkart, a major Indian e-commerce company.",http://dx.doi.org/10.1007/978-3-030-45439-5_43,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-25001-0_8,Phronesis and Automated Science: The Case of Machine Learning and Biology,A Critical Reflection on Automated Science,10.1007/978-3-030-25001-0_8,Springer,2020-01-01,"The applications of machine learning (ML) and deep learning to biology has fostered the idea that the automated nature of algorithmic analysis will gradually dispense human beings from scientific work. In this paper, I will show that this view is problematic, at least when ML is applied to biology. In particular, I will claim that ML is not independent of human beings and cannot form the basis of automated science . Computer scientists conceive their work as being a case of Aristotle’s poiesis perfected by techne , which can be reduced to a number of straightforward rules and technical knowledge. I will show a number of concrete cases where at each level of computational analysis, more is required to ML than just poiesis and techne , and that the work of ML practitioners in biology needs also the cultivation of something analogous to phronesis , which cannot be automated. But even if we knew how to frame phronesis into rules (which is inconsistent with its own definition), still this virtue is deeply entrenched in our biological constitution, which computers lack. Whether computers can fully perform scientific practice (which is the result of the way we are cognitively and biologically) independently of humans (and their cognitive and biological specificities) is an ill-posed question.",http://dx.doi.org/10.1007/978-3-030-25001-0_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-66498-5_15,Conceptualizing a Capability-Based View of Artificial Intelligence Adoption in a BPM Context,Business Process Management Workshops,10.1007/978-3-030-66498-5_15,Springer,2020-01-01,"Advances in Artificial Intelligence (AI) technologies are creating new opportunities for organizations to improve their performance; however, as with other technologies, many of them have difficulties leveraging AI technologies and realizing performance gains. Research on the business value of information technology (IT) suggests that the adoption of AI should improve organizational performance, though indirectly, through improved business processes and other mediators, but research so far has not extensively empirically investigated the way AI creates business value. The paper proposes a capability-based view of AI adoption based on the conception that, with the adoption of AI, an organization develops AI-enabled capabilities – abilities to mobilize AI resources to effectively exploit, create, extend, or modify its resource base. This leads to higher organizational performance through cognitive process automation, innovation, and organizational learning. The first step in this research is to clarify the AI adoption construct. The goal of the paper is thus to provide a conceptual definition, and deeper insights into the components of the AI adoption construct at the organizational level.",http://dx.doi.org/10.1007/978-3-030-66498-5_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-52167-7_4,Summarized Logical Forms for Controlled Question Answering,Artificial Intelligence for Customer Relationship Management,10.1007/978-3-030-52167-7_4,Springer,2020-01-01,"Providing a high-end question answering (Q/A) requires a special knowledge representation technique, which is based on phrasing-independent partial formalization of the essential information contained in domain answers. We introduce Summarized Logical forms (SLFs), the formalized expressions which contain the most important knowledge extracted from answers to be queried. Instead of indexing the whole answer, we index only its SLFs as a set of expressions for most important topics in this answer. By doing that, we achieve substantially higher Q/A precision since foreign answers will not be triggered. We also introduce Linked SLFs connected by entries of a domain-specific ontology to increase the coverage of a knowledge domain. A methodology of constructing SLFs and Linked SLFs is outlined and the achieved Q/A accuracy is evaluated. Meta-programming issues of matching query representations (QRs) against SLFs and domain taxonomy are addressed as well.",http://dx.doi.org/10.1007/978-3-030-52167-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44999-5_41,A Model for Evaluating Big Data Analytics Tools for Organisation Purposes,"Responsible Design, Implementation and Use of Information and Communication Technology",10.1007/978-3-030-44999-5_41,Springer,2020-01-01,"Big data analytics tools have many functions that are common or similar to one another. This is a problem for many organisations that are either interested or have deployed some of the tools. The problem arises because there is no mechanism on how to determine appropriateness of the tools within context in an environment. Some of the implications of the problem are that it is difficult to assess appropriateness of the tools in an environment, which sometimes result to duplication; and the value of the tools. The aim of this project was to propose a solution through a model that can be used to evaluate big data analytics tools for organisations’ benefits. The qualitative method, case study approach and semi-structured interview technique were applied in the study. From the analysis, the role of criteria, business and IT alignment, governance, and skill-sets were revealed as critical factors. Based on the factors, a model was developed, which can be used as a building block through which evaluation of big data analytics tools in an organisation is carried out.",http://dx.doi.org/10.1007/978-3-030-44999-5_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-2043-3_40,Identifying User’s Interest in Using E-Payment Systems,Innovations in Computer Science and Engineering,10.1007/978-981-15-2043-3_40,Springer,2020-01-01,"Web usage mining is used to analyse the user/customer behaviour which is required for business intelligence (BI). The usage of e-payment applications through electronic devices has become more important in organisations and is growing with unprecedented pace. Discovering web usage patterns can result in making strategic decisions for business growth. Especially organisations that need ground truth for exploiting/influencing the customer behaviour. Many researchers contributed towards web usage mining. However, working on real-world data sets provides more useful outcomes. Based on this, we proposed a framework with an EPUD algorithm to perform web usage mining. We have collected electronic payment indicators from RBI dataset and converted it into synthesised server logs suitable for web usage mining. Our algorithm mines the server logs discovers the electronic payment usage and our experimental results reveal the trends in identifying the behaviour of customers in using e-payment systems. The insights in this paper help in understanding the patterns of electronic payment usage for different payment indicators.",http://dx.doi.org/10.1007/978-981-15-2043-3_40,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-33578-6_2,How Big Data Creates New Job Opportunities: Skill Profiles of Emerging Professional Roles,Behavioral Competencies of Digital Professionals,10.1007/978-3-030-33578-6_2,Springer,2020-01-01,"Big data jobs will increase in importance over the next years. However, at the international level, the labor market for these professionals is characterized by a critical skill shortage. What are the big data specialist profiles that are most sought in the market? What are their main differences in terms of tasks and skill requirements? This chapter provides a snapshot of the most in-demand big data jobs, contributing to clarify their boundaries. It also delves into the main characteristics of the specific professional profiles that have received increasing attention in recent years, namely data scientists and data/business analysts. The review of the contributions provided by experts and scholars operating in the data science and analytics domain clarifies the main differences between these roles on the technical side. However, despite the increasing importance of soft skills, the behavioral competency profile of big data jobs is still ill defined.",http://dx.doi.org/10.1007/978-3-030-33578-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-25797-2_2,Recommendation Systems for Interactive Multimedia Entertainment,Data Visualization and Knowledge Engineering,10.1007/978-3-030-25797-2_2,Springer,2020-01-01,"In the era of internet has embarked on World Wide Web for searching or knowing any information about any topic which has resulted in humongous information load. Access to open source creates ever-growing content on web, where user will succumb to thousands of arrays of options available, when seeking for any product or services. As the entertainment industry is no way an exception, optimization of user’s choice is of utmost importance. Recommendation system (RS) is the application that provides decision tool for tracking the user’s previous choices about products or browsing web pages history, clicks and choices of similar users. The main purpose of RS is to support the user to select his desired product among the multiple, equally-competitive choices available. It can be employed for diverse set of item recommendation such as books, songs, movies, restaurants, gadgets, e-learning materials etc. This chapter attempts to explore the various techniques and reveals the human–machine cooperation by implementing recommendation systems, especially meant for entertainment industry. In summary, the essence of this treatise is the soft computing/knowledge engineering approaches (such as filtering techniques, machine learning algorithms) guided by internet of things to provide prediction that can be displayed by data visualization in entertainment landscape convincingly.",http://dx.doi.org/10.1007/978-3-030-25797-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-37484-6_2,A Mobile Recommender System for Location-Aware Telemedical Diagnostics,Innovations for Community Services,10.1007/978-3-030-37484-6_2,Springer,2020-01-01,"As recommender systems have proven their effectiveness in providing personalised recommendations based on previous user preferences in e-commerce, this approach is to be transferred for use in medicine. In particular, the aim is to complement the diagnoses made by physicians in rural hospitals of developing countries, in remote areas or in situations of uncertainty by machine recommendations that draw on large bases of expert knowledge to reduce the risk to patients. To this end, a database of patients’ medical history and a cluster model is maintained centrally. The model is constructed incrementally by a combination of collaborative and knowledge-based filtering, employing a weighted similarity distance specifically derived for medical knowledge. In the course of this process, the model permanently widens its base of knowledge on a medical area given. To give a recommendation, the model’s cluster best matching the diagnostic pattern of a considered patient is sought. Fuzzy sets are employed to cope with possible confusion in decision making, which may occur when large data sets cause clusters to overlap. The degrees of membership to these fuzzy sets are expressed by the Mahalanobis distance, whose weights are derived from risk factors identified by experts. The therapy actually applied after the recommendation and its subsequently observed consequences are fed back for model updating. Readily available mobile digital accessories can be used for remote data entry and recommendation display as well as for communication with the central site. The approach is validated in the area of obstetrics and gynecology.",http://dx.doi.org/10.1007/978-3-030-37484-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-9996-1_4,Technological Disruptions and the Indian IT Industry: Employment Concerns and Beyond,Digitalisation and Development,10.1007/978-981-13-9996-1_4,Springer,2020-01-01,"Internet of Things (IoT) industry is one of the most dynamic sectors in India. This US$ 150 billion-strong industry employs 3.8 million people and contributes more than 9% to Indian GDP. However, this largest private-sector employer has been experiencing stress due to fast-changing business models, increased competition from other countries, restrictive visa policies, upsurge in anti-outsourcing sentiments and, most importantly, technological disruptions. These disruptive technologies—captured in a moment in the history of technological transformations as the Fourth Industrial Revolution or Industrie 4.0 —principally include such developments as cloud computing, big data and analytics, Internet of Things (IoTs), automation, robotics and blockchain. While Industrie 4.0 has rendered conventional engineering expertise and low-end IT services redundant, it has the potential of creating new employment opportunities in a host of sectors including administration, banks, retail trade and online marketing. Disruptive technologies have a strong chance of transforming the nature and composition of the Indian IT industry in a big way, including endangering India’s position as the software superpower in the world. Albeit, the Indian IT industry has historically proved itself to be extraordinarily resilient and fortified during turbulent shocks of the dotcom bubble, the sub-prime crisis and US visa restrictions. Based on secondary data, this paper aims at mapping the changing nature and composition of the Indian IT industry during recent years. It tries to identify contemporary challenges to employment and business opportunities in the Indian IT industry. The paper includes policy suggestions for enhancement of relevant technological and skill capabilities in the country.",http://dx.doi.org/10.1007/978-981-13-9996-1_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-18732-3_1,"The Convergence of Digital Twin, IoT, and Machine Learning: Transforming Data into Action",Digital Twin Technologies and Smart Cities,10.1007/978-3-030-18732-3_1,Springer,2020-01-01,"Digital twins, Internet of Things (IoT), block chains, and Artificial Intelligence (AI) may redefine our imagination and future vision of globalization. Digital Twin will likely affect most of the enterprises worldwide as it duplicates the physical model for remote monitoring, viewing, and controlling based on the digital format. It is actually the living model of the physical system which continuously adapts to operational changes based on the real-time data from various IoT sensors and devices and forecasts the future of the corresponding physical counterparts with the help of machine learning/artificial intelligence. We have investigated the architecture, applications, and challenges in the implementation of digital twin with IoT capabilities. Some of the major research areas like big data and cloud, data fusion, and security in digital twins have been explored. AI facilitates the development of new models and technology systems in the domain of intelligent manufacturing.",http://dx.doi.org/10.1007/978-3-030-18732-3_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-45124-0_10,Towards the Detection of Malicious URL and Domain Names Using Machine Learning,Technological Innovation for Life Improvement,10.1007/978-3-030-45124-0_10,Springer,2020-01-01,"Malicious Uniform Resource Locator (URL) is an important problem in web search and mining. Malicious URLs host unsolicited content (spam, phishing, drive-by downloads, etc.) and try to lure uneducated users into clicking in such links or downloading malware which will result in critical data exfiltration. Traditional techniques in detecting such URLs have been to use blacklists and rule-based methods. The main disadvantage of such problems is that they are not resistant to 0-day attacks, meaning that there will be at least one victim for each URL before the blacklist is created. Other techniques include having sandbox and testing the URLs before clicking on them in the production or main environment. Such methods have two main drawbacks which are the cost of the sandboxing as well as the non-real-time response which is due to the approval process in the test environment. In this paper, we propose a method that exploits semantic features in both domains and URLs as well. The method is adaptive, meaning that the model can dynamically change based on the new feedback received on the 0-day attacks. We extract features from all sections of a URL separately. We then apply three methods of machine learning on three different sets of data. We provide an analysis of features on the most efficient value of N for applying the N-grams to the domain names. The result shows that Random Forest has the highest accuracy of over 96% and at the same time provides more interpretability as well as performance benefits.",http://dx.doi.org/10.1007/978-3-030-45124-0_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-018-0862-8,Sentiment analysis: a review and comparative analysis over social media,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-018-0862-8,Springer,2020-01-01,"Sentiment analysis is the computational examination of end user’s opinion, attitudes and emotions towards a particular topic or product. Sentiment analysis classifies the message according to their polarity whether it is positive, negative, or neutral. Recently researchers focused on lexical and machine-learning based method for sentiment analysis of social media post. Social media is a micro blogger site in which end users can post their comment in slag language that contains symbols, idioms, misspelled words and sarcastic sentences. Social media data also have curse of dimension problem i.e. high dimension nature of data that required specific pre-processing and feature extraction, which leads to improve classification accuracy. This paper present comprehensive overview of sentiment analysis technique based on recent research and subsequently explores machine learning (SVM, Navies Bayes, Linear Regression and Random Forest) and feature extraction techniques (POS, BOW and HASS tagging) in context of Sentiment analysis over social media data set. Further twitter data-sets are scrutinized and pre-processed with proposed framework,which yield intersecting facts about the capabilities and deficiency of sentiment analysis methods. POS is most suitable feature extraction technique with SVM and Navie Bayes classifier. Whereas Random Forest and linear regression provide the better result with Hass tagging.",http://dx.doi.org/10.1007/s12652-018-0862-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57745-2_45,Deep Learning Decision Support for Sustainable Asset Management,Advances in Asset Management and Condition Monitoring,10.1007/978-3-030-57745-2_45,Springer,2020-01-01,"Sustainable decisions can be thwarted by a plethora of conflicting influences and information, yet the need to prioritise sustainability in management has never been greater. In an era of high- and ultra-high dimensional data, deep learning models offer the scalability required to extract good representations of significant features from raw data. With automatic learning at several levels of abstraction, deep learning can support sustainable asset management by learning complex functions mapping of systems. By processing data directly from input to output, clear and concise information can support visionary asset management whilst exposing hidden insights, detecting anomalies or predicting future states. This research will look at the necessity of applying deep learning in sustainable asset management and reveal some of the challenges that exist.",http://dx.doi.org/10.1007/978-3-030-57745-2_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-38961-1_38,Data Poisoning Attacks on Graph Convolutional Matrix Completion,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-38961-1_38,Springer,2020-01-01,"Recommender systems have been widely adopted in many web services. As the performance of the recommender system will directly affect the profitability of the business, driving bad merchants to boost revenue for themselves by conducting adversarial attacks to compromise the effectiveness of such systems. Several studies have shown that recommender systems are vulnerable to adversarial attacks, e.g. data poisoning attack. Since different recommender systems adopt different algorithms, existing attacks are designed for specific systems. In recent years, with the development of graph deep learning, recommender systems have been also starting to use new methods, like graph convolutional networks. More recently, graph convolutional networks have also been found to be affected by poisoning attacks. However, characteristics of data sources in recommender systems, such as heterogeneity of nodes and edges, will bring challenge to solve attack problem. To overcome this challenge, in this paper, we propose data poisoning attacks on graph convolutional matrix completion (GCMC) recommender system by adding fake users. The key point of the method is to make fake users mimicrking rating behavior of normal users, then pass the information of thier rating behaviors towards the target item back to related normal users, attempting to interfere with the prediction of the recommender system. Futhermore, on two real-world datasets ML-100K and Flixster, the results show that our method significantly overmatches three baseline methods: (i) random attack, (ii) popular item based attack, (iii) and mimicry with random scores based attack.",http://dx.doi.org/10.1007/978-3-030-38961-1_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-06170-8_11,Cross-Fertilisation Between Human-Computer Interaction and Artificial Intelligence,A Guided Tour of Artificial Intelligence Research,10.1007/978-3-030-06170-8_11,Springer,2020-01-01,"Human-Computer Interaction (HCI) and Artificial Intelligence (AI) are two disciplines that followed parallel trajectories for about four decades. They also both complement each other and overlap in various problem-rich domains. This chapter is far from being exhaustive, but provides a representative story of how HCI and AI cross-fertilise each other since their inception. It reviews the following domains: intelligent user interfaces and more specifically conversational animated affective agents; capitalisation, formulation and use of ergonomic knowledge for the design and evaluation of interactive systems; synergy between visualisation and data mining.",http://dx.doi.org/10.1007/978-3-030-06170-8_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64096-5_9,Battery Management for Automated Warehouses via Deep Reinforcement Learning,Distributed Artificial Intelligence,10.1007/978-3-030-64096-5_9,Springer,2020-01-01,"Automated warehouses are widely deployed in large-scale distribution centers due to their ability of reducing operational cost and improving throughput capacity. In an automated warehouse, orders are fulfilled by battery-powered AGVs transporting movable shelves or boxes. Therefore, battery management is crucial to the productivity since recovering depleted batteries can be time-consuming and seriously affect the overall performance of the system by reducing the number of available robots. In this paper, we propose to solve the battery management problem by using deep reinforcement learning (DRL). We first formulate the battery management problem as a Markov Decision Process (MDP). Then we show the state-of-the-art DRL method which uses Gaussian noise to enforce exploration could perform poorly in the formulated MDP, and present a novel algorithm called TD3-ARL that performs effective exploration by regulating the magnitude of the outputted action. Finally, extensive empirical evaluations confirm the superiority of our algorithm over the state-of-the-art and the rule-based policies.",http://dx.doi.org/10.1007/978-3-030-64096-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-13705-2_1,Enterprise Systems for Networked Smart Cities,Smart Infrastructure and Applications,10.1007/978-3-030-13705-2_1,Springer,2020-01-01,"Smart city concept redefines the urban planning and development of the existing and new cities. It drives on economic, social, and environmental sustainability of a city and attracts citizens, professionals, and corporations to build sustainable living. It portrays a city that is operationally optimal and provides a space for innovation. This is achieved through state of the art physical, institutional, and digital infrastructure. This chapter addresses the challenges of the digital aspect of the smart city. Enterprise systems technology is widely used in the organizations and will be utilized in the Smart city systems conceptualization and implementation. Smart city systems definition has been derived by analyzing the smart city requirements. Enterprise systems technology has been explained and the latest ICT trends have been explored to develop the technological foundation of smart city systems. Finally, we introduce partial least square regression, a structural equation modeling method to explore interrelationships between different interdisciplinary constructs and show its application to studying smart city systems. From the digital perspective of smart city, it may be concluded that connectedness leads to integration and integration leads to dynamism and dynamism leads to smartness and cycle continues to realize the best in class smart city.",http://dx.doi.org/10.1007/978-3-030-13705-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-43229-4_23,Click-Fraud Detection for Online Advertising,Parallel Processing and Applied Mathematics,10.1007/978-3-030-43229-4_23,Springer,2020-01-01,"In affiliate marketing, an affiliate offers to handle the marketing effort selling products of other companies. Click-fraud is damaging to affiliate marketers as they increase the cost of internet traffic. There is a need for a solution that has an economic incentive to protect marketers while providing them with data they need to reason about the traffic quality. In our solution, we propose a set of interpretable flags explainable ones to describe the traffic. Given the different needs of marketers, differences in traffic quality across campaigns and the noisy nature of internet traffic, we propose the use of equality testing of two proportions to highlight flags which are important in certain situations. We present measurements of real-world traffic using these flags.",http://dx.doi.org/10.1007/978-3-030-43229-4_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-31729-4_10,Trust-Based Access Control Management in Collaborative Open Social Networks,Access Control Management in Cloud Environments,10.1007/978-3-030-31729-4_10,Springer,2020-01-01,"This chapter proposes a trust involved access management framework for supporting privacy preserving access control policies and mechanisms. The mechanism enforces access policy to data containing personally identifiable information. The key component of the framework is an access control model that provides full support for expressing highly complex privacy-related policies, taking into account features like purposes and obligations. A policy refers to an access right that a subject can have on an object, based on relationship, trust, purpose and obligations. The structure of purpose involved access control policy is studied and the authorization approaches are discussed including positive authorization and negative authorizations. Finally a discussion of our work in comparison with other access control and frameworks such as EPAL is discussed.",http://dx.doi.org/10.1007/978-3-030-31729-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19135-1_18,UTAUT-QiU: Technology Acceptance Evaluation Model with Integrated Quality-in-Use Assessment for Mobile UI Adapted for Low- and Post-literate Users,Advances in Usability and User Experience,10.1007/978-3-030-19135-1_18,Springer,2020-01-01,"The Mobile technology evolution has greatly affected our lives, in terms of performing our daily tasks more efficiently and effectively. It includes recent advances in voice-enabled technology empowered by artificial intelligence, machine learning and natural language processing. Then again, technology evolution has created a problem for low and post-literate population in terms of understanding and using mobile devices with complex functionality. We intend to increase technology acceptance and the quality-in-use of MUI for low-and post-literate users by applying text-free approach combined with voice as a service. A new technology acceptance evaluation model UTAUT-QiU is proposed in this paper with the aim of assessing both user acceptance of text free MUI and MUI’s quality-in-use.",http://dx.doi.org/10.1007/978-3-030-19135-1_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49435-3_11,Online Reinforcement Learning for Self-adaptive Information Systems,Advanced Information Systems Engineering,10.1007/978-3-030-49435-3_11,Springer,2020-01-01,"A self-adaptive information system is capable of maintaining its quality requirements in the presence of dynamic environment changes. To develop a self-adaptive information system, information system engineers have to create self-adaptation logic that encodes when and how the system should adapt itself. However, developing self-adaptation logic may be difficult due to design time uncertainty; e.g., anticipating all potential environment changes at design time is in most cases infeasible. Online reinforcement learning (RL) addresses design time uncertainty by learning the effectiveness of adaptation actions through interactions with the system’s environment at run time, thereby automating the development of self-adaptation logic. Existing online RL approaches for self-adaptive information systems exhibit two shortcomings that limit the degree of automation: they require manually fine-tuning the exploration rate and may require manually quantizing environment states to foster scalability. We introduce an approach to automate the aforementioned manual activities by employing policy-based RL as a fundamentally different type of RL. We demonstrate the feasibility and applicability of our approach using two self-adaptive information system exemplars.",http://dx.doi.org/10.1007/978-3-030-49435-3_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-47686-1_1,Foundations,Information Retrieval: A Biomedical and Health Perspective,10.1007/978-3-030-47686-1_1,Springer,2020-01-01,"This chapter presents the foundations of the field of information retrieval (IR), which is also known as search. It begins with a number of basic definitions of terms in the field. Next, it describes various models that explain aspects of IR. This is followed by an enumeration of the different organizations, journals, textbooks, and tools that serve the field. Next, the chapter describes IR on the Internet and World Wide Web. Finally, the chapter describes evaluation methods and challenge evaluations for the field.",http://dx.doi.org/10.1007/978-3-030-47686-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-4067-7_2,World Network Information Technology Development,World Internet Development Report 2018,10.1007/978-981-15-4067-7_2,Springer,2020-01-01,"The year 2018 has witnessed the steady development of the world network information technology, with new technical innovations and breakthroughs, which have led to a new round of technical upgrades in the economy and society. Information technology tends to develop from digitalization and networking to intelligence, network information technology is being integrated with real economy.",http://dx.doi.org/10.1007/978-981-15-4067-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50341-3_32,The Evolution of Marketing in the Context of Voice Commerce: A Managerial Perspective,"HCI in Business, Government and Organizations",10.1007/978-3-030-50341-3_32,Springer,2020-01-01,"The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N = 62) revealed the expected impact of voice assistants on the shopping process. Findings show that managers consider voice assistants a disruptive technology assuming a central relational role in the consumer market. However, they often divergence in opinions across industry, function, and seniority level. Besides, managers’ familiarity with voice commerce is correlated to a higher optimism towards voice technologies (opportunity for brands) but also a greater sense of urgency (short-term focus) with implications for marketing strategy. This article offers support to brand owners explaining how voice assistants work and examining their effects on consumption. The authors discuss empirical results while providing managerial guidelines to create resilient and sustainable brands in the era of voice commerce.",http://dx.doi.org/10.1007/978-3-030-50341-3_32,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-37439-6_4,Why We Need Knowledge Graphs: Applications,Knowledge Graphs,10.1007/978-3-030-37439-6_4,Springer,2020-01-01,"No matter how well curated and high quality Knowledge Graphs we build are, they are only as powerful as their applications. In this section we introduce concrete real-world use cases where Knowledge Graphs power dialog-based access to information and services. We do that by giving an overview of the existing chatbot and voice assistant market first and then demonstrating their limitations. We explain in which ways Knowledge Graphs can improve conversational interfaces with the help of pilots from different domains such as tourism and energy.",http://dx.doi.org/10.1007/978-3-030-37439-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63171-0_1,Towards Interference-Aware Dynamic Scheduling in Virtualized Environments,Job Scheduling Strategies for Parallel Processing,10.1007/978-3-030-63171-0_1,Springer,2020-01-01,"Our previous work shows that multiple applications contending for shared resources in virtualized environments are susceptible to cross-application interference, which can lead to significant performance degradation and consequently an increase in the number of broken SLAs. Nevertheless, state of the art in resource scheduling in virtualized environments still relies mainly on resource capacity, adopting heuristics such as bin packing, overlooking this source of overhead. However, in recent years interference-aware scheduling has gained traction, with the investigation of ways to classify applications regarding their interference levels and the proposal of static cost models and policies for scheduling co-hosted cloud applications. Preliminary results in this area already show a considerable improvement on resource usage and in the reduction of broken SLAs, but we strongly believe that there are still opportunities for improvement in the areas of application classification and pro-active dynamic scheduling strategies. This paper presents the state of the art in interference-aware scheduling for virtualized environments and the challenges and advantages of a dynamic scheme.",http://dx.doi.org/10.1007/978-3-030-63171-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-9031-3_25,Privacy-Preserving Nonlinear SVM Classifier Training Based on Blockchain,Security and Privacy in Social Networks and Big Data,10.1007/978-981-15-9031-3_25,Springer,2020-01-01,"The SVM classifier has been a significant and prevailing technique in machine learning applications. Training a high-quality SVM classifier usually requires a huge amount of data, which makes collaborative training by multiple parties become an inevitable trend. However, it causes privacy risks when sharing sensitive data with others. There are some existing methods to solve this problem. These methods mainly contain computation-intensive cryptographic techniques which are inefficient and not suitable for practical use. Therefore, it is important to realize efficient SVM classifier training while protecting privacy. In this paper, we propose a novel privacy-preserving SVM classifier training scheme based on blockchain. We establish a blockchain-based SVM classifier training mechanism which realizes collaboratively training while protecting privacy. We adopt the additive secret sharing technique to design several computation protocols, which are much more efficient than the schemes which contain complex cryptographic primitives. We conduct a thorough analysis of the security properties of our scheme. Experiments over a real dataset show that our scheme achieves high accuracy and practical efficiency.",http://dx.doi.org/10.1007/978-981-15-9031-3_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59410-7_24,Game Recommendation Based on Dynamic Graph Convolutional Network,Database Systems for Advanced Applications,10.1007/978-3-030-59410-7_24,Springer,2020-01-01,"Recent years have witnessed the popularity of game recommendation. Different from the other recommendation scenarios, the user and item properties in game recommendation usually exhibit highly dynamic properties, and may influence each other in the user-item interaction process. For taming such characters, so as to design a high quality recommender system tailored for game recommendation, in this paper, we design a dynamic graph convolutional network to highlight the user/item evolutionary features. More specifically, the graph neighbors in our model are not static, they will be adaptively changed at different time. The recently interacted users or items are gradually involved into the aggregation process, which ensures that the user/item embeddings can evolve as the time goes on. In addition, to timely match the changed neighbors, we also update the convolutional weights in a RNN-manner. By these customized strategies, our model is expected to learn more accurate user behavior patterns in the field of game recommendation. We conduct extensive experiments on real-world datasets to demonstrate the superiority of our model.",http://dx.doi.org/10.1007/978-3-030-59410-7_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59419-0_26,Decentralized Embedding Framework for Large-Scale Networks,Database Systems for Advanced Applications,10.1007/978-3-030-59419-0_26,Springer,2020-01-01,"Network embedding aims to learn vector representations of vertices, that preserve both network structures and properties. However, most existing embedding methods fail to scale to large networks. A few frameworks have been proposed by extending existing methods to cope with network embedding on large-scale networks. These frameworks update the global parameters iteratively or compress the network while learning vector representation. Such network embedding schemes inevitably lead to a high cost of either high communication overhead or sub-optimal embedding quality. In this paper, we propose a novel decentralized large-scale network embedding framework called DeLNE . As the name suggests, DeLNE divides a network into smaller partitions and learn vector representation in a distributed fashion, avoiding any unnecessary communication overhead. Our proposed framework uses Variational Graph Convolution Auto-Encoders to embed the structure and properties of each sub-network. Secondly, we propose an embedding aggregation mechanism, that captures the global properties of each node. Thirdly, we propose an alignment function, that reconciles all sub-networks embedding into the same vector space. Due to the parallel nature of DeLNE, it scales well on large clustered environments. Through extensive experimentation on realistic datasets, we show that DeLNE produces high-quality embedding and outperforms existing large-scale network embeddings frameworks, in terms of both efficiency and effectiveness.",http://dx.doi.org/10.1007/978-3-030-59419-0_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63836-8_34,Asymmetric Pairwise Preference Learning for Heterogeneous One-Class Collaborative Filtering,Neural Information Processing,10.1007/978-3-030-63836-8_34,Springer,2020-01-01,"Heterogeneous one-class collaborative filtering (HOCCF) is a recent and important recommendation problem which involves two different types of one-class feedback such as purchases and examinations. In this paper, we propose a generic asymmetric pairwise preference assumption and a novel like-minded user-group construction strategy for the HOCCF problem. Specifically, our generic assumption contains six different pairwise preference relations derived from the heterogeneous feedback, where we introduce a series of weighting strategies to make our assumption more reasonable. Our group construction strategy introduces richer interactions within user-groups, which is expected to learn the users’ preference more accurately. We then design a novel recommendation model called a symmetric p airwise p reference le arning (APPLE). Extensive empirical studies show that our APPLE can recommend items significantly more accurately than the closely related state-of-the-art methods on three real-world datasets.",http://dx.doi.org/10.1007/978-3-030-63836-8_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62466-8_37,Understanding Data Centers from Logs: Leveraging External Knowledge for Distant Supervision,The Semantic Web – ISWC 2020,10.1007/978-3-030-62466-8_37,Springer,2020-01-01,"Data centers are a crucial component of modern IT ecosystems. Their size and complexity present challenges in terms of maintaining and understanding knowledge about them. In this work we propose a novel methodology to create a semantic representation of a data center, leveraging graph-based data, external semantic knowledge, as well as continuous input and refinement captured with a human-in-the-loop interaction. Additionally, we specifically demonstrate the advantage of leveraging external knowledge to bootstrap the process. The main motivation behind the work is to support the task of migrating data centers, logically and/or physically, where the subject matter expert needs to identify the function of each node - a server, a virtual machine, a printer, etc - in the data center, which is not necessarily directly available in the data and to be able to plan a safe switch-off and relocation of a cluster of nodes. We test our method against two real-world datasets and show that we are able to correctly identify the function of each node in a data center with high performance.",http://dx.doi.org/10.1007/978-3-030-62466-8_37,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-39863-7_6,Case Studies in Application Placement and Infrastructure Optimisation,Managing Distributed Cloud Applications and Infrastructure,10.1007/978-3-030-39863-7_6,Springer,2020-01-01,"This chapter presents four case studies each illustrating an implementation of one or more RECAP subsystems. The first case study illustrates how RECAP can be used for infrastructure optimisation for a 5G network use case. The second case study explores application optimisation for virtual content distribution networks (vCDN) on a large Tier 1 network operator. The third case study looks at how RECAP components can be embedded in an IoT platform to reduce costs and increase quality of service. The final case study presents how data analytics and simulation components, within RECAP, can be used by a small-to-medium-sized enterprise (SME) for cloud capacity planning.",http://dx.doi.org/10.1007/978-3-030-39863-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-43506-6_7,Polyglot Persistence in Data Management,Fast and Scalable Cloud Data Management,10.1007/978-3-030-43506-6_7,Springer,2020-01-01,"As applications become more data-driven and highly distributed, providing low response times to increasingly many users becomes more challenging within the scope of a single database system. Not only the variety of use cases is increasing, but also the requirements are becoming more heterogeneous: horizontal scalability, schema flexibility, and high availability are primary concerns for modern applications. While RDBMSs cover many of the functional requirements (e.g., ACID transactions and expressive queries), they cannot cover scalability, performance, and fault tolerance in the same way that specialized data stores can. The explosive growth of available systems through the Big Data and NoSQL movement sparked the idea of employing particularly well-suited database systems for subproblems of the overall application.",http://dx.doi.org/10.1007/978-3-030-43506-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-42291-2_12,The Next Sustainability Frontier Is Digital,Sustainability Leadership,10.1007/978-3-030-42291-2_12,Springer,2020-01-01,"Digitalization is a powerful accelerator to create and scale sustainable solutions. Artificial intelligence (AI), robotics, the Internet of Things, and other technologies can provide breakthrough transformations for sustainable development. Yet business leaders must weigh how they deploy and scale technology with the ethical implications that can emerge with a new form of pollution: digital or data pollution. The societal impacts of data-driven technologies are the next big sustainability challenge. Leaders need to act early to curtail or avoid privacy and ethical risks. Stockholm’s AI Sustainability Center advises how to manage the different pitfalls that lead to risks: misuse or overuse of data, data bias, bias of the creator, and immature data or AI. Scania and Telia Company share how they navigate responsible use of technology.",http://dx.doi.org/10.1007/978-3-030-42291-2_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-53199-7_1,Chapter 1 Ecosystem of Big Data,Knowledge Graphs and Big Data Processing,10.1007/978-3-030-53199-7_1,Springer,2020-01-01,"The rapid development of digital technologies, IoT products and connectivity platforms, social networking applications, video, audio and geolocation services has created opportunities for collecting/accumulating a large amount of data. While in the past corporations used to deal with static, centrally stored data collected from various sources, with the birth of the web and cloud services, cloud computing is rapidly overtaking the traditional in-house system as a reliable, scalable and cost-effective IT solution. The high volumes of structures and unstructured data, stored in a distributed manner, and the wide variety of data sources pose problems related to data/knowledge representation and integration, data querying, business analysis and knowledge discovery. This introductory chapter serves to characterize the relevant aspects of the Big Data Ecosystem with respect to big data characteristics, the components needed for implementing end-to-end big data processing and the need for using semantics for improving the data management, integration, processing, and analytical tasks.",http://dx.doi.org/10.1007/978-3-030-53199-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41110-7_5,Living at the Edge? Optimizing availability in IoT,The Cloud-to-Thing Continuum,10.1007/978-3-030-41110-7_5,Springer,2020-01-01,"Cloud, edge, and fog computing enable Internet of Things (IoT) applications, offering high connectivity, scalability, and high availability. Smart cities, smart agriculture, and e-health systems are examples of IoT applications that can exploit the opportunities generated by these technologies. However, due to the scale and complexity of the IoT and the heterogeneity of the devices and service level expectations, resource management is not a trivial task. While facilitating storage and processing at the end device (the edge), at the intermediary layer (the fog), or centrally (the cloud), new points of failure are introduced at and between each layer. In some use cases, such as e-health, device availability also has high criticality. Any downtime impacting one or more components in the architecture can result in adverse effects and/or additional logistical effort and cost. This chapter discusses extant research on how cloud, fog, and edge computing is being used in smart city, smart agriculture, and e-health systems.",http://dx.doi.org/10.1007/978-3-030-41110-7_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49435-3_3,Modeling and Analyzing Architectural Diversity of Open Platforms,Advanced Information Systems Engineering,10.1007/978-3-030-49435-3_3,Springer,2020-01-01,"Nowadays, successful software companies attain enhanced business objectives by opening their platforms to thousands of third-party providers. When developing an open platform many architectural design decisions have to be made, which are driven from the companies’ business objectives. The set of decisions results in an overwhelming design space of architectural variabilities. Until now, there are no architectural guidelines and tools that explicitly capture design variabilities of open platforms and their relation to business objectives. As a result, systematic knowledge is missing; platform providers have to fall back to ad-hoc decision-making; this bears consequences such as risks of failure and extra costs. In this paper, we present a pattern-driven approach called SecoArc to model diverse design decisions of open platforms and to analyze and compare alternative architectures with respect to business objectives. SecoArc consists of a design process , a modeling language , and an automated architectural analysis technique . It is implemented and ready-to-use in a tool. We evaluate the approach by means of a real-world case study. Results show that the approach improves the decision-making. Future platform providers can reduce risks by making informed decisions at design time.",http://dx.doi.org/10.1007/978-3-030-49435-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35679-8_4,Top-Down Approach to Object Identification in a Cluttered Environment Using Single RGB-D Image and Combinational Classifier for Team Nanyang’s Robotic Picker at the Amazon Picking Challenge 2015,Advances on Robotic Item Picking,10.1007/978-3-030-35679-8_4,Springer,2020-01-01,"In order to determine proper grasp strategy for a picking robot, identification of the target item in a cluttered environment such as a shelf’s bin is necessary. However, the presence of non-target items in the same bin could result in misidentification and wrong picking. This paper presents a method that uses RGB-D image data from a training image library to improve identity estimation likelihood for each object class. Global features extracted from a set of segments in the RGB-D image are matched with those corresponding to many different segments belonging to different object classes. The ratio of the best matching scores achieved with each possible object class in the library is then converted to a class identity likelihood estimate for each object. The strategy has been successfully implemented for a robotic picking system deployed at the Amazon Picking Challenge 2015. The system could identify and differentiate between the 25 items available for picking.",http://dx.doi.org/10.1007/978-3-030-35679-8_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51999-5_25,A Two Tier Architecture for Local Energy Market Simulation and Control,"Highlights in Practical Applications of Agents, Multi-Agent Systems, and Trust-worthiness. The PAAMS Collection",10.1007/978-3-030-51999-5_25,Springer,2020-01-01,"This paper addresses energy management and security having as basis sensing and monitoring of cyber-physical infrastructure of consumers and prosumers, and their participation in the Local Energy Market (LEM). The vision is to create a layered multi-agent framework that brings a complete view of the cyber-physical system of LEM participants, and provides optimization and control of energy for said participants. The proposed system is separated into a Market layer and a Cyber-Physical layer, each of them providing different services. The cyber-physical layer, represented by SMARTERCtrol system, provides Data Monitoring and Optimized Energy Control of individual building resources. The Market layer, represented by LEM Multi-Agent System, provides Negotiation, Forecasting, and Trust Evaluation. Both systems work together to provide and integrate a tool for simulation and control of LEM.",http://dx.doi.org/10.1007/978-3-030-51999-5_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-06164-7_23,Knowledge Engineering,A Guided Tour of Artificial Intelligence Research,10.1007/978-3-030-06164-7_23,Springer,2020-01-01,"Knowledge engineering refers to all technical, scientific and social aspects involved in designing, maintaining and using knowledge-based systems. Research in this domain requires to develop studies on the nature of the knowledge and its representation, either the users’ knowledge or the knowledge-based system’s knowledge. It also requires the analysis of what type of knowledge sources is considered, what human-machine interaction is envisaged and more generally the specific end use. To that end, knowledge engineering needs to integrate innovation originating from artificial intelligence, knowledge representation, software engineering as well as modelling. This integration enables both users and software systems to manage and use the knowledge for inference reasoning. Other advances are fuelling new methods, software tools and interfaces to support knowledge modelling that are enabled by conceptual or formal knowledge representation languages. This chapter provides an overview of the main issues and major results that are considered as milestones in the domain, with a focus on recent advances marked by the raise of the semantic web, of ontologies and the social web.",http://dx.doi.org/10.1007/978-3-030-06164-7_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-12719-0_14,Growth Hacking Health: Scaling Your Venture,Digital Health Entrepreneurship,10.1007/978-3-030-12719-0_14,Springer,2020-01-01,"There are approximately 7.5 billion people that share our planet. It takes roughly seven trillion dollars per year to keep the global population relatively healthy, with over 50% of that spending occurring in the United States (Institute of Medicine/Reports. Best Care at Lower Cost The Path to Continuously Learning Health Care in America. 2012). No hospital, no matter how tall or wide, can treat all those people. True scale in healthcare can only be achieved through digital means. The belated promise of prevention in healthcare, a pyrrhic battle until the recent widespread use of smartphones, will also only be realized by digital means. The Holy Grail of Healthcare, that is precision or personalized medicine, will also only be seized by hybrid technological innovations. Traditionally, the art and science of medicine (and some would say even the very nature of life itself) relied on the constant yin and yang of ‘trial and error’. Growth hacking is taking that same stochastic process and exponentially increasing its base and pace thanks to the power of digital technologies, data collection and analytics. This process of rapid experimentation across marketing funnel(s), product development, sales segments, and other areas of the business will help the most diligent digital health entrepreneurs find the most efficient way(s) to scale their business. And healthcare has always been about scale. Digital healthcare entrepreneurs will also need to employ a hybrid healthcare approach to address the pain points of future generations. Growth hackers in health must also focus on low-cost alternatives to traditional marketing, e.g. using social media, viral marketing, psychographics, or targeted advertising instead of ‘wasting’ valuable runway dollars on advertising through more traditional snail media mediums such as radio, newspaper, and television. This chapter will shed light on the hard work that is required to develop a viral digital health venture. Magical spagyric self-care apps or philosopher stone platforms do not simply or spontaneously self-generate ex-nihilo. In the dog-eat-dog world of entrepreneurship there is no such thing as luck. These new miraculous tools of medicine are the result of thousands of man-hours of analog and artificial intelligence. To paraphrase Thomas Jefferson, the harder you work, the luckier you get.",http://dx.doi.org/10.1007/978-3-030-12719-0_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-658-27582-2_3,Theoretical foundation,Big Data to Improve Strategic Network Planning in Airlines,10.1007/978-3-658-27582-2_3,Springer,2020-01-01,"When following a qualitative research design, as developed in chapter 2, it is vital to ground the research on a relevant overarching theory (Creswell, 2013, p. 63). The research topic “big data to improve strategic network planning in airlines” is situated on the intersection of four different research domains – information systems, logistics, operations research, and strategic management. The overarching theory needs to be applicable to all domains to facilitate the creation of an overarching theoretical concept, although additional technical theories can be used to explain certain phenomena or research objects (Wynn & Williams, 2012, p. 798).",http://dx.doi.org/10.1007/978-3-658-27582-2_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-37955-1_27,Case Study 6: The Digital Transformation of Manufacturing,Deliberately Digital,10.1007/978-3-030-37955-1_27,Springer,2020-01-01,"The Industry 4.0 concept was launched in Germany in the early 2010s. Its aim was to increase flexibility, improve efficiency, and reduce time to market: initially concentrating on automation and robotics on the shop floor, and subsequently building out product-related services (servitization). The next challenge, which is precipitated by the availability of massive increases in quantities of data resulting from the Internet of Things, is that of being able to share industrial data among the various stakeholders of end-to-end product lifecycle value chains. The formation of ecosystems of market players willing to share their respective industrial data will be able to unlock inherent data value through industrial data platforms. Such platforms are expected to bring significant returns on investment in terms of flexibility, efficiency, and time to market.",http://dx.doi.org/10.1007/978-3-030-37955-1_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-01585-4_8,"Federated Learning for Vision, Language, and Recommendation",Federated Learning,10.1007/978-3-031-01585-4_8,Springer,2020-01-01,"In this chapter, we discuss the existing works of applying federated learning in computer vision, natural language processing, and recommender system, for enabling privacy-preserving AI applications.",http://dx.doi.org/10.1007/978-3-031-01585-4_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-62271-1_6,Enabling Decision Support Through Ranking and Summarization of Association Rules for TOTAL Customers,Transactions on Large-Scale Data- and Knowledge-Centered Systems XLIV,10.1007/978-3-662-62271-1_6,Springer,2020-01-01,"Our focus in this experimental analysis paper is to investigate existing measures that are available to rank association rules and understand how they can be augmented further to enable real-world decision support as well as providing customers with personalized recommendations. For example, by analyzing receipts of TOTAL customers, one can find that, customers who buy windshield wash, also buy engine oil and energy drinks or middle-aged customers from the South of France subscribe to a car wash program. Such actionable insights can immediately guide business decision making, e.g., for product promotion, product recommendation or targeted advertising. We present an analysis of 30 million unique sales receipts, spanning 35 million records, by almost 1 million customers, generated at 3,463 gas stations, over three years. Our finding is that the 35 commonly used measures to rank association rules, such as Confidence and Piatetsky-Shapiro, can be summarized into 5 synthesized clusters based on similarity in their rankings. We then use one representative measure in each cluster to run a user study with a data scientist and a product manager at TOTAL. Our analysis draws actionable insights to enable decision support for TOTAL decision makers: rules that favor Confidence are best to determine which products to recommend and rules that favor Recall are well-suited to find customer segments to target. Finally, we present how association rules using the representative measures can be used to provide customers with personalized product recommendations.",http://dx.doi.org/10.1007/978-3-662-62271-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50334-5_14,Cross-Scenario Performance Modelling for Big Data Ecosystems,Artificial Intelligence in HCI,10.1007/978-3-030-50334-5_14,Springer,2020-01-01,"Performance prediction is an essential aspect of several critical system design decisions, such as workload scheduling and resource planning. However, developing a model with higher prediction accuracy is a challenging task in big data systems due to the stack complexity and environmental heterogeneity. Workload modelling aims to simplify the connection between workloads factors and performance testing. Most of the workload models rely on a single scenario under test (SUT) method, where the trained and the evaluated data have the same distribution. However, a single SUT is not the ideal modelling method for big data workloads, as SUTs change frequently. Big data systems have a considerable amount of possible test scenarios that are generated from changing one or more elements in the testing environment, such as changing benchmarks, software versions, or cloud service types. To address this issue, we propose a cross-Scenario workload modelling method that aims to improve the workloads’ performance classification accuracy. The proposed approach adopts the Transfer Learning concept for reusing models cross different but related scenarios. In this work, we evaluate the proposed approach on multi real-world scenarios in Hadoop which is an example of big data system. The empirical results showed that the proposed approach is more accurate than SUT method.",http://dx.doi.org/10.1007/978-3-030-50334-5_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57997-5_41,Industry 4.0 Data-Related Technologies and Servitization: A Systematic Literature Review,Advances in Production Management Systems. Towards Smart and Digital Manufacturing,10.1007/978-3-030-57997-5_41,Springer,2020-01-01,"The advancements and adoption of digital technologies enable manufacturers to approach intelligent production and reach a higher level of automation in the wave of Industry 4.0. Even though manufacturing is at the center of this industrial revolution, the impact of digital technologies is more far-reaching: indeed, one of the biggest growth potentials is recognized in the paradigm shift from a traditional product orientation to the provision of bundled solutions. Particularly the possibility to gather and analyze data has been recognized as a key enabler for the advancement of the product-services offering. In this view, the research presented a systematic literature review exploring the state of the art considering on one side the newest technologies related to data and digitalization and on the other side servitization, aiming at understanding the point of contact between them. Four different perspectives have been identified and discussed and possible research directions have been proposed.",http://dx.doi.org/10.1007/978-3-030-57997-5_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-36178-5_45,On the Prediction of Possibly Forgotten Shopping Basket Items,Artificial Intelligence and Applied Mathematics in Engineering Problems,10.1007/978-3-030-36178-5_45,Springer,2020-01-01,"With the easy availability of shopping transaction data, it is now possible to use historical information to enhance the shopping experience of shoppers. In particular, we focus on the issue of forgotten items. We have all had the experience of shopping at a supermarket and either forgetting to buy certain items or not realizing that certain items are needed. In this paper, we focus on predicting such items during a shopper’s visit and providing hints to the shopper that they may in fact need certain items that were not purchased. Note that, by providing hints for forgotten items, the shopper benefits by avoiding a return trip to the supermarket and the supermarket benefits because the shopper purchases additional items. We provide examples to illustrate the utility of the proposed approach.",http://dx.doi.org/10.1007/978-3-030-36178-5_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-33624-0_5,Cloud-Enabled Domain-Based Software Development,Software Engineering in the Era of Cloud Computing,10.1007/978-3-030-33624-0_5,Springer,2020-01-01,"A cloud-based software development framework is presented that does not require programmer capabilities. The development starts with a graphical modelling of the process model, defining the top-level flow for the application. Such a flow coordinates the functional units that are components or services linked to the process again through graphical means such as drag and drop. Variability Variability affects all processes and functional constituents, being the principal specification requires for the application under development. The idea has been partially implemented in a commercial setting and is in its assessment phase. This framework needs to be domain-specific for successful deployment of user ideas without programming-level input. As a platform, the suggested environment allows the setting up of different development environments for different domains. A user community can construct new domains by defining reference architectures, process models and other assets for the application developers. Consequently, there is a possibility of a market place shaping up where such assets can be offered and consumed, subject to an administration for security and optionally commercial purposes. Open, free or paid marketplaces can be created based on administrative policies.",http://dx.doi.org/10.1007/978-3-030-33624-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-13438-9_3,State of the Art,Recommender System for Improving Customer Loyalty,10.1007/978-3-030-13438-9_3,Springer,2020-01-01,"In this chapter, different types of available information technology solutions supporting customer relationship management as well as collecting the customer feedback, are discussed, with the focus on the new generation on intelligent decision support and recommender systems.",http://dx.doi.org/10.1007/978-3-030-13438-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_118-1,Use of GIS and Remote Sensing in Tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_118-1,Springer,2020-01-01,"A geographic information system (GIS) is a computer-based information system using special tools to manage location-based data and their attributes for decision-making. Geospatial functions cut across many fields and support problem solving through geodata design and analysis. GIS have been used, for example, in environmental conservation and wildlife management. Its use in tourism planning, development and management, and marketing of destination products is only a more recent approach. The adoption of the technology affects both the sustainability of environmental resources and the quality of tourists’ experience. The purpose of this chapter is, first, to explore the functionalities and usage potentials of GIS in the tourism domain. Second, two studies of Maasai Mara Game Reserve and Nairobi National Park portray how GIS and satellite remote sensing imagery is applied to assess the ecosystem’s changes, their causes, and major implications. Examination of Landsat satellite image data for 2000 and 2017 shows that due to conversion of areas to farmlands and settlements, the coverage of Mau Forest Complex, the main catchment area for the Mara ecosystem, had reduced by 30.2% and vegetation by 22.8%. The analysis of Nairobi National Park showed that the Kitengela wildlife migration corridor has been completely encroached by human settlement and mining activities, thus seriously compromising the performance of the ecosystem. Mapping of human development pressure on the ecosystem using GIS technologies can be used to assess and manage the tourism resources potential in conjunction to biodiversity conservation as a critical element in improving wildlife as a tourism destination product.",http://dx.doi.org/10.1007/978-3-030-05324-6_118-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39081-5_35,Numerical Problems in XBRL Reports and the Use of Blockchain as Trust Enabler,Numerical Computations: Theory and Algorithms,10.1007/978-3-030-39081-5_35,Springer,2020-01-01,Financial statements are formal records of the financial activities that companies use to provide an accurate picture of their financial history. Their main purpose is to offer all the necessary data for an accurate assessment of the economic situation of a company and its ability to attract stakeholders. Our goal is to investigate how Benford’s law can be used to detect fraud in a financial report with the support of trustworthiness by blockchain.,http://dx.doi.org/10.1007/978-3-030-39081-5_35,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5720-0_6,Intelligent Freight Transportation and Supply Chain Drivers: A Literature Survey,Proceedings of the Seventh International Forum on Decision Sciences,10.1007/978-981-15-5720-0_6,Springer,2020-01-01,"Over the last 10 years, Intelligent Freight Transportation (IFT) has significantly transformed the structure of the trucking industry in North America by implementing new digital-dependent policies (e.g. the ELD mandate), digital freight marketplaces (e.g., digital load boards) and intelligent hardware (e.g., autonomous trucks). In this paper, the author reviews the IFT literature in freight transportation from between 2009 and 2019, focusing on the effect of digitization in performance indicators and supply chain drivers. Based on the current gap in the body of literature available, while many behavioral studies in drivers’ safety have been conducted, there is a lack of behavioral research on most human-oriented topics (interface with IFT). Moreover, the role of smart contracts in improving sustainability (e.g., GHG reduction) is rarely measured and cited in many IFT frameworks.",http://dx.doi.org/10.1007/978-981-15-5720-0_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-34463-4_1,Introduction,Dynamic Lines of Collaboration,10.1007/978-3-030-34463-4_1,Springer,2020-01-01,"The more complex and interdependent systems and service networks become, the more vulnerable they are to disruptions, events and developments that disturb their normal existence and intended usefulness. At the same time, intelligent planning and control mechanisms can be developed to help prevent, mitigate, and recover from these disruptions. What are disruptions? Who suffers from them? How have they been handled, and how can they be handled and controlled in the future? In this chapter, definitions and examples of e-Work and cyber Physical systems, their vulnerabilities, and the disruptions that impact them are described. Their characteristics as innovative disruptions, and as damaging disruptions are explained. For both types of disruptions, who they disrupt, and how they have been handled and controlled so far are explored and explained. The key related problems of service resource allocation and protection priorities, and four typical examples of disruptions in connected and networked e-Work are also discussed. This chapter concludes with the Network-to-Network framework of collaborative e-Work, which has been found to be highly effective for disruption handling and control.",http://dx.doi.org/10.1007/978-3-030-34463-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41110-7_4,Orchestration from the Cloud to the Edge,The Cloud-to-Thing Continuum,10.1007/978-3-030-41110-7_4,Springer,2020-01-01,"The effective management of complex and heterogeneous computing environments is one of the biggest challenges that service and infrastructure providers are facing in the cloud-to-thing continuum era. Advanced orchestration systems are required to support the resource management of large-scale cloud data centres integrated with the big data generation of IoT devices. The orchestration system should be aware about all available resources and their current status in order to perform dynamic allocations and enable short time deployment of applications. This chapter will review the state of the art with regards to orchestration along the cloud-to-thing continuum with a specific emphasis on container-based orchestration (e.g. Docker Swarm and Kubernetes) and fog-specific orchestration architectures (e.g. SORTS, SOAFI, ETSI IGS MEC, and CONCERT).",http://dx.doi.org/10.1007/978-3-030-41110-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-37468-6_19,A Decade Survey on Internet of Things in Agriculture,Internet of Things (IoT),10.1007/978-3-030-37468-6_19,Springer,2020-01-01,"The Internet of Things (IoT) is a united system comprising of physical devices, mechanical and digital machines, and different hardware components like sensors, actuators, cameras etc., monitored and operated by the software. The combination of devices and systems connected over the internet opens the pathway for development of various applications beneficial in terms of economic growth of a nation. IoT has evolved as a potentially emerging computer technology solving various real-life problems and issues. IoT covers vast group of applications, from warfare to surveillance, from habitat monitoring to energy harnessing, predictive analytics and personalized health care, and so on. Among various fields, agriculture is one important field having maximum scope of implementation and investment. The main aim of this book chapter is to furnish all the details related to applications of IoT in the field of agriculture. This includes the details related to data collection, types of sensors used, deployment details, data access through cloud. It also covers details related to various communication technologies used in IoT such as Bluetooth, LoRaWAN, LTE, 6LowPAN, NFC, RFID etc. And above all, the chapter focuses on the significance of IoT on agronomics, agricultural engineering, crop production and livestock production. This chapter is a decade survey conducted to study the contribution of IoT in the field of agriculture. Around 40 research papers for the duration 2008–2018 are collected from peer reviewed journals and conferences. The collected articles are analyzed to provide relevant information required for the various end users.",http://dx.doi.org/10.1007/978-3-030-37468-6_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1420-3_91,Efficient and Scalable Job Recommender System Using Collaborative Filtering,ICDSMLA 2019,10.1007/978-981-15-1420-3_91,Springer,2020-01-01,"Recommendation system is a techniques, which provides users with information, which he/she may be interested in or accessed in past. Traditional recommender techniques such as content and collaborative filtering used in various applications such as education, social media, marketing, entertainment, e-governance and many more. Content-based and collaborative filtering has many advantages and disadvantage and they are useful in specific application. Sparsity and cold start problem are major challenges in content and collaborative filtering. Challenges of content and collaborative filtering can be solved by using hybrid filtering. Hybrid filtering combines the features of two recommender system like content and collaborative; content-based filtering improves the classification accuracy and collaborative model easily gives the best-predicted result of a latent factor model. In this paper, we have presented a brief survey of the recommendation system approaches, techniques and application, one important application of recommendation system in Job Recruitment; in which candidates are elected by using online job recruitment portal based on their profile and job history and behaviour components; wherein it serves millions of candidates with suitable and personifies jobs. As per the recent survey this domain is less explored till now and existing job recommender system has many shortcomings, they use resumes/profile and job descriptions for analysis and new job post and candidate profiles are not matched properly because of cold start problem, sometime potential candidate loses their job due to the incomplete job description and education detail in the ontology. LinkedIn’s Job Ecosystem handles few problems, few are still unsolved that we discussed in result part. In this paper, we have presented a comparative analysis of different job recommender system and their techniques.",http://dx.doi.org/10.1007/978-981-15-1420-3_91,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-36107-5_4,Using Technology and Gamification  as a Means of Enhancing Users’ Experience at Cultural Heritage Sites,Rediscovering Heritage Through Technology,10.1007/978-3-030-36107-5_4,Springer,2020-01-01,"Technology is an application of science that aims to develop and create innovations that improve human society. This process has been ongoing for centuries ever since human progression Human progression  started with the invention of the first tools. In today’s world, with the advanced pace of technological innovations, we may not be taking advantage of all the usefulness that these innovations can offer. In the digital age of big data, information is always present at the user’s fingertips. How can old practices and traditional dissemination of information, such as, that used by most museums and cultural heritage Cultural heritage  sites keep up? In this chapter, we explore several emerging technologies, such as AI, AR, VR and mobile technologies as well as the use of gamification that can serve as aids in presenting cultural heritage Cultural heritage information to younger generations in ways that are more appealing to them. Combining gamification with emerging technologies can represent an effective way of increasing visitors’ interest and engagement at cultural heritage Cultural heritage  sites by providing a user-centred experience that is more playful and enjoyable.",http://dx.doi.org/10.1007/978-3-030-36107-5_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-22277-2_11,Security and Privacy in Social Networks: Data and Structural Anonymity,Handbook of Computer Networks and Cyber Security,10.1007/978-3-030-22277-2_11,Springer,2020-01-01,"Social networking has become an inevitable catchline among teenagers as well as today’s older generation. In recent years, there has been observed remarkable growth in social networking sites, especially in terms of adaptability as well as popularity both in the media and academia. The information present on social networking sites is used in social, geographic and economic analysis, thereby giving meaningful insights. Although publishing of such analysis may create serious security threats, users sharing personal information on these social platforms may face privacy breach. Various third-party applications are making use of network data for advertisement, academic research and application development which can also raise security and privacy concerns. This chapter has a binary focus towards studying and analysing security and privacy threats prevailing and providing a detailed description regarding solutions that will aid towards sustaining user’s privacy and security. Currently, there exist multiple privacy techniques that propose solutions for maintaining user anonymity on online social networks. The chapter also highlights all the available techniques as well as the issue and challenges surrounding their real-world implementation. The goal of such mechanisms is to push deterged data on social platforms, thereby strengthening user privacy despite of the sensitive information shared on online social networks (OSN). While such mechanisms have gathered researcher’s attention for their simplicity, their ability to preserve the user’s privacy still struggles with regard to preserving useful knowledge contained in it. Thus, anonymization of OSN might lead to certain information loss. This chapter explores multiple data and structural anonymity techniques for modelling, evaluating and managing user’s privacy risks cum concerns with respect to online social networks (OSNs).",http://dx.doi.org/10.1007/978-3-030-22277-2_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-29739-8_13,Key Success Factors for Strategic Management in Digital Business,Digital Business Strategies in Blockchain Ecosystems,10.1007/978-3-030-29739-8_13,Springer,2020-01-01,Technology improves quickly and every object that comes into direct contact with life is being digitized. The developments in the field of information technologies and the need for digital transformation have led to a rapid change in the traditional ways of doing business. Both the biggest threat and opportunity comes from technology. It can bring on fail for the companies that don’t understand the technological developments correctly and adapt to changing environment. It has become an important issue to create a right strategic management model in order to enable firms to evaluate the opportunities and minimise risk during the digital transformation because every enterprise has a different approach to digitalization.,http://dx.doi.org/10.1007/978-3-030-29739-8_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63161-1_20,ElasTest: An Elastic Platform for E2E Testing Complex Distributed Large Software Systems,Advances in Service-Oriented and Cloud Computing,10.1007/978-3-030-63161-1_20,Springer,2020-01-01,"As systems get more complex testing has also increased not only in complexity but in the total IT cost, which is estimated to increase even more by 2020. Testing large complex distributed applications is hard, time consuming and lacks tooling. Given that the digitisation of business has proved to be a key aspect for improving the productivity of developers in the delivery of the service to end-users, in this paper we present early results showing how these capabilities can also be provided to testers of software and services, by adopting standard interfaces and leveraging the tools provided by an early research open-source platform, capable of efficiently testing large scale systems, ElasTest.",http://dx.doi.org/10.1007/978-3-030-63161-1_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5506-3_7,Autonomous Database,Practical Oracle Cloud Infrastructure,10.1007/978-1-4842-5506-3_7,Springer,2020-01-01,"Storing data can be challenging. There are many aspects to consider. In this chapter, we are going to explore one of the flagships of Oracle Cloud, a fully managed Oracle database available as a platform as a service in Oracle Cloud.",http://dx.doi.org/10.1007/978-1-4842-5506-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64642-4_6,The Effect of Big Data Analytics on Firm Decision Making: The Case of the Lebanese Banking Sector,Digital Economy. Emerging Technologies and Business Innovation,10.1007/978-3-030-64642-4_6,Springer,2020-01-01,"The purpose of this paper is to study the perceived impact of big data analytics, a subset of business analytics, on the decision-making process in the banking sector considering that decisions made using big data analytics uncover unseen innovation opportunities and improve compliance within a more stringent regulatory environment. These large complex data sets also known as big data are used by many organizations to enhance their business operations, address business problems as well as generate new opportunities. Big Data Analytics (BDA) analyze Big Data (BD) to uncover relevant information such as customer preferences, hidden patterns, market trends and unknown associations. Data analytics are frequently instilled among the most effective businesses supporting their decision-making process. This paper discusses the impacts of big data analytics on the decision-making process in financial organizations knowing that these analytics can create a constant flow of possible new insights. A qualitative approach has been adopted by conducting in depth interviews with executives in the financial sector to examine how data analytics impact every stage of the decision-making process.",http://dx.doi.org/10.1007/978-3-030-64642-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-38961-1_5,Pimiento: A Vertex-Centric Graph-Processing Framework on a Single Machine,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-38961-1_5,Springer,2020-01-01,"Here, we describe a method for handling large graphs with data sizes exceeding memory capacity using minimal hardware resources. This method (called Pimiento) is a vertex-centric graph-processing framework on a single machine and represents a semi-external graph-computing system, where all vertices are stored in memory, and all edges are stored externally in compressed sparse row data-storage format. Pimiento uses a multi-core CPU, memory, and multi-threaded data preprocessing to optimize disk I/O in order to reduce random-access overhead in the graph-algorithm implementation process. An on-the-fly update-accumulated mechanism was designed to reduce the time that the graph algorithm accesses disks during execution. Our experiments compared external this method with other graph-processing systems, including GraphChi, X-Stream, and FlashGraph, revealing that Pimiento achieved $$7.5\times , 4\times , 1.6\times $$ 7.5 × , 4 × , 1.6 × better performance on large real-world graphs and synthetic graphs in the same experimental environment.",http://dx.doi.org/10.1007/978-3-030-38961-1_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63319-6_14,"Collaborative Filtering Recommendation Systems Algorithms, Strengths and Open Issues",Software Engineering Perspectives in Intelligent Systems,10.1007/978-3-030-63319-6_14,Springer,2020-01-01,"Recommendation systems recommender systems are a subcategory of information filtering that is utilized to determine the preferences of users towards certain items. These systems emerged in the 1990’s and they have since changed the intelligence of both the web and humans. Vast amounts of research papers have been published in various domains. Recommendation systems suggest items to users and their principal purpose is to recommend items that are predicted to be suitable for users. Some of the most popular domains where recommendation systems are used include movies, music, jokes, restaurants, financial services, life insurance, Instagram Facebook and twitter followers. This paper explores different collaborative filtering algorithms. In so doing, the paper looks at the strengths and challenges (open issues) faced by this technique. The open issues give direction of future research work to researchers and also provide information of where to use collaborative filtering recommender systems applications.",http://dx.doi.org/10.1007/978-3-030-63319-6_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58951-6_29,PGC: Decentralized Confidential Payment System with Auditability,Computer Security – ESORICS 2020,10.1007/978-3-030-58951-6_29,Springer,2020-01-01,"Many existing cryptocurrencies fail to provide transaction anonymity and confidentiality. As the privacy concerns grow, a number of works have sought to enhance privacy by leveraging cryptographic tools. Though strong privacy is appealing, it might be abused in some cases. In decentralized payment systems, anonymity poses great challenges to system’s auditability, which is a crucial property for scenarios that require regulatory compliance and dispute arbitration guarantee. Aiming for a middle ground between privacy and auditability, we introduce the notion of decentralized confidential payment (DCP) system with auditability. In addition to offering confidentiality, DCP supports privacy-preserving audit in which an external party can specify a set of transactions and then request the participant to prove their compliance with a large class of policies. We present a generic construction of auditable DCP system from integrated signature and encryption scheme and non-interactive zero-knowledge proof systems. We then instantiate our generic construction by carefully designing the underlying building blocks, yielding a standalone cryptocurrency called PGC. In PGC, the setup is transparent, transactions are less than 1.3 KB and take under 38ms to generate and 15 ms to verify. At the core of PGC is an additively homomorphic public-key encryption scheme that we newly introduce, twisted ElGamal, which is not only as secure as standard exponential ElGamal, but also friendly to Sigma protocols and Bulletproofs. This enables us to easily devise zero-knowledge proofs for basic correctness of transactions as well as various application-dependent policies in a modular fashion.",http://dx.doi.org/10.1007/978-3-030-58951-6_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-49108-6_34,Assistive Technology for the Visually Impaired: Optimizing Frame Rate (Freshness) to Improve the Performance of Real-Time Objects Detection Application,Universal Access in Human-Computer Interaction. Applications and Practice,10.1007/978-3-030-49108-6_34,Springer,2020-01-01,"It has been 100+ years since the world’s first commercial radio station started. This century witnessed several astonishing inventions (e.g. the computer, internet and mobiles) that have shaped the way we work and socialize. With the start of a new decade, it is evident that we are becoming more reliant on these new technologies as the majority of the world population relies on the new technology on a daily basis. As world’s population is becoming reliant on new technologies and we are shaping our lives around it, it is of paramount importance to consider those people who struggle in using the new technologies and inventions. In this paper, we are presenting an algorithm and a framework that helps partially sighted people to locate their essential belongings. The framework integrates state-of-the-art technologies from computer vision, speech recognition and communication queueing theory to create a framework that can be implemented on low computing power platforms. The framework verbally communicates with the users to identify the object they are aiming to find and then notify them when it is within the range.",http://dx.doi.org/10.1007/978-3-030-49108-6_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-019-00733-4,Transient fault aware application partitioning computational offloading algorithm in microservices based mobile cloudlet networks,Computing,10.1007/s00607-019-00733-4,Springer,2020-01-01,"Mobile Cloudlet Computing paradigm (MCC) allows execution of resource-intensive mobile applications using computation cloud resources by exploiting computational offloading method for resource-constrained mobile devices. Whereas, computational offloading needs the mobile application to be partitioned during the execution in the MCC so that total execution cost is minimized. In the MCC, at the run-time network contexts (i.e., network bandwidth, signal strength, latency, etc.) are intermittently changed, and transient failures (due to temporary network connection failure, services busy, database disk out of storage) often occur for a short period of time. Therefore, transient failure aware partitioning of the mobile application at run-time is a challenging task. Since, existing MCC offers computational monolithic services by exploiting heavyweight virtual machines, which incurs with long VM startup time and high overhead, and these cannot meet the requirements of fine-grained microservices applications (e.g., E-healthcare, E-business, 3D-Game, and Augmented Reality). To cope up with prior issues, we propose microservices based mobile cloud platform by exploiting containerization which replaces heavyweight virtual machines, and we propose the application partitioning task assignment (APTA) algorithm which determines application partitioning at run-time and adopts the fault aware (FA) policy to execute microservices applications robustly without interruption in the MCC. Simulation results validate that the proposed microservices mobile cloud platform not only shrinks the setup time of run-time platform but also reduce the energy consumption of nodes and improve the application response time by exploiting APTA and FA to the existing VM based MCC and application partitioning strategies.",http://dx.doi.org/10.1007/s00607-019-00733-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-57997-5_53,Dynamic Distributed Job-Shop Scheduling Problem Consisting of Reconfigurable Machine Tools,Advances in Production Management Systems. Towards Smart and Digital Manufacturing,10.1007/978-3-030-57997-5_53,Springer,2020-01-01,"Keeping pace with rapidly changing customer requirements forces companies to increase the capability of adaptation of their production systems. To fulfill the market requirements in a reasonable time and cost, distributed manufacturing has been emerged as one of the efficient approaches. Moreover, the ability of reconfigurability makes manufacturing systems and tools to be more adaptable. This research deals with a dynamic production scheduling problem simultaneously in several different shop-floors consisting of reconfigurable machine tools (RMTs) by utilizing the real-time data extracted from a cyber-physical system (CPS). First, a mathematical programming model is presented for the static state. Thereafter, by utilizing the CPS capabilities, a dynamic model is extended to schedule new jobs, in which there have already been some other jobs in each facility. A numerical example is solved to illustrate the validation of the model. Finally, some potential solving approaches are proposed to make the model implementable in real-world applications.",http://dx.doi.org/10.1007/978-3-030-57997-5_53,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_17-1,Mobile Applications for e-Tourism,Handbook of e-Tourism,10.1007/978-3-030-05324-6_17-1,Springer,2020-01-01,"More and more people are using smartphones and other mobile devices as their main means for information access. This is especially true for travelers, and mobile applications supporting them have become very popular in the last years. This chapter first introduces basic concepts and technologies that are important for mobile applications for e-Tourism. After a brief historical overview, we then discuss issues regarding the development of mobile applications, such as determining the context of users with sensors. We also explain basic principles of user modeling and personalization and mobile user interfaces. The second main part of the chapter classifies and outlines existing mobile applications for travel and tourism. We introduce a taxonomy that reflects a traveler’s journey from vacation planning until concluding the trip. This includes applications that assist users in finding destinations; searching for and booking hotels, events, and activities; and identifying other travel-related items. A more specific scenario is the search for POI! s ( POI! s) that a user can visit during a trip. Modern e-Tourism applications allow browsing and filtering relevant POI! s and can combine them to interesting and practical itineraries. In addition, we present applications for social networking, entertainment in e-Tourism, and others that are frequently used by tourists.",http://dx.doi.org/10.1007/978-3-030-05324-6_17-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-43589-9_4,Knowledge and Digital Strategies in Manufacturing Firms: The Experience of Top Performers,Knowledge Management and Industry 4.0,10.1007/978-3-030-43589-9_4,Springer,2020-01-01,"In the past few decades, ICT supported firms managing knowledge through both codification and social interaction, also at distance. Within the Industry 4.0 framework, firms can access knowledge through the cloud and rely on big data and AI to improve their processes and enhance their market comprehension. However, it is not fully explored how knowledge management should be organized in the fourth industrial revolution, since a lot of emphasis has been given to automatization in data management, while the relational dimension of knowledge management has received limited attention. Through an empirical analysis based on mixed method of a survey on 75 top performing Italian manufacturing firms and follow-up on 5 case studies, the chapter explores these questions to identify the implications of Industry 4.0 for firms’ strategy.",http://dx.doi.org/10.1007/978-3-030-43589-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-25432-2_3,Fuzzy Optimization and Reasoning Approaches,Integrating Soft Computing into Strategic Prospective Methods,10.1007/978-3-030-25432-2_3,Springer,2020-01-01,"Long-term strategic reflection is a process that faces several challenges. Among them the uncertainty, which may be due to a multitude of reasons. The literature covers a wide range of contributions with methods and models focused on dealing with uncertainty in terms of optimization of complex systems and little on dealing with conjecture processes to build knowledge about the future. The Future Studies and Soft Computing fields offer a meeting place for the notions of experience, meta-knowledge, macro-effects and non-arbitrariness. This chapter develops a proposed link between the two fields to help decision makers change their ways of thinking, make new decisions about the choices they have to make and learn to plant new seeds of the future.",http://dx.doi.org/10.1007/978-3-030-25432-2_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58520-4_37,Exchangeable Deep Neural Networks for Set-to-Set Matching and Learning,Computer Vision – ECCV 2020,10.1007/978-3-030-58520-4_37,Springer,2020-01-01,"Matching two different sets of items, called heterogeneous set-to-set matching problem, has recently received attention as a promising problem. The difficulties are to extract features to match a correct pair of different sets and also preserve two types of exchangeability required for set-to-set matching: the pair of sets, as well as the items in each set, should be exchangeable. In this study, we propose a novel deep learning architecture to address the abovementioned difficulties and also an efficient training framework for set-to-set matching. We evaluate the methods through experiments based on two industrial applications: fashion set recommendation and group re-identification. In these experiments, we show that the proposed method provides significant improvements and results compared with the state-of-the-art methods, thereby validating our architecture for the heterogeneous set matching problem.",http://dx.doi.org/10.1007/978-3-030-58520-4_37,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1420-3_138,"A Survey on the Internet of Things: Applications, Challenges and Opportunities with India Perspective",ICDSMLA 2019,10.1007/978-981-15-1420-3_138,Springer,2020-01-01,"Extensive research efforts are going on to contribute to the Internet of Things (IoT) application development. IoT will create network of “Things” capable of communicating and sharing information with one another. The main goal of IoT is to make the physical environment more intelligent. IoT plays an important role in smart cities and smart homes. The goals of this research paper are six-fold: (i) serve as a guideline for researchers who are new to the Internet of Things (IoT) and want to contribute to this research area, (ii) analyze problems and challenges identified in the implementation of middleware for IoT, (iii) provides a brief overview of the sensor network in Internet of Things (IoT) for building smart cities, (iv) depicts challenges on technologies and applications from India’s perspective, (v) proposes a general IoT architecture to meet the architecture challenge, and (vi) provides further research directions required into the Internet of Things (IoT) middleware and software architectures.",http://dx.doi.org/10.1007/978-981-15-1420-3_138,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-9574-1_4,Intrusion Detection System in Internet of Things,Design Frameworks for Wireless Networks,10.1007/978-981-13-9574-1_4,Springer,2020-01-01,"The Internet of Things (IoT) is a fast-expanding network of smart heterogeneous objects. It refers to the physical devices that are capable of communicating with other physical devices. Unlike the wireless sensor networks (WSNs), IoT is connected to worldwide Internet that exposes it to global intrusion in addition to wireless attacks inside an IoT network. It is protected by cryptographic and network security techniques, but they are vulnerable to internal and external attacks. The IoT devices are resource constrained in terms of limited storage, battery, limited transmission range and processing. To protect these tiny devices from the inside and outside cyberattacks, we need a lightweight security system that can run efficiently and effectively on these IoT devices. We also need a system, which can identify the type of intrusion and trigger an alarm in intrusion scenario to take appropriate preventive measure. Hence, an Intrusion Detection System (IDS) plays an important role to prevent such cyberattacks in IoT. These devices can be static or mobile in an IoT environment; this must be considered while designing IDS for IoT system. This book chapter presents various IDSs for an IoT system and their comparisons in terms of detection rate, false positive and accuracy in both static and mobility of devices.",http://dx.doi.org/10.1007/978-981-13-9574-1_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-47358-7_13,Sensitivity to Risk Profiles of Users When Developing AI Systems,Advances in Artificial Intelligence,10.1007/978-3-030-47358-7_13,Springer,2020-01-01,"The AI community today has renewed concern about the social implications of the models they design, imagining the impact of deployed systems. One thrust has been to reflect on issues of fairness and explainability before the design process begins. There is increasing awareness as well of the need to engender trust from users, examining the origins of mistrust as well as the value of multiagent trust modelling solutions. In this paper, we argue that social AI efforts to date often imagine a homogenous user base and those models which do support differing solutions for users with different profiles have not yet examined one important consideration upon which trusted AI may depend: the risk profile of the user. We suggest how user risk attitudes can be integrated into approaches that try to reason about such dilemmas as sacrificing optimality for the sake of explainability. In the end, we reveal that it is challenging to be satisfying the myriad needs of users in their desire to be more comfortable accepting AI solutions and conclude that tradeoffs need to be examined and balanced. We advocate reasoning about these tradeoffs concerning user models and risk profiles, as we design the decision making algorithms of our systems.",http://dx.doi.org/10.1007/978-3-030-47358-7_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-29844-9_4,New Approaches to Cyber Defense,Cyberspace Mimic Defense,10.1007/978-3-030-29844-9_4,Springer,2020-01-01,"As noted in Chap. 3 , conventional cyberspace defense technologies focus on bolstering the target system externally and trying to test, discover, and eliminate known threats. In spite of the substantial and fruitful researches in the field of vulnerability detection and backdoor testing, we are still far from the ideal goal of rooting out vulnerabilities and backdoors. Both the academia and the industry have realized that the conventional static or coordinated approaches of defense are not well adept at handling Advanced Persistent Threat (APT). In response, many advanced countries have launched research programs based on new defense approaches (such as moving target defense, or MTD) [1] in an attempt to change the rules of the game. The nature of cyberspace is such that it is easy to attack but difficult to defend. By increasing the dynamism, randomness, and redundancy of the system or network against external attacks, the new defensive technologies render attackers unable to effectively sustain the cognitive advantage over the target system and the available resources over time and space, making it difficult to accumulate information, duplicate the mode of attack, recreate the effect, or continue the method of attack, which significantly increases the cost of the attack and hopefully would change the rules of the game.",http://dx.doi.org/10.1007/978-3-030-29844-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-58666-9_5,Socially-Aware Business Process Redesign,Business Process Management,10.1007/978-3-030-58666-9_5,Springer,2020-01-01,"Existing techniques for the redesign of business processes are mostly concerned with optimizing efficiency and productivity, but do not take social considerations into account. In this paper, we represent social business process redesign (SBPR) as a constrained optimization problem (COP). Assuming a workforce of human and computer resources, SBPR considers two types of decisions: (1) how to allocate tasks among this workforce and (2) which skills it should acquire. The latter decision can be used to control for the amount of automation (by setting an upper bound), which may ensure, for example, that disadvantaged workers are included. We discuss scenarios inspired by real-world considerations where the COP representation of SBPR can be used as a decision support tool. Furthermore, we present an extensive computational analysis that demonstrates the applicability of our COP-based solution to large SBPR instances, as well as a detailed analysis of the factors that influence the performance of the approach. Our work shows that it is feasible to incorporate multiple considerations into redesign decision making, while providing meaningful insights into the trade-offs involved.",http://dx.doi.org/10.1007/978-3-030-58666-9_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-05324-6_86-1,Information and Communication Technology in Event Management,Handbook of e-Tourism,10.1007/978-3-030-05324-6_86-1,Springer,2020-01-01,"This chapter provides a comprehensive overview of information and communication technologies (ICTs) used by event organizers and attendees. The ways that ICTs are integrated into event administration, design, operations, marketing, and risk management, both back-stage and in plain sight, are considered from an applied perspective and through the lenses of theories applied in the literature. Currently, events and festivals use diverse ICTs to enhance utilitarian aspects, such as ticket purchasing, safety procedures, wayfinding and scheduling, as well as hedonic visitor experiences, like virtual and enhanced reality, gamification, and innovative programming using social media. How ICTs influence attendees’ experiences is discussed in-depth by exploring the contribution of ICTs to “communitas,” “liminality,” sense of place, mindfulness, memorableness, and co-creation. Throughout the chapter, both emerging and established ICTs are described, and real-world examples from festivals are provided to gain insights into the opportunities and drawbacks of ICTs in the event and festival domain. The chapter focuses on ICTs used during the festival experience. However, the importance of the pre- and post-event and festival experience is acknowledged as well.",http://dx.doi.org/10.1007/978-3-030-05324-6_86-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-50523-3_9,Fluid Interface Concept for Automated Driving,"HCI in Mobility, Transport, and Automotive Systems. Automated Driving and In-Vehicle Experience Design",10.1007/978-3-030-50523-3_9,Springer,2020-01-01,"The biggest challenge for a human-machine interface in highly automated vehicles is to provide enough information to the potentially unaware human operator to induce an appropriate response avoiding cognitive overload. Current interface design struggles to provide timely and relevant information tailored for future driver’s needs. Therefore, a new human-centered approach is required to connect drivers, vehicles and infrastructures and account for non-driving related activities in the forthcoming automated vehicles. A viable solution derives from a holistic approach that merges technological tools with human factors knowledge, to enable the understanding and resolution of potential usability, trust and acceptance issues. In this paper, the human factors challenges introduced by automated driving provide the starting point for the conceptualization of a new Fluid interface. The requirements for the new concept are derived from a systematic analysis of the necessary interactions among driver, vehicle and environment. Therefore, the characteristics, components and functions of the interface are described at a theoretical level and compared to alternative solutions.",http://dx.doi.org/10.1007/978-3-030-50523-3_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-62974-8_18,"BlockVoke – Fast, Blockchain-Based Certificate Revocation for PKIs and the Web of Trust",Information Security,10.1007/978-3-030-62974-8_18,Springer,2020-01-01,"A reliable certificate revocation mechanism is crucial, as illustrated by the recent revocation of 1.7 million certificates issued by the Let’s Encrypt certificate authority. It is just as essential to get revocation information to users in an efficient and timely manner without impacting their privacy. Existing approaches such as Certificate Revocation Lists (CRLs) or the Online Certificate Status Protocol (OCSP) fail with respect to either of those metrics, while approaches that try to mitigate both, such as OCSP-Staple and Must-Staple suffer from soft-failure modes and meager adoption rates. To address these issues, we propose the BlockVoke scheme, which decentralizes revocations, allowing certificate owners as well as CAs to revoke certificates, and distribute revocation information rapidly. Our approach furthermore allows the revocation of CA root certificates, which is not possible with traditional approaches. The use of a blockchain as an underlying layer ensures the continued availability and immutability of revocation information. BlockVoke interacts favorably with approaches such as CRLite and Certificate Revocation Vectors (CRV), allowing organizations to update revocation filters with as little delay as required by their security policies. We also demonstrate the cost-efficiency of our approach in comparison to other approaches such as CRLs, showing its high feasibility.",http://dx.doi.org/10.1007/978-3-030-62974-8_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-35649-1_9,Infocommunication Tasks of University Information System,Data-Centric Business and Applications,10.1007/978-3-030-35649-1_9,Springer,2020-01-01,"Active usage of information technologies in every field of human activity nowadays is not a matter of choice. So any higher education institution as well as any other organization is forced to use information systems in order to be in the flow. So, it should be noted that real pace of changes in global education sector (especially its private part) is much quicker than stereotypes. Thus, higher education institutions eagerly try to meet these changes, though in most cases higher education institutions’ infrastructure and information systems fail to do that. Consequently, there is a pressing scientific task of redefining infocommunication needs of higher education institutions through their information flows in order to identify actual modern requirements to the higher education institutions’ information systems and infocommunication infrastructure. Those specific needs and requirements are identified on the basis of analysis of cutting-edge information technologies and trends that are used or expected to be used in education. As the result specific recommendations on infocommunication flows and university information systems integration are proposed.",http://dx.doi.org/10.1007/978-3-030-35649-1_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-33509-0_61,Reinforcement Learning for Resource Allocation in Cloud Datacenter,"Advances on P2P, Parallel, Grid, Cloud and Internet Computing",10.1007/978-3-030-33509-0_61,Springer,2020-01-01,"Cloud technologies provide capabilities that can guarantee to the end user high availability, performance and scalability. However, the growing use of IoT technologies and devices, have made the applications not only more computationally intensive, but also data intensive. Because of this, dynamically scaling applications running on clouds can lead to varied and unpredictable results due to highly time-varying workloads distinguishes this new kind of applications. These applications are also often composed of different independent modules that could be easily moved across devices. Automatic scheduling and allocation of these modules is not an easy task, because there could be many conditions that prevent the design of a smart solutions. Thus determining appropriate scaling policies in a dynamic non-stationary environment is non-trivial, as a problem arises concerning resource allocation. Decision making about which resources should be added and removed, when the underlying performance of the resource is in a constant state of flux, becomes an issues. In this work we model both the applications and the infrastructure in order to formulate e Reinforcement Learning problem for automatically find the best configuration for the applications modules, taking into account the environment in which they are placed and the applications already running.",http://dx.doi.org/10.1007/978-3-030-33509-0_61,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44081-7_17,Untangling Header Bidding Lore,Passive and Active Measurement,10.1007/978-3-030-44081-7_17,Springer,2020-01-01,"Header bidding (HB) is a relatively new online advertising technology that allows a content publisher to conduct a client-side (i.e., from within the end-user’s browser), real-time auction for selling ad slots on a web page. We developed a new browser extension for Chrome and Firefox to observe this in-browser auction process from the user’s perspective. We use real end-user measurements from 393,400 HB auctions to (a) quantify the ad revenue from HB auctions, (b) estimate latency overheads when integrating with ad exchanges and discuss their implications for ad revenue, and (c) break down the time spent in soliciting bids from ad exchanges into various factors and highlight areas for improvement. For the users in our study, we find that HB increases ad revenue for web sites by $$28\%$$ compared to that in real-time bidding as reported in a prior work. We also find that the latency overheads in HB can be easily reduced or eliminated and outline a few solutions, and pitch the HB platform as an opportunity for privacy-preserving advertising.",http://dx.doi.org/10.1007/978-3-030-44081-7_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-15347-6_466,Start-Up and Small Business Life,"Encyclopedia of Creativity, Invention, Innovation and Entrepreneurship",10.1007/978-3-319-15347-6_466,Springer,2020-01-01,,http://dx.doi.org/10.1007/978-3-319-15347-6_466,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-64846-6_9,A Qualitative Literature Review on Microservices Identification Approaches,Service-Oriented Computing,10.1007/978-3-030-64846-6_9,Springer,2020-01-01,"Microservices has become a widely used and discussed architectural style for designing modern applications due to advantages like granular scalability and maintainability. However, it is still a complex task decomposing an application into microservices. Software architects often design architectures manually. In this paper we give a state-of-the-art overview of current approaches to identifying microservices. Therefore we use a literature review and classify the content based on the software development process. The main results are that mostly monolithic artifacts are used for starting with microservice decomposition. Data-intensive applications are less focused. Rule-based and clustering algorithms are suitable ways to find microservice candidates. Both researchers and software architects profit from this overview. Practically it supports choosing suitable approaches considering aspects like cohesion, coupling, workload, deployment and further quality criteria for each phase during the software development process.",http://dx.doi.org/10.1007/978-3-030-64846-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-0978-0_1,Capturing Anomalies of Cassandra Performance with Increase in Data Volume: A NoSQL Analytical Approach,Advances in Data Science and Management,10.1007/978-981-15-0978-0_1,Springer,2020-01-01,"NoSQL database technology has been doing rounds since the early 1990s, but it was the exponential growth of internet and the rise of web applications that lead to a dynamic surge in the popularity of NoSQL databases. The BigTable research by Google (2006) and the Dynamo research by Amazon (2007) paved the way for databases which could develop with agility and operate at any scale. Cassandra and MongoDB have emerged as the two most widely used NoSQL database and hence either of the two is preferred depending on the data problem user is attempting to solve. This paper describes the underlying principles as well as the differences between both the databases. We focus on showing the anomaly in performance of Cassandra as the data volume increases and at the same time we compare its performance with that of MongoDB. We establish how important factor is data volume in choosing either of the databases for an application. Extensive experiments have been carried out to scale the performance in terms of anomaly similarities, and the future scope is pinpointed.",http://dx.doi.org/10.1007/978-981-15-0978-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-41309-5_11,Ubiquitous Computing: From 5G to the Edge and Beyond,Innovative Technologies for Market Leadership,10.1007/978-3-030-41309-5_11,Springer,2020-01-01,"This is an invitation to a journey from our communication technology’s past to the technological borders of today and beyond to the unknown. We will jump back in time for about three generations to become aware of the major steps of progress we have achieved in the past 50 years. From there we will move forward in three main paths, covering the invention of the (inter-networking) network, the development of hard- and software, and the advance of mobile communications. We will have a look at how these three streams of development eventually merged into one and how it led us to the technological reality of today. If you have been part of this story yourself, or if you already know all about it, you may want to read it anyway with a smile of remembrance. If you do not want to repeat this part, please feel free to jump ahead a couple of pages to Sect. 4 .",http://dx.doi.org/10.1007/978-3-030-41309-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59065-9_8,A SAT-Based Approach for Mining High Utility Itemsets from Transaction Databases,Big Data Analytics and Knowledge Discovery,10.1007/978-3-030-59065-9_8,Springer,2020-01-01,"Mining high utility itemsets is a keystone in several data analysis tasks. High Utility Itemset Mining generalizes the frequent itemset mining problem by considering item quantities and weights. A high utility itemset is a set of items that appears in the transadatabase and having a high importance to the user, measured by a utility function. The utility of a pattern can be quantified in terms of various objective criteria, e.g., profit, frequency, and weight. Constraint Programming (CP) and Propositional Satisfiability (SAT) based frameworks for modeling and solving pattern mining tasks have gained a considerable attention in recent few years. This paper introduces the first declarative framework for mining high utility itemsets from transaction databases. First, we model the problem of mining high utility itemsets from transaction databases as a propositional satifiability problem. Moreover, to facilitate the mining task, we add an additional constraint to the efficiency of our method by using weighted clique cover problem. Then, we exploit the efficient SAT solving techniques to output all the high utility itemsets in the data that satisfy a user-specified minimum support and minimum utility values. Experimental evaluations on real and synthetic datasets show that the performance of our proposed approach is close to that of the optimal case of state-of-the-art HUIM algorithms.",http://dx.doi.org/10.1007/978-3-030-59065-9_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40537-019-0268-2,Internet of Things is a revolutionary approach for future technology enhancement: a review,Journal of Big Data,10.1186/s40537-019-0268-2,Springer,2019-12-09,"Internet of Things (IoT) is a new paradigm that has changed the traditional way of living into a high tech life style. Smart city, smart homes, pollution control, energy saving, smart transportation, smart industries are such transformations due to IoT. A lot of crucial research studies and investigations have been done in order to enhance the technology through IoT. However, there are still a lot of challenges and issues that need to be addressed to achieve the full potential of IoT. These challenges and issues must be considered from various aspects of IoT such as applications, challenges, enabling technologies, social and environmental impacts etc. The main goal of this review article is to provide a detailed discussion from both technological and social perspective. The article discusses different challenges and key issues of IoT, architecture and important application domains. Also, the article bring into light the existing literature and illustrated their contribution in different aspects of IoT. Moreover, the importance of big data and its analysis with respect to IoT has been discussed. This article would help the readers and researcher to understand the IoT and its applicability to the real world.",http://dx.doi.org/10.1186/s40537-019-0268-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-019-01387-4,Efficient Machine Learning Model for Movie Recommender Systems Using Multi-Cloud Environment,Mobile Networks and Applications,10.1007/s11036-019-01387-4,Springer,2019-12-01,"A recommender system or a recommendation system is a subclass of information filtering system which in turn predicts the “preference” or “ratings” which a user would provide to the specified item. Recommender systems are utilized in a variety of areas comprising news, music, movies, books, search queries, social tags, research articles, and products in general. The primary aim of the recommender system is to allow the computers learn automatically without any human intervention or assistance and regulate activities consequently. The existing methods had a lower amount of search result quality and a minimum rate of ranking accuracy. To overcome this issue and to enhance the ranking quality and search result quality a novel recommender system in the multi-cloud with the use of proposed machine learning algorithm. In this proposed work (NPCA-HAC), the social data set are pre-processed to remove the noise and making them pure. Then, the method of feature selection is carried out with the use of principle component analysis method (PCA). The selected features are then clustered with the use of k-means followed by the Hierarchical Agglomerative Clustering algorithm (HAC). These clusters are then ranked by the use of trust ranking algorithm. Finally, the ranked output was evaluated and the performance measure was analyzed which provides the efficient results from the recommender system.",http://dx.doi.org/10.1007/s11036-019-01387-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13162-019-00146-8,THE DATA HIERARCHY: factors influencing the adoption and implementation of data-driven decision making,AMS Review,10.1007/s13162-019-00146-8,Springer,2019-12-01,"Marketing practitioners have access to a rapidly increasing quantity and variety of data from customers and other stakeholders. Managers use the term “Big Data” to describe this avalanche of information, which many view as critical to providing a better understanding of customers and markets. This research uses interviews with managers to examine the marketing function’s perspective on data-driven decision making within the firm. Based on informant responses, we develop a hierarchy of data-oriented decision making, describe the drivers that influence where a firm falls within this hierarchy, and detail several transition capabilities for marketing managers interested in becoming more data-driven. The key factors that influence the level of data driven decision making are: 1) firm environment; 2), competition, 3) executive commitment, 4) interdepartmental dynamics, and 5) organizational structure. This framework guides marketing managers both in evaluating the firm’s data capabilities and facilitating change.",http://dx.doi.org/10.1007/s13162-019-00146-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11235-019-00597-1,Greening internet of things for greener and smarter cities: a survey and future prospects,Telecommunication Systems,10.1007/s11235-019-00597-1,Springer,2019-12-01,"Tremendous technological developments in the field of internet of things (IoT) have changed the way we live and work. Although the numerous advantages of IoT are enriching our society, it should be reminded that the IoT also contributes to toxic pollution, consumes energy and generates e-waste. These persistent issues place new stress on the smart world and environments. To enhance the benefits and reduce the harmful effects of IoT, there is an increasingly desired to move towards green IoT. Green IoT is seen as the environmentally friendly future of IoT. Therefore, it is necessary to put different desired measures to conserve environmental resources, reduce carbon footprints and promote efficient techniques for energy usage. It is the reason for moving towards green IoT, where the machines, sensors, communications, clouds, and internet operate in synergy towards the common goal of increased energy efficiency and reduced carbon emissions. This work presents a thorough survey of the current ongoing research and potential technologies of green IoT with an intention to provide some directions for future green IoT research.",http://dx.doi.org/10.1007/s11235-019-00597-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-018-1416-9,Industrial wearable system: the human-centric empowering technology in Industry 4.0,Journal of Intelligent Manufacturing,10.1007/s10845-018-1416-9,Springer,2019-12-01,"The Industry 4.0 program and corresponding international initiatives continue to transform the industrial workforce and their work. The service-oriented, customer-centric and demand-driven production is pushing forward the progress of industrial automation. Even though, it does not mean that human can be fully replaced by machines/robots. There is an increasing awareness that human presence is not only one type of manufacturing capability, but also contributes to the overall system’s fault tolerant. How to achieve the seamless integration between human and machines/robots and harness human’s full potential is a critical issue for the success of Industry 4.0. In this research, a human-centric empowering technology: industrial wearable system is proposed. The aim of this system is to establish a human–cyber–physical symbiosis to support real time, trusting, and dynamic interaction among operators, machines and production systems. In order to design a substantial framework, three world-leading R&D groups in this field are investigated. Five design considerations have been identified from real-life pilot projects. The future trends and research opportunities also show great promise of industrial wearable system in the next generation of manufacturing.",http://dx.doi.org/10.1007/s10845-018-1416-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-019-01340-7,In-memory transaction processing: efficiency and scalability considerations,Knowledge and Information Systems,10.1007/s10115-019-01340-7,Springer,2019-12-01,"Traditional disk-resident OLTP systems were mainly designed for computers with relatively small memory. Driven by the advance of hardware, OLTP systems need to be redesigned for larger memory and multi-core environments. Compared to disk-resident systems, in-memory systems have significant performance advantages, from the perspectives of both transaction throughput and query latency. Their performance is no longer limited by disk I/Os. Instead, the efficiency and scalability over multi-core CPUs become more important. In this paper, we survey and summarize a wide spectrum of design and implementation considerations that may affect the efficiency or scalability of an in-memory OLTP system. These considerations are concerned with most of the main components of databases, including concurrency control, logging, indexing and transaction compilation. For each of the components, we provide some in-depth analysis based on recent research works. This survey also aims to provide some guidance for designing or implementing high-performance in-memory OLTP systems.",http://dx.doi.org/10.1007/s10115-019-01340-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-019-01331-8,An expected win rate-based real-time bidding strategy for branding campaigns on display advertising,Knowledge and Information Systems,10.1007/s10115-019-01331-8,Springer,2019-12-01,"For branding campaigns, the demand-side platforms (DSPs) in real-time bidding (RTB) usually need to win as many impressions as possible to inform most audiences about the product messages under constraints on budgets, campaign lifetimes and budget spending plans. In this paper, we propose a novel bidding strategy by introducing the concept of expected win rate. With the proposed expected win rate-based bidding strategy, the DSP can dynamically adjust the expected win rate for each incoming bid request based on factors such as the predicted number of bid requests in the near future, the remaining budget and the remaining lifetime of the campaign. The experimental results show that the proposed bidding strategy has a lower cost per thousand impressions and cost per clicks than existing pacing model-based bidding strategies for branding campaigns with the same budgets and budget spending plans.",http://dx.doi.org/10.1007/s10115-019-01331-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-019-00362-x,Designing a multi-sided data platform: findings from the International Data Spaces case,Electronic Markets,10.1007/s12525-019-00362-x,Springer,2019-12-01,"The paper presents the findings from a 3-year single-case study conducted in connection with the International Data Spaces (IDS) initiative. The IDS represents a multi-sided platform (MSP) for secure and trusted data exchange, which is governed by an institutionalized alliance of different stakeholder organizations. The paper delivers insights gained during the early stages of the platform’s lifecycle (i.e. the platform design process). More specifically, it provides answers to three research questions, namely how alliance-driven MSPs come into existence and evolve, how different stakeholder groups use certain governance mechanisms during the platform design process, and how this process is influenced by regulatory instruments. By contrasting the case of an alliance-driven MSP with the more common approach of the keystone-driven MSP, the results of the case study suggest that different evolutionary paths can be pursued during the early stages of an MSP’s lifecycle. Furthermore, the IDS initiative considers trust and data sovereignty more relevant regulatory instruments compared to pricing, for example. Finally, the study advances the body of scientific knowledge with regard to data being a boundary resource on MSPs.",http://dx.doi.org/10.1007/s12525-019-00362-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-018-1118-3,"Evaluation and monitoring of XSS defensive solutions: a survey, open research issues and future directions",Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-018-1118-3,Springer,2019-11-01,"XSS is well-thought-out to be an industry-wide problem that is affecting the diverse contemporary web platforms. The collection of most recent web application reports revealed that XSS reserved the topmost position among all other cyber-attacks. This survey article wishes to present the improvements related to XSS worm defensive methodologies. We have enlarged our discussion to different classes of XSS attacks, i.e., non-persistent, persistent, DOM-Based and mutation-based XSS attacks that has recently stated in the state-of-art. This complete survey offers full vision into the classification, avoidance, recognition and alleviation mechanisms of such attacks. In addition, broad solution classification has been designed for the classification of approaches used by numerous contributions. This article discusses the impact of real world XSS worms and the associated recent real world incidents of such worms. Existing client-side, server-side, proxy-enabled and certain other XSS defensive techniques was presented with an aim to recognize their key contributions and the current performance concerns. In the end, we present certain future research guidelines, a complete mechanism and the associated requirements towards the designing of an effective and robust XSS defensive methodology.",http://dx.doi.org/10.1007/s12652-018-1118-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-018-1302-y,Joint prediction of time series data in inventory management,Knowledge and Information Systems,10.1007/s10115-018-1302-y,Springer,2019-11-01,"The problem of time series prediction has been well explored in the community of data mining. However, little research attention has been paid to the case of predicting the movement of a collection of related time series data. In this work, we study the problem of simultaneously predicting multiple time series data using joint predictive models. We observe that in real-world applications, strong relationships between different time-sensitive variables are often held, either explicitly predefined or implicitly covered in nature of the application. Such relationships indicate that the prediction on the trajectory of one given time series could be improved by incorporating the properties of other related time series data into predictive models. The key challenge is to capture the temporal dynamics of these relationships to jointly predict multiple time series. In this research, we propose a predictive model for multiple time series forecasting and apply it to the domain of inventory management. The relationships among multiple time series are modeled as a class of constraints, and in turn, refine the predictions on the corresponding time series. Experimental results on real-world data reveal that the proposed algorithms outperform well-established methods of time series forecasting.",http://dx.doi.org/10.1007/s10115-018-1302-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-019-00680-2,Two-level task scheduling with multi-objectives in geo-distributed and large-scale SaaS cloud,World Wide Web,10.1007/s11280-019-00680-2,Springer,2019-11-01,"With the exploding of data-intensive web applications and requests (tasks), geo-distributed and large-scale data centers (DCs) are widely deployed in Software as a Service (SaaS) cloud, but server failures continue to grow at the same time. In this context, task scheduling problems become more intricate and both scheduling quality and scheduling speed raise further concerns. In this paper, we first propose a virtualized & monitoring SaaS model with predictive maintenance to minimize the costs of fault tolerance. Then with the monitored and predicted available states of servers, we focus on dynamic real-time task scheduling in geo-distributed and large-scale DCs with heterogeneous servers. Multiple objectives, including the long-term performance benefits, energy and communication costs, are taken into consideration in order to improve scheduling quality. For inter-DC and intra-DC task scheduling, two dynamic programming problems are formulated respectively, but there exists the problem that both state and action spaces are too large to be solved by simple iterations. To address this issue, we introduce the idea of reinforcement learning theory into solving traditional stochastic dynamic programming problems in the large-scale SaaS cloud, and put forward a cascaded two-level (inter-DC and intra-DC level) approximate dynamic programming (ADP) task-scheduling algorithm. The computation complexity can be significantly reduced and scheduling speed can be greatly improved. Finally, we conduct experiments with both random simulation data and Google cloud trace-logs. QoS evaluations and comparisons demonstrate that two ADP algorithms can work cooperatively, and our two-level ADP algorithm is more effective under large quantity of bursty requests.",http://dx.doi.org/10.1007/s11280-019-00680-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-018-3550-x,Of daemons and men: reducing false positive rate in intrusion detection systems with file system footprint analysis,Neural Computing and Applications,10.1007/s00521-018-3550-x,Springer,2019-11-01,"In this work, we propose a methodology for reducing false alarms in file system intrusion detection systems, by taking into account the daemon’s file system footprint. More specifically, we experimentally show that sequences of outliers can serve as a distinguishing characteristic between true and false positives, and we show how analysing sequences of outliers can lead to lower false positive rates, while maintaining high detection rates. Based on this analysis, we developed an anomaly detection filter that learns outlier sequences using k -nearest neighbours with normalised longest common subsequence. Outlier sequences are then used as a filter to reduce false positives on the $$FI^2DS$$ F I 2 D S file system intrusion detection system. This filter is evaluated on both overlapping and non-overlapping sequences of outliers. In both cases, experiments performed on three real-world web servers and a honeynet show that our approach achieves significant false positive reduction rates (up to 50 times), without any degradation of the corresponding true positive detection rates.",http://dx.doi.org/10.1007/s00521-018-3550-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-018-2387-5,"Analysis of Blockchain technology: pros, cons and SWOT",Cluster Computing,10.1007/s10586-018-2387-5,Springer,2019-11-01,"Any online transaction that involves digital money is a bit of a challenge these days with the rising threats of hackers trying to steal bank details posted online. This leads to the invention of various kinds of crypto-currency, Bitcoin being one of them. The technology behind using the Bitcoin is popularly called as Blockchain. Blockchain is a digitized, de-centralized, public ledger of all crypto-currency transaction/s. Blockchain tries to create and share all the online transactions, stored in a distributed ledger, as a data structure on a network of computers. It validates the transactions using peer-to-peer network of computers. It allows users to make and verify transactions immediately without a central authority. Blockchain is a transaction database which contains information about all the transactions ever executed in the past and works on Bitcoin protocol. In this analysis paper we discussed what is Blockchain?, SWOT analysis of BC, Types of BC and how Blockchain works along with its advantages and disadvantages.",http://dx.doi.org/10.1007/s10586-018-2387-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40537-019-0258-4,"Context-aware rule learning from smartphone data: survey, challenges and future directions",Journal of Big Data,10.1186/s40537-019-0258-4,Springer,2019-10-31,"Smartphones are considered as one of the most essential and highly personal devices of individuals in our current world. Due to the popularity of context-aware technology and recent developments in smartphones, these devices can collect and process raw contextual data about users’ surrounding environment and their corresponding behavioral activities with their phones. Thus, smartphone data analytics and building data-driven context-aware systems have gained wide attention from both academia and industry in recent days. In order to build intelligent context-aware applications on smartphones, effectively learning a set of context-aware rules from smartphone data is the key. This requires advanced data analytical techniques with high precision and intelligent decision making strategies based on contexts. In comparison to traditional approaches, machine learning based techniques provide more effective and efficient results for smartphone data analytics and corresponding context-aware rule learning. Thus, this article first makes a survey on previous work in the area of contextual smartphone data analytics and then presents a discussion of challenges and future directions for effectively learning context-aware rules from smartphone data, in order to build rule-based automated and intelligent systems.",http://dx.doi.org/10.1186/s40537-019-0258-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-017-4739-1,Large scale product search with spatial quantization and deep ranking,Multimedia Tools and Applications,10.1007/s11042-017-4739-1,Springer,2019-10-15,"Product image search aims to retrieve similar product images based on a query image. While deep learning based features work well in retrieving images of the same category (e.g. “searching for T-shirts from all the clothing images”), they perform poorly when retrieving variants of images within the same category (e.g. “searching for uniform of Chelsea football club from all T-shirts image”), since it requires fine-grained matching on image details. In this paper, we present a spatial quantization approach that utilizes spatial pyramid pooling (SPP) and vector of locally aggregated descriptors (VLAD) to extract more discriminative features for instance-aware product search. By using the proposed spatial quantization, spatial information is encoded into the image feature to improve the fine grained product image search. We also present an triplet learning to rank method to finetune the deep learning model on product image search task. Finally, the experiments conducted on a large scale real world dataset provided by Alibaba large-scale image search challenge (ALISC) demonstrate the effectiveness of our method.",http://dx.doi.org/10.1007/s11042-017-4739-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-017-4352-3,A privacy-preserving multimedia recommendation in the context of social network based on weighted noise injection,Multimedia Tools and Applications,10.1007/s11042-017-4352-3,Springer,2019-10-15,"With the popularity of social networks such as Facebook and Twitter, more information such as individual’s social connections is considered to make personalized multimedia recommendation, compared to traditional approaches based on the rating matrix. However, the massive data information used for recommendation often contains much personal privacy information. Once the information is obtained by attackers, user’s privacy will be revealed directly or indirectly. This paper proposes a privacy preserving method based on weighted noise injection technique to address the issue of multimedia recommendation in the context of social networks. More specifically, first, we extract core users from entire users. The extracted core users can represent the features of all users adequately. Only the relevant data of core users are then used for rating prediction. Second, we inject different noises to the rating matrix of core users according to different relations between the target user and core users. Third, we use the perturbed matrix to predict the ratings of unused multimedia resources for the target user based on a mixed collaborative filtering approach. By comparing with the traditional noise injection method, the experimental results show that the proposed approach can get better performance of privacy preserving multimedia recommendation.",http://dx.doi.org/10.1007/s11042-017-4352-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-018-05777-9,Dynamic attention-integrated neural network for session-based news recommendation,Machine Learning,10.1007/s10994-018-05777-9,Springer,2019-10-14,"Online news recommendation aims to continuously select a pool of candidate articles that meet the temporal dynamics of user preferences. Most of the existing methods assume that all user-item interaction history are equally importance for recommendation, which is not alway applied in real-word scenario since the user-item interactions are sometime full of stochasticity and contingency. In addition, previous work on session-based algorithms only considers user sequence behaviors within current session without incorporating users’ historical interests or pointing out users’ main purposes within such session. In this paper, we propose a novel neural network framework, dynamic attention-integrated neural network, to tackle the problems. Specifically, we propose a dynamic neural network to model users’ dynamic interests over time in a unified framework for personalized news recommendations. News article semantic embedding, user interests modelling, session-based public behavior mining and an attention scheme that used to learn the attention score of user and item interaction within sessions are four key factors for online sequences mining and recommendation strategy. Experimental results on three real-world datasets show significant improvements over several baselines and state-of-the-art methods on session-based neural networks.",http://dx.doi.org/10.1007/s10994-018-05777-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11747-019-00662-w,A multi-facet item response theory approach to improve customer satisfaction using online product ratings,Journal of the Academy of Marketing Science,10.1007/s11747-019-00662-w,Springer,2019-09-15,"While online platforms often provide a single composite rating and the ratings of different attributes of a product, they largely ignore the attribute characteristics and customer criticality, which limits managerial action. We propose a multi-facet item response theory (MFIRT) approach to simultaneously examine the effects of product attributes, reviewer criticality, consumption situation, product type, and time in assessing latent customer satisfaction. Analyses of hotel ratings from TripAdvisor and beer ratings from BeerAdvocate suggest that product attributes differ with respect to their discriminating and threshold characteristics and that reviewer segments emphasize different attributes when rating various products over time. The MFIRT approach predicts product performance more accurately than alternative methods and provides novel insights to inform marketing strategies. The MFIRT framework can fundamentally advance how we analyze customer satisfaction and other consumer attitudes and improve marketing research and practice.",http://dx.doi.org/10.1007/s11747-019-00662-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-018-2880-x,Analysis model for server consolidation of virtualized heterogeneous data centers providing internet services,Cluster Computing,10.1007/s10586-018-2880-x,Springer,2019-09-15,"Server consolidation based on virtualization technology simplifies system administration, reduces the cost of power and physical infrastructure, and improves resource utilizations in today’s service-oriented Internet data centers. How many servers for the underlying physical infrastructure are saved via server consolidation in virtualized data centers is of great interest to the administrators and designers of the data centers. Various workload consolidations differ in saving physical servers for the infrastructure. The impacts caused by virtualization to these concurrent services are fluctuating considerably which may have a great effect on server consolidation. This paper proposes an analytic model for server consolidation in virtualized Internet data centers based on the queuing theory. According to the features of these services’ workloads, this model can provide the supremum number of consolidated physical servers needed to guarantee QoS with same loss probabilities of requests as in dedicated servers. We verify the model via a case study. The experiments results confirm the superior accuracy of our model and show that the virtual machine-based server consolidation saves up to 50% physical infrastructure and improves 50% CPU resource utilization as well as 2.67 times in I/O bandwidth utilization, satisfying required QoS.",http://dx.doi.org/10.1007/s10586-018-2880-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-019-09369-0,A survey on anonymous voice over IP communication: attacks and defenses,Electronic Commerce Research,10.1007/s10660-019-09369-0,Springer,2019-09-15,"Anonymous voice over IP (VoIP) communication is important for many users, in particular, journalists, human rights workers and themilitary. Recent research work has shown an increasing interest in methods of anonymous VoIP communication. This survey starts by introducing and identifying the major concepts and challenges in this field. Then we review anonymity attacks on VoIP and the existing work done to design defending strategies. We also propose a taxonomy of attacks and defenses. Finally, we discuss possible future work.",http://dx.doi.org/10.1007/s10660-019-09369-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-018-1248-0,"The big data system, components, tools, and technologies: a survey",Knowledge and Information Systems,10.1007/s10115-018-1248-0,Springer,2019-09-01,"The traditional databases are not capable of handling unstructured data and high volumes of real-time datasets. Diverse datasets are unstructured lead to big data, and it is laborious to store, manage, process, analyze, visualize, and extract the useful insights from these datasets using traditional database approaches. However, many technical aspects exist in refining large heterogeneous datasets in the trend of big data. This paper aims to present a generalized view of complete big data system which includes several stages and key components of each stage in processing the big data. In particular, we compare and contrast various distributed file systems and MapReduce-supported NoSQL databases concerning certain parameters in data management process. Further, we present distinct distributed/cloud-based machine learning (ML) tools that play a key role to design, develop and deploy data models. The paper investigates case studies on distributed ML tools such as Mahout, Spark MLlib, and FlinkML. Further, we classify analytics based on the type of data, domain, and application. We distinguish various visualization tools pertaining three parameters: functionality, analysis capabilities, and supported development environment. Furthermore, we systematically investigate big data tools and technologies (Hadoop 3.0, Spark 2.3) including distributed/cloud-based stream processing tools in a comparative approach. Moreover, we discuss functionalities of several SQL Query tools on Hadoop based on 10 parameters. Finally, We present some critical points relevant to research directions and opportunities according to the current trend of big data. Investigating infrastructure tools for big data with recent developments provides a better understanding that how different tools and technologies apply to solve real-life applications.",http://dx.doi.org/10.1007/s10115-018-1248-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-019-00266-w,Experimental comparison of the diagnostic capabilities of classification and clustering algorithms for the QoS management in an autonomic IoT platform,Service Oriented Computing and Applications,10.1007/s11761-019-00266-w,Springer,2019-09-01,"The Internet of Things (IoT) platforms must allow the communication between the Applications and Devices according to their non-functional requirements. One of the main non-functional requirements is the Quality of Service (QoS). In a previous work has been defined an autonomic IoT platform for the QoS Management, based on the concept of autonomic cycle of data analysis tasks. In this platform have been defined two autonomic cycles, one based on a classification task that determines the current operational state to define the set of tasks to execute in the communication system to guarantee a given QoS. The other one is based on a clustering task that discovers the current operational state and, based on it, determines the set of tasks to be executed in the communication system. This paper analyzes the diagnostic capabilities of the system based on both approaches, using different metrics. For that, a real scenario has been considered, with simulations that have generated data to test both tasks. Each technique has different aspects to be considered for a correct QoS management in the context of IoT platforms. The classification technique can determine very well the learned operational states, but the clustering approach can carry out a more detailed description of the operational states. Additionally, due to the classification and clustering technique used, called learning algorithm for multivariate data analysis, the paper analyzes the operational state profile determined by them, which is very useful in a diagnostic process.",http://dx.doi.org/10.1007/s11761-019-00266-w,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10723-018-09471-x,"A Survey on Global Management View: Toward Combining System Monitoring, Resource Management, and Load Prediction",Journal of Grid Computing,10.1007/s10723-018-09471-x,Springer,2019-09-01,"Today, enterprise applications impose more and more resource requirements to support an ascending number of clients and to deliver them an acceptable Quality of Service (QoS). To ensure such requirements are met, it is essential to apply appropriate resource and application monitoring techniques. Such techniques collect data to enable predictions and actions which can offer better system performance. Typically, system administrators need to consider different data sources, so making the relationship among them by themselves. To address these gaps and considering the context of general networked-based systems, we propose a survey that combines a discussion about system monitoring, data prediction, and resource management procedures in a unified view. The article discusses resource and application monitoring, resource management, and data forecast at both performance and architectural perspectives of enterprise systems. Our idea is to describe consolidated subjects such as monitoring metrics and resource scheduling, together with novel trends, including cloud elasticity and artificial intelligence-based load prediction algorithms. This survey links the aforesaid three pillars, emphasizing relationships among them and also pointing out opportunities and research challenges in the area.",http://dx.doi.org/10.1007/s10723-018-09471-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-019-00356-9,Design principles for digital value co-creation networks: a service-dominant logic perspective,Electronic Markets,10.1007/s12525-019-00356-9,Springer,2019-09-01,"Information systems (IS) increasingly expand actor-to-actor networks beyond their temporal, organizational, and spatial boundaries. In such networks and through digital technology, IS enable distributed economic and social actors to not only exchange but also integrate their resources in materializing value co-creation processes. To account for such IS-enabled value co-creation processes in multi -actor settings, this research gives rise to the phenomenon of digital value co-creation networks (DVNs). In designing DVNs, it is not only necessary to consider underpinning value co-creation processes, but also the characteristics of the business environments in which DVNs evolve. To this end, our study guides the design of DVNs through employing service-dominant logic, a theoretical lens that conceptualizes value co-creation as well as business environments. Through an iterative research process, this study derives design requirements and design principles for DVNs, and eventually discusses how these design principles can be illustrated by expository design features for DVNs.",http://dx.doi.org/10.1007/s12525-019-00356-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-017-1182-z,Feature selection using fish swarm optimization in big data,Cluster Computing,10.1007/s10586-017-1182-z,Springer,2019-09-01,"The rapid advances in the field of information and communication technology has made the ubiquitous type of computing along with the internet of things extremely popular. Such applications have created the volumes of the data that are available for the analysis as well as the classification which is an aid to the process of decision making. Among the several methods that are used for the purpose of dealing with the big data, feature selection is found to be very effective. One of the common approaches that involve the searching using a subset of features that have been relevant to that of the topic or will represent an accurate description of this dataset. But unfortunately, the searching using this type of a subset is a problem that is combinatorial and may also be quite time consuming. The meta-heuristic algorithms have been commonly used for the purpose of facilitating the choice of features. Artificial fish swarm optimization (AFSO) algorithms will employ the fish swarming behavior to be the means of overcoming the combinatorial problems. The AFSA has now proved to be highly successful in the applications of a diverse nature. The results of the experiment show that this method proposed will achieve better performance than that of the other methods.",http://dx.doi.org/10.1007/s10586-017-1182-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-019-09691-z,Assessing and optimizing the performance impact of the just-in-time configuration parameters - a case study on PyPy,Empirical Software Engineering,10.1007/s10664-019-09691-z,Springer,2019-08-15,"Many modern programming languages (e.g., Python, Java, and JavaScript) support just-in-time (JIT) compilation to speed up the execution of a software system. During runtime, the JIT compiler translates the frequently executed part of the system into efficient machine code, which can be executed much faster compared to the default interpreted mode. There are many JIT configuration parameters, which vary based on the programming languages and types of the jitting strategies (method vs. tracing-based). Although there are many existing works trying to improve various aspects of the jitting process, there are very few works which study the performance impact of the JIT configuration settings. In this paper, we performed an empirical study on the performance impact of the JIT configuration settings of PyPy. PyPy is a popular implementation of the Python programming language. Due to PyPy’s efficient JIT compiler, running Python programs under PyPy is usually much faster than other alternative implementations of Python (e.g., cPython, Jython, and IronPython). To motivate the need for tuning PyPy’s JIT configuration settings, we first performed an exploratory study on two microbenchmark suites. Our findings show that systems executed under PyPy’s default JIT configuration setting may not yield the best performance. Optimal JIT configuration settings vary from systems to systems. Larger portions of the code being jitted do not necessarily lead to better performance. To cope with these findings, we developed an automated approach, ESM-MOGA, to tuning the JIT configuration settings. ESM-MOGA, which stands for effect-size measure-based multi-objective genetic algorithm, automatically explores the PyPy’s JIT configuration settings for optimal solutions. Case studies on three open source systems show that systems running under the resulting configuration settings significantly out-perform (5% - 60% improvement in average peak performance) the default configuration settings.",http://dx.doi.org/10.1007/s10664-019-09691-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-018-0919-8,Deep learning models for human centered computing in fog and mobile edge networks,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-018-0919-8,Springer,2019-08-01,,http://dx.doi.org/10.1007/s12652-018-0919-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-018-0626-6,A framework for classifying trust for online systems,World Wide Web,10.1007/s11280-018-0626-6,Springer,2019-07-15,"There is no single universally agreed definition of trust for online systems. This has resulted in various trust metrics being proposed by researchers with diverse methods of computing and sourcing trust information. Consequently, it becomes difficult to carry out a comparative study of different types of trust in an organized manner. A classification framework of trust research is required to understand research trends and gaps in existing research. Existing trust classification frameworks are based on few dimensions and have restricted scope. There is a need for developing a generic and scalable method of classifying online trust approaches that can serve as a framework for researchers to analyze upcoming works and carry them forward. In this paper, we develop an open, extensible and scalable trust classification framework built on a set of orthogonal trust dimensions. After taking a bird’s eye view of existing trust classifications, we use wide applicability and extensibility as guidelines to incorporate and extend some of the existing trust categories and propose new dimensions for developing a more comprehensive classification framework. We enhance the prior proposed dimensions computational approach , computational model , trust inference , genesis of trust and trust context by adding new trust categories within each of them. We introduce a new classification dimension that is based on the life cycle maturity of trust systems. Taking a cue from the study of offline trust in social sciences, we refine implicit trust into two new sub-branches namely, relational and similarity based. We categorize existing works on online trust within the proposed framework to highlight their properties along different trust dimensions. Finally, we present a comprehensive review of similarity based implicit and relational implicit trust metrics, the two new key trust sub-categories defined in this paper.",http://dx.doi.org/10.1007/s11280-018-0626-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40565-019-0510-0,Enhancing scalability of peer-to-peer energy markets using adaptive segmentation method,Journal of Modern Power Systems and Clean Energy,10.1007/s40565-019-0510-0,Springer,2019-07-13,"This paper proposes an adaptive segmentation method as a market clearing mechanism for peer-to-peer (P2P) energy trading scheme with large number of market players. In the proposed method, market players participate in the market by announcing their bids. In the first step, players are assigned to different segments based on their features, where the balanced k -means clustering method is implemented to form segments. These segments are formed based on the similarity between players, where the amount of energy for trade and its corresponding price are considered as features of players. In the next step, a distributed method is employed to clear the market in each segment without any need to private information of players. The novelty of this paper relies on developing an adaptive algorithm for dividing large number of market players into multiple segments to enhance scalability of the P2P trading by reducing data exchange and communication overheads. The proposed approach can be used along with any distributed method for market clearing. In this paper, two different structures including community-based market and decentralized bilateral trading market are used to demonstrate the efficacy of the proposed method. Simulation results show the beneficial properties of the proposed segmentation method.",http://dx.doi.org/10.1007/s40565-019-0510-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13222-019-00313-y,Using the Semantic Web as a Source of Training Data,Datenbank-Spektrum,10.1007/s13222-019-00313-y,Springer,2019-07-01,"Deep neural networks are increasingly used for tasks such as entity resolution, sentiment analysis, and information extraction. As the methods are rather training data hungry, it is necessary to use large training sets in order to enable the methods to play their strengths. Millions of websites have started to annotate structured data within HTML pages using the schema.org vocabulary. Popular types of entities that are annotated are products, reviews, events, people, hotels, and other local businesses [ 12 ]. These semantic annotations are used by all major search engines to display rich snippets in search results. This is also the main driver behind the wide-scale adoption of the annotation techniques. This article explores the potential of using semantic annotations from large numbers of websites as training data for supervised entity resolution, sentiment analysis, and information extraction methods. After giving an overview of the types of structured data that are available on the Semantic Web, we focus on the task of product matching in e‑commerce and explain how semantic annotations can be used to gather a large training dataset for product matching. The dataset consists of more than 20 million pairs of offers referring to the same products. The offers were extracted from 43 thousand e‑shops, that provide schema.org annotations including some form of product identifiers, such as manufacturer part numbers (MPNs), global trade item numbers (GTINs), or stock keeping units (SKUs). The dataset, which we offer for public download, is orders of magnitude larger than the Walmart-Amazon [ 7 ], Amazon-Google [ 10 ], and Abt-Buy [ 10 ] datasets that are widely used to evaluate product matching methods. We verify the utility of the dataset as training data by using it to replicate the recent result of Mudgal et al. [ 15 ] stating that embeddings and RNNs outperform traditional symbolic matching methods on tasks involving less structured data. After the case study on product data matching, we focus on sentiment analysis and information extraction and discuss how semantic annotations from the Web can be used as training data within both tasks.",http://dx.doi.org/10.1007/s13222-019-00313-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11276-018-1658-7,Relay selection based clustering techniques for high density LTE networks,Wireless Networks,10.1007/s11276-018-1658-7,Springer,2019-07-01,"In very crowded areas, a large number of LTE users contained in a single cell will try to access services at the same time causing high load on the Base Station (BS). Some users may be blocked from getting their requested services due to this high load. Using a two-hop relay architecture can help in increasing the system capacity, increasing coverage area, decreasing energy consumption, and reducing the BS load. Clustering techniques can be used to configure the nodes in such two-layer topology. This paper proposes a new algorithm for relay selection based on the Basic Sequential Algorithmic Scheme (BSAS) along with power control protocol. Unlike other capacity improving techniques such as small cells and relay stations this approach does not require additional infrastructure. Instead, users themselves will act as a temporary relay stations. Modifications are implemented to the original BSAS to make it suitable for LTE environment and to improve its performance. The protocol for resource allocation and power control is implemented assuming a multi cell scenario. The algorithm is compared to other relaying and clustering schemes in addition to the conventional LTE. The simulation results show that the proposed algorithm has improved system capacity and energy consumption compared to other existing clustering/relaying schemes.",http://dx.doi.org/10.1007/s11276-018-1658-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-018-6755-1,An intelligent recommendation system using gaze and emotion detection,Multimedia Tools and Applications,10.1007/s11042-018-6755-1,Springer,2019-06-15,"Recently, recommendation system has become popular in many e-commerce websites. It helps users by suggesting products which they could buy. Existing work till now uses past feedback of user, similarity of other users’ buying pattern, or a hybrid approach in which both type of information is used. But the pitfall of these approaches is that there is a need to collect and process huge amount of data for good recommendation. This paper is aimed at developing an efficient recommendation system by incorporating user’s emotion and interest to provide good recommendations. The proposed system does not require any of aforementioned data and works without the continuous and interminable attention of the user. In this framework, we capture user’s eye-gaze and facial expression while exploring websites through inexpensive, visible light “webcam”. The eye-gaze detection method uses pupil-center extraction of both eyes and calculates the reference point through a joint probability. The facial expression uses landmark points of face and analyzes the emotion of the user. Both methods work in approximate real time and the proposed framework thus provides intelligent recommendations on-the-fly without requirement of feedback and buying patterns of users.",http://dx.doi.org/10.1007/s11042-018-6755-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12053-018-9753-2,A review on energy efficiency and demand response with focus on small and medium data centers,Energy Efficiency,10.1007/s12053-018-9753-2,Springer,2019-06-15,"Data centers are the backbone of a growing number of activities in modern economies. However, the large increase of digital content, big data, e-commerce, and Internet traffic is also making data centers one of the fastest-growing users of electricity. The total energy consumption of data centers corresponded to almost 1.5% of the global electricity consumption and has an approximated annual growth rate of 4.3%. Therefore, it is very important to increase the energy efficiency in data centers with actions such as power usage management, server consolidation, energy-efficient components and systems, as well as demand response programs and renewable energy sources. Small and medium data centers account for more than 50% of the total electricity consumption in this sector. In fact, surveys indicate that this data center profile waste more energy than larger facilities. Nevertheless, existing studies tend to be focused on the energy-related issues for large data centers rather than small and medium data centers. Therefore, through a meticulous state-of-the-art literature review of data centers energy efficiency and demand response perspectives, this paper aims to present how an intensive energy consumer, such as small and medium data centers, can become more efficient from the energy point of view and how they can take advantage of demand response programs to decrease costs and to cooperate with the grid to ensure higher reliability and sustainable development goals.",http://dx.doi.org/10.1007/s12053-018-9753-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-019-00585-2,Perception-Guided Mobile Manipulation Robots for Automation of Warehouse Logistics,KI - Künstliche Intelligenz,10.1007/s13218-019-00585-2,Springer,2019-06-01,,http://dx.doi.org/10.1007/s13218-019-00585-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-018-2331-8,An ontology-driven personalized food recommendation in IoT-based healthcare system,The Journal of Supercomputing,10.1007/s11227-018-2331-8,Springer,2019-06-01,"The recent developments of internet technology have created premium space for recommender system (RS) to help users in their daily life. An effective personalized recommendation of a travel recommender system can reduce time and travel cost of the travellers. ProTrip RS addresses the personalization problem through exploiting user interests and preferences to generate suggestions. Data considered for the recommendations include travel sequence, actions, motivations, opinions and demographic information of the user. ProTrip is completely designed to be intelligent and in addition, the ProTrip is a health-centric RS which is capable of suggesting the food availability through considering climate attributes based on user’s personal choice and nutritive value. A novel functionality of ProTrip supports travellers with long-term diseases and followers of strict diet. The ProTrip is built on the pillars of ontological knowledge base and tailored filtering mechanisms. The gap between heterogeneous user profiles and descriptions is bridged using semantic ontologies. The effectiveness of recommendations is enhanced through a hybrid model of blended filtering approaches, and results prove that the proposed ProTrip to be a proficient system. The developed food recommendation approach is evaluated for the real-time IoT-based healthcare support system. We also present a detailed case study on the food recommendation-based health management. The proposed system is evaluated on real-time dataset, and analysis of the results shows improved accuracy and efficiency compared to existing models.",http://dx.doi.org/10.1007/s11227-018-2331-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-019-00262-0,Auto-scaling for real-time stream analytics on HPC cloud,Service Oriented Computing and Applications,10.1007/s11761-019-00262-0,Springer,2019-06-01,"There are very-high-volume streaming data in the cyber world today. With the popularization of 5G technology, the streaming Big Data grows larger. Moreover, it needs to be analyzed in real time. We propose a new strategy HPC2-ARS to enable streaming services on HPC platforms. This strategy includes a three-tier high-performance cloud computing (HPC2) platform and a novel autonomous resource-scheduling (ARS) framework. The HPC2 platform is our de facto base platform for research on streaming service. It has three components: Tianhe-2 high-performance computer, custom OpenStack cloud computing software, and Apache Storm stream data analytic system. Our ARS framework ensures real-time response on unpredictable and fluctuating stream, especially streaming Big Data in the 5G era. This strategy addresses an essential problem in the convergence of HPC Cloud, Big Data, and streaming service. Specifically, Our ARS framework provides theoretical and practical solutions for resource provisioning, placement, and scheduling optimization. Extensive experiments have validated the effectiveness of the proposed strategy.",http://dx.doi.org/10.1007/s11761-019-00262-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-018-1359-z,A social recommender system using deep architecture and network embedding,Applied Intelligence,10.1007/s10489-018-1359-z,Springer,2019-05-15,"A recommender system is an active tool for information filtering that can be deployed in a complex and dynamic online environment to provide the most relevant and accurate content to the users based on their unique preferences and tastes. The recent direction towards enhancing the recommender system leverages deep learning techniques and trust information. However, building a unified model for a recommender system that integrates deep architecture with trust information is an open challenge. Here, we propose a hybrid method by modeling a joint optimization function which extends deep Autoencoder with top- k semantic social information. We use network representation learning methods to capture the implicit semantic social information. We conducted experiments with various real-world data sets and evaluated the performance of the proposed method using different evaluation measures. Experimental results show the performance improvement of the proposed system compared to state-of-the-art methods.",http://dx.doi.org/10.1007/s10489-018-1359-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12942-019-0171-2,An overview of GeoAI applications in health and healthcare,International Journal of Health Geographics,10.1186/s12942-019-0171-2,BioMed Central,2019-05-02,"The moulding together of artificial intelligence (AI) and the geographic/geographic information systems (GIS) dimension creates GeoAI. There is an emerging role for GeoAI in health and healthcare, as location is an integral part of both population and individual health. This article provides an overview of GeoAI technologies (methods, tools and software), and their current and potential applications in several disciplines within public health, precision medicine, and Internet of Things-powered smart healthy cities. The potential challenges currently facing GeoAI research and applications in health and healthcare are also briefly discussed.",http://dx.doi.org/10.1186/s12942-019-0171-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42488-019-00004-z,Retail supply chain management: a review of theories and practices,"Journal of Data, Information and Management",10.1007/s42488-019-00004-z,Springer,2019-05-01,"Retail business has been rapidly evolving in the past decades with the boom of internet, mobile technologies and most importantly e-commerce. Supply chain management, as a core part of retail business, has also gone through significant changes with new business scenarios and more advanced technologies in both algorithm design and computation power. In this review, we focus on several core components of supply chain management, i.e. vendor management, demand forecasting, inventory management and order fulfillment. We will discuss the key innovations from both academia and industry and highlight the current trend and future challenges.",http://dx.doi.org/10.1007/s42488-019-00004-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-017-1077-z,Opinion mining on large scale data using sentiment analysis and k-means clustering,Cluster Computing,10.1007/s10586-017-1077-z,Springer,2019-05-01,"With the rapid growth of web technology and easy access of internet, online shopping has been increased. Now people express their opinions and share their experiences that greatly influence new buyers for purchasing products, thereby generating large data sets. This large data is very helpful for analyzing customer preference, needs and its behavior toward a product. Companies face the challenge of analyzing this sheer amount of data to extract customer opinion. To address this challenge, in this paper, we performed sentiment analysis on the customer review real-world data at phrase level to find out customer preference by analyzing subjective expressions. Then we calculated the strength of sentiment word to find out the intensity of each expression and applied clustering for placing the words in various clusters based on their intensity. We also compared the results of our technique with star-ranking given on the same dataset and found the drastic change in our results. We also provide a visual representation of our results to provide a clear insight of customer preference and behavior to help decision makers for better decision making.",http://dx.doi.org/10.1007/s10586-017-1077-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-018-6788-5,Inference-based creation of synthetic 3D content with ontologies,Multimedia Tools and Applications,10.1007/s11042-018-6788-5,Springer,2019-05-01,"Creation of synthetic 3D content is typically a complex task, covering different geometrical, structural, spatial and presentational elements. The available approaches enable 3D content creation by programming or visual modeling of its elements. This demands expertise in computer science from content authors, limits the possibilities of using domain knowledge, and requires to determine all content details within the content creation process. In this paper, we propose a new method of 3D content creation, which is based on ontologies. Ontologies are the foundation of the semantic web, enabling the use of knowledge in various domains. In the proposed method, the use of ontologies facilitates 3D content creation by domain experts without skills in programming and computer graphics. In addition, due to the use of ontologies, the method enables automated reasoning, liberating the authors from determining many elements of the created content, which can be inferred by the content generation algorithm on the basis of explicitly specified content elements. The method has been implemented and evaluated. It simplifies 3D content creation in comparison to the available approaches by reducing the number of activities that must be completed by the content authors. Hence, the proposed method can increase the use of 3D content in different application domains.",http://dx.doi.org/10.1007/s11042-018-6788-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10791-018-9341-2,Search bias quantification: investigating political bias in social media and web search,Information Retrieval Journal,10.1007/s10791-018-9341-2,Springer,2019-04-15,"Users frequently use search systems on the Web as well as online social media to learn about ongoing events and public opinion on personalities. Prior studies have shown that the top-ranked results returned by these search engines can shape user opinion about the topic (e.g., event or person) being searched. In case of polarizing topics like politics, where multiple competing perspectives exist, the political bias in the top search results can play a significant role in shaping public opinion towards (or away from) certain perspectives. Given the considerable impact that search bias can have on the user, we propose a generalizable search bias quantification framework that not only measures the political bias in ranked list output by the search system but also decouples the bias introduced by the different sources—input data and ranking system. We apply our framework to study the political bias in searches related to 2016 US Presidential primaries in Twitter social media search and find that both input data and ranking system matter in determining the final search output bias seen by the users. And finally, we use the framework to compare the relative bias for two popular search systems—Twitter social media search and Google web search—for queries related to politicians and political events. We end by discussing some potential solutions to signal the bias in the search results to make the users more aware of them.",http://dx.doi.org/10.1007/s10791-018-9341-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-019-09218-7,Connectionist recommendation in the wild: on the utility and scrutability of neural networks for personalized course guidance,User Modeling and User-Adapted Interaction,10.1007/s11257-019-09218-7,Springer,2019-04-01,"The aggregate behaviors of users can collectively encode deep semantic information about the objects with which they interact. In this paper, we demonstrate novel ways in which the synthesis of these data can illuminate the terrain of users’ environment and support them in their decision making and wayfinding. A novel application of recurrent neural networks and skip-gram models, approaches popularized by their application to modeling language, are brought to bear on student university enrollment sequences to create vector representations of courses and map out traversals across them. We present demonstrations of how scrutability from these neural networks can be gained and how the combination of these techniques can be seen as an evolution of content tagging and a means for a recommender to balance user preferences inferred from data with those explicitly specified. From validation of the models to the development of a UI, we discuss additional requisite functionality informed by the results of a usability study leading to the ultimate deployment of the system at a university.",http://dx.doi.org/10.1007/s11257-019-09218-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-018-9217-6,Addressing the user cold start with cross-domain collaborative filtering: exploiting item metadata in matrix factorization,User Modeling and User-Adapted Interaction,10.1007/s11257-018-9217-6,Springer,2019-04-01,"Providing relevant personalized recommendations for new users is one of the major challenges in recommender systems. This problem, known as the user cold start has been approached from different perspectives. In particular, cross-domain recommendation methods exploit data from source domains to address the lack of user preferences in a target domain. Most of the cross-domain approaches proposed so far follow the paradigm of collaborative filtering, and avoid analyzing the contents of the items, which are usually highly heterogeneous in the cross-domain setting. Content-based filtering, however, has been successfully applied in domains where item content and metadata play a key role. Such domains are not limited to scenarios where items do have text contents (e.g., books, news articles, scientific papers, and web pages), and where text mining and information retrieval techniques are often used. Potential application domains include those where items have associated metadata, e.g., genres, directors and actors for movies, and music styles, composers and themes for songs. With the advent of the Semantic Web, and its reference implementation Linked Data, a plethora of structured, interlinked metadata is available on the Web. These metadata represent a potential source of information to be exploited by content-based and hybrid filtering approaches. Motivated by the use of Linked Data for recommendation purposes, in this paper we present and evaluate a number of matrix factorization models for cross-domain collaborative filtering that leverage metadata as a bridge between items liked by users in different domains. We show that in case the underlying knowledge graph connects items from different domains and then in situations that benefit from cross-domain information, our models can provide better recommendations to new users while keeping a good trade-off between recommendation accuracy and diversity.",http://dx.doi.org/10.1007/s11257-018-9217-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-018-3358-0,Factored Item Similarity and Bayesian Personalized Ranking for Recommendation with Implicit Feedback,Arabian Journal for Science and Engineering,10.1007/s13369-018-3358-0,Springer,2019-04-01,"Item recommendations aim to predict a list of items (e.g., items on Amazon website) for each user that he or she might like. In fact, implicit feedback, such as transaction records in e-commerce websites and the “likes” behavior in social networks website (e.g., Facebook), has been received more and more attention in the scenarios of item recommendation. The core of the recommender system is the ranking algorithm which exploits the implicit feedback and generates the personalized item list to meet user’s specific preferences. In most of the previous studies, the pairwise personalized ranking techniques empirically achieve better performance than the matrix factorization and adaptive k nearest-neighbor method since the pairwise ranking methods can directly reflect the model user’s ranking preference on items. In most of the recent works, factored item similarity techniques which learn the global item similarity by utilizing two low-dimensional latent factor matrices achieve better performance than other state-of-art top-N methods with predefined similarity, such as cosine similarity. The individual relative preference assumption among observed items and unobserved items are critical for the pairwise ranking methods. As a response, this paper proposes a new and improved preference assumption based on the factored item similarity and individual preference. In addition, a novel recommendation algorithm correspondingly named factored item similarity and Bayesian Personalized Ranking model is designed. The novelty of the algorithm is that it can (1) learn the global item similarity with latent factor models. (2) utilize effective pairwise ranking methods to deal with the item recommendation problems with implicit feedback. (3) assign different item weights on explicit feedback and implicit feedback. Empirical results show that this model outperforms other state-of-the-art top-N recommendation methods on two public datasets in terms of prec@5 and ndcg@5. It can be found that the advantage of FSBPR lies in its ability to exploit implicit feedback and capture global item similarity.",http://dx.doi.org/10.1007/s13369-018-3358-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-018-3507-5,Integrated Intrusion Detection Model Using Chi-Square Feature Selection and Ensemble of Classifiers,Arabian Journal for Science and Engineering,10.1007/s13369-018-3507-5,Springer,2019-04-01,"Intrusion detection system is a device or software application that monitors a network of systems to identify any malicious activity or policy violations. In order to identify intrusions or normal activity, IDS would consider different network-related features such as source address, protocol and flag. The major challenge for any intrusion detection model is to achieve maximum accuracy with minimal false alarms. The aim of this paper is to identify the critical features required in the construction of intrusion detection model, thereby achieving the maximum accuracy. The model utilizes an ensemble approach of classifiers with minimum complexity to overcome the issues in the existing ensemble-based intrusion detection models. In this paper, Chi-square feature selection and the ensemble of classifiers such as support vector machine (SVM), modified Naive Bayes (MNB) and LPBoost are utilized to develop an intrusion detection model. The motivation for selecting Chi-square feature selection is that they rank the features based on the statistical significance test and consider only those features that are dependent on the class label. Supervised classifiers are highly consistent and produce precise results as the use of training data improves the ability to distinguish between classes with similar features. Experimental results indicate high accuracy in comparison with base classifiers by the ensemble of LPBoost. As there is a huge class imbalance present in the network traffic, the prediction of the class label by a majority voting of SVM, MNB and LPBoost is an optimal solution in preference to reliance on a single classifier.",http://dx.doi.org/10.1007/s13369-018-3507-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11235-018-0475-8,A comprehensive survey on network anomaly detection,Telecommunication Systems,10.1007/s11235-018-0475-8,Springer,2019-03-15,"Nowadays, there is a huge and growing concern about security in information and communication technology among the scientific community because any attack or anomaly in the network can greatly affect many domains such as national security, private data storage, social welfare, economic issues, and so on. Therefore, the anomaly detection domain is a broad research area, and many different techniques and approaches for this purpose have emerged through the years. In this study, the main objective is to review the most important aspects pertaining to anomaly detection, covering an overview of a background analysis as well as a core study on the most relevant techniques, methods, and systems within the area. Therefore, in order to ease the understanding of this survey’s structure, the anomaly detection domain was reviewed under five dimensions: (1) network traffic anomalies, (2) network data types, (3) intrusion detection systems categories, (4) detection methods and systems, and (5) open issues. The paper concludes with an open issues summary discussing presently unsolved problems, and final remarks.",http://dx.doi.org/10.1007/s11235-018-0475-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11219-018-9413-y,Usability improvement through A/B testing and refactoring,Software Quality Journal,10.1007/s11219-018-9413-y,Springer,2019-03-15,"Usability evaluation is an essential task in web application development. There have been several attempts to integrate user-centered design with agile methods, but it is hard to synchronize their practices. User testing is very valuable to learn from feedback of actual use, but it remains expensive to find and solve usability problems. Furthermore, the high cost of usability evaluation forces small/medium-sized companies to trust the first solution applied, without actually testing the success of the solution or considering a possible regression in usability, as could be highlighted by an iterative testing method. In this article, we advocate for a usability improvement cycle oriented by user feedback, and compatible with an agile development process. We propose an iterative method supported by a toolkit that allows usability experts to design user tests, run them remotely, analyze results, and assess alternative solutions to usability problems similarly to A/B testing. Each solution is created by applying client-side web refactorings, i.e., changes to the web pages in the client which are meant to improve usability. The main benefit of our approach is that it reduces the overall cost of user testing and particularly, A/B testing, by applying refactorings to create alternative solutions without modifying the application’s server code. By making it affordable for usability experts to apply the method in parallel with the development cycle, we aim to encourage them to incorporate user feedback and try different ideas to discover the best-performing solution in terms of the metrics of interest.",http://dx.doi.org/10.1007/s11219-018-9413-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-019-00336-z,Cognitive computing for customer profiling: meta classification for gender prediction,Electronic Markets,10.1007/s12525-019-00336-z,Springer,2019-03-12,"Analyzing data from micro blogs is an increasingly interesting option for enterprises to learn about customer sentiments, public opinion, or unsatisfied needs. A better understanding of the underlying customer profiles (considering e.g. gender or age) can substantially enhance the economic value of the customer intimacy provided by this type of analytics. In a design science approach, we draw on information processing theory and meta machine learning to propose an extendable, cognitive classifier that, for profiling purposes, integrates and combines various isolated base classifiers. We evaluate its feasibility and the performance via a technical experiment, its suitability in a real use case, and its utility via an expert workshop. Thus, we augment the body of knowledge by a cognitive method that enables the integration of existing, as well as emerging customer profiling classifiers for an improved overall prediction performance. Specifically, we contribute a concrete classifier to predict the gender of German-speaking Twitter users. We enable enterprises to reap information from micro blog data to develop customer intimacy and to tailor individual offerings for smarter services.",http://dx.doi.org/10.1007/s12525-019-00336-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13740-018-0095-1,The Short-term User Modeling for Predictive Applications,Journal on Data Semantics,10.1007/s13740-018-0095-1,Springer,2019-03-08,"One of the important purposes of data mining on the web is to reveal hidden characteristics of users including their behavior. These characteristics are often used to analyze previous user actions, his/her preferences, and also to predict the future behavior. An average user session consists of only few actions, which brings several complications for the user modeling and also for subsequent prediction tasks. Such tasks are usually researched from the long-term point of view (e.g., contract renewal or course quit). On the contrary, the short-term user modeling plays an important role in the context of web applications, where it helps to improve user experience. Its shortcoming is that it often requires rich data, which availability is rather rare. For this reason, we propose a novel user model focused on the capturing changes in the user’s behavior on the level of specific actions. The model idea is based on the enrichment of user actions by a comparison of actual user session data with previous sessions. As the model basis on generally available data sources, the approach is applicable to wide scale of existing systems. We evaluate our model by the task of session end intent prediction in the e-learning and news domain. Thanks to reflecting differences in user behavior we are able to predict the intent to end the session for particular user in the scale of his/her next couple of actions. Obtained results clearly show that the proposed model brings higher precision, accuracy and session hit ratio than baseline models.",http://dx.doi.org/10.1007/s13740-018-0095-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13174-019-0104-0,Improving microservice-based applications with runtime placement adaptation,Journal of Internet Services and Applications,10.1186/s13174-019-0104-0,Springer,2019-02-26,"Microservices are a popular method to design scalable cloud-based applications. Microservice-based applications ( μ Apps) rely on message passing for communication and to decouple each microservice, allowing the logic in each service to scale independently. Complex μ Apps can contain hundreds of microservices, complicating the ability of DevOps engineers to reason about and automatically optimize the deployment. In particular, the performance and resource utilization of a μ App depends on the placement of the microservices that compose it. However, existing tools for μ Apps, like Kubernetes, provide minimal ability to influence the placement and utilization of a μ App deployment. In this paper, we first identify the runtime aspects of microservice execution that impact the placement of microservices in a μ App. We then review the challenges of reconfiguring a μ App based on these aspects. Our main contribution is an adaptation mechanism, named REMaP, to manage the placement of microservices in an μ App automatically. To achieve this, REMaP uses microservice affinities and resource usage history. We evaluate our REMaP prototype and demonstrate that our solution is autonomic, lowers resource utilization, and can substantially improve μ App performance.",http://dx.doi.org/10.1186/s13174-019-0104-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-017-9738-2,Discovering composable web services using functional semantics and service dependencies based on natural language requests,Information Systems Frontiers,10.1007/s10796-017-9738-2,Springer,2019-02-15,"The processes of service discovery, selection and composition are crucial tasks in web service based application development. Most web service-driven applications are complex and are composed of more than one service, so, it becomes important for application designers to identify the best service to perform the next task in the intended application’s workflow. In this paper, a framework for discovering composable service sets as per user’s complex requirements is proposed. The proposed approach uses natural language processing and semantics based techniques to extract the functional semantics of the service dataset and also to understand user context. In case of simple queries, basic services may be enough to satisfy the user request, however, in case of complex queries, several basic services may have to be identified to serve all the requirements, in the correct sequence. For this, the service dependencies of all the services are used for constructing a service interface graph for finding suitable composable services. Experiments showed that the proposed approach was effective towards finding relevant services for simple & complex queries and achieved an average accuracy rate of 75.09 % in finding correct composable service templates.",http://dx.doi.org/10.1007/s10796-017-9738-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4215-5_6,Machine Learning Theory and Practice,Machine Learning Using R,10.1007/978-1-4842-4215-5_6,Springer,2019-01-01,"The world is quickly adapting the use of machine learning (ML). Whether its driverless cars, the intelligent personal assistant, or machines playing the games like Go and Jeopardy against humans, ML is pervasive. The availability and ease of collecting data coupled with high computing power has made this field even more conducive to researchers and businesses to explore data-driven solutions for some of the most challenging problems. This has led to a revolution and outbreak in the number of new startups and tools leveraging ML to solve problems in sectors such as healthcare, IT, HR, automobiles, manufacturing, and the list is ever expanding.",http://dx.doi.org/10.1007/978-1-4842-4215-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-19034-7_14,A Taxonomy of Software Engineering Challenges for Machine Learning Systems: An Empirical Investigation,Agile Processes in Software Engineering and Extreme Programming,10.1007/978-3-030-19034-7_14,Springer,2019-01-01,"Artificial intelligence enabled systems have been an inevitable part of everyday life. However, efficient software engineering principles and processes need to be considered and extended when developing AI- enabled systems. The objective of this study is to identify and classify software engineering challenges that are faced by different companies when developing software-intensive systems that incorporate machine learning components. Using case study approach, we explored the development of machine learning systems from six different companies across various domains and identified main software engineering challenges. The challenges are mapped into a proposed taxonomy that depicts the evolution of use of ML components in software-intensive system in industrial settings. Our study provides insights to software engineering community and research to guide discussions and future research into applied machine learning.",http://dx.doi.org/10.1007/978-3-030-19034-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-68837-4_16,Machine Learning (Supervised),Essentials of Business Analytics,10.1007/978-3-319-68837-4_16,Springer,2019-01-01,"Every time we search the Web, buy a product online, swipe a credit card, or even check our e-mail, we are using a sophisticated machine learning system, built on a massive cloud platform, driving billions of decisions every day. Machine learning has many paradigms. In this chapter, we explore the philosophical, theoretical, and practical aspects of one of the most common machine learning paradigms— supervised learning —that essentially learns a mapping from an observation (e.g., symptoms and test results of a patient) to a prediction (e.g., disease or medical condition), which in turn is used to make decisions (e.g., prescription). This chapter explores the process, science, and art of building supervised learning models.",http://dx.doi.org/10.1007/978-3-319-68837-4_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-06222-4_1,Marketing Meets Data Science: Bridging the Gap,Business and Consumer Analytics: New Ideas,10.1007/978-3-030-06222-4_1,Springer,2019-01-01,"It is certain that computer science is completely reformulating the way that business is being conducted around the world. We are witnessing the increasing availability of large volumes of data together with the advances in artificial intelligence, machine learning and optimization techniques. Breakthroughs in statistics, discrete applied mathematics and new algorithms are leading to the development of a new interdisciplinary field: data science. The purpose of this chapter is to provide a bridge, a short-cut to understand some of the questions that computer science deals with in a context of developing new techniques to get knowledge from data.",http://dx.doi.org/10.1007/978-3-030-06222-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-1675-3_4,The Enterprise Technology Landscape,Business Innovation and ICT Strategies,10.1007/978-981-13-1675-3_4,Springer,2019-01-01,"This chapter explores the broad technological themes in the evolving enterprise landscape, including the key ICT technologies that will gain force, for example, cloud, AI/ML, IoT, drones, blockchain, and so on. The evolving role of the CTO/CIO is examined and the future demands of the role are discussed. Finally the current (indicative) ICT spend and its breakup in any organization were described.",http://dx.doi.org/10.1007/978-981-13-1675-3_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4106-6_5,Cognitive Robotics Process Automation: Automate This!,Cognitive Computing Recipes,10.1007/978-1-4842-4106-6_5,Springer,2019-01-01,"As automation becomes a norm in digital businesses, technology professionals are fast embracing it as a tool for creating operational efficiencies. In more recent years, robotics process automation (RPA), or IPA (intelligent process automation), has been helping out businesses by providing much-needed relief from doing mundane and repetitive tasks.",http://dx.doi.org/10.1007/978-1-4842-4106-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-0550-4_3,Big Data Analysis in Cloud and Machine Learning,Big Data Processing Using Spark in Cloud,10.1007/978-981-13-0550-4_3,Springer,2019-01-01,"In today’s digital universe, the amount of digital data that exists is growing at an exponential rate. Data is considered to be the lifeblood for any business organization, as it is the data that streams into actionable insights of businesses. The data available with the organizations are so much in volume that it is popularly referred as big data. It is the hottest buzzword spanning the business and technology worlds. Economies over the world is using big data and big data analytics as a new frontier for business so as to plan smarter business moves, improve productivity, improve performance, and plan strategy more effectively. To make big data analytics effective, storage technologies, and analytical tools play a critical role. However, it is evident that big data places rigorous demands on networks, storage and servers, which has motivated organizations and enterprises to move on cloud, in order to harvest maximum benefits of the available big data. Furthermore, we are also aware that conventional analytics tools are incapable to capture the full value of big data. Hence, machine learning seems to be an ideal solution for exploiting the opportunities hidden in big data. In this chapter, we shall discuss big data and big data analytics with a special focus in cloud computing and machine learning.",http://dx.doi.org/10.1007/978-981-13-0550-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-10997-4_12,A Practical Deep Online Ranking System in E-commerce Recommendation,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-030-10997-4_12,Springer,2019-01-01,"User online shopping experience in modern e-commerce websites critically relies on real-time personalized recommendations. However, building a productionized recommender system still remains challenging due to a massive collection of items, a huge number of online users, and requirements for recommendations to be responsive to user actions. In this work, we present our relevant, responsive, and scalable deep online ranking system (DORS) that we developed and deployed in our company. DORS is implemented in a three-level architecture which includes (1) candidate retrieval that retrieves a board set of candidates with various business rules enforced; (2) deep neural network ranking model that takes advantage of available user and item specific features and their interactions; (3) multi-arm bandits based online re-ranking that dynamically takes user real-time feedback and re-ranks the final recommended items in scale. Given a user as a query, DORS is able to precisely capture users’ real-time purchasing intents and help users reach to product purchases. Both offline and online experimental results show that DORS provides more personalized online ranking results and makes more revenue.",http://dx.doi.org/10.1007/978-3-030-10997-4_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3799-1_1,What Is Artificial Intelligence?,Machine Learning and AI for Healthcare,10.1007/978-1-4842-3799-1_1,Springer,2019-01-01,"Artificial intelligence (AI) is considered, once again, to be one of the most exciting advances of our time. Virtual assistants can determine our music tastes with remarkable accuracy, cars are now able to drive themselves, and mobile apps can reverse diseases once considered to be chronic and progressive.",http://dx.doi.org/10.1007/978-1-4842-3799-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26169-6_9,Survey of Vehicular Network Simulators: A Temporal Approach,Enterprise Information Systems,10.1007/978-3-030-26169-6_9,Springer,2019-01-01,"Evaluating protocols and applications for Intelligent Transportation Systems is the first step before deploying them in the real world. Simulations provide scalable evaluations with low costs. However, to produce reliable results, the simulators should implement models that represent as closely as possible real situations. In this survey, we provide a study of the main simulators focused on Intelligent Transport Systems assessment. Additionally, we examine the temporal evolution of these simulators giving information that leads to an overview understanding of how long the scientific community takes to absorb a new simulator proposal. The conclusions presented in this survey provide valuable insights that help researchers make better choices when selecting the appropriate simulator to evaluate new proposals.",http://dx.doi.org/10.1007/978-3-030-26169-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30146-0_25,Positive-Unlabeled Learning for Sentiment Analysis with Adversarial Training,"Collaborative Computing: Networking, Applications and Worksharing",10.1007/978-3-030-30146-0_25,Springer,2019-01-01,"Sentiment classification is a critical task in sentiment analysis and other text mining applications. As a sub-problem of sentiment classification, positive and unlabeled learning or positive-unlabeled learning (PU learning) problem widely exists in real-world cases, but it has not been given enough attention. In this paper, we aim to solve PU learning problem under the framework of adversarial training and neural network. We propose a novel model for PU learning problem, which is based on adversarial training and attention-based long short-term memory (LSTM) network. In our model, we design a new adversarial training technique. We conducted extensive experiments on two real-world datasets. The experimental results demonstrate that our proposed model outperforms the compared methods, including the well-known traditional methods and state-of-the-art methods. We also report the training time, and discuss the sensitivity of our model to parameters.",http://dx.doi.org/10.1007/978-3-030-30146-0_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-98512-1_33,Embedding Humans into Service Systems Analysis: The Evolution of Mathematical Thinking About Services,"Handbook of Service Science, Volume II",10.1007/978-3-319-98512-1_33,Springer,2019-01-01,"Current technology-driven innovations in service systems tend to replace human workers with machines, rather than engineering a partnership between the two. Engineering this cooperation is not an easy task, and requires cyber-physical systems that seamlessly adapt and respond to unexpected human interactions. This chapter provides an overview of how mathematical modeling of service systems with human-machine cooperation is evolving. In addition to the modeling challenges, a historical view of modeling humans in service systems is presented, including current promising work and tools, such as deep learning, and Markov process approaches to model human behavior and interaction. The chapter also explores using other mathematical paradigms and creating a new mathematical language to model humans.",http://dx.doi.org/10.1007/978-3-319-98512-1_33,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-0094-7_1,Big Data Analytics,"Big Data Analytics: Systems, Algorithms, Applications",10.1007/978-981-15-0094-7_1,Springer,2019-01-01,"The latest disruptive trends and developments in digital age comprise social networking, mobility, analytics and cloud, popularly known as SMAC. The year 2016 saw Big Data Technologies being leveraged to power business intelligence applications. What holds in store for 2020 and beyond?",http://dx.doi.org/10.1007/978-981-15-0094-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-03131-2_1,"Intelligent Computational Techniques for the Better World 2020: Concepts, Methodologies, Tools, and Applications",Smart Techniques for a Smarter Planet,10.1007/978-3-030-03131-2_1,Springer,2019-01-01,"Over the past few decades, researchers, practitioners are increasingly moving toward the domain of searching, and optimization, by using advanced machine learning concepts based on nature-inspired computation, and metaheuristics, to solve problems spanning across all the spectrums of human endeavor. Evolutionary and nature-inspired techniques have granted us incredible power to solve multi-model and combinatorial problems in a smarter way. Deep learning, a new frontier in AI research, has revolutionized machine learning and related AI talent to next level of constructing algorithms which can make the system intelligent enough to become a better analyzer. These techniques and concepts are inspired from nature and biological behaviors. The intelligent use of these techniques, collectively known as smart techniques, has driven us to solve complex computational problems in areas of diversified domain in an affordable amount of time. Clearly, these smart techniques involve complex processes that are evolving very fast to take over in all spheres of the world affairs. This introductory chapter aims to provide an in-depth study of intelligent computational techniques and its interdisciplinary applications in different domains. To stimulate the future work, we conclude the chapter proposing new possible research directions and outline several open issues.",http://dx.doi.org/10.1007/978-3-030-03131-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-37231-6_18,Phish-Hook: Detecting Phishing Certificates Using Certificate Transparency Logs,Security and Privacy in Communication Networks,10.1007/978-3-030-37231-6_18,Springer,2019-01-01,"Certificate misissuance is a growing issue in the context of phishing attacks, as it leads inexperienced users to further trust fraudulent websites, if they are equipped with a technically valid certificate. Certificate Transparency (CT) aims at increasing the visibility of such malicious actions by requiring certificate authorities (CAs) to log every certificate they issue in public, tamper-proof, append-only logs. This work introduces Phish-Hook , a novel approach towards detecting phishing websites based on machine learning. Phish-Hook analyses certificates submitted to the CT system based on a conceptually simple, well-understood classification mechanism to effectively attest the phishing likelihood of newly issued certificates. Phish-Hook relies solely on CT log data and foregoes intricate analyses of websites’ source code and traffic. As a consequence, we are able to provide classification results in near real-time and in a resource-efficient way. Our approach advances the state of the art by classifying websites according to five different incremental certificate risk labels, instead of assigning a binary label. Evaluation results demonstrate the effectiveness of our approach, achieving a success rate of over 90%, while requiring fewer, less complex input data, and delivering results in near real-time.",http://dx.doi.org/10.1007/978-3-030-37231-6_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-02110-8_8,Deception-Enhanced Threat Sensing for Resilient Intrusion Detection,Autonomous Cyber Deception,10.1007/978-3-030-02110-8_8,Springer,2019-01-01,"Enhancing standard web services with deceptive responses to cyberattacks can be a powerful and practical strategy for improved intrusion detection. Such deceptions are particularly helpful for addressing and overcoming barriers to effective machine learning-based intrusion detection encountered in many practical deployments. For example, they can provide a rich source of training data when training data is scarce, they avoid imposing a labeling burden on operators in the context of (semi-)supervised learning, they can be deployed post-decryption on encrypted data streams, and they learn concept differences between honeypot attacks and attacks against genuine assets. The approach presented in this chapter examines how deceptive web service responses can be realized as software security patches that double as feature extraction engines for a network-level intrusion detection system. The resulting system coordinates multiple levels of the software stack to achieve fast, automatic, and accurate labeling of live web data streams, and thereby detects attacks with higher accuracy and adaptability than comparable non-deceptive defenses.",http://dx.doi.org/10.1007/978-3-030-02110-8_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31511-5_5,On the Statistical Detection of Adversarial Instances over Encrypted Data,Security and Trust Management,10.1007/978-3-030-31511-5_5,Springer,2019-01-01,"Adversarial instances are malicious inputs designed to fool machine learning models. In particular, motivated and sophisticated attackers intentionally design adversarial instances to evade classifiers which have been trained to detect security violation, such as malware detection. While the existing approaches provide effective solutions in detecting and defending adversarial samples, they fail to detect them when they are encrypted. In this study, a novel framework is proposed which employs statistical test to detect adversarial instances, when data under analysis are encrypted. An experimental evaluation of our approach shows its practical feasibility in terms of computation cost.",http://dx.doi.org/10.1007/978-3-030-31511-5_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4185-1_1,Eagle-Eye View of Azure Cognitive Services,Developing Bots with QnA Maker Service,10.1007/978-1-4842-4185-1_1,Springer,2019-01-01,What are Azure Cognitive Services? What problems do they solve in the real world? These are a few of the questions that might come to mind when we come across the term Azure Cognitive Services. This chapter will dive in and find answers to these questions.,http://dx.doi.org/10.1007/978-1-4842-4185-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30796-7_32,A Pay-as-you-go Methodology to Design and Build Enterprise Knowledge Graphs from Relational Databases,The Semantic Web – ISWC 2019,10.1007/978-3-030-30796-7_32,Springer,2019-01-01,"Business users must answer business questions quickly to address Business Intelligence (BI) needs. The bottleneck is to understand the complex databases schemas. Only few people in the IT department truly understand them. A holy grail is to empower business users to ask and answer their own questions with minimal IT support. Semantic technologies, now dubbed as Knowledge Graphs, become useful here. Even though the research and industry community has provided evidence that semantic technologies works in the real world, our experience is that there continues to be a major challenge: the engineering of ontologies and mappings covering enterprise databases containing thousands of tables with tens of thousands of attributes. In this paper, we present a novel and unique pay-as-you-go methodology that addresses the aforementioned difficulties. We provide a case study with a large scale e-commerce company where Capsenta’s Ultrawrap has been deployed in production for over 3 years.",http://dx.doi.org/10.1007/978-3-030-30796-7_32,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-01557-2_2,Physical Activity,Health and Wellness Measurement Approaches for Mobile Healthcare,10.1007/978-3-030-01557-2_2,Springer,2019-01-01,"An attempt has been made to review the potential of mhealth in terms of remote monitoring of physical activities. This allows individuals to resume their normal daily activities while their health parameters are remotely monitored to predict/detect a decline in their health index that demands in-patient care. The ability of sensor technologies and algorithms to deliver health outcomes is discussed to allay doubts about the potential usefulness of the proposed solutions. Additionally, this chapter discussed the major challenges and the response of leading-edge technologies to these challenges in order to optimise the technology fitness for the application of interest. A summary of pilots and trials that have been carried out in many countries and regions is provided to create well-established fact bases of mhealth solutions for remote monitoring of physical activities.",http://dx.doi.org/10.1007/978-3-030-01557-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4888-1_1,Introduction: Azure Chatbots,Introducing Azure Bot Service,10.1007/978-1-4842-4888-1_1,Springer,2019-01-01,"In this introductory chapter, we take a simple initial and down-to-earth look at artificial intelligence (AI) and chatbots. We examine Azure and Azure chatbots, and last, study how to build chatbots using Azure chatbots. Readers with technical backgrounds and nontechnical backgrounds can gain an understanding of chatbots. In general, if you are fond of technology, passionate about digital transformation, and have a desire to bring about change management, generate user engagement, and create high impact in terms of customer satisfaction, then this book is for you.",http://dx.doi.org/10.1007/978-1-4842-4888-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-10997-4_9,Intent-Aware Audience Targeting for Ride-Hailing Service,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-030-10997-4_9,Springer,2019-01-01,"As the market for ride-hailing service is increasing dramatically, an efficient audience targeting system (which aims to identify a group of recipients for a particular message) for ride-hailing services is demanding for marketing campaigns. In this paper, we describe the details of our deployed system for intent-aware audience targeting on Baidu Maps for ride-hailing services. The objective of the system is to predict user intent for requesting a ride and then send corresponding coupons to the user. For this purpose, we develop a hybrid model to combine the LSTM model and GBDT model together to handle sequential map query data and heterogeneous non-sequential data, which leads to a significant improvement in the performance of the intent prediction. We verify the effectiveness of our method over a large real-world dataset and conduct a large-scale online marketing campaign over Baidu Maps app. We present an in-depth analysis of the model’s performance and trade-offs. Both offline experiment and online marketing campaign evaluation show that our method has a consistently good performance in predicting user intent for a ride request and can significantly increase the click-through rate (CTR) of vehicle coupon targeting compared with baseline methods.",http://dx.doi.org/10.1007/978-3-030-10997-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-1483-4_7,A Methodology for Retrofitting Privacy and Its Application to e-Shopping Transactions,"Advances in Cyber Security: Principles, Techniques, and Applications",10.1007/978-981-13-1483-4_7,Springer,2019-01-01,"The huge growth of e-shopping has brought convenience to customers and increased revenue to merchants and financial entities. Moreover, e-shopping has evolved to possess many functions, features, and requirements (e.g., regulatory ones). However, customer privacy has been mostly ignored, and while it is easy to add simple privacy to an existing system, this typically causes loss of functions. What is needed is enhanced privacy on one hand, and retaining the critical functions and features on the other hand. This is a dilemma which typifies the “privacy versus utility” paradigm, especially when it is applied to an established primitive with operational systems, where applying conventional privacy-by-design principles is not possible and completely altering information flows and system topologies is not an option. This dilemma is becoming more problematic with the advent of regulations such as the European GDPR, which requires companies to provide better privacy guarantees whenever and wherever personal information is involved. In this chapter, we put forward a methodology for privacy augmentation design that is specially suitable for real-world engineering processes that need to adhere to the aforementioned constraints. We call this the “utility, privacy, and then utility again” paradigm. In particular, we start from the state-of-the-art industry systems that we need to adapt; then we add privacy enhancing mechanisms, reducing functionality in order to tighten privacy to the fullest (privacy); and finally, we incorporate tools which add back lost features, carefully relaxing privacy this time (utility again). Specifically, we apply this process to current e-shopping infrastructures, making them privacy respectful without losing functionality. This gives an e-shopping system with enhanced privacy features, presents a set of “utility-privacy trade-offs,” and showcases a practical approach implementing the notion of “privacy by design” while maintaining as much compatibility as possible with current infrastructures. Finally, we note that we implemented and tested performance of our design, verifying its reasonable added costs.",http://dx.doi.org/10.1007/978-981-13-1483-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5431-8_5,Bird’s-Eye View of a Zero Trust Network,Zero Trust Networks with VMware NSX,10.1007/978-1-4842-5431-8_5,Springer,2019-01-01,"You have learned the basics of how to create distributed firewall rules as well as how to create security groups, service composers, etc. It’s time to get ruthless with real-world scenarios. The intention here is to explain how you can implement a Zero Trust policy-based network on a real production system.",http://dx.doi.org/10.1007/978-1-4842-5431-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-01869-5_1,Introduction,Data Management in Machine Learning Systems,10.1007/978-3-031-01869-5_1,Springer,2019-01-01,"Machine learning (ML) and, in general, artificial intelligence (AI) techniques, are undoubtedly changing many aspects of our lives and societies, even though often unnoticed. Applications of ML and AI are ubiquitous in almost every domain and they leverage (1) a diverse set of algorithms from clustering, classification, regression, time series analysis, recommendations, and reinforcement learning, together with (2) application-specific pipelines that connect these algorithms with steps for preparing data, incorporating domain knowledge, interpreting results, and applying insights.",http://dx.doi.org/10.1007/978-3-031-01869-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5034-1_5,"Natural Language Processing, Understanding, and Generation",Building an Enterprise Chatbot,10.1007/978-1-4842-5034-1_5,Springer,2019-01-01,"The human brain is one of the most advanced machines when it comes to processing, understanding, and generating (P-U-G) natural language. The capabilities of the human brain stretch far beyond just being able to perform P-U-G on one language, dialect, accent, and conversational undertone. No machine has so far reached the human potential of performing all three tasks seamlessly. However, the advances in machine learning algorithms and computing power are making the distant dream of creating human-like bots a possibility.",http://dx.doi.org/10.1007/978-1-4842-5034-1_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5028-0_7,Physical Robots,Artificial Intelligence Basics,10.1007/978-1-4842-5028-0_7,Springer,2019-01-01,"In the city of Pasadena, I went to CaliBurger for lunch and noticed a crowd of people next to the area where the food was being cooked—which was behind glass. The people were taking photos with their smartphones!",http://dx.doi.org/10.1007/978-1-4842-5028-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22338-0_30,User Experiences of Incident Reporting Software in Fire Services: An Integrative Review and Meta-Analysis,"HCI in Business, Government and Organizations. Information Systems and Analytics",10.1007/978-3-030-22338-0_30,Springer,2019-01-01,"This integrative review gathers data from published articles and user feedback for a meta-analysis of the common problems, use contexts, and recommendations. The project supplements primary interviews with secondary data from prior studies and reports, as well as online feedback and reviews. This approach helps validate user experience findings for rarely-tested products, and it helps to confirm and identify user affordances and system pain points. Findings suggest that poor visibility of system status, lack of match between system and real-world use, and opaque help and documentation are common barriers. NFIRS software programs also do not anticipate the cultural idiosyncrasies endemic to fire services (such as apprenticeship learning) that, if addressed, could help software users better recognize, diagnose and recover from decision-making errors. Firefighters request more functionality, more help to find pertinent codes, and differentiating between nondescript codes. Recommendations for improving the quality of software programs for incident reporting in fire services include improving customization features, providing templates and content guides, and improving the glossaries of common acronyms. Help systems should address the diverse backgrounds and levels of education that comprise fire services.",http://dx.doi.org/10.1007/978-3-030-22338-0_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-34339-2_10,CATCHA: When Cats Track Your Movements Online,Information Security Practice and Experience,10.1007/978-3-030-34339-2_10,Springer,2019-01-01,"Any website can record its users’ mouse interactions within that site, an emerging practice used to learn about users’ regions of interests usually for personalization purposes. However, the dark side of such recording is that it is oblivious to the users as no permissions are solicited from the users prior to recording (unlike other resources like webcam or microphone). Since mouse dynamics may be correlated with users’ behavioral patterns, any website with nefarious intentions (“cat”) could thus try to surreptitiously infer such patterns, thereby compromising users’ privacy and making them prone to targeted attacks. In this paper, we show how users’ personal information, specifically their demographic characteristics , could leak in the face of such mouse movement eavesdropping. As a concrete case study along this line, we present CATCHA , a mouse analytic attack system that gleans potentially sensitive demographic attributes— age group , gender , and educational background —based on mouse interactions with a game CAPTCHA system (a simple drag-and-drop animated object game to tell humans and machines apart). CATCHA ’s algorithmic design follows the machine learning approach that predicts unknown demographic attributes based on a total of 64 mouse dynamics features extracted from within the CAPTCHA game, capturing users’ innate cognitive abilities and behavioral patterns. Based on a comprehensive data set of mouse movements with respect to a simple game CAPTCHA collected in an online environment, we show that CATCHA can identify the users’ demographics attributes with a high probability ( almost all attributes with more than 85% ), significantly better than random guessing (50%) and in a very short span of interaction time ( about 14 s ). We also provide a thorough statistical analysis and interpretation of differentiating features across the demographics attributes that make users susceptible to the CATCHA attack. Finally, we discuss potential extensions to our attack using other user interaction paradigms (e.g., other types of CAPTCHAs or typical web browsing interactions, and under longitudinal settings), and provide potential mitigation strategies to curb the impact of mouse movement eavesdropping.",http://dx.doi.org/10.1007/978-3-030-34339-2_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-16145-3_34,RNE: A Scalable Network Embedding for Billion-Scale Recommendation,Advances in Knowledge Discovery and Data Mining,10.1007/978-3-030-16145-3_34,Springer,2019-01-01,"Nowadays designing a real recommendation system has been a critical problem for both academic and industry. However, due to the huge number of users and items, the diversity and dynamic property of the user interest, how to design a scalable recommendation system, which is able to efficiently produce effective and diverse recommendation results on billion-scale scenarios, is still a challenging and open problem for existing methods. In this paper, given the user-item interaction graph, we propose RNE, a data-efficient R ecommendation-based N etwork E mbedding method, to give personalized and diverse items to users. Specifically, we propose a diversity- and dynamics-aware neighbor sampling method for network embedding. On the one hand, the method is able to preserve the local structure between the users and items while modeling the diversity and dynamic property of the user interest to boost the recommendation quality. On the other hand the sampling method can reduce the complexity of the whole method theoretically to make it possible for billion-scale recommendation. We also implement the designed algorithm in a distributed way to further improves its scalability. Experimentally, we deploy RNE on a recommendation scenario of Taobao, the largest E-commerce platform in China, and train it on a billion-scale user-item graph. As is shown on several online metrics on A/B testing, RNE is able to achieve both high-quality and diverse results compared with CF-based methods. We also conduct the offline experiments on Pinterest dataset comparing with several state-of-the-art recommendation methods and network embedding methods. The results demonstrate that our method is able to produce a good result while runs much faster than the baseline methods.",http://dx.doi.org/10.1007/978-3-030-16145-3_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-17141-4_1,Traditional Business Process Management,Dynamic Business Process Management in the Knowledge Economy,10.1007/978-3-030-17141-4_1,Springer,2019-01-01,"The rapid development of process management and its practical uses stems from the changing conditions of business, which are the result of overlapping and mutually stimulating changes in business culture, social conventions, the development of information and communication technologies, as well as the process of globalization and changes to the principles of competition themselves. For several years now it has become apparent that practical methodologies and IT systems supporting the implementation and use of process management in organizations are developing at a much faster pace than their theoretical underpinnings. This chapter discusses the limitations of traditional business process management, as well as its main discrepancies with the requirements of business in the knowledge economy. The 3rd wave of development of process management, which has been initiated around the year 2003, is becoming increasingly less responsive to the requirements of modern business. There is a lack of theoretical reflection on traditional process management, despite the fact that due to changes in the paradigms of the knowledge economy it may be used in the case of a mere 20–30% of the processes within the organization. The chapter describes changes to process management and the practical solutions which exceed traditional process management. Of fundamental significance for practitioners dealing with the preparation of tools and the implementation of methodologies pertaining to process management is the distinct integration of the methodologies and tools of business process management (BPM) and case management (CM). Such integrations are often the result of trial and error, sometimes fall outside of the mainstream of process management, but have nonetheless been positively verified by the clients, that is, in the most objective manner possible. The chapter also points to the factors leading to the emergence, as well as the main characteristics of the so-called 4th wave of process management. Just as in the case of the previous waves, its direction is mostly determined by practical solutions.",http://dx.doi.org/10.1007/978-3-030-17141-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-10997-4_18,Learning Cheap and Novel Flight Itineraries,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-030-10997-4_18,Springer,2019-01-01,"We consider the problem of efficiently constructing cheap and novel round trip flight itineraries by combining legs from different airlines. We analyse the factors that contribute towards the price of such itineraries and find that many result from the combination of just 30% of airlines and that the closer the departure of such itineraries is to the user’s search date the more likely they are to be cheaper than the tickets from one airline. We use these insights to formulate the problem as a trade-off between the recall of cheap itinerary constructions and the costs associated with building them. We propose a supervised learning solution with location embeddings which achieves an AUC = 80.48, a substantial improvement over simpler baselines. We discuss various practical considerations for dealing with the staleness and the stability of the model and present the design of the machine learning pipeline. Finally, we present an analysis of the model’s performance in production and its impact on Skyscanner’s users.",http://dx.doi.org/10.1007/978-3-030-10997-4_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-32101-7_34,Thinking Like a Fraudster: Detecting Fraudulent Transactions via Statistical Sequential Features,Financial Cryptography and Data Security,10.1007/978-3-030-32101-7_34,Springer,2019-01-01,"Aiming at the increasing threat of fraud in electronic transactions, so far researchers have already proposed many different models. However, few previous studies take advantage of the sequential characteristics of fraudulent transactions. In this paper, by statistical analysis on a real dataset, we discover that partial-order sequential features are able to reflect the intrinsic motivation of fraudsters, e.g., stealing the money as quickly as possible before being intercepted. Based on the sequential features, we propose a novel model, SeqFD (Sequential feature boosting Fraud Detector) , to detect fraudulent transactions real-timely. SeqFD applies a sliding time window strategy to aggregate the historical transactions. In specific, statistical sequential features are computed based on the transactions within the time window. Thus, the raw dataset can be transformed into a feature set. Several classification models are evaluated on the feature set, and finally, XGBoost is validated to be a fast, accurate and robust classifier which fits well with SeqFD . The experiments on real dataset show that the proposed model reaches a 97.2% TPR (True Positive Rate) when FPR (False Positive Rate) is less than 1%. Furthermore, the average time for giving a prediction is 1.5 ms, which meets the real-time requirement in the industry.",http://dx.doi.org/10.1007/978-3-030-32101-7_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-5028-0_6,Natural Language Processing (NLP),Artificial Intelligence Basics,10.1007/978-1-4842-5028-0_6,Springer,2019-01-01,"In 2014, Microsoft launched a chatbot—an AI system that communicates with people—called Xiaoice. It was integrated into Tencent’s WeChat, the largest social messaging service in China. Xiaoice performed quite well, getting to 40 million users within a few years.",http://dx.doi.org/10.1007/978-1-4842-5028-0_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-28954-6_1,Towards Explainable Artificial Intelligence,"Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",10.1007/978-3-030-28954-6_1,Springer,2019-01-01,"In recent years, machine learning (ML) has become a key enabling technology for the sciences and industry. Especially through improvements in methodology, the availability of large databases and increased computational power, today’s ML algorithms are able to achieve excellent performance (at times even exceeding the human level) on an increasing number of complex tasks. Deep learning models are at the forefront of this development. However, due to their nested non-linear structure, these powerful models have been generally considered “black boxes”, Black-Box AI  not providing any information about what exactly makes them arrive at their predictions. Since in many applications, e.g., in the medical domain, such lack of transparency may be not acceptable, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This introductory paper presents recent developments and applications in this field and makes a plea for a wider use of explainable learning algorithms in practice.",http://dx.doi.org/10.1007/978-3-030-28954-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26169-6_4,Payment Authorization in Smart Environments: Security-Convenience Balance,Enterprise Information Systems,10.1007/978-3-030-26169-6_4,Springer,2019-01-01,"One of the major roadblocks to mass adoption of smart environments and IoT services (and IoE in future) is the lack of ubiquitous solutions for passive and at the same time secure payment authorization at physical locations where services are provided. The main research goal of this work is to comprehensively evaluate such system proposed by the authors. When customers approach a point of sale it identifies them using face biometrics. After the order is completed, the system takes advantage of multimodal context-aware payment authorization to make a multi-criteria selection of the authorization method, optimally to make the whole process fully passive. All this enables a controlled balance between payment security and convenience for the client and for the seller. Empirical tests at an existing point of sale have been performed, the usage data have been collected, statistically analyzed and confronted with formulated research hypotheses.",http://dx.doi.org/10.1007/978-3-030-26169-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-11821-1_8,What Is Data Science?,Applied Data Science,10.1007/978-3-030-11821-1_8,Springer,2019-01-01,"Data science, a new discovery paradigm, is potentially one of the most significant advances of the early twenty-first century. Originating in scientific discovery, it is being applied to every human endeavor for which there is adequate data. While remarkable successes have been achieved, even greater claims have been made. Benefits, challenge, and risks abound. The science underlying data science has yet to emerge. Maturity is more than a decade away. This claim is based firstly on observing the centuries-long developments of its predecessor paradigms—empirical, theoretical, and Jim Gray’s Fourth Paradigm of Scientific Discovery (Hey et al., The fourth paradigm: data-intensive scientific discovery Edited by Microsoft Research, 2009) (aka eScience, data-intensive, computational, procedural)—and secondly on my studies of over 150 data science use cases, several data science-based startups, and, on my scientific advisory role for Insight ( https://www.insight-centre.org/ ), a Data Science Research Institute (DSRI) that requires that I understand the opportunities, state of the art, and research challenges for the emerging discipline of data science. This chapter addresses essential questions for a DSRI: What is data science ? What is world-class data science research ? A companion chapter (Brodie, On Developing Data Science, in Braschler et al. (Eds.), Applied data science – Lessons learned for the data-driven business, Springer 2019 ) addresses the development of data science applications and of the data science discipline itself.",http://dx.doi.org/10.1007/978-3-030-11821-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-92447-2_28,Artificial Intelligence Applications,"Operations, Logistics and Supply Chain Management",10.1007/978-3-319-92447-2_28,Springer,2019-01-01,"Automation, machine learning and predictive analytics all adhere to the same objective: improvement of operations, logistics, and supply chain processes by means of enhanced information technology applications and machines. This chapter outlines definitions and connections to operational and strategy questions in supply chain and logistics management for this new and evolving field of research as well as business application. Therefore, first basic developments and definitions of AI applications are described after which a case study is provided. Subsequently, applications of AI in intralogistics as well as core conceptual issues and problems are outlined (basic level). Applications in transportation and elaborate concepts and interactions with other management areas are discussed at a more advanced level. Finally, AI applications in supply chain design as well as an outlook for AI developments relating to logistics are described (state-of-the-art level), followed by suggestions for future topics and further reading material.",http://dx.doi.org/10.1007/978-3-319-92447-2_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-97556-6_5,Information Retrieval and Recommender Systems,Data Science in Practice,10.1007/978-3-319-97556-6_5,Springer,2019-01-01,"This Bellogín, Alejandro chapter Said, Alan provides a brief introduction to two of the most common applications of data science methods in e-commerce: information retrieval and recommender systems. First, a brief overview of the systems is presented followed by details on some of the most commonly applied models used for these systems and how these systems are evaluated. The chapter ends with an overview of some of the application areas in which information retrieval and recommender systems are typically developed.",http://dx.doi.org/10.1007/978-3-319-97556-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-95651-0_3,Data Science and Conversational Interfaces: A New Revolution in Digital Business,Data Science and Digital Business,10.1007/978-3-319-95651-0_3,Springer,2019-01-01,"Recent advances in Artificial Intelligence, Semantic Web and intelligent interaction devices have made conversational interfaces increasingly popular. These advances in technologies including automatic speech recognition and synthesis, natural language understanding and generation, and dialog management are result of decades of work in these areas to make possible a more natural and intuitive communication with machines. In this chapter, we describe the tremendous potential of Data Science to improve the performance of conversational interfaces and increase the number of users of these interfaces. Following this cycle, the more people use these systems, more data is generated to learn their models and improve their performance, thus increasing the number of users and extending the possibilities for new applications in Digital Business.",http://dx.doi.org/10.1007/978-3-319-95651-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-18579-4_26,Online Collaborative Filtering with Implicit Feedback,Database Systems for Advanced Applications,10.1007/978-3-030-18579-4_26,Springer,2019-01-01,"Studying recommender systems with implicit feedback has become increasingly important. However, most existing works are designed in an offline setting while online recommendation is quite challenging due to the one-class nature of implicit feedback. In this paper, we propose an online collaborative filtering method for implicit feedback. We highlight three critical issues of existing works. First, when positive feedback arrives sequentially, if we treat all the other missing items for this given user as the negative samples, the mis-classified items will incur a large deviation since some items might appear as the positive feedback in the subsequent rounds. Second, the cost of missing a positive feedback should be much higher than that of having a false-positive. Third, the existing works usually assume that a fixed model is given prior to the learning task, which could result in poor performance if the chosen model is inappropriate. To address these issues, we propose a unified framework for Online Collaborative Filtering with Implicit Feedback (OCFIF). Motivated by the regret aversion, we propose a divestiture loss to heal the bias derived from the past mis-classified negative samples. Furthermore, we adopt cost-sensitive learning method to efficiently optimize the implicit MF model without imposing a heuristic weight restriction on missing data. By leveraging meta-learning, we dynamically explore a pool of multiple models to avoid the limitations of a single fixed model so as to remedy the drawback of manual/heuristic model selection. We also analyze the theoretical bounds of the proposed OCFIF method and conduct extensive experiments to evaluate its empirical performance on real-world datasets.",http://dx.doi.org/10.1007/978-3-030-18579-4_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-7452-3_31,"Big Data, Cloud Computing, and Internet of Things",Neural Networks and Statistical Learning,10.1007/978-1-4471-7452-3_31,Springer,2019-01-01,"The era of big data has arrived. Big data and cloud computing go hand-in-hand. Internet of things (IoT) has resulted in a hyper-world consisting of the social, cyber, and physical worlds, with data as a bridge. These topics are closely related to data science and are introduced in this chapter.",http://dx.doi.org/10.1007/978-1-4471-7452-3_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-5802-9_87,Classification of Service Robot Environments Using Multimodal Sequence Data,"Emerging Research in Electronics, Computer Science and Technology",10.1007/978-981-13-5802-9_87,Springer,2019-01-01,"The usage of autonomous robots is getting increased day by day. Most of the applications are moving toward automation with the help of robots. This paper mainly focuses on service robots and understanding their working environments. A few robotic scenarios are created using Webots tool, and the data from there are collected as a sequence of images and lidar sensor values. The lidar values are collected with both single layer and multilayer. The environments are analyzed with the help of the collected data. The collected multimodal data are preprocessed in order to reduce the number of features. After that, the collected data are sorted out to suitably characterize each environment, and the machine learning techniques are applied to classify the environments. Different machine learning algorithms like Naive Bayes classifier, support vector machine, decision-tree-like random forest tree, and simple logistic regression are used for the classification, and results are compared with each other.",http://dx.doi.org/10.1007/978-981-13-5802-9_87,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-11821-1_9,On Developing Data Science,Applied Data Science,10.1007/978-3-030-11821-1_9,Springer,2019-01-01,"Understanding phenomena based on the facts—on the data—is a touchstone of data science. The power of evidence-based, inductive reasoning distinguishes data science from science. Hence, this chapter argues that, in its initial stages, data science applications and the data science discipline itself be developed inductively and deductively in a virtuous cycle. The virtues of the twentieth Century Virtuous Cycle (aka virtuous hardware-software cycle, Intel-Microsoft virtuous cycle) that built the personal computer industry (National Research Council, The new global ecosystem in advanced computing: Implications for U.S. competitiveness and national security. The National Academies Press, Washington, DC, 2012) were being grounded in reality and being self-perpetuating—more powerful hardware enabled more powerful software that required more powerful hardware, enabling yet more powerful software, and so forth. Being grounded in reality—solving genuine problems at scale—was critical to its success, as it will be for data science. While it lasted, it was self-perpetuating, due to a constant flow of innovation, and to benefitting all participants—producers, consumers, the industry, the economy, and society. It is a wonderful success story for twentieth Century applied science . Given the success of virtuous cycles in developing modern technology, virtuous cycles grounded in reality should be used to develop data science, driven by the wisdom of the sixteenth Century proverb, Necessity is the mother of invention. This chapter explores this hypothesis using the example of the evolution of database management systems over the last 40 years. For the application of data science to be successful and virtuous, it should be grounded in a cycle that encompasses industry (i.e., real problems), research, development, and delivery. This chapter proposes applying the principles and lessons of the virtuous cycle to the development of data science applications; to the development of the data science discipline itself, for example, a data science method; and to the development of data science education; all focusing on the critical role of collaboration in data science research and management, thereby addressing the development challenges faced by the more than 150 Data Science Research Institutes (DSRIs) worldwide. A companion chapter (Brodie, What is Data Science, in Braschler et al (Eds.), Applied data science – Lessons learned for the data-driven business, Springer 2019 ), addresses essential questions that DSRIs should answer in preparation for the developments proposed here: What is data science ? What is world-class data science research ?",http://dx.doi.org/10.1007/978-3-030-11821-1_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-27325-5_21,Using Disruptive Technologies in Government: Identification of Research and Training Needs,Electronic Government,10.1007/978-3-030-27325-5_21,Springer,2019-01-01,"Over the past years, a number of new technologies have emerged with a potential to disrupt many spheres of the society. While public sector traditionally lacks behind business in innovation, significant changes are anticipated with the use of disruptive technologies. The implementation of the new technologies for the government service provision, along with possible benefits, need to be well thought through and challenges need to be carefully discussed, analysed and evaluated. This paper uses scenario-technique to identify research and training needs for the implementation of disruptive technologies in government services. Using the input of 58 experts from three workshops, research and training needs for the internet of things, artificial intelligence, virtual and augmented reality, as well as big data technologies have been identified. The identified needs can serve as a starting point for a broader and more informed discussion about the knowledge and skills that the researchers and practitioners of digital government need to obtain for the broad use of such new (disruptive) technologies.",http://dx.doi.org/10.1007/978-3-030-27325-5_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02486-3_4,Privacy Implications of Mobile and Pervasive Computing,Privacy in Mobile and Pervasive Computing,10.1007/978-3-031-02486-3_4,Springer,2019-01-01,"In his seminal 1991 Scientific American article, Mark Weiser already cautioned that “hundreds of computers in every room, all capable of sensing people near them and linked by high-speed networks, have the potential to make totalitarianism up to now seem like sheerest anarchy” [Weiser, 1991]. Chapter 3 presented some of the reasons for this: mobile systems come in highly portable form factors that make it easy to always carry them with us; their powerful communication capabilities encourage data offloading to the cloud; the potential of context awareness and novel low-power sensors make continuous data collection the default; and thriving app ecosystems challenge traditional trust relationships. The vision of pervasive systems furthermore makes it difficult to tell when one is detected and potentially recorded by invisible devices; its focus on understanding user intent drives ever expanding data collection; and the ubiquity of smart devices and environments offers the tantalizing promise of better “managing” and “optimizing” society.",http://dx.doi.org/10.1007/978-3-031-02486-3_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-13342-9_20,Deploying Blockchains for a New Paradigm of Media Experience,"Economics of Grids, Clouds, Systems, and Services",10.1007/978-3-030-13342-9_20,Springer,2019-01-01,"In this paper, we demonstrate the multiple points of innovation when combining multimedia content with blockchain technology. As of today, content creators (authors, photographers, radio and video reporters, data visualizers etc.) are publishing and sharing content (articles, photos, audio, video and combinations) on media/social networks but without the effective control over who is going to reuse this content. To this direction, we introduce a blockchain based service which successfully blends different technologies to provide more transparency on how the content is further tracked, promote openness, trust and security between participants, allow direct monetization for the content creator and expose the benefits of using blockchain technology as: a database of multimedia content, a novel payment method while using a dedicated created cryptocurrency, an insurance of proof of ownership through the exploitation of smart contracts running on Ethereum blockchain platform and a means to implement new solutions to value content based on quality. Additionally, by integrating Hyperledger Projects (Fabric, Composer, Explorer), we examine how their functionalities such as private and permissioned blockchain improve our system. Highlighting the importance of applications exploiting blockchain technology to efficiently support, store and retrieve data we utilized, integrated with blockchain and compared different solutions among which InterPlanetary File System (IPFS) and traditional databases such as MongoDB with GridFS tool.",http://dx.doi.org/10.1007/978-3-030-13342-9_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-22948-1_21,Continuous Evaluation of Large-Scale Information Access Systems: A Case for Living Labs,Information Retrieval Evaluation in a Changing World,10.1007/978-3-030-22948-1_21,Springer,2019-01-01,"A/B testing is currently being increasingly adopted for the evaluation of commercial information access systems with a large user base since it provides the advantage of observing the efficiency and effectiveness of information access systems under real conditions. Unfortunately, unless university-based researchers closely collaborate with industry or develop their own infrastructure or user base, they cannot validate their ideas in live settings with real users. Without online testing opportunities open to the research communities, academic researchers are unable to employ online evaluation on a larger scale. This means that they do not get feedback for their ideas and cannot advance their research further. Businesses, on the other hand, miss the opportunity to have higher customer satisfaction due to improved systems. In addition, users miss the chance to benefit from an improved information access system. In this chapter, we introduce two evaluation initiatives at CLEF, NewsREEL and Living Labs for IR (LL4IR), that aim to address this growing “evaluation gap” between academia and industry. We explain the challenges and discuss the experiences organizing theses living labs.",http://dx.doi.org/10.1007/978-3-030-22948-1_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26619-6_24,Design Patterns for Business Process Individualization,Business Process Management,10.1007/978-3-030-26619-6_24,Springer,2019-01-01,"Competition is forcing organizations to constantly innovate and identify ways to deliver high quality services and products. The Business Process Management (BPM) discipline has contributed by providing a rich set of analysis and re-design techniques. However, BPM methods and guidelines are often driven by process standardization and economies of scale, while emerging digital technologies (e.g. advanced manufacturing, sophisticated data analytics) increasingly facilitate process individualization. In this paper we contribute to an extended BPM body of knowledge by presenting design patterns for process individualization. We argue that (1) technological developments have made scalable process variant management viable and that (2) these technologies enable new forms of process individualization altogether. In our research, we identified and analyzed design patterns that make use of rapid digitalization to obtain individualized products and services. A conceptual model supported by literature and case examples is presented. This model forms theory on design and action of business process individualization in the digital age. Companies can deploy the design patterns developed in this paper as guidelines in their quest for process individualization.",http://dx.doi.org/10.1007/978-3-030-26619-6_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-15504-9_2,Learning from Others’ Experience,Artificial Companion for Second Language Conversation,10.1007/978-3-030-15504-9_2,Springer,2019-01-01,"This chapter explains the relationship between the work presented here and the related fields of research at the time of the research described in this book. Three large fields have impact on the presented research: ICALL, NLP and CA. Specific fields using CA for dialogue modelling are also of high relevance for this work. The current state of the art in the area of chatbots and conversational interfaces and the problems with evaluation of the dialogue quality are also discussed. The specific contributions of this research to each area are highlighted in each section.",http://dx.doi.org/10.1007/978-3-030-15504-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4828-7_4,Monitoring Azure Service Fabric Clusters,Building Microservices Applications on Microsoft Azure,10.1007/978-1-4842-4828-7_4,Springer,2019-01-01,"In the previous chapter, you learned the core concepts of Service Fabric, such as the application model, application scaling, supported programming models, and clusters. Service Fabric very effectively streamlines an application, cluster deployment, and the scaling of applications. In this chapter, you discover how you can effectively monitor a Service Fabric cluster and the applications deployed on it. We will create an ASP.NET Core-based application to demonstrate how easy it is to add application monitoring, and use Application Insights to troubleshoot issues in database calls and remote HTTP calls.",http://dx.doi.org/10.1007/978-1-4842-4828-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-04299-8_2,Chatbot Components and Architectures,Developing Enterprise Chatbots,10.1007/978-3-030-04299-8_2,Springer,2019-01-01,"In the Introduction, we discussed that chatbot platforms offered by enterprises turned out to be good for simple cases, not really enterprise-level deployments. In this chapter we make a first step towards industrial–strength chatbots. We will outline the main components of chatbots and show various kinds of architectures employing these components. The descriptions of these components will be the reader’s starting points to learning them in-depth in the consecutive chapters. Building a chatbot for commercial use via data-driven methods poses two main challenges. First is broad-coverage: modeling natural conversation in an unrestricted number of topics is still an open problem as shown by the current concentration of research on dialogues in restricted domains. Second is the difficulty to get a clean, systematic, unbiased and comprehensive datasets of open-ended and task-oriented conversations, which makes it difficult for chatbot improvement and limits the viability of using purely data-driven methods such as neural networks. We will explore the usability of rule-based and statistical machine learning - based dialogue managers, the central component in a chatbot architecture. We conclude this chapter by illustrating specific learning architectures, based on active and transfer learning.",http://dx.doi.org/10.1007/978-3-030-04299-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-15035-8_102,Cost Benefits of Multi-cloud Deployment of Dynamic Computational Intelligence Applications,"Web, Artificial Intelligence and Network Applications",10.1007/978-3-030-15035-8_102,Springer,2019-01-01,"Cost savings is one of the main motivations for deploying commercial applications in the Cloud. These savings are more pronounced for applications with varying computational needs, like Computational Intelligence (CI) applications. However, continuously deploying, adapting, and decommissioning the provided Cloud resources manually is challenging, and autonomous deployment support is necessary. This paper discusses the specific challenges of CI applications and provide calculations to show that dynamic use of Cloud resources will result in significant cost benefits for CI applications.",http://dx.doi.org/10.1007/978-3-030-15035-8_102,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30490-4_15,DCAR: Deep Collaborative Autoencoder for Recommendation with Implicit Feedback,Artificial Neural Networks and Machine Learning – ICANN 2019: Text and Time Series,10.1007/978-3-030-30490-4_15,Springer,2019-01-01,"In recent years, deep neural networks have been widely applied to recommender systems. Although there are extensive explorations of deep neural networks on the collaborative filtering problem in item recommendation, most of the existing methods employ a similar loss function, i.e., the prediction loss of user-item interactions, and only change the form of the input, which may limit the model’s performance. To address this problem, we present a novel framework, named DCAR , short for D eep C ollaborative A utoencoder for R ecommendation. Specifically, with the implicit feedback matrix as the input, we employ the autoencoder module to obtain the latent representations of users and items respectively. Then, to predict the matching score of corresponding user-item pairs, an interaction prediction module is designed based on the neural network architecture. The two parts are coupled together and employ alternating training to learn. We conduct extensive experiments on several real-world datasets and the results empirically verify the superior performance of DCAR on item recommendation. The code related to this paper is available at: https://github.com/strange-jiong/DCAR .",http://dx.doi.org/10.1007/978-3-030-30490-4_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-4335-0_1,Introduction to PySpark SQL,PySpark SQL Recipes,10.1007/978-1-4842-4335-0_1,Springer,2019-01-01,"The amount of data that’s generated increases every day. Technology advances have facilitated the storage of huge amounts of data. This data deluge has forced users to adopt to the distributed system. Distributed systems look for distributed programming, which require extra care for fault tolerance and efficient algorithms. Distributed systems always look for two things—reliability on the system and availability of all the components.",http://dx.doi.org/10.1007/978-1-4842-4335-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26169-6_5,An Intelligent and Data-Driven Decision Support Solution for the Online Surgery Scheduling Problem,Enterprise Information Systems,10.1007/978-3-030-26169-6_5,Springer,2019-01-01,"In operational business situations it is necessary to be aware of and to understand what happens around you and what probably will happen in the near future to make optimal decisions. For example, Online Surgery Scheduling is the planning and control task of Operating Room Management and includes decisions that are difficult to deal with due to high cognitive and communicational efforts to gather the needed information. In addition, several uncertainties like complications, cancellations and emergencies as well as the need to monitor and control the interventions during execution distinguish the operational decision tasks in surgery scheduling from the tactical and strategical planning decisions. However, the emerging trend of connecting devices and intelligent methods in analytics, facilitate innovative approaches for decision support in this area. With the utilization of these concepts, we propose a data-driven approach for a Decisions Support System including components for monitoring, prediction and optimization in Online Surgery Scheduling.",http://dx.doi.org/10.1007/978-3-030-26169-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-2628-8_12,Case X: IBM and Cognitive Healthcare: Smart Healthcare Based on Cognitive Computing,Emerging Champions in the Digital Economy,10.1007/978-981-13-2628-8_12,Springer,2019-01-01,"As an information technology company with over a hundred years of history, IBM sets itself a clear path in the healthcare industry. From traditional healthcare, to smart healthcare, then to cognitive healthcare, IBM keeps holding on to its “Healthcare Dream”.",http://dx.doi.org/10.1007/978-981-13-2628-8_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-13342-9_5,An Evaluation of a Market Based Resource Trading in a Multi-campus Compute Co-operative (CCC),"Economics of Grids, Clouds, Systems, and Services",10.1007/978-3-030-13342-9_5,Springer,2019-01-01,"Computational and data scientists at universities are often limited by the quantity and diversity of the shared resources available at their institution. Access cost for these resources are often uniform, that is, it is not differentiated based on job priority or resource requirements. This flat access policy on shared resources often lead to sub-optimal values for the institutions, and researchers with special requirements (i.e. GPU, large-memory, etc.) often have to wait significantly longer to get their job scheduled. A market-based resource trading in a multi-campus Compute Co-operative can lead to higher aggregated value for the co-operative as well as provide significant benefits for the individual institutions by scheduling jobs opportunistically when resources of one campus are over-subscribed and by placing jobs efficiently based on resource requirements. In this paper, we evaluate a resource allocation scheme in a multi-campus environment, (i.e. CCC [ 10 ]) based on job priority and resource cost, with the provision for resource trading between campuses. We collected real data traces from three (3) universities over a month and conducted a simulation to evaluate the effectiveness of our resource trading approach over the existing single institution flat rate allocation policy. Our simulation shows that, with CCC and market-based resource trading, the aggregated institutional value for the co-operative increases by 15% and the average wait time for the jobs reduce by 49%.",http://dx.doi.org/10.1007/978-3-030-13342-9_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02318-7_7,Systems and Data Pipelines,The Practice of Crowdsourcing,10.1007/978-3-031-02318-7_7,Springer,2019-01-01,"In this chapter we describe some examples of systems and data pipelines in different domains that contain human computation as an important component. Unfortunately, we cannot present a comprehensive list of existing systems. Instead, we describe examples that use crowdsourcing in a novel way starting with applications that utilize a commercial platform and later introduce systems that are designed around crowd-based computation.",http://dx.doi.org/10.1007/978-3-031-02318-7_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-04299-8_11,Discourse-Level Dialogue Management,Developing Enterprise Chatbots,10.1007/978-3-030-04299-8_11,Springer,2019-01-01,"In this Chapter we learn how to manage a dialogue relying on discourse of its utterances. We first explain how to build an invariant discourse tree for a corpus of texts to arrange a chatbot-facilitated navigation through this corpus. We define extended discourse trees, introduce means to manipulate with them, and outline scenarios of multi-document navigation. We then show how a dialogue structure can be built from an initial utterance. After that, we introduce imaginary discourse tree to address a problem of involving background knowledge on demand, answering questions. Finally, an approach to dialogue management based on lattice walk is described.",http://dx.doi.org/10.1007/978-3-030-04299-8_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-0094-7_7,Social Semantic Web Mining and Big Data Analytics,"Big Data Analytics: Systems, Algorithms, Applications",10.1007/978-981-15-0094-7_7,Springer,2019-01-01,"In the context of Big Data Analytics and Social Networking, Semantic Web Mining is an amalgamation of three scientific areas of research: (1) Social Networking (2) Semantic Web and (3) Big Data Analytics, including Web Mining and Data Mining.",http://dx.doi.org/10.1007/978-981-15-0094-7_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-13342-9_2,Applying Auctions to Bank Holding Company Software Project Portfolio Selection,"Economics of Grids, Clouds, Systems, and Services",10.1007/978-3-030-13342-9_2,Springer,2019-01-01,"Large banks in the United States are often organized as bank holding companies controlling one or more subsidiaries. Their inorganic growth has led to duplicated capacity. In pursuit of cost savings, many holding companies provide shared services, including software development. Demand for development resources generally exceeds supply, leading to the need for a centralized project selection process. The selection methodology chosen is sometimes based on a resource constraint problem, using projected financials provided by the subsidiaries. This solution architecture is susceptible to misaligned incentives. We propose the use of a combinatorial auction to assist in project selection and more closely align the incentives of executives to those of the bank. We discuss appropriate auction formats for the contest based on the economic characteristics of the problem and explore impediments to implementation.",http://dx.doi.org/10.1007/978-3-030-13342-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-7440-0_39,Internet of Things: An Opportunity for Advancing Universal Access,Web Accessibility,10.1007/978-1-4471-7440-0_39,Springer,2019-01-01,"IoT enables the worldwide connection of heterogeneous things or objects, which can hence interact with each other and cooperate with their neighbors to reach common goals, by using different communication technologies and communication protocol standards. IoT and related technologies can increase or reduce the gap among people. In this respect, this chapter aims to highlight the virtuose use of the IoT paradigm by providing examples of its application for enhancing universal access in different fields.",http://dx.doi.org/10.1007/978-1-4471-7440-0_39,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-93061-9_6,Big Data in Agricultural and Food Research: Challenges and Opportunities of an Integrated Big Data E-infrastructure,Big Data for the Greater Good,10.1007/978-3-319-93061-9_6,Springer,2019-01-01,"Agricultural and food research are increasingly becoming fields where data acquisition, processing, and analytics play a major role in the provision and application of novel methods in the general context of agri-food practices. The chapter focuses on the presentation of an innovative, holistic e-infrastructure solution that aims to enable researches for distinct but interconnected domains to share data, algorithms and results in a scalable and efficient fashion. It furthermore discusses on the potentially significant impact that such infrastructures can have on agriculture and food management and policy making, by applying the proposed solution in variegating agri-food related domains.",http://dx.doi.org/10.1007/978-3-319-93061-9_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-92447-2_27,Multi-agent Systems,"Operations, Logistics and Supply Chain Management",10.1007/978-3-319-92447-2_27,Springer,2019-01-01,"Within a Multi-Agent System (MAS), multiple autonomous agents negotiate, cooperate, and perform actions based on the goals and preferences of the (real-world) entities they represent. This chapter provides an introduction into MASs. In Sect.  27.1 , on the basic level, we introduce the concept of agents and MASs, address their history, formally define MASs, and provide an overview of associated design methodologies. We illustrate one of these design methodologies using a case study of the use of Automated Guided Vehicles (AGVs) for trailer docking at a distribution centre. Next, we specifically focus on the use of MASs for manufacturing and logistics. First, in Sect.  27.2 , on the advanced level, we discuss MASs for controlling the logistics processes within a company. We provide the motivation for using MASs in these environments, briefly review the literature on this topic, and present a case study on MAS control of AGVs in an industrial bakery. Next, in Sect.  27.3 , on the state-of-the-art level, we focus on MASs to align the processes between different companies. We provide a brief overview of existing applications, describe the main challenges involved in inter-company MASs, and present a case study on MASs in the Port of Rotterdam.",http://dx.doi.org/10.1007/978-3-319-92447-2_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-21290-2_28,A Method to Improve the Early Stages of the Robotic Process Automation Lifecycle,Advanced Information Systems Engineering,10.1007/978-3-030-21290-2_28,Springer,2019-01-01,"The robotic automation of processes is of much interest to organizations. A common use case is to automate the repetitive manual tasks (or processes) that are currently done by back-office staff through some information system (IS). The lifecycle of any Robotic Process Automation (RPA) project starts with the analysis of the process to automate. This is a very time-consuming phase, which in practical settings often relies on the study of process documentation. Such documentation is typically incomplete or inaccurate, e.g., some documented cases never occur, occurring cases are not documented, or documented cases differ from reality. To deploy robots in a production environment that are designed on such a shaky basis entails a high risk. This paper describes and evaluates a new proposal for the early stages of an RPA project: the analysis of a process and its subsequent design. The idea is to leverage the knowledge of back-office staff, which starts by monitoring them in a non-invasive manner. This is done through a screen-mouse-key-logger, i.e., a sequence of images, mouse actions, and key actions are stored along with their timestamps. The log which is obtained in this way is transformed into a UI log through image-analysis techniques (e.g., fingerprinting or OCR) and then transformed into a process model by the use of process discovery algorithms. We evaluated this method for two real-life, industrial cases. The evaluation shows clear and substantial benefits in terms of accuracy and speed. This paper presents the method, along with a number of limitations that need to be addressed such that it can be applied in wider contexts.",http://dx.doi.org/10.1007/978-3-030-21290-2_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-29962-0_29,Testing for Integrity Flaws in Web Sessions,Computer Security – ESORICS 2019,10.1007/978-3-030-29962-0_29,Springer,2019-01-01,"Web sessions are fragile and can be attacked at many different levels. Classic attacks like session hijacking, session fixation and cross-site request forgery are particularly dangerous for web session security, because they allow the attacker to breach the integrity of honest users’ sessions by forging requests which get authenticated on the victim’s behalf. In this paper, we systematize current countermeasures against these attacks and the shortcomings thereof, which may completely void protection under specific assumptions on the attacker’s capabilities. We then build on our security analysis to introduce black-box testing strategies to discover insecure session implementation practices on existing websites, which we implement in a browser extension called Dredd. Finally, we use Dredd to assess the security of 20 popular websites from Alexa, exposing a number of session integrity flaws.",http://dx.doi.org/10.1007/978-3-030-29962-0_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-22482-0_4,Robots in the Classroom,Innovations for Community Services,10.1007/978-3-030-22482-0_4,Springer,2019-01-01,"The field of mobile robotics has a long tradition and due to recent developments, we expect a huge potential for the future. Expertise in the area of mobile robotics is important for computer science students. The topic has many connections to different other computer science areas such as computer vision, algorithms, planning, world modeling and machine learning but is also related to basic fields such as mathematics, geometry, statistics, graph theory and optimization techniques. Students have to consider hardware and real-time issues, meanwhile they have to deal with uncertainty of data that are based on sensors. Software development differs from typical desktop, office or client-server developments that often are in focus of computer science studies. As a consequence, academic courses on mobile robotics differ in many ways from other courses. A major issue: we have to get the students very quickly to a point to achieve progress in their projects. Moreover, the teacher has to have an environment to manage the different facets of the complex topics.",http://dx.doi.org/10.1007/978-3-030-22482-0_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-71288-8_10,Marketing of Media and Information,Managing Media and Digital Organizations,10.1007/978-3-319-71288-8_10,Springer,2019-01-01,"The marketing of media products and services differ from the marketing of other products in a variety of ways, in particular because it is often two-sided: it requires the promotion of media products to end users and for the promotion of the media outlet to advertisers. The authors discuss the role of marketing in the product design. The analysis of positioning requires demand and audience studies, diffusion models, competitor analysis, and branding. Several dimensions of promotion are then discussed: timing; word of mouth; publicity and public relations; and product placement. The authors then look at advertising: optimal budgets and the mix of media choices. Critical to success is promotion to advertisers, retailers, and distributors, all with their own techniques. These marketing activities have been impacted by the Internet with its new tools and approaches. The authors then analyze the promotion of media products—film, TV channels, music, books, newspapers, magazines, videogames, and technology. Next discussed is the regulation of marketing. The authors conclude by investigating marketing performance tools. The issues are highlighted by a case discussion on the marketing efforts for a planned magazine by Condé Nast.",http://dx.doi.org/10.1007/978-3-319-71288-8_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-10889-2_1,Characterising Social Machines,The Theory and Practice of Social Machines,10.1007/978-3-030-10889-2_1,Springer,2019-01-01,"This opening chapter introduces the idea of social machines. The metaphor of a machine is introduced, and it is explained how it applies to social groups connected through digitally networked technologies, ubiquitous devices and large quantities of data. Social machines enable mechanistic explanations of social phenomena, without the reductionist claim that these social groups are determined by the technology. Building blocks of the social machines concept are enumerated and described, including heterogeneous human-computer networks, social computing, communication, platforms and communities, ecosystems of social machines, dynamics of networks and various ethical concepts. Examples of social machines are introduced, including Wikipedia, citizen science social machines such as Zooniverse and Eyewire, healthcare social machines and Pokémon Go! After considering ways of classifying social machines, and contrasting social machines with similar concepts such as crowdsourcing and social computing, it is argued that producing a definition of social machines would be counterproductive, such is the fluidity of the concept and its social and technical contexts. Instead, the book will consider how technologically enabled social groups can be studied through a social machine lens.",http://dx.doi.org/10.1007/978-3-030-10889-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05819-7_14,Exploring European Cultural Heritage Using Conversational Agents,VR Technologies in Cultural Heritage,10.1007/978-3-030-05819-7_14,Springer,2019-01-01,"The semantic web and open data paradigms are gaining momentum in recent years and more information is being published online following the linked data principles. This enables easy access and processing of data by external services. An example of such services are intelligent conversational agents that provide to the users the ability to interact with a computer system in natural language. Such communication is much more intuitive and facilitates the use of complex services to less skilled users (e.g., elderly) or users with disabilities (e.g., visually impaired) thus providing to these groups access to the huge amount of information stored in the semantic web or specific online services. In this paper, we present a proof-of-concept conversational agent able to provide information about the European cultural heritage and display stored digital content from the Europeana database.",http://dx.doi.org/10.1007/978-3-030-05819-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-00262-6_11,Software Engineering of Self-adaptive Systems,Handbook of Software Engineering,10.1007/978-3-030-00262-6_11,Springer,2019-01-01,"Modern software systems are expected to operate under uncertain conditions, without interruption. Possible causes of uncertainties include changes in the operational environment, dynamics in the availability of resources, and variations of user goals. The aim of self-adaptation is to let the system collect additional data about the uncertainties during operation. The system uses the additional data to resolve uncertainties, to reason about itself, and based on its goals to reconfigure or adjust itself to satisfy the changing conditions, or if necessary to degrade gracefully. In this chapter, we provide a particular perspective on the evolution of the field of self-adaptation in six waves. These waves put complementary aspects of engineering self-adaptive systems in focus that synergistically have contributed to the current knowledge in the field. From the presented perspective on the field, we outline a number of challenges for future research in self-adaptation, both in a short and long term.",http://dx.doi.org/10.1007/978-3-030-00262-6_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-28464-0_1,Non-technical Challenges of Industry 4.0,Collaborative Networks and Digital Transformation,10.1007/978-3-030-28464-0_1,Springer,2019-01-01,"Cyber-physical systems, Industry 4.0, and Economy 4.0 are defined as current trends in industrial manufacturing and more broadly – in economy and society. Three non-technical challenges are distinguished: (1) a challenge to future employees requiring new educational methods; (2) a challenge to fixing errors in complex software and training datasets; and finally (3) a challenge to responsibility of complex software designers, developers and integrators. These challenges may be considered as directions of future research on Industry 4.0 and Economy 4.0. All these challenges have roots in technology, but they have far social consequences.",http://dx.doi.org/10.1007/978-3-030-28464-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5454-9_15,Health Information Technology and Its Evolution in Australian Hospitals,Textbook of Medical Administration and Leadership,10.1007/978-981-10-5454-9_15,Springer,2019-01-01,"Information technology has altered many aspects of our lives. Healthcare has accelerated its adoption primarily with the aim to reduce health system inefficiencies and improve the quality and safety of healthcare delivery. The burgeoning and seasoned medical administrator is likely to encounter more and more transformational programs where health information technology plays a significant role. This chapter focuses on key principles of a typical Electronic Medical Record (EMR) implementation, with a practical case study of Australia’s first fully integrated digital hospital at St Stephen’s Hospital Hervey Bay, from the perspective of a Chief Medical Information Officer. This will equip medical administrators with a base level of expertise to support these endeavours within their organisations and serve as a preliminary introduction to health information technology.",http://dx.doi.org/10.1007/978-981-10-5454-9_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-34872-4_32,A Hybrid Framework for Improving Diversity and Long Tail Items in Recommendations,Pattern Recognition and Machine Intelligence,10.1007/978-3-030-34872-4_32,Springer,2019-01-01,"In today’s information overloaded era, recommender system is a necessity and it is widely used in most of the domains of e-commerce. Over the years, recommender system is improved to meet the main purpose of achieving better user experience, where accuracy is considered as one of the important aspects in its design. However, other aspects such as diversity, long tail item recommendation, novelty and serendipity are equally important while providing recommendations to the users. Research to improve above mentioned aspects is limited. In this paper, we propose an efficient approach to improve diversity and long tail item recommendations. The experiments are conducted on two real world movie rating datasets namely, MovieLens and Netflix. Experimental analysis shows that the proposed method outperforms the state-of-the art approaches in recommending diverse and long tail items.",http://dx.doi.org/10.1007/978-3-030-34872-4_32,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30000-5_84,Situation Awareness for Effective Production Control,Advances in Production Management Systems. Production Management for the Factory of the Future,10.1007/978-3-030-30000-5_84,Springer,2019-01-01,"Situation awareness is a growing need for manufacturing operators with the digital transformation of manufacturing environments where operators are expected to take larger responsibilities and tasks on the production flow. To make effective production control decisions, workers need to be aware of the situation that consists of multiple factors such as the production status, and internal and external demand requirements. Adapting existing models for situation awareness, this paper presents four case examples of manufacturing companies that implement digital technologies for situation awareness.",http://dx.doi.org/10.1007/978-3-030-30000-5_84,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03405-4_38,Intelligent Communication Between IoT Devices on Edges in Retail Sector,Advances in Information and Communication Networks,10.1007/978-3-030-03405-4_38,Springer,2019-01-01,"In this paper, we have designed a custom communication model for IoT devices on its edges to induce intelligence in the retail sector. Wireless technologies, such as RFID (Radio Frequency Identification), NFC (Near Field Communication), needed BLE (Bluetooth Low Energy), and LPWAN (Low-Power Wide-Area Network), etc. were delegated to perform various tasks within the available services. We introduce Smart Shop (SmSH) architecture that integrates features of context-aware services, platform independent, edge computing and proximity sensing to establish seamless connectivity for the customer entrusted tasks. This architecture should encompass the M2M communication devices and gateways which are generally connected to the cloud environment to establish meaningful communication in commercial IoT applications. Our architecture has been proposed primarily for the retail sector and can be extended easily to other domains by altering the required functionalities, device types and services.",http://dx.doi.org/10.1007/978-3-030-03405-4_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-8797-4_23,"Hadoop Based Architecture for a Smart, Secure and Efficient Insurance Solution Using IoT","Integrated Intelligent Computing, Communication and Security",10.1007/978-981-10-8797-4_23,Springer,2019-01-01,"The “Internet of Things” (IoT) is among the most highly subsidized and promising topics in both academia and industry these days. Contemporary developments in digital technology have raised the interest of many researchers towards implementation in this area. The influence of IoT within the insurance field is vital. This chapter asserts an innovative concept of IoT pooled with an insurance application, which is beneficial for insurance companies to monitor and analyze the health of their clients continuously. Numerous insurance companies are clustered together to provide a standardized health status monitoring of clients. Since there is a large amount data generated by the system, we adopt Hadoop in the background to map the data effectively and to reduce it into a simpler format. We assimilate Sqoop tool to enable data transfer between Hadoop and RDBMS, in consort with Apache Hive for providing a database query interface to the Hadoop. By consuming the output from Hadoop MapReduce, a non-probabilistic binary linear classifier predicts the policyholder’s chances of developing some health problems. Ultimately, the resultant outcomes are presented on the user’s smartphones. The Apache Ranger framework interweaved with the Hadoop ecosystem aims to ensure data confidentiality. The endowments are granted to the policy holders based on the health report generated by our system. To evaluate the efficiency of the system, experiments are conducted using various policyholder’s health datasets and from the results, it is observed that SVM predicts sepsis with an accuracy of approximately 86%. While testing with the medical dataset, SVM proved to be more accurate than the C4.5 algorithm.",http://dx.doi.org/10.1007/978-981-10-8797-4_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-98512-1_25,Leveraging Big Data Platform Technologies and Analytics to Enhance Smart City Mobility Services,"Handbook of Service Science, Volume II",10.1007/978-3-319-98512-1_25,Springer,2019-01-01,"The Internet of Things (IoT) allows objects to be sensed and managed over networks, creating opportunities for beneficial interactions and integration between the physical world, computer-based systems, and human beings. The recently enabled people-centric sensing or social sensing transforms how we sense and interact with the world. For instance, social sensing via mobile apps complements physical sensing (e.g., IoT) by substantially extending the horizon we know about our living communities and environments in real time. This chapter presents how we can integrate physical and social sensing to enable better and smarter services in great detail. With the support of big data technologies, we use city mobility services to demonstrate the great potential of the proposed data integration and aggregation. Specifically, real time data from Citi Bike and Twitter.com are collected, processed, and modelled. The developed prototype in support of city mobility management and operations shows numerous potential benefits of the proposed digital ecosystem platform.",http://dx.doi.org/10.1007/978-3-319-98512-1_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-77525-8_240,Network Big Data Security Issues,Encyclopedia of Big Data Technologies,10.1007/978-3-319-77525-8_240,Springer,2019-01-01,,http://dx.doi.org/10.1007/978-3-319-77525-8_240,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-04173-1_8,IoT-Based Ambient Intelligence Microcontroller for Remote Temperature Monitoring,Guide to Ambient Intelligence in the IoT Environment,10.1007/978-3-030-04173-1_8,Springer,2019-01-01,"The aim of this book chapter is to provide a comprehensive assessment of the ambient intelligence ( AmI AmI ) microcontrollers suitable for low-power Internet of things ( IoT IoT ) applications. The current challenges and trends in the evolution of low-power and high-performance microcontroller are also explored. The key focus is on the performance analysis of such devices as they facilitate the IoT vision with increased reliability. A detailed discussion of various microcontrollers, their architectures, low-power modes, and available temperature monitoring systems is also provided. In this context, design and architecture of a low-powered microcontroller is proposed and TCAD TCAD simulations are carried out for a better understanding of the suggested system. The intended audience is expected to be research and scientific community working in the field of IoT-based smart and intelligent microcontrollers for environmental study applications. The book chapter could be used for a course of higher education and for researchers in the fields of computer science, microelectronics Microelectronics , nanotechnology, and VLSI VLSI design. The microcontroller features and content related to IoT, as presented in this contribution, will hopefully be most valuable to the readers to understand the underlying concepts and to develop advanced high-performance circuits and systems. Illustrations, tables, and figures are also provided to supplement the text.",http://dx.doi.org/10.1007/978-3-030-04173-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-93940-7_4,Sustainable Cloud Computing Realization for Different Applications: A Manifesto,Digital Business,10.1007/978-3-319-93940-7_4,Springer,2019-01-01,"In cloud computing, an application design plays an important role and the efficient structure of an application can increase the energy-efficiency and sustainability of cloud datacenters. To make the infrastructure eco-friendly, energy-efficient and sustainable, there is a need for innovative applications. In this chapter, we comprehensively analyze the challenges in sustainable cloud computing and review the current developments for different applications. We propose a taxonomy of application management for sustainable cloud computing and identified research challenges. We also map the existing related studies to the taxonomy in order to identify current search gaps in the area of application management for sustainable cloud computing. Furthermore, we propose open research challenges for sustainable cloud computing based on the observations.",http://dx.doi.org/10.1007/978-3-319-93940-7_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-018-6094-2,Enhancing touch behavioral authentication via cost-based intelligent mechanism on smartphones,Multimedia Tools and Applications,10.1007/s11042-018-6094-2,Springer,2018-12-01,"Due to the popularity of smartphones, there is a great need to deploy appropriate authentication mechanisms to safeguard users’ sensitive data. Touch dynamics-based authentication has been developed to verify smartphone users and detect imposters. These schemes usually employ machine learning techniques to detect behavioral anomalies by comparing current behavioral actions with the stored normal model. However, we notice that machine learning classifiers often have an unstable performance, which would greatly reduce the system usability, i.e., causing a high false rejection. In this work, we are motivated by this challenge and design a cost-based intelligent mechanism that can choose a less costly algorithm for user authentication. In the evaluation, we conduct a user study with a total of 60 users to investigate the performance of our mechanism with a lightweight touch gesture-based scheme on smartphones. Experimental results demonstrate that our approach can help achieve a relatively higher and more stable authentication accuracy, as compared to the use of a sole classifier.",http://dx.doi.org/10.1007/s11042-018-6094-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42044-018-0024-3,"Construing the big data based on taxonomy, analytics and approaches",Iran Journal of Computer Science,10.1007/s42044-018-0024-3,Springer,2018-12-01,"Big data have become an important asset due to its immense power hidden in analytics. Every organization is inundated with colossal amount of data generated with high speed, requiring high-performance resources for storage and processing, special skills and technologies to get value out of it. Sources of big data may be either internal or external to organization, and big data may reside in structured, semi-structured or unstructured form. Artificial intelligence, Internet of Things, and social media are contributing to the growth of big data. Analytics is the use of statistics, maths, and machine learning to derive meaningful insights from data to make timely decisions and enable data-driven organization of the future. This paper sheds light upon big data, taxonomy of data, and hierarchical journey of data from its original form to the high level understanding in terms of wisdom. The paper also focuses on key characteristics of big data and challenges of handling big data. In addition, big data storage systems have also been briefly covered to get the idea on how storage systems help to accommodate the requirements of big data. This paper scrupulously articulates the eras of evolution of analytics varying from descriptive, predictive and prescriptive analytics. Process models used for inferring information from data have been compared and their applicability for analyzing big data has also been sought. Finally, recent developments carried in the domain of big data and analytics are compared based on the state-of-the-art approaches.",http://dx.doi.org/10.1007/s42044-018-0024-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11023-018-9479-0,An Analysis of the Interaction Between Intelligent Software Agents and Human Users,Minds and Machines,10.1007/s11023-018-9479-0,Springer,2018-12-01,"Interactions between an intelligent software agent (ISA) and a human user are ubiquitous in everyday situations such as access to information, entertainment, and purchases. In such interactions, the ISA mediates the user’s access to the content, or controls some other aspect of the user experience, and is not designed to be neutral about outcomes of user choices. Like human users, ISAs are driven by goals, make autonomous decisions, and can learn from experience. Using ideas from bounded rationality (and deploying concepts from artificial intelligence, behavioural economics, control theory, and game theory), we frame these interactions as instances of an ISA whose reward depends on actions performed by the user. Such agents benefit by steering the user’s behaviour towards outcomes that maximise the ISA’s utility, which may or may not be aligned with that of the user. Video games, news recommendation aggregation engines, and fitness trackers can all be instances of this general case. Our analysis facilitates distinguishing various subcases of interaction (i.e. deception, coercion, trading, and nudging), as well as second-order effects that might include the possibility for adaptive interfaces to induce behavioural addiction, and/or change in user belief. We present these types of interaction within a conceptual framework, and review current examples of persuasive technologies and the issues that arise from their use. We argue that the nature of the feedback commonly used by learning agents to update their models and subsequent decisions could steer the behaviour of human users away from what benefits them, and in a direction that can undermine autonomy and cause further disparity between actions and goals as exemplified by addictive and compulsive behaviour. We discuss some of the ethical, social and legal implications of this technology and argue that it can sometimes exploit and reinforce weaknesses in human beings.",http://dx.doi.org/10.1007/s11023-018-9479-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41872-018-0051-y,Digitization for reliable and efficient manufacturing,Life Cycle Reliability and Safety Engineering,10.1007/s41872-018-0051-y,Springer,2018-12-01,"Manufacturing is an important economic activity and all manufacturers are fiercely vying to grab the scarce market space using quality and price competitiveness to achieve their objectives. The paper highlights digitization as a means to achieve greater reliability and efficiency in manufacturing operations. Mathematical models capable of analyzing enormous data using statistics and optimization algorithms along with the development of affordable electronics and software algorithms does translate manufacturing from traditional to one that is data driven. Digitization does lead to enhanced efficiency in manufacturing operations. The shortcoming of these is that, it needs cultural change, which is difficult, but not impossible to implement in a manufacturing system. The methodologies explained might enable practicing managers to translate their manufacturing systems into ones that are data driven, reliable and efficient. Though there are evidences that suggest the use of data analytics in other domains, such as e-commerce, but the technology has not yet been exploited for data-based manufacturing. The manuscript gives an insight into how digitization can act as a driver for higher reliability and efficiency in manufacturing domain. The paper attempts to fill this gap. The methodologies explained in the manuscript may act as a good guide for practicing operational managers.",http://dx.doi.org/10.1007/s41872-018-0051-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-017-9800-0,"Personality, User Preferences and Behavior in Recommender systems",Information Systems Frontiers,10.1007/s10796-017-9800-0,Springer,2018-12-01,"This paper reports on a study of 1840 users of the MovieLens recommender system with identified Big-5 personality types. Based on prior literature that suggests that personality type is a stable predictor of user preferences and behavior, we examine factors of user retention and engagement, content preferences, and rating patterns to identify recommender-system related behaviors and preferences that correlate with user personality. We find that personality traits correlate significantly with behaviors and preferences such as newcomer retention, intensity of engagement, activity types, item categories, consumption versus contribution, and rating patterns.",http://dx.doi.org/10.1007/s10796-017-9800-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-018-2817-4,An empirical study of web browsers’ resistance to traffic analysis and website fingerprinting attacks,Cluster Computing,10.1007/s10586-018-2817-4,Springer,2018-12-01,"Anonymity protocols are employed to establish encrypted tunnels to protect the privacy of Internet users from traffic analysis attacks. However, the attackers strive to infer some traffic patterns’ characteristics (e.g. packet directions, packet sizes, inter-packet timing, etc.) in order to expose the identities of Internet users and their activities. A recent and popular traffic analysis attack is called website fingerprinting which reveals the identity of websites visited by target users. Existing work in the literature studied the website fingerprinting attack using a single web browser, namely Firefox. In this paper we propose a unified traffic analysis attack model composed of a sequence of phases that demonstrate the efficiency of website fingerprinting attack using popular web browsers under Tor (The Onion Router). In addition, we reveal the main factors that affect the accuracy of website fingerprinting attack over Tor anonymous system and using different browsers. To the best of our knowledge, no previous study uncovered such factors by deploying real-world traffic analysis attack utilizing the top five web browsers. The outcomes of the research are very relevant to Internet users (individuals/companies/governments) since they allow to assess to which extent their privacy is preserved in presence of traffic analysis attacks, in particular, website fingerprinting over different browsers. A recommendation for future research direction regarding the investigation of website fingerprinting over different scenarios is also provided.",http://dx.doi.org/10.1007/s10586-018-2817-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40264-018-0719-2,"18th ISoP Annual Meeting “Pharmacovigilance without borders” Geneva, Switzerland, 11–14 November, 2018",Drug Safety,10.1007/s40264-018-0719-2,Springer,2018-11-01,,http://dx.doi.org/10.1007/s40264-018-0719-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/nbt.4267,How user intelligence is improving PubMed,Nature Biotechnology,10.1038/nbt.4267,Nature,2018-11-01,"Machine learning and natural language processing methods are applied to learn from PubMed searches and improve user experience. PubMed is a widely used search engine for biomedical literature. It is developed and maintained by the US National Library of Medicine/National Center for Biotechnology Information and is visited daily by millions of users around the world. For decades, PubMed has used advanced artificial intelligence technologies that extract patterns of collective user activity, such as machine learning and natural language processing, to inform the algorithmic changes that ultimately improve a user's search experience. Although these efforts have led to objective improvements in search quality, the technical underpinnings remain largely invisible and go largely unnoticed by most users. Here we describe how these 'under-the-hood' techniques work within PubMed and report how their effectiveness and usage is assessed in real-world scenarios. In doing so, we hope to increase the transparency of the PubMed system and enable users to make more effective use of the search engine. We also identify open challenges and new opportunities for computational researchers to explore the potential of future improvements.",http://dx.doi.org/10.1038/nbt.4267,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12525-018-0290-9,Enhancing energy efficiency in the residential sector with smart meter data analytics,Electronic Markets,10.1007/s12525-018-0290-9,Springer,2018-11-01,"Tailored energy efficiency campaigns that make use of household-specific information can trigger substantial energy savings in the residential sector. The information required for such campaigns, however, is often missing. We show that utility companies can extract that information from smart meter data using machine learning. We derive 133 features from smart meter and weather data and use the Random Forest classifier that allows us to recognize 19 household classes related to 11 household characteristics (e.g., electric heating, size of dwelling) with an accuracy of up to 95% (69% on average). The results indicate that even datasets with an hourly or daily resolution are sufficient to impute key household characteristics with decent accuracy and that data from different yearly seasons does not considerably influence the classification performance. Furthermore, we demonstrate that a small training data set consisting of only 200 households already reaches a good performance. Our work may serve as benchmark for upcoming, similar research on smart meter data and provide guidance for practitioners for estimating the efforts of implementing such analytics solutions.",http://dx.doi.org/10.1007/s12525-018-0290-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42400-018-0015-6,"Cloud repository as a malicious service: challenge, identification and implication",Cybersecurity,10.1186/s42400-018-0015-6,Springer,2018-10-11,"The popularity of cloud hosting services also brings in new security chal- lenges: it has been reported that these services are increasingly utilized by miscreants for their malicious online activities. Mitigating this emerging threat, posed by such “bad repositories” (simply Bar ), is challenging due to the different hosting strategy to traditional hosting service, the lack of direct observations of the repositories by those outside the cloud, the reluctance of the cloud provider to scan its customers’ repositories without their consent, and the unique evasion strategies employed by the adversary. In this paper, we took the first step toward understanding and detecting this emerging threat. Using a small set of “seeds” (i.e., confirmed Bars), we identified a set of collective features from the websites they serve (e.g., attempts to hide Bars), which uniquely characterize the Bars. These features were utilized to build a scanner that detected over 600 Bars on leading cloud platforms like Amazon, Google, and 150 K sites, including popular ones like groupon.com , using them. Highlights of our study include the pivotal roles played by these repositories on malicious infrastructures and other important discoveries include how the adversary exploited legitimate cloud repositories and why the adversary uses Bars in the first place that has never been reported. These findings bring such malicious services to the spotlight and contribute to a better understanding and ultimately eliminating this new threat.",http://dx.doi.org/10.1186/s42400-018-0015-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40595-018-0116-x,A hybrid mobile call fraud detection model using optimized fuzzy C-means clustering and group method of data handling-based network,Vietnam Journal of Computer Science,10.1007/s40595-018-0116-x,Springer,2018-09-01,"A novel two-stage fraud detection system in mobile telecom networks has been presented in this paper that identifies the malicious calls among the normal ones in two stages. Initially, a genetic algorithm-based optimized fuzzy c-means clustering is applied to the user’s historical call records for constructing the calling profile. Thereafter, the identification of the fraudulent calls occurs in two stages. In the first stage, each incoming call is passed to the clustering module that identifies the call as genuine, malicious or suspicious. This is done by comparing the distance value of the new calling instance from the profile cluster centers against two predefined threshold values. The calls detected as genuine or malicious are not further processed. However, the call records that are found to be suspicious are additionally scrutinized in the second stage by a previously trained group method of data handling model for final decision making. The legitimate and forged labeled call records generated out of the clustering module are utilized for training the supervised classifier. Experimentation is done on a real-world call dataset to exhibit the effectiveness of the proposed model. A comparative analysis of the current approach with one of our earlier propositions and another recent fraud detection system clearly illustrates the efficacy of the developed model.",http://dx.doi.org/10.1007/s40595-018-0116-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-017-0593-1,Trust-based service composition and selection in service oriented architecture,Peer-to-Peer Networking and Applications,10.1007/s12083-017-0593-1,Springer,2018-09-01,"Service composition is a complex task that has attracted an increasing attention. It is significant to develop an approach to evaluate the trust of a composite service so that the client can obtain a satisfactory service from a large number of services. While, the fact is that many current approaches do not consider the trust dependency between component services in a composite service. Moreover, the approaches considering it focus only on the evaluation of already implemented composite service that can provide the rating of each component service in each execution. In this paper, we propose a method for evaluating the global trust of a composite service. It can be used for the evaluation of unexecuted composite services. In the trust evaluation procedure, we take trust dependency and the composite service’s invocation structure into account. We use a trust dependency analysis method inspired by the static program analysis technology to obtain the trust dependency relationship between component services. A greedy algorithm is also proposed to select the optimal component services from several candidate services for a composite service with the linear time complexity. Analysis and experiments show that our proposed approaches can evaluate the trust of a composite service reasonably and discover the optimal component service efficiently.",http://dx.doi.org/10.1007/s12083-017-0593-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-018-5711-8,"A Comprehensive Survey on Multi-hop Wireless Networks: Milestones, Changing Trends and Concomitant Challenges",Wireless Personal Communications,10.1007/s11277-018-5711-8,Springer,2018-07-01,"With remarkable advancements in the fields of global satellite based navigation systems and wireless communication networks, there is a tremendous increase in the number of mobile device users throughout the globe. Each day, new arduous projects and applications utilizing mobile devices are evolving, with a prime motive to deploy wireless multi-hop networks into the real world. As these networks are, in general, deployed in extreme environmental conditions their performance evaluation is a matter of great concern and demands rigorous analysis. Several models, simulators, testbeds and visualization tools have evolved in the last two decades for analyzing the characteristics of these wireless multi-hop networks. In this paper, first we discuss a number of models and the changing trends of research along with the associated challenges. Then, we discuss several simulators, emulators, testbeds and real world projects implementing such networks. Besides, we also discuss an important aspect of wireless multi-hop networks, i.e., reliability and identify various imperative metrics from the literature for performance evaluation of such dynamic networks.",http://dx.doi.org/10.1007/s11277-018-5711-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11390-018-1853-0,Illuminating Recommendation by Understanding the Explicit Item Relations,Journal of Computer Science and Technology,10.1007/s11390-018-1853-0,Springer,2018-07-01,"Recent years have witnessed the prevalence of recommender systems in various fields, which provide a personalized recommendation list for each user based on various kinds of information. For quite a long time, most researchers have been pursing recommendation performances with predefined metrics, e.g., accuracy. However, in real-world applications, users select items from a huge item list by considering their internal personalized demand and external constraints. Thus, we argue that explicitly modeling the complex relations among items under domain-specific applications is an indispensable part for enhancing the recommendations. Actually, in this area, researchers have done some work to understand the item relations gradually from “implicit” to “explicit” views when recommending. To this end, in this paper, we conduct a survey of these recent advances on recommender systems from the perspective of the explicit item relation understanding. We organize these relevant studies from three types of item relations, i.e., combination-effect relations, sequence-dependence relations, and external-constraint relations. Specifically, the combination-effect relation and the sequence-dependence relation based work models the intra-group intrinsic relations of items from the user demand perspective, and the external-constraint relation emphasizes the external requirements for items. After that, we also propose our opinions on the open issues along the line of understanding item relations and suggest some future research directions in recommendation area.",http://dx.doi.org/10.1007/s11390-018-1853-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-017-0476-7,Joint user knowledge and matrix factorization for recommender systems,World Wide Web,10.1007/s11280-017-0476-7,Springer,2018-07-01,"Currently, most of the existing recommendation methods treat social network users equally, which assume that the effect of recommendation on a user is decided by the user’s own preferences and social influence. However, a user’s own knowledge in a field has not been considered. In other words, to what extent does a user accept recommendations in social networks need to consider the user’s own knowledge or expertise in the field. In this paper, we propose a novel matrix factorization recommendation algorithm based on integrating social network information such as trust relationships, rating information of users and users’ own knowledge. Specifically, since we cannot directly measure a user’s knowledge in the field, we first use a user’s status in a social network to indicate a user’s knowledge in a field, and users’ status is inferred from the distributions of users’ ratings and followers across fields or the structure of domain-specific social network. Then, we model the final rating of decision-making as a linear combination of the user’s own preferences, social influence and user’s own knowledge. Experimental results on real world data sets show that our proposed approach generally outperforms the state-of-the-art recommendation algorithms that do not consider the knowledge level difference between the users.",http://dx.doi.org/10.1007/s11280-017-0476-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-018-2001-2,Cyber-physical integration for moving digital factories forward towards smart manufacturing: a survey,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-018-2001-2,Springer,2018-07-01,"The current study on digital factory (DF) meets some problems, such as disconnected manufacturing sites, independent digital models, isolated data, and non-self-controlled applications. In order to move current situation of DFs forward towards smart manufacturing, this paper attempts to present an overview of current digital situation of factories, and propose a systematical framework of cyber-physical integration in factories, with consideration of the concept of digital twin and the theory of manufacturing service. Particularly, the proposed framework includes four key issues, i.e., (a) fully interconnected physical elements integration , (b) faithful-mirrored virtual models integration , (c) all of elements/flows/businesses-covered data fusion , and (d) data-driven and application-oriented services integration . The corresponding implementable solutions of these four key issues are discussed in turn. As a reference, this paper is promising to bridge the gap in factories from current digital situation to smart manufacturing, so as to effectively facilitate their smart production.",http://dx.doi.org/10.1007/s00170-018-2001-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12911-018-0623-9,CogStack - experiences of deploying integrated information retrieval and extraction services in a large National Health Service Foundation Trust hospital,BMC Medical Informatics and Decision Making,10.1186/s12911-018-0623-9,BioMed Central,2018-06-25,"Background Traditional health information systems are generally devised to support clinical data collection at the point of care. However, as the significance of the modern information economy expands in scope and permeates the healthcare domain, there is an increasing urgency for healthcare organisations to offer information systems that address the expectations of clinicians, researchers and the business intelligence community alike. Amongst other emergent requirements, the principal unmet need might be defined as the 3R principle (right data, right place, right time) to address deficiencies in organisational data flow while retaining the strict information governance policies that apply within the UK National Health Service (NHS). Here, we describe our work on creating and deploying a low cost structured and unstructured information retrieval and extraction architecture within King’s College Hospital, the management of governance concerns and the associated use cases and cost saving opportunities that such components present. Results To date, our CogStack architecture has processed over 300 million lines of clinical data, making it available for internal service improvement projects at King’s College London. On generated data designed to simulate real world clinical text, our de-identification algorithm achieved up to 94% precision and up to 96% recall. Conclusion We describe a toolkit which we feel is of huge value to the UK (and beyond) healthcare community. It is the only open source, easily deployable solution designed for the UK healthcare environment, in a landscape populated by expensive proprietary systems. Solutions such as these provide a crucial foundation for the genomic revolution in medicine.",http://dx.doi.org/10.1186/s12911-018-0623-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13174-018-0087-2,"A comprehensive survey on machine learning for networking: evolution, applications and research opportunities",Journal of Internet Services and Applications,10.1186/s13174-018-0087-2,Springer,2018-06-21,"Machine Learning (ML) has been enjoying an unprecedented surge in applications that solve problems and enable automation in diverse domains. Primarily, this is due to the explosion in the availability of data, significant improvements in ML techniques, and advancement in computing capabilities. Undoubtedly, ML has been applied to various mundane and complex problems arising in network operation and management. There are various surveys on ML for specific areas in networking or for specific network technologies. This survey is original, since it jointly presents the application of diverse ML techniques in various key areas of networking across different network technologies. In this way, readers will benefit from a comprehensive discussion on the different learning paradigms and ML techniques applied to fundamental problems in networking, including traffic prediction, routing and classification, congestion control, resource and fault management, QoS and QoE management, and network security. Furthermore, this survey delineates the limitations, give insights, research challenges and future opportunities to advance ML in networking. Therefore, this is a timely contribution of the implications of ML for networking, that is pushing the barriers of autonomic network operation and management.",http://dx.doi.org/10.1186/s13174-018-0087-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-018-5705-5,A scalable preference model for autonomous decision-making,Machine Learning,10.1007/s10994-018-5705-5,Springer,2018-06-01,"Emerging domains such as smart electric grids require decisions to be made autonomously, based on the observed behaviors of large numbers of connected consumers. Existing approaches either lack the flexibility to capture nuanced, individualized preference profiles, or scale poorly with the size of the dataset. We propose a preference model that combines flexible Bayesian nonparametric priors—providing state-of-the-art predictive power—with well-justified structural assumptions that allow a scalable implementation. The Gaussian process scalable preference model via Kronecker factorization ( GaSPK ) model provides accurate choice predictions and principled uncertainty estimates as input to decision-making tasks. In consumer choice settings where alternatives are described by few key attributes, inference in our model is highly efficient and scalable to tens of thousands of choices.",http://dx.doi.org/10.1007/s10994-018-5705-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-017-9547-8,Inference of development activities from interaction with uninstrumented applications,Empirical Software Engineering,10.1007/s10664-017-9547-8,Springer,2018-06-01,"Studying developers’ behavior in software development tasks is crucial for designing effective techniques and tools to support developers’ daily work. In modern software development, developers frequently use different applications including IDEs, Web Browsers, documentation software (such as Office Word, Excel, and PDF applications), and other tools to complete their tasks. This creates significant challenges in collecting and analyzing developers’ behavior data. Researchers usually instrument the software tools to log developers’ behavior for further studies. This is feasible for studies on development activities using specific software tools. However, instrumenting all software tools commonly used in real work settings is difficult and requires significant human effort. Furthermore, the collected behavior data consist of low-level and fine-grained event sequences, which must be abstracted into high-level development activities for further analysis. This abstraction is often performed manually or based on simple heuristics. In this paper, we propose an approach to address the above two challenges in collecting and analyzing developers’ behavior data. First, we use our ActivitySpace framework to improve the generalizability of the data collection. ActivitySpace uses operating-system level instrumentation to track developer interactions with a wide range of applications in real work settings. Secondly, we use a machine learning approach to reduce the human effort to abstract low-level behavior data. Specifically, considering the sequential nature of the interaction data, we propose a Condition Random Field (CRF) based approach to segment and label the developers’ low-level actions into a set of basic, yet meaningful development activities. To validate the generalizability of the proposed data collection approach, we deploy the ActivitySpace framework in an industry partner’s company and collect the real working data from ten professional developers’ one-week work in three actual software projects. The experiment with the collected data confirms that with initial human-labeled training data, the CRF model can be trained to infer development activities from low-level actions with reasonable accuracy within and across developers and software projects. This suggests that the machine learning approach is promising in reducing the human efforts required for behavior data analysis.",http://dx.doi.org/10.1007/s10664-017-9547-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-017-9553-x,Empirical study on the discrepancy between performance testing results from virtual and physical environments,Empirical Software Engineering,10.1007/s10664-017-9553-x,Springer,2018-06-01,"Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving field requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O traffic) to the testing environment and lead to unrealistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems – namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments.",http://dx.doi.org/10.1007/s10664-017-9553-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-017-1030-0,AmbISPDM,Applied Intelligence,10.1007/s10489-017-1030-0,Springer,2018-06-01,"The need to manage embedded systems, brought forward by the wider adoption of pervasive computing, is particularly vital in the context of secure and safety-critical applications. Technology infiltrates in ordinary things, hitching intelligence and materializing smart systems. Each of these individual entities monitors a specific set of parameters and deduces a constrained local view of the surrounding environment. Many distributed devices exchange information in order to infer the real system state and achieve a consistent global view. However, conflicts may arise due to the integration of deficit pieces of local knowledge. Robust and efficient conflict resolution is essential, especial in cases of emergency where the system must contribute with timely and accurate data to the overall crisis management operation. In this paper, we present AmbISPDM – a formal framework for the management of embedded systems with a coherent conflict resolution mechanism. The process is implemented as a software agent’s reasoning behaviour and applied in the multi-agent domain. As a proof of concept, a smart university campus setting is deployed, with agents controlling embedded devices to assist living conditions in normal operation and the evacuation planning in case of fire.",http://dx.doi.org/10.1007/s10489-017-1030-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-017-9539-5,Knowledge-based recommendation: a review of ontology-based recommender systems for e-learning,Artificial Intelligence Review,10.1007/s10462-017-9539-5,Springer,2018-06-01,"Recommender systems in e-learning domain play an important role in assisting the learners to find useful and relevant learning materials that meet their learning needs. Personalized intelligent agents and recommender systems have been widely accepted as solutions towards overcoming information retrieval challenges by learners arising from information overload. Use of ontology for knowledge representation in knowledge-based recommender systems for e-learning has become an interesting research area. In knowledge-based recommendation for e-learning resources, ontology is used to represent knowledge about the learner and learning resources. Although a number of review studies have been carried out in the area of recommender systems, there are still gaps and deficiencies in the comprehensive literature review and survey in the specific area of ontology-based recommendation for e-learning. In this paper, we present a review of literature on ontology-based recommenders for e-learning. First, we analyze and classify the journal papers that were published from 2005 to 2014 in the field of ontology-based recommendation for e-learning. Secondly, we categorize the different recommendation techniques used by ontology-based e-learning recommenders. Thirdly, we categorize the knowledge representation technique, ontology type and ontology representation language used by ontology-based recommender systems, as well as types of learning resources recommended by e-learning recommenders. Lastly, we discuss the future trends of this recommendation approach in the context of e-learning. This study shows that use of ontology for knowledge representation in e-learning recommender systems can improve the quality of recommendations. It was also evident that hybridization of knowledge-based recommendation with other recommendation techniques can enhance the effectiveness of e-learning recommenders.",http://dx.doi.org/10.1007/s10462-017-9539-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10270-016-0566-5,WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction—a model-driven approach for session-based application systems,Software & Systems Modeling,10.1007/s10270-016-0566-5,Springer,2018-05-01,"The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.",http://dx.doi.org/10.1007/s10270-016-0566-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-017-5107-x,Guest Editorial: Multimedia for Predictive Analytics,Multimedia Tools and Applications,10.1007/s11042-017-5107-x,Springer,2018-04-01,,http://dx.doi.org/10.1007/s11042-017-5107-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1038/s41746-017-0012-2,Artificial intelligence powers digital medicine,npj Digital Medicine,10.1038/s41746-017-0012-2,Nature,2018-03-14,"Artificial intelligence (AI) has recently surpassed human performance in several domains, and there is great hope that in healthcare, AI may allow for better prevention, detection, diagnosis, and treatment of disease. While many fear that AI will disrupt jobs and the physician–patient relationship, we believe that AI can eliminate many repetitive tasks to clear the way for human-to-human bonding and the application of emotional intelligence and judgment. We review several recent studies of AI applications in healthcare that provide a view of a future where healthcare delivery is a more unified, human experience.",http://dx.doi.org/10.1038/s41746-017-0012-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-017-0955-8,Developing advanced fingerprint attacks on challenge-based collaborative intrusion detection networks,Cluster Computing,10.1007/s10586-017-0955-8,Springer,2018-03-01,"Traditionally, an isolated intrusion detection system (IDS) is vulnerable to various types of attacks. In order to enhance IDS performance, collaborative intrusion detection networks (CIDNs) are developed through enabling a set of IDS nodes to communicate with each other. Due to the distributed network architecture, insider attacks are one of the major threats. In the literature, challenge-based trust mechanisms have been built to identify malicious nodes by evaluating the satisfaction levels between challenges and responses. However, such mechanisms rely on two major assumptions, which may result in a weak threat model. In this case, CIDNs may be still vulnerable to advanced insider attacks in real-world deployment. In this paper, we propose a novel collusion attack, called passive message fingerprint attack (PMFA) , which can collect messages and identify normal requests in a passive way. In the evaluation, we explore the attack performance under both simulated and real network environments. Experimental results demonstrate that our attack can help malicious nodes send malicious responses to normal requests, while maintaining their trust values.",http://dx.doi.org/10.1007/s10586-017-0955-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13638-018-1033-5,Mining shopping data with passive tags via velocity analysis,EURASIP Journal on Wireless Communications and Networking,10.1186/s13638-018-1033-5,Springer,2018-02-03,"Unlikeonline shopping, it is difficult for the physical store to collect customer shopping data during the process of shopping and conduct in-depth data mining. The existing methods to solve this problem only considered how to collect and analyze the data, but they have not paid attention to the large computation amount, bulk data amount, and long time delay, in which they can not feedback user data timely and effectively. In this paper, we present the received signal strength of passive radio frequency identification (RFID) tags that can be used to carry out on-site shopping data mining, such as which items are popular, which goods are customers interested in, which items are usually bought together, which areas have a large customer flow, and what is the order of items being bought by customers. By exploiting the received signal strength indicator (RSSI) information, we calculate the velocity of the items and then leverage machine learning and hierarchical agglomerative clustering to carry out in-depth analysis of velocity data. We implement a prototype in which all components are built by off-the-shelf devices. Meanwhile, we conduct extensive experiments in the real environment. The experiment results show that our methods have low computation and latency, which demonstrate that our proposed system is quite feasible in practical shopping data analysis.",http://dx.doi.org/10.1186/s13638-018-1033-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11704-016-5228-9,A retrospective of knowledge graphs,Frontiers of Computer Science,10.1007/s11704-016-5228-9,Springer,2018-02-01,"Information on the Internet is fragmented and presented in different data sources, which makes automatic knowledge harvesting and understanding formidable for machines, and even for humans. Knowledge graphs have become prevalent in both of industry and academic circles these years, to be one of the most efficient and effective knowledge integration approaches. Techniques for knowledge graph construction can mine information from either structured, semi-structured, or even unstructured data sources, and finally integrate the information into knowledge, represented in a graph. Furthermore, knowledge graph is able to organize information in an easy-to-maintain, easy-to-understand and easy-to-use manner. In this paper, we give a summarization of techniques for constructing knowledge graphs. We review the existing knowledge graph systems developed by both academia and industry. We discuss in detail about the process of building knowledge graphs, and survey state-of-the-art techniques for automatic knowledge graph checking and expansion via logical inferring and reasoning. We also review the issues of graph data management by introducing the knowledge data models and graph databases, especially from a NoSQL point of view. Finally, we overview current knowledge graph systems and discuss the future research directions.",http://dx.doi.org/10.1007/s11704-016-5228-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11235-017-0334-z,"Defending against phishing attacks: taxonomy of methods, current issues and future directions",Telecommunication Systems,10.1007/s11235-017-0334-z,Springer,2018-02-01,"Internet technology is so pervasive today, for example, from online social networking to online banking, it has made people’s lives more comfortable. Due the growth of Internet technology, security threats to systems and networks are relentlessly inventive. One such a serious threat is “phishing”, in which, attackers attempt to steal the user’s credentials using fake emails or websites or both. It is true that both industry and academia are working hard to develop solutions to combat against phishing threats. It is therefore very important that organisations to pay attention to end-user awareness in phishing threat prevention. Therefore, aim of our paper is twofold. First, we will discuss the history of phishing attacks and the attackers’ motivation in details. Then, we will provide taxonomy of various types of phishing attacks. Second, we will provide taxonomy of various solutions proposed in literature to protect users from phishing based on the attacks identified in our taxonomy. Moreover, we have also discussed impact of phishing attacks in Internet of Things (IoTs). We conclude our paper discussing various issues and challenges that still exist in the literature, which are important to fight against with phishing threats.",http://dx.doi.org/10.1007/s11235-017-0334-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-01578-6_3,Predicting Human Decision-Making,Predicting Human Decision-Making,10.1007/978-3-031-01578-6_3,Springer,2018-01-01,Designing intelligent agents that interact proficiently with people necessitates the prediction of human decision-making. We present and discuss three prediction paradigms for predicting human decision-making which are common in many real world application fields. These paradigms are illustrated and compared across a wide variety of domains and applications in Chapter 4.,http://dx.doi.org/10.1007/978-3-031-01578-6_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90092-6_14,Recommending Based on Implicit Feedback,Social Information Access,10.1007/978-3-319-90092-6_14,Springer,2018-01-01,"Recommender systems have shown to be valuable tools for filtering, ranking, and discovery in a variety of application domains such as e-commerce, media repositories or document-based information in general that includes the various scenarios of Social Information Access discussed in this book. One key to the success of such systems lies in the precise acquisition or estimation of the user’s preferences. While general recommender systems research often relies on the existence of explicit preference statements for personalization, such information is often very sparse or unavailable in real-world applications. Information that allows us to assess the relevance of certain items indirectly through a user’s actions and behavior ( implicit feedback ) is in contrast often available in abundance. In this chapter we categorize different types of implicit feedback and review their use in the context of recommender systems and Social Information Access applications. We then extend the categorization scheme to be suitable to recent application domains. Finally, we present state-of-the-art algorithmic approaches, discuss challenges when using implicit feedback signals in particular with respect to popularity biases, and discuss selected recent works from the literature.",http://dx.doi.org/10.1007/978-3-319-90092-6_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3564-5_1,Basics of Machine Learning,Pro Machine Learning Algorithms,10.1007/978-1-4842-3564-5_1,Springer,2018-01-01,"Machine learning can be broadly classified into supervised and unsupervised learning. By definition, the term supervised means that the “machine” (the system) learns with the help of something—typically a labeled training data.",http://dx.doi.org/10.1007/978-1-4842-3564-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3709-0_1,The Artificial Intelligence 2.0 Revolution,"IoT, AI, and Blockchain for .NET",10.1007/978-1-4842-3709-0_1,Springer,2018-01-01,"Once upon a time, computers were as big as rooms. They were capable of complex mathematical calculations. They were not, though, meant to be operated by people like me and you. Nor were they designed for creating documents and presentations, playing games, or surfing the web. Early computers were powered by vacuum tubes—just like most other sophisticated electronic devices of the time—and were used in scientific research. Then, the semiconductor revolution happened, and the transistor was born.",http://dx.doi.org/10.1007/978-1-4842-3709-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3832-5_6,Test Automation and Architecture,Complete Guide to Test Automation,10.1007/978-1-4842-3832-5_6,Springer,2018-01-01,"Because the vast majority of manual tests is done through the UI, and on a complete system that attempts to mimic the production environment as much as possible, it is often assumed that this is also the right approach for automated tests. However, as we already discussed in Chapter 2 , there are different considerations for manual tests and for automated ones. In this chapter we’ll discuss some strategic considerations about the architecture of the test automation. As we’ll see, the considerations about the architecture of the test automation are tightly related to the architecture of the SUT.",http://dx.doi.org/10.1007/978-1-4842-3832-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03062-9_3,The UbiCARS Model-Driven Framework: Automating Development of Recommender Systems for Commerce,Ambient Intelligence,10.1007/978-3-030-03062-9_3,Springer,2018-01-01,"Recommendations of products to customers are proved to boost sales, increase customer satisfaction and improve user experience, making recommender systems an important tool for retail businesses. With recent technological advancements in AmI and Ubiquitous Computing, the benefits of recommender systems can be enjoyed not only in e-commerce, but in the physical store scenario as well. However, developing effective context-aware recommender systems by non-expert practitioners is not an easy task due to the complexity of building the necessary data models and selecting and configuring recommendation algorithms. In this paper we apply the Model Driven Development paradigm on the physical commerce recommendation domain by defining a UbiCARS Domain Specific Modelling Language, a modelling editor and a system, that aim to reduce complexity, abstract the technical details and expedite the development and application of State-of-the-Art recommender systems in ubiquitous environments (physical retail stores), as well as to enable practitioners to utilize additional data resulting from ubiquitous user-product interaction in the recommendation process to improve recommendation accuracy.",http://dx.doi.org/10.1007/978-3-030-03062-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94472-2_4,Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method,Services – SERVICES 2018,10.1007/978-3-319-94472-2_4,Springer,2018-01-01,"The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7% on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible.",http://dx.doi.org/10.1007/978-3-319-94472-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-70942-0_1,Data in the 21st Century,Predictive Econometrics and Big Data,10.1007/978-3-319-70942-0_1,Springer,2018-01-01,"The past couple of decades have witnessed exponential growth in data, due to the penetration of information technology across all aspects of science and society; the increasing ease with which we are able to collect more data; and the growth of Internet-scale, planet-wide Web-based and mobile services—leading to the notion of “big data”. While the emphasis so far has been on developing technologies to manage the volume, velocity, and variety of the data, and to exploit available data assets via machine learning techniques, going forward the emphasis must also be on translational data science and the responsible use of all of these data in real-world applications. Data science in the 21 st century must provide trust in the data and provide responsible and trustworthy techniques and systems by supporting the notions of transparency, interpretability, and reproducibility. The future offers exciting opportunities for transdisciplinary research and convergence among disciplines—computer science, statistics, mathematics, and the full range of disciplines that impact all aspects of society. Econometrics and economics can find an important role in this convergence of ideas.",http://dx.doi.org/10.1007/978-3-319-70942-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01421-6_33,Real-Time Session-Based Recommendations Using LSTM with Neural Embeddings,Artificial Neural Networks and Machine Learning – ICANN 2018,10.1007/978-3-030-01421-6_33,Springer,2018-01-01,"Recurrent neural networks have successfully been used as core elements of intelligent recommendation engines in e-commerce platforms. We demonstrate how LSTM networks can be applied to recommend products of interest for a customer, based on the events of the current session only. Inspired by recent advances in natural language processing, our network computes vector space representations (VSR) of available products and uses these representations to derive predictions of user behaviour based on the clickstream of the current session. The experimental results suggest that the Embedding-LSTM is well suited for session-based recommendations, thus offering a promising method for attacking the user cold start problem. A live test gives proof that our LSTM model outperforms a recommendation model created with traditional methods. We also show that providing the learned VSR as features to neighbourhood-based methods leads to improved performance as compared to standard nearest neighbour methods.",http://dx.doi.org/10.1007/978-3-030-01421-6_33,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-74947-1_18,A Modular Environment to Test SCADA Solutions for Wind Parks,"Measurement, Modelling and Evaluation of Computing Systems",10.1007/978-3-319-74947-1_18,Springer,2018-01-01,"Supervisory Control and Data Acquisition (SCADA) systems monitor and control industrial processes, like power generation and distribution. Research on e.g. SCADA security and the implementation of new approaches is made difficult through the lack of accessible test beds. We investigate running a dedicated SCADA test bed on a Raspberry Pi cluster and report the experiences made during installation, configuration and administration. Build with production readiness in mind, we describe how a large level of automation contributes to both, ease of use and a reliable set-up. In the future this testbed will be used to implement new approaches for (i) process monitoring, (ii) intrusion-detection and the combination of different (iii) information and communication technologies for SCADA systems.",http://dx.doi.org/10.1007/978-3-319-74947-1_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01554-1_19,Moving Target Defense for the Placement of Intrusion Detection Systems in the Cloud,Decision and Game Theory for Security,10.1007/978-3-030-01554-1_19,Springer,2018-01-01,"A lot of software systems are deployed in the cloud. Owing to realistic demands for an early product launch, oftentimes there are vulnerabilities that are present in these deployed systems (or eventually found out). The cloud service provider can find and leverage this knowledge about known vulnerabilities and the underlying communication network topology of the system to position network and host-based Intrusion Detection Systems (IDS) that can effectively detect attacks. Unfortunately, deploying IDS on each host and network interface impacts the performance of the overall system. Thus, in this paper, we address the problem of placing a limited number of IDS by using the concept of Moving Target Defense (MTD). In essence, we propose an MTD system that allows a defender to shift the detection surfaces and strategically switch among the different IDS placement configurations in each round. To find a secure switching strategy, we (1) formulate the problem of placing a limited number of IDS systems in a large cloud network as a Stackelberg Game between the cloud administrator and an (external or stealthy) attacker, (2) design scalable methods to find the optimal strategies for switching IDS placements at the start of each round, and (3) formally define the problem of identifying the most critical vulnerability that should be fixed, and propose a solution for it. We compare the strategy generated by our method to other state-of-the-art strategies, showcasing the effectiveness and scalability of our method for real-world scenarios.",http://dx.doi.org/10.1007/978-3-030-01554-1_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3207-1_8,Customer Segmentation and Effective Cross Selling,Practical Machine Learning with Python,10.1007/978-1-4842-3207-1_8,Springer,2018-01-01,"Money makes the world go round and in the current ecosystem of data intensive business practices, it is safe to claim that data also makes the world go round. A very important skill set for data scientists is to match the technical aspects of analytics with its business value, i.e., its monetary value. This can be done in a variety of ways and is very much dependent on the type of business and the data available. In the earlier chapters, we covered problems that can be framed as business problems (leveraging the CRISP-DM model) and linked to revenue generation. In this chapter we will directly focus on two very important problems that can directly have a positive impact on the revenue streams of businesses and establishments particularly from the retail domain. This chapter is also unique in the way that we address a different paradigm of Machine Learning algorithm altogether, focusing more on tasks pertaining to pattern recognition and unsupervised learning.",http://dx.doi.org/10.1007/978-1-4842-3207-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3417-4_13,Trends and Innovation in Modern Digital Solutions,Complete Guide to Digital Project Management,10.1007/978-1-4842-3417-4_13,Springer,2018-01-01,"Many recent changes and developments in digital technologies (along with customer expectations) are shaping digital project management aspects. Digital project managers have to be educated about the latest developments in the digital space in order to effectively manage digital projects. Being aware of the latest advancements in the digital world enables digital project managers to use the right set of tools, techniques, and best practices effectively. Innovation provides a competitive edge.",http://dx.doi.org/10.1007/978-1-4842-3417-4_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01554-1_30,A Bayesian Multi-armed Bandit Approach for Identifying Human Vulnerabilities,Decision and Game Theory for Security,10.1007/978-3-030-01554-1_30,Springer,2018-01-01,"We consider the problem of identifying the set of users in an organization’s network that are most susceptible to falling victim to social engineering attacks. To achieve this goal, we propose a testing strategy, based on the theory of multi-armed bandits, that involves a system administrator sending fake malicious messages to users in a sequence of unannounced tests and recording their responses. To accurately model the administrator’s testing problem, we propose a new bandit setting, termed the structured combinatorial multi-bandit model, that allows one to impose combinatorial constraints on the space of allowable queries. The model captures the diversity in attack types and user responses by considering multiple multi-armed bandits, where each bandit problem represents an attack (message) type and each arm represents a user. Users respond to test messages according to a response model with unknown statistics. The response model associates a Bernoulli distribution with an unknown mean with each message-user pair, dictating the likelihood that a user will respond to a given message. The administrator’s problem of identifying the most susceptible users can then be expressed as identifying the set of message-user pairs with means that exceed a given threshold. We adopt a Bayesian approach to solving the problem, associating a (beta) prior distribution with each unknown mean. In a given trial, the system administrator queries a selection of users with test messages, generating query responses which are then used to update posterior distributions on the means. By defining a state as the parameters of the posteriors, we show that the optimal testing strategy can be characterized as the solution of a Markov decision process (MDP). Unfortunately, solving the MDP is computationally intractable. As a result, we propose a heuristic testing strategy, based on Thompson sampling, that focuses queries on message-user pairs that are estimated to have means close to the threshold. The heuristic testing strategy is shown to yield accurate identifications.",http://dx.doi.org/10.1007/978-3-030-01554-1_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-93935-3_1,Introduction,Entity-Oriented Search,10.1007/978-3-319-93935-3_1,Springer,2018-01-01,"Entity-oriented search is the search paradigm of organizing and accessing information centered around entities, and their attributes and relationships. This introductory chapter defines what an entity is, identifies prominent contexts for entity-oriented search, presents a number of specific tasks, puts the subject into a historical perspective, and lays the foundations for the rest of the book.",http://dx.doi.org/10.1007/978-3-319-93935-3_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-70688-7_1,Beyond Automation: The Cognitive IoT. Artificial Intelligence Brings Sense to the Internet of Things,Cognitive Computing for Big Data Systems Over IoT,10.1007/978-3-319-70688-7_1,Springer,2018-01-01,"The Internet of Things (IoT) Internet of things (IoT) has already been infiltrated to our everyday life in the forms of smartphones Smartphone , smart TVs, fitness trackers, health monitoring systems, smart watches, vending machines Machine , smart meters, city traffic, building security systems and much more like this. It has steered the automation Automation to a new high. But IoT alone has limited capability. To reap the actual benefit of IoT, it has to be intelligent. In this chapter, we have reasoned why IoT needs Artificial Intelligence Artificial intelligence (AI) (AI). The intelligent IoT that we discuss here, is termed as the Cognitive IoT (CIoT) Cognitive IoT (CIoT) . Cognitive IoT uses a new computing paradigm called Cognitive Computing Cognitive computing , often popularly dubbed as the third era of computing. Cognitive Computing will make IoT more sophisticated, more intelligent, and more interactive Interactive . This chapter essentially focuses on the convergence of IoT with Cognitive AI Cognitive AI . In addition to introducing a preliminary idea of Cognitive Computing, the chapter discusses several aspects of CIoT. It explains how Cognitive Computing has been used in IoT through different forms such as Cognitive Network Cognitive network , Cognitive Devices Cognitive devices , and Cognitive Analytics Cognitive analytics . The desirable properties of the CIoT are mentioned. A special discussion is presented on how CIoT has taken automation to a new level. Realizing CIoT is not straightforward for the reason that it is a complex system and is quite different from other computing systems we have been familiar with. The implementation challenges along with the societal and ethical apprehensions of CIoT have been identified and discussed in detail. The business world is showing great interest in IoT and subsequently in CIoT. Considering that, we have highlighted the business values of CIoT and some prospective application areas along with a few prominent use cases. But, will excessive adoption of AI and tendering human-like intellect to inorganic devices be a threat to the human race? Do we need to be warned? A rational discussion on that has been presented before winding up.",http://dx.doi.org/10.1007/978-3-319-70688-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3808-0_1,The Economics of Artificial Intelligence,How to Compete in the Age of Artificial Intelligence,10.1007/978-1-4842-3808-0_1,Springer,2018-01-01,"When three types of disruptive forces (a new source of energy, a new kind of transport, and a new kind of communication) converge in concert, something dramatic happens. The cost of goods drops, the demand-supply equilibrium gets disrupted, new avenues of business opportunities open up, society by and large benefits, and we find ourselves at the cusp of an economic revolution. The last economic revolution was driven by oil (new source of energy), automobiles (new kind of transport), and telecommunication (a new kind of communication mode). In the same parlance, the new economy emerging now can be attributed to be driven by the convergence of data (the new oil), autonomous vehicles, and digital communication.",http://dx.doi.org/10.1007/978-1-4842-3808-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-58715-8_2,"E-Commerce: Mechanisms, Platforms, and Tools",Electronic Commerce 2018,10.1007/978-3-319-58715-8_2,Springer,2018-01-01,"Upon completion of this chapter, you will be able to: 1. Describe the major electronic commerce (EC) activities and processes and the mechanisms that support them. 2. Define e-marketplaces and list their components. 3. List the major types of e-marketplaces and describe their features. 4. Describe electronic catalogs, search engines, and shopping carts. 5. Describe the major types of auctions and list their characteristics. 6. Discuss the benefits and limitations of e-auctions. 7. Describe bartering and negotiating online. 8. Describe virtual communities. 9. Describe social networks as EC mechanisms. 10. Describe the emerging technologies of augmented reality and crowdsourcing. 11. Describe Web 3.0 and define Web 4.0 and Web 5.0.",http://dx.doi.org/10.1007/978-3-319-58715-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-95092-1_7,Data Science Techniques,Data Science Thinking,10.1007/978-3-319-95092-1_7,Springer,2018-01-01,"In the age of analytics, data analytics and learning form a comprehensive spectrum and evolutionary map that cover.",http://dx.doi.org/10.1007/978-3-319-95092-1_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-60435-0_20,Sentiment Analysis and Mining of Opinions,Internet of Things and Big Data Analytics Toward Next-Generation Intelligence,10.1007/978-3-319-60435-0_20,Springer,2018-01-01,"Now days the way of expressing opinions on certain products that people purchase and the services that they receive in the various industries has been transformed considerably because of World Wide Web. Social Networking sites fascinate people to post feedbacks and reviews online on blogs, Internet forums, review portals and much more. These opinions play a very important role for customers and product manufacturers as they tend to give better knowledge of buying and selling by setting positive and negative comments on products and other information which can improve their decision making policies. Mining of such opinions have focused the researchers to pay a keen intention in developing such a system which can not only collect useful and relevant reviews online in a ranked manner and also produce an effective summary of such reviews collected on different products according to their respective domains. However, there is little evidence that researchers have approached this issue in opinion mining with the intent of developing such a system. Our work will focus on what opinion mining is the existing works on opinion mining, the challenges in the existing techniques and the workflow of mining opinions. Consequently, the aim of this chapter is to discuss the overall novel architecture of developing an opinion system that will address the remaining challenges and provide an overview of how to mine opinions. Existing research in sentiment analysis tend to focus on finding out how to classify the opinions and produce a collaborative summary in their respective domains, despite an increase in the field of opinion mining and its research, many challenges remain in designing a more comprehensive way of building a system to mine opinions. This chapter addresses the problem of how to classify sentiments and develop the opinion system by combining theories of supervised learning.",http://dx.doi.org/10.1007/978-3-319-60435-0_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-61161-7_19,Future Technologies of the Cloud Century,Inventing the Cloud Century,10.1007/978-3-319-61161-7_19,Springer,2018-01-01,"All the technology areas we have discussed throughout this book like computing, networking, the Internet, virtualization, the IoT and big data analytics will see significant changes but also significant improvements, which will form the basis of how our lives might look some decades from now. Among all these evolutions, we will find some of the next big things that will surely revolutionize our future.",http://dx.doi.org/10.1007/978-3-319-61161-7_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-81-322-3760-0_5,The Value of Disruptive Innovations,Global Innovation and Economic Value,10.1007/978-81-322-3760-0_5,Springer,2018-01-01,"The exceptional characteristics of disruptive innovations (the Internet, Social media, Internet of Things and Autonomous driving) are discussed. The transformative impact of these radical innovations is assessed. The consumer surplus generated by the ubiquitous mobile phones and the role of social media in the ‘socialized’ world is discussed. The staggering impact of IOT to connect all inanimate things and the truly disruptive nature of autonomous vehicles will be watershed moments.",http://dx.doi.org/10.1007/978-81-322-3760-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-93713-7_62,How Is the Forged Certificates in the Wild: Practice on Large-Scale SSL Usage Measurement and Analysis,Computational Science – ICCS 2018,10.1007/978-3-319-93713-7_62,Springer,2018-01-01,"Forged certificate is a prominent issue in the real world deployment of SSL/TLS - the most widely used encryption protocols for Internet security, which is typically used in man-in-the-middle (MITM) attacks, proxies, anonymous or malicious services, personal or temporary services, etc. It wrecks the SSL encryption, leading to privacy leakage and severe security risks. In this paper, we study forged certificates in the wild based on a long term large scale passive measurement. With the combination of certificate transparency (CT) logs and our measurement results, nearly 3 million forged certificates against the Alexa Top 10K sites are identified and studied. Our analysis reveals the causes and preference of forged certificates, as well as several significant differences from the benign ones. Finally, we discover several IP addresses used for MITM attacks by forged certificate tracing and deep behavior analysis. We believe our study can definitely contribute to research on SSL/TLS security as well as real world protocol usage.",http://dx.doi.org/10.1007/978-3-319-93713-7_62,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-13-0650-1_2,"Framing Learning Analytics and Educational Data Mining for Teaching: Critical Inferencing, Domain Knowledge, and Pedagogy",Frontiers of Cyberlearning,10.1007/978-981-13-0650-1_2,Springer,2018-01-01,"This chapter reviews key challenges of learning analytics and educational data mining. It highlights early generation learning analytics pitfalls that could compromise the future of their use in technology-delivered instruction, especially if teachers are not well trained and adequately equipped with both technical and sociocritical literacy of this new field. Among the issues are potential for bias and inaccuracy in the algorithms involved, the propensity toward closed proprietary systems whose algorithms cannot be scrutinized, and the paucity of learning models typically considered. The new learning analytics and educational data mining systems bring with them a set of claims, aspirations, and mystique. These underlying technologies could be harbingers of future breakthroughs: a new generation of artificial intelligence systems adaptively responding to students’ interactions with online teaching environments.",http://dx.doi.org/10.1007/978-981-13-0650-1_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94779-2_23,How Machine Learning Could Detect Anomalies on Thinger.io Platform?,"Highlights of Practical Applications of Agents, Multi-Agent Systems, and Complexity: The PAAMS Collection",10.1007/978-3-319-94779-2_23,Springer,2018-01-01,"This research explores the capacity of Machine Learning techniques to detect anomalies and how incorporate this capacity to thinger.io platform. Thinger.io is a IoT opensource platform that allows to create an IoT environment using any hardware available on market. In this paper, several ML techniques are proposed to detect anomalies in the platform.",http://dx.doi.org/10.1007/978-3-319-94779-2_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-01027-0_3,Scaling Things Up: Large Group Decision Making (LGDM),Large Group Decision Making,10.1007/978-3-030-01027-0_3,Springer,2018-01-01,"What is a Large Group Decision Making problem? What differentiates them from the conventional Group Decision Making problems and approaches introduced in the previous chapter, and what are the added complexities of supporting high-quality decisions to be made by large groups? The present chapter aims at introducing and contextualizing this relatively new area of research, highlighting its main limitations of challenges and discussing some of its newly related disciplines, as witnessed in recent research.",http://dx.doi.org/10.1007/978-3-030-01027-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-017-2135-2,Dynamic performance isolation management for cloud computing services,The Journal of Supercomputing,10.1007/s11227-017-2135-2,Springer,2018-01-01,"Unmanaged resource contention in cloud computing environments can cause problems such as performance interference, service quality degradation, and consequently service agreements violation. Performance isolation is an indispensable remedy solution for the mentioned challenges. Dynamic analysis and monolithic management of the performance isolation from the perspective of cloud computing services with different operating entities is a challenging problem. This issue has not been addressed in previous studies, despite its significance. Most previous researches have focused on particular algorithms and methods for specific application scenarios, and lack sufficient descriptions about analysis and management aspects of the performance isolation. Due to the importance of this issue, this paper aims to make an in-depth investigation of this problem and propose a novel approach in order to dynamic analysis and management of the performance isolation for cloud computing services. Proposed approach employs a novel architectural framework, named DPIM, which enables service providers to realize different isolation methods and enforces performance isolation transparently. The experimental results demonstrate the practicality and effectiveness of the proposed approach and related framework for performance isolation management in different service environments, with different operating entities.",http://dx.doi.org/10.1007/s11227-017-2135-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-92898-2_6,Increasing Trust in (Big) Data Analytics,Advanced Information Systems Engineering Workshops,10.1007/978-3-319-92898-2_6,Springer,2018-01-01,"Trust is a key concern in big data analytics (BDA). Explaining “black-box” models, demonstrating transferability of models and robustness to data changes with respect to quality or content can help in improving confidence in BDA. To this end, we propose metrics for measuring robustness with respect to input noise. We also provide empirical evidence by showcasing how to compute and interpret these metrics using multiple datasets and classifiers. Additionally, we discuss the state-of-the-art of various areas in machine learning such as explaining “black box” models and transfer learning with respect to model validation. We show how methods from these areas can be adjusted to support classical validity measures in science such as content validity.",http://dx.doi.org/10.1007/978-3-319-92898-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5209-5_9,Deep Learning in Social Computing,Deep Learning in Natural Language Processing,10.1007/978-981-10-5209-5_9,Springer,2018-01-01,"The goal of social computing is to devise computational systems to learn mechanisms and principles to explain and understand the behaviors of each individual and collective teams, communities, and organizations. The unprecedented online data in social media provides a fruitful resource for this purpose. However, traditional techniques have a hard time in handling the complex and heterogeneous nature of social media for social computing. Fortunately, the recent revival and success of deep learning brings new opportunities and solutions to address these challenges. This chapter introduces the recent progress of deep learning on social computing in three aspects, namely user-generated content, social connections, and recommendation, which have covered most of the core elements and applications in social computing. Our focus lies in the discussions on how to adapt deep learning techniques to mainstream social computing tasks.",http://dx.doi.org/10.1007/978-981-10-5209-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03596-9_31,QoS-Aware Web Service Recommendation with Reinforced Collaborative Filtering,Service-Oriented Computing,10.1007/978-3-030-03596-9_31,Springer,2018-01-01,"With the overwhelming increase of web services on the Internet, how to accurately perform QoS prediction has played a key role in service recommendation. Recently, three kinds of approaches have been presented on service QoS prediction based on collaborative filtering (CF), including user-intensive, service-intensive and their combination. However, the deficiency of current approaches is that all of the services invoked by target user (or all of the users who invoked target service) are applied to calculate average QoS, without the reduction to those dissimilar with target service (or target user). In this paper, we propose a reinforced collaborative filtering approach, where both similar users and services are integrally considered into a singleton CF. The experiments are conducted on a large-scale dataset called WS-DREAM, involving 5,825 real-world Web services in 73 countries and 339 service users in 30 countries. The experimental results demonstrate that our approach for QoS prediction outperforms the competing approaches.",http://dx.doi.org/10.1007/978-3-030-03596-9_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99127-6_21,"Complex Collaborative Physical Process Management: A Position on the Trinity of BPM, IoT and DA",Collaborative Networks of Cognitive Systems,10.1007/978-3-319-99127-6_21,Springer,2018-01-01,"In the modern economy, we see complex business processes with a physical character executed collaboratively by a set of autonomous business organizations. Examples are international container logistics, integrated supply and manufacturing networks, and collaborative healthcare chains - all of which handle physical objects. Over time, these processes have become more complex, more business-critical, more time-critical, and at the same time heavily mass-customized. This implies that the processes need to be managed more explicitly in an increasingly real-time fashion, with ample attention to individual process cases. To support this kind of processes, no single existing technology class suffices. Therefore, we propose to integrate technologies from the areas of business process management (BPM - to manage the processes), internet of things (IoT - to sense and actuate the physical objects) and distributed analytics (DA - to take the right decisions at the right place in real-time) into a trinity. We illustrate our position with an example from the domain of container logistics.",http://dx.doi.org/10.1007/978-3-319-99127-6_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-3141-8_1,"The Era of Big Data, Hadoop, and Other Big Data Processing Frameworks",PySpark Recipes,10.1007/978-1-4842-3141-8_1,Springer,2018-01-01,"After a few years, I joined Facebook. And day by day, I was introduced to what became an infinite amount of information from all over world. Next, I started purchasing items online, and I liked it more than shopping offline. I could easily get a lot of information about products, and I could compare prices and features. And I wasn’t the only one; millions of people were feeling the same way about the Web.",http://dx.doi.org/10.1007/978-1-4842-3141-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94147-9_17,Privacy in e-Shopping Transactions: Exploring and Addressing the Trade-Offs,Cyber Security Cryptography and Machine Learning,10.1007/978-3-319-94147-9_17,Springer,2018-01-01,"The huge growth of e-shopping has brought convenience to customers, increased revenue to merchants and financial entities and evolved to possess a rich set of functionalities and requirements (e.g., regulatory ones). However, enhancing customer privacy remains to be a challenging problem; while it is easy to create a simple system with privacy, this typically causes loss of functions . In this work, we look into current e-shopping infrastructures and aim at enhancing customer privacy while retaining important features and requiring the system to maintain the topology and transaction flow of established e-shopping systems that are currently operational. Thus, we apply what we call the “utility, privacy, and then utility again” paradigm: we start from the state of the art of e-shopping (utility); then we add privacy enhancing mechanisms, reducing its functionality in order to tighten privacy to the fullest (privacy); and finally, we incorporate tools which add back lost features, carefully relaxing privacy this time (utility again). We also implemented and tested our design, verifying its reasonable added costs.",http://dx.doi.org/10.1007/978-3-319-94147-9_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-65455-3_2,A Comprehensive Survey on Healthcare Management,Operations Research Applications in Health Care Management,10.1007/978-3-319-65455-3_2,Springer,2018-01-01,"Healthcare management (HCM) is the profession providing control and guidance to health service providers. Numerous quantitative and qualitative techniques including operations research (OR) techniques, statistical analyses, multi-criteria decision making techniques, etc. have been applied to healthcare problems. This chapter summarizes these techniques using a classification and presents graphical analyses of the survey results.",http://dx.doi.org/10.1007/978-3-319-65455-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4939-7131-2_110162,Recommender Systems Evaluation,Encyclopedia of Social Network Analysis and Mining,10.1007/978-1-4939-7131-2_110162,Springer,2018-01-01,,http://dx.doi.org/10.1007/978-1-4939-7131-2_110162,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-02671-4_1,Optimized Container-Based Process Execution in the Cloud,On the Move to Meaningful Internet Systems. OTM 2018 Conferences,10.1007/978-3-030-02671-4_1,Springer,2018-01-01,"A key challenge for elastic business processes is the resource-efficient scheduling of cloud resources in such a way that Quality-of-Service levels are met. So far, this has been difficult, since existing approaches use a coarse-granular resource allocation based on virtual machines. In this paper, we present a technique that provides fine-granular resource scheduling for elastic processes based on containers. In order to address the increased complexity of the respective scheduling problem, we develop a novel technique called GeCo based on genetic algorithms. Our evaluation demonstrates that in comparison to a baseline that follows an ad hoc approach a cost saving between 32.90% and 47.45% is achieved by GeCo while considering a high service level.",http://dx.doi.org/10.1007/978-3-030-02671-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-64161-4_3,Development of Knowledge-Based Systems Which Use Bayesian Networks,Synergies Between Knowledge Engineering and Software Engineering,10.1007/978-3-319-64161-4_3,Springer,2018-01-01,"Bayesian networks allow for a concise graphical representation of decision makers’ knowledge on an uncertain domain. However, there are no well-defined methodologies showing how to use a Bayesian network as the core of a knowledge-based system, even less if not all the features should be supported by the knowledge model. That is to say, the software, that has to be released to customers, has also to embed functionalities not based on knowledge, concerning to the information management processes closer to the world of a classical software development projects. These components of the software application have to be built according to practices and methods of Software Engineering discipline. This chapter is conceived as a guideline about how to manage and intertwine languages and techniques related to Knowledge Engineering and Software Engineering in order to build a knowledge based system supported by Bayesian networks.",http://dx.doi.org/10.1007/978-3-319-64161-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-6265-228-6_7,The Potential for Privacy Seals in Emerging Technologies,Privacy and Data Protection Seals,10.1007/978-94-6265-228-6_7,Springer,2018-01-01,"This chapter examines the feasibility for privacy seals in emerging technologies focusing upon cyber-physical systems, also known as the Internet of Things (IoT). This focus provides an opportunity to compare technologies where privacy seals have purchase against those that do not, further refining the model of an effective privacy seal. It examines the privacy and data protection issues surrounding smart homes, smart cars, wearables and drones, and evaluates the potential for deploying privacy and data protection seals in these contexts by deploying design fictions. From these thought experiments, it becomes apparent that in addition to the general requirements of a privacy seal, there also needs to be strong alignment between the technology, (including its physical design, logical design, and level of generativity) and its social context of use. By its interconnected nature, IoT fundamentally disrupts our expectations around objects (things) and information flows. Seals might act as part of the mechanisms of re-transcribing such expectations. Designing a workable seal therefore means understanding information norms, and expectations, but also desired states of information flow in particular contexts.",http://dx.doi.org/10.1007/978-94-6265-228-6_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-75681-3_8,Utilization Phase: Utilization of OUSAF,Measuring and Analysing the Use of Ontologies,10.1007/978-3-319-75681-3_8,Springer,2018-01-01,"To demonstrate the utilization of the OUSAF, in this chapter, a methodological approach is adopted which provides a systematic flow of activities and the interaction between different components to analyse the utilization. This methodological approach is presented in Sect.  8.2 . Section  8.3 presents details on the construction of the dataset that is used to demonstrate the utilization phase. In Sects.  8.4 – 8.6 , the utilization of the different phases of the OUSAF is presented. Section  8.7 summarizes the achievements of the utilization phase. Section  8.8 concludes the chapter.",http://dx.doi.org/10.1007/978-3-319-75681-3_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-02140-5_6,Fintech and Procurement Finance 4.0,Procurement Finance,10.1007/978-3-030-02140-5_6,Springer,2018-01-01,"The future of procurement finance is connected to the digital transformation, which in the case of procurement finance is a digital revolution connected with Business 4.0. The correct concept is to consider procurement finance 4.0 as a platform, with several actors—proprietors, providers, producers, and purchasers—with interchangeable roles. Fintech organizations are and will play more and more an important role in this new vision. At the same time, the technological solution which can make all this possible is blockchain, whose characteristics are more and more appreciated around the world. The digital transformation can gain a lot also from artificial intelligence and mobility.",http://dx.doi.org/10.1007/978-3-030-02140-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94370-1_10,An Empirical Analysis of Smart Connected Home Data,Internet of Things – ICIOT 2018,10.1007/978-3-319-94370-1_10,Springer,2018-01-01,"The increasing presence of heterogeneous Internet of Things devices inside the home brings with it added convenience and value to the householders. At the same time, these devices tend to be Internet-connected and continuously monitor and collect data about the residents and their daily lifestyle activities. Such data can be of a sensitive nature, given that the house is the place where privacy is naturally expected. To gain insight into this state of affairs, we empirically investigate the privacy policies of 87 different categories of commercial smart home devices in terms of data being collected. This is done using a combination of manual and data mining techniques. The overall contribution of this work is a model that identifies and categorizes smart connected home data in terms of its collection mode, collection method, and collection phase. Our findings bring up several implications for smart connected home privacy, which include the need for better security controls to safeguard the privacy of the householders.",http://dx.doi.org/10.1007/978-3-319-94370-1_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-93408-2_2,Multi-agent Architecture of a MIBES for Smart Energy Management,Innovations for Community Services,10.1007/978-3-319-93408-2_2,Springer,2018-01-01,This paper introduces the concept of Multi-Institution Building Energy System (MIBES) for the smart energy management. The MIBES addresses the exploitation of energy data shared by numerous multi-site multi-purpose institutions. It is a “hierarchical graph” describing the physical and structural reality of the data collected for these institutions. We propose the architecture of a multi-agent system (MAS) for the MIBES smart management. This MAS is then used within a data collection system to allow real time treatment of the system. This complete system is being deployed in a french company called Energisme .,http://dx.doi.org/10.1007/978-3-319-93408-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99819-0_1,When Service-Oriented Computing Meets the IoT: A Use Case in the Context of Urban Mobile Crowdsensing,Service-Oriented and Cloud Computing,10.1007/978-3-319-99819-0_1,Springer,2018-01-01,"The possibilities of new mobile distributed systems have reached unprecedented levels. Such systems are dynamically composed of networked resources in the environment, which may span from the immediate neighborhood of the users - as advocated by pervasive computing - up to the entire globe - as envisioned by the Future Internet and one of its major constituents, the Internet of Things. This paper more specifically concentrates on urban participatory mobile distributed systems where people get involved in producing new knowledge about the urban environment. Service-oriented and cloud computing are evident baseline technologies for the target mobile distributed systems. Service orientation provides the abstraction to deal with the assembly of the relevant heterogeneous component systems. The cloud provides the infrastructure to deal with the gathering and analyses of the observations coming from the sensing infrastructure, including from people. However, cloud-based centralized solutions come at a price, regarding both resource consumption and privacy risk. Further, the high heterogeneity of the participating nodes results in diverse levels of sensing accuracy. This paper provides an overview of our past and ongoing research to overcome the challenges facing urban participatory mobile distributed systems, which leverages mobile collaborative sensing, networking and computing. The experience with the Ambiciti platform and associated mobile app for monitoring the individual and collective exposure to environmental pollution serves as an illustrative use case.",http://dx.doi.org/10.1007/978-3-319-99819-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-73459-0_2,Optimizing Service Level Agreements in Peer-to-Peer Supply Chain Model for Complex Projects Management,Informatics in Economy,10.1007/978-3-319-73459-0_2,Springer,2018-01-01,"The focus of this paper is to find appropriate approaches to facilitate end-to-end SLA (Service Level Agreements) in complex projects environments using Peer-to-Peer Supply Chain Model, to establish and enforce service levels between each pair of component consumer/provider, so that the overall project requirements can be achieved at the best utility value (SLA). The Supply Chain Formation problem is described in terms of a directed acyclic graph where the nodes are represented by the component suppliers/consumers. Intelligent agents send messages in the name of component suppliers/consumers on three constraints (scope, time, cost) giving raise to SLAs. The SLAs are expressed as utility functions and it is concluded that in complex projects scenario where the graph is always a tree the proposed model will converge to the optimal solution and the best utility value will be propagated autonomously across all component providers within the project environment.",http://dx.doi.org/10.1007/978-3-319-73459-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03596-9_60,QKnober: A Knob-Based Fairness-Efficiency Scheduler for Cloud Computing with QoS Guarantees,Service-Oriented Computing,10.1007/978-3-030-03596-9_60,Springer,2018-01-01,"Fairness and efficiency are generally two important metrics for users in modern cloud computing. Due to the heterogeneous resource demands of CPU and memory for users’ tasks, it cannot achieve the strict 100% fairness and the maximum efficiency at the same time. Quantitatively showing the fairness degradation/loss becomes essentially important in the design of any fairness-efficiency tradeoff scheduler. Existing fairness-efficiency schedulers (e.g., Tetris) can balance such a tradeoff elastically by relaxing fairness constraint for improved efficiency using the knob. However, their approaches are insensitive to the fairness degradation under different knobs, which makes several drawbacks. First, it cannot quantitatively tell how much relaxed fairness can be guaranteed (i.e., QoS of fairness guarantee) given a knob value. Second, it fails to meet several essential properties such as sharing incentive. To address these issues, we propose a new fairness-efficiency scheduler, QKnober , to balance the fairness and efficiency elastically and flexibly using a tunable fairness knob. QKnober is a fairness-sensitive scheduler that can maximize the system efficiency while guaranteeing the $$\theta $$ -soft fairness by modeling the whole allocation as a combination of fairness-purpose allocation and efficiency-purpose allocation. Moreover, QKnober satisfies fairness properties of sharing incentive, envy-freeness and pareto efficiency given a proper knob. We have implemented QKnober in YARN and evaluated it using real experiments. The results show that QKnober can achieve good performance and fairness.",http://dx.doi.org/10.1007/978-3-030-03596-9_60,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-658-20460-0_3,Digital Technologies and Business Model Innovations for Urban Mobility,Paradigm Shift in Urban Mobility,10.1007/978-3-658-20460-0_3,Springer,2018-01-01,"Cities have long been at the forefront of sustainable, multimodal mobility due to the transportation demands placed on a city by a large, densely located population. There is a considerable movement towards a more advanced and intelligent approach to urban mobility. Cities are moving toward a model of on-demand mobility in which citizens can take advantage of clean transportation options that meet their immediate needs, increase accessibility and contribute to much higher quality of life in urban areas.",http://dx.doi.org/10.1007/978-3-658-20460-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-02671-4_12,Data Analytics Challenges in Industry 4.0: A Case-Based Approach,On the Move to Meaningful Internet Systems. OTM 2018 Conferences,10.1007/978-3-030-02671-4_12,Springer,2018-01-01,"Creating business value with data analytics is a continuous process that requires to effectively consider the design and deployment of powerful analytics solutions. This requires a significant effort in understanding, customizing, assembling and adapting these solutions to the specific environment. However, this might be different from one context to another. The objective of this paper is to discuss the use of data analytics in Industry 4.0 by harvesting some challenges and lessons-learnt. A case-based approach is followed, as a research methodology to explore and understand complex and common issues related to data analytics. Scalability, interoperability and standardization are among the topics that are reviewed.",http://dx.doi.org/10.1007/978-3-030-02671-4_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94295-7_8,Fault Injection and Detection for Artificial Intelligence Applications in Container-Based Clouds,Cloud Computing – CLOUD 2018,10.1007/978-3-319-94295-7_8,Springer,2018-01-01,"Container technique is increasingly used to build modern cloud computing systems to achieve higher efficiency and lower resource costs, as compared with traditional virtual machine technique. Artificial intelligence (AI) is a mainstream method to deal with big data, and is used in many areas to achieve better effectiveness. It is known that attacks happen every day in production cloud systems, however, the fault behaviors and interferences of up-to-date AI applications in container-based cloud systems is still not clear. This paper aims to study the reliability issue of container-based clouds. We first propose a fault injection framework for container-based cloud systems. We build a docker container environment installed with TensorFlow deep learning framework, and develop four typical attack programs, i.e., CPU attack, Memory attack, Disk attack and DDOS attack. Then, we inject the attack programs to the containers running AI applications (CNN, RNN, BRNN and DRNN), to observe fault behaviors and interferences phenomenon. After that, we design fault detection models based on quantile regression method to detect potential faults in containers. Experimental results show the proposed fault detection models can effectively detect the injected faults with more than 60% Precision, more than 90% Recall and nearly 100% Accuracy.",http://dx.doi.org/10.1007/978-3-319-94295-7_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-73951-9_10,Adaptive Traffic Fingerprinting for Darknet Threat Intelligence,Cyber Threat Intelligence,10.1007/978-3-319-73951-9_10,Springer,2018-01-01,"Darknet technology such as Tor has been used by various threat actors for organising illegal activities and data exfiltration. As such there is a case for organisations to block such traffic, or to try and identify when it is used and for what purposes. However, anonymity in cyberspace has always been a domain of conflicting interests. While it gives enough power to nefarious actors to masquerade their illegal activities, it is also the corner stone to facilitate freedom of speech and privacy. We present a proof of concept for a novel algorithm that could form the fundamental pillar of a darknet-capable Cyber Threat Intelligence platform. The solution can reduce anonymity of users of Tor, and considers the existing visibility of network traffic before optionally initiating targeted or widespread BGP interception. In combination with server HTTP response manipulation, the algorithm attempts to reduce the candidate data set to eliminate client-side traffic that is most unlikely to be responsible for server-side connections of interest. Our test results show that MITM manipulated server responses lead to expected changes received by the Tor client. Using simulation data generated by shadow, we show that the detection scheme is effective with false positive rate of 0.001, while sensitivity detecting non-targets was 0.016±0.127. Our algorithm could assist collaborating organisations willing to share their threat intelligence or cooperate during investigations.",http://dx.doi.org/10.1007/978-3-319-73951-9_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01554-1_23,Towards Scientific Incident Response,Decision and Game Theory for Security,10.1007/978-3-030-01554-1_23,Springer,2018-01-01,"A scientific incident analysis is one with a methodical, justifiable approach to the human decision-making process. Incident analysis is a good target for additional rigor because it is the most human-intensive part of incident response. Our goal is to provide the tools necessary for specifying precisely the reasoning process in incident analysis. Such tools are lacking, and are a necessary (though not sufficient) component of a more scientific analysis process. To reach this goal, we adapt tools from program verification that can capture and test abductive reasoning. As Charles Peirce coined the term in 1900, “Abduction is the process of forming an explanatory hypothesis. It is the only logical operation which introduces any new idea.” We reference canonical examples as paradigms of decision-making during analysis. With these examples in mind, we design a logic capable of expressing decision-making during incident analysis. The result is that we can express, in machine-readable and precise language, the abductive hypotheses than an analyst makes, and the results of evaluating them. This result is beneficial because it opens up the opportunity of genuinely comparing analyst processes without revealing sensitive system details, as well as opening an opportunity towards improved decision-support via limited automation.",http://dx.doi.org/10.1007/978-3-030-01554-1_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-02698-1_8,Optimization of Hypergraph Based News Recommendation by Binary Decision Tree,Intelligence Science and Big Data Engineering,10.1007/978-3-030-02698-1_8,Springer,2018-01-01,"News personalized recommendation has long been a favourite domain for recommender research. Traditional approaches strive to satisfy the users by constructing the users’ preference profiles. Naturally, most of recent methods use users’ reading history (content-based) or access pattern (collaborative filtering based) to recommend proper news articles to them. Besides, some researches encapsule the news content and access pattern in a recommender by vector space model. In this paper, we propose to use a hypergraph ranking for obtaining the preference rough, and then utilize the binary decision tree for eliminating the definition subjectivity of hypergraph. In this way, we can combine the content attributes on news content attributes, users and user’s access pattern in a unified hypergraph and get more accuracy results, whereas we needn’t to construct the user profile and select the possible important attributes empirically. Finally, we designed several experiments compared to the state-of-the-art methods on a real world dataset, and the results demonstrate that our approach significantly improves the accuracy, diversity, and coverage metrics in mass data.",http://dx.doi.org/10.1007/978-3-030-02698-1_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-64161-4_8,Agile Knowledge Engineering for Mission Critical Software Requirements,Synergies Between Knowledge Engineering and Software Engineering,10.1007/978-3-319-64161-4_8,Springer,2018-01-01,"This chapter explains how a mission critical Knowledge-Based System (KBS) has been designed and implemented within a real case study of a governamental organization. Moreover, the KBS has been developed using a novel agile software development methodology. Due to fast changing operational scenarios and volatile requirements, traditional procedural development methodologies perform poorly. Thus, an Agile-like methodology has been exploited, called iAgile. The KBS is based on an ontology used to merge different mental models of users and developers. Moreover, the ontology of the system is useful for interoperability and knowledge representation. Mission critical functionalities have been developed in 5-week cycles, along with the ontology. So, the KBS serves for three main activities: (i) requirement disambiguation, (ii) interoperability with other legacy systems, and (iii) information retrieval and display of different informative sources.",http://dx.doi.org/10.1007/978-3-319-64161-4_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-02925-8_2,Integrating Collaborative Filtering and Association Rule Mining for Market Basket Recommendation,Web Information Systems Engineering – WISE 2018,10.1007/978-3-030-02925-8_2,Springer,2018-01-01,"This paper proposes a market basket recommendation algorithm based on association rules and collaborative filtering. It solves the problem that traditional association rule recommendation algorithms cannot generate association rules from cold commodity items under big data environment. An implicit semantic model based on historical transaction data of all users is constructed to represent potential features of commodities and measure similarities among commodities. The missing unknown elements in the implicit semantic model are complemented by the least square method. Association rules on unpopular commodities are obtained by the similarity of the commodities, thereby improving the recommendation accuracy. Experiments with real supermarket sales data demonstrate its effectiveness.",http://dx.doi.org/10.1007/978-3-030-02925-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00668-6_13,DistLODStats: Distributed Computation of RDF Dataset Statistics,The Semantic Web – ISWC 2018,10.1007/978-3-030-00668-6_13,Springer,2018-01-01,"Over the last years, the Semantic Web has been growing steadily. Today, we count more than 10,000 datasets made available online following Semantic Web standards. Nevertheless, many applications, such as data integration, search, and interlinking, may not take the full advantage of the data without having a priori statistical information about its internal structure and coverage. In fact, there are already a number of tools, which offer such statistics, providing basic information about RDF datasets and vocabularies. However, those usually show severe deficiencies in terms of performance once the dataset size grows beyond the capabilities of a single machine. In this paper, we introduce a software component for statistical calculations of large RDF datasets, which scales out to clusters of machines. More specifically, we describe the first distributed in-memory approach for computing 32 different statistical criteria for RDF datasets using Apache Spark. The preliminary results show that our distributed approach improves upon a previous centralized approach we compare against and provides approximately linear horizontal scale-up. The criteria are extensible beyond the 32 default criteria, is integrated into the larger SANSA framework and employed in at least four major usage scenarios beyond the SANSA community.",http://dx.doi.org/10.1007/978-3-030-00668-6_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-65012-8_8,Intelligent System,Ontology Engineering Applications in Healthcare and Workforce Management Systems,10.1007/978-3-319-65012-8_8,Springer,2018-01-01,"Ontologies play an important role in enabling knowledge representation, knowledge management, and knowledge sharing. Many applications benefit greatly from making use of ontologies as a means of achieving semantic interoperability among heterogeneous and distributed systems.",http://dx.doi.org/10.1007/978-3-319-65012-8_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99127-6_35,The Robot Who Loved Me: Building Consciousness Models for Use in Human Robot Interaction Following a Collaborative Systems Approach,Collaborative Networks of Cognitive Systems,10.1007/978-3-319-99127-6_35,Springer,2018-01-01,We build on the results of our MARIO project to support the benefit of informing research taking place in the area of development of human consciousness models for use by robots to facilitate human robot interaction with research results from the area of collaborative systems. The main outcome of such a research would be a software model of a robot assistant that might offer functionality and features of a ‘virtual coach’ with an in-built evolution capability.,http://dx.doi.org/10.1007/978-3-319-99127-6_35,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90092-6_16,Location Recommendation with Social Media Data,Social Information Access,10.1007/978-3-319-90092-6_16,Springer,2018-01-01,"Smartphones with inbuilt location-sensing technologies are now creating a new realm for recommender systems research and pratice. In this chapter, we focus on recommender systems that use location data to help users navigate the physical world. We examine various recommendation problems: recommending new places, recommending the next place to visit, events to attend, and recommending neighbourhoods or large areas to explore further. Lastly, we discuss how (personalized) place search is analogous to web search. For each of these domains, we present relevant data, algorithms, and methods, and we illustrate how researchers are investigating them with examples from the literature. We close by summarizing key aspects and suggesting future directions.",http://dx.doi.org/10.1007/978-3-319-90092-6_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90415-3_10,Energy vs. QoX Network- and Cloud Services Management,Autonomous Control for a Reliable Internet of Services,10.1007/978-3-319-90415-3_10,Springer,2018-01-01,"Network Performance (NP)- and more recently Quality of Service/Experience/anything (QoS/QoE/QoX)-based network management techniques focus on the maximization of associated Key Performance Indicators (KPIs). Such mechanisms are usually constrained by certain thresholds of other system design parameters. e.g., typically, cost. When applied to the current competitive heterogeneous Cloud Services scenario, this approach may have become obsolete due to its static nature. In fact, energy awareness and the capability of modern technologies to deliver multimedia content at different possible combinations of quality (and prize) demand a complex optimization framework. It is therefore necessary to define more flexible paradigms that make it possible to consider cost, energy and even other currently unforeseen design parameters not as simple constraints, but as tunable variables that play a role in the adaptation mechanisms. In this chapter we will briefly introduce most commonly used frameworks for multi-criteria optimization and evaluate them in different Energy vs. QoX sample scenarios. Finally, the current status of related network management tools will be described, so as to identify possible application areas.",http://dx.doi.org/10.1007/978-3-319-90415-3_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-61893-7_14,"Modeling, Modeling, Modeling: From Web to Enterprise to Crowd to Social",A Comprehensive Guide Through the Italian Database Research Over the Last 25 Years,10.1007/978-3-319-61893-7_14,Springer,2018-01-01,"Data management is continuously evolving for serving the needs of an increasingly connected society. New challenges apply not only to systems and technology, but also to the models and abstractions for capturing new application requirements. In this paper, we describe several models and abstractions which have been progressively designed to capture new forms of data-centered interactions in the last twenty five years – a period of huge changes due to the spreading of web-based applications and the increasingly relevant role of social interactions. We initially focus on Web-based applications for individuals, then discuss applications among enterprises, then we discuss how these applications may include rankings which are computed using services or using crowds; we conclude with hints to a recent research discussing how social sources can be used for capturing emerging knowledge.",http://dx.doi.org/10.1007/978-3-319-61893-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-68318-8_6,Enhancing Virtual Learning Spaces: The Impact of the Gaming Analytics,Software Data Engineering for Network eLearning Environments,10.1007/978-3-319-68318-8_6,Springer,2018-01-01,"Online virtual labs Online virtual labs have been important to educational practice by providing students with distance courses that otherwise would be difficult to be offered. However, the majority of them cannot be easily applied to different courses or pedagogical approaches. In order to overcome this, we propose a high-level, easy-to-use authoring tool that will allow building course-independent high-standard virtual labs. This solution is based on learning and gaming analytics Learning and gaming analytics. . Ιn the gaming industry, there have been developed strong game analytics methods and tools, which could be easily transferred into the learning domain. Game analytics monitor the users’ activity; model their current behavior through the use of shallow analytics and predict the future behavior of the users through the use of deep analytics. We propose that both of these approaches combined with visualization methodologies Visualization methodologies will offer insights on what features are important and what functionalities users expect to find in a virtual lab.",http://dx.doi.org/10.1007/978-3-319-68318-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-04491-6_21,An Approach Based on Contrast Patterns for Bot Detection on Web Log Files,Advances in Soft Computing,10.1007/978-3-030-04491-6_21,Springer,2018-01-01,"Nowadays, companies invest resources in detecting non-human accesses on their web traffics. Usually, non-human accesses are a few compared with the human accesses, which is considered as a class imbalance problem, and as a consequence, classifiers bias their classification results toward the human accesses obviating, in this way, the non-human accesses. In some classification problems, such as the non-human traffic detection, high accuracy is not only the desired quality, the model provided by the classifier should be understood by experts. For that, in this paper, we study the use of contrast pattern-based classifiers for building an understandable and accurate model for detecting non-human traffic on web log files. Our experiments over five databases show that the contrast pattern-based approach obtains significantly better AUC results than other state-of-the-art classifiers.",http://dx.doi.org/10.1007/978-3-030-04491-6_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-74947-1_10,On the Value of Service Demand Estimation for Auto-scaling,"Measurement, Modelling and Evaluation of Computing Systems",10.1007/978-3-319-74947-1_10,Springer,2018-01-01,"In the context of performance models, service demands are key model parameters capturing the average time individual requests of different workload classes are actively processed. In a system under load, due to measurement interference, service demands normally cannot be measured directly, however, a number of estimation approaches exist based on high-level performance metrics. In this paper, we show that service demands provide significant benefits for implementing modern auto-scalers. Auto-scaling describes the process of dynamically adjusting the number of allocated virtual resources (e.g., virtual machines) in a data center according to the incoming workload. We demonstrate that even a simple auto-scaler that leverages information about service demands significantly outperforms auto-scalers solely based on CPU utilization measurements. This is shown by testing two approaches in three different scenarios. Our results show that the service demand-based auto-scaler outperforms the CPU utilization-based one in all scenarios. Our results encourage further research on the application of service demand estimates for resource management in data centers.",http://dx.doi.org/10.1007/978-3-319-74947-1_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94541-5_18,A Framework to Support the Design of Digital Initiatives in Social Science Based Research,"Digitalisation, Innovation, and Transformation",10.1007/978-3-319-94541-5_18,Springer,2018-01-01,"The rapid development of new digital technologies has increased the expectations of academic research outputs. To meet these pressures, researchers have greater expectations of their digital work environments. In this paper we outline the drivers for digital transformation at our institution and how this manifested itself in a series of exploratory projects called digital initiatives. Based on our findings we propose a Digital Research Initiative framework to support research institutions in assessing and implementing digital transformation.",http://dx.doi.org/10.1007/978-3-319-94541-5_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-61161-7_18,Big Data Analytics,Inventing the Cloud Century,10.1007/978-3-319-61161-7_18,Springer,2018-01-01,"Big Data Analytics describes how massive amounts of data are collected, organized and stored to allow efficient and timely analysis opens new areas of potential disruption in several different ecosystems. We will discuss what really is behind this new trend, what are the promised disruptions and what new ecosystems are inaugural. We will see how this massive amount of data is collected and organized appropriately to allow for efficient analysis, which is referred to as analytics, or big data analytics.",http://dx.doi.org/10.1007/978-3-319-61161-7_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-05051-1_35,POWER: A Parallel-Optimization-Based Framework Towards Edge Intelligent Image Recognition and a Case Study,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-05051-1_35,Springer,2018-01-01,"To improve the intelligent image recognition abilities of edge devices, a parallel-optimization-based framework called POWER is introduced in this paper. With FPGA (Field-Programmable Gate Array) as its hardware module, POWER provides well extensibility and flexible customization capability for developing intelligent firmware suitable for different types of edge devices in various scenarios. Through an actual case study, we design and implement a firmware prototype following the specification of POWER and explore its performance improvement using parallel optimization. Our experimental results show that the firmware prototype we implement exhibits good performance and is applicable to substation inspection robots, which also validate the effectiveness of our POWER framework in designing edge intelligent firmware modules indirectly.",http://dx.doi.org/10.1007/978-3-030-05051-1_35,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03596-9_63,Transparently Capturing Execution Path of Service/Job Request Processing,Service-Oriented Computing,10.1007/978-3-030-03596-9_63,Springer,2018-01-01,"Distributed platforms are widely deployed to provide services in various trades. With the increasing scale and complexity of these distributed platforms, it is becoming more and more challenging to understand and diagnose a service request’s processing in a distributed platform, as even one simple service request may traverse numerous heterogeneous components across multiple hosts. Thus, it is highly demanded to capture the complete end-to-end execution path of service requests among all involved components accurately. This paper presents REPTrace, a generic methodology for capturing the complete request execution path (REP) in a transparent fashion. We propose principles for identifying causal relationships among events for a comprehensive list of execution scenarios, and stitch all events to generate complete request execution paths based on library/system calls tracing and network labelling. The experiments on different distributed platforms with different workloads show that REPTrace transparently captures the accurate request execution path with reasonable latency and negligible network overhead.",http://dx.doi.org/10.1007/978-3-030-03596-9_63,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94965-9_4,Real-Time CPU Scheduling Approach for Mobile Edge Computing System,Smart Grid and Innovative Frontiers in Telecommunications,10.1007/978-3-319-94965-9_4,Springer,2018-01-01,"Mobile edge computing (MEC) system has outstanding advantages of providing smart city applications with relatively low latency and immediately response. How to guarantee the QoS of the services in MEC system is consequently becoming a hot issue. This work focuses on solving the problem by real-time CPU scheduling. The proposed scheduling algorithm considers different services arrival profiles, computation time consumption and deadline requirements simultaneously. Specifically, the combination and optimization of support vector machine (SVM) and earliest deadline first (EDF) algorithm is designed, which could automatically classify services type and efficiently allocate the computation time in real-time manner. By deploying the traffic trace from the real world, the proposed scheduling algorithm could reduce $$45\mathrm{{\% }}$$ latency and improve the reliability of transmission, comparing with popular fixed-priority CPU scheduling algorithm.",http://dx.doi.org/10.1007/978-3-319-94965-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-98648-7_17,Finding Structure in the Unstructured: Hybrid Feature Set Clustering for Process Discovery,Business Process Management,10.1007/978-3-319-98648-7_17,Springer,2018-01-01,"Process discovery is widely used in business process intelligence to reconstruct process models from event logs recorded by information systems. With the increase of complexity and flexibility of processes, it is getting more and more challenging for discovery algorithms to generate accurate and comprehensive models. Trace clustering aims to overcome this issue by splitting event logs into smaller behavioral similar sub-logs. From these sub-logs more accurate and comprehensive process models can be reconstructed. In this paper, we propose a novel clustering approach that uses frequent itemset mining on the case attributes to also reveal relationships on the data perspective. Our approach includes this additional knowledge as well as optimizes the fitness of the underlying process models of each cluster to generate accurate clustering results. We compare our method with six other clustering methods and evaluate our approach using synthetic and real-life event logs.",http://dx.doi.org/10.1007/978-3-319-98648-7_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-8476-8_3,Big-Data Analysis of Process Performance: A Case Study of Smart Cities,Big Data in Engineering Applications,10.1007/978-981-10-8476-8_3,Springer,2018-01-01,"This chapter presents a data-centric software architecture that provides timely data access to key performance indicators (KPIs) about process performance. This architecture comes in the form of an analytical framework that lies on big-data and cloud-computing technologies aimed to cope with the demands of the crowd-sourced data analysis in terms of latency and data volume. This framework is proposed to be applied to the Smart Cities and the Internet of Things (IoT) arenas to monitor, analyse and improve the business processes and smart services of the city. Once the framework is presented from the technical standpoint, a case study is rolled out to leverage this process-centric framework and apply its fundamentals to the smart cities realm with the aim of analysing live smart data and improve the efficiency of smart cities. More specifically, this case study is focussed on the improvement of the service delivery process of the Open311 smart services deployed in the city of Chicago. The outcomes of the test show the ability of the systems to generate metrics in nearly real-time for high volumes of data.",http://dx.doi.org/10.1007/978-981-10-8476-8_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-63962-8_240-1,Network Big Data Security Issues,Encyclopedia of Big Data Technologies,10.1007/978-3-319-63962-8_240-1,Springer,2018-01-01,,http://dx.doi.org/10.1007/978-3-319-63962-8_240-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-90424-5_21,Future of Capability Management,Capability Management in Digital Enterprises,10.1007/978-3-319-90424-5_21,Springer,2018-01-01,"Capability management has been the subject of a lot of research during the past years. Many of the results achieved have been presented in the previous chapters. Although the advancements have been substantial, a number of open issues and research questions remain. The chapter gives a summary on the ongoing research in the field and an outlook on future activities. More specifically, we discuss capability management for increasing cyber resilience, supporting digital transformation in organizations, managing big data, as well as carrying out continuous information system development.",http://dx.doi.org/10.1007/978-3-319-90424-5_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-017-4712-3,Challenges in the Analysis of Online Social Networks: A Data Collection Tool Perspective,Wireless Personal Communications,10.1007/s11277-017-4712-3,Springer,2017-12-01,"The present era of internet has radically changed the way people communicate with each other. Online Social Network platforms have enhanced this to real-time communication where interactions vary from casual relationships to formal bonding. This real-time communication between the users over Online Social Network platforms generates data which directly or indirectly gives lot of information. But extracting this data and mining information out of it is a profound challenge. Researchers need appropriate tools to churn out this data and get valuable information by analyzing and visualizing it. This paper does a comprehensive survey of types of Online Social Network Analysis resulting in segregation of research challenges associated with each of the types. A detailed study of the existing data collection tools and analysis techniques was further carried out to understand the challenges a researcher faces while using it. Finally, mapping analysis was done using research challenges, data collection tools and the types of Online Social Network Analysis, to understand to what extent the existing data collection tools and analysis techniques can meet the research challenges. The mapping analysis shows an absolute requirement of new data collection tools and algorithms by the researchers/developers .",http://dx.doi.org/10.1007/s11277-017-4712-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10515-017-0218-1,Experience report on applying software analytics in incident management of online service,Automated Software Engineering,10.1007/s10515-017-0218-1,Springer,2017-12-01,"As online services become more and more popular, incident management has become a critical task that aims to minimize the service downtime and to ensure high quality of the provided services. In practice, incident management is conducted through analyzing a huge amount of monitoring data collected at runtime of a service. Such data-driven incident management faces several significant challenges such as the large data scale, complex problem space, and incomplete knowledge. To address these challenges, we carried out 2-year software-analytics research where we designed a set of novel data-driven techniques and developed an industrial system called the Service Analysis Studio (SAS) targeting real scenarios in a large-scale online service of Microsoft. SAS has been deployed to worldwide product datacenters and widely used by on-call engineers for incident management. This paper shares our experience about using software analytics to solve engineers pain points in incident management, the developed data-analysis techniques, and the lessons learned from the process of research development and technology transfer.",http://dx.doi.org/10.1007/s10515-017-0218-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10791-017-9311-0,Product review summarization through question retrieval and diversification,Information Retrieval Journal,10.1007/s10791-017-9311-0,Springer,2017-12-01,"Product reviews have become an important resource for customers before they make purchase decisions. However, the abundance of reviews makes it difficult for customers to digest them and make informed choices. In our study, we aim to help customers who want to quickly capture the main idea of a lengthy product review before they read the details. In contrast with existing work on review analysis and document summarization, we aim to retrieve a set of real-world user questions to summarize a review. In this way, users would know what questions a given review can address and they may further read the review only if they have similar questions about the product. Specifically, we design a two-stage approach which consists of question selection and question diversification. For question selection phase, we first employ probabilistic retrieval models to locate candidate questions that are relevant to a given review. A Recurrent Neural Network Encoder–Decoder is utilized to measure the “answerability” of questions to a review. We then design a set function to re-rank the questions with the goal of rewarding diversity in the final question set. The set function satisfies submodularity and monotonicity, which results in an efficient greedy algorithm of submodular optimization. Evaluation on product reviews from two categories shows that the proposed approach is effective for discovering meaningful questions that are representative of individual reviews.",http://dx.doi.org/10.1007/s10791-017-9311-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11066-017-9122-x,Digital transformation in maritime ports: analysis and a game theoretic framework,NETNOMICS: Economic Research and Electronic Networking,10.1007/s11066-017-9122-x,Springer,2017-12-01,"Digitalization is pushing the maritime industry beyond its traditional limits and provides many new opportunities to enhance the productivity, efficiency, and sustainability of logistics. The concept of smart ports, for instance, aims to adopt modern information technologies to enable a better planning and management within and between ports. Strong facilitators of the digitalization are investments into technology and cooperations for promoting information sharing and a better coordination and collaboration, often regarded as a stumbling block in highly competitive environments. Besides many new opportunities, important economic issues and problems arise. We provide an overview of the development and state-of-the-art of digital transformation in modern seaports in order to identify current potentials and barriers. Focusing on the crucial and challenging aspects of coordination and collaboration, we present a conceptual game theoretic framework that allows benefits and cost allocations considering inter-, intra-, and meta-organizational perspectives. We further demonstrate how this framework can be used to develop tools and methods for supporting strategic decision making for driving the digital transformation in seaports and addressing new economic issues and problems.",http://dx.doi.org/10.1007/s11066-017-9122-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12517-017-3296-2,Web GIS and its architecture: a review,Arabian Journal of Geosciences,10.1007/s12517-017-3296-2,Springer,2017-11-29,"Phenomenal progress has been witnessed in the field of Geographic Information System (GIS) in recent times. The development of webGIS is the result of the growth of the Internet and consequently World Wide Web. The webGIS architecture is continuously changing according to contemporary technologies and requirements. In this paper, webGIS and its architectures are reviewed. Firstly, GIS and invention of the Internet are discussed. Evolution of webGIS is then covered along with major milestones of its development and open source initiatives. It is followed by discussion on client server architecture and its types. Thick and thin client architectures are then described and compared. As the paradigm in the computing world shifted towards web services, service-oriented architecture (SOA) is also discussed in context of webGIS. Spatial cloud computing and cloud-based architecture for webGIS are then described. The paper also provides a comparison of different webGIS architectures so that suitable architecture can be selected by the user based upon the requirements.",http://dx.doi.org/10.1007/s12517-017-3296-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-016-0429-6,A context-aware approach for trustworthy worker selection in social crowd,World Wide Web,10.1007/s11280-016-0429-6,Springer,2017-11-01,"Crowdsourcing applications like Amazon Mechanical Turk (AMT) make it possible to address many difficult tasks (e.g., image tagging and sentiment analysis) on the internet and make full use of the wisdom of crowd, where worker quality is one of the most crucial issues for the task owners. Thus, a challenging problem is how to effectively and efficiently select the high quality workers, so that the tasks online can be accomplished successfully under a certain budget. The existing methods on the crowd worker selection problem mainly based on the quality measurement of the crowd workers, those who have to register on the crowdsourcing platforms. With the connect of the OSNs and the crowdsourcing applications, the social contexts like social relationships and social trust between participants and social positions of participants can assist requestors to select one or a group of trustworthy crowdsourcing workers. In this paper, we first present a contextual social network structure and a concept of Strong Social Component (SSC) , which emblems a group of workers who have high social contexts values. Then, we propose a novel index for SSC , and a new efficient and effective algorithm C-AWSA to find trustworthy workers, who can complete the tasks with high quality. The results of our experiments conducted on four real OSN datasets illustrate that the superiority of our method in trustworthy worker selection.",http://dx.doi.org/10.1007/s11280-016-0429-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-016-9646-x,Index partitioning through a bipartite graph model for faster similarity search in recommendation systems,Information Systems Frontiers,10.1007/s10796-016-9646-x,Springer,2017-10-01,"Scalability of a recommendation system is an important factor for large e-commerce sites containing millions of products visited by millions of users. Similarity search is the core operation in recommendation systems. In this paper, we explain a framework to alleviate performance bottleneck of similarity search for very large-scale recommendation systems. The framework employs inverted index for real-time similarity search and handles dynamic updates. As the inverted index gets larger, retrieving recommendations become computationally expensive. There are various works devoted to solve this problem, such as clustering and preprocessing to compute recommendations offline. Our solution is based on bipartite graph partitioning for minimizing the affinity between entities in different partitions. Number of operations in similarity search is reduced by executing search within the closest partitions to the query. Parts are balanced, so that computational loads of partitions are almost the same, which is significant for reducing the computational cost. Sequential experiments with several different recommendation approaches and large datasets consisting of millions of users and items validate the scalability of the proposed recommendation framework. Accuracy drops only by a small factor due to partitioning, if any. Even slight improvements in recommendation accuracy are observed in our collaborative filtering experiments.",http://dx.doi.org/10.1007/s10796-016-9646-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40171-017-0159-3,Big Data Analytics: A Review on Theoretical Contributions and Tools Used in Literature,Global Journal of Flexible Systems Management,10.1007/s40171-017-0159-3,Springer,2017-09-01,"The importance of data science and big data analytics is growing very fast as organizations are gearing up to leverage their information assets to gain competitive advantage. The flexibility offered through big data analytics empowers functional as well as firm-level performance. In the first phase of the study, we attempt to analyze the research on big data published in high-quality business management journals. The analysis was visualized using tools for big data and text mining to understand the dominant themes and how they are connected. Subsequently, an industry-specific categorization of the studies was done to understand the key use cases. It was found that most of the existing research focuses majorly on consumer discretionary, followed by public administration. Methodologically, a major focus in such exploration is in social media analytics, text mining and machine learning applications for meeting objectives in marketing and supply chain management. However, it was found that not much focus was highlighted in these studies to demonstrate the tools used for the analysis. To address this gap, this study also discusses the evolution, types and usage of big data tools. The brief overview of big data technologies grouped by the services they enable and some of their applications are presented. The study categorizes these tools into big data analysis platforms, databases and data warehouses, programming languages, search tools, and data aggregation and transfer tools. Finally, based on the review, future directions for exploration in big data has been provided for academic and practice.",http://dx.doi.org/10.1007/s40171-017-0159-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41650-017-0031-9,Big data storage and management in SaaS applications,Journal of Communications and Information Networks,10.1007/s41650-017-0031-9,Springer,2017-09-01,"As an important service model for advanced computing, SaaS uses a defined protocol that manages services and applications. The popularity of advanced computing has reached a level that has led to the generation of large data sets, which is also called Big data. Big data is evolving with great velocity, large volumes, and great diversity. Such an amplification of data has brought into question the existing database tools in terms of their capabilities. Previously, storage and processing of data were simple tasks; however, it is now one of the biggest challenges in the industry. Experts are paying close attention to big data. Designing a system capable of storing and analyzing such data in order to extract meaningful information for decision-making is a priority. The Apache Hadoop, Spark, and NoSQL databases are some of the core technologies that are being used to solve these issues. This paper contributes to the solutions to the issues of big data storage and processing. It presents an analysis of the current technologies in the industry that could be useful in this context. Efforts have been focused on implementing a novel Trinity model, which is built using the lambda architecture with the following technologies: Hadoop, Spark, Kafka, and MongoDB.",http://dx.doi.org/10.1007/s41650-017-0031-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-015-0596-5,"Digital technologies and artificial intelligence’s present and foreseeable impact on lawyering, judging, policing and law enforcement",AI & SOCIETY,10.1007/s00146-015-0596-5,Springer,2017-08-01,"‘AI & Law’ research has been around since the 1970s, even though with shifting emphasis. This is an overview of the contributions of digital technologies, both artificial intelligence and non-AI smart tools, to both the legal professions and the police. For example, we briefly consider text mining and case-automated summarization, tools supporting argumentation, tools concerning sentencing based on the technique of case-based reasoning, the role of abductive reasoning, research into applying AI to legal evidence, tools for fighting crime and tools for identification.",http://dx.doi.org/10.1007/s00146-015-0596-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11769-017-0890-x,"Fourth Industrial Revolution: technological drivers, impacts and coping methods",Chinese Geographical Science,10.1007/s11769-017-0890-x,Springer,2017-08-01,"The world is marching into a new development period when the digital technology, physical technology, and biological technology have achieved an unprecedented development respectively in their own fields, and at the same time their applications are converging greatly. These are the three major technological drivers for the Fourth Industrial Revolution. This paper discusses the specific technology niches of each kind technological driver behind the Fourth Industrial Revolution, and then evaluates impacts of the Fourth Industrial Revolution on global industrial, economic, and social development. At last this paper proposes possible measures and policies for both firms and governments to cope with the changes brought by the Fourth Industrial Revolution.",http://dx.doi.org/10.1007/s11769-017-0890-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13635-017-0063-6,Selection of Pareto-efficient response plans based on financial and operational assessments,EURASIP Journal on Information Security,10.1186/s13635-017-0063-6,Springer,2017-07-10,"Finding adequate responses to ongoing attacks on ICT systems is a pertinacious problem and requires assessments from different perpendicular viewpoints. However, current research focuses on reducing the impact of an attack irregardless of side effects caused by responses. In order to achieve a comprehensive yet accurate response to possible and ongoing attacks on a managed ICT system, we propose an approach that evaluates a response from two perpendicular perspectives: (1) A response financial impact assessment, considering the financial benefits of restoring and protecting potentially threatened operational capabilities while considering implementation and maintenance costs of responses. (2) A response operational impact assessment, which assesses potential impacts that efficient mitigation actions may inadvertently cause on the organization in an operational perspective, e.g., negative side effects of deploying mitigations. It is the key benefit of the presented approach to combine all obtained evaluations with a multi-dimensional optimization procedure such that a response plan is selected which reduces a state of risk below an admissible level while minimizing potential negative side effects of deliberately taken actions.",http://dx.doi.org/10.1186/s13635-017-0063-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-016-1005-1,"Exploiting interactions of review text, hidden user communities and item groups, and time for collaborative filtering",Knowledge and Information Systems,10.1007/s10115-016-1005-1,Springer,2017-07-01,"Rich side information concerning users and items are valuable for collaborative filtering (CF) algorithms for recommendation. For example, rating score is often associated with a piece of review text, which is capable of providing valuable information to reveal the reasons why a user gives a certain rating. Moreover, the underlying community and group relationship buried in users and items are potentially useful for CF. In this paper, we develop a new model to tackle the CF problem which predicts user’s ratings on previously unrated items by effectively exploiting interactions among review texts as well as the hidden user community and item group information. We call this model CMR (co-clustering collaborative filtering model with review text). Specifically, we employ the co-clustering technique to model the user community and item group, and each community–group pair corresponds to a co-cluster, which is characterized by a rating distribution in exponential family and a topic distribution. We have conducted extensive experiments on 22 real-world datasets, and our proposed model CMR outperforms the state-of-the-art latent factor models. Furthermore, both the user’s preference and item profile are drifting over time. Dynamic modeling the temporal changes in user’s preference and item profiles are desirable for improving a recommendation system. We extend CMR and propose an enhanced model called TCMR to consider time information and exploit the temporal interactions among review texts and co-clusters of user communities and item groups. In this TCMR model, each community–group co-cluster is characterized by an additional beta distribution for time modeling. To evaluate our TCMR model, we have conducted another set of experiments on 22 larger datasets with wider time span. Our proposed model TCMR performs better than CMR and the standard time-aware recommendation model on the rating score prediction tasks. We also investigate the temporal effect on the user–item co-clusters.",http://dx.doi.org/10.1007/s10115-016-1005-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-2128-0,A survey of botnet detection based on DNS,Neural Computing and Applications,10.1007/s00521-015-2128-0,Springer,2017-07-01,"Botnet is a thorny and a grave problem of today’s Internet, resulting in economic damage for organizations and individuals. Botnet is a group of compromised hosts running malicious software program for malicious purposes, known as bots. It is also worth mentioning that the current trend of botnets is to hide their identities (i.e., the command and control server) using the DNS services to hinder their identification process. Fortunately, different approaches have been proposed and developed to tackle the problem of botnets; however, the problem still rises and emerges causing serious threat to the cyberspace-based businesses and individuals. Therefore, this paper comes up to explore the various botnet detection techniques through providing a survey to observe the current state of the art in the field of botnet detection techniques based on DNS traffic analysis. To the best of our knowledge, this is the first survey to discuss DNS-based botnet detection techniques in which the problems, existing solutions and the future research direction in the field of botnet detection based on DNS traffic analysis for effective botnet detection mechanisms in the future are explored and clarified.",http://dx.doi.org/10.1007/s00521-015-2128-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10922-017-9402-7,Decreasing the Management Burden in Multi-tier Systems Through Partial Correlation-Based Monitoring,Journal of Network and Systems Management,10.1007/s10922-017-9402-7,Springer,2017-07-01,"Modern web applications often consist of hundreds of services distributed in different servers or tiers. On one hand, this architecture may provide easy abstraction and modularity for software development and reuse. On the other hand, such architecture makes difficult to predict the behavior of the systems, as each tier has its own functionality, configuration, and demands for computing resources. Thus, anomaly detection becomes an important aspect for the management and operation of multi-tier web systems. In order to track their operation and aid on their behavior analysis, web systems expose numerous metrics in all the tiers. However, collecting and analyzing all available metrics reduces the system performance due to a non-negligible overhead on communication, storage, and processing. Another concern is the nature of the workload of these systems, which may fluctuate widely over time. One of the approaches to support anomaly detection in web systems is to use stable correlations among monitoring metrics. This approach, called correlation-based monitoring, does not require any deep understanding about the system internals or metric semantic, and also does not demand the existence of data about the faults. In addition, as only the metrics involved in stable correlations are periodically collected, the monitoring overhead is reduced. Stable correlations also have the desired property of holding for long period of time before becoming invalid due to workload fluctuations. The challenge, however, is to identify the stable correlations. In this work, we address this challenge by proposing three novel strategies based on partial correlation, a statistical tool commonly employed to summarize the relevant information of complex systems. We evaluate our strategies using traces obtained from an e-commerce, web transaction benchmark deployed in our testbed. Results show that our best strategy allows the construction of a monitoring network with less metrics than a state-of-the-art solution while achieving larger fault coverage. They also show that the correlations are reasonably stable, and the models can be applied for sufficiently long periods of time (at least 50 times the training time) before they become invalid.",http://dx.doi.org/10.1007/s10922-017-9402-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-017-1044-2,A review of task scheduling based on meta-heuristics approach in cloud computing,Knowledge and Information Systems,10.1007/s10115-017-1044-2,Springer,2017-07-01,"Heterogeneous distributed computing systems are the emerging for executing scientific and computationally intensive applications. Cloud computing in this context describes a paradigm to deliver the resource-like computing and storage on-demand basis using pay-per-use model. These resources are managed by data centers and dynamically provisioned to the users based on their availability, demand and quality parameters required to be satisfied. The task scheduling onto the distributed and virtual resources is a main concern which can affect the performance of the system. In the literature, a lot of work has been done by considering cost and makespan as the affecting parameters for scheduling the dependent tasks. Prior work has discussed the various challenges affecting the performance of dependent task scheduling but did not consider storage cost, failure rate-related challenges. This paper accomplishes a review of using meta-heuristics techniques for scheduling tasks in cloud computing. We presented the taxonomy and comparative review on these algorithms. Methodical analysis of task scheduling in cloud and grid computing is presented based on swarm intelligence and bio-inspired techniques. This work will enable the readers to decide suitable approach for suggesting better schemes for scheduling user’s application. Future research issues have also been suggested in this research work.",http://dx.doi.org/10.1007/s10115-017-1044-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-016-0456-1,The IoT electric business model: Using blockchain technology for the internet of things,Peer-to-Peer Networking and Applications,10.1007/s12083-016-0456-1,Springer,2017-07-01,"Nowadays, the development of traditional business models become more and more mature that people use them to guide various kinds of E-business activities. Internet of things (IoT), being an innovative revolution over the Internet, becomes a new platform for E-business. However, old business models could hardly fit for the E-business on the IoT. In this article, we 1) propose an IoT E-business model, which is specially designed for the IoT E-business; 2) redesign many elements in traditional E-business models; 3) realize the transaction of smart property and paid data on the IoT with the help of P2P trade based on the Blockchain and smart contract. We also experiment our design and make a comprehensive discuss.",http://dx.doi.org/10.1007/s12083-016-0456-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12530-016-9166-4,Sustainable mobility leveraging on 5G mobile communication infrastructures in the context of smart city operations,Evolving Systems,10.1007/s12530-016-9166-4,Springer,2017-06-01,"Economic growth has been strongly associated with urbanization, overwhelming cities with vehicles. This renders mobility inside cities problematic, since it is often associated with large waste of time in traffic congestions, environmental pollution and accidents. Cities struggle to invent and deploy continuously evolving, “smart” solutions in the domain of urban mobility, so as to improve the overall quality of life therein. In this context, the paper discusses on the fundamental challenges that cities face when trying to become smarter, focusing on the particular area of mobility-as-a-service. Moreover, the paper describes a specific framework that leverages on 5G mobile communication infrastructures, in order to increase the effectiveness of vehicular communications and the relevant mobility services and applications offered in urban environments.",http://dx.doi.org/10.1007/s12530-016-9166-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-014-2387-2,Towards next-generation business intelligence: an integrated framework based on DME and KID fusion engine,Multimedia Tools and Applications,10.1007/s11042-014-2387-2,Springer,2017-05-01,"Advances in information technology prompt a tremendous usage growth of the Internet. Online activities, such as e-commerce, social interaction, etc., have drawn increasing attentions in regard to the provision of personalized services which require best and comprehensive understanding of users. As an approach, this study outlines a general framework based on human (or consumer) contexts for the discovery and creation of business intelligence. Three major portions are discussed. First, the collection of human contexts, including activity logs in both cyber and physical worlds, is modeled. Second, data analysis was performed via proposed mining algorithms that concern potential fusion at different levels according to situations and ultimate purposes. Third, sustenance of developed model is then concentrated. An open platform was developed to support the evolutionary process of human models, and to allow contributions (e.g., data sharing, accessing, etc.) from third parties.",http://dx.doi.org/10.1007/s11042-014-2387-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10257-016-0330-y,A novel programming framework for architecting next generation enterprise scale information systems,Information Systems and e-Business Management,10.1007/s10257-016-0330-y,Springer,2017-05-01,"The increasing popularity and usage of internet based services makes design of software system complex and their power unlimited in scale. These systems often involve heterogeneous environment and platforms. They continuously evolve in order to meet the changes in technology and business practices. Emergence of information system architecture based on disparate externally provided internet based services warrant incorporation of novel design primitives in the application design. Traditionally popular application design primitives includes separation, abstraction, compression, uniform composition, replication and resource sharing that has evolved and came to vogue based on past experience and expert practice. This work examines and evaluates approaches to incorporation of new and novel unit operations around which applications can be architected, designed and analyzed for the internet computing and big data era. Incidentally it is found that portions of agent technology provides several unit operations such as migration of code and speech-act based responsibility delegation/application composition as application architectural primitives. This work determines extensions to Web Services-Business Process Execution Language (WS-BPEL) programming framework—called as ACtive Internet Application Framework (ACIAF) and is suited for incorporation of novel unit operations such as migration of code and speech-act based component orchestration/application composition to enable construction of next generation information systems. An analysis of merits and demerits of using WS-BPEL technology to realize ACIAF is also carried out here. Code mobility feature of ACIAF is demonstrated using a use case while loosely coupled application design using ACIAF is theoretically discussed. Formal analyzability of mobility behavior of ACIAF application is highlighted based on its conformance to Petri-net formalism. Further formal logical analyzability/interpolatability of individual actions performed by collaborating ACIAF applications is also highlighted. It is argued here that ACIAF shall provide necessary foundation, guidance and motivation for further detailed technical work on several ideas presented to realize next generation information systems. This work firmly establishes extension to WS-BPEL platform as a most viable approach to realize novel architectural primitives to the design and implementation of next generation information systems.",http://dx.doi.org/10.1007/s10257-016-0330-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-016-0985-1,Measuring similarity of users with qualitative preferences for service selection,Knowledge and Information Systems,10.1007/s10115-016-0985-1,Springer,2017-05-01,"Similarity measures are essential in many preference-based personalized applications such as collaborative recommendation and web service selection. However, previous studies have been mainly focused on the similarity measures for quantitative preference rather than those for qualitative preference, though the latter has attracted much attention recently. This paper aims to fill in this gap by proposing an intuitive similarity measure for conditional qualitative preference which is represented by CP-nets. In particular, we introduce two methods, a basic and a general similarity measures, corresponding to whether two CP-nets share similar structures and contents or not. Experimental results on two real-world data sets demonstrate that our similarity measure can not only correctly reflect the changes of users’ preferences, but also be effective in identifying similar users. In addition, only by adopting the K most important attributes, the computational cost can be greatly reduced while sufficiently high accuracy is preserved. Furthermore, we demonstrate the effectiveness of our method in complementing users’ preferences by aggregating those of similar users in a scenario where users’ preferences are incomplete.",http://dx.doi.org/10.1007/s10115-016-0985-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13740-016-0061-8,Using Implicit Preference Relations to Improve Recommender Systems,Journal on Data Semantics,10.1007/s13740-016-0061-8,Springer,2017-03-01,"Our work is generally focused on making recommendations for small or medium-sized e-commerce portals, where we are facing scarcity of explicit feedback, low user loyalty, short visit durations or a low number of visited objects. In this paper, we present a novel approach to use a specific user behavior pattern as implicit feedback, forming binary relations between objects. Our hypothesis is that if a user selects a specific object from the list of displayed objects, it is an expression of his/her binary preference between the selected object and others that are visible, but ignored. We expand this relation with content-based similarity of objects. We define implicit preference relation (IPR) a partial ordering of objects based on similarity expansion of ignored-selected preference relation. We propose a merging algorithm utilizing the synergic effect of two approaches this IPR partial ordering and a list of recommended objects based on any/another algorithm. We report on a series of offline experiments with various recommending algorithms on two real-world e-commerce datasets. The merging algorithm could improve the ranked list of most of the evaluated algorithms in terms of nDCG. Furthermore, we also provide access to the relevant datasets and source codes for further research.",http://dx.doi.org/10.1007/s13740-016-0061-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-016-0191-8,CluCF: a clustering CF algorithm to address data sparsity problem,Service Oriented Computing and Applications,10.1007/s11761-016-0191-8,Springer,2017-03-01,"In QoS-based Web service recommendation, predicting Quality of Service (QoS) for users will greatly aid service selection and discovery. Collaborative filtering (CF) is an effective method for Web service selection and recommendation. Data sparsity is an important challenges for CF algorithms. Although model-based algorithms can address the data sparsity problem, those models are often time-consuming to build and update. Thus, these CF algorithms aren’t fit for highly dynamic and large-scale environments, such as Web service recommendation systems. In order to overcome this drawback, this paper proposes a novel approach CluCF, which employs user clusters and service clusters to address the data sparsity problem and classifies the new user (the new service) by location factor to lower the time complexity of updating clusters. Additionally, in order to improve the prediction accuracy, CluCF employs time factor. Time-aware user-service matrix Mu;s(tk, d) is introduced, and the time-aware similarity measurement and time-aware QoS prediction are employed in this paper. Since the QoS performance of Web services is highly related to invocation time due to some time-varying factors (e.g., service status, network condition), time-aware similarity measurement and time-aware QoS prediction are more trustworthy than traditional similarity measurement and QoS prediction, respectively. Since similarity measurement and QoS prediction are two key steps of neighborhood-based CF, time-aware CF will be more accurate than traditional CF. Moreover, our approach systematically combines user-based and item-based methods and employs influence weights to balance these two predicted values, automatically. To validate our algorithm, this paper conducts a series of large-scale experiments based on a real-world Web service QoS dataset. Experimental results show that our approach is capable of alleviating the data sparsity problem.",http://dx.doi.org/10.1007/s11761-016-0191-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-015-1870-7,Modeling and predicting the user next input by Bayesian reasoning,Soft Computing,10.1007/s00500-015-1870-7,Springer,2017-03-01,"We focus on enhancing the user experience by predicting entries when a form is filled, according to past interactions. The purpose of having a predictive model of form filling is to reduce the amount of time required to fill a form, and thus to reduce the fatigue and repetitiveness associated to this common task. Generally predictive models ignore the values entered by users in the other fields in the form, and just focus on the value getting entered at the current field. This is a limit to the model capabilities. Instead, we are aimed at predicting the sequence of entries in a form, instead of the value of single fields in isolation. This is done by means of inference over a Bayesian network, able to compute the a posteriori probability that remaining fields will assume certain values, given the set of values entered so far. The model structure and parameters can be learned from a dataset of past entries. The paper investigates computational and convergence issues under both the closed world assumption and the open world assumptions. As case study, we considered forms used for online payment of money order used at Poste Italiane, and we exploited this approach to prototype two different solutions for desktop and mobile applications. Results of experimentation with a user test group prove the proposed approach is able to provide an effective and appreciated support in filling a form.",http://dx.doi.org/10.1007/s00500-015-1870-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10618-016-0482-x,Modeling user interests from web browsing activities,Data Mining and Knowledge Discovery,10.1007/s10618-016-0482-x,Springer,2017-03-01,"Browsing sessions are rich in elements useful to build profiles of user interests, but at the same time HTML pages include noisy data such as advertisements, navigation menus and privacy notes. Moreover, some pages cover several different topics making it difficult to identify the most relevant to the user. For these reasons, they are often ignored by personalized search and recommender systems. We propose a novel approach for recognizing valuable text descriptions of current user information needs—namely cues —based on the data mined from browsing interactions over the web. The approach combines page clustering techniques based on Document Object Model-based representations for acquiring evidence about relevant correlations between text contents. This evidence is exploited for better filtering out irrelevant information and facilitating the construction of interest profiles. A comparative framework proves the accuracy of the extracted cues in the personalize search task, where results are re-ranked according to the last browsed resources.",http://dx.doi.org/10.1007/s10618-016-0482-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-015-9413-5,FOREPOST: finding performance problems automatically with feedback-directed learning software testing,Empirical Software Engineering,10.1007/s10664-015-9413-5,Springer,2017-02-01,"A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster in order to automatically find performance bottlenecks in applications. We propose FOREPOST, a novel solution, for automatically finding performance bottlenecks in applications using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications. Theses rules are then used to automatically select test input data for performance testing. We hypothesize that FOREPOST can find more performance bottlenecks as compared to random testing. We have implemented our solution and applied it to a medium-size industrial application at a major insurance company and to two open-source applications. Performance bottlenecks were found automatically and confirmed by experienced testers and developers. We also thoroughly studied the factors (or independent variables) that impact the results of FOREPOST.",http://dx.doi.org/10.1007/s10664-015-9413-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-016-0937-9,Selective AnDE for large data learning: a low-bias memory constrained approach,Knowledge and Information Systems,10.1007/s10115-016-0937-9,Springer,2017-02-01,"Learning from data that are too big to fit into memory poses great challenges to currently available learning approaches. Averaged n -Dependence Estimators (A n DE) allows for a flexible learning from out-of-core data, by varying the value of n (number of super parents). Hence, A n DE is especially appropriate for learning from large quantities of data. Memory requirement in A n DE, however, increases combinatorially with the number of attributes and the parameter n . In large data learning, number of attributes is often large and we also expect high n to achieve low-bias classification. In order to achieve the lower bias of A n DE with higher n but with less memory requirement, we propose a memory constrained selective A n DE algorithm, in which two passes of learning through training examples are involved. The first pass performs attribute selection on super parents according to available memory, whereas the second one learns an A n DE model with parents only on the selected attributes. Extensive experiments show that the new selective A n DE has considerably lower bias and prediction error relative to A $$n'$$ n ′ DE, where $$n' = n-1$$ n ′ = n - 1 , while maintaining the same space complexity and similar time complexity. The proposed algorithm works well on categorical data. Numerical data sets need to be discretized first.",http://dx.doi.org/10.1007/s10115-016-0937-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-2334-5_6,Machine Learning Theory and Practices,Machine Learning Using R,10.1007/978-1-4842-2334-5_6,Springer,2017-01-01,"The world is quickly adapting the use of Machine Learning (ML). Whether its driverless cars, the intelligent personal assistant, or machines playing the games like Go and Jeopardy against humans, ML is pervasive.",http://dx.doi.org/10.1007/978-1-4842-2334-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-2988-0_3,Machine Learning Algorithms and Their Relationship with Modern Technologies,Machine Learning for Decision Makers,10.1007/978-1-4842-2988-0_3,Springer,2017-01-01,"In this chapter, I provide the executive summary of the machine learning algorithms. I do this because for any decision maker it is important to understand, analyze, and evaluate the ground level reality of the business and technological landscape. This is equally critical for managers, because proper understanding of algorithms and associated technologies will make them more confident to manage their projects in a better way. It becomes more crucial when it comes to machine learning based project implementations and strategies because of the high technical aspects of the subject. Hence, having a practical overview of the algorithms and their behaviors in real-time business scenarios will enlighten you to make accurate decisions and define thoughtful roadmaps for your teams and organizations.",http://dx.doi.org/10.1007/978-1-4842-2988-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-57529-2_41,Web-Scale Personalized Real-Time Recommender System on Suumo,Advances in Knowledge Discovery and Data Mining,10.1007/978-3-319-57529-2_41,Springer,2017-01-01,"In this paper we investigate the performance of machine learning based recommender system with real-time log streaming on a large real-estate site, in the views of system robustness, business productivity and algorithm performance. Our proposed recommender system, providing personalized contents as opposed to item/query based recommendation, consists of a real-time log processor, auto-scaling recommender API and machine learning modules. System is carefully designed to let data scientists focus on improving core algorithms and features (instead of taking care of distributing systems) and achieves weekly release cycle in production environment. On Suumo, the largest real-estate portal site in Japan, the system returns more than 99.9% of the API calls successfully in real-time and shows finally a 250% improvement of conversion rate compared to the existing recommendation. With its flexible nature, we would also expect the system to be applied in various kinds of real-time recommendation in the near future.",http://dx.doi.org/10.1007/978-3-319-57529-2_41,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-60161-8_3,IT and the Consumer,The Web at Graduation and Beyond,10.1007/978-3-319-60161-8_3,Springer,2017-01-01,"In this chapter we look at the implications for consumers in light of the developments (technological and otherwise) that we have presented in the previous two chapters. We start with electronic commerce and look at various approaches that businesses, both brick-and-mortar and mobile, now have at their disposal for getting their message to the customer, including advertising, social media marketing, and recommendation.",http://dx.doi.org/10.1007/978-3-319-60161-8_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-71273-4_7,Disjoint-Support Factors and Seasonality Estimation in E-Commerce,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-319-71273-4_7,Springer,2017-01-01,"Successful inventory management in retail entails accurate demand forecasts for many weeks/months ahead. Forecasting models use seasonality : recurring pattern of sales every year, to make this forecast. In e-commerce setting, where the catalog of items is much larger than brick and mortar stores and hence includes a lot of items with short history, it is infeasible to compute seasonality for items individually. It is customary in these cases to use ideas from factor analysis and express seasonality by a few factors/basis vectors computed together for an entire assortment of related items. In this paper, we demonstrate the effectiveness of choosing vectors with disjoint support as basis for seasonality when dealing with a large number of short time-series. We give theoretical results on computation of disjoint support factors that extend the state of the art, and also discuss temporal regularization necessary to make it work on walmart e-commerce dataset. Our experiments demonstrate a marked improvement in forecast accuracy for items with short history.",http://dx.doi.org/10.1007/978-3-319-71273-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-54024-5_3,The Princeton Web Transparency and Accountability Project,Transparent Data Mining for Big and Small Data,10.1007/978-3-319-54024-5_3,Springer,2017-01-01,"When you browse the web, hidden “third parties” collect a large amount of data about your behavior. This data feeds algorithms to target ads to you, tailor your news recommendations, and sometimes vary prices of online products. The network of trackers comprises hundreds of entities, but consumers have little awareness of its pervasiveness and sophistication. This chapter discusses the findings and experiences of the Princeton Web Transparency Project ( https://webtap.princeton.edu/ ), which continually monitors the web to uncover what user data companies collect, how they collect it, and what they do with it. We do this via a largely automated monthly “census” of the top 1 million websites, in effect “tracking the trackers”. Our tools and findings have proven useful to regulators and investigatory journalists, and have led to greater public awareness, the cessation of some privacy-infringing practices, and the creation of new consumer privacy tools. But the work raises many new questions. For example, should we hold websites accountable for the privacy breaches caused by third parties? The chapter concludes with a discussion of such tricky issues and makes recommendations for public policy and regulation of privacy.",http://dx.doi.org/10.1007/978-3-319-54024-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5107-4_2,Predictive Computing and Information Security: A Technical Review,Predictive Computing and Information Security,10.1007/978-981-10-5107-4_2,Springer,2017-01-01,"With the advancement in technology and computing techniques, it has become possible to integrate several different technologies that make task of data processing in real-time easier and faster. It is believed that integration of cloud computing and IoT with wireless sensor networks will completely reshape the Information and Communication Technology (ICT) industry. One major advantage of this integration is that it has become easy to design predictive computing-based techniques and models for many key areas. In this chapter, we have focused on these hot key areas, where predictive computing-based techniques and frameworks are applied for better human living and environment. We aim to pinpoint the predictive techniques, data handling techniques, sustainable techniques, navigation techniques, intelligent agents, smart object based techniques. Key areas for the predictive framework: healthcare, smart home, navigation, e-commerce are discussed. Security in context to predictive computing can be defined in terms of data confidentiality, privacy and trust. At the end, we have given the key challenges related to integration and implementation of IoT and cloud computing.",http://dx.doi.org/10.1007/978-981-10-5107-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-47474-8_20,Self-awareness of Cloud Applications,Self-Aware Computing Systems,10.1007/978-3-319-47474-8_20,Springer,2017-01-01,"Cloud applications today deliver an increasingly larger portion of the information and communications technology (ICT) services. To address the scale, growth, and reliability of cloud applications, self-aware management and scheduling are becoming commonplace. How are they used in practice? In this chapter, we propose a conceptual framework for analyzing the state-of-the-art self-awareness approaches used in the context of cloud applications. We map important applications corresponding to the popular and emerging application domains to this conceptual framework and compare the practical characteristics, benefits, and drawbacks of self-awareness approaches. Last, we propose a road map for addressing the open challenges in self-aware cloud and datacenter applications.",http://dx.doi.org/10.1007/978-3-319-47474-8_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-54024-5_8,"Regulating Algorithms’ Regulation? First Ethico-Legal Principles, Problems, and Opportunities of Algorithms",Transparent Data Mining for Big and Small Data,10.1007/978-3-319-54024-5_8,Springer,2017-01-01,"Algorithms are regularly used for mining data, offering unexplored patterns and deep non-causal analyses in what we term the “classifying society”. In the classifying society individuals are no longer targetable as individuals but are instead selectively addressed for the way in which some clusters of data that they (one or more of their devices) share with a given model fit in to the analytical model itself. This way the classifying society might bypass data protection as we know it. Thus, we argue for a change of paradigm: to consider and regulate anonymities—not only identities—in data protection. This requires a combined regulatory approach that blends together (1) the reinterpretation of existing legal rules in light of the central role of privacy in the classifying society; (2) the promotion of disruptive technologies for disruptive new business models enabling more market control by data subjects over their own data; and, eventually, (3) new rules aiming, among other things, to provide to data generated by individuals some form of property protection similar to that enjoyed by the generation of data and models by businesses (e.g. trade secrets). The blend would be completed by (4) the timely insertion of ethical principles in the very generation of the algorithms sustaining the classifying society.",http://dx.doi.org/10.1007/978-3-319-54024-5_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69035-3_21,An Artifact-Driven Approach to Monitor Business Processes Through Real-World Objects,Service-Oriented Computing,10.1007/978-3-319-69035-3_21,Springer,2017-01-01,"Nowadays, many business processes once intra-organizational are becoming inter-organizational. Thus, being able to monitor how such processes are performed, including portions carried out by service providers, is paramount. Yet, traditional process monitoring techniques present some shortcomings when dealing with inter-organizational processes. In particular, they require human operators to notify when business activities are performed, and to stop the process when it is not executed as expected. In this paper, we address these issues by proposing an artifact-driven monitoring service, capable of autonomously and continuously monitor inter-organizational processes. To do so, this service relies on the state of the artifacts (i.e., physical entities) participating to the process, represented using the E-GSM notation. A working prototype of this service is presented and validated using real-world processes and data from the logistics domain.",http://dx.doi.org/10.1007/978-3-319-69035-3_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-62594-2_7,Detecting Anomaly in Cloud Platforms Using a Wavelet-Based Framework,Cloud Computing and Services Science,10.1007/978-3-319-62594-2_7,Springer,2017-01-01,"Cloud computing enables the delivery of compute resources as services in an on-demand fashion. The reliability of these services is of significant importance to their consumers. The presence of anomaly in Cloud platforms can put their reliability into question, since an anomaly indicates deviation from normal behaviour. Monitoring enables efficient Cloud service provisioning management; however, most of the management efforts are focused on the performance of the services and little attention is paid to detecting anomalous behaviour from the gathered monitoring data. In addition, the existing solutions for detecting anomaly in Clouds lacks a multi-dimensional approach. In this chapter, we present a wavelet-based anomaly detection framework that is capable of analysing multiple monitored metrics simultaneously to detect anomalous behaviour. It operates in both frequency and time domains in analysing monitoring data that represents system behaviour. The framework is first trained using over seven days worth of historical monitoring data to identify healthy behaviour. Based on this training, anomalous behaviour can be detected as deviations from the healthy system. The effectiveness of the proposed framework was evaluated based on a Cloud service deployment use-case scenario that produced both healthy and anomalous behaviour.",http://dx.doi.org/10.1007/978-3-319-62594-2_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-57015-0_3,The Smart City in Practice,Understanding Smart Cities: A Tool for Smart Government or an Industrial Trick?,10.1007/978-3-319-57015-0_3,Springer,2017-01-01,"In the previous chapter, it has been realized that smart city concerns urban innovation not necessarily but mainly based on ICT. This kind of innovation structures the smart city ecosystem, which was presented as a multi-tier scheme (Fig.  2.7 ). This figure indicates the different types of hard and soft technologies that are being built by the smart city industry and can be classified as in the following subsections. In each of the following sub-sections a brief presentation and discussion is performed for these technologies and the reader must seek for further details to explore them deeper.",http://dx.doi.org/10.1007/978-3-319-57015-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4899-7687-1_964,Recommender Systems,Encyclopedia of Machine Learning and Data Mining,10.1007/978-1-4899-7687-1_964,Springer,2017-01-01,,http://dx.doi.org/10.1007/978-1-4899-7687-1_964,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-58484-3_35,Analyzing Load Profiles of Electricity Consumption by a Time Series Data Mining Framework,"HCI in Business, Government and Organizations. Supporting Business",10.1007/978-3-319-58484-3_35,Springer,2017-01-01,"Given the problems of gradual oil depletion and global warming, energy consumption has become a critical factor for energy-intensive sectors, especially the semiconductor, manufacturing, iron and steel, and aluminum industries. In turn, reducing energy consumption for sustainability and both tracking and managing energy efficiently have become critical challenges. In response, we analyzed electricity consumption from the perspective of load profiling, which charts variation in electrical load during a specified period in order to track energy consumption. As a result, we proposed a time series data mining and analytic framework for electricity consumption analysis and pattern extraction by streaming data mining and machine learning techniques. We identified key factors to predict the state of the annealing furnace and detect abnormal patterns of the load profile of their electricity consumption. Our experimental results show that the dimension reduction method known as piecewise aggregate approximation can help to detect the state of the annealing furnace.",http://dx.doi.org/10.1007/978-3-319-58484-3_35,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-62386-3_3,The Stuttgart IT Architecture for Manufacturing,Enterprise Information Systems,10.1007/978-3-319-62386-3_3,Springer,2017-01-01,"The global conditions for manufacturing are rapidly changing towards shorter product life cycles, more complexity and more turbulence. The manufacturing industry must meet the demands of this shifting environment and the increased global competition by ensuring high product quality, continuous improvement of processes and increasingly flexible organization. Technological developments towards smart manufacturing create big industrial data which needs to be leveraged for competitive advantages. We present a novel IT architecture for data-driven manufacturing, the Stuttgart IT Architecture for Manufacturing (SITAM). It addresses the weaknesses of traditional manufacturing IT by providing IT systems integration, holistic data analytics and mobile information provisioning. The SITAM surpasses competing reference architectures for smart manufacturing because it has a strong focus on analytics and mobile integration of human workers into the smart production environment and because it includes concrete recommendations for technologies to implement it, thus filling a granularity gap between conceptual and case-based architectures. To illustrate the benefits of the SITAM’s prototypical implementation, we present an application scenario for value-added services in the automotive industry.",http://dx.doi.org/10.1007/978-3-319-62386-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-57285-7_8,Human-Computer Agent Negotiation Using Cross Culture Reliability Models,Conflict Resolution in Decision Making,10.1007/978-3-319-57285-7_8,Springer,2017-01-01,"People’s cultural background has been shown to affect the way they reach agreements in negotiation and how they fulfill these agreements. This paper presents a novel methodology that can be used as a good infrastructure to design a computer-agent for negotiating with people from different cultures. Our setting involved data from different agents and human versus human data that were based on an alternating-offer protocol that allowed parties to choose the extent to which they kept each of their agreements during the negotiation. A challenge to develop this methodology for such setting is to create cross culture models automatically that will predict how people reciprocate their actions over time, despite the scarcity of prior data on different cultures. Our methodology addresses this challenge by using a Leave-One-Out algorithm named CCMA, which is described in Sect.  5 , with classical machine learning algorithms to predict the extent to which people fulfill agreements. Our methodology based its strategy on a data from different agents that used the same negotiation scenario in different cultures. This methodology used data in three countries: Lebanon, the U.S.A and Israel, in which people are known to vary widely in their negotiation behaviour. Our methodology was able to find the accurate models that should be used when designing a computer-agent in the negotiation scenario.",http://dx.doi.org/10.1007/978-3-319-57285-7_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5026-8_8,Dynamic Selection of Virtual Machines for Application Servers in Cloud Environments,Research Advances in Cloud Computing,10.1007/978-981-10-5026-8_8,Springer,2017-01-01,"Autoscaling is a hallmark of cloud computing as it allows flexible just-in-time allocation and release of computational resources in response to dynamic and often unpredictable workloads. This is especially important for web applications, whose workload is time dependent and prone to flash crowds. Most of them follow the 3-tier architectural pattern, and are divided into presentation, application/domain and data layers. In this work, we focus on the application layer. Reactive autoscaling policies of the type “ Instantiate a new Virtual Machine (VM) when the average server CPU utilisation reaches X% ” have been used successfully since the dawn of cloud computing. But which VM type is the most suitable for the specific application at the moment remains an open question. In this work, we propose an approach for dynamic VM type selection. It uses a combination of online machine learning techniques, works in real time and adapts to changes in the users’ workload patterns, application changes as well as middleware upgrades and reconfigurations. We have developed a prototype, which we tested with the CloudStone benchmark deployed on AWS EC2. Results show that our method quickly adapts to workload changes and reduces the total cost compared to the industry standard approach.",http://dx.doi.org/10.1007/978-981-10-5026-8_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4899-7687-1_833,Text Mining for News and Blogs Analysis,Encyclopedia of Machine Learning and Data Mining,10.1007/978-1-4899-7687-1_833,Springer,2017-01-01,"News and blogs are temporally indexed online texts and play a key role in today’s information distribution and consumption. News communicate selected information on current events, written by professional or citizen journalists; blogs are updated publications on the Web that span a much wider range of topics, styles, and authors. Particularly important in recent years have been microblogs such as Twitter. The entry gives an overview of how text mining (for tasks such as description, classification, prediction, search, recommendation, or summarization) is applied to analyze the textual parts of news and blogs, extracting topics, events, opinions, sentiments, and other aspects of content. Often, textual analysis is complemented by the analysis of further data such as the social network of authors and readers. The properties of news and blogs data structures and language use require methods for preprocessing and analyzing that are tailored to news and (micro)blogs, and the tasks often profit from an interactive approach in which the user plays an active role in sensemaking. The methods are deployed in a wide range of applications and services.",http://dx.doi.org/10.1007/978-1-4899-7687-1_833,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69035-3_28,"
      
                  
                    
                  
                  $$\mathbb {ECHO}$$
                : An Adaptive Orchestration Platform for Hybrid Dataflows across Cloud and Edge",Service-Oriented Computing,10.1007/978-3-319-69035-3_28,Springer,2017-01-01,"The Internet of Things (IoT) is offering unprecedented observational data that are used for managing Smart City utilities. Edge and Fog gateway devices are an integral part of IoT deployments to acquire real-time data and enact controls. Recently, Edge-computing is emerging as first-class paradigm to complement Cloud-centric analytics. But a key limitation is the lack of a platform-as-a-service for applications spanning Edge and Cloud. Here, we propose $$\mathbb {ECHO}$$ , an orchestration platform for dataflows across distributed resources. $$\mathbb {ECHO}$$ ’s hybrid dataflow composition can operate on diverse data models – streams, micro-batches and files, and interface with native runtime engines like TensorFlow and Storm to execute them. It manages the application’s lifecycle, including container-based deployment and a registry for state management. $$\mathbb {ECHO}$$ can schedule the dataflow on different Edge, Fog and Cloud resources, and also perform dynamic task migration between resources. We validate the $$\mathbb {ECHO}$$ platform for executing video analytics and sensor streams for Smart Traffic and Smart Utility applications on Raspberry Pi, NVidia TX1, ARM64 and Azure Cloud VM resources, and present our results.",http://dx.doi.org/10.1007/978-3-319-69035-3_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-41163-7_6,Recommender Systems in E-Learning Environments,E-Learning Systems,10.1007/978-3-319-41163-7_6,Springer,2017-01-01,"Recommender system can be defined as a platform for providing recommendations to users based on their personal likes and dislikes. These systems use a specific type of information filtering technique that attempt to recommend information items (movies, music, books, news, Web pages, learning objects, and so on.) to the user. Recommender systems strongly depend on the context or domain they operate in, and it is often not possible to take a recommendation strategy from one context and transfer it to another context or domain. Personalized recommendation can help learners to overcome the information overload problem, by recommending learning resources according to learners’ habits and level of knowledge. The first challenge for designing a recommender component for e-learning systems is to define the learners and the purpose of the specific context or domain in a proper way. This chapter provides an overview of techniques for recommender systems, folksonomy and tag-based recommendation to assist the reader in understanding the material which follows in subsequent chapters.",http://dx.doi.org/10.1007/978-3-319-41163-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-5107-4_7,Applications of Predictive Computing,Predictive Computing and Information Security,10.1007/978-981-10-5107-4_7,Springer,2017-01-01,"Predictive computing has become a core enterprise exercise necessary for the sustenance of an organization in this competitive business world. This practice empowers the business to evolve by organizing data-driven tasks and by applying organizational learning to enable business to not only survive but to excel across multiple fronts. In this chapter, various applications where predictive computing can be deployed are presented. Three case studies; smart mobility using predictive computing, e-Health using predictive computing, and finally, e-Logistics using predictive computing are discussed. In each case study, various applications for deploying predictive computing are discussed.",http://dx.doi.org/10.1007/978-981-10-5107-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7098-3_12,Fuzzy Models and Business Intelligence in Web-Based Applications,Applications of Soft Computing for the Web,10.1007/978-981-10-7098-3_12,Springer,2017-01-01,"A significant amount of data gathered by the web-based applications are analyzed to generate more business opportunity and to make critical decisions based on predictability. Automation with decent intelligence makes it possible to model the amount of associated risk and well-assessed mitigation plan. The deviation of actual results from the prediction could be used to improve the prediction quality using evolutionary techniques. Not only the input and the output of such software engines but the process rules also could be best modelled by fuzzy set theory. This chapter focuses on discussing the fuzzy models, their applicability, and ability to provide solutions to such applications. This chapter also gives an overview of the software components as a high-level design that could be used to understand the relationship between the artifacts. The overall discussion also focuses on understanding the nature of business domain criteria which maps to critical elements of decision making in business intelligence in the context of the application of well-established algorithms that work on the fuzzy data set to formulate a decision. During this part of the discussion, we introduce the common deficiencies in a range of decision-making algorithms that may produce the wrong result. This anomaly may creep in because of the presence of the outliers in the decision table leading to affect the steps of the algorithm. We also propose an algorithm to deal with outliers to rectify the result in three well-known methods.",http://dx.doi.org/10.1007/978-981-10-7098-3_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-53417-6_10,What Is Data Analysis from Data Warehousing Perspective?,"Business Resilience System (BRS): Driven Through Boolean, Fuzzy Logics and Cloud Computation",10.1007/978-3-319-53417-6_10,Springer,2017-01-01,"Analysis of data is a process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information; suggesting conclusions; and supporting decision-making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, in different business, science, and social science domains. Data is collected from a variety of sources. The requirements may be communicated by analysts to custodians of the data, such as information technology personnel within an organization. The data may also be collected from sensors in the environment, such as traffic cameras, satellites, recording devices, etc. It may also be obtained through interviews, downloads from online sources, or reading documentation. Data initially obtained must be processed or organized for analysis. For instance, these may involve placing data into rows and columns in a table format (i.e., structured data) for further analysis, such as within a spreadsheet or statistical software.",http://dx.doi.org/10.1007/978-3-319-53417-6_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-60161-8_6,The Road Ahead: Living in a Digital World,The Web at Graduation and Beyond,10.1007/978-3-319-60161-8_6,Springer,2017-01-01,"Worldwide, economic activities are now largely driven by information and communication technologies. Indeed, few areas of society remain untouched by the disruptive impacts of ICT, and there is little doubt: we are not only rapidly heading towards the digital economy, but to an entirely digital world as well. So the question is: how do we want to live, learn, and work in this world? Future-focused answers must be found to these questions.",http://dx.doi.org/10.1007/978-3-319-60161-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-57391-5_6,Performing Data Routing and Real-Time Analysis,Building an Effective IoT Ecosystem for Your Business,10.1007/978-3-319-57391-5_6,Springer,2017-01-01,"As a consequence of the proliferation of connected products and people, we must change our data acquisition and processing strategies to accommodate new data-driven business models and connected product development. A connected product enables us to gather and analyze various data including product usages, updates, operating status, maintenance history and interactions with users while it is in-service. As an OEM, you must able to use collected information to improve and enhance product performances and features. Also, you can develop new offerings based on new insights from data analytics.",http://dx.doi.org/10.1007/978-3-319-57391-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-7098-3_2,Context Similarity Measurement Based on Genetic Algorithm for Improved Recommendations,Applications of Soft Computing for the Web,10.1007/978-981-10-7098-3_2,Springer,2017-01-01,"Recommender Systems (RSs) are new types of internet-based software tools, used to provide personalized recommendations to users by handling information overload problem on the Web. Collaborative Filtering (CF), the most known and commonly used recommendation technique in the domain of RSs, generates recommendations toward items which were preferred by other like-minded users in the past. Computing similarity among users efficiently in case of sparse data is the major concern of CF technique. A recent study observed that Context Awareness in CF (CACF) is the next generation of the traditional user–item RSs which provides more accurate and relevant situational recommendations by incorporating contextual ratings given by the user. In this work, we first extend two-dimensional RSs by incorporating contextual information into fuzzy CF user profile (CA-FCF) through contextual rating count approach. Second, we employ genetic algorithm into CACF (GA-CA-FCF) to learn user preferences on individual hybrid user features. By learning the weights on each feature, the user similarity is computed efficiently. We evaluate our approach with Mean Absolute Error (MAE) and coverage performance measures using LDOS-CoMoDa dataset. Experimental results show that our approach has an acceptable improvement in the accuracy with comparisons to classical CF approaches.",http://dx.doi.org/10.1007/978-981-10-7098-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-53417-6_2,Building Intelligent Models from Data Mining,"Business Resilience System (BRS): Driven Through Boolean, Fuzzy Logics and Cloud Computation",10.1007/978-3-319-53417-6_2,Springer,2017-01-01,"In order for Business Resilience System to function and induced advanced warning for proper action, the BRS Risk Atom and, in particular, the fourth orbit have to stay in stable status, by assessing the risk elements and responses. Thus, looking at risk assessment and understanding it are an essential fact, and it is inevitable; therefore, we need to build an intelligent model to invoke information from variety of data available to us at more than terabyte from around the globe we are living on. These data need to be processed by Process Data Point in the core of Risk Atom, either real time or manually. The feed point for PDP is structured on fuzzy or Boolean logic as suggested by us authors in this book. This chapter under lays foundation for Risk Atom by discussing the risk assessment and goes through process of building intelligent models, along with data mining and expert knowledge and a look at some fundamental principles that can interact with the Risk Atom.",http://dx.doi.org/10.1007/978-3-319-53417-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4614-7163-9_110162-1,Recommender Systems Evaluation,Encyclopedia of Social Network Analysis and Mining,10.1007/978-1-4614-7163-9_110162-1,Springer,2017-01-01,,http://dx.doi.org/10.1007/978-1-4614-7163-9_110162-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13198-015-0376-0,Cross-Site Scripting (XSS) attacks and defense mechanisms: classification and state-of-the-art,International Journal of System Assurance Engineering and Management,10.1007/s13198-015-0376-0,Springer,2017-01-01,"Nowadays, web applications are becoming one of the standard platforms for representing data and service releases over the World Wide Web. Since web applications are progressively more utilized for security-critical services, therefore they have turned out to be a well-liked and precious target for the web-related vulnerabilities. Even though several defensive mechanisms have been building up to reinforce the modern web applications and alleviate the attacks instigated against them. We have analyzed the major concerns for web applications and Internet-based services which are persistent in several web applications of diverse organizations like banking, health care, financial service, retail and so on by the referring the Website Security Statistics Report of White Hat Security. In this paper, we highlight some of the serious vulnerabilities found in the modern web applications and revealed various serious vulnerabilities. Cross-Site Scripting (XSS) attack is the top most vulnerability found in the today’s web applications which to be a plague for the modern web applications. XSS attacks permit an attacker to execute the malicious scripts on the victim’s web browser resulting in various side-effects such as data compromise, stealing of cookies, passwords, credit card numbers etc. We have also discussed a high level of taxonomy of XSS attacks and detailed incidences of these attacks on web applications. A detailed comprehensive analysis of the exploitation, detection and prevention mechanisms of XSS attacks has also been discussed. Based on explored strength and flaws of these mechanisms, we have discussed some further work.",http://dx.doi.org/10.1007/s13198-015-0376-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-53417-6_9,Building Intelligent Models from Data Mining and Expert Knowledge,"Business Resilience System (BRS): Driven Through Boolean, Fuzzy Logics and Cloud Computation",10.1007/978-3-319-53417-6_9,Springer,2017-01-01,"While the idea of a data warehouse remains the core ideal of most corporate IT shops, the concepts surrounding the organization and architecture and, especially, the delivery mechanisms have changed remarkably. In today’s rapid changing and highly competitive marketplace, the idea of physical centralization has given way to a virtual data warehouse tied together with message-oriented middleware and distributed through application servers, Web servers, and intelligent database systems. The overriding influence in the corporate response to its information assets has been, of course, the dramatic rise of the Internet as a knowledge-bearing framework. From the global reach of the Internet, corporations have carved out their own pieces of this universe—intranets to bind together the information needs of the enterprise, extranets to solidify and control supply chains, and B2B and B2C service nets to give even the smallest corporation an equal footing with corporate giants as well as an essentially low-cost worldwide online presence. The Internet has given corporate decision-makers and knowledge workers a vast (and sometimes seemingly infinite) access to raw data—in fact, to “raw” knowledge.",http://dx.doi.org/10.1007/978-3-319-53417-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-44003-3_14,Profiting from Several Recommendation Algorithms Using a Scalable Approach,NEO 2015,10.1007/978-3-319-44003-3_14,Springer,2017-01-01,"This chapter proposes Lanza, Daniel the use of a scalable platform to run a complex Chávez, Francisco recommendation system. We focus on a system Fernández de Vega, Francisco made up of several recommendation García-Valdez, Mario algorithms which are run as an offline process. This offline process generates user profiles that represent Trujillo, Leonardo which algorithm should provide the recommendations to a given user and item, and will be combined with Olague, Gustavo a fuzzy decision system to generate every recommendation. Yet, given the amount of data that will be processed and the need to run that offline process frequently, we propose to reduce execution time by using Hadoop, a scalable, distributed and fault-tolerant platform. Obtained results shows how the main goal pursued here is achieved: the efficient use of computer resources which allows for a significant reduction in computing time.",http://dx.doi.org/10.1007/978-3-319-44003-3_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-58469-0_31,Differentially Private Neighborhood-Based Recommender Systems,ICT Systems Security and Privacy Protection,10.1007/978-3-319-58469-0_31,Springer,2017-01-01,"In this paper, we apply the differential privacy concept to neighborhood-based recommendation methods (NBMs) under a probabilistic framework. We first present a solution, by directly calibrating Laplace noise into the training process, to differential-privately find the maximum a posteriori parameters similarity . Then we connect differential privacy to NBMs by exploiting a recent observation that sampling from the scaled posterior distribution of a Bayesian model results in provably differentially private systems. Our experiments show that both solutions allow promising accuracy with a modest privacy budget, and the second solution yields better accuracy if the sampling asymptotically converges. We also compare our solutions to the recent differentially private matrix factorization (MF) recommender systems, and show that our solutions achieve better accuracy when the privacy budget is reasonably small. This is an interesting result because MF systems often offer better accuracy when differential privacy is not applied.",http://dx.doi.org/10.1007/978-3-319-58469-0_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-71679-4_10,"Computers That Negotiate on Our Behalf: Major Challenges for Self-sufficient, Self-directed, and Interdependent Negotiating Agents",Autonomous Agents and Multiagent Systems,10.1007/978-3-319-71679-4_10,Springer,2017-01-01,"Computers that negotiate on our behalf hold great promise for the future and will even become indispensable in emerging application domains such as the smart grid, autonomous driving, and the Internet of Things. Much research has thus been expended to create agents that are able to negotiate in an abundance of circumstances. However, up until now, truly autonomous negotiators have rarely been deployed in real-world applications. This paper sizes up current negotiating agents and explores a number of technological, societal and ethical challenges that autonomous negotiation systems are bringing about. The questions we address are: in what sense are these systems autonomous, what has been holding back their further proliferation, and is their spread something we should encourage? We relate the automated negotiation research agenda to dimensions of autonomy and distill three major themes that we believe will propel autonomous negotiation forward: accurate representation, long-term perspective, and user trust. We argue these orthogonal research directions need to be aligned and advanced in unison to sustain tangible progress in the field.",http://dx.doi.org/10.1007/978-3-319-71679-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-319-05542-8_3-1,Field Experiments,Handbook of Market Research,10.1007/978-3-319-05542-8_3-1,Springer,2017-01-01,"Digitalization of value chains and company processes offers new opportunities to measure and control a firm’s activities and to make a business more efficient by better understanding markets, competitors, and consumers’ behaviors. Among other methodologies, field experiments conducted in online and offline environments are rapidly changing the way companies make business decisions. Simple A/B tests as well as more complex multivariate experiments are increasingly employed by managers to inform their marketing decisions. This chapter explains why field experiments are a reliable way to reveal and to prove that a business action results in a desired outcome and provides guidelines on how to perform such experiments step by step covering issues such as randomization, sample selection, and data analysis. Various practical issues in the design of field experiments are covered with the main focus on causal inference and internal and external validity. We conclude the chapter with a practical case study as well as a brief literature review on recent published articles employing field experiments as a data collection method, providing the reader with a list of examples to consider and to refer to when conducting and designing a field experiment.",http://dx.doi.org/10.1007/978-3-319-05542-8_3-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-72413-3_2,Big Data Analytics Enabled Smart Financial Services: Opportunities and Challenges,Big Data Analytics,10.1007/978-3-319-72413-3_2,Springer,2017-01-01,"Of late, the financial services industry is fast moving away from the traditional paradigm to the sophisticated digital way of dealing and the customer. Both the facets of the financial service industry, viz., the financial service provider and the customer are going through a digital evolution. In particular, banking industry has evolved from just journal and ledger entry paradigm to data and analytics driven banking operations, which subsumes online as well as offline customer behavior. This paper discusses various scenarios in baking, finance services and insurance (BFSI) areas, where big data analytics is turning out to be paramount. The paper also highlights the potential benefits, of the new-age technologies viz., Internet of Things (IoT), Blockchain, Chatbots and robotics.",http://dx.doi.org/10.1007/978-3-319-72413-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-50920-4_19,Swarm Intelligence: A Review of Algorithms,Nature-Inspired Computing and Optimization,10.1007/978-3-319-50920-4_19,Springer,2017-01-01,"Swarm intelligence (SI), an integral part in the field of artificial intelligence, is gradually gaining prominence, as more and more high complexity problems require solutions which may be sub-optimal but yet achievable within a reasonable period of time. Mostly inspired by biological systems, swarm intelligence adopts the collective behaviour of an organized group of animals, as they strive to survive. This study aims to discuss the governing idea, identify the potential application areas and present a detailed survey of eight SI algorithms. The newly developed algorithms discussed in the study are the insect-based algorithms and animal-based algorithms in minute detail. More specifically, we focus on the algorithms inspired by ants, bees, fireflies, glow-worms, bats, monkeys, lions and wolves. The inspiration analyses on these algorithms highlight the way these algorithms operate. Variants of these algorithms have been introduced after the inspiration analysis. Specific areas for the application of such algorithms have also been highlighted for researchers interested in the domain. The study attempts to provide an initial understanding for the exploration of the technical aspects of the algorithms and their future scope by the academia and practice.",http://dx.doi.org/10.1007/978-3-319-50920-4_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-52181-7_6,A Predictive Approach Enabling Process Execution Recommendations,Advances in Intelligent Process-Aware Information Systems,10.1007/978-3-319-52181-7_6,Springer,2017-01-01,"In enterprises, decision makers need to continuously monitor business processes to guarantee for a high product and service quality. To accomplish this task, process-related data needs to be retrieved from various information systems—periodically or in real-time—and then be aggregated based on key performance indicators (KPIs). If target values of the defined KPIs are violated (e.g., production takes longer than a predefined threshold), the reasons of these violations need to be identified. In general, such a retrospective analysis of business process data does not always contribute to prevent respective key performance violations. To remedy this drawback, process-aware information systems (PAIS) should enable the automated identification of processes, which are not well performing, and support users in executing these processes through recommendations. For example, it should be indicated, which problems might occur in future when taking the current course of the process instance as well as previous process instances into account. This chapter presents a methodology as well as an architecture for the support of predictive process analyses. In this context, algorithms from machine learning are applied to compare running process instances with historic process data and to identify diverging processes. In particular, the predictive approach will enable enterprises to quickly react to upcoming problems and inefficiencies.",http://dx.doi.org/10.1007/978-3-319-52181-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-58481-2_13,Implementing Digital Parliament Innovative Concepts for Citizens and Policy Makers,"HCI in Business, Government and Organizations. Interacting with Information Systems",10.1007/978-3-319-58481-2_13,Springer,2017-01-01,"The organizational stability of Parliaments comes in direct contradiction with rapid progress in digital technology in recent decades, particularly in the ICT domain. By participating in a series of networking activities through European funded research programs, the Hellenic Parliament and the Austrian Parliament have placed themselves in the forefront of parliamentary innovation. This paper will focus on these activities and relevant findings on their impact, citizen adoption and application-to-end-user acceptance, where end users are parliaments and citizens alike. A range of technological challenges that modern Parliaments face and discrete actions of parliamentary innovation will also be shown. Finally, the paper will present the prospects that arise from the use of the latest ICT technologies in Parliaments. We shall also examine limitations in the use of such tools and shall propose potential areas of technological research and innovation for parliamentary application.",http://dx.doi.org/10.1007/978-3-319-58481-2_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-49106-6_68,VegeShop Tool: A Tool for Vegetable Recognition Using DNN,"Advances on Broad-Band Wireless Computing, Communication and Applications",10.1007/978-3-319-49106-6_68,Springer,2017-01-01,"Deep Learning also called Deep Neural Network (DNN) has a deep hierarchy that connect multiple internal layers for feature detection and recognition learning. In our previous work, we proposed vegetable recognition system which was based on Convolutional Neural Network (CNN). In this paper, we propose a tool called VegeShop for vegetable category recognition which is based on CNN. The user interface serves as e-commerce system for sellers and buyers using Android mobile device. The system can be accessed ubiquitously from any where. Moreover, our system can be applied also for other category recognition.",http://dx.doi.org/10.1007/978-3-319-49106-6_68,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-2564-8_1,"Simulating and Modeling Dual Market Segmentation Using 
                
                  
                
                $$\mathsf {PSA}$$
                
                  
                    PSA
                  
                
               Framework",Multi-agent and Complex Systems,10.1007/978-981-10-2564-8_1,Springer,2017-01-01,"Market segmentation refers to the analytical process of dividing a broad market into segments taking into account multiple factors such as consumer needs, interests and tastes; it has been considered one of the most important marketing strategies as it helps a business to identify hidden market trends, define target segments, and design marketing plans. Market segmentation may also be viewed as a computational challenge: Given the massive amount of data describing interactions between consumers and commodities, the task is to partition the set of consumers and commodities into subsets that corresponds to market segments—two consumers are in the same segments when they exhibit a similar purchasing pattern, while two products are in the same segments when they are purchased by a similar group of consumers. In this work, we focus on the definition and simulation of market segments. We employ the $$\mathsf {Propose}$$ Propose - $$\mathsf {Select}$$ Select - $$\mathsf {Adjust}$$ Adjust ( $$\mathsf {PSA}$$ PSA ) framework, introduced in an earlier work [ 10 ], to simulate the forming of market segments. Our approach is distributed and can be applied to large and dynamic market data set. The experimental results suggest that the proposed approach is a promising technique for supporting intelligent market segmentation.",http://dx.doi.org/10.1007/978-981-10-2564-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-662-54970-4_2,Graph Analytics for Real-Time Scoring of Cross-Channel Transactional Fraud,Financial Cryptography and Data Security,10.1007/978-3-662-54970-4_2,Springer,2017-01-01,"We present a new approach to cross channel fraud detection: build graphs representing transactions from all channels and use analytics on features extracted from these graphs. Our underlying hypothesis is community based fraud detection : an account (holder) performs normal or trusted transactions within a community that is “local” to the account. We explore several notions of community based on graph properties. Our results show that properties such as shortest distance between transaction endpoints, whether they are in the same strongly connected component , whether the destination has high page rank , etc., provide excellent discriminators of fraudulent and normal transactions whereas traditional social network analysis yields poor results. Evaluation on a large dataset from a European bank shows that such methods can substantially reduce false positives in traditional fraud scoring. We show that classifiers built purely out of graph properties are very promising, with high AUC, and can complement existing fraud detection approaches.",http://dx.doi.org/10.1007/978-3-662-54970-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-66332-6_8,Filtering for Malice Through the Data Ocean: Large-Scale PHA Install Detection at the Communication Service Provider Level,"Research in Attacks, Intrusions, and Defenses",10.1007/978-3-319-66332-6_8,Springer,2017-01-01,"As a key stakeholder in mobile communications, the communication service provider ( CSP , including carriers and ISPs) plays a critical role in safeguarding mobile users against potentially-harmful apps (PHA), complementing the security protection at app stores. However a CSP-level scan faces an enormous challenge: hundreds of millions of apps are installed everyday; retaining their download traffic to construct their packages entails a huge burden on the CSP side, forces them to change their infrastructure and can have serious privacy and legal ramifications. To control the cost and avoid trouble, today’s CSPs acquire apps from download URLs for a malware analysis. Even this step is extremely expensive and hard to meet the demand of online protection: for example, a CSP we are working with runs hundreds of machines to check the daily downloads it observes. To rise up to this challenge, we present in this paper an innovative “app baleen” (called Abaleen ) framework for an on-line security vetting of an extremely large number of app downloads, through a high-performance, concurrent inspection of app content from the sources of the downloads. At the center of the framework is the idea of retrieving only a small amount of the content from the remote sources to identify suspicious app downloads and warn the end users, hopefully before the installation is complete. Running on 90 million download URLs recorded by our CSP partner, our screening framework achieves an unparalleled performance, with a nearly 85 $$\times $$ speed-up compared to the existing solution. This level of performance enables an online vetting for PHAs at the CSP scale: among all unique URLs used in our study, more than 95% were processed before the completion of unfettered downloads. With the CSP-level dataset, we revealed not only the surprising pervasiveness of PHAs, but also the real impact of them (over 2 million installs in merely 3 days).",http://dx.doi.org/10.1007/978-3-319-66332-6_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-54229-4_10,Autonomous Power Trading Approaches of a Winner Broker,Agent-Mediated Electronic Commerce. Designing Trading Strategies and Mechanisms for Electronic Markets,10.1007/978-3-319-54229-4_10,Springer,2017-01-01,"The future smart grid will bring new actors such as local producers, storage capacities and interruptible consumers to the existing electricity grid along with the challenge of sustainability. Intermediary power actors, i.e., brokers, will take the burden of financial management, during the integration of these customers. This paper describes the mathematical modelling, formalization and the design of decision making systems of a winner broker agent, AgentUDE14, which competed in Power Trading Agent Competition 2014 Final (Power TAC). In this work, we divide the main trading problem into sub problems and then formalize and solve them individually to reduce the mathematical complexity. In the wholesale market, we propose a dynamic programming approach whereas our retailer algorithm uses an aggressive tariff publication policy, which exploits tariff fees, such as early withdrawal penalty and bonus payment. We show the results that AgentUDE14 is a successful agent in many metrics, analyzing the tournament data from Power TAC 2014 Finals.",http://dx.doi.org/10.1007/978-3-319-54229-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-52764-2_2,A Semantic-Based Analytics Architecture and Its Application to Commodity Pricing,"Enterprise Applications, Markets and Services in the Finance Industry",10.1007/978-3-319-52764-2_2,Springer,2017-01-01,"Over the past decade, several sophisticated analytic techniques such as machine learning, neural networks, and predictive modelling have evolved to enable scientists to derive insights from data. Data Science is characterised by a cycle of model selection, customization and testing, as scientists often do not know the exact goal or expected results beforehand. Existing research efforts which explore maximising automation, reproducibility and interoperability are quite mature and fail to address a third criterion, usability. The main contribution of this paper is to explore the development of more complex semantic data models linked with existing ontologies (e.g. FIBO) that enable the standardisation of data formats as well as meaning and interpretation of data in automated data analysis. A model-driven architecture with the reference model that capture statistical learning requirement is proposed together with a prototype based around a case study in commodity pricing.",http://dx.doi.org/10.1007/978-3-319-52764-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-58481-2_10,"Context-Awareness and Mobile HCI: Implications, Challenges and Opportunities","HCI in Business, Government and Organizations. Interacting with Information Systems",10.1007/978-3-319-58481-2_10,Springer,2017-01-01,"Context-awareness endows mobile devices and services with the capability of interacting with users in an efficient, intelligent, natural and smart fashion. Consequently, context-awareness makes a significant difference to mobile HCI. However, the challenges brought by context-awareness to users of mobile devices are rarely examined in depth. In this paper, previous conceptions of context and their contribution to context-awareness in mobile HCI is scrutinized and a preliminary context-computer interaction (CCI) model is advanced to illustrate the interaction characterized by mobile context-awareness. Furthermore, the paper examines the limitations of information processing models and review alternative models of context. We also address user experience challenges related to the enablement of mobile context-awareness and highlight avenues for future research issues. Specifically, we found that context-awareness has been employed broadly in developing applications and services on mobile platform, has had a huge impact on mobile user experience, and has altered the interaction between humans and computers by giving the latter a more active role to play. The significance of context-awareness in the usage of mobile systems calls for systematic and in-depth appreciation of its impact on mobile HCI.",http://dx.doi.org/10.1007/978-3-319-58481-2_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69644-7_23,Continuous User Authentication on Touch-Screen Mobile Phones: Toward More Secure and Usable M-Commerce,Internetworked World,10.1007/978-3-319-69644-7_23,Springer,2017-01-01,"Recent advances in sensing and wireless communication technologies have led to an explosion in the use of touch-screen mobile devices such as smartphones and tablets in mobile commerce and other daily work and life activities. These activities have resulted in more and more private and sensitive information stored on those devices. Therefore, improving the security of mobile devices by effective user authentication to prevent unauthorized information access becomes an imminent task. Mobile user authentication refers to the process of checking a user’s identity and verifying whether he/she is authorized to access a device. Due to the increasing incidence of mobile phones getting lost, stolen, or snatched while being used by the owner, continuous user authentication (CUA) after logging in a mobile device has attracted increasing attention. Prior research has shown that traditional password authentication is insufficient or ineffective for CUA. Despite the recent research progress in CUA, many existing methods are explicit by nature in that they require users to perform specific operations, which can cause interruptions to users’ ongoing activities or may be easily learned from observation by others. In this research, we propose a new touch dynamics based approach to CUA on touch screen mobile devices that authenticates users while they are interacting with mobile devices. Touch dynamics, which is rich in cognitive quality and unique to individuals, has yet to be explored for implicit CUA. We conducted a longitudinal study to evaluate the proposed mobile CUA approach. The results demonstrate that our method can improve the security of CUA for touch screen mobile devices. The findings have significant implications for the security and adoption of m-commerce.",http://dx.doi.org/10.1007/978-3-319-69644-7_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-51463-5_3,Recommender Solutions Overview,Decision Support System for Diagnosis and Treatment of Hearing Disorders,10.1007/978-3-319-51463-5_3,Springer,2017-01-01,"This chapter aims at providing an overview of RS technology, describing different types of RS, with emphasis on choosing the right approach for the system supporting tinnitus treatment and justifying particular choice. Current generation of recommendation methods is presented in division to four main categories: collaborative, content-based, knowledge-based, hybrid. The chapter introduces basic concepts of each type, along with their mathematical/algorithmic foundations and general system architectures. The last section compares these different approaches with regard to requirements for tinnitus therapy recommendation and provides motivation to choose the rule-based approach for building a recommender system for the given problem area.",http://dx.doi.org/10.1007/978-3-319-51463-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-71682-4_17,Multiple-Profile Prediction-of-Use Games,Autonomous Agents and Multiagent Systems,10.1007/978-3-319-71682-4_17,Springer,2017-01-01,"Prediction-of-use (POU) games [ 14 ] address the mismatch between energy supplier costs and the incentives imposed on consumers by fixed-rate electricity tariffs. However, the framework does not address how consumers should coordinate to maximize social welfare. To address this, we develop multiple-profile prediction-of-use (MPOU) games, an extension of POU games in which agents report multiple acceptable electricity use profiles. We show that MPOU games share many attractive properties with POU games attractive (e.g., convexity). However, MPOU games introduce new incentive issues that limit our ability to exploit convexity effectively, a problem we analyze and resolve. We validate our approach with experimental results using utility models learned from real electricity use data.",http://dx.doi.org/10.1007/978-3-319-71682-4_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-10-3776-4_10,Emerging Possibilities for Design of Digital Resources for Learning,Digital Resources for Learning,10.1007/978-981-10-3776-4_10,Springer,2017-01-01,"This final chapter will make note of some of the latest and emerging interactive and representational technologies, and provide arguments how these might influence design, developments and delivery of digital resources for learning in the near future. However, considering that this is the final chapter in this book, in the last section, we will look back at the key points made so far.",http://dx.doi.org/10.1007/978-981-10-3776-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-68066-8_13,Client-Side Scheduling Based on Application Characterization on Kubernetes,"Economics of Grids, Clouds, Systems, and Services",10.1007/978-3-319-68066-8_13,Springer,2017-01-01,"In container management systems, such as Kubernetes, the scheduler has to place containers in physical machines and it should be aware of the degradation in performance caused by placing together containers that are barely isolated. We propose that clients provide a characterization of their applications to allow a scheduler to evaluate what is the best configuration to deal with the workload at a given moment. The default Kubernetes Scheduler only takes into account the sum of requested resources in each machine, which is insufficient to deal with the performance degradation. In this paper, we show how specifying resource limits is not enough to avoid resource contention, and we propose the architecture of a scheduler, based on the client application characterization, to avoid the resource contention.",http://dx.doi.org/10.1007/978-3-319-68066-8_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-65151-4_20,Data Rich – But Information Poor,Collaboration in a Data-Rich World,10.1007/978-3-319-65151-4_20,Springer,2017-01-01,"The article describes the missing link between the information type and quality required by the process of decision making and the knowledge provided using the recent developments of ‘big data’ technologies, with emphasis on management and control in systems of systems and collaborative networks. Using known theories of decision making, the article exposes a gap in present technology arising from the disparity between the large amount of patterns that can be identified in available data using data analytics, and the lack of technology that is able to provide a narrative that is necessary for timely and effective decision making. The conclusion is that a second level of situated logic is necessary for the efficient use of data analytics, so as to effectively support the dynamic configuration and reconfiguration of systems of systems for resilience, efficiency and other desired systemic properties.",http://dx.doi.org/10.1007/978-3-319-65151-4_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-65151-4_65,Intelligent Food Information Provision to Consumers in an Internet of Food Era,Collaboration in a Data-Rich World,10.1007/978-3-319-65151-4_65,Springer,2017-01-01,"Food information is a crucial tool for facilitating consumers in decision-making activities related to their consumption process. Recent advances in “Internet of food” technologies (such as food sensors, cloud computing, food data analysis, and mobile app technologies) makes possible to conceive new consumer information platforms. The rationale is to empower consumers by letting them get more relevant food information than they usually obtain through on-product labeling, mass media or other traditional channels. In this paper, we envisage a new generation of food information provision services, called intelligent food services (IFSs), which would be responsive to consumer’s expectations and information needs. We outline IFS structure and main features as well as constitutive elements of user-IFS interaction context. Particularly, we focus on food-in-context awareness capability and we discuss its influence on consumer and IFS behaviors.",http://dx.doi.org/10.1007/978-3-319-65151-4_65,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-3322-3_27,User Localization in an Indoor Environment Using Fuzzy Hybrid of Particle Swarm Optimization & Gravitational Search Algorithm with Neural Networks,Proceedings of Sixth International Conference on Soft Computing for Problem Solving,10.1007/978-981-10-3322-3_27,Springer,2017-01-01,"Detecting users in an indoor environment based on Wi-Fi signal strength has a wide domain of applications. This can be used for objectives like locating users in smart home systems, locating criminals in bounded regions, obtaining the count of users on an access point etc. The paper develops an optimized model that could be deployed in monitoring and tracking devices used for locating users based on the Wi-Fi signal strength they receive in their personal devices. Here, we procure data of signal strengths from various routers, map them to the user’s location and consider this mapping as a classification problem. We train a neural network using the weights obtained by the proposed fuzzy hybrid of Particle Swarm Optimization & Gravitational Search Algorithm (FPSOGSA), an optimization strategy that results in better accuracy of the model.",http://dx.doi.org/10.1007/978-981-10-3322-3_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-48854-7_6,Dynamic Data: Branding the Digital Drive,Brand Fans,10.1007/978-3-319-48854-7_6,Springer,2017-01-01,"This chapter delivers the fifth lesson that brand power accumulates when it is given away, with consumer-generated content as a central mediator of brand intensity, carefully mediated through data analytics designed to craft bespoke consumer experiences. The chapter ventures into the vast world of dynamic data, and its potential for enhancing the consumer experience. Through the use of “superdata”, sport brands address their consumers’ preferences with an unprecedented degree of surgical precision. In removing the data noise, sport enterprises have discovered an ability to make real-time branding decisions, often including those enabling consumers to fluidly control their own content. Sport recognises that the best brands incorporate digital destinations as part of their value propositions.",http://dx.doi.org/10.1007/978-3-319-48854-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-69035-3_47,Continuous Learning as a Service for Conversational Virtual Agents,Service-Oriented Computing,10.1007/978-3-319-69035-3_47,Springer,2017-01-01,"IT support services are moving towards self assist mode by means of cognitive agents. Such cognitive agents are typically being designed as conversational system. It is important that as the agent interacts with users, it should continuously observe, infer and learn as to what is it that it is doing well, what topics is it not able to handle well and what topics it does not seem to know about at all. In this paper, we have proposed a service that enables feedback based learning in cognitive agents. Conversation systems typically support feedback mechanism for example, some of them may ask the users to vote for the answers, or rate the experience/response that they got for their query. We propose a reinforcement learning based model for the agent to continuously learn and improve. To the best of our knowledge, this is a first attempt in modeling the continuous learning problem in conversational systems as a reinforcement learning problem. We also provide the service design for continuous learning as a service in context of conversational agents. We have evaluated the model against real data to show how the learning is helpful in improving agent’s performance. The model can also be generalized for any supervised classification problem.",http://dx.doi.org/10.1007/978-3-319-69035-3_47,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-41163-7_8,Semantic Web,E-Learning Systems,10.1007/978-3-319-41163-7_8,Springer,2017-01-01,"The Semantic Web is a next generation of the Web in which information is presented in such a way that it can be used by computers not only to be presented but also to be used for automation of the search, integration, and reuse between applications. The goal of the Semantic Web is to develop the basis for intelligent applications that enable more efficient information use by not just providing a set of linked documents but a collection of knowledge repositories with meaningful content and additional logic structure. Also, one of the main goals is to build an appropriate infrastructure for intelligent agents to perform complex actions on the network. There are a number of important concepts that enable the development of the Semantic Web. This chapter presents the most important of them: knowledge organization systems, ontologies, Semantic Web languages and adaptation rules. Possibilities of applying Semantic Web technologies in e-learning systems are presented in this chapter.",http://dx.doi.org/10.1007/978-3-319-41163-7_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4614-6616-1_466-2,Start-Up and Small Business Life,"Encyclopedia of Creativity, Invention, Innovation and Entrepreneurship",10.1007/978-1-4614-6616-1_466-2,Springer,2017-01-01,,http://dx.doi.org/10.1007/978-1-4614-6616-1_466-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-016-1760-5,Characterizing and benchmarking stand-alone Hadoop MapReduce on modern HPC clusters,The Journal of Supercomputing,10.1007/s11227-016-1760-5,Springer,2016-12-01,"With the emergence of high-performance data analytics, the Hadoop platform is being increasingly used to process data stored on high-performance computing clusters. While there is immense scope for improving the performance of Hadoop MapReduce (including the network-intensive shuffle phase) over these modern clusters, that are equipped with high-speed interconnects such as InfiniBand and 10/40 GigE, and storage systems such as SSDs and Lustre, it is essential to study the MapReduce component in an isolated manner. In this paper, we study popular MapReduce workloads, obtained from well-accepted, comprehensive benchmark suites, to identify common shuffle data distribution patterns. We determine different environmental and workload-specific factors that affect the performance of the MapReduce job. Based on these characterization studies, we propose a micro-benchmark suite that can be used to evaluate the performance of stand-alone Hadoop MapReduce, and demonstrate its ease-of-use with different networks/protocols, Hadoop distributions, and storage architectures. Performance evaluations with our proposed micro-benchmarks show that stand-alone Hadoop MapReduce over IPoIB performs better than 10 GigE by about 13–15 %, and the RDMA-enhanced hybrid MapReduce design can achieve up to 43 % performance improvement over default Hadoop MapReduce over IPoIB, in both shared-nothing and shared storage architectures.",http://dx.doi.org/10.1007/s11227-016-1760-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-016-0357-4,Testing and evaluating recommendation algorithms in internet of things,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-016-0357-4,Springer,2016-12-01,"Technological revolution in communication and embedded computing has led to the Internet of Things (IoT) where all objects are connected together to provide users with services. Nowadays, many third party service providers are providing a large number of IoT services. Suggesting suitable services to IoT users based on objects they own has not been tackled yet. In this paper, we investigate the possibilities of leveraging recommendation algorithms, especially graph-based, to IoT. We propose a graph-based model for IoT systems and conduct experiment in which analyze and explore correlations between performances of different algorithms. We show that the graph-based recommendation algorithm can be used to develop an effective recommender system for the IoT. Moreover, we show that some algorithms perform reasonably well and produce high quality results.",http://dx.doi.org/10.1007/s12652-016-0357-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00799-015-0156-0,Research-paper recommender systems: a literature survey,International Journal on Digital Libraries,10.1007/s00799-015-0156-0,Springer,2016-11-01,"In the last 16 years, more than 200 research articles were published about research-paper recommender systems . We reviewed these articles and present some descriptive statistics in this paper, as well as a discussion about the major advancements and shortcomings and an overview of the most common recommendation concepts and approaches. We found that more than half of the recommendation approaches applied content-based filtering (55 %). Collaborative filtering was applied by only 18 % of the reviewed approaches, and graph-based recommendations by 16 %. Other recommendation concepts included stereotyping, item-centric recommendations, and hybrid recommendations. The content-based filtering approaches mainly utilized papers that the users had authored, tagged, browsed, or downloaded. TF-IDF was the most frequently applied weighting scheme. In addition to simple terms, n-grams, topics, and citations were utilized to model users’ information needs. Our review revealed some shortcomings of the current research. First, it remains unclear which recommendation concepts and approaches are the most promising. For instance, researchers reported different results on the performance of content-based and collaborative filtering. Sometimes content-based filtering performed better than collaborative filtering and sometimes it performed worse. We identified three potential reasons for the ambiguity of the results. (A) Several evaluations had limitations. They were based on strongly pruned datasets, few participants in user studies, or did not use appropriate baselines. (B) Some authors provided little information about their algorithms, which makes it difficult to re-implement the approaches. Consequently, researchers use different implementations of the same recommendations approaches, which might lead to variations in the results. (C) We speculated that minor variations in datasets, algorithms, or user populations inevitably lead to strong variations in the performance of the approaches. Hence, finding the most promising approaches is a challenge. As a second limitation, we noted that many authors neglected to take into account factors other than accuracy, for example overall user satisfaction. In addition, most approaches (81 %) neglected the user-modeling process and did not infer information automatically but let users provide keywords, text snippets, or a single paper as input. Information on runtime was provided for 10 % of the approaches. Finally, few research papers had an impact on research-paper recommender systems in practice. We also identified a lack of authority and long-term research interest in the field: 73 % of the authors published no more than one paper on research-paper recommender systems, and there was little cooperation among different co-author groups. We concluded that several actions could improve the research landscape: developing a common evaluation framework, agreement on the information to include in research papers, a stronger focus on non-accuracy aspects and user modeling, a platform for researchers to exchange information, and an open-source framework that bundles the available recommendation approaches.",http://dx.doi.org/10.1007/s00799-015-0156-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-015-0402-7,C-trust: A trust management system to improve fairness on circular P2P networks,Peer-to-Peer Networking and Applications,10.1007/s12083-015-0402-7,Springer,2016-11-01,"An important issue in Peer-to-Peer networks is to encourage users to share with others as they use the resources of the network. However, some nodes may only consume from users without giving anything in return. To fix this problem, we can incorporate trust management systems with network infrastructures. Current trust managements are usually made for unstructured overlays and have several shortcomings. They are made to be very similar to e-commerce scoring websites which may not be the best design for fairness in P2P networks. Several problems may arise with their designs such as difficulties to provide a complete history of freeloaders or lack of an autonomous removal mechanism in case of severe attacks. In this paper, we argue that such systems can be deployed more efficiently by using a structured paradigm. For this purpose, we propose C-Trust, a trust management system which is focused on fairness for P2P networks. This is done by getting help from current circular structured designs. This method is able to mark freeloaders, identify their severity of abusion and punish them accordingly. We are also able to effectively protect both Seeder-to-Leecher and Leecher-to-Leecher transactions. This feature is specially important for fairness which other trust systems have not considered so far.",http://dx.doi.org/10.1007/s12083-015-0402-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40595-016-0071-3,Speech classification using SIFT features on spectrogram images,Vietnam Journal of Computer Science,10.1007/s40595-016-0071-3,Springer,2016-11-01,"Classification of speech is one of the most vital problems in speech processing. Although there have been many studies on the classification of speech, the results are still limited. Firstly, most of the speech classification approaches requiring input data have the same dimension. Secondly, all traditional methods must be trained before classifying speech signal and must be retrained when having more training data or new class. In this paper, we propose an approach for speech classification using Scale-invariant Feature Transform (SIFT) features on spectrogram images of speech signal combination with Local naïve Bayes nearest neighbor. The proposed approach allows using feature vectors to have different sizes. With this approach, the achieved classification results are satisfactory. They are 73, 96, 95, 97 %, and 97 % on the ISOLET, English Isolated Digits, Vietnamese Places, Vietnamese Digits, JVPD databases, respectively. Especially, in a subset of the TMW database, the accuracy is 100 %. In addition, in our proposed approach, non-retraining is needed for additional training data after the training phase. The experiment shows that the more features are added to the model, the more is the accuracy in performance.",http://dx.doi.org/10.1007/s40595-016-0071-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10766-016-0406-9,SARP: Synopsis-Based Approximate Request Processing for Low Latency and Small Correctness Loss in Cloud Online Services,International Journal of Parallel Programming,10.1007/s10766-016-0406-9,Springer,2016-10-01,"Despite the importance of providing quick responsiveness to user requests for online services, such request processing is very resource expensive when dealing with large-scale service datasets. These often exceed the service providers’ budget when services are deployed on a cloud, in which resources are charged in monetary terms. Providing approximate processing results in request processing is a feasible solution for such problem that trades off result correctness (e.g. prediction or query accuracy) for response time reduction. However, existing techniques in this area either use parts of datasets or skip expensive computations to produce approximate results, thus resulting in large losses in result correctness on a tight resource budget. In this paper, we propose Synopsis-based Approximate Request Processing (SARP), a SARP framework to produce approximate results with small correctness losses even using small amount of resources. To achieve this, SARP conducts computations over synopses, which aggregate the statistical information of the entire service dataset at different approximation levels, based on two key ideas: (1) offline synopsis management that generates and maintains a set of synopses that represent the aggregation information of the dataset at different approximation levels. (2) Online synopsis selection that considers both the current resource allocation and the workload status so as to select the synopsis with the maximal length that can be processed within the required response time. We demonstrate the effectiveness of our approach by testing the recommendation services in e-commerce sites using a large, real-world dataset. Using prediction accuracy as the result correctness metric, the results demonstrate: (i) SARP achieves significant response time reduction with very small correctness losses compared to the exact processing results; (ii) using the same processing time, SARP demonstrates a considerable reduction in correctness loss compared to existing approximation techniques.",http://dx.doi.org/10.1007/s10766-016-0406-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13677-016-0065-9,Prediction-based VM provisioning and admission control for multi-tier web applications,Journal of Cloud Computing,10.1186/s13677-016-0065-9,Springer,2016-09-27,"We present a prediction-based, cost-efficient Virtual Machine (VM) provisioning and admission control approach for multi-tier web applications. The proposed approach provides automatic deployment and scaling of multiple web applications on a given Infrastructure as a Service (IaaS) cloud. It monitors and uses collected resource utilization metrics itself and does not require a performance model of the applications or the infrastructure dynamics. The approach uses the OSGi component model to share VM resources among deployed applications, reducing the total number of required VMs. The proposed approach comprises three sub-approaches: a reactive VM provisioning approach called ARVUE, a hybrid reactive-proactive VM provisioning approach called Cost-efficient Resource Allocation for Multiple web applications with Proactive scaling (CRAMP), and a session-based adaptive admission control approach called adaptive Admission Control for Virtualized Application Servers (ACVAS). Performance under varying load conditions is guaranteed by automatic adjustment and tuning of the CRAMP and ACVAS parameters. The proposed approach is demonstrated in discrete-event simulations and is evaluated in a series of experiments involving synthetic as well as realistic load patterns.",http://dx.doi.org/10.1186/s13677-016-0065-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10618-016-0474-x,Bayesian Wishart matrix factorization,Data Mining and Knowledge Discovery,10.1007/s10618-016-0474-x,Springer,2016-09-01,User tastes are constantly drifting over time as users are exposed to different types of products. The ability to model the tendency of both user preferences and product attractiveness is vital to the success of recommender systems (RSs). We propose a Bayesian Wishart matrix factorization method to model the temporal dynamics of variations among user preferences and item attractiveness in a novel algorithmic perspective. The proposed method is able to well model and properly control diverse rating behaviors across time frames and related temporal effects within time frames in the tendency of user preferences and item attractiveness. We evaluate the proposed method on two synthetic and three real-world benchmark datasets for RSs. Experimental results demonstrate that our proposed method significantly outperforms a variety of state-of-the-art methods in RSs.,http://dx.doi.org/10.1007/s10618-016-0474-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-015-1501-1,"A general perspective of Big Data: applications, tools, challenges and trends",The Journal of Supercomputing,10.1007/s11227-015-1501-1,Springer,2016-08-01,"Big Data has become a very popular term. It refers to the enormous amount of structured, semi-structured and unstructured data that are exponentially generated by high-performance applications in many domains: biochemistry, genetics, molecular biology, physics, astronomy, business, to mention a few. Since the literature of Big Data has increased significantly in recent years, it becomes necessary to develop an overview of the state-of-the-art in Big Data. This paper aims to provide a comprehensive review of Big Data literature of the last 4 years, to identify the main challenges, areas of application, tools and emergent trends of Big Data. To meet this objective, we have analyzed and classified 457 papers concerning Big Data. This review gives relevant information to practitioners and researchers about the main trends in research and application of Big Data in different technical domains, as well as a reference overview of Big Data tools.",http://dx.doi.org/10.1007/s11227-015-1501-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10472-015-9475-5,Preferences in artificial intelligence,Annals of Mathematics and Artificial Intelligence,10.1007/s10472-015-9475-5,Springer,2016-08-01,"The paper presents a focused survey about the presence and the use of the concept of “preferences” in Artificial Intelligence. Preferences are a central concept for decision making and have extensively been studied in disciplines such as economy, operational research, decision analysis, psychology and philosophy. However, in the recent years it has also become an important topic both for research and applications in Computer Science and more specifically in Artificial Intelligence, in fields spanning from recommender systems to automatic planning, from non monotonic reasoning to computational social choice and algorithmic decision theory. The survey essentially covers the basics of preference modelling, the use of preference in reasoning and argumentation, the problem of compact representations of preferences, preference learning and the use of non conventional preference models based on extended logical languages. It aims at providing a general reference for all researchers both in Artificial Intelligence and Decision Analysis interested in this exciting interdisciplinary topic.",http://dx.doi.org/10.1007/s10472-015-9475-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-1930-z,Improving the accuracy of a flood forecasting model by means of machine learning and chaos theory,Neural Computing and Applications,10.1007/s00521-015-1930-z,Springer,2016-07-01,"Monitoring natural environments is a challenging task on account of their hostile features. The use of wireless sensor networks (WSNs) for data collection is a feasible method since these domains lack any infrastructure. However, further studies are required to handle the data collected for a better modeling of behavior and thus make it possible to forecast impending disasters. In light of this, in this paper an analysis is conducted on the use of data gathered from urban rivers to forecast flooding with a view to reducing the damage it causes. The data were collected by means of a WSN in São Carlos, São Paulo State, Brazil, which gathered and processed data about the river level and rainfall by means of machine learning techniques and employing chaos theory to model the time series; this meant that the inputs of the machine learning technique were the time series gathered by the WSN modeled on the basis of the immersion theorem. The WSNs were deployed by our group in the city of São Carlos where there have been serious problems caused by floods. After the data interdependence had been established by the immersion theorem, the artificial neural networks were investigated to determine their degree of accuracy in the forecasting models.",http://dx.doi.org/10.1007/s00521-015-1930-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-014-0407-8,A survey and taxonomy on energy efficient resource allocation techniques for cloud computing systems,Computing,10.1007/s00607-014-0407-8,Springer,2016-07-01,"In a cloud computing paradigm, energy efficient allocation of different virtualized ICT resources (servers, storage disks, and networks, and the like) is a complex problem due to the presence of heterogeneous application (e.g., content delivery networks, MapReduce, web applications, and the like) workloads having contentious allocation requirements in terms of ICT resource capacities (e.g., network bandwidth, processing speed, response time, etc.). Several recent papers have tried to address the issue of improving energy efficiency in allocating cloud resources to applications with varying degree of success. However, to the best of our knowledge there is no published literature on this subject that clearly articulates the research problem and provides research taxonomy for succinct classification of existing techniques. Hence, the main aim of this paper is to identify open challenges associated with energy efficient resource allocation. In this regard, the study, first, outlines the problem and existing hardware and software-based techniques available for this purpose. Furthermore, available techniques already presented in the literature are summarized based on the energy-efficient research dimension taxonomy. The advantages and disadvantages of the existing techniques are comprehensively analyzed against the proposed research dimension taxonomy namely: resource adaption policy, objective function, allocation method, allocation operation, and interoperability.",http://dx.doi.org/10.1007/s00607-014-0407-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-015-1932-x,Personalized news recommendation based on articles chain building,Neural Computing and Applications,10.1007/s00521-015-1932-x,Springer,2016-07-01,"News personalized recommendation has long been a favorite research in recommender. Previous methods strive to satisfy the users by constructing the users’ preference profiles. Traditionally, most of recent researches use users’ reading history (content based) or access pattern (collaborative filtering based) to recommend newly published news to them. In this way, they only considered the relationship between news articles and the users and ignored the context of news report background. In other words, they fail to provide more useful information with considering the progression of the news story chain. In this paper, we propose to define the quality of a news story chain. Besides, we propose a method to construct a news story chain on a news corpus with date information. At last, we use a greedy selection method for filtering the final recommended news articles with considering accuracy and diversity. In this way, we can provide the news articles for users and meet their requirement: after reading the recommended news, the user gains a better understanding of the progression of the news story they read before. Finally, we designed several experiments compared to the state-of-the-art approaches, and the experimental results show that our proposed method significantly improves the accuracy, diversity and NDCG metrics.",http://dx.doi.org/10.1007/s00521-015-1932-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-016-9457-y,Application of intelligent agents in health-care: review,Artificial Intelligence Review,10.1007/s10462-016-9457-y,Springer,2016-06-01,"The successful use of intelligent agents in healthcare has attracted researchers to apply this emerging software engineering paradigm in more advanced and complex applications. Main success factor is the natural mapping of real world medical problems into cyber world. Multi-agent architecture can easily model the heterogeneous, distributed and autonomous health care systems. The multi agent systems have been applied from single healthcare activity like knowledge based medical system to complex, multi-component based systems like complete healthcare unit. The use of multi agent systems in health care domain has also opened the ways to find out new applications like personalized and socialized health care systems. This versatile use of multi agent systems has also posed new problems for researchers like; security, communication, and different social issues. This work reviews recent years’ research and applications of multi agent systems in healthcare published in different research journals, international conferences, and implemented practically. We reviewed five subdomains and three systems in each subdomain. A set of common parameters of these systems has been extracted and compared to analyze systems’ merits and deficiencies. Based on our analysis, we have provided recommendations for multi agent systems applied in healthcare domain. Future research directions for interested researchers and practitioners are also discussed. As our own future research work, we intend to study healthcare and multi agent systems in e-commerce.",http://dx.doi.org/10.1007/s10462-016-9457-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-014-0168-4,A Web service QoS prediction approach based on time- and location-aware collaborative filtering,Service Oriented Computing and Applications,10.1007/s11761-014-0168-4,Springer,2016-06-01,"In QoS-based Web service recommendation, predicting quality of service (QoS) for users will greatly aid service selection and discovery. Collaborative filtering (CF) is an effective method for Web service selection and recommendation. CF algorithms can be divided into two main categories: memory-based and model-based algorithms. Memory-based CF algorithms are easy to implement and highly effective, but they suffer from a fundamental problem: inability to scale-up. Model-based CF algorithms, such as clustering CF algorithms, address the scalability problem by seeking users for recommendation within smaller and highly similar clusters, rather than within the entire database. However, they are often time-consuming to build and update. In this paper, we propose a time-aware and location-aware CF algorithms. To validate our algorithm, this paper conducts series of large-scale experiments based on a real-world Web service QoS data set. Experimental results show that our approach is capable of addressing the three important challenges of recommender systems–high quality of prediction, high scalability, and easy to build and update.",http://dx.doi.org/10.1007/s11761-014-0168-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-015-0866-z,AMORE: design and implementation of a commercial-strength parallel hybrid movie recommendation engine,Knowledge and Information Systems,10.1007/s10115-015-0866-z,Springer,2016-06-01,"AMORE is a hybrid recommendation system that provides movie recommendation functionality to video-on-demand subscribers of a major triple-play service provider in Greece. Without any user relevance feedback for movies available, all recommendations are solely based on the users’ viewing history. To overcome such limitations as well as the extra problem of user histories that are usually the merger of the preferences of all persons in each household, we have performed extensive experiments with open-source recommendation software such as Apache Mahout and Lens-Kit, as well as with our own implementations of several user-based, item-based, and content-based recommendation algorithms. Our results indicate that our own custom multi-threaded implementation of collaborative filtering combined with a custom content-based algorithm outperforms current state-of-the-art implementations of similar algorithms both in solution quality and in response time by margins exceeding 100 % in terms of recall quality and 6300 % in terms of running time. The hybrid nature of the ensemble allows the system to perform well and to overcome inherent limitations of collaborative filtering, such as various cold-start problems. AMORE has been deployed in a production environment where it has contributed to an increase in the provider’s rental profits, while at the same time offers customer retention support.",http://dx.doi.org/10.1007/s10115-015-0866-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00779-016-0923-y,Online social trust reinforced personalized recommendation,Personal and Ubiquitous Computing,10.1007/s00779-016-0923-y,Springer,2016-06-01,"Recommendation techniques greatly promote the development of online service in the interconnection environment. Personalized recommendation has attracted researchers’ special attention because it is more targeted to individual tasks with the characteristics of diversification and novelty. However, the data sets that personalized recommendation process usually possess the characteristics of data sparseness and information loss, which is more likely to have problems such as cognitive deviation and interest drift. To solve these issues, in recent years people gradually notice the important role in which trust factor plays in promoting the development of personalized recommendation. Given the difference between online social trust and traditional offline social trust in facilitating personalized recommendation, this paper proposes a novel technique of online social trust reinforced personal recommendation to improve the recommendation performance. Compared with traditional offline social trust-based personal recommendation, our work synthesizes both factors of online social trust and offline social trust to identify private and public trusted user communities. The trusted degree or the accredited degree can be deduced by Bayesian network probabilistic inferences. In this way, the performance of personalized recommendation can be improved by avoiding excessive interest deviation. Moreover, we also get time sequence into personal recommendation model to effectively track how user’s interest changes over time. Accordingly, the recommendation accuracy can be improved by eliminating the unfavorable effect of interest drift caused by temporal variation. Empirical experiments on typical Yelp testing data set illustrate the effectiveness of the proposed recommendation technique.",http://dx.doi.org/10.1007/s00779-016-0923-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40593-016-0107-y,Technology Support for Discussion Based Learning: From Computer Supported Collaborative Learning to the Future of Massive Open Online Courses,International Journal of Artificial Intelligence in Education,10.1007/s40593-016-0107-y,Springer,2016-06-01,"This article offers a vision for technology supported collaborative and discussion-based learning at scale. It begins with historical work in the area of tutorial dialogue systems. It traces the history of that area of the field of Artificial Intelligence in Education as it has made an impact on the field of Computer-Supported Collaborative Learning through the creation of forms of dynamic support for collaborative learning, and makes an argument for the importance of advances in the field of Language Technologies for this work. In particular, this support has been enabled by an integration of text mining and conversational agents to form a novel type of micro-script support for productive discussion processes. This research from the early part of the century has paved the way for emerging technologies that support discussion-based learning at scale in Massive Open Online Courses (MOOCs). In the next 25 years, we expect to see this early, emerging work in MOOC contexts grow into ubiquitously available social learning approaches in free online learning environments like MOOCs, or what comes next in the online learning space. These ambitious social learning approaches include Problem Based Learning, Team Project Based Learning, and Collaborative Reflection. We expect to see the capability of drawing in and effectively supporting learners of all walks of life, especially impacting currently under-served learners. To that end, we describe the current exploratory efforts to deploy technology supported collaborative and discussion-based learning in MOOCs and offer a vision for work going forward into the next decade, where we envision learning communities and open collaborative work communities coming together as persistent technology supported and enhanced communities of practice.",http://dx.doi.org/10.1007/s40593-016-0107-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-016-0335-z,Using weak ties to understand the resource usage and sharing patterns of a professional learning community,Social Network Analysis and Mining,10.1007/s13278-016-0335-z,Springer,2016-05-21,"This research demonstrates the utility of the theory of weak ties for understanding the patterns of resource usage and sharing in an online professional learning community. Our context of study is a community of educators using and sharing teaching resources such as lesson plans, presentation slides and animations. We consider whether the deduced relationships between members of the community of educators constitute weak ties. A deduced relationship exists when two educators access the same resource. If these deduced relationships do constitute weak ties, then other theorized network properties should also be manifest, namely homophily and triadic closures. Our findings support these theoretical conjectures. Firstly, results indicate that the strength of a tie is directly proportional to the level of similarity between users in the network in terms of their propensity to use and share resources and their level of comfort with and use of technology (homophily property). Secondly, we found strong support for the triadic closure property (formation of a weak tie between unconnected nodes that share a common neighbor). Thus, we developed a computational model to predict the formation of weak ties via triadic closures with an accuracy of 97.8 %. Finally, we show that augmenting collaborative and hybrid recommender systems with our triadic closure prediction model can improve the performance of these systems.",http://dx.doi.org/10.1007/s13278-016-0335-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-016-1677-z,Handling big data: research challenges and future directions,The Journal of Supercomputing,10.1007/s11227-016-1677-z,Springer,2016-04-01,"Today, an enormous amount of data is being continuously generated in all walks of life by all kinds of devices and systems every day. A significant portion of such data is being captured, stored, aggregated and analyzed in a systematic way without losing its “4V” (i.e., volume, velocity, variety, and veracity) characteristics. We review major drivers of big data today as well the recent trends and established platforms that offer valuable perspectives on the information stored in large and heterogeneous data sets. Then, we present a classification of some of the most important challenges when handling big data. Based on this classification, we recommend solutions that could address the identified challenges, and in addition we highlight cross-disciplinary research directions that need further investigation in the future.",http://dx.doi.org/10.1007/s11227-016-1677-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-014-1557-5,Variational learning of hierarchical infinite generalized Dirichlet mixture models and applications,Soft Computing,10.1007/s00500-014-1557-5,Springer,2016-03-01,"Data clustering is a fundamental unsupervised learning task in several domains such as data mining, computer vision, information retrieval, and pattern recognition. In this paper, we propose and analyze a new clustering approach based on both hierarchical Dirichlet processes and the generalized Dirichlet distribution, which leads to an interesting statistical framework for data analysis and modelling. Our approach can be viewed as a hierarchical extension of the infinite generalized Dirichlet mixture model previously proposed in Bouguila and Ziou (IEEE Trans Neural Netw 21(1):107–122, 2010 ). The proposed clustering approach tackles the problem of modelling grouped data where observations are organized into groups that we allow to remain statistically linked by sharing mixture components. The resulting clustering model is learned using a principled variational Bayes inference-based algorithm that we have developed. Extensive experiments and simulations, based on two challenging applications namely images categorization and web service intrusion detection, demonstrate our model usefulness and merits.",http://dx.doi.org/10.1007/s00500-014-1557-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-015-0830-y,A survey on indexing techniques for big data: taxonomy and performance evaluation,Knowledge and Information Systems,10.1007/s10115-015-0830-y,Springer,2016-02-01,"The explosive growth in volume, velocity, and diversity of data produced by mobile devices and cloud applications has contributed to the abundance of data or ‘big data.’ Available solutions for efficient data storage and management cannot fulfill the needs of such heterogeneous data where the amount of data is continuously increasing. For efficient retrieval and management, existing indexing solutions become inefficient with the rapidly growing index size and seek time and an optimized index scheme is required for big data. Regarding real-world applications, the indexing issue with big data in cloud computing is widespread in healthcare, enterprises, scientific experiments, and social networks. To date, diverse soft computing, machine learning, and other techniques in terms of artificial intelligence have been utilized to satisfy the indexing requirements, yet in the literature, there is no reported state-of-the-art survey investigating the performance and consequences of techniques for solving indexing in big data issues as they enter cloud computing. The objective of this paper is to investigate and examine the existing indexing techniques for big data. Taxonomy of indexing techniques is developed to provide insight to enable researchers understand and select a technique as a basis to design an indexing mechanism with reduced time and space consumption for BD-MCC. In this study, 48 indexing techniques have been studied and compared based on 60 articles related to the topic. The indexing techniques’ performance is analyzed based on their characteristics and big data indexing requirements. The main contribution of this study is taxonomy of categorized indexing techniques based on their method. The categories are non-artificial intelligence, artificial intelligence, and collaborative artificial intelligence indexing methods. In addition, the significance of different procedures and performance is analyzed, besides limitations of each technique. In conclusion, several key future research topics with potential to accelerate the progress and deployment of artificial intelligence-based cooperative indexing in BD-MCC are elaborated on.",http://dx.doi.org/10.1007/s10115-015-0830-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-29206-9_8,Analytics and Big Data,Intelligent Techniques for Data Science,10.1007/978-3-319-29206-9_8,Springer,2016-01-01,"In this chapter, we outline some advanced tools and technologies, including the Apache Hadoop ecosystem, real-time data streams, scaling up machine learning algorithms, and fundamental issues such as data privacy and security. We cover much of the basic theory underlying the field of big data analytics in this chapter, but of course, we have only scratched the surface. Keep in mind that to apply the concepts contained in this overview of big data analytics, a much deeper understanding of the topics discussed herein is necessary.",http://dx.doi.org/10.1007/978-3-319-29206-9_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-40667-1_19,Leveraging Sensor Fingerprinting for Mobile Device Authentication,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-40667-1_19,Springer,2016-01-01,"Device fingerprinting is a technique for identification and recognition of clients and widely used in practice for Web tracking and fraud prevention. While common systems depend on software attributes, sensor-based fingerprinting relies on hardware imperfections and thus opens up new possibilities for device authentication. Recent work focusses on accelerometers as easily accessible sensors of modern mobile devices. However, it has remained unclear if device recognition via sensor-based fingerprinting is feasible under real-world conditions. In this paper, we analyze the effectiveness of a specialized feature set for sensor-based device fingerprinting and compare the results to feature-less fingerprinting techniques based on raw measurements. Furthermore, we evaluate other sensor types—like gravity and magnetic field sensors—as well as combinations of different sensors concerning their suitability for the purpose of device authentication. We demonstrate that combinations of different sensors yield precise device fingerprints when evaluating the approach on a real-world data set consisting of empirical measurement results obtained from almost 5,000 devices.",http://dx.doi.org/10.1007/978-3-319-40667-1_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-39972-0_5,Theory of Mind Engine,Computational Autism,10.1007/978-3-319-39972-0_5,Springer,2016-01-01,"We build an automated reasoner for the mental world, which approximates human reasoning about mental states and actions. The Theory-of-Mind engine takes an initial mental state and deduces the most plausible consecutive mental states of multiple possibly conflicting agents. The engine is implemented as a logic program – based simulator and serves as a reasoning benchmark to assist with remediation of autistic reasoning about the mental world.",http://dx.doi.org/10.1007/978-3-319-39972-0_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-1479-4_9,Machine Learning at Scale,Pro Spark Streaming,10.1007/978-1-4842-1479-4_9,Springer,2016-01-01,"Data by itself is a static, lifeless entity. You need analytics to breathe life into it and make it talk or even sing. The most sophisticated and popular class of such analytics revolves around nowcasting, forecasting, and recommendations, more generally known as machine learning and data mining. Machine-learning algorithms learn patterns in data and can then be used to make predictions, whereas data mining helps extract structure from unstructured data. Machine learning at scale is the key to practical predictions and recommendations, which are essential to drive the needs of consumers: commercial, academic, or scientific. This chapters uses MLlib to enable such applications.",http://dx.doi.org/10.1007/978-1-4842-1479-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-45507-5_6,Towards interactive Machine Learning (iML): Applying Ant Colony Algorithms to Solve the Traveling Salesman Problem with the Human-in-the-Loop Approach,"Availability, Reliability, and Security in Information Systems",10.1007/978-3-319-45507-5_6,Springer,2016-01-01,"Most Machine Learning (ML) researchers focus on automatic Machine Learning (aML) where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from the availability of “big data”. However, sometimes, for example in health informatics, we are confronted not a small number of data sets or rare events, and with complex problems where aML-approaches fail or deliver unsatisfactory results. Here, interactive Machine Learning (iML) may be of help and the “human-in-the-loop” approach may be beneficial in solving computationally hard problems, where human expertise can help to reduce an exponential search space through heuristics. In this paper, experiments are discussed which help to evaluate the effectiveness of the iML-“human-in-the-loop” approach, particularly in opening the “black box”, thereby enabling a human to directly and indirectly manipulating and interacting with an algorithm. For this purpose, we selected the Ant Colony Optimization (ACO) framework, and use it on the Traveling Salesman Problem (TSP) which is of high importance in solving many practical problems in health informatics, e.g. in the study of proteins.",http://dx.doi.org/10.1007/978-3-319-45507-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-29206-9_2,Data Analytics,Intelligent Techniques for Data Science,10.1007/978-3-319-29206-9_2,Springer,2016-01-01,"In this digital era, data is proliferating at an unprecedented rate. Data sources such as historical customer information, customer’s online clickstreams, channel data, credit card usage, customer relationship management (CRM) data, and huge amounts of social media data are available. In today’s world, the basic challenge is in managing the complexity in data sources, types and the velocity with which it is growing. Obviously, data-intensive computing is coming into the world that aims to provide the tools we need to handle the large-scale data problems. The recent big data revolution is not in the volume explosion of data, but in the capability of actually doing something with the data; making more sense out of it. In order to build a capability that can achieve beneficial data targets, enterprises need to understand the data lifecycle and challenges at different stages.",http://dx.doi.org/10.1007/978-3-319-29206-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-26989-4_13,Final Remarks on Big Data Analysis and Its Impact on Society and Science,Big Data Analysis: New Algorithms for a New Society,10.1007/978-3-319-26989-4_13,Springer,2016-01-01,"In this chapter, we summarize the lessons learned from the contributions to this book, add some of the important points regarding the current state of the art in Big Data Analysis that have not been discussed at length in the contributions per se, but are worth being aware of, and conclude with a discussion of the influence that Stan Matwin has had throughout the years on the successive related fields of Machine Learning, Data Mining and Big Data Analysis.",http://dx.doi.org/10.1007/978-3-319-26989-4_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-39958-4_10,Enhanced Query Classification with Millions of Fine-Grained Topics,Web-Age Information Management,10.1007/978-3-319-39958-4_10,Springer,2016-01-01,"Query classification is a crucial task to understand user search intents. Although this problem has been well studied in the past decades, it is still a big challenge in real-world applications due to the sparse, noisy and ambiguous nature of queries. In this paper, we present another important issue called “the pomegranate phenomenon”. This phenomenon is named for the gap between manually manageable small taxonomy and massive coherent topics in each category. Furthermore, the fine-grained topics in the same category of the taxonomy may be textually more relevant to the topics in other categories. This phenomenon will hurt the performances of most traditional classification methods. To overcome this problem, we present a practical approach to enhance the performances of traditional query classifiers. First, we detect millions of fine-grained query topics from two years of click logs which can represent different query intents and give them category labels. Second, for a given query, we calculate the K most relevant topics and select the label by majority voting, then try to use this label to improve the results of classical query classification methods. Empirical evaluation confirms that our topic based classification algorithms can significantly enhance the performances of traditional classifiers in read-world query classification tasks.",http://dx.doi.org/10.1007/978-3-319-39958-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-81-322-3628-3_2,"Massive Data Analysis: Tasks, Tools, Applications, and Challenges",Big Data Analytics,10.1007/978-81-322-3628-3_2,Springer,2016-01-01,"In this study, we provide an overview of the state-of-the-art technologies in programming, computing, and storage of the massive data analytics landscape. We shed light on different types of analytics that can be performed on massive data. For that, we first provide a detailed taxonomy on different analytic types along with examples of each type. Next, we highlight technology trends of massive data analytics that are available for corporations, government agencies, and researchers. In addition, we enumerate several instances of opportunities that exist for turning massive data into knowledge. We describe and position two distinct case studies of massive data analytics that are being investigated in our research group: recommendation systems in e-commerce applications; and link discovery to predict unknown association of medical concepts. Finally, we discuss the lessons we have learnt and open challenges faced by researchers and businesses in the field of massive data analytics.",http://dx.doi.org/10.1007/978-81-322-3628-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-29206-9_4,Fuzzy Logic,Intelligent Techniques for Data Science,10.1007/978-3-319-29206-9_4,Springer,2016-01-01,"Set is defined as a collection of entities that share common characteristics. From the formal definition of the set, it can be easily determined whether an entity can be member of the set or not. Classically, when an entity satisfies the definition of the set completely, then the entity is a member of the set. Such membership is certain in nature and it is very clear that an entity either belongs to the set or not. There is no intermediate situation. Thus, the classical sets handle bi-state situations and sets membership results in either ‘true’ or ‘false’ status only. These types of sets are also known as crisp sets. In other words, a crisp set always has a pre-defined boundary associated with it. A member must fall within the boundary to become a valid member of the set. An example of such classical set is the number of students in a class, ‘Student’. Students who have enrolled themselves for the class by paying fees and following rules are the valid members of the class ‘Student’. The class ‘Student’ is crisp, finite and non-negative. Here are some types of crisp sets.",http://dx.doi.org/10.1007/978-3-319-29206-9_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-40667-1_7,Reviewer Integration and Performance Measurement for Malware Detection,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-40667-1_7,Springer,2016-01-01,"We present and evaluate a large-scale malware detection system integrating machine learning with expert reviewers, treating reviewers as a limited labeling resource. We demonstrate that even in small numbers, reviewers can vastly improve the system’s ability to keep pace with evolving threats. We conduct our evaluation on a sample of VirusTotal submissions spanning 2.5 years and containing 1.1 million binaries with 778 GB of raw feature data. Without reviewer assistance, we achieve 72 % detection at a 0.5 % false positive rate, performing comparable to the best vendors on VirusTotal. Given a budget of 80 accurate reviews daily, we improve detection to 89 % and are able to detect 42 % of malicious binaries undetected upon initial submission to VirusTotal. Additionally, we identify a previously unnoticed temporal inconsistency in the labeling of training datasets. We compare the impact of training labels obtained at the same time training data is first seen with training labels obtained months later. We find that using training labels obtained well after samples appear, and thus unavailable in practice for current training data, inflates measured detection by almost 20 % points. We release our cluster-based implementation, as well as a list of all hashes in our evaluation and 3 % of our entire dataset.",http://dx.doi.org/10.1007/978-3-319-40667-1_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-015-9284-6,Strategic advice provision in repeated human-agent interactions,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-015-9284-6,Springer,2016-01-01,"This paper addresses the problem of automated advice provision in scenarios that involve repeated interactions between people and computer agents. This problem arises in many applications such as route selection systems, office assistants and climate control systems. To succeed in such settings agents must reason about how their advice influences people’s future actions or decisions over time. This work models such scenarios as a family of repeated bilateral interaction called “choice selection processes”, in which humans or computer agents may share certain goals, but are essentially self-interested. We propose a social agent for advice provision ( SAP ) for such environments that generates advice using a social utility function which weighs the sum of the individual utilities of both agent and human participants. The SAP agent models human choice selection using hyperbolic discounting and samples the model to infer the best weights for its social utility function. We demonstrate the effectiveness of SAP in two separate domains which vary in the complexity of modeling human behavior as well as the information that is available to people when they need to decide whether to accept the agent’s advice. In both of these domains, we evaluated SAP in extensive empirical studies involving hundreds of human subjects. SAP was compared to agents using alternative models of choice selection processes informed by behavioral economics and psychological models of decision-making. Our results show that in both domains, the SAP agent was able to outperform alternative models. This work demonstrates the efficacy of combining computational methods with behavioral economics to model how people reason about machine-generated advice and presents a general methodology for agent-design in such repeated advice settings.",http://dx.doi.org/10.1007/s10458-015-9284-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-25958-1_7,Trends in Machine and Human Face Recognition,Advances in Face Detection and Facial Image Analysis,10.1007/978-3-319-25958-1_7,Springer,2016-01-01,"Face recognition (FR) is a natural and intuitive way for human beings to identify or verify or at least get familiar and interact with other members of the community. Hence, human beings expect and endeavor to develop similar competency in machine recognition of human faces. Due to the rapid increase in computing power in recent decades and the need to automate the FR tasks for many applications, researchers from diverse areas like cognitive and computer sciences are making efforts in understanding how humans and machines recognize human faces respectively. Its application is innumerable (like access control, surveillance, social interactions, e-commerce, just to name a few). In this chapter we will review two aspects of FR: machine recognition of faces and how human beings recognize human faces. We will also discuss the recent benchmark studies, their protocols and databases for FR and psychophysical studies of FR abilities of human beings.",http://dx.doi.org/10.1007/978-3-319-25958-1_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-24106-7_14,Quality of Web Data and Quality of Big Data: Open Problems,Data and Information Quality,10.1007/978-3-319-24106-7_14,Springer,2016-01-01,"In this chapter we discuss some open issues related to two typologies of information sources that nowadays are particularly significant, namely, Web data and Big Data.",http://dx.doi.org/10.1007/978-3-319-24106-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-4899-7502-7_833-1,Text Mining for News and Blogs Analysis,Encyclopedia of Machine Learning and Data Mining,10.1007/978-1-4899-7502-7_833-1,Springer,2016-01-01,"News and blogs are temporally indexed online texts and play a key role in today’s information distribution and consumption. News communicate selected information on current events, written by professional or citizen journalists; blogs are updated publications on the Web that span a much wider range of topics, styles, and authors. Particularly important in recent years have been microblogs such as Twitter. The entry gives an overview of how text mining (for tasks such as description, classification, prediction, search, recommendation, or summarization) is applied to analyze the textual parts of news and blogs, extracting topics, events, opinions, sentiments, and other aspects of content. Often, textual analysis is complemented by the analysis of further data such as the social network of authors and readers. The properties of news and blogs data structures and language use require methods for preprocessing and analyzing that are tailored to news and (micro)blogs, and the tasks often profit from an interactive approach in which the user plays an active role in sensemaking. The methods are deployed in a wide range of applications and services.",http://dx.doi.org/10.1007/978-1-4899-7502-7_833-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-25808-9_1,Autonomic Road Transport Support Systems: An Introduction,Autonomic Road Transport Support Systems,10.1007/978-3-319-25808-9_1,Springer,2016-01-01,"One of the most persistent problems that plague modern-day road transport facilities is the quality of service provided. Especially during rush hours, this expensive infrastructure does not operate at capacity nor does it provide the level of service required by its users. Congestion has become a problem with severe economic and environmental repercussions. Hence, efficient road traffic management is more important than ever.",http://dx.doi.org/10.1007/978-3-319-25808-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-46523-4_39,Unsupervised Entity Resolution on Multi-type Graphs,The Semantic Web – ISWC 2016,10.1007/978-3-319-46523-4_39,Springer,2016-01-01,"Entity resolution is the task of identifying all mentions that represent the same real-world entity within a knowledge base or across multiple knowledge bases. We address the problem of performing entity resolution on RDF graphs containing multiple types of nodes, using the links between instances of different types to improve the accuracy. For example, in a graph of products and manufacturers the goal is to resolve all the products and all the manufacturers. We formulate this problem as a multi-type graph summarization problem, which involves clustering the nodes in each type that refer to the same entity into one super node and creating weighted links among super nodes that summarize the inter-cluster links in the original graph. Experiments show that the proposed approach outperforms several state-of-the-art generic entity resolution approaches, especially in data sets with missing values and one-to-many, many-to-many relations.",http://dx.doi.org/10.1007/978-3-319-46523-4_39,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-28907-6_19,The Business with Digital Signage for Advertising,Information and Communication Technologies in Organizations and Society,10.1007/978-3-319-28907-6_19,Springer,2016-01-01,"The market for digital signage has been growing at an accelerated pace for years. The benefits of novel approaches—such as contextualization and interaction functionalities—were soon recognized for achieving better advertising effects. However, the major types of digital signage currently in use have different requirements on the entire digital signage system. These requirements include components such as the digital signage network, digital signage exchange, scheduling, and pricing. The present paper discusses the differences between these components in depth. The core contribution of this paper is a detailed analysis of the potential of digital signage. Emphasis is placed on challenges in performance measurement and implementation, operating and using a digital signage system, display blindness, and negative externalities. Possible solutions, as well as best practices are presented. At its core, this paper provides an overview of the essentials of doing business with digital signage.",http://dx.doi.org/10.1007/978-3-319-28907-6_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-48740-3_6,Joint User Knowledge and Matrix Factorization for Recommender Systems,Web Information Systems Engineering – WISE 2016,10.1007/978-3-319-48740-3_6,Springer,2016-01-01,"Currently, most of the existing recommendation methods treat social network users equally, which assume that the effect of recommendation on a user is decided by the user’s own preferences and social influence. However, a user’s own knowledge in a field has not been considered. In other words, to what extent does a user accept recommendations in social networks need to consider the user’s own knowledge or expertise in the field. In this paper, we propose a novel matrix factorization recommendation algorithm based on integrating social network information such as trust relationships, rating information of users and users’ own knowledge. Specifically, we first use a user’s status (in this paper, status refers to the number of followers and the number of ratings one has done) in a social network to indicate a user’s knowledge in a field since we cannot directly measure a user’s knowledge in the field. Then, we model the final rating of decision-making as a linear combination of the user’s own preferences, social influence and user’s own knowledge. Experimental results on real world data sets show that our proposed approach generally outperforms the state-of-the-art recommendation algorithms that do not consider the knowledge level difference between the users.",http://dx.doi.org/10.1007/978-3-319-48740-3_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-16658-2_4,Emerging Semantic-Based Applications,Semantic Web,10.1007/978-3-319-16658-2_4,Springer,2016-01-01,"In the last decade, we have witnessed the birth and spread of the Semantic Web and its associated semantic technologies. In this successful scenario, ontologies have played a crucial role. However, being knowledge representation frameworks as they are, the benefits of their use are beyond the WWW, but to many other different kind of systems, making it possible to design and develop smarter information systems which exploit the semantics of data.In this chapter, we present different semantic-based applications and projects that we have developed in the Distributed Information Systems (SID, in Spanish) research group of the University of Zaragoza. They address different application fields benefiting from semantic technologies to broaden their capabilities. In particular, we present our semantic systems for keyword-based search (QueryGen, Doctopush), information extraction (GENIE), fuzzy logic editing (Fuzzy OWL 2) and reasoning (fuzzy DL, DeLorean), and Location-Based Services managing (SHERLOCK).",http://dx.doi.org/10.1007/978-3-319-16658-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-34096-8_2,Dependability of Adaptable and Evolvable Distributed Systems,Formal Methods for the Quantitative Evaluation of Collective Adaptive Systems,10.1007/978-3-319-34096-8_2,Springer,2016-01-01,"This article is a tutorial on how to achieve software evolution and adaptation in a dependable manner, by systematically applying formal modelling and verification. It shows how software can be designed upfront to tolerate different sources of uncertainty that cause continuous future changes. If possible changes can be predicted, and their occurrence can be detected, it is possible to design the software to be self-adaptable. Otherwise, continuous evolution has to be supported and continuous flow into operation has to be ensured. In cases where systems are designed to be continuously running, it is necessary to support safe continuous software deployment that guarantees correct operation in the presence of dynamic reconfigurations. The approaches we survey here have been mainly developed in the context of the SMScom project, funded by the European Commission –Programme IDEAS-ERC ( http://erc-smscom.dei.polimi.it/ .) – and lead by the author. It is argued that these approaches fit well the current agile methods for development and operations that are popularized as DevOps.",http://dx.doi.org/10.1007/978-3-319-34096-8_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-40667-1_5,Towards Vulnerability Discovery Using Staged Program Analysis,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-40667-1_5,Springer,2016-01-01,"Eliminating vulnerabilities from low-level code is vital for securing software. Static analysis is a promising approach for discovering vulnerabilities since it can provide developers early feedback on the code they write. But, it presents multiple challenges not the least of which is understanding what makes a bug exploitable and conveying this information to the developer. In this paper, we present the design and implementation of a practical vulnerability assessment framework, called . Mélange performs data and control flow analysis to diagnose potential security bugs, and outputs well-formatted bug reports that help developers understand and fix security bugs. Based on the intuition that real-world vulnerabilities manifest themselves across multiple parts of a program, Mélange performs both local and global analyses in stages. To scale up to large programs, global analysis is demand-driven. Our prototype detects multiple vulnerability classes in C and C++ code including type confusion, and garbage memory reads. We have evaluated Mélange extensively. Our case studies show that Mélange scales up to large codebases such as Chromium, is easy-to-use, and most importantly, capable of discovering vulnerabilities in real-world code. Our findings indicate that static analysis is a viable reinforcement to the software testing tool set.",http://dx.doi.org/10.1007/978-3-319-40667-1_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-31486-0_3,Design Mining Color Semantics,Quantifying Aesthetics of Visual Design Applied to Automatic Design,10.1007/978-3-319-31486-0_3,Springer,2016-01-01,"Unlike visual arts where the main goals may be abstract, visual design is conceptualized and created to convey a message and communicate with audiences [16, 17, 45, 64, 66, 78, 80, 114, 115, 167]. This is a key but subtle difference between visual arts and visual design. In fact, it is a critical measure of success in applied arts along with the visual appeal of the design. A design message has to be conveyed at first glance. Studies suggest that designers need to make a good first impression only in some few milliseconds [99, 100], and this impression deals with expressive aesthetics [156], which is a matter of visual appeal by itself.",http://dx.doi.org/10.1007/978-3-319-31486-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-1-349-70229-9_1,The Grants Register,The Grants Register 2017,10.1007/978-1-349-70229-9_1,Springer,2016-01-01,,http://dx.doi.org/10.1007/978-1-349-70229-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-31456-3_7,"Revocable Privacy: Principles, Use Cases, and Technologies",Privacy Technologies and Policy,10.1007/978-3-319-31456-3_7,Springer,2016-01-01,"Security and privacy often seem to be at odds with one another. In this paper, we revisit the design principle of revocable privacy which guides the creation of systems that offer anonymity for people who do not violate a predefined rule, but can still have consequences for people who do violate the rule. We first improve the definition of revocable privacy by considering different types of sensors for users’ actions and different types of consequences of violating the rules (for example blocking). Second, we explore some use cases that can benefit from a revocable privacy approach. For each of these, we derive the underlying abstract rule that users should follow. Finally, we describe existing techniques that can implement some of these abstract rules. These descriptions not only illustrate what can already be accomplished using revocable privacy, they also reveal directions for future research.",http://dx.doi.org/10.1007/978-3-319-31456-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-32967-3_2,The Dawn of the Conversational Interface,The Conversational Interface,10.1007/978-3-319-32967-3_2,Springer,2016-01-01,"With a conversational interface, people can speak to their smartphones and other smart devices in a natural way in order to obtain information, access Web services, issue commands, and engage in general chat. This chapter presents some examples of conversational interfaces and reviews technological advances that have made conversational interfaces possible. Following this, there is an overview of the technologies that make up a conversational interface.",http://dx.doi.org/10.1007/978-3-319-32967-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-29659-3_7,Evaluating Recommender Systems,Recommender Systems,10.1007/978-3-319-29659-3_7,Springer,2016-01-01,The evaluation of collaborative filtering shares a number of similarities with that of classification. This similarity is due to the fact that collaborative filtering can be viewed as a generalization of the classification and regression modeling problem (cf. section  1.3.1.3 of Chapter  1 ).,http://dx.doi.org/10.1007/978-3-319-29659-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-0271-5_1,Setting the Stage for Hive: Hadoop,Practical Hive,10.1007/978-1-4842-0271-5_1,Springer,2016-01-01,"By now, any technical specialist with even a sliver of curiosity has heard the term Hadoop tossed around at the water cooler. The discussion likely ranges from, “Hadoop is a waste-of-time,” to “This is big. This will solve all our current problems.” You may also have heard your company director, manager, or even CIO ask the team to begin implementing this new Big Data thing and to somehow identify a problem it is meant to solve.",http://dx.doi.org/10.1007/978-1-4842-0271-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-015-9440-z,Recommender systems in e-learning environments: a survey of the state-of-the-art and possible extensions,Artificial Intelligence Review,10.1007/s10462-015-9440-z,Springer,2015-12-01,"With the development of sophisticated e-learning environments, personalization is becoming an important feature in e-learning systems due to the differences in background, goals, capabilities and personalities of the large numbers of learners. Personalization can achieve using different type of recommendation techniques. This paper presents an overview of the most important requirements and challenges for designing a recommender system in e-learning environments. The aim of this paper is to present the various limitations of the current generation of recommendation techniques and possible extensions with model for tagging activities and tag-based recommender systems, which can apply to e-learning environments in order to provide better recommendation capabilities.",http://dx.doi.org/10.1007/s10462-015-9440-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-015-9165-3,What recommenders recommend: an analysis of recommendation biases and possible countermeasures,User Modeling and User-Adapted Interaction,10.1007/s11257-015-9165-3,Springer,2015-12-01,"Most real-world recommender systems are deployed in a commercial context or designed to represent a value-adding service, e.g., on shopping or Social Web platforms, and typical success indicators for such systems include conversion rates, customer loyalty or sales numbers. In academic research, in contrast, the evaluation and comparison of different recommendation algorithms is mostly based on offline experimental designs and accuracy or rank measures which are used as proxies to assess an algorithm’s recommendation quality. In this paper, we show that popular recommendation techniques—despite often being similar when compared with the help of accuracy measures—can be quite different with respect to which items they recommend. We report the results of an in-depth analysis in which we compare several recommendations strategies from different perspectives, including accuracy, catalog coverage and their bias to recommend popular items. Our analyses reveal that some recent techniques that perform well with respect to accuracy measures focus their recommendations on a tiny fraction of the item spectrum or recommend mostly top sellers. We analyze the reasons for some of these biases in terms of algorithmic design and parameterization and show how the characteristics of the recommendations can be altered by hyperparameter tuning. Finally, we propose two novel algorithmic schemes to counter these popularity biases.",http://dx.doi.org/10.1007/s11257-015-9165-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40537-015-0032-1,A survey of open source tools for machine learning with big data in the Hadoop ecosystem,Journal of Big Data,10.1186/s40537-015-0032-1,Springer,2015-11-05,"With an ever-increasing amount of options, the task of selecting machine learning tools for big data can be difficult. The available tools have advantages and drawbacks, and many have overlapping uses. The world’s data is growing rapidly, and traditional tools for machine learning are becoming insufficient as we move towards distributed and real-time processing. This paper is intended to aid the researcher or professional who understands machine learning but is inexperienced with big data. In order to evaluate tools, one should have a thorough understanding of what to look for. To that end, this paper provides a list of criteria for making selections along with an analysis of the advantages and drawbacks of each. We do this by starting from the beginning, and looking at what exactly the term “big data” means. From there, we go on to the Hadoop ecosystem for a look at many of the projects that are part of a typical machine learning architecture and an understanding of how everything might fit together. We discuss the advantages and disadvantages of three different processing paradigms along with a comparison of engines that implement them, including MapReduce, Spark, Flink, Storm, and H 2 O. We then look at machine learning libraries and frameworks including Mahout, MLlib, SAMOA, and evaluate them based on criteria such as scalability, ease of use, and extensibility. There is no single toolkit that truly embodies a one-size-fits-all solution, so this paper aims to help make decisions smoother by providing as much information as possible and quantifying what the tradeoffs will be. Additionally, throughout this paper, we review recent research in the field using these tools and talk about possible future directions for toolkit-based learning.",http://dx.doi.org/10.1186/s40537-015-0032-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-014-1950-1,Tuning metadata for better movie content-based recommendation systems,Multimedia Tools and Applications,10.1007/s11042-014-1950-1,Springer,2015-09-01,"The increasing number of television channels, on-demand services and online content, is expected to contribute to a better quality of experience for a costumer of such a service. However, the lack of efficient methods for finding the right content, adapted to personal interests, may lead to a progressive loss of clients. In such a scenario, recommendation systems are seen as a tool that can fill this gap and contribute to the loyalty of users. Multimedia content, namely films and television programmes are usually described using a set of metadata elements that include the title, a genre, the date of production, and the list of directors and actors. This paper provides a deep study on how the use of different metadata elements can contribute to increase the quality of the recommendations suggested. The analysis is conducted using Netflix and Movielens datasets and aspects such as the granularity of the descriptions, the accuracy metric used and the sparsity of the data are taken into account. Comparisons with collaborative approaches are also presented.",http://dx.doi.org/10.1007/s11042-014-1950-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13673-015-0036-z,Design of fusion technique-based mining engine for smart business,Human-centric Computing and Information Sciences,10.1186/s13673-015-0036-z,Springer,2015-07-31,"Keys to successful implementation of smart business require a wide spectrum of domain knowledge, experts, and their correlated experiences. Excluding those external factors—which can be collected by well-deployed sensors—being aware of user (or consumer) has the highest priority on the to-do-list. The more user is understood, the more user can be satisfied from an intuitive point of view, and thus, data plays a rather essential role in the scenario. However, it is never easy to achieve comprehensive understanding as the data requires further processing before its values can be extracted and used. So how the data can be properly transformed into something useful for smart business development is exactly what we pursue in this study. As a pioneer, three major tasks are focused. First, a data mining engine based on the concept of the KID model is designed and developed to be responsible for the universal collection of data and mining valuable information which is primarily from real world, cyber world, and social world. Second, we go further into the fusion process of the collected data and meaningful information extracted and interpreted by algorithms or fused algorithms in the data mining engine (e.g., the consumer purchase data shared by real-world company) and turn them into valuable knowledge about the situation of customers and business situations based on the concept of knowledge, information, and data. A three-layer analysis and mining procedure is designed to enhance the mining engine through conventional RFM (Recency, Frequency, and Monetary Value) model and a set of fusion techniques. And in the end, we make planning-based predictions for a real-world company for expansion of the business interests.",http://dx.doi.org/10.1186/s13673-015-0036-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40881-015-0005-3,Online field experiments: a selective survey of methods,Journal of the Economic Science Association,10.1007/s40881-015-0005-3,Springer,2015-07-01,"The Internet presents today’s researchers with unprecedented opportunities to conduct field experiments. Using examples from Economics and Computer Science, we present an analysis of the design choices, with particular attention to the underlying technologies, in conducting online field experiments and report on lessons learned.",http://dx.doi.org/10.1007/s40881-015-0005-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s40854-015-0004-7,Harnessing Internet finance with innovative cyber credit management,Financial Innovation,10.1186/s40854-015-0004-7,Springer,2015-06-09,"In the last two decades, Internet technologies, such as cloud computing, mobile communications, social media, and big data analytics, have brought tremendous changes to our society and reshaped the business in various industries. Specifically, the mushrooming innovations in the financial area fertilized by information and communication technologies indicates the advent of the Internet finance era. Applying the exploratory research approach, we investigate major innovative Internet-based financial services and classify them into five categories, as of e-commerce, e-payment, e-money market, online loan services, and digital currencies. Then we propose a market structure of Internet finance extended from the traditional financial market. We claim that credit management is the key issue in the marketplace of Internet finance, characterized by big data analytics, in which cyber credit appears as whole-process, multi-dimensional, and holographic. We further suggest that cyber credit be represented in the form of vector to overcome the limits of traditional single-value measure in cyber credit management. Based on this framework, we raise main research issues in Internet finance from the perspectives of theory, technology, and governance.",http://dx.doi.org/10.1186/s40854-015-0004-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-013-0723-x,"
              CloudRec: a framework for personalized service Recommendation in the Cloud",Knowledge and Information Systems,10.1007/s10115-013-0723-x,Springer,2015-05-01,"The elastic computing power and the pay-as-you-go model of the cloud offer an attractive platform to deploy software as a service applications. The large number of applications expected to heavily take advantage of the cloud will result in an explosive growth of various cloud services. As many cloud services may compete to offer similar functionalities, it is desirable to consider user preferences on the nonfunctional service properties (aka, quality of service, or QoS) when delivering cloud services to the end users. Unfortunately, current approaches primarily rely on the descriptions from the cloud service providers or expert-provided rankings, which are completely orthogonal to the open and distributed nature of the cloud. We present a novel framework (referred to as CloudRec ) that exploits a user-centric strategy to achieve personalized QoS assessment of cloud services. CloudRec integrates a novel community-based QoS assessment model with an iterative algorithm to accurately discover a set of homogenous user and service communities from scarce and large-scale QoS data. The communities can serve as a bridge to relate users and services and hence provide an effective means to estimate the QoS of unknown cloud services. The effectiveness of the proposed framework is demonstrated through a rigorous theoretical analysis and an extensive empirical study on real QoS data.",http://dx.doi.org/10.1007/s10115-013-0723-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00779-014-0831-y,Reviving community networks: hyperlocality and suprathresholding in Web 2.0 designs,Personal and Ubiquitous Computing,10.1007/s00779-014-0831-y,Springer,2015-02-01,"Social scientists have identified a crisis of community in modern society, for example, Putnam’s (Bowling alone: the collapse and revival of American community. Simon and Schuster, New York, 2000 ) study of a 40-year decline of community in American society. We argue that the design palette of Web 2.0 offers critical affordances for community information and interaction that enable hyperlocality and suprathresholding . We describe a community-based participatory design research project through which we investigated the design characteristics of hyperlocality and suprathresholding. We speculate on the possibility of a new design model for community networks.",http://dx.doi.org/10.1007/s00779-014-0831-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-014-0241-1,Characterizing and automatically detecting crowdturfing in Fiverr and Twitter,Social Network Analysis and Mining,10.1007/s13278-014-0241-1,Springer,2015-01-09,"As human computation on crowdsourcing systems has become popular and powerful for performing tasks, malicious users have started misusing these systems by posting malicious tasks, propagating manipulated contents, and targeting popular web services such as online social networks and search engines. Recently, these malicious users moved to Fiverr, a fast growing micro-task marketplace, where workers can post crowdturfing tasks (i.e., astroturfing campaigns run by crowd workers) and malicious customers can purchase those tasks for only $5. In this manuscript, we present a comprehensive analysis of crowdturfing in Fiverr and Twitter and develop predictive models to detect and prevent crowdturfing tasks in Fiverr and malicious crowd workers in Twitter. First, we identify the most popular types of crowdturfing tasks found in Fiverr and conduct case studies for these crowdturfing tasks. Second, we build crowdturfing task detection classifiers to filter these tasks and prevent them from becoming active in the marketplace. Our experimental results show that the proposed classification approach effectively detects crowdturfing tasks, achieving 97.35 % accuracy. Third, we analyze the real-world impact of crowdturfing tasks by purchasing active Fiverr tasks and quantifying their impact on a target site (Twitter). As part of this analysis, we show that current security systems inadequately detect crowdsourced manipulation, which confirms the necessity of our proposed crowdturfing task detection approach. Finally, we analyze the characteristics of paid Twitter workers, find distinguishing features between these workers and legitimate Twitter accounts, and use these features to build classifiers that detect Twitter workers. Our experimental results show that our classifiers are able to detect Twitter workers effectively, achieving 99.29 % accuracy.",http://dx.doi.org/10.1007/s13278-014-0241-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_11,Recommender Systems in Industry: A Netflix Case Study,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_11,Springer,2015-01-01,"The Netflix Prize put a spotlight on the importance and use of recommender systems in real-world applications. Many the competition provided many lessons about how to approach recommendation and many more have been learned since the Grand Prize was awarded in 2009. The evolution of industrial applications of recommender systems has been driven by the availability of different kinds of user data and the level of interest for the area within the research community. The goal of this chapter is to give an up-to-date overview of recommender systems techniques used in an industrial setting. We will give a high-level description the practical use of recommendation and personalization techniques. We will highlight some of the main lessons learned from the Netflix Prize. We will then use Netflix personalization as a case study to describe several approaches and techniques used in a real-world recommendation system. Finally, we will pinpoint what we see as some promising current research avenues and unsolved problems that deserve attention in this domain from an industry perspective.",http://dx.doi.org/10.1007/978-1-4899-7637-6_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25007-6_23,Decision-Making Bias in Instance Matching Model Selection,The Semantic Web - ISWC 2015,10.1007/978-3-319-25007-6_23,Springer,2015-01-01,"Instance matching has emerged as an important problem in the Semantic Web, with machine learning methods proving especially effective. To enhance performance, task-specific knowledge is typically used to introduce bias in the model selection problem. Such biases tend to be exploited by practitioners in a piecemeal fashion. This paper introduces a framework where the model selection design process is represented as a factor graph. Nodes in this bipartite graphical model represent opportunities for explicitly introducing bias. The graph is first used to unify and visualize common biases in the design of existing instance matchers. As a direct application, we then use the graph to hypothesize about potential unexploited biases. The hypotheses are evaluated by training 1032 neural networks on three instance matching tasks on Microsoft Azure’s cloud-based platform. An analysis over 25 GB of experimental data indicates that the proposed biases can improve efficiency by over 65% over a baseline configuration, with effectiveness improving by a smaller margin. The findings lead to a promising set of four recommendations that can be integrated into existing supervised instance matchers.",http://dx.doi.org/10.1007/978-3-319-25007-6_23,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-10091-3_2,"E-Commerce: Mechanisms, Platforms, and Tools",Electronic Commerce,10.1007/978-3-319-10091-3_2,Springer,2015-01-01,An e-commerce site talked about a great deal since 2011 is Pinterest.,http://dx.doi.org/10.1007/978-3-319-10091-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-10091-3_8,Social Enterprise and Other Social Commerce Topics,Electronic Commerce,10.1007/978-3-319-10091-3_8,Springer,2015-01-01,"Upon completion of this chapter, you will be able to:",http://dx.doi.org/10.1007/978-3-319-10091-3_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-25485-2_3,Introduction to Formal Concept Analysis and Its Applications in Information Retrieval and Related Fields,Information Retrieval,10.1007/978-3-319-25485-2_3,Springer,2015-01-01,"This paper is a tutorial on Formal Concept Analysis (FCA) and its applications. FCA is an applied branch of Lattice Theory, a mathematical discipline which enables formalisation of concepts as basic units of human thinking and analysing data in the object-attribute form. Originated in early 80s, during the last three decades, it became a popular human-centred tool for knowledge representation and data analysis with numerous applications. Since the tutorial was specially prepared for RuSSIR 2014, the covered FCA topics include Information Retrieval with a focus on visualisation aspects, Machine Learning, Data Mining and Knowledge Discovery, Text Mining and several others.",http://dx.doi.org/10.1007/978-3-319-25485-2_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-13659-2_2,Intelligent Decision Support Systems,Biometric and Intelligent Decision Making Support,10.1007/978-3-319-13659-2_2,Springer,2015-01-01,"This chapter presents the latest IDSSs, such as text analytics and mining based DSSs; ambient intelligence and the internet of things-based DSSs; biometrics-based DSSs; recommender, advisory and expert systems; data mining, data analytics, neural networks, remote sensing and their integration with decision support systems and other IDSSs. These other IDSSs include GA-based DSS; fuzzy sets DSS; rough sets-based DSS; intelligent agent-assisted DSS; process mining integration to decision support, adaptive DSS; computer vision based DSS; sensory DSS and robotic DSS. In addition to acquainting these IDSSs, author introduce practical examples where they have been effectively applied.",http://dx.doi.org/10.1007/978-3-319-13659-2_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_6,Context-Aware Recommender Systems,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_6,Springer,2015-01-01,"The importance of contextual information has been recognized by researchers and practitioners in many disciplines, including e-commerce personalization, information retrieval, ubiquitous and mobile computing, data mining, marketing, and management. While a substantial amount of research has already been performed in the area of recommender systems, many existing approaches focus on recommending the most relevant items to users without taking into account any additional contextual information, such as time, location, or the company of other people (e.g., for watching movies or dining out). There is growing understanding that relevant contextual information does matter in recommender systems and that it is important to take this information into account when providing recommendations. We discuss the general notion of context and how it can be modeled in recommender systems. We also discuss three popular algorithmic paradigms—contextual pre-filtering, post-filtering, and modeling—for incorporating contextual information into the recommendation process, and survey recent work on context-aware recommender systems. We also discuss important directions for future research. context-aware recommender system",http://dx.doi.org/10.1007/978-1-4899-7637-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-07812-0_10,Click Fraud Detection: Adversarial Pattern Recognition over 5 Years at Microsoft,Real World Data Mining Applications,10.1007/978-3-319-07812-0_10,Springer,2015-01-01,"Microsoft adCenter is the third largest Search advertising platform in the United States behind Google and Yahoo, and services about 10 % of US traffic. At this scale of traffic approximately 1 billion events per hour, amounting to 2.3 billion ad dollars annually, need to be scored to determine if it is fraudulent or bot-generated [32, 37, 41]. In order to accomplish this, adCenter has developed arguably one of the largest data mining systems in the world to score traffic quality, and has employed them successfully over 5 years. The current paper describes the unique challenges posed by data mining at massive scale, the design choices and rationale behind the technologies to address the problem, and shows some examples and some quantitative results on the effectiveness of the system in combating click fraud.",http://dx.doi.org/10.1007/978-3-319-07812-0_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1057/9781137477729_3,The Business Impact of Digital Technologies,Building the Digital Enterprise,10.1057/9781137477729_3,Springer,2015-01-01,"The scale of digitization is a pervasive story across all industries in the developed and developing world (Figure 3.1). Digital information through devices and networks span local, regional, and global economies. As technology adoption spreads, information become digitized, and products and service barriers are transformed.",http://dx.doi.org/10.1057/9781137477729_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_8,Evaluating Recommender Systems,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_8,Springer,2015-01-01,"Recommender systems are now popular both commercially and in the research community, where many approaches have been suggested for providing recommendations. In many cases a system designer that wishes to employ a recommendater system must choose between a set of candidate approaches. A first step towards selecting an appropriate algorithm is to decide which properties of the application to focus upon when making this choice. Indeed, recommender systems have a variety of properties that may affect user experience, such as accuracy, robustness, scalability, and so forth. In this paper we discuss how to compare recommenders based on a set of properties that are relevant for the application. We focus on comparative studies, where a few algorithms are compared using some evaluation metric, rather than absolute benchmarking of algorithms. We describe experimental settings appropriate for making choices between algorithms. We review three types of experiments, starting with an offline setting, where recommendation approaches are compared without user interaction, then reviewing user studies, where a small group of subjects experiment with the system and report on the experience, and finally describe large scale online experiments, where real user populations interact with the system. In each of these cases we describe types of questions that can be answered, and suggest protocols for experimentation. We also discuss how to draw trustworthy conclusions from the conducted experiments. We then review a large set of properties, and explain how to evaluate systems given relevant properties. We also survey a large set of evaluation metrics in the context of the property that they evaluate.",http://dx.doi.org/10.1007/978-1-4899-7637-6_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-6551-4_1,Complex Systems,Metasynthetic Computing and Engineering of Complex Systems,10.1007/978-1-4471-6551-4_1,Springer,2015-01-01,"Complex systems are ubiquitous and have become increasingly focused on scientific and business domains since they are part of our daily life, business, and environment. Deeply understanding the intricacies of complex systems is thus a basic task in the scientific domain. In this chapter, we explore: The system complexities of complex systems, to summarize the main characteristics of complex systems System transparency, to outline general categories of complex (as well as simple) systems in terms of the transparency of their content and complexity to users System classification, to create multiple dimensions for categorizing complex systems Open complex systems, to discuss their characteristics and challenges Large-scale systems, to discuss those complex systems that have a huge number of components Hybrid intelligent systems, to show those systems that hybridize different techniques, methods, and tools Computing and engineering complex systems, to summarize the main computing paradigms, system analysis and design, and the objectives of metasynthetic computing and engineering",http://dx.doi.org/10.1007/978-1-4471-6551-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_18,Human Decision Making and Recommender Systems,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_18,Springer,2015-01-01,"If we assume that an important function of recommender systems is to help people make better choices, it follows that people who design and study recommender systems ought to have a good understanding of how people make choices and how human choice can be supported. This chapter starts with a compact synthesis of research on the various ways in which people make choices in everyday life, in terms of six choice patterns ; we explain for each pattern how recommender systems can support its application, both in familiar ways and in ways that have not been explored so far. Similarly, we distinguish six high-level strategies for supporting choice, noting that one strategy is directly supported by recommendation technology but that the others can also be applied fruitfully in recommender systems. We then illustrate how this conceptual framework can be used to shed new light on several fundamental questions that arise in recommender systems research: In what ways can explanations of recommendations support choice processes? What are we referring to when we speak of a person’s “preferences”? What goes on in people’s heads when they rate an item? What is “choice overload”, and how can recommender systems help prevent it? How can recommender systems help choosers to engage in trial and error? What subtle influences on choice can arise when people choose among a small number of options; and how can a recommender system take them into account? One general contribution of the chapter is to generate new ideas about how recommendation technology can be deployed in support of human choice, often in conjunction with other strategies and technologies.",http://dx.doi.org/10.1007/978-1-4899-7637-6_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-17112-8_6,Monitoring of Client-Cloud Interaction,Correct Software in Web Applications and Web Services,10.1007/978-3-319-17112-8_6,Springer,2015-01-01,"When a client consumes a cloud service, computational liabilities are transferred to the service provider in accordance to the cloud paradigm, and the client loses some control over software components. One way to raise assurance about correctness and dependability of a consumed service and its software components is monitoring. In particular, a monitor is a system that observes the behavior of another system, and observation points that expose the target system’s state and state changes are required. Due to the cloud paradigm, popular techniques for monitoring such as code instrumentation are often not available to the client because of limited visibility, lack of control, and black-box software components. Based on a literature review, we identify potential observation points in today’s cloud services. Furthermore, we investigate two cloud-specific monitoring applications based on our ongoing research. While service level agreement (SLA) monitoring ensures that agreed-upon conditions between clients and providers are met, language-based anomaly detection monitors the interaction between client and cloud for misuse attempts.",http://dx.doi.org/10.1007/978-3-319-17112-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-0964-6_3,Spark Core,Big Data Analytics with Spark,10.1007/978-1-4842-0964-6_3,Springer,2015-01-01,"Spark is the most active open source project in the big data world. It has become hotter than Hadoop. It is considered the successor to Hadoop MapReduce, which we discussed in Chapter 1 . Spark adoption is growing rapidly. Many organizations are replacing MapReduce with Spark.",http://dx.doi.org/10.1007/978-1-4842-0964-6_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.2991/978-94-6239-142-0_7,"Ethical Implications of AmI and the IoT: Risks to Privacy, Security, and Trust, and Prospective Technological Safeguards",The Shaping of Ambient Intelligence and the Internet of Things,10.2991/978-94-6239-142-0_7,Springer,2015-01-01,"AmI and the IoT are among the metaphors that are used to depict visions of a future filled with smart, interacting, and interconnected everyday objects and a whole range of immense opportunities and fascinating possibilities such future will open up and bring that are created by the incorporation of ICT intelligence into people’s everyday lives. The vision of AmI entails integrating tiny microelectronic information processors and networks of miniature sensors and actuators into everyday objects so to make them smart, and the vision of the IoT involves interconnecting uniquely identified embedded devices and physical, virtual, and smart objects within the existing Internet infrastructure. Sharing many technological features, these two visions of computationally augmented everyday environments have claims to be aware of people’s presence and situational context, adaptive and anticipatory to their desires and intentions, and personalized to their needs. However, while many technologists and scientists paint the promises of AmI and the IoT in sunny colors, touting them as a step towards a better world, social observers and scholars have doubts about the potentials of this technological evolution. The ramifications of such extensive integration of ICT intelligence into people’s everyday lives are difficult to predict. With the open challenges and the growing concerns pertaining to their deployment, AmI and the IoT are visions that are worth attention and further research. This chapter aims to investigate the risks that AmI and the IoT pose to ethical values, and to provide some prospective technological safeguards. The intention of this endeavor is to better understand how far such visions should influence people’s everyday lives and to contribute to, by identifying and addressing the great challenges involved, steering this development in a direction that goes some distance towards mitigating the risks posed by the emerging worlds of AmI and the IoT so to help foster users’ trust and confidence in the technological vision of the twenty-first century, and thus create and revive optimism among technology users as to how this vision will unfold.",http://dx.doi.org/10.2991/978-94-6239-142-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25524-8_45,Adaptive Multi-stage Optimisation for EV Charging Integration into Smart Grid Control,PRIMA 2015: Principles and Practice of Multi-Agent Systems,10.1007/978-3-319-25524-8_45,Springer,2015-01-01,"The increasing amount of both, renewable energy production and electric vehicle usage, puts considerable stress on smart grids, making it necessary to synchronize vehicle charging with energy production, but also allowing to use those vehicles as additional energy storages. In this paper, we combine machine learning and evolutionary algorithms to create near-optimal vehicle charging schedules from incomplete information. Using multi-agent systems and process modelling techniques, the different stages can easily be combined and distributed. The result is a reusable and extensible solution that is used for optimizing charging schedules in many different project settings.",http://dx.doi.org/10.1007/978-3-319-25524-8_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_19,Privacy Aspects of Recommender Systems,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_19,Springer,2015-01-01,"The popularity of online recommender systems has soared; they are deployed in numerous websites and gather tremendous amounts of user data that are necessary for recommendation purposes. This data, however, may pose a severe threat to user privacy, if accessed by untrusted parties or used inappropriately. Hence, it is of paramount importance for recommender system designers and service providers to find a sweet spot, which allows them to generate accurate recommendations and guarantee the privacy of their users. In this chapter we overview the state of the art in privacy enhanced recommendations. We analyze the risks to user privacy imposed by recommender systems, survey the existing solutions, and discuss the privacy implications for the users of recommenders. We conclude that a considerable effort is still required to develop practical recommendation solutions that provide adequate privacy guarantees, while at the same time facilitating the delivery of high-quality recommendations to their users.",http://dx.doi.org/10.1007/978-1-4899-7637-6_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_1,Recommender Systems: Introduction and Challenges,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_1,Springer,2015-01-01,"Recommender Systems (RSs) are software tools and techniques that provide suggestions for items that are most likely of interest to a particular user. In this introductory chapter, we briefly discuss basic RS ideas and concepts. Our main goal is to delineate, in a coherent and structured way, the chapters included in this handbook. Additionally, we aim to help the reader navigate the rich and detailed content that this handbook offers.",http://dx.doi.org/10.1007/978-1-4899-7637-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20550-2_15,On the Security and Engineering Implications of Finer-Grained Access Controls for Android Developers and Users,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-20550-2_15,Springer,2015-01-01,"One of the main security mechanisms in Android is the permission system. Previous research has pointed out that this system is too coarse-grained . Hence, several mechanisms have been proposed to address this issue. However, to date, the impact of changes in the current permission system on both end users and software developers has not been studied, and no significant work has been done to determine whether adopting a finer-grained permission system would be feasible in practice. In this work, we perform the first study to explore the practicality of the adoption of finer-grained system for the Internet permission. In particular, we have developed several analysis tools that we used to perform an empirical study on 1,227 real-world Android applications. The results of this study provide useful insights to answer the following three conceptual questions: (1) Is it practical to apply fine-grained access control mechanisms to real-world Android applications? (2) How can a system for fine-grained permission enforcement be integrated into the application development and distribution life-cycle with minimal additional required effort? (3) What are the incentives and practical benefits for both developers and end users to adopt a fine-grained permission model? Our preliminary results show that, in general, finer-grained permissions could be practical and desirable for Android applications. In addition, we show how the tools we have developed can be used to automatically generate and enforce security policies, and thus could be used to lower the burden of adoption of finer-grained permission systems.",http://dx.doi.org/10.1007/978-3-319-20550-2_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-79465-0_1,Library Standards and the Semantic Web,Library Linked Data in the Cloud,10.1007/978-3-031-79465-0_1,Springer,2015-01-01,,http://dx.doi.org/10.1007/978-3-031-79465-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20550-2_4,Intrusion Detection for Airborne Communication Using PHY-Layer Information,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-20550-2_4,Springer,2015-01-01,"With passenger and cargo traffic growing rapidly world-wide, and unmanned aerial vehicles (UAV) poised to enter commercial airspaces, a secure next generation of air traffic management systems is required. Recent articles in the academic and hacker community highlight crucial security challenges faced by integral parts of these next generation protocols, with the most dangerous attacks based on classic message injection. In this article, we analyze the possibility and effectiveness of detecting such attacks on critical air traffic infrastructures with a single receiver based on physical layer information. Using hypothesis testing and anomaly detection schemes, we develop an intrusion detection system (IDS) that can accurately detect attackers within 40 s.",http://dx.doi.org/10.1007/978-3-319-20550-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-45777-1_9,e-Service Industry,"Revolutionizing Collaboration through e-Work, e-Business, and e-Service",10.1007/978-3-662-45777-1_9,Springer,2015-01-01,"e-Service refers to the provision and support of services remotely via information and communication components and services, and over electronic networks. Such services are not limited to the scope of businesses and organizations, and with the global approach to service-orientation, all e-Systems even e-Manufacturing systems are increasingly shifting towards the development and implementation of sound service practices over e-Networks. To achieve this end, this chapter first reviews the state-of-the-art developments in various e-Service industries, their commons characteristics, and emerging challenges. Then, techniques for service performance monitoring, evaluation, and optimization are discussed. Following the preliminary definitions, advanced service design, optimization, and control techniques are introduced, including Task Administration Protocols (TAP) for real-time e-Service design and monitoring, collaborative e-Service portal design, and protocols for diagnosis and prognosis of errors and conflicts in e-Service networks.",http://dx.doi.org/10.1007/978-3-662-45777-1_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-18275-9_7,A Bio-Inspired Hybrid Artificial Intelligence Framework for Cyber Security,"Computation, Cryptography, and Network Security",10.1007/978-3-319-18275-9_7,Springer,2015-01-01,"Confidentiality, Integrity, and Availability of Military information is a crucial and critical factor for a country’s national security. The security of military information systems (MIS) and Networks (MNET) is a subject of continuous research and design, due to the fact that they manage, store, manipulate, and distribute the information. This study presents a bio-inspired hybrid artificial intelligence framework for cyber security (bioHAIFCS). This framework combines timely and bio-inspired Machine Learning methods suitable for the protection of critical network applications, namely military information systems, applications and networks. More specifically, it combines (a) the hybrid evolving spiking anomaly detection model (HESADM), which is used in order to prevent in time and accurately, cyber-attacks, which cannot be avoided by using passive security measures, namely: Firewalls, (b) the evolving computational intelligence system for malware detection (ECISMD) that spots and isolates malwares located in packed executables untraceable by antivirus, and (c) the evolutionary prevention system from SQL injection (ePSSQLI) attacks, which early and smartly forecasts the attacks using SQL Injections methods.",http://dx.doi.org/10.1007/978-3-319-18275-9_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4899-7637-6_9,Evaluating Recommender Systems with User Experiments,Recommender Systems Handbook,10.1007/978-1-4899-7637-6_9,Springer,2015-01-01,"Proper evaluation of the user experience of recommender systems requires conducting user experiments. This chapter is a guideline for students and researchers aspiring to conduct user experiments with their recommender systems. It first covers the theory of user-centric evaluation of recommender systems, and gives an overview of recommender system aspects to evaluate. It then provides a detailed practical description of how to conduct user experiments, covering the following topics: formulating hypotheses, sampling participants, creating experimental manipulations, measuring subjective constructs with questionnaires, and statistically evaluating the results.",http://dx.doi.org/10.1007/978-1-4899-7637-6_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08422-0_24,Web Service Intrusion Detection Using a Probabilistic Framework,Progress in Systems Engineering,10.1007/978-3-319-08422-0_24,Springer,2015-01-01,"In this paper, we propose an anomaly-based approach to detect intrusions attempts that may target web services. These intrusions (or attacks) are modeled as outliers (or noise) within a principled probabilistic framework. The proposed framework is based on finite Gaussian mixtures and allows the detection of both previously seen and unknown attacks against web services. The main idea of our framework is based on the consideration of malicious requests as outliers within our finite mixture model. Using this idea the intrusion detection problem is reduced to an adversarial classification problem. The merits of the proposed approach are shown using a data set containing both normal and intrusive requests, which were collected from a large real-life web service.",http://dx.doi.org/10.1007/978-3-319-08422-0_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1057/9781137474162_7,The Role of Spam in Cybercrime: Data from the Australian Cybercrime Pilot Observatory,Cybercrime Risks and Responses,10.1057/9781137474162_7,Springer,2015-01-01,"The use of the Internet for the purpose of crime is a rapidly growing phenomenon that requires a proactive and coordinated response (UNODC 2013). Cybercriminals increasingly use sophisticated tools and methods to distribute a wide range of malicious content, often combining deceptive “social engineering” tricks with spam emails, hosting of phishing sites, and identity theft (Smith and Hutchings 2014). Unsolicited bulk, mass emails, or “spam,” pose a global challenge because this remains a major vector for the dissemination of malware.",http://dx.doi.org/10.1057/9781137474162_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-24069-5_11,A Survey of Twitter Rumor Spreading Simulations,Computational Collective Intelligence,10.1007/978-3-319-24069-5_11,Springer,2015-01-01,"Viral marketing, marketing techniques that use pre-existing social networks, has experienced a significant encouragement in the last years. In this scope, Twitter is the most studied social network in viral marketing and the rumor spread is a widely researched problem. This paper contributes with a survey of research works which study rumor diffusion in Twitter. Moreover, the most useful aspects of these works to build new multi-agent based simulations dealing with this interesting and complex problem are discussed. The main four research lines in rumor dissemination found and discussed in this paper are: exploratory data analysis, rumor detection, epidemiological modeling, and multi-agent based social simulation. The survey shows that the reproducibility in the specialized literature has to be considerably improved. Finally, a free and open-source simulation tool implementing several of the models considered in this survey is presented.",http://dx.doi.org/10.1007/978-3-319-24069-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-08254-7_15,The Web KnowARR Framework: Orchestrating Computational Intelligence with Graph Databases,"Information Granularity, Big Data, and Computational Intelligence",10.1007/978-3-319-08254-7_15,Springer,2015-01-01,"This chapter presents fuzzy cognitive maps (FCM) as a vehicle for Web knowledge aggregation, representation, and reasoning. The corresponding Web KnowARR framework incorporates findings from fuzzy logic. To this end, a first emphasis is particularly on the Web KnowARR framework along with a stakeholder management use case to illustrate the framework’s usefulness as a second focal point. This management form is to help projects to acceptance and assertiveness where claims for company decisions are actively involved in the management process. Stakeholder maps visually (re-) present these claims. On one hand, they resort to non-public content and on the other they resort to content that is available to the public (mostly on the Web). The Semantic Web offers opportunities not only to present public content descriptively but also to show relationships. The proposed framework can serve as the basis for the public content of stakeholder maps.",http://dx.doi.org/10.1007/978-3-319-08254-7_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-47011-4_12,Recommending Web Services Using Crowdsourced Testing Data,Crowdsourcing,10.1007/978-3-662-47011-4_12,Springer,2015-01-01,"With the rapid growth of Web Services in the past decade, the issue of QoS-aware Web service recommendation is becoming more and more critical. Web service QoS is highly relevant to the corresponding invocation context like invocation time and location. Therefore, it is of paramount importance to collect the QoS data with different invocation context. We have crawled over 30,000 Web services Web services distributed across Internet. In this work, we propose to use crowdsourcing to collect the required QoS data. This is achieved through two approaches. On the one hand, we deploy a generic Web service invocation client to 343 Planet-Lab nodes and these nodes serve as simulated users Simulated users distributing worldwide. The Web service invocation client is scheduled to invoke target Web services Web services from time to time. On the other hand, we design and develop a mobile crowdsourced Web service tesing framework on Android Android platform, with which a user can easily invoke selected Web services. With the above two approaches, the observed service invocation data, e.g. response time, will be collected in this way. Then we design a Temporal QoS-aware Web service recommendation QoS-Aware Web Service Recommendation Recommendation Framework to predict missing QoS value under various temporal context. Further, we formalize this problem as a generalized tensor factorization model and propose a Non-negative Tensor Factorization Non-negative tensor factorization (NTF) algorithm which is able to deal with the triadic relations of user-service-time model. Extensive experiments are conducted based on collected Crowdsourced testing data. The comprehensive experimental analysis shows that our approach achieves better prediction accuracy than other approaches.",http://dx.doi.org/10.1007/978-3-662-47011-4_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-1251-6_1,Introducing Giraph,Practical Graph Analytics with Apache Giraph,10.1007/978-1-4842-1251-6_1,Springer,2015-01-01,This chapter covers,http://dx.doi.org/10.1007/978-1-4842-1251-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11390-015-1502-9,Using Memory in the Right Way to Accelerate Big Data Processing,Journal of Computer Science and Technology,10.1007/s11390-015-1502-9,Springer,2015-01-01,"Big data processing is becoming a standout part of data center computation. However, latest research has indicated that big data workloads cannot make full use of modern memory systems. We find that the dramatic inefficiency of the big data processing is from the enormous amount of cache misses and stalls of the depended memory accesses. In this paper, we introduce two optimizations to tackle these problems. The first one is the slice-and-merge strategy, which reduces the cache miss rate of the sort procedure. The second optimization is direct-memory-access, which reforms the data structure used in key/value storage. These optimizations are evaluated with both micro-benchmarks and the real-world benchmark HiBench. The results of our micro-benchmarks clearly demonstrate the effectiveness of our optimizations in terms of hardware event counts; and the additional results of HiBench show the 1.21X average speedup on the application-level. Both results illustrate that careful hardware/software co-design will improve the memory efficiency of big data processing. Our work has already been integrated into Intel distribution for Apache Hadoop.",http://dx.doi.org/10.1007/s11390-015-1502-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20550-2_7,Jackdaw: Towards Automatic Reverse Engineering of Large Datasets of Binaries,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-20550-2_7,Springer,2015-01-01,"When analyzing an untrusted binary, reverse engineers usually rely on ad-hoc collections of interesting dynamic patterns—known as behaviors in the malware-analysis community—and static patterns—known as signatures in the antivirus community. Such patterns are often part of the skill set of the analyst, sometimes implemented in manually-created post-processing scripts. It would be desirable to be able to automatically find such behaviors, present them to analysts, and create a systematic catalog of matching rules and relevant implementations. We propose Jackdaw , a system that finds interesting dynamic patterns, and ranks them to unveil potentially interesting behaviors. Then, it annotates them with static information, capturing the distinct implementations of each across different malware families. Finally, Jackdaw associates semantic information to the behaviors, so as to create a descriptive summary that helps the analysts in querying the catalog of behaviors by type. To do this, it leverages the dynamic information and an indexed Web-based knowledge databases. We implement and demonstrate Jackdaw on the Win32 API (even if the technique can be generalized to any OS). On a dataset of 2,136 distinct binaries, including both malicious and benign libraries and executables, we compared the behaviors extracted automatically against a ground truth of 44 behaviors created manually by expert analysts. Jackdaw found 77.3 % of them and was able to exclude spurious behaviors in 99.6 % cases. We also discovered 466 novel behaviors, among which manual exploration and review by expert reverse engineers revealed interesting findings and confirmed the correctness of the semantic tagging.",http://dx.doi.org/10.1007/978-3-319-20550-2_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20550-2_17,Controlled Data Sharing for Collaborative Predictive Blacklisting,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-20550-2_17,Springer,2015-01-01,"Although data sharing across organizations is often advocated as a promising way to enhance cybersecurity, collaborative initiatives are rarely put into practice owing to confidentiality, trust, and liability challenges. We investigate whether collaborative threat mitigation can be realized via controlled data sharing. With such an approach, organizations make informed decisions as to whether or not to share data, and how much. We propose using cryptographic tools for entities to estimate the benefits of collaboration and agree on what to share without having to disclose their datasets (i.e., in a privacy-preserving way). We focus on collaborative predictive blacklisting: Forecasting attack sources based on one’s logs and those contributed by other organizations. We study the impact of different sharing strategies by experimenting on a real-world dataset of two billion suspicious IP addresses collected from Dshield over two months. We find that controlled data sharing yields up to 105 % accuracy improvement on average, while also reducing the false positive rate.",http://dx.doi.org/10.1007/978-3-319-20550-2_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-349-68305-5_1,The Grants Register,The Grants Register 2016,10.1007/978-1-349-68305-5_1,Springer,2015-01-01,,http://dx.doi.org/10.1007/978-1-349-68305-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25903-1_34,Soft Biometrics by Modeling Temporal Series of Gaze Cues Extracted in the Wild,Advanced Concepts for Intelligent Vision Systems,10.1007/978-3-319-25903-1_34,Springer,2015-01-01,"Soft biometric systems have spread among recent years, both for powering classical biometrics, as well as stand alone solutions with several application scopes ranging from digital signage to human-robot interaction. Among all, in the recent years emerged the possibility to consider as a soft biometrics also the temporal evolution of the human gaze and some recent works in the literature explored this exciting research line by using expensive and (perhaps) unsafe devices which, moreover, require user cooperation to be calibrated. By our knowledge the use of a low-cost, non-invasive, safe and calibration-free gaze estimator to get soft-biometrics data has not been investigated yet. This paper fills this gap by analyzing the soft-biometrics performances obtained by modeling the series of gaze estimated by exploiting the combination of head poses and eyes’ pupil locations on data acquired by an off-the-shelf RGB-D device.",http://dx.doi.org/10.1007/978-3-319-25903-1_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-08254-7_3,Information Granules Problem: An Efficient Solution of Real-Time Fuzzy Regression Analysis,"Information Granularity, Big Data, and Computational Intelligence",10.1007/978-3-319-08254-7_3,Springer,2015-01-01,"Currently, Big Data is one of the common scenario which cannot be avoided. The presence of the voluminous amount of unstructured and semi-structured data would take too much time and cost too much money to load into a relational database for analysis purpose. Beside that, regression models are well known and widely used as one of the important categories of models in system modeling. This chapter shows an extended version of fuzzy regression concept in order to handle real-time data analysis of information granules. An ultimate objective of this study is to develop a hybrid of a genetically-guided clustering algorithm called genetic algorithm-based Fuzzy C-Means (GAFCM) and a convex hull-based regression approach, which is regarded as a potential solution to the formation of information granules. It is shown that a setting of Granular Computing with the proposed approach, helps to reduce the computing time, especially in case of real-time data analysis, as well as an overall computational complexity. Additionally, the proposed approach shows an efficient real-time processing of information granules regression analysis based on the convex hull approach in which a Beneath-Beyond algorithm is employed to design sub-convex hulls as well as a main convex hull structure. In the proposed design setting, it was emphasized a pivotal role of the convex hull approach or more specifically the Beneath-Beyond algorithm, which becomes crucial in alleviating limitations of linear programming manifesting in system modeling.",http://dx.doi.org/10.1007/978-3-319-08254-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20550-2_12,Quit Playing Games with My Heart: Understanding Online Dating Scams,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-20550-2_12,Springer,2015-01-01,"Online dating sites are experiencing a rise in popularity, with one in five relationships in the United States starting on one of these sites. Online dating sites provide a valuable platform not only for single people trying to meet a life partner, but also for cybercriminals, who see in people looking for love easy victims for scams. Such scams span from schemes similar to traditional advertisement of illicit services or goods (i.e., spam ) to advanced schemes, in which the victim starts a long-distance relationship with the scammer and is eventually extorted money. In this paper we perform the first large-scale study of online dating scams. We analyze the scam accounts detected on a popular online dating site over a period of eleven months, and provide a taxonomy of the different types of scammers that are active in the online dating landscape. We show that different types of scammers target a different demographics on the site, and therefore set up accounts with different characteristics. Our results shed light on the threats associated to online dating scams, and can help researchers and practitioners in developing effective countermeasures to fight them.",http://dx.doi.org/10.1007/978-3-319-20550-2_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-22668-2_20,What Users Prefer and Why: A User Study on Effective Presentation Styles of Opinion Summarization,Human-Computer Interaction – INTERACT 2015,10.1007/978-3-319-22668-2_20,Springer,2015-01-01,"Opinion Summarization research addresses how to help people in making appropriate decisions in an effective way. This paper aims to help users in their decision-making by providing them effective opinion presentation styles. We carried out two phases of experiments to systematically compare usefulness of different types of opinion summarization techniques. In the first crowd-sourced study, we recruited 46 turkers to generate high quality summary information. This first phase generated four styles of summaries: Tag Clouds, Aspect Oriented Sentiments, Paragraph Summary and Group Sample. In the follow-up second phase, 34 participants tested the four styles in a card sorting experiment. Each participant was given 32 cards with 8 per presentation styles and completed the task of grouping the cards into five categories in terms of the usefulness of the cards. Results indicated that participants preferred Aspect Oriented Sentiments the most and Tag cloud the least. Implications and hypotheses are discussed.",http://dx.doi.org/10.1007/978-3-319-22668-2_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-81-322-2494-5_6,Big Data Service Agreement,Big Data,10.1007/978-81-322-2494-5_6,Springer,2015-01-01,"World today having several services on Web generates high volume of data around, so much so that one cannot just afford to ignore. These data volumes together usually referred as big data, though look heterogeneous and unrelated at a glance; still, big data carry striking relations among them implicitly as well as explicitly, so that many users across the world may get interested of data patterns being generated at a far end of the world. Thus, there is a need to deliver big data available on cyberspace to users as per their needs. This brings in a notion of big data service. For such service, we here propose a cyber infrastructure that takes user’s data request and finds an appropriate data service provider to deliver data. We also propose an approach for SLA: service level agreement specification. SLA for a service is derived from SLAs of data consumer and provider on negotiation. Matching of consumer’s SLA to that of a provider SLA and a process of negotiation between these two are illustrated.",http://dx.doi.org/10.1007/978-81-322-2494-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-25594-1_12,Determining a Discrete Set of Site-Constrained Privacy Options for Users in Social Networks Through Stackelberg Games,Decision and Game Theory for Security,10.1007/978-3-319-25594-1_12,Springer,2015-01-01,"The privacy policies of an online social network play an important role in determining user involvement and satisfaction, and in turn site profit and success. In this paper, we develop a game theoretic framework to model the relationship between the set of privacy options offered by a social network site and the sharing decisions of its users within these constraints. We model the site and the users in this scenario as the leader and followers, respectively, in a Stackelberg game. We formally establish the conditions under which this game reaches a Nash equilibrium in pure strategies and provide an approximation algorithm for the site to determine a discrete set of privacy options to maximize payoff. We validate hypotheses in our model on data collected from a mock-social network of users’ privacy preferences both within and outside the context of peer influence, and demonstrate that the qualitative assumptions of our model are well-founded.",http://dx.doi.org/10.1007/978-3-319-25594-1_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-26362-5_6,Demystifying the IP Blackspace,"Research in Attacks, Intrusions, and Defenses",10.1007/978-3-319-26362-5_6,Springer,2015-01-01,"A small part of the IPv4 address space has still not been assigned for use to any organization. However, some of this IP space is announced through BGP, and is, therefore, globally reachable. These prefixes which are a subset of the bogon prefixes, constitute what we call the blackspace .It is generally admitted that the blackspace stands to be abused by anybody who wishes to carry out borderline and/or illegal activities without being traced. The contribution of this paper is twofold. First, we propose a novel methodology to accurately identify the IP blackspace. Based on data collected over a period of seven months, we study the routing-level characteristics of these networks and identify some benign reasons why these networks are announced on the Internet. Second, we focus on the security threat associated with these networks by looking at their application-level footprint. We identify live IP addresses and leverage them to fingerprint services running in these networks. Using this data we uncover a large amount of spam and scam activities. Finally, we present a case study of confirmed fraudulent routing of IP blackspace.",http://dx.doi.org/10.1007/978-3-319-26362-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1057/9781137376183_4,Founders,The Business of Sharing,10.1057/9781137376183_4,Springer,2015-01-01,"Just a few years after the greatest downturn since the Great Depression, it felt like the economy was healthier than ever. At least in some places. I was perched on a stool in a sleek, candle-lit San Francisco bar surrounded by 30-somethings drinking wine at $15 a glass. I was there to meet ShelbyClark, the founder of RelayRides. The last time we had met, he had pulled up in a bright yellow convertible. This time, Clark went one better. He strolled into the bar in a flared orange suit, holding aloft a giant disco ball. With his handlebar moustache immaculately curled above his huge and infectious smile, Clark explained that he had just come from RelayRides’ Halloween party.",http://dx.doi.org/10.1057/9781137376183_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10639-012-9245-5,Personalized recommendation of learning material using sequential pattern mining and attribute based collaborative filtering,Education and Information Technologies,10.1007/s10639-012-9245-5,Springer,2014-12-01,"Material recommender system is a significant part of e-learning systems for personalization and recommendation of appropriate materials to learners. However, in the existing recommendation algorithms, dynamic interests and multi-preference of learners and multidimensional-attribute of materials are not fully considered simultaneously. Moreover, these algorithms cannot effectively use the learner’s historical sequential patterns of material accessing in recommendation. For addressing these problems and improving the accuracy and quality of recommendation, a new material recommender system framework based on sequential pattern mining and multidimensional attribute-based collaborative filtering (CF) is proposed. In the sequential pattern based approach, modified Apriori and PrefixSpan algorithms are implemented to discover latent patterns in accessing of materials and use them for recommendation. Leaner Preference Tree (LPT) is introduced to take into account multidimensional-attribute of materials, and learners’ rating and model dynamic and multi-preference of learners in the multidimensional attribute-based CF approach. Finally, the recommendation results of two approaches are combined using cascade, weighted and mixed methods. The proposed method outperforms the previous algorithms on the classification accuracy measures and the learner’s real learning preference can be satisfied accurately according to the real-time up dated contextual information.",http://dx.doi.org/10.1007/s10639-012-9245-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-013-0251-3,Automatic extraction of persistent topics from social text streams,World Wide Web,10.1007/s11280-013-0251-3,Springer,2014-11-01,"Microblogging services allow users to publish their thoughts, activities, and interests in the form of text streams and to share them with others in a social network. A user’s text stream in a microblogging service is temporally composed of the posts the user has written or republished from other socially connected users. In this context, most research on the microblogging service has primarily focused on social graph or topic extraction from the text streams, and in particular, several studies attempted to discover user’s topics of interests from a text stream since the topics play a crucial role in user search, friend recommendation, and contextual advertisement. Yet, they did not yet fully address unique properties of the stream. In this paper, we study a problem of detecting the topics of long-term steady interests to a user from a text stream, considering its dynamic and social characteristics, and propose a graph-based topic extraction model. Extensive experiments have been carried out to investigate the effects of the proposed approach by using a real-world dataset, and the proposed model is shown to produce better performance than the existing alternatives.",http://dx.doi.org/10.1007/s11280-013-0251-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10766-013-0272-7,Parallel Programming Paradigms and Frameworks in Big Data Era,International Journal of Parallel Programming,10.1007/s10766-013-0272-7,Springer,2014-10-01,"With Cloud Computing emerging as a promising new approach for ad-hoc parallel data processing, major companies have started to integrate frameworks for parallel data processing in their product portfolio, making it easy for customers to access these services and to deploy their programs. We have entered the Era of Big Data. The explosion and profusion of available data in a wide range of application domains rise up new challenges and opportunities in a plethora of disciplines—ranging from science and engineering to biology and business. One major challenge is how to take advantage of the unprecedented scale of data—typically of heterogeneous nature—in order to acquire further insights and knowledge for improving the quality of the offered services. To exploit this new resource, we need to scale up and scale out both our infrastructures and standard techniques. Our society is already data-rich, but the question remains whether or not we have the conceptual tools to handle it. In this paper we discuss and analyze opportunities and challenges for efficient parallel data processing. Big Data is the next frontier for innovation, competition, and productivity, and many solutions continue to appear, partly supported by the considerable enthusiasm around the MapReduce paradigm for large-scale data analysis. We review various parallel and distributed programming paradigms, analyzing how they fit into the Big Data era, and present modern emerging paradigms and frameworks. To better support practitioners interesting in this domain, we end with an analysis of on-going research challenges towards the truly fourth generation data-intensive science.",http://dx.doi.org/10.1007/s10766-013-0272-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-013-9141-8,Personalised viewing-time prediction in museums,User Modeling and User-Adapted Interaction,10.1007/s11257-013-9141-8,Springer,2014-10-01,"People are often overwhelmed by the large amount of information provided in museum spaces, which makes it difficult for them to select exhibits of potential interest. As a first step in recommending exhibits where a visitor may wish to spend some time, this article investigates predictive user models for personalised prediction of museum visitors’ viewing times at exhibits. We consider two content-based models and a nearest-neighbour collaborative filter, and develop a collaborative model based on the theory of spatial processes which relies on a notion of distance between exhibits. We discuss models of exhibit distance derived from viewing-time similarity, semantic similarity and walking distance. The results from our evaluation with a real-world dataset of visitor pathways collected at Melbourne Museum (Melbourne, Australia) suggest that utilising walking and semantic distances between exhibits enables more accurate predictions of a visitor’s viewing times of unseen exhibits than using distances derived from observed exhibit viewing times. Our results also show that all models outperform a non-personalised baseline, that content-based viewing time prediction yields better results than nearest-neighbour collaborative prediction, and that our collaborative model based on spatial processes attains the highest predictive accuracy overall.",http://dx.doi.org/10.1007/s11257-013-9141-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13388-014-0013-5,Security informatics research challenges for mitigating cyber friendly fire,Security Informatics,10.1186/s13388-014-0013-5,Springer,2014-09-25,"This paper addresses cognitive implications and research needs surrounding the problem of cyber friendly fire (FF). We define cyber FF as intentional offensive or defensive cyber/electronic actions intended to protect cyber systems against enemy forces or to attack enemy cyber systems, which unintentionally harms the mission effectiveness of friendly or neutral forces. We describe examples of cyber FF and discuss how it fits within a general conceptual framework for cyber security failures. Because it involves human failure, cyber FF may be considered to belong to a sub-class of cyber security failures characterized as unintentional insider threats. Cyber FF is closely related to combat friendly fire in that maintaining situation awareness (SA) is paramount to avoiding unintended consequences. Cyber SA concerns knowledge of a system’s topology (connectedness and relationships of the nodes in a system), and critical knowledge elements such as the characteristics and vulnerabilities of the components that comprise the system and its nodes, the nature of the activities or work performed, and the available defensive and offensive countermeasures that may be applied to thwart network attacks. We describe a test bed designed to support empirical research on factors affecting cyber FF. Finally, we discuss mitigation strategies to combat cyber FF, including both training concepts and suggestions for decision aids and visualization approaches.",http://dx.doi.org/10.1186/s13388-014-0013-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-013-0320-5,PhishTackle—a web services architecture for anti-phishing,Cluster Computing,10.1007/s10586-013-0320-5,Springer,2014-09-01,"Phishing is web based criminal activity of making innocent online users to reveal sensitive information into fake web sites. Such fake web sites lead to fraudulent charges against individuals and corporations. Phishers have a lot of methods to design and host phished web pages, so in reality there cannot be a single solution that can help us combat phishing. As technology advances, the phishing techniques being used are also getting advanced and hence it demands the anti-phishing techniques also to be upgraded and the new techniques are to be included along with the existing methods. But most of the anti-phishing techniques today do not satisfy these criteria. In this paper, we propose service oriented three-layer architecture model for detecting and identifying phishing web sites as it overcomes the shortcomings of existing anti-phishing solutions. This model enables us to separate the user interface layer from the anti-phishing components layer. This is done through web service middleware layer, which provides us with the freedom of building our own anti-phishing components layer in an efficient and flexible way, independent of other layers. Anti-phishing components layer provides a set of reusable components to convert webpage into feature vectors using finest heuristic methods and external repositories of information. The feature vectors act as an input to trained support vector machine classifier to generate phishing label which determines whether a webpage is legitimate or a phishing page. This when experimented, displayed the significance and importance of three-layered architecture model along with combination of heuristics in detection of phishing webpage. This results in high accuracy of 99 % with less than 1 % of false positive rate.",http://dx.doi.org/10.1007/s10586-013-0320-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-013-9152-0,Better decision support through exploratory discrimination-aware data mining: foundations and empirical evidence,Artificial Intelligence and Law,10.1007/s10506-013-9152-0,Springer,2014-06-01,"Decision makers in banking, insurance or employment mitigate many of their risks by telling “good” individuals and “bad” individuals apart. Laws codify societal understandings of which factors are legitimate grounds for differential treatment (and when and in which contexts)—or are considered unfair discrimination, including gender, ethnicity or age. Discrimination-aware data mining (DADM) implements the hope that information technology supporting the decision process can also keep it free from unjust grounds. However, constraining data mining to exclude a fixed enumeration of potentially discriminatory features is insufficient. We argue for complementing it with exploratory DADM, where discriminatory patterns are discovered and flagged rather than suppressed. This article discusses the relative merits of constraint-oriented and exploratory DADM from a conceptual viewpoint. In addition, we consider the case of loan applications to empirically assess the fitness of both discrimination-aware data mining approaches for two of their typical usage scenarios: prevention and detection. Using Mechanical Turk, 215 US-based participants were randomly placed in the roles of a bank clerk (discrimination prevention) or a citizen / policy advisor (detection). They were tasked to recommend or predict the approval or denial of a loan, across three experimental conditions: discrimination-unaware data mining, exploratory, and constraint-oriented DADM (eDADM resp. cDADM). The discrimination-aware tool support in the eDADM and cDADM treatments led to significantly higher proportions of correct decisions, which were also motivated more accurately. There is significant evidence that the relative advantage of discrimination-aware techniques depends on their intended usage. For users focussed on making and motivating their decisions in non-discriminatory ways, cDADM resulted in more accurate and less discriminatory results than eDADM. For users focussed on monitoring for preventing discriminatory decisions and motivating these conclusions, eDADM yielded more accurate results than cDADM.",http://dx.doi.org/10.1007/s10506-013-9152-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10207-013-0214-9,Risk balance defense approach against intrusions for network server,International Journal of Information Security,10.1007/s10207-013-0214-9,Springer,2014-06-01,"The paper presents a new defense approach based on risk balance to protect network servers from intrusion activities. We construct and implement a risk balance system, which consists of three modules, including a comprehensive alert processing module, an online risk assessment module, and a risk balance response decision-making module. The alert processing module improves the information quality of intrusion detection system (IDS) raw alerts by reducing false alerts rate, forming alert threads, and computing general parameters from the alert threads. The risk assessment module provides accurate evaluation of risks accordingly to alert threads. Based on the risk assessment, the response decision-making module is able to make right response decisions and perform very well in terms of noise immunization. Having advantages over conventional intrusion response systems, the risk balancer protects network servers not by directly blocking intrusion activities but by redirecting related network traffics and changing service platform. In this way, the system configurations that favor attackers are changed, and attacks are stopped with little impact on services to users. Therefore, the proposed risk balance approach is a good solution to not only the trade-off between the effectiveness and the negative effects of responses but also the false response problems caused by both IDS false-positive alerts and duplicated alerts.",http://dx.doi.org/10.1007/s10207-013-0214-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-013-0503-z,Modeling the user state for context-aware spoken interaction in ambient assisted living,Applied Intelligence,10.1007/s10489-013-0503-z,Springer,2014-06-01,"Ambient Assisted Living (AAL) systems must provide adapted services easily accessible by a wide variety of users. This can only be possible if the communication between the user and the system is carried out through an interface that is simple, rapid, effective, and robust. Natural language interfaces such as dialog systems fulfill these requisites, as they are based on a spoken conversation that resembles human communication. In this paper, we enhance systems interacting in AAL domains by means of incorporating context-aware conversational agents that consider the external context of the interaction and predict the user’s state. The user’s state is built on the basis of their emotional state and intention, and it is recognized by means of a module conceived as an intermediate phase between natural language understanding and dialog management in the architecture of the conversational agent. This prediction, carried out for each user turn in the dialog, makes it possible to adapt the system dynamically to the user’s needs. We have evaluated our proposal developing a context-aware system adapted to patients suffering from chronic pulmonary diseases, and provide a detailed discussion of the positive influence of our proposal in the success of the interaction, the information and services provided, as well as the perceived quality.",http://dx.doi.org/10.1007/s10489-013-0503-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-013-0365-6,"
              PRESC
              
                
                  
                
                $$^{2}$$
                
                  
                    
                      
                      2
                    
                  
                
              : efficient self-reconfiguration of cache strategies for elastic caching platforms",Computing,10.1007/s00607-013-0365-6,Springer,2014-05-01,"Elastic caching platforms (ECPs) play an important role in accelerating the performance of Web applications. Several cache strategies have been proposed for ECPs to manage data access and distributions while maintaining the service availability. In our earlier research, we have demonstrated that there is no “one-fits-all” strategy for heterogeneous scenarios and the selection of the optimal strategy is related with workload patterns, cluster size and the number of concurrent users. In this paper, we present a new reconfiguration framework named PRESC $$^{2}$$ 2 . It applies machine learning approaches to determine an optimal cache strategy and supports online optimization of performance model through trace-driven simulation or semi-supervised classification. Besides, the authors also propose a robust cache entries synchronization algorithm and a new optimization mechanism to further lower the adaptation costs. In our experiments, we find that PRESC $$^{2}$$ 2 improves the elasticity of ECPs and brings big performance gains when compared with static configurations.",http://dx.doi.org/10.1007/s00607-013-0365-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11036-013-0489-0,Big Data: A Survey,Mobile Networks and Applications,10.1007/s11036-013-0489-0,Springer,2014-04-01,"In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop. We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aim to provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.",http://dx.doi.org/10.1007/s11036-013-0489-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-013-0351-z,Ubiquitous recommender systems,Computing,10.1007/s00607-013-0351-z,Springer,2014-03-01,"Ubiquitous recommender systems combine characteristics from ubiquitous systems and recommender systems in order to provide personalized recommendations to users in ubiquitous environments. Although not a new research area, ubiquitous recommender systems research has not yet been reviewed and classified in terms of ubiquitous research and recommender systems research, in order to deeply comprehend its nature, characteristics, relevant issues and challenges. It is our belief that ubiquitous recommenders can nowadays take advantage of the progress mobile phone technology has made in identifying items around, as well as utilize the faster wireless connections and the endless capabilities of modern mobile devices in order to provide users with more personalized and context-aware recommendations on location to aid them with their task at hand. This work focuses on ubiquitous recommender systems, while a brief analysis of the two fundamental areas from which they emerged, ubiquitous computing and recommender systems research is also conducted. Related work is provided, followed by a classification schema and a discussion about the correlation of ubiquitous recommenders with classic ubiquitous systems and recommender systems: similarities inevitably exist, however their fundamental differences are crucial. The paper concludes by proposing UbiCARS: a new class of ubiquitous recommender systems that will combine characteristics from ubiquitous systems and context-aware recommender systems in order to utilize multidimensional context modeling techniques not previously met in ubiquitous recommender systems.",http://dx.doi.org/10.1007/s00607-013-0351-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-012-9136-x,Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols,User Modeling and User-Adapted Interaction,10.1007/s11257-012-9136-x,Springer,2014-02-01,"Exploiting temporal context has been proved to be an effective approach to improve recommendation performance, as shown, e.g. in the Netflix Prize competition. Time-aware recommender systems (TARS) are indeed receiving increasing attention. A wide range of approaches dealing with the time dimension in user modeling and recommendation strategies have been proposed. In the literature, however, reported results and conclusions about how to incorporate and exploit time information within the recommendation processes seem to be contradictory in some cases. Aiming to clarify and address existing discrepancies, in this paper we present a comprehensive survey and analysis of the state of the art on TARS. The analysis show that meaningful divergences appear in the evaluation protocols used—metrics and methodologies. We identify a number of key conditions on offline evaluation of TARS, and based on these conditions, we provide a comprehensive classification of evaluation protocols for TARS. Moreover, we propose a methodological description framework aimed to make the evaluation process fair and reproducible. We also present an empirical study on the impact of different evaluation protocols on measuring relative performances of well-known TARS. The results obtained show that different uses of the above evaluation conditions yield to remarkably distinct performance and relative ranking values of the recommendation approaches. They reveal the need of clearly stating the evaluation conditions used to ensure comparability and reproducibility of reported results. From our analysis and experiments, we finally conclude with methodological issues a robust evaluation of TARS should take into consideration. Furthermore we provide a number of general guidelines to select proper conditions for evaluating particular TARS.",http://dx.doi.org/10.1007/s11257-012-9136-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13218-013-0285-9,Interview with Peter Stone and Matthew E. Taylor,KI - Künstliche Intelligenz,10.1007/s13218-013-0285-9,Springer,2014-02-01,,http://dx.doi.org/10.1007/s13218-013-0285-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-012-9137-9,Experimental evaluation of context-dependent collaborative filtering using item splitting,User Modeling and User-Adapted Interaction,10.1007/s11257-012-9137-9,Springer,2014-02-01,"Collaborative Filtering (CF) computes recommendations by leveraging a historical data set of users’ ratings for items. CF assumes that the users’ recorded ratings can help in predicting their future ratings. This has been validated extensively, but in some domains the user’s ratings can be influenced by contextual conditions, such as the time, or the goal of the item consumption. This type of contextual information is not exploited by standard CF models. This paper introduces and analyzes a novel technique for context-aware CF called Item Splitting. In this approach items experienced in two alternative contextual conditions are “split” into two items. This means that the ratings of a split item, e.g., a place to visit, are assigned (split) to two new fictitious items representing for instance the place in summer and the same place in winter. This split is performed only if there is statistical evidence that under these two contextual conditions the items ratings are different; for instance, a place may be rated higher in summer than in winter. These two new fictitious items are then used, together with the unaffected items, in the rating prediction algorithm. When the system must predict the rating for that “split” item in a particular contextual condition (e.g., in summer), it will consider the new fictitious item representing the original one in that particular contextual condition, and will predict its rating. We evaluated this approach on real world, and semi-synthetic data sets using matrix factorization, and nearest neighbor CF algorithms. We show that Item Splitting can be beneficial and its performance depends on the method used to determine which items to split. We also show that the benefit of the method is determined by the relevance of the contextual factors that are used to split.",http://dx.doi.org/10.1007/s11257-012-9137-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12599-013-0303-3,Information Systems for “Wicked Problems”,Business & Information Systems Engineering,10.1007/s12599-013-0303-3,Springer,2014-02-01,"The objective of this commentary is to propose fruitful research directions built upon the reciprocal interplay of social media and collective intelligence. We focus on “wicked problems” – a class of problems that Introne et al. (Künstl. Intell. 27:45–52, 2013 ) call “problems for which no single computational formulation of the problem is sufficient, for which different stakeholders do not even agree on what the problem really is, and for which there are no right or wrong answers, only answers that are better or worse from different points of view”. We argue that information systems research in particular can aid in designing appropriate systems due to benefits derived from the combined perspectives of both social media and collective intelligence. We document the relevance and timeliness of social media and collective intelligence for business and information systems engineering, pinpoint needed functionality of information systems for wicked problems, describe related research challenges, highlight prospective suitable methods to tackle those challenges, and review examples of initial results.",http://dx.doi.org/10.1007/s12599-013-0303-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-014-5067-y,Temporal evolution of contacts and communities in networks of face-to-face human interactions,Science China Information Sciences,10.1007/s11432-014-5067-y,Springer,2014-02-01,"Temporal dynamics of social interaction networks as well as the analysis of communities are key aspects to gain a better understanding of the involved processes, important influence factors, their effects, and their structural implications. In this article, we analyze temporal dynamics of contacts and the evolution of communities in networks of face-to-face proximity. As our application context, we consider four scientific conferences. On a structural level, we focus on static and dynamic properties of the contact graphs. Also, we analyze the resulting community structure using state-of-the-art automatic community detection algorithms. Specifically, we analyze the evolution of contacts and communities over time to consider the stability of the respective communities. Furthermore, we assess different factors which have an influence on the quality of community prediction. Overall, we provide first important insights into the evolution of contacts and communities in face-to-face contact networks.",http://dx.doi.org/10.1007/s11432-014-5067-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08245-5_6,Ensuring Web Interface Quality through Usability-Based Split Testing,Web Engineering,10.1007/978-3-319-08245-5_6,Springer,2014-01-01,"Usability is a crucial quality aspect of web applications, as it guarantees customer satisfaction and loyalty. Yet, effective approaches to usability evaluation are only applied at very slow iteration cycles in today’s industry. In contrast, conversion-based split testing seems more attractive to e-commerce companies due to its more efficient and easy-to-deploy nature. We introduce Usability-based Split Testing as an alternative to the above approaches for ensuring web interface quality, along with a corresponding tool called WaPPU . By design, our novel method yields better effectiveness than using conversions at higher efficiency than traditional evaluation methods. To achieve this, we build upon the concept of split testing but leverage user interactions for deriving quantitative metrics of usability. From these interactions, we can also learn models for predicting usability in the absence of explicit user feedback. We have applied our approach in a split test of a real-world search engine interface. Results show that we are able to effectively detect even subtle differences in usability. Moreover, WaPPU can learn usability models of reasonable prediction quality, from which we also derived interaction-based heuristics that can be instantly applied to search engine results pages.",http://dx.doi.org/10.1007/978-3-319-08245-5_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-40837-3_3,"Spatio-temporal Data Mining for Climate Data: Advances, Challenges, and Opportunities",Data Mining and Knowledge Discovery for Big Data,10.1007/978-3-642-40837-3_3,Springer,2014-01-01,"Our planet is experiencing simultaneous changes in global population, urbanization, and climate. These changes, along with the rapid growth of climate data and increasing popularity of data mining techniques may lead to the conclusion that the time is ripe for data mining to spur major innovations in climate science. However, climate data bring forth unique challenges that are unfamiliar to the traditional data mining literature, and unless they are addressed, data mining will not have the same powerful impact that it has had on fields such as biology or e-commerce. In this chapter, we refer to spatio-temporal data mining (STDM) as a collection of methods that mine the data’s spatio-temporal context to increase an algorithm’s accuracy, scalability, or interpretability (relative to non-space-time aware algorithms).We highlight some of the singular characteristics and challenges STDM faces within climate data and their applications, and provide the reader with an overview of the advances in STDM and related climate applications. We also demonstrate some of the concepts introduced in the chapter’s earlier sections with a real-world STDM pattern mining application to identify mesoscale ocean eddies from satellite data. The case-study provides the reader with concrete examples of challenges faced when mining climate data and how effectively analyzing the data’s spatio-temporal context may improve existing methods’ accuracy, interpretability, and scalability. We end the chapter with a discussion of notable opportunities for STDM research within climate.",http://dx.doi.org/10.1007/978-3-642-40837-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-45135-5_11,Benchmarking,Recommendation Systems in Software Engineering,10.1007/978-3-642-45135-5_11,Springer,2014-01-01,"This chapter describes the concepts involved in the process of benchmarking of recommendation systems. Benchmarking of recommendation systems is used to ensure the quality of a research system or production system in comparison to other systems, whether algorithmically, infrastructurally, or according to any sought-after quality. Specifically, the chapter presents evaluation of recommendation systems according to recommendation accuracy, technical constraints, and business values in the context of a multi-dimensional benchmarking and evaluation model encompassing any number of qualities into a final comparable metric. The focus is put on quality measures related to recommendation accuracy, technical factors, and business values. The chapter first introduces concepts related to evaluation and benchmarking of recommendation systems, continues with an overview of the current state of the art, then presents the multi-dimensional approach in detail. The chapter concludes with a brief discussion of the introduced concepts and a summary.",http://dx.doi.org/10.1007/978-3-642-45135-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10491-1_14,Modelling User Preferences from Implicit Preference Indicators via Compensational Aggregations,E-Commerce and Web Technologies,10.1007/978-3-319-10491-1_14,Springer,2014-01-01,"In our work, we focus on recommending for small or medium-sized e-commerce portals. Due to high competition, users of these portals lack loyalty and e.g. refuse to register or provide any/enough explicit feedback. Furthermore, products such as tours, cars or furniture have very low average consumption rate preventing us from tracking unregistered user between two consecutive purchases. Recommending on such domains proves to be very challenging, yet interesting research task. We will introduce new method for learning user preferences based on their implicit feedback. The method is based on aggregating various types of implicit feedback with parameterized fuzzy T-norms and S-norms. We have conducted several off-line experiments with real user data from travel agency confirming competitiveness of our method, however further optimizing and on-line experiments should be conducted in the future work.",http://dx.doi.org/10.1007/978-3-319-10491-1_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-13257-0_30,transAD: An Anomaly Detection Network Intrusion Sensor for the Web,Information Security,10.1007/978-3-319-13257-0_30,Springer,2014-01-01,"Content-based Anomaly Detection (AD) techniques are regarded as a promising mechanism to detect ‘zero-day’ attacks. AD sensors have also been shown to perform better than signature-based systems in detecting polymorphic attacks. However, the False Positive Rates (FPRs) produced by current AD sensors have been a cause of concern. In this paper, we introduce and evaluate transAD, a system of network traffic inspection AD sensors that are based on Transductive Confidence Machines (TCM). Existing TCM-based implementations have very high FPRs when used as NIDS. Our approach leverages an unsupervised machine-learning algorithm to identify anomalous packets and thus, unlike most AD sensors, transAD does not require manually labeled data. Moreover, transAD uses an ensemble of TCM sensors to achieve better detection rates and lower FPRs than single sensor implementations. Therefore, transAD presents a hardened defense against poisoning attacks. We evaluated our prototype implementation using two real-world data sets collected from a public university’s network. TransAD processed approximately 1.1 million packets containing real attacks. To compute the ground truth, we manually labeled 18,500 alerts. In the course of scanning millions of packets, our sensor’s low FPR would significantly reduce the number of false alerts that need to be inspected by an operator, while maintaining a high detection rate.",http://dx.doi.org/10.1007/978-3-319-13257-0_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-11071-4_9,An Accurate Flood Forecasting Model Using Wireless Sensor Networks and Chaos Theory: A Case Study with Real WSN Deployment in Brazil,Engineering Applications of Neural Networks,10.1007/978-3-319-11071-4_9,Springer,2014-01-01,"Monitoring natural environments is a challenging task on account of their hostile features. The use of wireless sensor networks (WSN) for data collection is a viable method since these domains lack any infrastructure. Further studies are required to handle the data collected to provide a better modeling of behavior and make it possible to forecast impending disasters. These factors have led to this paper which conducts an analysis of the use of data gathered from urban rivers to forecast future flooding with a view to reducing the damage they cause. The data were collected by means of a WSN in São Carlos, São Paulo State, Brazil and were handled by employing the Immersion Theorem. The WSN were deployed by our group in the city of São Carlos due to numerous problems with floods. After discovering the data interdependence, artificial neural networks were employed to establish more accurate forecasting models.",http://dx.doi.org/10.1007/978-3-319-11071-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-38736-4_5,"The COLIBRI Platform: Tools, Features and Working Examples",Successful Case-based Reasoning Applications-2,10.1007/978-3-642-38736-4_5,Springer,2014-01-01,"COLIBRI is an open source platform for the development of Case-based reasoning (CBR) systems. It supports the development of different families of specialized CBR systems: from Textual CBR to Knowledge Intensive applications. This chapter provides a functional description of the platform, its capabilities and tools. These features are illustrated with real examples of working systems that have been developed using COLIBRI. This overview should serve to motivate and guide those readers that plan to develop CBR systems and are looking for a tool that eases this task.",http://dx.doi.org/10.1007/978-3-642-38736-4_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07626-3_36,A Visual Programming Approach to Big Data Analytics,"Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments",10.1007/978-3-319-07626-3_36,Springer,2014-01-01,"Data processing and analysis has become a major task in a lot of application domains. Most tools for defining analytical processes lack a user oriented interface – especially when it comes to Big Data analytics. In this work we propose an abstraction layer for process design that enables domain experts to define their processes at an abstract level that matches their expertise. Based on that, we investigate the use of machine learning to provide gesture recognition on input devices like tablets to provide these experts with a intuitive environment for process design.",http://dx.doi.org/10.1007/978-3-319-07626-3_36,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-06245-7_6,Big Data Applications,Big Data,10.1007/978-3-319-06245-7_6,Springer,2014-01-01,"In the previous chapter, we examined big data analysis, which is the final and most important phase of the value chain of big data. Big data analysis can provide useful values via judgments, recommendations, supports, or decisions. However, data analysis involves a wide range of applications, which frequently change and are extremely complex. In this chapter, the evolution of data sources is reviewed. Then, six of the most important data analysis fields are examined, including structured data analysis, text analysis, website analysis, multimedia analysis, network analysis, and mobile analysis. This chapter is concluded with a discussion of several key application fields of big data.",http://dx.doi.org/10.1007/978-3-319-06245-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08509-8_12,Quantifiable Run-Time Kernel Attack Surface Reduction,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-08509-8_12,Springer,2014-01-01,"The sheer size of commodity operating system kernels makes them a prime target for local attackers aiming to escalate privileges. At the same time, as much as 90% of kernel functions are not required for processing system calls originating from a typical network daemon. This results in an unnecessarily high exposure. In this paper, we introduce kRazor, an approach to reduce the kernel’s attack surface by limiting the amount of kernel code accessible to an application. kRazor first traces individual kernel functions used by an application. kRazor can then detect and prevent uses of unnecessary kernel functions by a process. This step is implemented as a kernel module that instruments select kernel functions. A heuristic on the kernel function selection allows kRazor to have negligible performance overhead. We evaluate results under real-world workloads for four typical server applications. Results show that the performance overhead and false positives remain low, while the attack surface reduction can be as high as 80%.",http://dx.doi.org/10.1007/978-3-319-08509-8_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08509-8_7,AV-Meter: An Evaluation of Antivirus Scans and Labels,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-319-08509-8_7,Springer,2014-01-01,"Antivirus scanners are designed to detect malware and, to a lesser extent, to label detections based on a family association. The labeling provided by AV vendors has many applications such as guiding efforts of disinfection and countermeasures, intelligence gathering, and attack attribution, among others. Furthermore, researchers rely on AV labels to establish a baseline of ground truth to compare their detection and classification algorithms. This is done despite many papers pointing out the subtle problem of relying on AV labels. However, the literature lacks any systematic study on validating the performance of antivirus scanners, and the reliability of those labels or detection. In this paper, we set out to answer several questions concerning the detection rate, correctness of labels, and consistency of detection of AV scanners. Equipped with more than 12,000 malware samples of 11 malware families that are manually inspected and labeled, we pose the following questions. How do antivirus vendors perform relatively on them? How correct are the labels given by those vendors? How consistent are antivirus vendors among each other? We answer those questions unveiling many interesting results, and invite the community to challenge assumptions about relying on antivirus scans and labels as a ground truth for malware analysis and classification. Finally, we stress several research directions that may help addressing the problem.",http://dx.doi.org/10.1007/978-3-319-08509-8_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-06245-7_3,Big Data Generation and Acquisition,Big Data,10.1007/978-3-319-06245-7_3,Springer,2014-01-01,"We have introduced several key technologies related to big data, i.e., cloud computing, IoT, data center, and Hadoop. Next, we will focus on the value chain of big data, which can be generally divided into four phases: data generation, data acquisition, data storage, and data analysis. If we take data as a raw material, data generation and data acquisition are exploitation process, data storage is a storage process, and data analysis is a production process that utilizes the raw material to create new value.",http://dx.doi.org/10.1007/978-3-319-06245-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10596-3_11,BDGS: A Scalable Big Data Generator Suite in Big Data Benchmarking,Advancing Big Data Benchmarks,10.1007/978-3-319-10596-3_11,Springer,2014-01-01,"Data generation is a key issue in big data benchmarking that aims to generate application-specific data sets to meet the 4 V requirements of big data. Specifically, big data generators need to generate scalable data (Volume) of different types (Variety) under controllable generation rates (Velocity) while keeping the important characteristics of raw data (Veracity). This gives rise to various new challenges about how we design generators efficiently and successfully. To date, most existing techniques can only generate limited types of data and support specific big data systems such as Hadoop. Hence we develop a tool, called Big Data Generator Suite (BDGS), to efficiently generate scalable big data while employing data models derived from real data to preserve data veracity. The effectiveness of BDGS is demonstrated by developing six data generators covering three representative data types (structured, semi-structured and unstructured) and three data sources (text, graph, and table data).",http://dx.doi.org/10.1007/978-3-319-10596-3_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-03949-7_2,Literature Review,A Defeasible Logic Programming-Based Framework to Support Argumentation in Semantic Web Applications,10.1007/978-3-319-03949-7_2,Springer,2014-01-01,"In this chapter, a comprehensive review of the literature, focusing on two important aspects of the research problem, is presented.",http://dx.doi.org/10.1007/978-3-319-03949-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-44509-9_3,On Stigmergically Controlling a Population of Heterogeneous Mobile Agents Using Cloning Resource,Transactions on Computational Collective Intelligence XIV,10.1007/978-3-662-44509-9_3,Springer,2014-01-01,"Cloning can greatly enhance the performance of networked systems that make use of mobile agents to patrol or service the nodes within. Uncontrolled cloning can however lead to generation of a large number of such agents which may affect the network performance adversely. Several attempts to control a population of homogeneous agents and their clones have been made. This paper describes an on-demand population control mechanism for a heterogeneous set of mobile agents along with an underlying application for their deployment as service providers in a networked robotic system. The mobile agents stigmergically sense and estimate the network conditions from within a node and control their own cloning rates. These agents also use a novel concept called the Cloning Resource which controls their cloning behaviour. The results, obtained from both simulation and emulation presented herein, portray the effectiveness of deploying this mechanism in both static and dynamic networks.",http://dx.doi.org/10.1007/978-3-662-44509-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-10596-3_7,"HcBench: Methodology, Development, and Full-System Characterization of a Customer Usage Representative Big Data/Hadoop Benchmark",Advancing Big Data Benchmarks,10.1007/978-3-319-10596-3_7,Springer,2014-01-01,"The Hadoop platform for Map-Reduce is extensively for Big Data batch analytics as well as interactive applications in e-commerce, telecom, media, retail, social networking, and other areas. However, to date no industry standard benchmarks exist to evaluate the true performance of a Hadoop cluster. Current Hadoop benchmarks such as HiBench, Terasort, etc. in the open source domain fail to capture the real usages and performance of a Hadoop cluster in a datacenter. Given that typical Hadoop deployments process jobs under strict Service Level Agreement requirements, benchmarks are needed to evaluate the effects of concurrently running such diverse analytics jobs for performance comparison and cluster configuration. In this paper, we present the methodology and the development of a customer usage representative Hadoop benchmark which includes a mix of job types, variety of data sizes, with inter-job arrival times as in a typical datacenter. We present the details of this benchmark and discuss application level, micro-architectural and cluster level performance characterization on an Intel Sandy Bridge Xeon Processor Hadoop cluster.",http://dx.doi.org/10.1007/978-3-319-10596-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-13021-7_1,On Big Data Benchmarking,"Big Data Benchmarks, Performance Optimization, and Emerging Hardware",10.1007/978-3-319-13021-7_1,Springer,2014-01-01,"Big data systems address the challenges of capturing, storing, managing, analyzing, and visualizing big data. Within this context, developing benchmarks to evaluate and compare big data systems has become an active topic for both research and industry communities. To date, most of the state-of-the-art big data benchmarks are designed for specific types of systems. Based on our experience, however, we argue that considering the complexity, diversity, and rapid evolution of big data systems, for the sake of fairness, big data benchmarks must include diversity of data and workloads. Given this motivation, in this paper, we first propose the key requirements and challenges in developing big data benchmarks from the perspectives of generating data with 4 V properties (i.e. volume, velocity, variety and veracity) of big data, as well as generating tests with comprehensive workloads for big data systems. We then present the methodology on big data benchmarking designed to address these challenges. Next, the state-of-the-art are summarized and compared, following by our vision for future research directions.",http://dx.doi.org/10.1007/978-3-319-13021-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02343-9_3,Major Themes in UPS Academic Research,Usable Security,10.1007/978-3-031-02343-9_3,Springer,2014-01-01,"Much of the UPS research of the past decade mirrors that of applied security work in general—tactical responses to specific problems of the day, rather than long-range strategic research. Tactical research is clearly important, as it addresses current needs and often results in immediate gains. However, literature reviews such as this are better suited to focusing on the longer-term strategic trends, as they represent the greatest opportunity for long-term payoff. Therefore we structure this section thematically, rather than chronologically, and some work that was only of tactical importance is left out. For the remainder we attempted to explain: What was the UPS problem, and how did it arise? Who was doing the research? In some cases themes were the result of intensive work by a single group that specialized in that area. In other cases, the theme was the result of a broad community effort. We believe that, in general, the most useful work has resulted from research performed at multiple institutions, although it is not clear whether multiple institutions attacked a problem because of its ripeness, or if a problem ripened as a result of multiple research efforts. Was the problem resolved? If not, why not?",http://dx.doi.org/10.1007/978-3-031-02343-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-13021-7_9,Performance Benefits of DataMPI: A Case Study with BigDataBench,"Big Data Benchmarks, Performance Optimization, and Emerging Hardware",10.1007/978-3-319-13021-7_9,Springer,2014-01-01,"Apache Hadoop and Spark are gaining prominence in Big Data processing and analytics. Both of them are widely deployed in Internet companies. On the other hand, high-performance data analysis requirements are causing academical and industrial communities to adopt state-of-the-art technologies in HPC to solve Big Data problems. Recently, we have proposed a key-value pair based communication library, DataMPI, which is extending MPI to support Hadoop/Spark-like Big Data Computing jobs. In this paper, we use BigDataBench, a Big Data benchmark suite, to do comprehensive studies on performance and resource utilization characterizations of Hadoop, Spark and DataMPI. From our experiments, we observe that the job execution time of DataMPI has up to 57 % and 50 % speedups compared with those of Hadoop and Spark, respectively. Most of the benefits come from the high-efficiency communication mechanisms in DataMPI. We also notice that the resource (CPU, memory, disk and network I/O) utilizations of DataMPI are also more efficient than those of the other two frameworks.",http://dx.doi.org/10.1007/978-3-319-13021-7_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-04447-7_1,Cyberpatterns: Towards a Pattern Oriented Study of Cyberspace,Cyberpatterns,10.1007/978-3-319-04447-7_1,Springer,2014-01-01,"A pattern represents a discernible regularity in the world or in manmade designs. In the prescriptive point of view, a pattern is a template from which instances can be created; while in the descriptive point of view, the elements of a pattern that repeat in a predictable manner can be observed and recognised. Similar to theories in sciences, patterns explain and predict regularities in a subject domain. In a complicated subject domain like cyberspace, there are usually a large number of patterns that each describes and predicts a subset of recurring phenomena, yet these patterns can interact with each other and be interrelated and composed with each other. The pattern-oriented research method studies a subject domain by identifying the patterns, classifying and categorising them, organising them into pattern languages, investigating the interactions between them, devising mechanisms and operations for detecting and predicting their occurrences, and facilitating their instantiations. This chapter illustrates this research methodology through a review of the research on software design patterns as an example of successful application of the methodology. It then discusses its possible applications to the research on cyberpatterns, i.e. patterns in cyberspace. It defines the scope of research, reviews the current state of art and identifies the key research questions.",http://dx.doi.org/10.1007/978-3-319-04447-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-04307-4_6,Digital Work and Collaboration,Trends and Challenges in Digital Business Innovation,10.1007/978-3-319-04307-4_6,Springer,2014-01-01,"The fast evolution of the Information Systems (IS) during the last decade makes it able to cover more areas in business and other fields. One example of these areas is the way that people communicate and collaborate in business environments. In business, the digital or IT collaboration is divided into electronic communication tools, electronic conferencing tools, and collaborative management tools. The previous mentioned systems have evolved tremendously in the last few years in order to improve the way a group of people from the same organization work together in a productive way. Also, Computer-Supported cooperative work (CSCW) is centrally concerned with teamwork, learning, problem solving, knowledge building, task accomplishment and other cognitive achievements by small groups of people. There are many theories useful for framing the cognitive work that groups undertake in CSCW settings, and they may in principle not be reducible to a single theory. This Chapter will look in details into the origin of the digital collaboration, its importance for work environments and its types. Also it will explain the different digital collaboration tools.",http://dx.doi.org/10.1007/978-3-319-04307-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-012-9207-8,Emergence of social networks via direct and indirect reciprocity,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-012-9207-8,Springer,2013-11-01,"Many models of social network formation implicitly assume that network properties are static in steady-state. In contrast, actual social networks are highly dynamic: allegiances and collaborations expire and may or may not be renewed at a later date. Moreover, empirical studies show that human social networks are dynamic at the individual level but static at the global level: individuals’ degree rankings change considerably over time, whereas network-level metrics such as network diameter and clustering coefficient are relatively stable. There have been some attempts to explain these properties of empirical social networks using agent-based models in which agents play social dilemma games with their immediate neighbours, but can also manipulate their network connections to strategic advantage. However, such models cannot straightforwardly account for reciprocal behaviour based on reputation scores (“indirect reciprocity”), which is known to play an important role in many economic interactions. In order to account for indirect reciprocity, we model the network in a bottom-up fashion: the network emerges from the low-level interactions between agents. By so doing we are able to simultaneously account for the effect of both direct reciprocity (e.g. “tit-for-tat”) as well as indirect reciprocity (helping strangers in order to increase one’s reputation). This leads to a strategic equilibrium in the frequencies with which strategies are adopted in the population as a whole, but intermittent cycling over different strategies at the level of individual agents, which in turn gives rise to social networks which are dynamic at the individual level but stable at the network level.",http://dx.doi.org/10.1007/s10458-012-9207-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00291-013-0349-0,A stochastic programming approach to determine robust delivery profiles in area forwarding inbound logistics networks,OR Spectrum,10.1007/s00291-013-0349-0,Springer,2013-11-01,"One technique to coordinate the suppliers’ and the producers’ production plans in a supply chain is the use of delivery profiles, which provide fixed delivery frequencies for all suppliers. The selection of a delivery profile assignment has major effects on the cost efficiency and the robustness of a supply chain and thus should be performed carefully. In this work, we consider planning approaches to select delivery profiles for the case of area forwarding-based inbound logistics networks, which are commonly used in several industries to consolidate supplies in an early stage of transport. We present a two-stage stochastic mixed integer linear programming model to determine robust delivery profile assignments under uncertain and infrequent demands and complex tariff systems. The model is embedded into a solution framework consisting of scenario generation and reduction techniques, a decomposition approach, a genetic algorithm, and a standard MILP solver. On the basis of an industrial case study, we show that our approach is computationally feasible and that the planning solutions obtained by our model outperform both a deterministic approach and the planning methodology prevailing in industrial practice.",http://dx.doi.org/10.1007/s00291-013-0349-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10922-012-9237-1,A Policy-Based Web Service Redundancy Detection in Wireless Sensor Networks,Journal of Network and Systems Management,10.1007/s10922-012-9237-1,Springer,2013-09-01,"Wireless sensor networks ( WSNs ) are attractive for monitoring and gathering physical information (e.g. temperature) via lots of deployed sensors. For the applications in WSNs , Web service is one of the recommended frameworks to publish, invoke, and manage services. However, the standard Web service description language ( WSDL ), defines only the service input and output while ignoring the corresponding input-to-output mapping relationships. This presents a serious challenge in distinguishing services with similar input and output interface. In this paper, we address this challenge by embedding the service policy into the traditional WSDL2.0 schema to describe the input-to-output mapping relationships. The service policy is then transformed into a policy binary tree so that the similarity between different Web services can be quantitatively evaluated. Furthermore, a new service redundancy detection approach is proposed based on this similarity. Finally, the case study and experimental analysis illustrate the applicability and capability of the proposed service redundancy detection approach.",http://dx.doi.org/10.1007/s10922-012-9237-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-012-0087-3,Reputation modelling in Citizen Science for environmental acoustic data analysis,Social Network Analysis and Mining,10.1007/s13278-012-0087-3,Springer,2013-09-01,"Citizen Science projects are initiatives in which members of the general public participate in scientific research projects and perform or manage research-related tasks such as data collection and/or data annotation. Citizen Science is technologically possible and scientifically significant. However, as the gathered information is from the crowd, the data reliability is always hard to manage. Data reliability issues are significant to the domain of Citizen Science due to the quantity and diversity of people and devices involved. Participants may submit low quality, misleading, inaccurate, or even malicious data. Therefore, finding a way to improve the data reliability has become an urgent demand. This study aims to investigate techniques to enhance the reliability of data contributed by general citizens in scientific research projects especially for acoustic sensing projects. In particular, we propose to design a reputation framework to enhance data reliability and also investigate some critical elements that should be aware of during developing and designing new reputation systems.",http://dx.doi.org/10.1007/s13278-012-0087-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1057/jos.2013.12,Simulation-based development and validation of multi-agent systems: AOSE and ABMS approaches,Journal of Simulation,10.1057/jos.2013.12,Springer,2013-08-01,"This paper briefly surveys an emerging research area: the integration of agent-oriented software engineering (AOSE) and agent-based modelling and simulation (ABMS). Both AOSE and ABMS are well-established research areas in the agent-based computing domain. Specifically, this paper provides an overview of the main simulation-based methodologies for developing multi-agent systems (MASs) that describe interesting ABMS application domains where the integration of AOSE and ABMS can benefit MAS development.",http://dx.doi.org/10.1057/jos.2013.12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11704-013-2193-4,An online service-oriented performance profiling tool for cloud computing systems,Frontiers of Computer Science,10.1007/s11704-013-2193-4,Springer,2013-06-01,"The growing scale and complexity of component interactions in cloud computing systems post great challenges for operators to understand the characteristics of system performance. Profiling has long been proved to be an effective approach to performance analysis; however, existing approaches confront new challenges that emerge in cloud computing systems. First, the efficiency of the profiling becomes of critical concern; second, service-oriented profiling should be considered to support separation-of-concerns performance analysis. To address the above issues, in this paper, we present P-Tracer, an online performance profiling tool specifically tailored for cloud computing systems. P-Tracer constructs a specific search engine that proactively processes performance logs and generates a particular index for fast queries; second, for each service, P-Tracer retrieves a statistical insight of performance characteristics from multi-dimensions and provides operators with a suite of web-based interfaces to query the critical information. We evaluate P-Tracer in the aspects of tracing overheads, data preprocessing scalability and querying efficiency. Three real-world case studies that happened in Alibaba cloud computing platform demonstrate that P-Tracer can help operators understand software behaviors and localize the primary causes of performance anomalies effectively and efficiently.",http://dx.doi.org/10.1007/s11704-013-2193-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-011-0064-0,The adARC pattern analysis architecture for adaptive human activity recognition systems,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-011-0064-0,Springer,2013-04-01,"Most approaches to recognize human activities rely on pattern recognition techniques that are trained once at design time, and then remain unchanged during usage. This reflects the assumption that the mapping between sensor signal patterns and activity classes is known at design-time. This cannot be guaranteed in mobile and pervasive computing, where unpredictable changes can often occur in open-ended environments. Run-time adaptation can address these issues. We introduce and formalize a data processing architecture extending current approaches that allows for a wide range of realizations of adaptive activity recognition systems. The adaptive activity recognition chain ( adARC ) includes self-monitoring, adaptation strategies and external feedback as components of the now closed-loop recognition system. We show an adARC capable of unsupervised self-adaptation to run-time changing class distributions. It improves activity recognition accuracy when sensors suffer from on-body displacement. We show an adARC capable of adaptation to changing sensor setups. It allows for scalability by enabling a recognition systems to autonomously exploit newly introduced sensors. We discuss other adaptive recognition systems within the adARC architecture. The results outline that this architecture frames a useful solution space for the real-world deployment of adaptive activity recognition systems. It allows to present and compare recognition systems in a coherent and modular manner. We discuss the challenges and new research directions resulting from this new perspective on adaptive activity recognition.",http://dx.doi.org/10.1007/s12652-011-0064-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-011-0069-8,An intelligent security architecture for distributed firewalling environments,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-011-0069-8,Springer,2013-04-01,"Due to the increasing threat of attacks and malicious activities, the use of firewall technology is an important milestone toward making networks of any complexity and size secure. Unfortunately, the inherent difficulties in designing and managing firewall policies within modern highly distributed, dynamic and heterogeneous environments might greatly limit the effectiveness of firewall security. It is therefore desirable to automate as much as possible the firewall configuration process. Accordingly, this work presents a new more active and scalable firewalling architecture based on dynamic and adaptive policy management facilities, thus enabling the automatic generation of new rules and policies to ensure a timely response in detecting unusual traffic activity as well as identify unknown potential attacks (zero-day). The proposed scheme, with a multi-stage modular structure, can be easily applied to a distributed security environment and does not depend on any specific security solutions or hardware/software packages.",http://dx.doi.org/10.1007/s12652-011-0069-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-011-9114-8,A PLA-based privacy-enhancing user modeling framework and its evaluation,User Modeling and User-Adapted Interaction,10.1007/s11257-011-9114-8,Springer,2013-03-01,"Reconciling personalization with privacy has been a continuing interest in user modeling research. This aim has computational, legal and behavioral/attitudinal ramifications. We present a dynamic privacy-enhancing user modeling framework that supports compliance with users’ individual privacy preferences and with the privacy laws and regulations that apply to each user. The framework is based on a software product line architecture. It dynamically selects personalization methods during runtime that meet the current privacy constraints. Since dynamic architectural reconfiguration is typically resource-intensive, we conducted a performance evaluation with four implementations of our system that vary two factors. The results demonstrate that at least one implementation of our approach is technically feasible with comparatively modest additional resources, even for websites with the highest traffic today. To gauge user reactions to privacy controls that our framework enables, we also conducted a controlled experiment that allowed one group of users to specify privacy preferences and view the resulting effects on employed personalization methods. We found that users in this treatment group utilized this feature, deemed it useful, and had fewer privacy concerns as measured by higher disclosure of their personal data.",http://dx.doi.org/10.1007/s11257-011-9114-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-5301-6_2,Generating Models of Recommendation Processes out of Annotated Ontologies,Semantic Models for Adaptive Interactive Systems,10.1007/978-1-4471-5301-6_2,Springer,2013-01-01,"Creating content- and dialogue-based recommendation processes through manual adaptations requires a lot of time and effort. Therefore, automated generation of such processes is desirable. We present an approach for generating models of recommendation processes out of annotated ontologies. Such product ontologies have to be provided manually, but certain adaptations to them can be discovered from unstructured data (customer-generated content such as blog entries or customer feedback on products in the Web). They are given input for our approach, which applies semantic model-driven transformations to these ontologies for generating discourse-based models of recommendation processes on a high conceptual level first. These generated discourses essentially consist of questions and answers about those items annotated as important in the ontologies, and their possible sequences. From such a high-level model, transformation rules create a model of an operationalized recommendation process. This model also represents a so-called concrete user interface and consists of both the structure of the process and the course of events, which defines how customers may navigate through the process. From such models, an already given infrastructure can generate running processes including their final user interfaces, which have already been deployed successfully for real-world use.",http://dx.doi.org/10.1007/978-1-4471-5301-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-41284-4_15,Deconstructing the Assessment of Anomaly-based Intrusion Detectors,"Research in Attacks, Intrusions, and Defenses",10.1007/978-3-642-41284-4_15,Springer,2013-01-01,"Anomaly detection is a key strategy for cyber intrusion detection because it is conceptually capable of detecting novel attacks. This makes it an appealing defensive technique for environments such as the nation’s critical infrastructure that is currently facing increased cyber adversarial activity. When considering deployment within the purview of such critical infrastructures it is imperative that the technology is well understood and reliable, where its performance is benchmarked on the results of principled assessments. This paper works towards such an imperative by analyzing the current state of anomaly detector assessments with a view toward mission critical deployments. We compile a framework of key evaluation constructs that identify how and where current assessment methods may fall short in providing sufficient insight into detector performance characteristics. Within the context of three case studies from literature, we show how error factors that influence the performance of detectors interact with different phases of a canonical evaluation strategy to compromise the integrity of the final results.",http://dx.doi.org/10.1007/978-3-642-41284-4_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38844-6_3,"What Recommenders Recommend – An Analysis of Accuracy, Popularity, and Sales Diversity Effects","User Modeling, Adaptation, and Personalization",10.1007/978-3-642-38844-6_3,Springer,2013-01-01,"In academic studies, the evaluation of recommender system (RS) algorithms is often limited to offline experimental designs based on historical data sets and metrics from the fields of Machine Learning or Information Retrieval. In real-world settings, however, other business-oriented metrics such as click-through-rates, customer retention or effects on the sales spectrum might be the true evaluation criteria for RS effectiveness. In this paper, we compare different RS algorithms with respect to their tendency of focusing on certain parts of the product spectrum. Our first analysis on different data sets shows that some algorithms – while able to generate highly accurate predictions – concentrate their top 10 recommendations on a very small fraction of the product catalog or have a strong bias to recommending only relatively popular items than others. We see our work as a further step toward multiple-metric offline evaluation and to help service providers make better-informed decisions when looking for a recommendation strategy that is in line with the overall goals of the recommendation service.",http://dx.doi.org/10.1007/978-3-642-38844-6_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-37932-1_11,Context-Aware Advertising in Pervasive Computing Environment,Electronic Business and Marketing,10.1007/978-3-642-37932-1_11,Springer,2013-01-01,"Due to the recent advances in sensing and wireless communication technologies, we have been able to capture and understand real-world phenomena by employing tiny ubiquitous sensors such as accelerometers, thermometers, and RFID tags installed in daily environments. For example, by attaching ubiquitous sensors to various indoor objects and furniture, we can observe their use and phenomena that occur around them. Real world context information obtained from the ubiquitous sensors has triggered a wide range of applications in, for example, context-aware systems, lifelogging, and monitoring. This article describes a new type of context-aware advertising that employs context information obtained by ubiquitous sensors. We also introduce examples of context-aware advertising on our lifelogging and recommender systems.",http://dx.doi.org/10.1007/978-3-642-37932-1_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-45260-4_10,The EternalS Roadmap – Defining a Research Agenda for Eternal Systems,"Trustworthy Eternal Systems via Evolving Software, Data and Knowledge",10.1007/978-3-642-45260-4_10,Springer,2013-01-01,"Science, technology and business are increasingly dependent on software. This trend is driven by increasing system size, complexity, diversity and flexibility and the obligation for tailored integration of end-users, processes and evolving technologies. The complexity scale of current systems exceeds our current understanding of systems engineering and the number of system parameters to be controlled as part of the overall design process exceeds the performance of the associated tools and techniques we are using. This leads to excessive costs for software maintenance and system degradation over its lifetime. The tools and techniques must evolve to take into account this increasing systems, software and architecture scale and complexity. Software intensive systems must be flexible to accommodate a range of requirements and operating conditions, and capable of evolving to allow these parameters to change over time. Software Engineering approaches to reusability and maintenance must cope with the dynamics and longevity of future software applications and infrastructures, e.g., for the Future Internet, e-commerce, e-health, and egovernment. The EternalS project is developing a roadmap for the next two decades to inspire a research agenda for software and systems engineering to help address these issues. This paper presents some of the key issues outlined above, the roadmapping process and some of the key findings to date.",http://dx.doi.org/10.1007/978-3-642-45260-4_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-37300-8_1,Using File Relationships in Malware Classification,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-642-37300-8_1,Springer,2013-01-01,"Typical malware classification methods analyze unknown files in isolation. However, this ignores valuable relationships between malware files, such as containment in a zip archive, dropping, or downloading. We present a new malware classification system based on a graph induced by file relationships, and, as a proof of concept, analyze containment relationships, for which we have much available data. However our methodology is general, relying only on an initial estimate for some of the files in our data and on propagating information along the edges of the graph. It can thus be applied to other types of file relationships. We show that since malicious files are often included in multiple malware containers, the system’s detection accuracy can be significantly improved, particularly at low false positive rates which are the main operating points for automated malware classifiers. For example at a false positive rate of 0.2%, the false negative rate decreases from 42.1% to 15.2%. Finally, the new system is highly scalable; our basic implementation can learn good classifiers from a large, bipartite graph including over 719 thousand containers and 3.4 million files in a total of 16 minutes.",http://dx.doi.org/10.1007/978-3-642-37300-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40203-6_31,Measuring and Detecting Malware Downloads in Live Network Traffic,Computer Security – ESORICS 2013,10.1007/978-3-642-40203-6_31,Springer,2013-01-01,"In this paper, we present AMICO, a novel system for measuring and detecting malware downloads in live web traffic. AMICO learns to distinguish between malware and benign file downloads from the download behavior of the network users themselves. Given a labeled dataset of past benign and malware file downloads, AMICO learns a provenance classifier that can accurately detect future malware downloads based on information about where the downloads originated from. The main intuition is that to avoid current countermeasures, malware campaigns need to use an “agile” distribution infrastructure, e.g., frequently changing the domains and/or IPs of the malware download servers. We engineer a number of statistical features that aim to capture these fundamental characteristics of malware distribution campaigns. We have deployed AMICO at the edge of a large academic network for almost nine months, where we continuously witness hundreds of new malware downloads per week, including many zero-days . We show that AMICO is able to accurately detect malware downloads with up to 90% true positives at a false positives rate of 0.1% and can detect zero-day malware downloads, thus providing an effective way to complement current malware detection tools.",http://dx.doi.org/10.1007/978-3-642-40203-6_31,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-94-007-5583-3_37,A Virtual Selling Agent Which Is Persuasive and Adaptive,Agreement Technologies,10.1007/978-94-007-5583-3_37,Springer,2013-01-01,"In this paper, we claim that the online selling process can be improved if the experience of the customer is closer to that of one in a retailing store. For this purpose, we provide a virtual selling agent that is persuasive and adaptive. Our persuasive selling agent initiates the dialogue and drives it in order to simultaneously advance two processes: customer profiling and the identification of relevant proposals which are supported by arguments. Moreover, our virtual seller is adaptive since she is able to adjust her behaviour and her arguments according to the customer profile.",http://dx.doi.org/10.1007/978-94-007-5583-3_37,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-39314-3_13,Multimedia Search,Web Information Retrieval,10.1007/978-3-642-39314-3_13,Springer,2013-01-01,"The Web is progressively becoming a multimedia content delivery platform. This trend poses severe challenges to the information retrieval theories, techniques, and tools. This chapter defines the problem of multimedia information retrieval with its challenges and application areas, overviews its major technical issues, proposes a reference architecture unifying the aspects of content processing and querying, exemplifies a next-generation platform for multimedia search, and concludes by showing the close ties between multi-domain search and multimodal/multimedia search.",http://dx.doi.org/10.1007/978-3-642-39314-3_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-39314-3_12,Semantic Search,Web Information Retrieval,10.1007/978-3-642-39314-3_12,Springer,2013-01-01,"Semantic search seeks to answer user queries based on meanings rather than keyword matching. For instance, when searching for “museums in Milan”, a traditional search engine would answer with a list of links to Web pages that contain the keywords “museums” and “Milan”. However, a semantic search engine understands the intention of the user to obtain a list of museums and returns Web representations of the required real-world entities, including their semantic properties. This chapter illustrates the process adopted by semantic search engines and uses it to compare alternative semantic search solutions offered on the market as well as academic prototypes.",http://dx.doi.org/10.1007/978-3-642-39314-3_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35890-6_17,Automated Smartphone Security Configuration,Data Privacy Management and Autonomous Spontaneous Security,10.1007/978-3-642-35890-6_17,Springer,2013-01-01,"Smartphones host operating systems that are on a par with modern desktop environments. For example, Google Android is a mobile operating system that is based upon a modified version of the Linux OS. Notwithstanding traditional threats to mobile phones, threats to desktop environments are also applicable to smartphones. Management of security configurations for the end-user has, to date, been complex and error-prone. As a consequence, misconfiguration of and/or a poor understanding of a security configuration may unnecessarily expose a smartphone to known threats. In this paper, a threat-based model for smartphone security configuration is presented. To evaluate the approach, a prototype smartphone security agent that automatically manages security configurations on behalf of the end-user is developed. A case study based on firewall access control demonstrates how automated security configuration recommendations can be made based on catalogues of countermeasures. These countermeasures are drawn from best-practice standards such as NIST 800-124, a guideline on cell phone and PDA security and NIST 800-41-rev1, a guideline on firewall security configuration.",http://dx.doi.org/10.1007/978-3-642-35890-6_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4302-4873-6_1,“Big Data” in the Enterprise,Big Data Imperatives,10.1007/978-1-4302-4873-6_1,Springer,2013-01-01,"Humans have been generating data for thousands of years. More recently we have seen an amazing progression in the amount of data produced from the advent of mainframes to client server to ERP and now everything digital. For years the overwhelming amount of data produced was deemed useless. But data has always been an integral part of every enterprise, big or small. As the importance and value of data to an enterprise became evident, so did the proliferation of data silos within an enterprise. This data was primarily of structured type, standardized and heavily governed (either through enterprise wide programs or through business functions or IT), the typical volumes of data were in the range of few terabytes and in some cases due to compliance and regulation requirements the volumes expectedly went up several notches higher.",http://dx.doi.org/10.1007/978-1-4302-4873-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4302-4873-6_4,Emerging Database Landscape,Big Data Imperatives,10.1007/978-1-4302-4873-6_4,Springer,2013-01-01,"Where do newer technologies such as columnar databases and NoSQL come into play? How will you effectively address the impact of big data on application performance, speed and reliability?",http://dx.doi.org/10.1007/978-1-4302-4873-6_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-6856-1_1,Data Cloudification,Web-Scale Data Management for the Cloud,10.1007/978-1-4614-6856-1_1,Springer,2013-01-01,"Although we already live in a world of data, we just see the tip of an iceberg. Data is everywhere and decisions based on large data sets are driving not only business related but more and more personal decisions.",http://dx.doi.org/10.1007/978-1-4614-6856-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-35728-2_30,Clothing Extraction by Coarse Region Localization and Fine Foreground/Background Estimation,Advances in Multimedia Modeling,10.1007/978-3-642-35728-2_30,Springer,2013-01-01,"Online shopping is becoming more and more popular for billions of web users because of its convenience and efficiency. Customers can use content-based product image search engine to find their desired products. However, a frustrating fact is that the search results are significantly affected by the presence of natural backgrounds and fashion models. To minimize the influence of these noises, in this paper, an automatic clothing extraction algorithm is proposed, which consists of two phases: coarse clothing region localization with human proportion, and fine foreground/background modeling. Experiments on two datasets crawled from e-commerce websites demonstrate that the proposed approach achieves good performance, and has competitive performance with the interactive solution.",http://dx.doi.org/10.1007/978-3-642-35728-2_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-38844-6_29,Understanding Email Writers: Personality Prediction from Email Messages,"User Modeling, Adaptation, and Personalization",10.1007/978-3-642-38844-6_29,Springer,2013-01-01,"Email is a ubiquitous communication tool and constitutes a significant portion of social interactions. In this paper, we attempt to infer the personality of users based on the content of their emails. Such inference can enable valuable applications such as better personalization, recommendation, and targeted advertising. Considering the private and sensitive nature of email content, we propose a privacy-preserving approach for collecting email and personality data. We then frame personality prediction based on the well-known Big Five personality model and train predictors based on extracted email features. We report prediction performance of 3 generative models with different assumptions. Our results show that personality prediction is feasible, and our email feature set can predict personality with reasonable accuracies.",http://dx.doi.org/10.1007/978-3-642-38844-6_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-5007-7_3,Sources of Inspiration for Autonomic Computing,Autonomic Computing,10.1007/978-1-4471-5007-7_3,Springer,2013-01-01,"Autonomic computing can capitalise on advancements available from several scientific fields, both within and beyond the computer science domain. This chapter provides an overview of such fields and highlights their possible contributions to autonomic computing systems. The manner in which concepts, mechanisms and processes can be adopted and reused as software engineering approaches is highlighted across this chapter. We discuss biology as the first source of inspiration for autonomic computing. While the bio-inspired autonomicity concept is highly relevant to autonomic computing, the potential of biology to inspire this field largely surpasses this metaphor. We therefore enlarge our discussion to biological systems in general, especially nervous systems, highlighting how their implementation in different species can inspire various solutions to autonomic computing systems. We also show how autonomic computing shares many of its goals and necessary underlying constructions with some well-established engineering and computing fields such as automated control systems, robotics, artificial intelligence and multi-­agent systems. The chapter summarises some of the most relevant concepts and approaches available from existing fields and indicates the manner in which they can be adopted to serve the autonomic computing initiative. A number of interrelated theoretical fields provide a potentially significant link between natural and artificial autonomic systems. Areas such as complex systems theory, cybernetics, networked systems theory and artificial life have set out to decipher the inner workings of complex adaptive systems and ultimately to control or to build artificial ones. We briefly point out the relevance of such fields and the core concepts that seem most readily applicable to autonomic computing. Certainly, the chapter cannot provide a comprehensive view of all areas relevant to autonomic computing. Rather, its purpose is to provide an (probably biased) overview of the most relevant sources of inspiration and to offer pointers towards more extensive specialty literature.",http://dx.doi.org/10.1007/978-1-4471-5007-7_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-41278-3_75,A Survey on Benchmarks for Big Data and Some More Considerations,Intelligent Data Engineering and Automated Learning – IDEAL 2013,10.1007/978-3-642-41278-3_75,Springer,2013-01-01,"A big data benchmark suite is needed eagerly by customers, industry and academia recently. A number of prominent works in last several years are reviewed, their characteristics are introduced and shortcomings are analyzed. The authors also provide some suggestions on building the expected benchmark, including: component based benchmarks as well as end-to-end benchmarks should be used together to test distinct tools and test the system as a whole; workloads should be enriched with complex analytics to encompass different application scenarios; metrics other than performance metrics should also be considered.",http://dx.doi.org/10.1007/978-3-642-41278-3_75,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-41320-9_1,"I Think, Therefore I Am: Usability and Security of Authentication Using Brainwaves",Financial Cryptography and Data Security,10.1007/978-3-642-41320-9_1,Springer,2013-01-01,"With the embedding of EEG (electro-encephalography) sensors in wireless headsets and other consumer electronics, authenticating users based on their brainwave signals has become a realistic possibility. We undertake an experimental study of the usability and performance of user authentication using consumer-grade EEG sensor technology. By choosing custom tasks and custom acceptance thresholds for each subject, we can achieve 99% authentication accuracy using single-channel EEG signals, which is on par with previous research employing multi-channel EEG signals using clinical-grade devices. In addition to the usability improvement offered by the single-channel dry-contact EEG sensor, we also study the usability of different classes of mental tasks. We find that subjects have little difficulty recalling chosen “pass-thoughts” (e.g., their previously selected song to sing in their mind). They also have different preferences for tasks based on the perceived difficulty and enjoyability of the tasks. These results can inform the design of authentication systems that guide users in choosing tasks that are both usable and secure.",http://dx.doi.org/10.1007/978-3-642-41320-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4302-4873-6_8,"Extracting Value From Big Data: In-Memory Solutions, Real Time Analytics, And Recommendation Systems",Big Data Imperatives,10.1007/978-1-4302-4873-6_8,Springer,2013-01-01,"Data is everywhere, but few organizations are deriving the full value from their data. How do you keep up with the velocity and variety of data streaming in and get actionable insights from it, all in real time?",http://dx.doi.org/10.1007/978-1-4302-4873-6_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-34952-2_16,A Recommendation System for Browsing of Multimedia Collections in the Internet of Things,Internet of Things and Inter-cooperative Computational Technologies for Collective Intelligence,10.1007/978-3-642-34952-2_16,Springer,2013-01-01,"Exploring new applications and services for mobile environments has generated considerable excitement among both industries and academics. In this paper we propose a context-aware recommender system that accommodates user’s needs with location-dependent multimedia information available in a mobile environment related to an indoor scenario. Specifically, we propose a recommender system for the planning of browsing activities that are based on objects features, users’ behaviours and on the current context the state of which is captured by apposite sensor networks. We present the features of such a system and we discuss the proposed approach.",http://dx.doi.org/10.1007/978-3-642-34952-2_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40276-0_14,NoizCrowd: A Crowd-Based Data Gathering and Management System for Noise Level Data,Mobile Web Information Systems,10.1007/978-3-642-40276-0_14,Springer,2013-01-01,"Many systems require access to very large amounts of data to properly function, like systems allowing to visualize or predict meteorological changes in a country over a given period of time, or any other system holding, processing and displaying scientific or sensor data. However, filling out a database with large amounts of valuable data can be a difficult, costly and time-consuming task. In this paper, we present techniques to create large amounts of data by combining crowdsourcing, data generation models, mobile computing, and big data analytics. We have implemented our methods in a system, NoizCrowd, allowing to crowdsource noise levels in a given region and to generate noise models by using state-of-the-art noise propagation models and array data management techniques. The resulting models and data can then be accessed using a visual interface.",http://dx.doi.org/10.1007/978-3-642-40276-0_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-39235-1_4,PeerRush: Mining for Unwanted P2P Traffic,"Detection of Intrusions and Malware, and Vulnerability Assessment",10.1007/978-3-642-39235-1_4,Springer,2013-01-01,"In this paper we present PeerRush, a novel system for the identification of unwanted P2P traffic. Unlike most previous work, PeerRush goes beyond P2P traffic detection, and can accurately categorize the detected P2P traffic and attribute it to specific P2P applications, including malicious applications such as P2P botnets . PeerRush achieves these results without the need of deep packet inspection, and can accurately identify applications that use encrypted P2P traffic. We implemented a prototype version of PeerRush and performed an extensive evaluation of the system over a variety of P2P traffic datasets. Our results show that we can detect all the considered types of P2P traffic with up to 99.5% true positives and 0.1% false positives. Furthermore, PeerRush can attribute the P2P traffic to a specific P2P application with a misclassification rate of 0.68% or less.",http://dx.doi.org/10.1007/978-3-642-39235-1_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-40203-6_38,Nowhere to Hide: Navigating around Privacy in Online Social Networks,Computer Security – ESORICS 2013,10.1007/978-3-642-40203-6_38,Springer,2013-01-01,"In this paper, we introduce a navigation privacy attack, where an external adversary attempts to find a target user by exploiting publicly visible attributes of intermediate users. If such an attack is successful, it implies that a user cannot hide simply by excluding himself from a central directory or search function. The attack exploits the fact that most attributes (such as place of residence, age, or alma mater) tend to correlate with social proximity, which can be exploited as navigational cues while crawling the network. The problem is exacerbated by privacy policies where a user who keeps his profile private remains nevertheless visible in his friends’ “friend lists”; such a user is still vulnerable to our navigation attack. Experiments with Facebook and Google+ show that the majority of users can be found efficiently using our attack, if a small set of attributes are known about the target as side information. Our results suggest that, in an online social network where many users reveal a (even limited) set of attributes, it is nearly impossible for a specific user to “hide in the crowd”.",http://dx.doi.org/10.1007/978-3-642-40203-6_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-33326-2_6,Web Usage Based Adaptive Systems,Advanced Techniques in Web Intelligence-2,10.1007/978-3-642-33326-2_6,Springer,2013-01-01,"The Internet is becoming an important tool for the realization of day-to-day activities, which leads to a new level of interaction between users and software systems. This new scenario presents endless opportunities as well as enormous challenges. In order to tackle these, user-adaptive software systems have been recently used. These technologies aim to allow computer systems to dynamically modify their content, structure and presentation for better delivery of the available resources, while considering the user’s interest and behavior, and most recently, mobile environments. This chapter overviews the newest technologies in the area of user-adaptive software systems applied to Web environments and proposes a set of directions for the future development of Web Usage Based Adaptive Systems in the new Internet environments.",http://dx.doi.org/10.1007/978-3-642-33326-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-03973-2_1,Mobile Social Travel Recommender System,Information and Communication Technologies in Tourism 2014,10.1007/978-3-319-03973-2_1,Springer,2013-01-01,"Travel Recommender Systems (TRSs) help tourists discovering and selecting the Points of Interest (POIs) that best fit their preferences. Recommendations rely on the data available about the POIs of a destination, the knowledge about tourists and their preferences about categories, and recommendation algorithms. This paper presents a Mobile Social TRS. The recommendation process is divided in two independent processes: the generation of user models and the calculation of the recommended POIs. The recommender generates user models taking into account their explicit preferences about categories, demographic information, and the tags they have created. Then, similarities between users are based on the POIs they have rated. Finally, a hybrid filtering algorithm combines these models with a content-based and a collaborative filtering algorithm to calculate a list of recommended POIs. The recommender has been integrated in a mobile prototype of the CRUMBS social network and preliminary results of its partial validation are presented.",http://dx.doi.org/10.1007/978-3-319-03973-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-5571-4_3,State-of-the-Art in Iris Biometrics,Iris Biometrics,10.1007/978-1-4614-5571-4_3,Springer,2013-01-01,"Iris biometrics has received remarkable attention in the biometric community due to its unrivaled properties. Possessing epigenetic (not genetically determined) pattern information apart from color, the iris is widely employed as a biometric identifier because of its high universality (almost every person has the characteristic), distinctiveness (high discriminative power due to its entropy), permanence (stability except for pigmentation change over time), and performance (accuracy and speed). While according to the classification by Jain et al. in 2004 [229] there are other modalities with better collectability (the characteristic can well be measured), acceptability (people are willing to provide the characteristic), and circumvention (how easy the system can be fooled) properties, a lot of research effort has been invested to improve iris recognition with respect to these biometric properties.",http://dx.doi.org/10.1007/978-1-4614-5571-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-34207-3_7,QoS-Aware Fault Tolerance for Web Services,QoS Management of Web Services,10.1007/978-3-642-34207-3_7,Springer,2013-01-01,"The highly dynamic Internet environment makes traditional fault tolerance strategies difficult to be used in the service-oriented environment. In this chapter, we propose an adaptive fault tolerance strategy for Web services, which can determine the optimal fault tolerance strategy dynamically at runtime based on the user preference and service QoS.",http://dx.doi.org/10.1007/978-3-642-34207-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10799-012-0123-z,Business intelligence in enterprise computing environment,Information Technology and Management,10.1007/s10799-012-0123-z,Springer,2012-12-01,"Business intelligence (BI) is the process of gathering correct information in the correct format at the correct time; and delivering the results for decision-making purposes, or have a positive impact on business operations, tactics, and strategy in the enterprises. This paper is intended as a brief review of BI in an enterprise computing environment, with an emphasis on the algorithms and methods. The review points out the challenges to the broad and deep deployment of business intelligence systems, and provide proposals to make business intelligence more effective.",http://dx.doi.org/10.1007/s10799-012-0123-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-011-9308-y,End-to-end reliability of service oriented applications,Information Systems Frontiers,10.1007/s10796-011-9308-y,Springer,2012-12-01,"As organizations move towards adopting a service oriented architecture that permits the coexistence of multiple technology environments, an increasing number of applications will be developed through the assembly of existing software components with standard web service interfaces. These components with web service interfaces may be available in-house, or may be supplied or hosted by external vendors. The use of multiple services, possibly utilizing different technologies, providers, locations, and sources, has implications for the end-to-end reliability of these applications to support a business process. Selecting the best service for individual tasks in a business process does not guarantee the most effective overall solution, particularly if criteria other than functional characteristics are employed. This paper examines reliability issues associated with applications developed within service oriented architecture. It develops a measure for deriving end-to-end application reliability, and develops a model to help select appropriate services for tasks in the business process which accommodate the redundant and overlapping functionality of available services and planned redundancy in task support to satisfy the reliability requirement of the resulting application. A genetic algorithm approach is adopted to select promising services to assemble the application using end-to-end reliability as the criterion of interest. An application to a real-world business process illustrates the effectiveness of the approach.",http://dx.doi.org/10.1007/s10796-011-9308-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1057/dddmp.2012.25,Measuring the diffusion of marketing messages across a social network,"Journal of Direct, Data and Digital Marketing Practice",10.1057/dddmp.2012.25,Springer,2012-11-01,"The last few years have seen significant investment in social media as an advertising, marketing and customer outreach opportunity. In the US alone, in 2010, almost $1.7 bn was spent by advertisers on social media marketing, with 53 per cent specifically allocated to Facebook 1 . Due to the explicit links that users maintain with each other, social media platforms are perceived as a highly suited environment for network-based marketing: word-of-mouth marketing, diffusion of innovation, or buzz and viral marketing 2 all aim to take advantage of the relationships between users to facilitate the spread of awareness or adoption. In order to predetermine the effectiveness of such campaigns, it is important to be able to estimate potential return on investment. In particular, the ability to model existing networks, track the propagation of marketing messages and estimate customer exposures and impressions are essential for this purpose. A wide range of techniques to measure notions such as user engagement on such platforms have been developed and there also exists a significant amount of research on modelling contagion and diffusion in network-based environments that can be exploited to generally refine an overall marketing strategy. However, the structure and properties of different social media platforms introduce various constraints on both the means via which data propagate and the visibility of content and nodes, constraints that must be taken into account when modelling or measuring the impact of social media campaigns. Perfect information about exposures within a given graph to a given message will not be available and as such it is important to investigate and define methodologies for diffusion monitoring that are suited to specific platforms.",http://dx.doi.org/10.1057/dddmp.2012.25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-011-9118-4,Explaining the user experience of recommender systems,User Modeling and User-Adapted Interaction,10.1007/s11257-011-9118-4,Springer,2012-10-01,"Research on recommender systems typically focuses on the accuracy of prediction algorithms. Because accuracy only partially constitutes the user experience of a recommender system, this paper proposes a framework that takes a user-centric approach to recommender system evaluation. The framework links objective system aspects to objective user behavior through a series of perceptual and evaluative constructs (called subjective system aspects and experience, respectively). Furthermore, it incorporates the influence of personal and situational characteristics on the user experience. This paper reviews how current literature maps to the framework and identifies several gaps in existing work. Consequently, the framework is validated with four field trials and two controlled experiments and analyzed using Structural Equation Modeling. The results of these studies show that subjective system aspects and experience variables are invaluable in explaining why and how the user experience of recommender systems comes about . In all studies we observe that perceptions of recommendation quality and/or variety are important mediators in predicting the effects of objective system aspects on the three components of user experience: process (e.g. perceived effort, difficulty), system (e.g. perceived system effectiveness) and outcome (e.g. choice satisfaction). Furthermore, we find that these subjective aspects have strong and sometimes interesting behavioral correlates (e.g. reduced browsing indicates higher system effectiveness). They also show several tradeoffs between system aspects and personal and situational characteristics (e.g. the amount of preference feedback users provide is a tradeoff between perceived system usefulness and privacy concerns). These results, as well as the validated framework itself, provide a platform for future research on the user-centric evaluation of recommender systems.",http://dx.doi.org/10.1007/s11257-011-9118-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10257-011-0170-8,Moving recommender systems from on-line commerce to retail stores,Information Systems and e-Business Management,10.1007/s10257-011-0170-8,Springer,2012-09-01,"The increasing diversity of consumers’ demand, as documented by the debate on the long tail of the distribution of sales volume across products, represents a challenge for retail stores. Recommender systems offer a tool to cope with this challenge. The recent developments in information technology and ubiquitous computing makes it feasible to move recommender systems from the on-line commerce, where they are widely used, to retail stores. In this paper, we aim to bridge the management literature and the computer science literature by analysing a number of issues that arise when applying recommender systems to retail stores: these range from the format of the stores that would benefit most from recommender systems to the impact of coverage and control of recommender systems on customer loyalty and competition among retail stores.",http://dx.doi.org/10.1007/s10257-011-0170-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10506-012-9131-x,A history of AI and Law in 50 papers: 25 years of the international conference on AI and Law,Artificial Intelligence and Law,10.1007/s10506-012-9131-x,Springer,2012-09-01,"We provide a retrospective of 25 years of the International Conference on AI and Law, which was first held in 1987. Fifty papers have been selected from the thirteen conferences and each of them is described in a short subsection individually written by one of the 24 authors. These subsections attempt to place the paper discussed in the context of the development of AI and Law, while often offering some personal reactions and reflections. As a whole, the subsections build into a history of the last quarter century of the field, and provide some insights into where it has come from, where it is now, and where it might go.",http://dx.doi.org/10.1007/s10506-012-9131-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12243-012-0310-2,Cooperative customer navigation between robots outside and inside a retail shop—an implementation on the ubiquitous market platform,annals of telecommunications - annales des télécommunications,10.1007/s12243-012-0310-2,Springer,2012-08-01,"Applying the technologies of a network robot system, recommendation methods used in e-commerce are incorporated in a retail shop in the real world. We constructed a platform for ubiquitous networked robots that focuses on a shop environment where communication robots perform customer navigation. The platform observes customers’ purchasing behavior by networked sensors, including a laser range finder-based human position tracking system, and then controls visible-type communication robots in the environment to perform customer navigation. Two types of navigation scenarios are implemented and investigated in experiments using 80 participants. The results indicate that the participants in the cooperative navigation scenario, who interacted with communication robots located both outside and inside the shop, felt friendliness toward the robots and found it easy to understand what the robots said.",http://dx.doi.org/10.1007/s12243-012-0310-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00354-012-0202-z,Dynamic SOA Framework to Support Ad Hoc Enterprise Alliance Formation,New Generation Computing,10.1007/s00354-012-0202-z,Springer,2012-06-01,"Collaboration among businesses is needed to successfully fulfill a given task and goal. Service-Oriented Architecture (SOA) has been regarded as an efficient platform to support flexible interoperability among various enterprises by discovering, selecting and composing services. However, since a large number of enterprises have been participating in this SOA platform, relationships among these enterprises are getting too complicated to obtain flexibility and scalability for efficient collaboration. Thereby, in this paper, we propose a dynamic SOA platform to discover service chains for building ad hoc enterprise alliances where the only relevant enterprises are sorted out and merged. As a result, given an event, decision makers can find out which enterprises (and services from the enterprises) might be selected for their collaboration. The proposed SOA platform has been applied to mobile advertisement application as a case study. With respect to two indicators (i.e., precision and agility), we have shown that the proposed SOA outperforms traditional enterprise collaboration schemes.",http://dx.doi.org/10.1007/s00354-012-0202-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-011-0663-x,Adaptive cascade of boosted ensembles for face detection in concept drift,Neural Computing and Applications,10.1007/s00521-011-0663-x,Springer,2012-06-01,"We propose an adaptive learning algorithm for cascades of boosted ensembles that is designed to handle the problem of concept drift in nonstationary environments. The goal was to create a real-time adaptive algorithm for dynamic environments that exhibit varying degrees of drift in high-volume streaming data. This we achieved using a hybrid of detect-and-retrain and constant-update approaches. The uniqueness of our method is found in two aspects of our framework. The first is the manner in which individual weak classifiers within each cascade layer of an ensemble are clustered during training and assigned a competence value. Secondly, the idea of learning optimal cascade-layer thresholds during runtime, which enables rapid adaptation to dynamic environments. The proposed adaptive learning method was applied to a binary-class problem with rare-event detection characteristics. For this, we chose the domain of face detection and demonstrate experimentally the ability of our algorithm to achieve an effective trade-off between accuracy and speed of adaptations in dense data streams with unknown rates of change.",http://dx.doi.org/10.1007/s00521-011-0663-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10618-012-0254-1,More than modelling and hiding: towards a comprehensive view of Web mining and privacy,Data Mining and Knowledge Discovery,10.1007/s10618-012-0254-1,Springer,2012-05-01,"Over the last decade, privacy has been widely recognised as one of the major problems of data collections in general and the Web in particular. This concerns specifically data arising from Web usage (such as querying or transacting) and social networking (characterised by rich self-profiling including relational information) and the inferences drawn from them. The data mining community has been very conscious of these issues and has addressed in particular the inference problems through various methods for “privacy-preserving data mining” and “privacy-preserving data publishing”. However, it appears that these approaches by themselves cannot effectively solve the privacy problems posed by mining. We argue that this is due to the underlying notions of privacy and of data mining, both of which are too narrow. Drawing on notions of privacy not only as hiding, but as control and negotiation, as well as on data mining not only as modelling, but as the whole cycle of knowledge discovery, we offer an alternative view. This is intended to be a comprehensive view of the privacy challenges as well as solution approaches along all phases of the knowledge discovery cycle. The paper thus combines a survey with an outline of an agenda for a comprehensive, interdisciplinary view of Web mining and privacy.",http://dx.doi.org/10.1007/s10618-012-0254-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-011-9112-x,Recommender systems: from algorithms to user experience,User Modeling and User-Adapted Interaction,10.1007/s11257-011-9112-x,Springer,2012-04-01,"Since their introduction in the early 1990’s, automated recommender systems have revolutionized the marketing and delivery of commerce and content by providing personalized recommendations and predictions over a variety of large and complex product offerings. In this article, we review the key advances in collaborative filtering recommender systems, focusing on the evolution from research concentrated purely on algorithms to research concentrated on the rich set of questions around the user experience with the recommender. We show through examples that the embedding of the algorithm in the user experience dramatically affects the value to the user of the recommender. We argue that evaluating the user experience of a recommender requires a broader set of measures than have been commonly used, and suggest additional measures that have proven effective. Based on our analysis of the state of the field, we identify the most important open research problems, and outline key challenges slowing the advance of the state of the art, and in some cases limiting the relevance of research to real-world applications.",http://dx.doi.org/10.1007/s11257-011-9112-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00165-011-0207-2,A formal approach to adaptive software: continuous assurance of non-functional requirements,Formal Aspects of Computing,10.1007/s00165-011-0207-2,Springer,2012-03-01,"Modern software systems are increasingly requested to be adaptive to changes in the environment in which they are embedded. Moreover, adaptation often needs to be performed automatically, through self-managed reactions enacted by the application at run time. Off-line, human-driven changes should be requested only if self-adaptation cannot be achieved successfully. To support this kind of autonomic behavior, software systems must be empowered by a rich run-time support that can monitor the relevant phenomena of the surrounding environment to detect changes, analyze the data collected to understand the possible consequences of changes, reason about the ability of the application to continue to provide the required service, and finally react if an adaptation is needed. This paper focuses on non-functional requirements, which constitute an essential component of the quality that modern software systems need to exhibit. Although the proposed approach is quite general, it is mainly exemplified in the paper in the context of service-oriented systems, where the quality of service (QoS) is regulated by contractual obligations between the application provider and its clients. We analyze the case where an application, exported as a service, is built as a composition of other services. Non-functional requirements—such as reliability and performance—heavily depend on the environment in which the application is embedded. Thus changes in the environment may ultimately adversely affect QoS satisfaction. We illustrate an approach and support tools that enable a holistic view of the design and run-time management of adaptive software systems. The approach is based on formal (probabilistic) models that are used at design time to reason about dependability of the application in quantitative terms. Models continue to exist at run time to enable continuous verification and detection of changes that require adaptation.",http://dx.doi.org/10.1007/s00165-011-0207-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-012-9087-7,Incorporating context into recommender systems: an empirical comparison of context-based approaches,Electronic Commerce Research,10.1007/s10660-012-9087-7,Springer,2012-03-01,"Recently, there has been growing interest in recommender systems (RSs) and particularly in context-aware RSs. Methods for generating context-aware recommendations were classified into the pre-filtering, post-filtering and contextual modeling approaches. This paper focuses on comparing the pre-filtering, the post-filtering, the contextual modeling and the un-contextual approaches and on identifying which method dominates the others and under which circumstances. Although some of these methods have been studied independently, no prior research compared the relative performance to determine which of them is better. This paper proposes an effective method of comparing the three methods to incorporate context and selecting the best alternatives. As a result, it provides analysts with a practical suggestion on how to pick a good approach in an effective manner to improve the performance of a context-aware recommender system.",http://dx.doi.org/10.1007/s10660-012-9087-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-90-481-8990-8_6,"Accounting for Social, Spatial, and Textual Interconnections","Computer Applications for Handling Legal Evidence, Police Investigation and Case Argumentation",10.1007/978-90-481-8990-8_6,Springer,2012-01-01,"This is a chapter about what link analysis and data mining can do for criminal investigation. It is a long and complex chapter, in which a variety of techniques and topics are accommodated. It is divided in two parts, one about methods, and the other one about real-case studies. We begin by discussing social networks and their visualisation, as well as what unites them with or distinguishes them from link analysis (which itself historically arose from the disciplinary context of ergonomics). Having considered applications of link analysis to criminal investigation, we turn to crime risk assessment, to geographic information systems for mapping crimes, to detection, and then to multiagent architectures and their application to policing. We then turn to the challenge of handling a disparate mass of data, and introduce the reader to data warehousing, XML, ontologies, legal ontologies, and financial fraud ontology. A section about automated summarisation and its application to law is followed by a discussion of text mining and its application to law, and by a section on support vector machines for information retrieval, text classification, and matching. A section follows, about stylometrics, determining authorship, handwriting identification and its automation, and questioned documents evidence. We next discuss classification, clustering, series analysis, and association in knowledge discovery from legal databases; then, inconsistent data; rule induction (including in law); using neural networks in the legal context; fuzzy logic; and genetic algorithms. Before turning to case studies of link analysis and data mining, we take a broad view of digital resources and uncovering perpetration: email mining, computer forensics, and intrusion detection. We consider the Enron email database; the discovery of social coalitions with the SIGHTS text mining system, and recursive data mining. We discuss digital forensics, digital steganography, and intrusion detection (the use of learning techniques, the detection of masquerading, and honeypots for trapping intruders). Case studies include, for example: investigating Internet auction fraud with NetProbe; graph mining for malware detection with Polonium; link analysis with Coplink; a project of the U.S. Federal Defense Financial Accounting Service; information extraction tools for integration with a link analysis tool; the Poznan ontology model for the link analysis of fuel fraud; and fiscal fraud detection with the Pisa SNIPER project.",http://dx.doi.org/10.1007/978-90-481-8990-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-32066-8_6,A Multi-classifier Approach to Dialogue Act Classification Using Function Words,Transactions on Computational Collective Intelligence VII,10.1007/978-3-642-32066-8_6,Springer,2012-01-01,"This paper extends a novel technique for the classification of sentences as Dialogue Acts, based on structural information contained in function words. Initial experiments on classifying questions in the presence of a mix of straightforward and “difficult” non-questions yielded promising results, with classification accuracy approaching 90%. However, this initial dataset does not fully represent the various permutations of natural language in which sentences may occur. Also, a higher Classification Accuracy is desirable for real-world applications. Following an analysis of categorisation of sentences, we present a series of experiments that show improved performance over the initial experiment and promising performance for categorising more complex combinations in the future.",http://dx.doi.org/10.1007/978-3-642-32066-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-25206-8_1,e-Business Challenges and Directions: Important Themes from the First ICE-B Workshop,e-Business and Telecommunications,10.1007/978-3-642-25206-8_1,Springer,2012-01-01,"A three-day asynchronous, interactive workshop was held at ICE-B’10 in Piraeus, Greece in July of 2010. This event captured conference themes for e-Business challenges and directions across four subject areas: a) e-Business applications and models, b) enterprise engineering, c) mobility, d) business collaboration and e-Services, and e) technology platforms. Quality Function Deployment (QFD) methods were used to gather, organize and evaluate themes and their ratings. This paper summarizes the most important themes rated by participants: a) Since technology is becoming more economic and social in nature, more agile and context-based application develop methods are needed. b) Enterprise engineering approaches are needed to support the design of systems that can evolve with changing stakeholder needs. c) The digital native groundswell requires changes to business models, operations, and systems to support Prosumers. d) Intelligence and interoperability are needed to address Prosumer activity and their highly customized product purchases. e) Technology platforms must rapidly and correctly adapt, provide widespread offerings and scale appropriately, in the context of changing situational contexts.",http://dx.doi.org/10.1007/978-3-642-25206-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33167-1_45,Scalable Telemetry Classification for Automated Malware Detection,Computer Security – ESORICS 2012,10.1007/978-3-642-33167-1_45,Springer,2012-01-01,"Industry reports and blogs have estimated the amount of malware based on known malicious files. This paper extends this analysis to the amount of unknown malware. The study is based on 26.7 million files referenced in telemetry reports from 50 million computers running commercial anti-malware (AM) products. To estimate the undetected malware, a classifier predicts the underlying nature of unknown files recorded in the telemetry reports. The telemetry classifier predicts that 69.6% (4.27 million) of the unknown files are malicious. Assuming the unknown files predicted to be malicious by the classifier are malware, the telemetry classifier also allows us to estimate the efficacy of the AM system indicating that signatures detected 82.8% (20.6 million) of the malicious files. We have validated our system by conducting a longitudinal study to measure the false positive and false negative rates over a period of thirteen months.",http://dx.doi.org/10.1007/978-3-642-33167-1_45,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-34601-9_1,Enhancing List-Based Packet Filter Using IP Verification Mechanism against IP Spoofing Attack in Network Intrusion Detection,Network and System Security,10.1007/978-3-642-34601-9_1,Springer,2012-01-01,"Signature-based network intrusion detection systems (NIDSs) have become an essential part in current network security infrastructure to identify different kinds of network attacks. However, signature matching is a big suffering problem for these systems in which the cost of the signature matching is at least linear to the size of an input string. To mitigate this issue, we have developed a context-aware packet filter by means of the blacklist technique to filter out network packets for a signature-based NIDS and achieved good results. But the effect of the whitelist technique has not been explored in our previous work. In this paper, we therefore aim to develop a list-based packet filter by combining the whitelist technique with the blacklist-based packet filter under some specific conditions, and investigate the effect of the whitelist on packet filtration. To protect both the blacklist and the whitelist, we employ an IP verification mechanism to defend against IP spoofing attack. We implemented the list-based packet filter in a network environment and evaluated it with two distinct datasets, the experimental results show that by deploying with the IP verification mechanism, the whitelist technique can improve the packet filtration without lowering network security.",http://dx.doi.org/10.1007/978-3-642-34601-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-90-481-8990-8_5,The Narrative Dimension,"Computer Applications for Handling Legal Evidence, Police Investigation and Case Argumentation",10.1007/978-90-481-8990-8_5,Springer,2012-01-01,"We begin by discussing legal narratives, and overall narrative plausibility. We consider approaches from the New Evidence scholarship, discuss background generalisations, as well as the impact of modes of communication (the pragmatics of the delivery in court of a legal narrative), and then warn about pitfalls to avoid, in consideration of what controversy within legal scholarship implies about the need for the modelling of legal narratives with artificial intelligence techniques to meet with approval from legal scholars. We then undertake a long overview (in over twenty subsections) of artificial intelligence approaches to narratives. Historically, a legal context for narratives was involved in tools such as BORIS and STARE. Among the other things, we consider the JAMA model, and then conclude the overview with a project from quarters different from those traditionally associated with story-processing in the artificial intelligence research community: namely, Löwe, Pacuit and Saraf’s application of mathematical logic to crime stories. We then explain episodic formulae, and develop an example: the controversy concerning a collection of stuffed birds amid allegations that items were stolen and restuffed. We finally consider Bex’s approach to combining stories and arguments in sense-making software for crime investigation, and then Bex and Bench-Capon’s undertaken project concerning persuasion stories vs. arguments.",http://dx.doi.org/10.1007/978-90-481-8990-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-27609-5_22,A Hybrid System Based on Multi-Agent Systems in Case of e-WeddingThailand,Agents and Data Mining Interaction,10.1007/978-3-642-27609-5_22,Springer,2012-01-01,"We describe the usage of the Multi-agent system in the on-going project, called e-WeddingThailand. The aim of this project is to utilize MAS and various approaches, like Web services, Ontology, and Data mining techniques, in e-Business that want to improve responsiveness and efficiency of systems so as to extract customer behavior model on Wedding Businesses. The multi agent system, which constitutes the backbone of the framework, connects these pieces together and makes them perform properly. JADE is the MAS platform implemented this project. JADE is quite easy to learn and use. Moreover, it supports many agent approaches such as agent communication, protocol, behavior and ontology.",http://dx.doi.org/10.1007/978-3-642-27609-5_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33338-5_11,Evaluating Electricity Theft Detectors in Smart Grid Networks,"Research in Attacks, Intrusions, and Defenses",10.1007/978-3-642-33338-5_11,Springer,2012-01-01,"Electricity theft is estimated to cost billions of dollars per year in many countries. To reduce electricity theft, electric utilities are leveraging data collected by the new Advanced Metering Infrastructure (AMI) and using data analytics to identify abnormal consumption trends and possible fraud. In this paper, we propose the first threat model for the use of data analytics in detecting electricity theft, and a new metric that leverages this threat model in order to evaluate and compare anomaly detectors. We use real data from an AMI system to validate our approach.",http://dx.doi.org/10.1007/978-3-642-33338-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4614-1894-8_1,Social Tagging Systems,Recommender Systems for Social Tagging Systems,10.1007/978-1-4614-1894-8_1,Springer,2012-01-01,"Social Tagging Systems (STS for short) are web applications where users can upload, tag, and share resources (e. g., websites, videos,photos, etc.) with other users. STS promote decentralization of content control and lead the web to be a more open and democratic environment. As we will see in the course of this book, STS put forward new challenges and opportunities for recommender systems, but before we delve into how to design and deploy efficient recommender systems for STS, in this chapter we formally define social tagging systems and their data structures, elaborate on the different recommendation tasks demanded by STS users, introduce real-world STS that already feature recommendation services, and fix the notation we will use throughout the book. The chapter is based on work published in [9].",http://dx.doi.org/10.1007/978-1-4614-1894-8_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-25694-3_3,Challenges in Tag Recommendations for Collaborative Tagging Systems,Recommender Systems for the Social Web,10.1007/978-3-642-25694-3_3,Springer,2012-01-01,"Originally introduced by social bookmarking systems, collaborative tagging, or social tagging, has been widely adopted by many web-based systems like wikis, e-commerce platforms, or social networks. Collaborative tagging systems allow users to annotate resources using freely chosen keywords, so called tags . Those tags help users in finding/retrieving resources, discovering new resources, and navigating through the system. The process of tagging resources is laborious. Therefore, most systems support their users by tag recommender components that recommend tags in a personalized way. The Discovery Challenges 2008 and 2009 of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) tackled the problem of tag recommendations in collaborative tagging systems. Researchers were invited to test their methods in a competition on datasets from the social bookmark and publication sharing system BibSonomy. Moreover, the 2009 challenge included an online task where the recommender systems were integrated into BibSonomy and provided recommendations in real time. In this chapter we review, evaluate and summarize the submissions to the two Discovery Challenges and thus lay the groundwork for continuing research in this area.",http://dx.doi.org/10.1007/978-3-642-25694-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-30864-2_1,A Strategic Perspective on Management Intelligent Systems,Management Intelligent Systems,10.1007/978-3-642-30864-2_1,Springer,2012-01-01,"Management intelligent systems (MIS) is a new paradigm integrating management with intelligent systems. What are the core components of MIS? What are intelligent systems for management? How can management integrate with intelligent systems? All these questions remain open in an MIS context. This article addresses these issues by examining MIS from a strategic perspective. More specifically, this article first examines management in information systems, management for intelligent systems and intelligent systems for management. Then this article provides a strategic model for MIS encompassing core components of MIS, through integrating main management functions with intelligent systems taking into account decision making of managers in organizations. The approach proposed in this article will facilitate the research and development of MIS, management and intelligent systems and information systems.",http://dx.doi.org/10.1007/978-3-642-30864-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33167-1_28,Introducing the gMix Open Source Framework for Mix Implementations,Computer Security – ESORICS 2012,10.1007/978-3-642-33167-1_28,Springer,2012-01-01,In this paper we introduce the open source software framework gMix which aims to simplify the implementation and evaluation of mix-based systems. gMix is targeted at researchers who want to evaluate new ideas and developers interested in building practical mix systems. The framework consists of a generic architecture structured in logical layers with a clear separation of concerns. Implementations of mix variants and supportive components are organized as plug-ins that can easily be exchanged and extended. We provide reference implementations for several well-known mix concepts.,http://dx.doi.org/10.1007/978-3-642-33167-1_28,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33338-5_18,N-Gram against the Machine: On the Feasibility of the N-Gram Network Analysis for Binary Protocols,"Research in Attacks, Intrusions, and Defenses",10.1007/978-3-642-33338-5_18,Springer,2012-01-01,"In recent years we have witnessed several complex and high-impact attacks specifically targeting “binary” protocols (RPC, Samba and, more recently, RDP). These attacks could not be detected by current – signature-based – detection solutions, while – at least in theory – they could be detected by state-of-the-art anomaly-based systems. This raises once again the still unanswered question of how effective anomaly-based systems are in practice. To contribute to answering this question, in this paper we investigate the effectiveness of a widely studied category of network intrusion detection systems: anomaly-based algorithms using n-gram analysis for payload inspection. Specifically, we present a thorough analysis and evaluation of several detection algorithms using variants of n-gram analysis on real-life environments. Our tests show that the analyzed systems, in presence of data with high variability, cannot deliver high detection and low false positive rates at the same time.",http://dx.doi.org/10.1007/978-3-642-33338-5_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-33469-6_10,Learning Research in Knowledge Transfer,Web Information Systems and Mining,10.1007/978-3-642-33469-6_10,Springer,2012-01-01,"This study is a productivity review on the literature gleaned from science citation index expanded (SCI-EXPANED) database on web of science, concerning learning research in knowledge transfer. The result indicates that the number of literature productions on this topic mainly distributes in recent years, reaching climax of 5 in 2010 and then followed by 2008. The main research development country is USA accounting for 27%. And from the analysis of institutions, HONG KONG UNIV SCI TECHNOL and UNIV OTTAWA rank parallel top one. As for source title, management science is in the first place. The related research can be classified into three branches, including effects of learning, approaches to knowledge transfer and modeling of knowledge transfer.",http://dx.doi.org/10.1007/978-3-642-33469-6_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_15,AristaFlow BPM Suite,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_15,Springer,2012-01-01,"In dynamic environments, it becomes necessary to quickly implement new business processes, to allow for ad hoc deviations from prespecified processes, and to enable controlled process evolution over time. These fundamental features should be provided by any PAISs without affecting the correctness and soundness of the processes it implements. This chapter presents the AristaFlow BPM Suite—an adaptive PAIS that addresses these challenges. It has originated from the ADEPT research projects. Its overall vision is to provide next generation process management technology for the flexible support of dynamic processes along the process lifecycle. Due to its generic services and application programming interfaces, the AristaFlow BPM Suite can be applied to a variety of applications from different domains.",http://dx.doi.org/10.1007/978-3-642-30409-5_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02279-1_1,Introduction,Theoretical Foundations for Digital Libraries,10.1007/978-3-031-02279-1_1,Springer,2012-01-01,"Digital libraries (DLs) are researched, developed, implemented, deployed, and used by millions of people in a wide variety of domains. They include advanced information systems that address the full information life cycle, facilitating asynchronous communication, across time and space, and enabling new methods for scholarly communication in our flat world. Since there is strong motivation to build DLs, they are studied by many of those doing advanced work in computer, information, or library science. Though there are a variety of definitions related to DLs, and varied perspectives to consider, few have adopted a formal approach. The 5S framework provides a theoretical foundation to define key constructs, building upon: Societies, Scenarios, Spaces, Structures, and Streams. Using these 5Ss, definitions of important concepts are provided, leading ultimately to a definition of a minimal digital library. Further, 5S guides us to develop a taxonomy for the DL field.",http://dx.doi.org/10.1007/978-3-031-02279-1_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-28786-2_6,A Virtual Selling Agent Which Is Proactive and Adaptive,Advances on Practical Applications of Agents and Multi-Agent Systems,10.1007/978-3-642-28786-2_6,Springer,2012-01-01,"In this paper, we claim that the online selling process can be improved if the experience of the customer is closer to the one in a retailing store. For this purpose, we aim at providing a virtual selling agent that is proactive and adaptive. Our proactive dialogical agent initiates the dialogue, uses marketing strategies and drives the inquiring process for collecting information in order to make relevant proposals. Moreover, our virtual seller is adaptive since she is able to adjust her behaviour according to the buyer profile.",http://dx.doi.org/10.1007/978-3-642-28786-2_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-28047-4_1,Introduction,Journeys to Data Mining,10.1007/978-3-642-28047-4_1,Springer,2012-01-01,It has been a great honour to have been given the opportunity to edit this book and a great pleasure to work with such a respected group of data mining scientists and professionals. It is our belief that the knowledge provided by studying the journeys these respected and recognised individuals took through the area of data mining is as important as simply gaining the required knowledge in the field. The contributors to this volume are successful scientists and professionals within the field of data analytics. All the authors in this volume have helped to shape the field of data analytics through their many valuable contributions.,http://dx.doi.org/10.1007/978-3-642-28047-4_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-30947-2_17,On-Line Communities Making Scense: A Hybrid Micro-Blogging Platform Community Analysis Framework,Agent and Multi-Agent Systems. Technologies and Applications,10.1007/978-3-642-30947-2_17,Springer,2012-01-01,"The upsurge of Micro-blogging platform attracts enterprises to use it as a public relationship tool. It also act as a new form of news source, journalists can hunt for next upcoming breaking news. It is worth to identify communities from it and reveal social relationships among community members in a timely manner. However, traditional SNA approaches are insufficient to achieve the requirement in a reasonable time. In this paper, we proposed a hybrid framework to tackle the problem. It is designed to identify the community with real social relationships automatically, that withstand dynamically changing content, have the ability to process fast and live-streaming data and provide a self-feedback mechanism to refine the result without human interference. The benefit of this framework is that average users should be able to employ it and to really understand communities in micro-blogging platforms without any or limited domain knowledge.",http://dx.doi.org/10.1007/978-3-642-30947-2_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_9,Process Evolution and Instance Migration,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_9,Springer,2012-01-01,"Business processes evolve over time due to changes in their legal, technical, or business context, or as a result of organizational learning. As a consequence, prespecified process models and their technical implementation in a PAIS need to be adapted accordingly. Moreover, prespecified process models often have to be changed to cope with design errors, technical problems, or poor model quality. This chapter presents techniques to tackle these challenges and to change implemented business processes at a technical level. First, it deals with process model evolution , i.e., the evolution of prespecified process models over time to accommodate changes of real-world processes. In this context, techniques are introduced for dealing with already running process instances and their on-the-fly migration to the changed process model, without violating any correctness and soundness properties. Second, this chapter introduces process model refactorings to foster internal process model quality and to ensure maintainability of the PAIS over time.",http://dx.doi.org/10.1007/978-3-642-30409-5_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_2,Process-Aware Information Systems,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_2,Springer,2012-01-01,"The success of commercial enterprises increasingly depends on their ability to flexibly and quickly react to changes in their environment. Businesses are therefore interested in improving the efficiency and quality of their business processes and in aligning their information systems in a process-centered way. This chapter deals with basic concepts related to business process automation and process-aware information systems (PAISs). Characteristic properties, perspectives, and components of a PAIS are presented based on real-world process scenarios.",http://dx.doi.org/10.1007/978-3-642-30409-5_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-34679-8_11,Determining Pattern Similarity in a Medical Recommender System,Data and Knowledge Engineering,10.1007/978-3-642-34679-8_11,Springer,2012-01-01,"As recommender systems have proven their effectiveness in other areas, it is aimed to transfer this approach for use in medicine. Particularly, the diagnoses of physicians made in rural hospitals of developing countries, in remote areas or in situations of uncertainty are to be complemented by machine recommendations drawing on large bases of expert knowledge in order to reduce the risk to patients. Recommendation is mainly based on finding known patterns similar to a case under consideration. To search for such patterns in rather large databases, a weighted similarity distance is employed, which is specially derived for medical knowledge. For collaborative filtering an incremental algorithm, called W-InCF, is used working with the Mahalanobis distance and fuzzy membership. W-InCF consists of a learning phase, in which a cluster model of patients’ medical history is constructed incrementally, and a prediction phase, in which the medical pattern of each patient considered is compared with the model to determine the most similar cluster. Fuzzy sets are employed to cope with possible confusion of decision making on overlapping clusters. The degrees of membership to these fuzzy sets is expressed by a weighted Mahalanobis radial basis function, and the weights are derived from risk factors identified by experts. The algorithm is validated using data on cephalopelvic disproportion.",http://dx.doi.org/10.1007/978-3-642-34679-8_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-34135-9_46,Biologically Inspired Computer Security System: The Way Ahead,Recent Trends in Computer Networks and Distributed Systems Security,10.1007/978-3-642-34135-9_46,Springer,2012-01-01,"Last two decades have witnessed tremendous growth of internet and it acts as a centrifugal force for a whole new array of applications and services which drives the e- business/ commerce globally. Millions of application has been designed to reach out to the end-user to provide necessary information. The users who are participating in various activities over internet are exposed to public network which is vulnerable to the ever growing threats like never before due to the fascination and value of information/ transaction involved. So concern about security of computer systems is justifiable, and to overcome/ prevent these threats has resulted in the development of various security concepts and products such as Firewalls, Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS). Lately it has been witnessed that there lies a huge potential in biological algorithms and methods to solve complex real world problems, we just need to relate and model the solution based on these biological theories. This paper critically reviews the information that is available on the internet as one has to spend a considerable amount of time to search it, also it explores the possibilities of development of a biologically inspired computer security system to overcome the ever growing complex security challenges.",http://dx.doi.org/10.1007/978-3-642-34135-9_46,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_12,Constraint-Based Process Models,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_12,Springer,2012-01-01,"This chapter introduces constraint-based approaches to process modeling and execution which enable loosely specified processes. While prespecified process models define how things have to be done (i.e., in what order and under what conditions activities shall be executed), constraint-based process models focus on what should be done by describing the activities that may be performed and the constraints prohibiting undesired execution behavior. In this chapter we address the modeling, verification, and execution of constraint-based process models. Moreover, we discuss how these models can be adapted and evolved over time. We further present techniques for assisting end-users during process execution. Finally, constraint-based process models and prespecified ones are systematically compared, and ways to integrate both approaches are discussed.",http://dx.doi.org/10.1007/978-3-642-30409-5_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_10,Business Process Compliance,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_10,Springer,2012-01-01,"In the previous chapters, the proper executability of a prespecified process model has been based on syntactical constraints, correctness of its data flow schema, and behavioral soundness. However, business processes are also subject to semantic constraints that stem from regulations, laws, and guidelines—also known as compliance rules . Process-aware information systems have to ensure that respective compliance rules are obeyed in order to guarantee semantically correct and error-free execution as well as changes of their business processes. This chapter discusses how such compliance rules can be defined and how they can be ensured in the different phases of the process life cycle.",http://dx.doi.org/10.1007/978-3-642-30409-5_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-30409-5_4,Process Modeling and Flexibility-by-Design,Enabling Flexibility in Process-Aware Information Systems,10.1007/978-3-642-30409-5_4,Springer,2012-01-01,"This chapter deals with process models whose behavior can be prespecified at build-time and their run-time support in a PAIS. Usually, such a prespecified process model defines all activities to be executed, their control flow and data flow dependencies, organizational entities performing the activities, the data objects manipulated by them, and the application services invoked during their execution. The chapter gives insights into the modeling, execution, and verification of prespecified process models, and therefore serves as foundation of the subsequent chapters of this book. In particular, it introduces control flow patterns as major building blocks for creating process models and discusses how flexibility-by-design can be achieved using these patterns. Furthermore, the chapter explores the verification of process models and the assurance of their correct executability before deploying them to the PAIS run-time environment. Finally, it elaborates on the enactment of process instances and the coordination of corresponding activities at run-time as specified in the process model.",http://dx.doi.org/10.1007/978-3-642-30409-5_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11047-011-9252-2,Evolutionary high-dimensional QoS optimization for safety-critical utility communication networks,Natural Computing,10.1007/s11047-011-9252-2,Springer,2011-12-01,"This paper proposes and evaluates an evolutionary multiobjective optimization algorithm, called EVOLT , which heuristically optimizes quality of service (QoS) parameters in communication networks. EVOLT uses a population of individuals, each of which represents a set of QoS parameters, and evolves the individuals via genetic operators such as crossover, mutation and selection for satisfying given QoS requirements. For evaluating EVOLT in real-world settings that have high-dimensional parameter and optimization objective spaces, this paper focuses on QoS optimization in safety-critical communication networks for electric power utilities. Simulation results show that EVOLT outperforms a well-known existing evolutionary algorithm for multiobjective optimization and efficiently obtains quality QoS parameters with acceptable computational costs. Moreover, EVOLT visualizes obtained QoS parameters in a self-organizing map in order to aid network administrators to intuitively understand the QoS parameters and the tradeoffs among optimization objectives.",http://dx.doi.org/10.1007/s11047-011-9252-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10726-010-9221-7,Context-Sensitive Semantic Synchronization Enablement in Electronic Negotiations,Group Decision and Negotiation,10.1007/s10726-010-9221-7,Springer,2011-11-01,"When integrating electronic negotiations into real-world business processes, an important problem arising is the magnitude of e-business standards in use. In order to support electronic negotiations when negotiation partners use and need to integrate terms named and formatted according to different document standards, taxonomies or similar standards, references between those standards are needed. In this paper, we present a framework for a negotiation support meta-tool which is designed to maintain and dynamically evolve a collection of such references. To deal with semantic ambiguities in different contexts, it provides users with context-sensitive references. The framework uses technologies from ontological engineering and machine learning, its services can be integrated into existing negotiation applications via web services. Furthermore, it allows parameterzation for the actual domain of use.",http://dx.doi.org/10.1007/s10726-010-9221-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11066-011-9060-y,Spatial agent-based modeling of household and firm location with endogenous transport costs,NETNOMICS: Economic Research and Electronic Networking,10.1007/s11066-011-9060-y,Springer,2011-07-01,"The paper describes a spatial economic agent-based model (ABM), consistent with the principles of new economic geography (NEG), which allows the discrete-time evolutionary simulation of complex interactions of household and firm location choices. In contrast with the current ABM approaches, it considers a multi-regional (multi-urban) setting to enable a more realistic representation of decisions related to commuting, migration and firm (re)location. The model allows simulating spatially differentiated, multi-commodity markets for land and labor in a system of cities and the behavior of profit-maximizing firms with multi-regional asset investment decisions, incorporating endogenous transport costs with congestion effects. It also accounts for the impact of agglomeration forces on industrial location choices and the formation of urban development patterns. The conceptual framework and main components of the spatial ABM are presented and several implementation issues are discussed with regard to possible case-specific applications and policy scenarios.",http://dx.doi.org/10.1007/s11066-011-9060-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13278-010-0015-3,"Promoting where, when and what? An analysis of web logs by integrating data mining and social network techniques to guide ecommerce business promotions",Social Network Analysis and Mining,10.1007/s13278-010-0015-3,Springer,2011-07-01,"The rapid development of the internet introduced new trend of electronic transactions that is gradually dominating all aspects of our daily life. The amount of data maintained by websites to keep track of the visitors is growing exponentially. Benefitting from such data is the target of the study described in this paper. We investigate and explore the process of analyzing log data of website visitor traffic in order to assist the owner of a website in understanding the behavior of the website visitors. We developed an integrated approach that involves statistical analysis, association rules mining, and social network construction and analysis. First, we analyze the statistical data on the types of visitors that come to the website, as well as the steps they take to reach and satisfy the goal of their visit. Second, we derive association rules in order to identify the correlations between the web pages. Third, we study the links between the web pages by constructing a social network based on the frequency of access to the web pages such that two web pages get linked in the social network if they are identified as frequently accessed together. The value added from the overall analysis of the website and its related data should be considered valuable for ecommerce and commercial website owners; the owners will get the information needed to display targeted advertisements or messages to their customers. Such an automated approach gives advantage to its users in the current competitive cyberspace. In the long run, this is expected to allow for the increase in sales and overall customer loyalty.",http://dx.doi.org/10.1007/s13278-010-0015-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-011-0524-7,Designing adaptive learning itineraries using features modelling and swarm intelligence,Neural Computing and Applications,10.1007/s00521-011-0524-7,Springer,2011-07-01,"In this paper, Bayesian network (BN) and ant colony optimization (ACO) techniques are combined in order to find the best path through a graph representing all available itineraries to acquire a professional competence. The combination of these methods allows us to design a dynamic learning path, useful in a rapidly changing world. One of the most important advances in this work, apart from the variable amount of pheromones, is the automatic processing of the learning graph. This processing is carried out by the learning management system and helps towards understanding the learning process as a competence-oriented itinerary instead of a stand-alone course. The amount of pheromones is calculated by taking into account the results acquired in the last completed course in relation to the minimum score required and by feeding this into the learning tree in order to obtain a relative impact on the path taken by the student. A BN is used to predict the probability of success, by taking historical data and student profiles into account. Usually, these profiles are defined beforehand; however, in our approach, some characteristics of these profiles, such as the level of knowledge, are classified automatically through supervised and/or unsupervised learning. By using ACO and BN, a fitness function, responsible for automatically selecting the next course in the learning graph, is defined. This is done by generating a path which maximizes the probability of each user’s success on the course. Therefore, the path can change in order to adapt itself to learners’ preferences and needs, by taking into account the pedagogical weight of each learning unit and the social behaviour of the system.",http://dx.doi.org/10.1007/s00521-011-0524-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10799-011-0091-8,Distributed data mining for e-business,Information Technology and Management,10.1007/s10799-011-0091-8,Springer,2011-06-01,"In the internet-based e-business environment, most business data are distributed, heterogeneous and private. To achieve true business intelligence, mining large amounts of distributed data is necessary. Through a thorough literature review, this paper identifies four main issues in distributed data mining (DDM) systems for e-business and classifies modern DDM systems into three classes with representative samples. To address these identified issues, this paper proposes a novel DDM model named DRHPDM (Data source Relevance-based Hierarchical Parallel Distributed data mining Model). In addition, to improve the quality of the final result, the data sources are divided into a centralized mining layer and a distributed mining layer, according to their relevance. To improve the openness, cross-platform ability, and intelligence of the DDM system, web service and multi-agent technologies are adopted. The feasibility of DRHPDM was verified by building a prototype system and applying it to a web usage mining scenario.",http://dx.doi.org/10.1007/s10799-011-0091-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-011-0081-z,Ontology-driven service composition for end-users,Service Oriented Computing and Applications,10.1007/s11761-011-0081-z,Springer,2011-03-24,"Current service composition techniques and tools are mainly designed for use by Service-Oriented Architecture (SOA) professionals to solve business problems. Little attention has been paid to allowing end-users without sufficient service composition skills to compose services and integrate SOA solutions into their online experience to fulfill their daily activities. To shelter end-users from the complexity of service composition, we propose an approach which can compose services on the fly to meet the situational needs of end-users. We present a tag-based service description schema which allows non-IT professional users to easily understand the description of services and add their own descriptions using descriptive tags. Instead of requiring end-users to specify detailed steps for composition, the end-users only need to describe their goals using a few keywords. Our approach expands the meaning of a user’s goal using ontologies then derives a group of keywords to discover services in order to fulfill the goal. A prototype is developed as a proof of concept to show that our approach enables end-users to discover and compose services easily. We conduct a case study to evaluate the effectiveness of our approach that eases end-users to compose services without the knowledge of SOA technologies. The results of our case study show that our approach can effectively generate ad-hoc processes and discover services with relatively high precision and recall.",http://dx.doi.org/10.1007/s11761-011-0081-z,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-19460-3_3,Supervised Learning,Web Data Mining,10.1007/978-3-642-19460-3_3,Springer,2011-01-01,"Supervised learning has been a great success in real-world applications. It is used in almost every domain, including text and Web domains. Supervised learning is also called classification or inductive learning in machine learning. This type of learning is analogous to human learning from past experiences to gain new knowledge in order to improve our ability to perform real-world tasks. However, since computers do not have “experiences”, machine learning learns from data, which are collected in the past and represent past experiences in some real-world applications.",http://dx.doi.org/10.1007/978-3-642-19460-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-85820-3_1,Introduction to Recommender Systems Handbook,Recommender Systems Handbook,10.1007/978-0-387-85820-3_1,Springer,2011-01-01,"Recommender Systems (RSs) are software tools and techniques providing suggestions for items to be of use to a user. In this introductory chapter we briefly discuss basic RS ideas and concepts. Our main goal is to delineate, in a coherent and structured way, the chapters included in this handbook and to help the reader navigate the extremely rich and detailed content that the handbook offers.",http://dx.doi.org/10.1007/978-0-387-85820-3_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-85820-3_19,Social Tagging Recommender Systems,Recommender Systems Handbook,10.1007/978-0-387-85820-3_19,Springer,2011-01-01,"The new generation of Web applications known as (STS) is successfully established and poised for continued growth. STS are open and inherently social; features that have been proven to encourage participation. But while STS bring new opportunities, they revive old problems, such as information overload. Recommender Systems are well known applications for increasing the level of relevant content over the “noise” that continuously grows as more and more content becomes available online. In STS however, we face new challenges. Users are interested in finding not only content, but also tags and even other users. Moreover, while traditional recommender systems usually operate over 2-way data arrays, STS data is represented as a third-order tensor or a hypergraph with hyperedges denoting (user, resource, tag) triples. In this chapter, we survey the most recent and state-of-the-art work about a whole new generation of recommender systems built to serve STS.We describe (a) novel facets of recommenders for STS, such as user, resource, and tag recommenders, (b) new approaches and algorithms for dealing with the ternary nature of STS data, and (c) recommender systems deployed in real world STS. Moreover, a concise comparison between existing works is presented, through which we identify and point out new research directions.",http://dx.doi.org/10.1007/978-0-387-85820-3_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-92913-0_13,Ontologies and the Semantic Web,Handbook of Semantic Web Technologies,10.1007/978-3-540-92913-0_13,Springer,2011-01-01,"Ontologies have become a prominent topic in Computer Science where they serve as explicit conceptual knowledge models that make domain knowledge available to information systems. They play a key role in the vision of the Semantic Web where they provide the semantic vocabulary used to annotate websites in a way meaningful for machine interpretation. As studied in the context of information systems, ontologies borrow from the fields of symbolic knowledge representation in Artificial Intelligence, from formal logic and automated reasoning and from conceptual modeling in Software Engineering, while also building on Web-enabling features and standards. Although in Computer Science ontologies are a rather new field of study, certain accomplishments can already be reported from the current situation in ontology research. Web-compliant ontology languages based on a thoroughly understood theory of underlying knowledge representation formalisms have been and are being standardized for their widespread use across the Web. Methodological aspects about the engineering of ontologies are being studied, concerning both their manual construction and (semi)automated generation. Initiatives on “linked open data” for collaborative maintenance and evolution of community knowledge based on ontologies emerge, and the first semantic applications of Web-based ontology technology are successfully positioned in areas like semantic search, information integration, or Web community portals. This chapter will present ontologies as one of the major cornerstones of Semantic Web technology. It will first explain the notion of formal ontologies in Computer Science and will discuss the range of concrete knowledge models usually subsumed under this label. Next, the chapter surveys ontology engineering methods and tools, both for manual ontology construction and for the automated learning of ontologies from text. Finally, different kinds of usage of ontologies are presented and their benefits in various application scenarios illustrated.",http://dx.doi.org/10.1007/978-3-540-92913-0_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-85820-3_7,Context-Aware Recommender Systems,Recommender Systems Handbook,10.1007/978-0-387-85820-3_7,Springer,2011-01-01,"The importance of contextual information has been recognized by researchers and practitioners in many disciplines, including e-commerce personalization, information retrieval, ubiquitous and mobile computing, data mining, marketing, and management. While a substantial amount of research has already been performed in the area of recommender systems, most existing approaches focus on recommending the most relevant items to users without taking into account any additional contextual information, such as time, location, or the company of other people (e.g., for watching movies or dining out). In this chapter we argue that relevant contextual information does matter in recommender systems and that it is important to take this information into account when providing recommendations. We discuss the general notion of context and how it can be modeled in recommender systems. Furthermore, we introduce three different algorithmic paradigms – contextual prefiltering, post-filtering, and modeling – for incorporating contextual information into the recommendation process, discuss the possibilities of combining several contextaware recommendation techniques into a single unifying approach, and provide a case study of one such combined approach. Finally, we present additional capabilities for context-aware recommenders and discuss important and promising directions for future research.",http://dx.doi.org/10.1007/978-0-387-85820-3_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-20946-8_3,"Spam, Opinions, and Other Relationships: Towards a Comprehensive View of the Web Knowledge Discovery",Advanced Topics in Information Retrieval,10.1007/978-3-642-20946-8_3,Springer,2011-01-01,"“Web mining” or “Web Knowledge Discovery” is the analysis of web resources with data-mining techniques such as classification, clustering, association-rule or graph-structure methods. Its applications pervade much of the software web users interact with on a daily basis: search engines’ indexing and ranking choices, recommender systems’ recommendations, targeted advertising, and many others. An understanding of this fast-moving field is therefore a key component of digital information literacy for everyone and a useful and fascinating extension of knowledge and skills for Information Retrieval researchers and practitioners. This chapter proposes an integrating model of learning cycles involving data, information and knowledge, explains how this model subsumes Information Retrieval and Knowledge Discovery and relates them to one another. We illustrate the usefulness of this model in an introduction to web content/text mining, using the model to structure the activities in this form of Knowledge Discovery. We focus on spam detection, opinion mining and relation mining. The chapter aims at complementing other books and articles that focus on the computational aspects of web mining, by emphasizing the often-neglected context in which these computational analyses take place: the full cycle of Knowledge Discovery, which ranges from application understanding via data understanding, data preparation, modeling and evaluation to deployment.",http://dx.doi.org/10.1007/978-3-642-20946-8_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-85820-3_8,Evaluating Recommendation Systems,Recommender Systems Handbook,10.1007/978-0-387-85820-3_8,Springer,2011-01-01,"Recommender systems are now popular both commercially and in the research community, where many approaches have been suggested for providing recommendations. In many cases a system designer that wishes to employ a recommendation system must choose between a set of candidate approaches. A first step towards selecting an appropriate algorithm is to decide which properties of the application to focus upon when making this choice. Indeed, recommendation systems have a variety of properties that may affect user experience, such as accuracy, robustness, scalability, and so forth. In this paper we discuss how to compare recommenders based on a set of properties that are relevant for the application. We focus on comparative studies, where a few algorithms are compared using some evaluation metric, rather than absolute benchmarking of algorithms. We describe experimental settings appropriate for making choices between algorithms. We review three types of experiments, starting with an offline setting, where recommendation approaches are compared without user interaction, then reviewing user studies, where a small group of subjects experiment with the system and report on the experience, and finally describe large scale online experiments, where real user populations interact with the system. In each of these cases we describe types of questions that can be answered, and suggest protocols for experimentation. We also discuss how to draw trustworthy conclusions from the conducted experiments. We then review a large set of properties, and explain how to evaluate systems given relevant properties. We also survey a large set of evaluation metrics in the context of the properties that they evaluate.",http://dx.doi.org/10.1007/978-0-387-85820-3_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-8462-3_9,A Survey of Link Prediction in Social Networks,Social Network Data Analytics,10.1007/978-1-4419-8462-3_9,Springer,2011-01-01,"Link prediction is an important task for analying social networks which also has applications in other domains like, information retrieval, bioinformatics and e-commerce. There exist a variety of techniques for link prediction, ranging from feature-based classification and kernel-based method to matrix factorization and probabilistic graphical models. These methods differ from each other with respect to model complexity, prediction performance, scalability, and generalization ability. In this article, we survey some representative link prediction methods by categorizing them by the type of the models. We largely consider three types of models: first, the traditional (non-Bayesian) models which extract a set of features to train a binary classification model. Second, the probabilistic approaches which model the joint-probability among the entities in a network by Bayesian graphical models. And, finally the linear algebraic approach which computes the similarity between the nodes in a network by rank-reduced similarity matrices. We discuss various existing link prediction models that fall in these broad categories and analyze their strength and weakness. We conclude the survey with a discussion on recent developments and future research direction.",http://dx.doi.org/10.1007/978-1-4419-8462-3_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-92913-0_22,Semantic Web Services,Handbook of Semantic Web Technologies,10.1007/978-3-540-92913-0_22,Springer,2011-01-01,"In recent years, service-orientation has increasingly been adopted as one of the main approaches for developing complex distributed systems from reusable components called services. Realizing the potential benefits of this software engineering approach requires semiautomated and automated techniques as well as tools for searching or locating services, selecting the suitable ones, composing them into complex processes, resolving heterogeneity issues through process and data mediation, and reducing other tedious yet recurrent tasks with minimal manual effort. Just as semantics has brought significant benefits to search, integration, and analysis of data, it is also seen as a key to achieving a greater level of automation to service-orientation. This has led to research and development, as well as standardization efforts on Semantic Web Services. Activities related to Semantic Web Services have involved developing conceptual models or ontologies, algorithms, and engines that could support machines in semiautomatically or automatically discovering, selecting, composing, orchestrating, mediating, and executing services. This chapter provides an overview of the area after nearly a decade of research. The chapter presents the main principles and conceptual models proposed thus far, including OWL-S, Web Service Modeling Ontology (WSMO), and Semantic Annotations for WSDL (SAWSDL)/Managing End-to-End Operations-Semantics (METEOR-S), as well as recent approaches that provide lighter solutions and bring support for the increasingly popular Web APIs and RESTful services, like SA-REST, WSMO-Lite, and MicroWSMO. The chapter also describes the main engines and frameworks developed by the research community, including discovery engines, composition engines, and even integrated frameworks that are able to use these semantic descriptions of services to support some of the typical activities related to services and service-based applications. Next, the ideas and techniques described are illustrated through two use cases that integrate Semantic Web Services technologies within real-world applications. Finally, a set of key resources that would allow the reader to reach a greater understanding of the field is provided, and the main issues that will drive the future of Semantic Web Services (SWS) are outlined.",http://dx.doi.org/10.1007/978-3-540-92913-0_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-22720-2_68,Machine Learning Approach for Multiple Misbehavior Detection in VANET,Advances in Computing and Communications,10.1007/978-3-642-22720-2_68,Springer,2011-01-01,"The motivation behind Vehicular Ad Hoc Networks (VANETs) is to improve traffic safety and driving efficiency. VANET applications operate on the principle of periodic exchange of messages between nodes. However, a malicious node may transmit inaccurate messages to trigger inevitable situations. Each transmitted packet contains the status of sender like its identity, position and time of sending the packet in addition to safety message. A misbehaving node may tamper with any information present in the propagated packet. Fake messages may be created by attacker node itself or it may force another node to create fake messages. In this paper, we present a machine learning approach to classify multiple misbehaviors in VANET using concrete and behavioral features of each node that sends safety packets. A security framework is designed to differentiate a malicious node from legitimate node. We implement various types of misbehaviors in VANET by tampering information present in the propagated packet. These misbehaviors are classified based upon multifarious features like speed-deviation of node, received signal strength (RSS), number of packets delivered, dropped packets etc. Two types of classification accuracies are measured : Binary and Multi-Class. In Binary classification, all types of misbehaviors are considered to be in a single “misbehavior” class whereas, Multi-class classification is able to categorize misbehaviors into particular misbehaving classes. Features of packet sending nodes are extracted by performing experiments in NCTUns-5.0 simulator with different simulation scenario (varying the number of legitimate and misbehaving nodes). Proposed framework for classification of misbehavior is evaluated using WEKA. Our approach is efficient in classifying multiple misbehaviors present in VANET scenario. Experiment result shows that Random Forest and J-48 classifiers perform better compared to other classifiers.",http://dx.doi.org/10.1007/978-3-642-22720-2_68,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-92913-0_18,Knowledge Management in Large Organizations,Handbook of Semantic Web Technologies,10.1007/978-3-540-92913-0_18,Springer,2011-01-01,"This chapter provides an overview of the knowledge management (KM) problems, and opportunities, faced by large organizations, and indeed also shared by some smaller organizations. The chapter shows how semantic technologies can make a contribution. It looks at the key application areas: finding and organizing information; sharing knowledge; supporting processes, in particular informal processes; information integration; extracting knowledge from unstructured information; and finally sharing and reusing knowledge across organizations. In each application area, the chapter describes some solutions, either currently available or being researched. This is done to provide examples of what is possible rather than to provide a comprehensive list. The chapter also describes some of the technologies which contribute to these solutions; for example, text mining for analyzing documents or text within documents; and natural language processing for analyzing language itself and, for example, identifying named entities. Most fundamentally, the use of ontologies as a form of knowledge representation underlies everything talked about in the chapter. Ontologies offer great expressive power; they provide enormous flexibility, with the ability to evolve dynamically unlike database schema; and they make possible machine reasoning. The chapter concludes by identifying the key trends and describing the key challenges to be faced in the development of more powerful tools to support knowledge work.",http://dx.doi.org/10.1007/978-3-540-92913-0_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-540-92913-0_6,Semantic Annotation and Retrieval: Web of Data,Handbook of Semantic Web Technologies,10.1007/978-3-540-92913-0_6,Springer,2011-01-01,"The World Wide Web has radically altered the way knowledge is shared by lowering the barrier to publishing and accessing documents. Recent initiatives have extended the principles and architecture of the Web to sharing and accessing data, resulting in an interconnected, global data space – the Web of Data. This chapter reviews the historical and scientific context to the emergence of this Web of Data, before detailing the technologies and principles on which it is based. Applications that have been developed and deployed on the Web of Data are reviewed, as are key resources in the field. The chapter concludes with a discussion of current research challenges in areas such as user interfaces, data fusion, link maintenance, trust, and privacy.",http://dx.doi.org/10.1007/978-3-540-92913-0_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-79432-2_4,Linked Data Design Considerations,Linked Data,10.1007/978-3-031-79432-2_4,Springer,2011-01-01,"So far this book has introduced the basic principles of Linked Data (Chapter 2) and given an overview of how these principles are being applied to the publication of data from a wide variety of domains (Chapter 3). This chapter will discuss the primary design considerations that must be taken into account when preparing data to be published as Linked Data on the Web, before introducing specific publishing recipes in Chapter 5.",http://dx.doi.org/10.1007/978-3-031-79432-2_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-19797-0_13,Semantic Technologies and Cloud Computing,Foundations for the Web of Information and Services,10.1007/978-3-642-19797-0_13,Springer,2011-01-01,"Cloud computing has become a generic umbrella term for the flexible delivery of IT resources—such as storage, computing power, software development platforms, and applications—as services over the Internet. The foremost innovation is that the IT infrastructure no longer lies with the user, breaking up the previously monolithic ownership and administrative control of its assets. The combination of cloud computing and semantic technologies holds great potential. In this chapter, we analyze three ways in which cloud computing and semantic technologies can be combined: (1) building on cloud computing technologies, e.g. from the area of distributed computing, to realize better semantic applications and enable semantic technologies to scale to ever larger data sets, (2) delivering semantic technologies as services in the cloud, and (3) using semantic technologies to improve cloud computing, in particular to further improve automatic data-center management. For each of these dimensions we identify challenges and opportunities, provide a survey, and present a research roadmap.",http://dx.doi.org/10.1007/978-3-642-19797-0_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-16615-0_3,Data Mining Fundamentals,Multiobjective Genetic Algorithms for Clustering,10.1007/978-3-642-16615-0_3,Springer,2011-01-01,"To extract useful information from different types of vast data repositories, knowledge discovery and data mining have recently emerged as a significant research direction. A huge amount of data is nowadays being routinely collected as a consequence of widespread automation, which may be considered to be a major advantage of advanced data collection and storage technologies. However it creates the imperative need for developing methods to integrate and make sense out of this immense volume of data. Knowledge discovery from databases (KDD) evolved as a major research area where various fields of computer science such as databases, machine learning, pattern recognition, statistics, artificial intelligence, reasoning with uncertainty, expert systems, information retrieval, signal processing, high-performance computing and networking are involved.",http://dx.doi.org/10.1007/978-3-642-16615-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-23902-1_11,Future User Centric Media: Research Challenges and the Road Ahead,Ambient Media and Systems,10.1007/978-3-642-23902-1_11,Springer,2011-01-01,"This work presents relevant excerpts from two white papers recently published with the support of the Networked Media Unit of the European Commission, outlining a number of research challenges and the way ahead towards providing user centric media, as well as rich multimedia and multimodal content, via the Internet and Ambient Systems over the next decade. It will focus on key advances in Future Media technologies that will enable innovative applications and services, engaging new experiences, where multimedia digital content will be more immersive and closely related to the physical world. According to the consolidated opinion of international experts in the field, high quality research on these challenges will be able to enhance our communication experiences, as well as the way we work and live in the next future.",http://dx.doi.org/10.1007/978-3-642-23902-1_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-7735-9_8,Web Mining and Recommendation Systems,Web Mining and Social Networking,10.1007/978-1-4419-7735-9_8,Springer,2011-01-01,"In last chapter, we have selectively addressed several interesting topics onWeb community and social network detecting, forming and analysis, especially temporal and evolutionary analysis. We have discussed the motivations of such kinds of techniques, the algorithmic issues, and the experimental studies as well as the insightful findings and results. In this chapter, we will shift to another important application of Web data mining: Web recommendation.",http://dx.doi.org/10.1007/978-1-4419-7735-9_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-19394-1_11,Facilitating Enterprise Service Discovery for Non-technical Business Users,Service-Oriented Computing,10.1007/978-3-642-19394-1_11,Springer,2011-01-01,"Enterprise Services (ES) are Web services with which enterprise applications expose a subset of their functionality. Due to the often high number of different ES, as well as the complex nature of their names, it is difficult for non-technical business users to discover services in ES repositories. However, most of this complexity stems from a SOA governance-driven service design process that is essential to the development of harmonized and long-lasting ES. Based on the example of SAP’s ES, we describe a representational model that consolidates existing models and patterns used during the service design process. We created an iterative search approach that uses this consolidated metadata. The evaluation of the approach with real business users, based on a prototypical implementation, demonstrates that our iterative search is more efficient and effective than the currently offered search.",http://dx.doi.org/10.1007/978-3-642-19394-1_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-19724-6_2,Distributed Architectures for Event-Based Systems,Reasoning in Event-Based Distributed Systems,10.1007/978-3-642-19724-6_2,Springer,2011-01-01,"Event-driven distributed systems have two important characteristics, which differentiate them from other system types: the existence of several software or hardware components that run simultaneously on different inter-networked nodes, and the use of events as the main vehicle to organize component intercommunication. Clearly, both attributes influence event-driven distributed architectures, which are discussed in this chapter. We start with presenting the event-driven software architecture, which describes various logical components and their roles in events generation, transmission, processing, and consumption. This is used in early phases of distributed event-driven systems’ development as a blueprint for the whole development process including concept, design, implementation, testing, and maintenance. It also grounds important architectural concepts and highlights the challenges faced by event-driven distributed system developers. The core part of the chapter presents several system architectures, which capture the physical realization of event-driven distributed systems, more specifically the ways logical components are instantiated and placed on real machines. Important characteristics such as performance, efficient use of resources, fault tolerance, security, and others are strongly determined by the adopted system architecture and the technologies behind it. The most important research results are organized along five themes: complex event processing, Event-Driven Service Oriented Architecture (ED-SOA), Grid architecture, Peer-to-Peer (P2P) architecture, and Agent architecture. For each topic, we present previous work, describe the most recent achievements, highlight their advantages and limitations, and indicate future research trends in event-driven distributed system architectures.",http://dx.doi.org/10.1007/978-3-642-19724-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-009-9108-7,Evolutionary mechanism design: a review,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-009-9108-7,Springer,2010-09-01,"The advent of large-scale distributed systems poses unique engineering challenges. In open systems such as the internet it is not possible to prescribe the behaviour of all of the components of the system in advance. Rather, we attempt to design infrastructure, such as network protocols, in such a way that the overall system is robust despite the fact that numerous arbitrary, non-certified, third-party components can connect to our system. Economists have long understood this issue, since it is analogous to the design of the rules governing auctions and other marketplaces, in which we attempt to achieve socially-desirable outcomes despite the impossibility of prescribing the exact behaviour of the market participants, who may attempt to subvert the market for their own personal gain. This field is known as “mechanism design”: the science of designing rules of a game to achieve a specific outcome, even though each participant may be self-interested. Although it originated in economics, mechanism design has become an important foundation of multi-agent systems (MAS) research. In a traditional mechanism design problem, analytical methods are used to prove that agents’ game-theoretically optimal strategies lead to socially desirable outcomes. In many scenarios, traditional mechanism design and auction theory yield clear-cut results; however, there are many situations in which the underlying assumptions of the theory are violated due to the messiness of the real-world. In this paper we review alternative approaches to mechanism design which treat it as an engineering problem and bring to bear engineering design principles, viz.: iterative step-wise refinement of solutions, and satisficing instead of optimization in the face of intractable complexity. We categorize these approaches under the banner of evolutionary mechanism design.",http://dx.doi.org/10.1007/s10458-009-9108-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11235-009-9254-x,Geographic server distribution model for key revocation,Telecommunication Systems,10.1007/s11235-009-9254-x,Springer,2010-08-01,"Key management is one of the important issues in ensuring the security of network services. The aim of key management is to ensure availability of the keys at both the receiver’s and the sender’s ends. Key management involves two aspects: key distribution and key revocation. Key distribution involves the distribution of keys to various nodes with secrecy to provide authenticity and privacy. Key revocation involves securely and efficiently managing the information about the keys which have been compromised. This paper presents the geographic server distributed model for key revocation which concerns about the security and performance of the system. The concept presented in this paper is more reliable, faster and scalable than the existing Public Key Infrastructure (PKI) framework in various countries, as it provides optimization of key authentication in a network. It proposes auto-seeking of a geographically distributed certifying authority’s key revocation server, which holds the revocation lists by the client, based on the best service availability. The network is divided itself into the strongest availability zones (SAZ), which automatically allows the new receiver to update the address of the authentication server and replace the old address with the new address of the SAZ, in case it moves to another location in the zone, or in case the server becomes unavailable in the same zone. In this way, it reduces the time to gain information about the revocation list and ensures availability and, thus, improvement of the system as a whole. Hence, the proposed system results in scalable, reliable and faster PKI infrastructure and will be attractive for the users who frequently change their location in the network. Our scheme eases out the revocation mechanism and enables key revocation in the legacy systems. It discusses the architecture as well as the performance of our scheme as compared to the existing scheme. However, our scheme does not call for the entire change in PKI, but is compatible with the existing scheme. Our simulations show that the proposed scheme is better for key revocation.",http://dx.doi.org/10.1007/s11235-009-9254-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-009-9126-8,An adaptive QoS-aware fault tolerance strategy for web services,Empirical Software Engineering,10.1007/s10664-009-9126-8,Springer,2010-08-01,"Service-Oriented Architecture (SOA) is widely adopted for building mission-critical systems, ranging from on-line stores to complex airline management systems. How to build reliable SOA systems becomes a big challenge due to the compositional nature of Web services. This paper proposes an adaptive QoS-aware fault tolerance strategy for Web services. Based on a user-collaborated QoS-aware middleware, SOA systems can dynamically adjust their optimal fault tolerance configurations to achieve optimal service reliability as well as good overall performance. Both the subjective user requirements and the objective system performance of the Web services are considered in our adaptive fault tolerance strategy. Experiments are conducted to illustrate the advantages of the proposed adaptive fault tolerance strategy. Performance and effectiveness comparisons of the proposed adaptive fault tolerance strategy and various traditional fault tolerance strategies are also provided.",http://dx.doi.org/10.1007/s10664-009-9126-8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-16576-4_22,Agent-Augmented Co-Space: Toward Merging of Real World and Cyberspace,Autonomic and Trusted Computing,10.1007/978-3-642-16576-4_22,Springer,2010-01-01,"Co-Space refers to interactive virtual environment modelled after the real world we are situated in. Through realistic 3D modelling and animation technologies, Co-Space simulates the real world in terms of look-and-feel of our physical surrounding. With the advancement in pervasive sensor network, Co-Space may also capture and mirror the happening in the physical world in real time. The development of Co-Space thus offers great opportunities for delivering innovative applications and services. Specifically, for enriching the experience of users in Co-Space, it is essential to incorporate knowledge facilities in the form of intelligent agents to enhance the interactivity and playability within. This paper will begin with a brief review of this emerging field of work related to agents in virtual worlds and integrated cognitive architectures. We then discuss the key requirement, issues and challenges in making Co-Space interactive and intelligent. Following the notion of embodied intelligence, we propose to develop cognitive agents, based on a family of self-organizing neural models, known as fusion Adaptive Resonance Theory (fusion ART). Our ultimate aim is to have such agents roaming freely in the landscape of Co-Space, developing an awareness of its surrounding and interacting with avatars of real human. As an illustration, a case study of our effort in building the Singapore Youth Olympic Village (YOV) Co-Space will be presented.",http://dx.doi.org/10.1007/978-3-642-16576-4_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4419-7335-1_10,Information Pre-Processing using Domain Meta-Ontology and Rule Learning System,Canadian Semantic Web,10.1007/978-1-4419-7335-1_10,Springer,2010-01-01,"Around the globe, extraordinary amounts of documents are being created by Enterprises and by users outside these Enterprises. The documents created in the Enterprises constitute the main focus of the present chapter. These documents are used to perform numerous amounts of machine processing. While using thesedocuments for machine processing, lack of semantics of the information in these documents may cause misinterpretation of the information, thereby inhibiting the productiveness of computer assisted analytical work. Hence, it would be profitable to the Enterprises if they use well defined domain ontologies which will serve as rich source(s) of semantics for the information in the documents. These domain ontologies can be created manually, semi-automatically or fully automatically. The focus of this chapter is to propose an intermediate solution which will enable relatively easy creation of these domain ontologies. The process of extracting and capturing domain ontologies from these voluminous documents requires extensive involvement of domain experts and application of methods of ontology learning that are substantially labor intensive; therefore, some intermediate solutions which would assist in capturing domain ontologies must be developed. This chapter proposes a solution in this direction which involves building a meta-ontology that will serve as an intermediate information source for the main domain ontology. This chapter proposes a solution in this direction which involves building a meta-ontology as a rapid approach in conceptualizing a domain of interest from huge amount of source documents. This meta-ontology can be populated by ontological concepts, attributes and relations from documents, and then refined in order to form better domain ontology either through automatic ontology learning methods or some other relevant ontology building approach.",http://dx.doi.org/10.1007/978-1-4419-7335-1_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-14435-6_2,Hybrid Multi-Agent Systems,Innovations in Multi-Agent Systems and Applications - 1,10.1007/978-3-642-14435-6_2,Springer,2010-01-01,Hybrid systems have grown tremendously in the past few years due to their abilities to offset the demerits of one technique by the merits of another. This chapter presents a number of computational intelligence techniques which are useful in the implementation of hybrid multi-agent systems. A brief review of the applications of the hybrid multi-agent systems is presented.,http://dx.doi.org/10.1007/978-3-642-14435-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-11224-9_2,Fuzzy ECA Rules for Pervasive Decision-Centric Personalised Mobile Learning,Computational Intelligence for Technology Enhanced Learning,10.1007/978-3-642-11224-9_2,Springer,2010-01-01,"This chapter addresses personalisation in intelligent context-aware information systems. A personalized mobile learning system can be viewed as an information system related to the domain of education. Personalization requires the identification and selection of individuals; this can be achieved using an individual’s profile (termed context). A context is inherently complex, its effective use representing a challenge that has to date not been adequately addressed. This chapter considers this challenge, identifies context-aware systems as intrinsically decision-centric, and introduces Fuzzy Event:Condition:Action (FEAC) rules as an effective approach to enable deterministic computational intelligence to be applied in intelligent context-aware personalised mobile learning systems. The FECA rules algorithm is presented with example implementations, an evaluation, and proof-of-concept. The chapter closes with a discussion, conclusions, open research questions, and consideration of future directions for future work.",http://dx.doi.org/10.1007/978-3-642-11224-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-15606-9_12,Collective Intelligence in Marketing,Marketing Intelligent Systems Using Soft Computing,10.1007/978-3-642-15606-9_12,Springer,2010-01-01,"As marketing professionals communicate value and manage customer relationships, they must target changing markets, and personalize offers to individual customers. With the recent adoption of large-scale, Internet-based information systems, marketing professionals now face large volumes of complex data, including detailed purchase and service transactions, social network links, click streams, blogs, comments and inquiries. While traditional marketing methodologies struggled to produce actionable insights from such information quickly, emerging collective intelligence techniques enable marketing professionals to understand and act on the observed behaviors, preferences and ideas of groups of people. Marketing professionals apply collective intelligence technology to create behavioral models and apply them for targeting and personalization. As they analyze preferences, match products to customers, discover groups of similar consumers, and construct pricing models, they generate significant competitive advantage. In this chapter, we highlight publications of interest, describe analytic processes, review techniques, and present a case study of matching products to customers.",http://dx.doi.org/10.1007/978-3-642-15606-9_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-0-387-30164-8_705,Recommender Systems,Encyclopedia of Machine Learning,10.1007/978-0-387-30164-8_705,Springer,2010-01-01,,http://dx.doi.org/10.1007/978-0-387-30164-8_705,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-0-387-30164-8_827,Text Mining for News and Blogs  Analysis,Encyclopedia of Machine Learning,10.1007/978-0-387-30164-8_827,Springer,2010-01-01,,http://dx.doi.org/10.1007/978-0-387-30164-8_827,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-12433-4_34,e-Wedding Based on Multi-agent System,Trends in Practical Applications of Agents and Multiagent Systems,10.1007/978-3-642-12433-4_34,Springer,2010-01-01,"Multi-agent system is continuously utilized in e-Business that want to improve responsiveness and efficiency of systems. In this paper, we propose multi-agent-system and various techniques that are Web service, ontology, and data mining techniques. The multi agent system, which constitutes the backbone of the framework, connects these pieces together and makes them perform properly. JADE is the MAS platform implemented this project. JADE is quite easy to learn and use. Moreover, it supports many agent approaches such as agent communication, protocol, behavior and ontology. This framework has been experimented and evaluated in the realization of a simple, but realistic, prototype of an e-Wedding system. The results, though still preliminary, are quite encouraging.",http://dx.doi.org/10.1007/978-3-642-12433-4_34,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-14400-4_49,Event Prediction in Network Monitoring Systems: Performing Sequential Pattern Mining in Osmius Monitoring Tool,Advances in Data Mining. Applications and Theoretical Aspects,10.1007/978-3-642-14400-4_49,Springer,2010-01-01,"Event prediction is one of the most challenging problems in network monitoring systems. This type of inductive knowledge provides monitoring systems with valuable real time predictive capabilities. By obtaining this knowledge, system and network administrators can anticipate and prevent failures. In this paper we present a prediction module for the monitoring software Osmius ( www.osmius.net ). Osmius has been developed by Peopleware ( peopleware.es ) under GPL licence. We have extended the Osmius database to store the knowledge we obtain from the algorithms in a highly parametrized way. Thus system administrators can apply the most appropriate settings for each system. Results are presented in terms of positive predictive values and false discovery rates over a huge event database. They confirm that these pattern mining processes will provide network monitoring systems with accurate real time predictive capabilities.",http://dx.doi.org/10.1007/978-3-642-14400-4_49,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-09751-0_25,P2P Reputation Management Through Social Networking,Handbook of Peer-to-Peer Networking,10.1007/978-0-387-09751-0_25,Springer,2010-01-01,"Reputation systems offer a viable solution to the problem of risk reduction in online communities, in situation in which other mechanism such as litigation or security cannot help. Building on the assumption that its participating entities engage in repeated interactions, a reputation system can either signal what happened in the past or aggregate the past feedback in such a way as to influence the future actions of the concerned entity. In the former case, the concerned entity’s behavior is seen as static, while the sent signal is expected to be indicative of the entity’s future actions. In the latter case, behavior is dynamic in the sense that the entity can adjust it given the observed feedback, while the purpose of the reputation system is to induce adjustments according to the designer’s needs. In this chapter, we discuss these two classes of solutions in detail. In particular, we investigate how they apply to P2P networks, what additional problems and difficulties the P2P environment introduces and what scalable solutions to these problems the current research offers.",http://dx.doi.org/10.1007/978-0-387-09751-0_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-1278-7_6,System Assessment and Evaluation,Infectious Disease Informatics,10.1007/978-1-4419-1278-7_6,Springer,2010-01-01,"Knowing how systems perform under various scenarios is important. We need to examine with which level of sensitivity and how quickly they can detect an outbreak or recognize a bioterrorism attack. Knowing the error rate of a system can help make decisions regarding how much effort is needed to investigate an alarm. The performance of the algorithms for outbreak characterization determines the amount of information they provide (e.g., sets of affected individuals, the outbreak size, and disease spreading rate), which provide important input for response planning. Substantial costs can be incurred when developing or managing syndromic surveillance systems and investigating possible outbreaks based on the outputs of these systems (Reingold, 2003). For example, as reported in (Doroshenko et al., 2005), the annual cost of the NHS Direct Syndromic Surveillance System is about $280,000 and the usefulness of surveillance systems for early detection and response is yet to be established. Assessing the performance of surveillance systems is of significant importance for improving the efficacy of the investment in system development and management (Buehler et al., 2004).",http://dx.doi.org/10.1007/978-1-4419-1278-7_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-1-4419-7335-1_6,Semantic Service Matchmaking in the ATM Domain Considering Infrastructure Capability Constraints,Canadian Semantic Web,10.1007/978-1-4419-7335-1_6,Springer,2010-01-01,"In a service-oriented environment business processes flexibly build on software services provided by systems in a network. A key design challenge is the semantic matchmaking of business processes and software services in two steps: 1. Find for one business process the software services that meet or exceed the BP requirements; 2. Find for all business processes the software services that can be implemented within the capability constraints of the underlying network, which poses a major problem since even for small scenarios the solution space is typically very large. In this chapter we analyze requirements from mission-critical business processes in the Air Traffic Management (ATM) domain and introduce an approach for semi-automatic semantic matchmaking for software services, the “System-Wide Information Sharing” (SWIS) business process integration framework. A tool-supported semantic matchmaking process like SWIS can provide system designers and integrators with a set of promising software service candidates and therefore strongly reduces the human matching effort by focusing on a much smaller space of matchmaking candidates. We evaluate the feasibility of the SWIS approach in an industry use case from the ATM domain.",http://dx.doi.org/10.1007/978-1-4419-7335-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15141-5_12,Proximal Business Intelligence on the Semantic Web,Sustainable e-Business Management,10.1007/978-3-642-15141-5_12,Springer,2010-01-01,"Ubiquitous information systems (UBIS) extend current Information System thinking to explicitly differentiate technology between devices and software components with relation to people and process. Adapting business data and management information to support specific user actions in context is an ongoing topic of research. Approaches typically focus on providing mechanisms to improve specific information access and transcoding but not on how the information can be accessed in a mobile, dynamic and ad-hoc manner. Although web ontology has been used to facilitate the loading of data warehouses, less research has been carried out on ontology based mobile reporting. This paper explores how business data can be modeled and accessed using the web ontology language and then re-used to provide the invisibility of pervasive access; uncovering more effective architectural models for adaptive information system strategies of this type. This exploratory work is guided in part by a vision of business intelligence that is highly distributed, mobile and fluid, adapting to sensory understanding of the underlying environment in which it operates. A proof-of-concept mobile and ambient data access architecture is developed in order to further test the viability of such an approach. The paper concludes with an ontology engineering framework for systems of this type – named UBIS-ONTO.",http://dx.doi.org/10.1007/978-3-642-15141-5_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-84996-238-4_7,From Collaborative to Privacy-Preserving Sequential Pattern Mining,Privacy and Anonymity in Information Management Systems,10.1007/978-1-84996-238-4_7,Springer,2010-01-01,"Research in the areas of privacy-preserving techniques in databases and subsequently in privacy enhancement technologies has witnessed an explosive growth spurt in recent years. This escalation has been fueled primarily by the growing mistrust of individuals toward organizations collecting and disbursing their personally identifiable information (PII). Digital repositories have become increasingly susceptible to intentional or unintentional abuse, resulting in organizations to be liable under the privacy legislations that are increasingly being adopted by governments the world over. These privacy concerns have necessitated new advancements in the field of distributed data mining, wherein collaborating parties may be legally bound not to reveal the private information of their customers. In this chapter, first we present the sequential pattern discovery problem in a collaborative framework and subsequently enhance the architecture by introducing the context of privacy. Thus we propose to extract sequential patterns from distributed databases while preserving privacy. A salient feature of the proposal is its flexibility and as a result is more pertinent to mining operations for real-world applications in terms of efficiency and functionality. Furthermore, under some reasonable assumptions, we prove that the architecture and protocol employed by our algorithm for multi-party computation is secure. Finally, we conclude with some trends of current research being conducted in the field.",http://dx.doi.org/10.1007/978-1-84996-238-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-15346-4_9,Transformative and Innovative E-Gov for the Next Generation: Linkages of Back Offices for One-Stop Portal,"E-Government, E-Services and Global Processes",10.1007/978-3-642-15346-4_9,Springer,2010-01-01,"It is imperative that e-Gov platform for the next generation achieves integrative administrative services via citizen’s one-stop portal and back-office linkages among ministries and external organizations. This objective aims to make further advancement in system integration and coordination by employing cloud computing and service-oriented architecture (SOA). To achieve these goals, expertise knowledge must be provided as well-organized citizen services, for which e-Gov platform should be built upon loose-coupling of databases. Japan’s e-Gov policy has addressed these needs and designed its national service platform using master registry for standardized metadata, which is the first attempt in the world. This paper discusses the objectives of Japan’s e-Gov policy, the architecture of one-stop service platform, and its evolutionary process of back-office linkages using common registry. It is proposed to manage metadata in labor saving manners according to a matrix of operation and disclosure classes via pre/post-process filters assigned.",http://dx.doi.org/10.1007/978-3-642-15346-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-93808-0_38,Data Mining for User Modeling and Personalization in Ubiquitous Spaces,Handbook of Ambient Intelligence and Smart Environments,10.1007/978-0-387-93808-0_38,Springer,2010-01-01,"User modeling (UM) has traditionally been concerned with analyzing a user’s interaction with a system and with developing cognitive models that aid in the design of user interfaces and interaction mechanisms. Elements of a user model may include representation of goals, plans, preferences, tasks, and/or abilities about one or more types of users, classification of a user into subgroups or stereotypes, the formation of assumptions about the user based on the interaction history, and the generalization of the interaction histories of many users into groups, among many others.",http://dx.doi.org/10.1007/978-0-387-93808-0_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-7142-5_10,Discovering Mobile Social Networks by Semantic Technologies,Handbook of Social Network Technologies and Applications,10.1007/978-1-4419-7142-5_10,Springer,2010-01-01,"It has been important for telecommunication companies to discover social networks from mobile subscribers. They have attempted to provide a number of recommendation services, but they realized that the services were not successful. In this chapter, we present semantic technologies for discovering social networks. The process is mainly composed of two steps; (1) profile identification and (2) context understanding. Through developing a Next generation Contents dElivery (NICE) platform, we were able to generate various services based on the discovered social networks.",http://dx.doi.org/10.1007/978-1-4419-7142-5_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-04117-4_7,Bio-Cryptography,Handbook of Information and Communication Security,10.1007/978-3-642-04117-4_7,Springer,2010-01-01,"Cryptography is the backbone upon which modern security has been established. For authentication, conventional cryptography depends on either secret knowledge such as passwords or possession of tokens. The fundamental problem of such mechanisms is that they cannot authenticate genuine users. Biometrics such as fingerprints, faces, irises, etc., are considered as uniquely linked to individuals and hence are powerful in authenticating people. However, biometric systems themselves are not attackproof and are vulnerable against several types of attacks. An emerging solution is to integrate the authentication feature of biometrics and the core function of conventional cryptography, called biocryptography. This chapter is designed to provide a comprehensive reference for this topic. The work is based on many publications which includes our own work in this field. This chapter also provides suitable background knowledge so that it is not only suitable for a research reference but also for a textbook targeting senior undergraduates and postgraduates with a major in security. The organization of this chapter is as follows. Section 7.1 provides background materials on cryptography. Section 7.2 introduces the concept of biometrics technology and its applications. Section 7.3 discusses the issue of protecting biometric systems using bio-cryptography techniques. Section 7.4 is dedicated to conclusions.",http://dx.doi.org/10.1007/978-3-642-04117-4_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11761-009-0052-9,A hierarchical framework for logical composition of web services,Service Oriented Computing and Applications,10.1007/s11761-009-0052-9,Springer,2009-11-17,"Automatically composing Web services to form processes in the context of service-oriented architectures has attracted significant research. Prevalent approaches for automatically composing Web services predominantly utilize planning techniques to achieve the composition. However, classical planning based approaches face the following challenges: (i) difficulty in modeling the uncertainty of Web service invocations, (ii) inability to optimize the composition using non-functional parameters, and (iii) difficulty in scaling efficiently to large compositions. In order to address these issues, we present a hierarchical framework for logically composing Web services, which we call Haley . In comparison to classical planners, Haley utilizes decision-theoretic planning that is able to model and reason with the uncertainty inherent in Web service invocations and provides an expected cost-based optimization. Haley uses symbolic planning techniques that operate directly on first-order logic based representations of the state space to obtain the compositions. Consequently, it supports automated elicitation of the corresponding planning problem from Web service descriptions and produces a domain representation that is more compact than that of classical planners. Furthermore, it promotes scalability by exploiting the natural hierarchy found in real-world processes. Due to the limitations of the existing approaches and the complexity of the Web service composition problem, few implemented tools exist, although many approaches have been proposed in the literature. We have implemented Haley and provided a comprehensive tool suite for composing Web services. The suite operates on Web services described using well-known languages such as SAWSDL. It provides process designers with an intuitive interface to specify composition requirements, goals and a hierarchical decomposition if available, and automatically generates BPEL compositions while hiding the complexity of the planning and of BPEL from users.",http://dx.doi.org/10.1007/s11761-009-0052-9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10845-008-0145-x,Data mining in manufacturing: a review based on the kind of knowledge,Journal of Intelligent Manufacturing,10.1007/s10845-008-0145-x,Springer,2009-10-01,"In modern manufacturing environments, vast amounts of data are collected in database management systems and data warehouses from all involved areas, including product and process design, assembly, materials planning, quality control, scheduling, maintenance, fault detection etc. Data mining has emerged as an important tool for knowledge acquisition from the manufacturing databases. This paper reviews the literature dealing with knowledge discovery and data mining applications in the broad domain of manufacturing with a special emphasis on the type of functions to be performed on the data. The major data mining functions to be performed include characterization and description, association, classification, prediction, clustering and evolution analysis. The papers reviewed have therefore been categorized in these five categories. It has been shown that there is a rapid growth in the application of data mining in the context of manufacturing processes and enterprises in the last 3 years. This review reveals the progressive applications and existing gaps identified in the context of data mining in manufacturing. A novel text mining approach has also been used on the abstracts and keywords of 150 papers to identify the research gaps and find the linkages between knowledge area, knowledge type and the applied data mining tools and techniques.",http://dx.doi.org/10.1007/s10845-008-0145-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-009-9065-5,Log file analysis for disengagement detection in e-Learning environments,User Modeling and User-Adapted Interaction,10.1007/s11257-009-9065-5,Springer,2009-10-01,"Most e-Learning systems store data about the learner’s actions in log files, which give us detailed information about learner behaviour. Data mining and machine learning techniques can give meaning to these data and provide valuable information for learning improvement. One area that is of particular importance in the design of e-Learning systems is learner motivation as it is a key factor in the quality of learning and in the prevention of attrition. One aspect of motivation is engagement, a necessary condition for effective learning. Using data mining techniques for log file analysis, our research investigates the possibility of predicting users’ level of engagement, with a focus on disengaged learners. As demonstrated previously across two different e-Learning systems, HTML-Tutor and iHelp, disengagement can be predicted by monitoring the learners’ actions (e.g. reading pages and taking test/quizzes). In this paper we present the findings of three studies that refine this prediction approach. Results from the first study show that two additional reading speed attributes can increase the accuracy of prediction. The second study suggests that distinguishing between two different patterns of disengagement (spending a long time on a page/test and browsing quickly through pages/tests) may improve prediction in some cases. The third study demonstrates the influence of exploratory behaviour on prediction, as most users at the first login familiarize themselves with the system before starting to learn.",http://dx.doi.org/10.1007/s11257-009-9065-5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-009-9154-3,Design of an RFID-based Healthcare Management System using an Information System Design Theory,Information Systems Frontiers,10.1007/s10796-009-9154-3,Springer,2009-09-01,"This design science research study describes the design and development of a Radio Frequency Identification (RFID)-based Healthcare Management System (RHMS) for the healthcare industry. We examined the use of RFID technology as the key enabler for building the RHMS to deliver higher business values and provide effective support in transforming and optimizing healthcare practices in the industry. In this study, a prototype RHMS was built and implemented in a quasi-real world setting. The results validate the practical viability of the proposed system architecture. We show that the Information System Design Theory used to develop the RHMS could form the basis for further research. We hope the proposed system architecture and the developed prototype system from this study will help support and further the efforts of both academics and practitioners in RFID research.",http://dx.doi.org/10.1007/s10796-009-9154-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11280-008-0049-x,An Operable Email Based Intelligent Personal Assistant,World Wide Web,10.1007/s11280-008-0049-x,Springer,2009-06-01,"The recent phenomena of email-function-overloading and email-centricness in daily life and business have created new problems to users. There is a practical need for developing a software assistant to facilitate the management of personal and organizational emails, and to enable users to complete their email-centric jobs or tasks smoothly. This paper presents the status, goals, and key technical elements of an Email-Centric Intelligent Personal Assistant, called ECIPA. ECIPA provides various assisting functions, including automated and cost-sensitive spam filtering based on corresponding analysis, ontology-mediated email classification, query and archiving. ECIPA can learn from dynamic user behaviors to effectively sort and automatically respond email. Techniques developed in Web Intelligence (WI) are adopted to implement ECIPA. In order to facilitate cooperation of ECIPAs of different users, the concept of operable email , an extension of traditional email with an operable form, is introduced. ECIPA can in fact be viewed as a family of collaborative agents working together on the operable email.",http://dx.doi.org/10.1007/s11280-008-0049-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-009-9693-4,An Architectural Framework and Enabling Wireless Technologies for Digital Cities & Intelligent Urban Environments,Wireless Personal Communications,10.1007/s11277-009-9693-4,Springer,2009-05-01,"The digital revolution that has been taking place for the past two decades propelled by major breakthroughs in the ICT field has changed the way we communicate, work, travel, live—and even the way we use public space. Our cities are increasingly moving from a collection of static buildings and infrastructures to dynamic and evolving smart ecosystems known as, Intelligent Cities . In this article we analyze an intelligent city from the electronic information and communication perspective and offer examples of variants of its implementation. An intelligent city lays its foundation on a digital-city infrastructure which connects a local community and drives growth, efficiency, productivity, and competitiveness. The high level architecture of an intelligent city ecosystem, key enabling technologies, and the necessary policy framework for the establishment of digital cities worldwide are introduced. Business models for this new ecosystem bridging the physical and virtual worlds are briefly discussed.",http://dx.doi.org/10.1007/s11277-009-9693-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11257-008-9048-y,Case-studies on exploiting explicit customer requirements in recommender systems,User Modeling and User-Adapted Interaction,10.1007/s11257-008-9048-y,Springer,2009-02-01,"Recommender Systems (RS) suggest useful and interesting items to users in order to increase user satisfaction and online conversion rates. They typically exploit explicit or implicit user feedback such as ratings, buying records or clickstream data and apply statistical methods to derive recommendations. This paper focuses on explicitly formulated customer requirements as the sole type of user feedback. Its contribution lies in comparing different techniques such as knowledge- and utility-based methods, collaborative filtering, association rule mining as well as hybrid variants when user models consist solely of explicit customer requirements. We examine how this type of user feedback can be exploited for personalization in e-commerce scenarios. Furthermore, examples of actual online shops are developed where such contextual user information is available, demonstrating how more efficient RS configurations can be implemented. Results indicate that, especially for new users, explicit customer requirements are a useful source of feedback for personalization and hybrid configurations of collaborative and knowledge-based techniques achieve best results.",http://dx.doi.org/10.1007/s11257-008-9048-y,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10618-008-0114-1,Controlled experiments on the web: survey and practical guide,Data Mining and Knowledge Discovery,10.1007/s10618-008-0114-1,Springer,2009-02-01,"The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person’s Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments.",http://dx.doi.org/10.1007/s10618-008-0114-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-0522-2_1,Introduction to Agent Mining Interaction and Integration,Data Mining and Multi-agent Integration,10.1007/978-1-4419-0522-2_1,Springer,2009-01-01,"In recent years, more and more researchers have been involved in research on both agent technology and data mining. A clear disciplinary effort has been activated toward removing the boundary between them, that is the interaction and integration between agent technology and data mining. We refer this to agent mining as a new area. The marriage of agents and data mining is driven by challenges faced by both communities, and the need of developing more advanced intelligence, information processing and systems. This chapter presents an overall picture of agent mining from the perspective of positioning it as an emerging area. We summarize the main driving forces, complementary essence, disciplinary framework, applications, case studies, and trends and directions, as well as brief observation on agent-driven data mining, data mining-driven agents, and mutual issues in agent mining. Arguably, we draw the following conclusions: (1) agent mining emerges as a new area in the scientific family, (2) both agent technology and data mining can greatly benefit from agent mining, (3) it is very promising to result in additional advancement in intelligent information processing and systems. However, as a new open area, there are many issues waiting for research and development from theoretical, technological and practical perspectives.",http://dx.doi.org/10.1007/978-1-4419-0522-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04342-0_2,Protecting a Moving Target: Addressing Web Application Concept Drift,Recent Advances in Intrusion Detection,10.1007/978-3-642-04342-0_2,Springer,2009-01-01,"Because of the ad hoc nature of web applications, intrusion detection systems that leverage machine learning techniques are particularly well-suited for protecting websites. The reason is that these systems are able to characterize the applications’ normal behavior in an automated fashion. However, anomaly-based detectors for web applications suffer from false positives that are generated whenever the applications being protected change. These false positives need to be analyzed by the security officer who then has to interact with the web application developers to confirm that the reported alerts were indeed erroneous detections. In this paper, we propose a novel technique for the automatic detection of changes in web applications, which allows for the selective retraining of the affected anomaly detection models. We demonstrate that, by correctly identifying legitimate changes in web applications, we can reduce false positives and allow for the automated retraining of the anomaly models. We have evaluated our approach by analyzing a number of real-world applications. Our analysis shows that web applications indeed change substantially over time, and that our technique is able to effectively detect changes and automatically adapt the anomaly detection models to the new structure of the changed web applications.",http://dx.doi.org/10.1007/978-3-642-04342-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-00909-9_3,Development of an Intelligent Facial Expression Recognizer for Mobile Applications,New Advances in Intelligent Decision Technologies,10.1007/978-3-642-00909-9_3,Springer,2009-01-01,"In the light of fast pace smart phone development, increasing numbers of applications are being developed to cater for portability. A real-time facial expression recognition application is develop that was tested in Windows Mobile environment. The underlying algorithm adopted in this work uses Boosting Naïve Bayesian (BNB) approach for recognition. We examine the structure of training data and the effect of attributes on the class probabilities through the use of Naïve Bayesian classifier (NBC). The experiments carried out show that we have achieved the important features of mobile application: speed and efficiency. This work is believed to be the first recorded initiative that de-ploys facial expression recognition into a mobile phone. It seeks to provide a launching point for a sound and portable mobile application that is capable of recognizing different facial expressions.",http://dx.doi.org/10.1007/978-3-642-00909-9_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-04468-7_26,Establishing a Framework for Dynamic Risk Management in ‘Intelligent’ Aero-Engine Control,"Computer Safety, Reliability, and Security",10.1007/978-3-642-04468-7_26,Springer,2009-01-01,"The behaviour of control functions in safety critical software systems is typically bounded to prevent the occurrence of known system level hazards. These bounds are typically derived through safety analyses and can be implemented through the use of necessary design features. However, the unpredictability of real world problems can result in changes in the operating context that may invalidate the behavioural bounds themselves, for example, unexpected hazardous operating contexts as a result of failures or degradation. For highly complex problems it may be infeasible to determine the precise desired behavioural bounds of a function that addresses or minimises risk for hazardous operation cases prior to deployment. This paper presents an overview of the safety challenges associated with such a problem and how such problems might be addressed. A self-management framework is proposed that performs on-line risk management. The features of the framework are shown in context of employing intelligent adaptive controllers operating within complex and highly dynamic problem domains such as Gas-Turbine Aero Engine control. Safety assurance arguments enabled by the framework necessary for certification are also outlined.",http://dx.doi.org/10.1007/978-3-642-04468-7_26,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-84800-356-9_9,Capturing Trust in Social Web Applications,Computing with Social Trust,10.1007/978-1-84800-356-9_9,Springer,2009-01-01,"The Social Web constitutes a shift in information flow from the traditional Web. Previously, content was provided by the owners of a website, for consumption by the end-user. Nowadays, these websites are being replaced by Social Web applications which are frameworks for the publication of user-provided content. Traditionally, Web content could be ‘trusted’ to some extent based on the site it originated from. Algorithms such as Google’s PageRank were (and still are) used to compute the importance of a website, based on analysis of underlying link topology. In the Social Web, analysis of link topology merely tells us about the importance of the information framework which hosts the content. Consumers of information still need to know about the importance/reliability of the content they are reading, and therefore about the reliability of the producers of that content. Research into trust and reputation of the producers of information in the Social Web is still very much in its infancy. Every day, people are forced to make trusting decisions about strangers on the Web based on a very limited amount of information. For example, purchasing a product from an eBay seller with a ‘reputation’ of 99%, downloading a file from a peer-to-peer application such as Bit-Torrent, or allowing Amazon.com tell you what products you will like. Even something as simple as reading comments on a Web-blog requires the consumer to make a trusting decision about the quality of that information. In all of these example cases, and indeed throughout the Social Web, there is a pressing demand for increased information upon which we can make trusting decisions. This chapter examines the diversity of sources from which trust information can be harnessed within Social Web applications and discusses a high level classification of those sources. Three different techniques for harnessing and using trust from a range of sources are presented. These techniques are deployed in two sample Social Web applications—a recommender system and an online auction. In all cases, it is shown that harnessing an increased amount of information upon which to make trust decisions greatly enhances the user experience with the Social Web application.",http://dx.doi.org/10.1007/978-1-84800-356-9_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-00282-3_2,Ontologies,Model Driven Engineering and Ontology Development,10.1007/978-3-642-00282-3_2,Springer,2009-01-01,"The word “ontology” ontology comes from the Greek ontos, for “being,” and logos, for “word.” In philosophy, it refers to the subject of existence, i.e., the study of being as such. More precisely, it is the study of the categories of things that exist or may exist in some domain (Sowa 2000). A domain ontology explains the types of things in that domain.",http://dx.doi.org/10.1007/978-3-642-00282-3_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01347-8_27,Knowledge Reuse in Data Mining Projects and Its Practical Applications,Enterprise Information Systems,10.1007/978-3-642-01347-8_27,Springer,2009-01-01,"The objective of this paper is providing an integrated environment for knowledge reuse in KDD, for preventing recurrence of known errors and reinforcing project successes, based on previous experience. It combines methodologies from project management, data warehousing, mining and knowledge representation. Different from purely algorithmic papers, this one focuses on performance metrics used for managerial such as the time taken for solution development, the amount of files not automatically managed and other, while preserving equivalent performance on the technical solution quality metrics. This environment has been validated with metadata collected from previous KDD projects developed and deployed for real world applications by the development team members. The case study carried out in actual contracted projects have shown that this environment assesses the risk of failure for new projects, controls and documents all the KDD project development process and helps understanding the conditions that lead KDD projects to success or failure.",http://dx.doi.org/10.1007/978-3-642-01347-8_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-78831-7_14,Artificial Intelligence and Automation,Springer Handbook of Automation,10.1007/978-3-540-78831-7_14,Springer,2009-01-01,"Artificial intelligence (AI) artificial intelligence (AI) focuses on getting machines to do things that we would call intelligent behavior. Intelligence – whether artificial or otherwise – does not have a precise definition, but there are many activities and behaviors that are considered intelligent when exhibited by humans and animals. Examples include seeing, learning, using tools, understanding human speech, reasoning, making good guesses, playing games, and formulating plans and objectives. AI focuses on how to get machines or computers to perform these same kinds of activities, though not necessarily in the same way that humans or animals might do them.",http://dx.doi.org/10.1007/978-3-540-78831-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-78831-7_30,Automating Errors and Conflicts Prognostics and Prevention,Springer Handbook of Automation,10.1007/978-3-540-78831-7_30,Springer,2009-01-01,"Errors automating errors prevention error prevention automation and conflicts exist in many systems. A fundamental question from industries is How can errors and conflicts in systems be eliminated by automation, or can we at least use automation to minimize their damage? The purpose of this chapter is to illustrate a theoretical background and applications of how to automatically prevent errors and conflicts with various devices, technologies, methods, and systems. Eight key functions to prevent errors and conflicts are identified and their theoretical background and applications in both production and service are explained with examples. As systems and networks become larger and more complex, such as global enterprises and the Internet, error and conflict prognostics and prevention become more important and challenging; the focus is shifting from passive response to proactive prognostics and prevention. Additional theoretical developments and implementation efforts are needed to advance the prognostics and prevention of errors and conflicts in many real-world applications.",http://dx.doi.org/10.1007/978-3-540-78831-7_30,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-02127-5_8,"Parallel, Distributed, and Grid Computing",Hagenberg Research,10.1007/978-3-642-02127-5_8,Springer,2009-01-01,"The core goal of parallel computing is to speedup computations by executing independent computational tasks concurrently (“in parallel”) on multiple units in a processor, on multiple processors in a computer, or on multiple networked computers which may be even spread across large geographical scales (distributed and grid computing); it is the dominant principle behind “supercomputing” respectively “high performance computing”. For several decades, the density of transistors on a computer chip has doubled every 18–24 months (“Moore’s Law”); until recently, this rate could be directly transformed into a corresponding increase of a processor’s clock frequency and thus into an automatic performance gain for sequential programs. However, since also a processor’s power consumption increases with its clock frequency, this strategy of “frequency scaling” became ultimately unsustainable: since 2004 clock frequencies have remained essentially stable and additional transistors have been primarily used to build multiple processors on a single chip (multi-core processors). Today therefore every kind of software (not only “scientific” one) must be written in a parallel style to profit from newer computer hardware.",http://dx.doi.org/10.1007/978-3-642-02127-5_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4419-0310-5_4,Reputation Assessment,Trust Management for Service-Oriented Environments,10.1007/978-1-4419-0310-5_4,Springer,2009-01-01,"In this chapter, we describe the assessment module of the RATEWeb framework: a Reputation Assessment framework for Trust Establishment among Web services. The focus is on providing a comprehensive solution for assessing the reputation of service providers in an accurate, reliable, and decentralized manner. Since reputation forms an integral part of service-oriented environments in relation to the dynamic selection of services, on-the-fly composition of value-added enterprises, and optimization of service tasks, we have chosen Web services as a representative domain. However, RATEWeb can be extended and used in other contexts and domains. The proposed framework takes into account the presence of malicious raters that may exhibit oscillating honest and dishonest behaviors. Previous solutions for reputation assessment make simplifying assumptions that may not apply in a service-oriented environment. For example, [66] relies on pre-existing trusted parties, in [31] and [20] data needs to be distributed according to a certain statistical distribution, a common set of past providers is required in [146] for evaluating rater credibility, and in [95] human intervention is required, meaning the assessment process is not fully automated. Other similar solutions either do not consider all facets of reputation [1, 65, 116] or are focused primarily on efficiency/performance (rather than functionality) [36]. We develop a simple and holistic solution that provides an automated and adaptive reputation mechanism, whereby reputations are evaluated through a number of heuristics with different perspectives providing a fair and accurate assessment [86].",http://dx.doi.org/10.1007/978-1-4419-0310-5_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-79883-5_2,Adverse Selection in the Culture Industries,The Economics of Symbolic Exchange,10.1007/978-3-540-79883-5_2,Springer,2009-01-01,"Until consumer collaborative filtering arrives, navigation will continue to be the burning issue for present-day culture. There are no books or articles giving clear, systematic consideration of the problem. This is odd, because how well people are able to find their way around in the available offerings of culture directly affects both their aesthetic experience and their outlook on life. Those working commercially in the cultural sphere target as large a proportion of the public as they can, and today the technological tools at their disposal are more powerful than ever before: anything that can be digitised can be delivered almost instantaneously to any place at minimal cost. Cultural goods are universally accessible, but the downside of such profusion is the problem of what to choose.",http://dx.doi.org/10.1007/978-3-540-79883-5_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-92673-3_32,Ontologies for Knowledge Management,Handbook on Ontologies,10.1007/978-3-540-92673-3_32,Springer,2009-01-01,"Within Computer Science and Artificial Intelligence, the term ontologies was coined in the Knowledge Sharing and Reuse Effort , for efficient engineering of (distributed, cooperating) knowledge-based systems. It is not surprising that it soon entered the Knowledge Management (KM) area: Sharing and reuse of personal, group, and organizational knowledge are among the central goals aimed at in most KM projects. In this chapter we introduce the main ideas of KM, as well as the role of and requirements for information technology (IT) in KM. We discuss the potential of ontologies as elements in IT support for KM. We characterize their current role in research and practice, derive a working focus for the near future, and conclude with an outlook on trends in KM software and their implications on ontologies.",http://dx.doi.org/10.1007/978-3-540-92673-3_32,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-78831-7_47,Automation and Ethics,Springer Handbook of Automation,10.1007/978-3-540-78831-7_47,Springer,2009-01-01,"Should we trust automation? Can automation cause harm to individuals and to society? Can individuals apply automation to harm other individuals? The answers are yes; hence, ethical issues are deeply associated with automation. The purpose of this chapter is to provide some ethical background and guidance to automation professionals and students. Governmental action and economic factors are increasingly resulting in more global interactions and competition for jobs requiring lower-end skills as well as those that are higher-end endeavors such as research. Moreover, as the Internet continually eliminates geographic boundaries, the concept of doing business within a single country is giving way to companies and organizations focusing on serving and competing in international frameworks and a global marketplace. Coupled with the superfluous nature of an Internet-driven social culture, the globally-distributed digitalization of work, services and products, and the reorganization of work processes across many organizations have resulted in ethically challenging questions that are not just economically, or socially sensitive, but also highly culturally sensitive. Like the shifting of commodity manufacturing jobs in the late 1900s, standardization of information technology and engineering jobs have also accelerated the prospect of services and jobs more easily moved across the globe, thereby driving a need for innovation in design, and in the creation of higher-skill jobs. In this chapter, we review the fundamental concepts of ethics as it relates to automation, and then focus on the impacts of automation and their significance in both education and research.",http://dx.doi.org/10.1007/978-3-540-78831-7_47,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-89299-3_10,A Multi-Agent Environment for Negotiation,Multi-Agent Programming,10.1007/978-0-387-89299-3_10,Springer,2009-01-01,"In this chapter we introduce the System for Analysis of Multi-Issue Negotiation (SAMIN). SAMIN offers a negotiation environment that supports and facilitates the setup of various negotiation setups. The environment has been designed to analyse negotiation processes between human negotiators, between human and software agents, and between software agents. It offers a range of different agents, different domains, and other options useful to define a negotiation setup. The environment has been used to test and evaluate a range of negotiation strategies in various domains playing against other negotiating agents as well as humans. We discuss some of the results obtained by means of these experiments.",http://dx.doi.org/10.1007/978-0-387-89299-3_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-03226-4_3,Future Challenges for Autonomous Systems,Artificial Intelligence An International Perspective,10.1007/978-3-642-03226-4_3,Springer,2009-01-01,"The domain of intelligent creatures, systems and entities is suffering today profound changes, and the pace of more than a hundred meetings (congresses, conferences, workshops) per year shows there is a very large community of interest, eager of innovations and creativity. There is now no unanimity and homogeneity of the crowd, no convergence on what concerns scientific or technological goals, and recent surveys offer us strange results about the desires of industry and academy. However, observing recent conferences, we can work out some tendencies and move toward the future, yet conflicts are present concerning the aims the multiple communities pursue because some themes are relevant for several communities. Also, interleaving of areas generates points of friction between what must be done next.",http://dx.doi.org/10.1007/978-3-642-03226-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10458-008-9029-x,User evaluation of a market-based recommender system,Autonomous Agents and Multi-Agent Systems,10.1007/s10458-008-9029-x,Springer,2008-10-01,"Recommender systems have been developed for a wide variety of applications (ranging from books, to holidays, to web pages). These systems have used a number of different approaches, since no one technique is best for all users in all situations. Given this, we believe that to be effective, systems should incorporate a wide variety of such techniques and then some form of overarching framework should be put in place to coordinate them so that only the best recommendations (from whatever source) are presented to the user. To this end, in our previous work, we detailed a market-based approach in which various recommender agents competed with one another to present their recommendations to the user. We showed through theoretical analysis and empirical evaluation with simulated users that an appropriately designed marketplace should be able to provide effective coordination. Building on this, we now report on the development of this multi-agent system and its evaluation with real users . Specifically, we show that our system is capable of consistently giving high quality recommendations, that the best recommendations that could be put forward are actually put forward, and that the combination of recommenders performs better than any constituent recommender.",http://dx.doi.org/10.1007/s10458-008-9029-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00530-008-0117-1,An efficient ad recommendation system for TV programs,Multimedia Systems,10.1007/s00530-008-0117-1,Springer,2008-07-01,"With broadcast Television (TV) going digital, the number of channels and the programs aired have increased tremendously. Millions of audiences of various categories such as adults, children, youth and families watch these programs. Advertisements (ads) aired during these programs are targeted to reach these varied audiences and are the main revenue earners for TV broadcasters. While TV broadcasters have the task of scheduling hundreds of ads during the various ad breaks of programs, it is important that the ads shown during any ad break have a good impact on the viewers. An intelligent ad recommendation system that takes into account various factors such as ad/program content, viewers’ interests, sponsors’ preferences, program timing, program popularity and the available ad slot that help increasing the ad revenue would be useful for sponsors and broadcasters. We present in this paper a single end-to-end ad recommender system that considers all of these factors and recommends a set of well scheduled and sequenced ads that are the best suited for a given TV ad break. The proposed recommendation system captures the features of the ad video in terms of annotations derived from MPEG-7 descriptions and these annotation keywords are systematically grouped into a number of pre-defined semantic categories by using a categorization technique. A fuzzy categorical data clustering technique is then applied on the categorized data for grouping the best suited ads for a set of pre-defined program classes such as News, Sports, Cartoons etc. The program classes considered are selected to match with the TV program genres proposed in the TV-anytime standard. Since the same ad can be recommended to more than one program depending upon multiple parameters, fuzzy clustering acts as a well suited (and perhaps also the best suited) technique for ad recommendation. The relative fuzzy score called “degree of membership” calculated for each ad is an indicator of the number of program clusters to which the given ad belongs to. The clustered ads are then scheduled using an algorithm that takes into consideration parameters such as program popularity, program timing and available ad slots, to provide the best possible package for sponsors to show their ads. The scheduled set of ads if played randomly during an ad break might make viewers (sponsors) unhappy, for instance, when similar (competing) product ads get played consecutively. Hence, the system employs sequencing algorithm that takes into account the pre- and post-ad sequences in order to better order the scheduled set of ads in any ad break. We show that our proposed recommendation system provides an effective way of recommending the right ads for broadcast TV programs. We also demonstrate that this strategy does indeed help sponsors to attract viewers’ attention while playing their ads during ad breaks of TV programs. The proposed ad recommendation system is compared and evaluated subjectively with the current ad display system, by ten different people, and is rated with a high success score.",http://dx.doi.org/10.1007/s00530-008-0117-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10922-007-9088-3,Bringing Autonomic Principles for Managing Next Generation Networks and Services: A Report on LANOMS 2007,Journal of Network and Systems Management,10.1007/s10922-007-9088-3,Springer,2008-03-01,,http://dx.doi.org/10.1007/s10922-007-9088-3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-84628-982-8_4,A Self-organizing Sensing System for Structural Health Monitoring of Aerospace Vehicles,Advances in Applied Self-organizing Systems,10.1007/978-1-84628-982-8_4,Springer,2008-01-01,,http://dx.doi.org/10.1007/978-1-84628-982-8_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-8349-9777-7_14,Supervised Classification for Decision Support in Customer Relationship Management,Intelligent Decision Support,10.1007/978-3-8349-9777-7_14,Springer,2008-01-01,"Supervised classification embraces theories and algorithms for disclosing patterns within large, heterogeneous data streams. Several empirical experiments in various domains including medical diagnosis, drug design, document and image classification as well as text recognition have proven its effectiveness to solve complex forecasting and identification tasks. This paper considers applications of classification within the scope of customer relationship management (CRM). Representative operational planning tasks are reviewed to describe the potential and limitations of classification analysis. To that end, a survey of the relevant literature is given to summarize the body of knowledge in each field and identify similarities across applications. The discussion provides a general understanding of technical and managerial challenges encountered in typical CRM applications and indicates promising areas for future research.",http://dx.doi.org/10.1007/978-3-8349-9777-7_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-89437-7_1,Engineering of Software-Intensive Systems: State of the Art and Research Challenges,Software-Intensive Systems and New Computing Paradigms,10.1007/978-3-540-89437-7_1,Springer,2008-01-01,Software-intensive systems become more and more important in our everyday lives. But their increasing complexity makes it difficult to develop and maintain them. This chapter gives an overview of the state of the art of building software-intensive systems and outlines research challenges that have been identified by the InterLink working group “software-intensive systems and new computing paradigms”.,http://dx.doi.org/10.1007/978-3-540-89437-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-69209-6_2,Automating Event Extraction for the Security Domain,Intelligence and Security Informatics,10.1007/978-3-540-69209-6_2,Springer,2008-01-01,"This chapter presents on-going efforts at the Joint-Research Center of the European Commission for automating event extraction from news articles collected through the Internet with the Europe Media Monitor system. Event extraction builds on techniques developed over several years in the fields of information extraction, whose basic goal is to derive quantitative data from unstructured text. The motivation for automated event tracking is to provide objective incident data with broad coverage on terrorist incidents and violent conflicts from around the world. This quantitative data then forms the basis for populating incident databases and systems for trend analysis and risk assessment. A discussion of the technical requirements for information extraction and the approach adopted by the authors is presented. In particular, we deploy lightweight methods for entity extraction and a machine-learning technique for pattern-based event extraction. A preliminary evaluation of the results shows that the accuracy is already acceptable. Future directions of improving the approach are also discussed.",http://dx.doi.org/10.1007/978-3-540-69209-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-0-387-09699-5_18,User Session Modeling for Effective Application Intrusion Detection,Proceedings of The Ifip Tc 11 23rd International Information Security Conference,10.1007/978-0-387-09699-5_18,Springer,2008-01-01,"With the number of data breaches on a rise, effective and efficient detection of anomalous activities in applications which manages data is critical. In this paper, we introduce a novel approach to improve attack detection at application layer by modeling user sessions as a sequence of events instead of analyzing every single event in isolation.We also argue that combining application access logs and the corresponding data access logs to generate unified logs eliminates the need to analyze them separately thereby resulting in an efficient and accurate system. We evaluate various methods such as conditional random fields, support vector machines, decision trees and naive Bayes, and experimental results show that our approach based on conditional random fields is feasible and can detect attacks at an early stage even when they are disguised within normal events.",http://dx.doi.org/10.1007/978-0-387-09699-5_18,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-85658-0_7,Web Services Discovery Utilizing Semantically Annotated WSDL,Reasoning Web,10.1007/978-3-540-85658-0_7,Springer,2008-01-01,"To make semantic Web services accessible to users, providers use registries to publish them. Unfortunately, the current registries use discovery mechanisms which are inefficient, as they do not support discovery based on the semantics of the services and thus lead to a considerable number of irrelevant matches. Semantic discovery and matching of services is a promising approach to address this challenge. This paper presents an algorithm to match a semantic Web service request described with SAWSDL against semantic Web service advertisements. The algorithm is novel in three fundamental aspects. First, the similarity among semantic Web service properties, such as inputs and outputs, is evaluated using Tversky’s model which is based on concepts (classes), their semantic relationships, and their common and distinguishing features (properties). Second, the algorithm, not only takes into account services’ inputs and outputs, but it also considers the functionality of services. Finally, the algorithm is able to match a semantic Web service request against advertisements that are annotated with concepts that are with or without a common ontological commitment. In other words, it can evaluate the similarity of concepts defined in the context of different ontologies.",http://dx.doi.org/10.1007/978-3-540-85658-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-73190-0_10,Applications of Genetic Algorithms,Introduction to Genetic Algorithms,10.1007/978-3-540-73190-0_10,Springer,2008-01-01,,http://dx.doi.org/10.1007/978-3-540-73190-0_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-69209-6_6,Modeling Anticipatory Event Transitions,Intelligence and Security Informatics,10.1007/978-3-540-69209-6_6,Springer,2008-01-01,"Major world events such as terrorist attacks, natural disasters, wars, etc. typically progress through various representative stages/states in time. For example, a volcano eruption could lead to earthquakes, tsunamis, aftershocks, evacuation, rescue efforts, international relief support, rebuilding, and resettlement, etc. By analyzing various types of catastrophical and historical events, we can derive corresponding event transition models to embed useful information at each state. The knowledge embedded in these models can be extremely valuable. For instance, a transition model of the 1918-1920 flu pandemic could be used for the planning and allocation of resources to decisively respond to future occurrences of similar outbreaks such as the SARS (severe acute respiratory syndrome) incident in 2003, and a future H5N1 bird-flue pandemic. In this chapter, we study the Anticipatory Event Detection (AED) framework for modeling a general event from online news articles. We analyze each news document using a combination of features including text content, term burstiness, and date/time stamp. Machine learning techniques such as classification, clustering, and natural language understanding are applied to extract the semantics embedded in each news article. Real world events are used to illustrate the effectiveness and practicality of our approach.",http://dx.doi.org/10.1007/978-3-540-69209-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-88140-7_7,Feedback Control-Based Database Connection Management for Proportional Delay Differentiation-Enabled Web Application Servers ,Network and Parallel Computing,10.1007/978-3-540-88140-7_7,Springer,2008-01-01,"As an important differentiated service model, proportional delay differentiation (PDD) aims to maintain the queuing delay ratio between different classes of requests or packets according to pre-specified parameters. This paper considers providing PDD service in web application servers through feedback control-based database connection management. To achieve this goal, an approximate linear time-invariant model of the database connection pool (DBCP) is identified experimentally and used to design a proportional-integral (PI) controller. Periodically the controller is invoked to calculate and adjust the probabilities for different classes of dynamic requests to use database connections, according to the error between the measured delay ratio and the reference value. Three kinds of workloads, which follow deterministic, uniform and heavy-tailed distributions respectively, are designed to evaluate the performance of the closed-loop system. Experiment results indicate that, the controller is effective in handling varying workloads, and PDD can be achieved in the DBCP even if the number of concurrent dynamic requests changes abruptly under different kinds of workloads.",http://dx.doi.org/10.1007/978-3-540-88140-7_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-78731-0_15,Object Recognition for the Internet of Things,The Internet of Things,10.1007/978-3-540-78731-0_15,Springer,2008-01-01,"We present a system which allows to request information on physical objects by taking a picture of them. This way, using a mobile phone with integrated camera, users can interact with objects or ”things” in a very simple manner. A further advantage is that the objects themselves don’t have to be tagged with any kind of markers. At the core of our system lies an object recognition method, which identifies an object from a query image through multiple recognition stages, including local visual features, global geometry, and optionally also metadata such as GPS location. We present two applications for our system, namely a slide tagging application for presentation screens in smart meeting rooms and a cityguide on a mobile phone. Both systems are fully functional, including an application on the mobile phone, which allows simplest point-and-shoot interaction with objects. Experiments evaluate the performance of our approach in both application scenarios and show good recognition results under challenging conditions.",http://dx.doi.org/10.1007/978-3-540-78731-0_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-87805-6_6,Filtering Algorithm for Agent-Based Incident Communication Support in Mobile Human Surveillance,Multiagent System Technologies,10.1007/978-3-540-87805-6_6,Springer,2008-01-01,"This paper presents an ontology and a filtering algorithm used in an agent-based system to support communication in case of incidents in the mobile human surveillance domain. In that domain reaching the right people as soon as possible is of the essence when incidents occur. The main goal of our efforts is to significantly reduce the response time in case of incidents by proposing and setting up the communication to the right people. Experimental results show that this can reduce the response time by more than 50%, e.g., from 40 to 20 minutes. To continuously improve the accuracy of the proposed communications, the agent-based system uses feedback mechanisms. An implementation of this system, ASK-ASSIST, has been deployed at a mobile human surveillance company.",http://dx.doi.org/10.1007/978-3-540-87805-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-69900-4_2,Engineering and Customizing Ontologies,Ontology Management,10.1007/978-0-387-69900-4_2,Springer,2008-01-01,"In this chapter we introduce and then discuss the broad and rather complex area of human-ontology interaction. After reviewing generic tenets of HCI and their relevance to ontology management, we give an empirical evidence of some HCI challenges for ontology engineering tools and the shortcomings in some existing tools from this viewpoint. We highlight several functional opportunities that seem to be missing in the existing tools, and then look at three areas that may help rectifying the identified gaps. We relate methods from user profiling, large data set navigation and ontology customization into a “triple stack,” which may bring tools for engineering ontologies from the level of niche products targeting highly trained specialists to the ‘mainstream’ level suitable for practitioners and ordinary users. The work presented in this chapter is based on the authors’ research together with other colleagues in the context of the “NeOn: Lifecycle Support for Networked Ontologies” project.",http://dx.doi.org/10.1007/978-0-387-69900-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4020-6662-7_1,Introduction,Safeguards in a World of Ambient Intelligence,10.1007/978-1-4020-6662-7_1,Springer,2008-01-01,"The brave new world of ambient intelligence is almost upon us. Ambient intelligence is the phrase coined to describe a world in which “intelligence” is embedded in virtually everything around us. It has been called an Internet of things, where radio frequency identification (RFID) tags are attached to all products. It is a world of smart dust with networked sensors and actuators so small as to be virtually invisible, where the clothes you wear, the paint on your walls, the carpets on your floor, and the paper money in your pocket have a computer communications capability. It is a 4G world where today’s mobile phone is transformed into a terminal capable of receiving television, accessing the Internet, downloading music, reading RFIDs, taking pictures, enabling interactive video telephony, and much more. It is a world of convergence, where heterogeneous devices are able to communicate seamlessly across today’s disparate networks, a world of machine learning and intelligent software, where computers monitor our activities, routines and behaviours to predict what we will do or want next. In the brave new world of ambient intelligence, we will never have to worry about losing track of our children because they will have a location device implanted under the skin or, if they are squeamish about that, then at least they will have one in their wristwatch.",http://dx.doi.org/10.1007/978-1-4020-6662-7_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-69209-6_12,Personal Information Management for Intelligence Tasks,Intelligence and Security Informatics,10.1007/978-3-540-69209-6_12,Springer,2008-01-01,"The Intelligence Cycle is one of information processing: data is gathered, organized, analyzed, and summarized. In the current environment, there is a large amount of data available for Intelligence Analysts (IAs); therefore, a considerable amount of time is spent in the gathering and organizing phases, leaving little time for analysis and summarization. Thus, software tools that help with acquiring and categorizing new data are extremely useful to IAs. The concept of Personal Information Management (PIM) is currently a hot topic of research, although its basic ideas have a long history. In this chapter we argue that many of the goals of PIM research are highly relevant to tasks that gather and organize large amounts of data; in particular, to Intelligence tasks. Hence, the intelligence community should pay attention to the developments in this area. After providing some basic background on the Intelligence Cycle, we examine the concept of PIM, point out some issues that are relevant to intelligence work, and discuss some areas of research that PIMs should address in order to be even more relevant to the Intelligence Community.",http://dx.doi.org/10.1007/978-3-540-69209-6_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-71611-4_14,Public Safety Information Sharing: An Ontological Perspective,Digital Government,10.1007/978-0-387-71611-4_14,Springer,2008-01-01,"In recent years there has been a thrust on public safety related information-sharing efforts. However, many public safety information systems are incapable of efficient data sharing due to their heterogeneous nature. Digital government research has focused on the use of ontologies as they might play a key role in achieving seamless connectivity between heterogeneous systems. In this chapter we conduct a survey of public safety information sharing initiatives and discuss the ontological implications of the systems and standards. We also include a comprehensive review on ontologies and ontology-based information sharing and integration approaches in the digital government and other domains. We discuss the importance of ontology mapping for the public safety domain and present a survey of the state-of-the-art in ontology mapping. To showcase ontology-based sharing efforts we present two case studies: the first on evaluating mapping tools with law enforcement data and the second on using ontologies for sharing and analysis of extremist data.",http://dx.doi.org/10.1007/978-0-387-71611-4_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-007-9038-7,Structure-based color learning on a mobile robot under changing illumination,Autonomous Robots,10.1007/s10514-007-9038-7,Springer,2007-10-01,"A central goal of robotics and AI is to be able to deploy an agent to act autonomously in the real world over an extended period of time. To operate in the real world, autonomous robots rely on sensory information. Despite the potential richness of visual information from on-board cameras, many mobile robots continue to rely on non-visual sensors such as tactile sensors, sonar, and laser. This preference for relatively low-fidelity sensors can be attributed to, among other things, the characteristic requirement of real-time operation under limited computational resources. Illumination changes pose another big challenge. For true extended autonomy, an agent must be able to recognize for itself when to abandon its current model in favor of learning a new one; and how to learn in its current situation. We describe a self-contained vision system that works on-board a vision-based autonomous robot under varying illumination conditions. First, we present a baseline system capable of color segmentation and object recognition within the computational and memory constraints of the robot. This relies on manually labeled data and operates under constant and reasonably uniform illumination conditions. We then relax these limitations by introducing algorithms for (i) Autonomous planned color learning, where the robot uses the knowledge of its environment (position, size and shape of objects) to automatically generate a suitable motion sequence and learn the desired colors, and (ii) Illumination change detection and adaptation, where the robot recognizes for itself when the illumination conditions have changed sufficiently to warrant revising its knowledge of colors. Our algorithms are fully implemented and tested on the Sony ERS-7 Aibo robots.",http://dx.doi.org/10.1007/s10514-007-9038-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-007-0035-6,On the use of hybrid reinforcement learning for autonomic resource allocation,Cluster Computing,10.1007/s10586-007-0035-6,Springer,2007-09-01,"Reinforcement Learning (RL) provides a promising new approach to systems performance management that differs radically from standard queuing-theoretic approaches making use of explicit system performance models. In principle, RL can automatically learn high-quality management policies without an explicit performance model or traffic model, and with little or no built-in system specific knowledge. In our original work (Das, R., Tesauro, G., Walsh, W.E.: IBM Research, Tech. Rep. RC23802 ( 2005 ), Tesauro, G.: In: Proc. of AAAI-05 , pp. 886–891 ( 2005 ), Tesauro, G., Das, R., Walsh, W.E., Kephart, J.O.: In: Proc. of ICAC-05 , pp. 342–343 ( 2005 )) we showed the feasibility of using online RL to learn resource valuation estimates (in lookup table form) which can be used to make high-quality server allocation decisions in a multi-application prototype Data Center scenario. The present work shows how to combine the strengths of both RL and queuing models in a hybrid approach, in which RL trains offline on data collected while a queuing model policy controls the system. By training offline we avoid suffering potentially poor performance in live online training. We also now use RL to train nonlinear function approximators (e.g. multi-layer perceptrons) instead of lookup tables; this enables scaling to substantially larger state spaces. Our results now show that, in both open-loop and closed-loop traffic, hybrid RL training can achieve significant performance improvements over a variety of initial model-based policies. We also find that, as expected, RL can deal effectively with both transients and switching delays, which lie outside the scope of traditional steady-state queuing theory.",http://dx.doi.org/10.1007/s10586-007-0035-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-007-5006-x,Discovering Significant Patterns,Machine Learning,10.1007/s10994-007-5006-x,Springer,2007-07-01,"Pattern discovery techniques, such as association rule discovery, explore large search spaces of potential patterns to find those that satisfy some user-specified constraints. Due to the large number of patterns considered, they suffer from an extreme risk of type-1 error, that is, of finding patterns that appear due to chance alone to satisfy the constraints on the sample data. This paper proposes techniques to overcome this problem by applying well-established statistical practices. These allow the user to enforce a strict upper limit on the risk of experimentwise error. Empirical studies demonstrate that standard pattern discovery techniques can discover numerous spurious patterns when applied to random data and when applied to real-world data result in large numbers of patterns that are rejected when subjected to sound statistical evaluation. They also reveal that a number of pragmatic choices about how such tests are performed can greatly affect their power.",http://dx.doi.org/10.1007/s10994-007-5006-x,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10796-006-9015-2,A web services framework for distributed model management,Information Systems Frontiers,10.1007/s10796-006-9015-2,Springer,2007-03-01,"Distributed model management aims to support the wide-spread sharing and usage of decision support models. Web services is a promising technology for supporting distributed model management activities such as model creation and delivery, model composition, model execution and model maintenance to fulfill dynamic decision-support and problem solving requests. We propose a web services based framework for model management (called MM-WS) to support various activities of the model management life cycle. The framework is based on the recently proposed Integrated Service Planning and Execution (ISP & E) approach for web services integration. We discuss encoding of domain knowledge (as individual models) and utilize the MM-WS framework to interleave synthesis of composite models with their execution. A prototypical implementation with an example is used to illustrate the utility of the framework to enable distributed model management and knowledge integration. Benefits and issues of using the framework to support model-based decision-making in organizational contexts are outlined.",http://dx.doi.org/10.1007/s10796-006-9015-2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10660-006-0060-1,A Semantic Web data retrieval implementation with an adaptive model for supporting agent decision structures,Electronic Commerce Research,10.1007/s10660-006-0060-1,Springer,2007-03-01,"This paper proposes an adaptive learning approach that yields decision models that can be applied by a transactions agent. This model can learn effectively with a variety of data distributions. This research uses the Semantic Web as a data access approach. The Semantic Web is a method that sellers can use to publish semantically meaningful information on Websites so automated applications can reliably access that information. We implemented a Semantic Web composed of 30 vendors’ Web pages and a spider to search those pages to obtain product and vendor information. This information was used to train a learning agent, which then provided a decision model to a transaction agent.",http://dx.doi.org/10.1007/s10660-006-0060-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10844-006-0004-1,A process of knowledge discovery from web log data: Systematization and critical review,Journal of Intelligent Information Systems,10.1007/s10844-006-0004-1,Springer,2007-02-01,"This paper presents a comprehensive survey of web log/usage mining based on over 100 research papers. This is the first survey dedicated exclusively to web log/usage mining. The paper identifies several web log mining sub-topics including specific ones such as data cleaning, user and session identification. Each sub-topic is explained, weaknesses and strong points are discussed and possible solutions are presented. The paper describes examples of web log mining and lists some major web log mining software packages.",http://dx.doi.org/10.1007/s10844-006-0004-1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10619-006-7003-7,Context-based matching for Web service composition,Distributed and Parallel Databases,10.1007/s10619-006-7003-7,Springer,2007-02-01,"In this paper, we propose a novel matching framework for Web service composition. The framework combines the concepts of Web service, context, and ontology. We adopt a broad definition of context for Web services, encompassing all information needed for enabling interactions between clients and providers. Context-based matching for Web services requires dealing with three major research thrusts: context categorization, modeling, and matching. We first propose an ontology-based categorization of contextual information in Web service environments. We then define a two-level mechanism for modeling Web service contexts. In the first level, service providers create context specifications using category-specific Web service languages and standards. In the second level, context specifications are enveloped by policies (called context policies) using WS-Policy standard. Finally, we present a peer-to-peer architecture for matching context policies. The architecture relies on a context matching engine, context policy assistants, and context community services. Community services implement rule-based techniques for comparing context policies.",http://dx.doi.org/10.1007/s10619-006-7003-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72079-9_16,Personalization in E-Commerce Applications,The Adaptive Web,10.1007/978-3-540-72079-9_16,Springer,2007-01-01,"This chapter is about personalization and adaptation in electronic commerce (e-commerce) applications. In the first part, we briefly introduce the challenges posed by e-commerce and we discuss how personalization strategies can help companies to face such challenges. Then, we describe the aspects of personalization, taken as a general technique for the customization of services to the user, which have been successfully employed in e-commerce Web sites. To conclude, we present some emerging trends and and we discuss future perspectives.",http://dx.doi.org/10.1007/978-3-540-72079-9_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72079-9_21,Privacy-Enhanced Web Personalization,The Adaptive Web,10.1007/978-3-540-72079-9_21,Springer,2007-01-01,"Consumer studies demonstrate that online users value personalized content. At the same time, providing personalization on websites seems quite profitable for web vendors. This win-win situation is however marred by privacy concerns since personalizing people’s interaction entails gathering considerable amounts of data about them. As numerous recent surveys have consistently demonstrated, computer users are very concerned about their privacy on the Internet. More over, the collection of personal data is also subject to legal regulations in many countries and states. Both user concerns and privacy regulations impact frequently used personalization methods. This article analyzes the tension between personal ization and privacy, and presents approaches to reconcile the both.",http://dx.doi.org/10.1007/978-3-540-72079-9_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-77028-2_1,Web Intelligence Meets Brain Informatics,Web Intelligence Meets Brain Informatics,10.1007/978-3-540-77028-2_1,Springer,2007-01-01,"In this chapter, we outline a vision of Web Intelligence (WI) research from the viewpoint of Brain Informatics (BI), a new interdisciplinary field that systematically studies the mechanisms of human information processing from both the macro and micro viewpoints by combining experimental cognitive neuroscience with advanced information technology. BI studies human brain from the viewpoint of informatics (i.e., human brain is an information processing system) and uses informatics (i.e., WI centric information technology) to support brain science study. Advances in instrumentation, e.g., based on fMRI and information technologies offer more opportunities for research in both Web intelligence and brain sciences. Further understanding of human intelligence through brain sciences fosters innovative Web intelligence research and development. WI portal techniques provide a powerful new platform for brain sciences. The synergy between WI and BI advances our ways of analyzing and understanding of data, knowledge, intelligence, and wisdom, as well as their interrelationships, organizations, and creation processes. Web intelligence is becoming a central field that revolutionizes information technologies and artificial intelligence to achieve human-level Web intelligence.",http://dx.doi.org/10.1007/978-3-540-77028-2_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-37882-2_3,Supervised Learning,Web Data Mining,10.1007/978-3-540-37882-2_3,Springer,2007-01-01,"Supervised learning has been a great success in real-world applications. It is used in almost every domain, including text and Web domains. Supervised learning is also called classification or inductive learning in machine learning. This type of learning is analogous to human learning from past experiences to gain new knowledge in order to improve our ability to perform real-world tasks. However, since computers do not have “experiences”, machine learning learns from data, which are collected in the past and represent past experiences in some real-world applications.",http://dx.doi.org/10.1007/978-3-540-37882-2_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-37017-8_22,Orchestrating the Knowledge Discovery Process,E-Service Intelligence,10.1007/978-3-540-37017-8_22,Springer,2007-01-01,,http://dx.doi.org/10.1007/978-3-540-37017-8_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-74951-6_1,"An Analysis of Bloggers, Topics and Tags for a Blog Recommender System",From Web to Social Web: Discovering and Deploying User and Content Profiles,10.1007/978-3-540-74951-6_1,Springer,2007-01-01,"Over the past few years the web has experienced an exponential growth in the use of weblogs or blogs , web sites containing journal-style entries presented in reverse chronological order. In this paper we provide an analysis of the type of recommendation strategy suitable for this domain. We introduce measures to characterise the blogosphere in terms of blogger and topic drift and we demonstrate how these measures can be used to construct a plausible explanation for blogger behaviour. We show that the blog domain is characterised by bloggers moving frequently from topic to topic and that blogger activity closely tracks events in the real world. We then demonstrate how tag cloud information within each cluster allows us to identify the most topic-relevant and consistent blogs in each cluster. We briefly describe how we plan to integrate this work within the SIOC framework.",http://dx.doi.org/10.1007/978-3-540-74951-6_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72912-9_14,Challenges of Testing Web Services and Security in SOA Implementations,Test and Analysis of Web Services,10.1007/978-3-540-72912-9_14,Springer,2007-01-01,"The World Wide Web is evolving into a medium providing a wide array of e-commerce, business-to-business, business-to-consumer, and other information-based services. In Service Oriented Architecture (SOA) technology, Web Services are emerging as the enabling technology that bridges decoupled systems across various platforms, programming languages, and applications. The benefits of Web Services and SOA come at the expense of introducing new level of complexity to the environments where these services are deployed. This complexity is compounded by the freedom to compose Web Services to address requirements such as quality of service (QoS), availability, security, reliability, and cost. The complexity of composing services compounds the task of securing, testing, and managing the quality of the deployed services. This chapter identifies the main security requirements for Web Services and describes how such security requirements are addressed by standards for Web Services security recently developed or under development by various standardizations bodies. Standards are reviewed according to a conceptual framework that groups them by the main functionalities they provide. Testing composite services in SOA environment is a discipline at an early stage of study. The chapter provides a brief overview of testing challenges that face early implementers of composite services in SOA taking into consideration Web Services security. The importance of Web Services Management systems in Web Services deployment is discussed. A step toward a fault model for Web Services is provided. The chapter investigates the use of crash-only software development techniques for enhancing the availability of Web Services. The chapter discusses security mechanisms from the point of view of interoperability of deployed services. The work discusses the concepts and strategies as developed by the WS-I Basic Security profile for enhancing the interoperability of secure Web Services.",http://dx.doi.org/10.1007/978-3-540-72912-9_14,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-76890-6_48,From Database to Semantic Web Ontology: An Overview,On the Move to Meaningful Internet Systems 2007: OTM 2007 Workshops,10.1007/978-3-540-76890-6_48,Springer,2007-01-01,"This paper intends to provide an overview of automated knowledge extraction and transformation from relational databases and their related sources into Semantic Web ontologies. Issues and challenges in this area are addressed. Knowledge embedded in each part of a relational database is analysed and defined. Corresponding techniques for extracting, acquiring and transforming the knowledge are highlighted. In this paper, we classify previous approaches on this work into two types. A comparison table of the first type of approach is also given.",http://dx.doi.org/10.1007/978-3-540-76890-6_48,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-36501-5_7,Tools,Ontology Alignment,10.1007/978-0-387-36501-5_7,Springer,2007-01-01,"After the creation of the new approaches, we now need to deploy them. Therefore, we will first show how these are implemented. This chapter is split into three implementations of the alignment approach: a basic infrastructure for ontology alignment and mapping (FOAM), Ontology Mapping based on Axioms (OMA), and the OntoStudio plug-in OntoMap. All of them have specific strengths, though the most important implementation undoubtedly is FOAM. We will refer to it in the subsequent practical applications.",http://dx.doi.org/10.1007/978-0-387-36501-5_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-76778-7_15,iManage: Policy-Driven Self-management for Enterprise-Scale Systems,Middleware 2007,10.1007/978-3-540-76778-7_15,Springer,2007-01-01,"It is obvious that big, complex enterprise systems are hard to manage. What is not obvious is how to make them more manageable. Although there is a growing body of research into system self-management, many techniques are either too narrow, focusing on a single component rather than the entire system, or not robust enough, failing to scale or respond to the full range of an administrator’s needs. In our iManage system we have developed a policy-driven system modeling framework that aims to bridge the gap between manageable components and manageable systems. In particular, iManage provides: (1)  system state-space partitioning , which divides a large system state-space into partitions that are more amenable to constructing system models and developing policies, (2) online model and policy adaptation to allow the self-management infrastructure to deal gracefully with changes in operating environment, system configuration, and workload, and (3) tractability and trust , where tractability allows an administrator to understand why the system chose a particular policy and also influence that decision, and trust allows an administrator to understand the system’s confidence in a proposed, automated action. Simulations driven by scenarios given to us by our industrial collaborators demonstrate that iManage is effective both at constructing useful system models and in using those models to drive automated system management.",http://dx.doi.org/10.1007/978-3-540-76778-7_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-37017-8_29,AGrIP – Agent Grid Intelligence Platform,E-Service Intelligence,10.1007/978-3-540-37017-8_29,Springer,2007-01-01,,http://dx.doi.org/10.1007/978-3-540-37017-8_29,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72912-9_13,Vulnerability Analysis of Web-based Applications,Test and Analysis of Web Services,10.1007/978-3-540-72912-9_13,Springer,2007-01-01,"In the last few years, the popularity of web-based applications has grown tremendously. A number of factors have led an increasing number of organizations and individuals to rely on web-based applications to provide access to a variety of services. Today, web-based applications are routinely used in security-critical environments, such as medical, financial, and military systems. Web-based systems are a composition of infrastructure components, such as web servers and databases, and of application-specific code, such as HTML-embedded scripts and server-side CGI programs. While the infrastructure components are usually developed by experienced programmers with solid security skills, the application-specific code is often developed under strict time constraints by programmers with little security training. As a result, vulnerable web-based applications are deployed and made available to the whole Internet, creating easily exploitable entry points for the compromise of entire networks. To ameliorate these security problems, it is necessary to develop tools and techniques to improve the security of web-based applications. The most effective approach would be to provide secure mechanisms that can be used by well-trained developers. Unfortunately, this is not always possible, and a second line of defense is represented by auditing the application code for possible security problems. This activity, often referred to as web vulnerability analysis , allows one to identify security problems in web-based applications at early stages of development and deployment. Recently, a number of methodologies and tools have been proposed to support the assessment of the security of web-based applications. In this chapter, we survey the current approaches to web vulnerability analysis and we propose a classification along two characterizing axes: detection model and analysis technique. We also present the most common attacks against web-based applications and discuss the effectiveness of certain analysis techniques in identifying specific classes of flaws.",http://dx.doi.org/10.1007/978-3-540-72912-9_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-72079-9_9,Collaborative Filtering Recommender Systems,The Adaptive Web,10.1007/978-3-540-72079-9_9,Springer,2007-01-01,"One of the potent personalization technologies powering the adaptive web is collaborative filtering. Collaborative filtering (CF) is the process of filtering or evaluating items through the opinions of other people. CF technology brings together the opinions of large interconnected communities on the web, supporting filtering of substantial quantities of data. In this chapter we introduce the core concepts of collaborative filtering, its primary uses for users of the adaptive web, the theory and practice of CF algorithms, and design decisions regarding rating systems and acquisition of ratings. We also discuss how to evaluate CF systems, and the evolution of rich interaction interfaces. We close the chapter with discussions of the challenges of privacy particular to a CF recommendation service and important open research questions in the field.",http://dx.doi.org/10.1007/978-3-540-72079-9_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-4020-5427-0_15,Location-based services: Enabling technologies and a concierge service model,Societies and Cities in the Age of Instant Access,10.1007/1-4020-5427-0_15,Springer,2007-01-01,,http://dx.doi.org/10.1007/1-4020-5427-0_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-69507-3_59,Building an Ontological Base for Experimental Evaluation of Semantic Web Applications,SOFSEM 2007: Theory and Practice of Computer Science,10.1007/978-3-540-69507-3_59,Springer,2007-01-01,"The increasing number of Semantic Web applications that work with ontologies implies an increased need for building ontological knowledge bases. In order to improve ontologies during their development as well as to allow applications to be experimentally evaluated prior to their complete implementation and deployment, ontology bases must be filled with experimental data (i.e., instance ontologies), which can be used to evaluate methods used for information processing. We describe several approaches together with a method of building an ontological knowledge base for purposes of experimentation with Semantic Web applications. We also discuss characteristics and suitability of particular approaches to the development of experimental ontological knowledge bases.",http://dx.doi.org/10.1007/978-3-540-69507-3_59,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-34351-6_25,Data Mining in Security,Introduction to Data Mining and its Applications,10.1007/978-3-540-34351-6_25,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-3-540-34351-6_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11839354_21,Learning to Negotiate Optimally in Non-stationary Environments,Cooperative Information Agents X,10.1007/11839354_21,Springer,2006-01-01,"We adopt the Markov chain framework to model bilateral negotiations among agents in dynamic environments and use Bayesian learning to enable them to learn an optimal strategy in incomplete information settings. Specifically, an agent learns the optimal strategy to play against an opponent whose strategy varies with time, assuming no prior information about its negotiation parameters. In so doing, we present a new framework for adaptive negotiation in such non-stationary environments and develop a novel learning algorithm, which is guaranteed to converge, that an agent can use to negotiate optimally over time. We have implemented our algorithm and shown that it converges quickly in a wide range of cases.",http://dx.doi.org/10.1007/11839354_21,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-84628-231-4_15,"e-Negotiation Systems and Software Agents: Methods, Models, and Applications",Intelligent Decision-making Support Systems,10.1007/1-84628-231-4_15,Springer,2006-01-01,"Negotiation is a decentralized decision-making process that seeks to find an agreement that will satisfy the requirements of two or more parties in the presence of limited common knowledge and conflicting preferences. Negotiation participants are agents who negotiate on their own behalf or represent the interests of their principals. When electronic negotiations enter the stage, these agents could be intelligent software entities that take part in the process of searching for an acceptable agreement. The degree of involvement of these “intelligent agents” in negotiations can range from supporting human negotiators ( e. g. information search, offer evaluation) to fully automating the conduct of negotiations. Choosing the degree of involvement depends upon the characteristics of the problem in the negotiation. In this chapter, we review electronic negotiation systems and intelligent agents for negotiations. Different types of negotiation agents, their roles and requirements, and various methods for effective support or conduct of negotiations are discussed. Selected applications of intelligent negotiation agents are presented.",http://dx.doi.org/10.1007/1-84628-231-4_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-34685-4_13,Building Semantic Business Services,"Semantic Web Services, Processes and Applications",10.1007/978-0-387-34685-4_13,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-0-387-34685-4_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10257-005-0021-6,Computational experimentations in market and supply-chain co-design: a mixed agent approach,Information Systems and e-Business Management,10.1007/s10257-005-0021-6,Springer,2006-01-01,"The synthetic environment for analysis and simulations (SEAS) is a computational experimentation environment that mimics real life economies, with multiple interlinked markets, multiple goods and services, multiple firms and channels and multiple consumers, all built from the ground up. It is populated with human agents who make strategically complex decisions and artificial agents who make simple but detail intensive decisions. These agents can be calibrated with real data and allowed to make the same decisions in this synthetic economy as their real life counterparts. The resulting outcomes can be surprisingly accurate. This paper discusses the research in this area and goes on to detail the architecture of SEAS. It also presents a detailed case study of market and supply-chain co-design for business-to-business e-commerce in the PC industry.",http://dx.doi.org/10.1007/s10257-005-0021-6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11805816_27,Combining Case-Based and Similarity-Based Product Recommendation,Advances in Case-Based Reasoning,10.1007/11805816_27,Springer,2006-01-01,"Product recommender systems are a popular application and research field of CBR for several years now. However, almost all CBR-based recommender systems are not case-based in the original view of CBR, but just perform a similarity-based retrieval of product descriptions. Here, a predefined similarity measure is used as a heuristic for estimating the customers’ product preferences. In this paper we propose an extension of these systems, which enables case-based learning of customer preferences. Further, we show how this approach can be combined with existing approaches for learning the similarity measure directly. The presented results of a first experimental evaluation demonstrate the feasibility of our novel approach in an example test domain.",http://dx.doi.org/10.1007/11805816_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/11837787_10,The Semantic Web from an Industry Perspective,Reasoning Web,10.1007/11837787_10,Springer,2006-01-01,"Semantic Web technology is being increasingly applied in a large spectrum of applications in which domain knowledge is conceptualized and formalized (e.g., by means of an ontology) in order to support diversified and automated knowledge processing (e.g., reasoning) performed by a machine. Moreover, through an optimal combination of (cognitive) human reasoning and (automated) machine reasoning and processing, it is possible for humans and machines to share complementary tasks. The spectrum of applications is extremely large and to name a few: corporate portals and knowledge manage-ment, e-commerce, e-work, e-business, healthcare, e-government, natural language understanding and automated translation, information search, data and services integration, social networks and collaborative filtering, knowledge mining, business intelligence and so on. From a social and economic perspective, this emerging technology should contribute to growth in economic wealth, but it must also show clear cut value for everyday activities through technological transparency and efficiency. The penetration of Semantic Web technology in industry and in services is progressing slowly but accelerating as new success stories are reported. In this paper and lecture we present ongoing work in the cross-fertilization between industry and academia. In particular, we present a collection of application fields and use cases from enterprises which are interested in the promises of Semantic Web technology. The use cases are detailed and focused on the key knowledge processing components that will unlock the deployment of the technology in the selected application field. The paper ends with the presentation of the current technology roadmap designed by a team of Academic and Industry researchers.",http://dx.doi.org/10.1007/11837787_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-34351-6_2,"Data Warehousing, Data Mining, and OLAP",Introduction to Data Mining and its Applications,10.1007/978-3-540-34351-6_2,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-3-540-34351-6_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-30984-5_10,iJADE Negotiator — An Intelligent Fuzzy Agent-Based Negotiation System for Internet Shopping,Fuzzy-Neuro Approach to Agent Applications,10.1007/3-540-30984-5_10,Springer,2006-01-01,,http://dx.doi.org/10.1007/3-540-30984-5_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-32182-9_2,Ontologies,Model Driven Architecture and Ontology Development,10.1007/3-540-32182-9_2,Springer,2006-01-01,,http://dx.doi.org/10.1007/3-540-32182-9_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-34351-6_16,Data Mining in Customer Value and Customer Relationship Management,Introduction to Data Mining and its Applications,10.1007/978-3-540-34351-6_16,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-3-540-34351-6_16,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-27972-5_5,Distributed Coordination of an Agent Society Based on Obligations and Commitments to Negotiated Agreements,Coordination of Large-Scale Multiagent Systems,10.1007/0-387-27972-5_5,Springer,2006-01-01,"This chapter discusses coordination from a commitment basis. Typically, commitments are established via a process of negotiation between the parties—the debtor and creditor—involved in the commitment. We define obligations to be those commitments, sometimes termed norms or social commitments, without a clearly identifiable creditor. The establishment of a commitment occurs in response to the adoption of a goal or the acceptance and performance of a task. Using a service-oriented computing (SOC) context, we describe an efficient negotiation process for establishing commitments. We then show how commitments and obligations can be used to monitor and control the aggregate behavior of a group of agents to yield coordinated progress towards the agents’ overall objective.",http://dx.doi.org/10.1007/0-387-27972-5_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-34351-6_5,Emerging Trends and Applications of Data Mining,Introduction to Data Mining and its Applications,10.1007/978-3-540-34351-6_5,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-3-540-34351-6_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11775300_15,Dynamic Configuring Service on Semantic Grid,Advances in Web-Age Information Management,10.1007/11775300_15,Springer,2006-01-01,"Dynamic configuring service composition can automatically leverage distributed service components and resources to compose an optimal configuration according to the requirements on Semantic Grid. One major challenge is how to comprehend service-specific semantics and how to generate workflow to reuse common service composition functionalities. Current ontological specifications for semantically describing properties of Grid services are limited to their static interface description. In this paper, we present an automaton [1, 2] model in which service providers express their service-specific knowledge in the form of a service template and create composition plan that is used by a synthesizer to perform dynamic configuring composition automatically. Our main contribution is to formally describe dynamic processing of composition, to take QoS-driven composition goal into account to find best quality composition on Semantic Grid.",http://dx.doi.org/10.1007/11775300_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11836025_48,Web Services Analysis: Making Use of Web Service Composition and Annotation,The Semantic Web – ASWC 2006,10.1007/11836025_48,Springer,2006-01-01,"Automated Web service composition and automated Web service annotation could be seen as complimentary methodologies. While automated annotation allows to extract Web service semantics from existing WSDL documents, automated composition uses this semantics for integrating applications. Therefore applicability of both methodologies is essential for increasing the productivity of information system integration. Although several papers have proposed methods for automated annotation, there is a lack of studies providing analysis of the general structure of Web services. We argue that having an overview of general Web services structures would greatly improve design of new annotation methods. At the same time, progress in automated composition has resulted in several methods for automating Web services orchestration. In this paper we propose application of automated composition also for analysing Web services domain. We identify and analyse some general Web services properties and provide their interpretation in an industrial context.",http://dx.doi.org/10.1007/11836025_48,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-35417-0_7,Ontological Engineering for Semantic Web-Based Education,Semantic Web and Education,10.1007/978-0-387-35417-0_7,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-0-387-35417-0_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-34685-4_9,Matching And Mapping For Semantic Web Processes,"Semantic Web Services, Processes and Applications",10.1007/978-0-387-34685-4_9,Springer,2006-01-01,,http://dx.doi.org/10.1007/978-0-387-34685-4_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10462-005-4607-7,Explanation in Case-Based Reasoning–Perspectives and Goals,Artificial Intelligence Review,10.1007/s10462-005-4607-7,Springer,2005-10-01,"We present an overview of different theories of explanation from the philosophy and cognitive science communities. Based on these theories, as well as models of explanation from the knowledge-based systems area, we present a framework for explanation in case-based reasoning (CBR) based on explanation goals. We propose ways that the goals of the user and system designer should be taken into account when deciding what is a good explanation for a given CBR system. Some general types of goals relevant to many CBR systems are identified, and used to survey existing methods of explanation in CBR. Finally, we identify some future challenges.",http://dx.doi.org/10.1007/s10462-005-4607-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00530-005-0174-7,Systems and architectures for multimedia information retrieval,Multimedia Systems,10.1007/s00530-005-0174-7,Springer,2005-10-01,"In this paper, we provide a brief survey on multimedia information retrieval and we introduce some ideas investigated in the special issue. We hope that the contributions of this issue will stimulate the readers to tackle the current challenges and problems in this highly important research direction. Such contributions are the basis of tomorrow's multimedia information systems. Our aims are to clarify some notions raised by this new technology by reviewing its current capabilities and potential usefulness to users in various areas. The research and development issues cover a wide range of fields, many of which are shared with media processing, signal processing, database technologies, and data mining.",http://dx.doi.org/10.1007/s00530-005-0174-7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10257-005-0019-0,A unified framework for managing Web-based services,Information Systems and e-Business Management,10.1007/s10257-005-0019-0,Springer,2005-10-01,"The emergence of Web technologies enables a variety of Web-based service applications, which can be examined from business process integration, supply chain management, and knowledge management perspectives. To categorize existing Web-based services while foreseeing potential new types, a unified view is needed to represent the structures and processes of Web-based services. This paper proposes a general framework to identify essential structures and operations of Web-based services, and then models these components. We articulate the framework with Web technologies, such as Web service and semantic Web, multi-agent and peer-to-peer, and Web information retrieval and mining. Two comprehensive examples in insurance and knowledge services are used to elaborate the use of Web-based service framework in fulfilling business processes. This study synthesizes essential structures and processes of Web-based services to build a framework for researchers and practitioners to develop Web-based services and techniques.",http://dx.doi.org/10.1007/s10257-005-0019-0,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF02706248,Data mining in e-commerce: A survey,Sadhana,10.1007/BF02706248,Springer,2005-04-01,"Data mining has matured as a field of basic and applied research in computer science in general and e-commerce in particular. In this paper, we survey some of the recent approaches and architectures where data mining has been applied in the fields of e-commerce and e-business. Our intent is not to survey the plethora of algorithms in data mining; instead, our current focus being e-commerce, we limit our discussion to data mining in the context of e-commerce. We also mention a few directions for further work in this domain, based on the survey.",http://dx.doi.org/10.1007/BF02706248,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-23392-X_9,Enabling Supply-Chain Coordination: Leveraging Legacy Sources for Rich Decision Support,Applications of Supply Chain Management and E-Commerce Research,10.1007/0-387-23392-X_9,Springer,2005-01-01,"As supply chains come under escalating pressure for responsiveness to customer demands as well as cost pressures, there is increased scope for decision support models to enhance coordination of supply chain activities. However, enhanced coordination implicitly requires sharing information about costs, production capacity, materials availability, delivery schedules, etc. This information is currently stored in a panoply of legacy information systems distributed across the many firms that comprise a given supply chain. As such, accessing useful information presents considerable technical challenges, effectively limiting the deployment of decision support tools for supply chain operations. The purpose of this chapter is to present the research issues and approaches to accessing or integrating data in legacy information systems. Current industry approaches to information integration, including information hubs and Web Services technologies, are briefly reviewed and critiqued as useful but inadequate to the task of integrating data stored in legacy systems. Recommended requirements for new methods include rapid deployment, ability to connect to heterogeneous legacy systems, composition of knowledge for decision support, and provision for secure data access. These requirements motivate a review of the research literature on knowledge extraction and composition. As an example of new methods built from current research, an integrated toolkit known as SEEK: Scalable Extraction of Enterprise Knowledge is presented. Capabilities and limitations of the SEEK toolkit are used to suggest novel areas of research in visualization and representation of data for human refinement of automatic integration results, as well as further development of evolutionary algorithms to enhance the scope of automatic knowledge extraction. Throughout the chapter, an example of a construction industry supply chain is used to motivate discussion.",http://dx.doi.org/10.1007/0-387-23392-X_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11577935_1,Intelligent Techniques for Web Personalization,Intelligent Techniques for Web Personalization,10.1007/11577935_1,Springer,2005-01-01,"In this chapter we provide a comprehensive overview of the topic of Intelligent Techniques for Web Personalization. Web Personalization is viewed as an application of data mining and machine learning techniques to build models of user behaviour that can be applied to the task of predicting user needs and adapting future interactions with the ultimate goal of improved user satisfaction. This chapter survey’s the state-of-the-art in Web personalization. We start by providing a description of the personalization process and a classification of the current approaches to Web personalization. We discuss the various sources of data available to personalization systems, the modelling approaches employed and the current approaches to evaluating these systems. A number of challenges faced by researchers developing these systems are described as are solutions to these challenges proposed in literature. The chapter concludes with a discussion on the open challenges that must be addressed by the research community if this technology is to make a positive impact on user satisfaction with the Web.",http://dx.doi.org/10.1007/11577935_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:ELEC.0000045973.51289.8c,CROC: A New Evaluation Criterion for Recommender Systems,Electronic Commerce Research,10.1023/B:ELEC.0000045973.51289.8c,Springer,2005-01-01,Evaluation of a recommender system algorithm is a challenging task due to the many possible scenarios in which such systems may be deployed. We have designed a new performance plot called the CROC curve with an associated statistic: the area under the curve. Our CROC curve supplements the widely used ROC curve in recommender system evaluation by discovering performance characteristics that standard ROC evaluation often ignores. Empirical studies on two domains and including several recommender system algorithms demonstrate that combining ROC and CROC curves in evaluation can lead to a more informed characterization of performance than using either curve alone.,http://dx.doi.org/10.1023/B:ELEC.0000045973.51289.8c,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-25739-X_13,Infectious Diseaxe Informatics and Outbreak detection,Medical Informatics,10.1007/0-387-25739-X_13,Springer,2005-01-01,"Infectious disease informatics is an emerging field that studies data collection, sharing, modeling, and management issues in the domain of infectious diseases. This chapter provides an overview of this field with specific emphasis on the following two sets of topics: (a) the design and main system components of an infectious disease information infrastructure, and (b) spatio-temporal data analysis and modeling techniques used to identify possible disease outbreaks. Several case studies involving real-world applications and research prototypes are presented to illustrate the application context and relevant system design and data modeling issues.",http://dx.doi.org/10.1007/0-387-25739-X_13,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-25757-8_10,Areas of Application & Future Directions,Agent Intelligence Through Data Mining,10.1007/0-387-25757-8_10,Springer,2005-01-01,,http://dx.doi.org/10.1007/0-387-25757-8_10,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11536406_6,Language Games: Solving the Vocabulary Problem in Multi-Case-Base Reasoning,Case-Based Reasoning Research and Development,10.1007/11536406_6,Springer,2005-01-01,"The problem of heterogeneous case representation poses a major obstacle to realising real-life multi-case-base reasoning (MCBR) systems. The knowledge overhead in developing and maintaining translation protocols between distributed case bases poses a serious challenge to CBR developers. In this paper, we situate CBR as a flexible problem-solving strategy that relies on several heterogeneous knowledge containers. We introduce a technique called language games to solve the interoperability issue. Our technique has two phases. The first is an eager learning phase where case bases communicate to build a shared indexing lexicon of similar cases in the distributed network. The second is the problem-solving phase where, using the distributed index, a case base can quickly consult external case bases if the local solution is insufficient. We provide a detailed description of our approach and demonstrate its effectiveness using an evaluation on a real data set from the tourism domain.",http://dx.doi.org/10.1007/11536406_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-24230-9_12,"Cyber Forensics: Managing, Modeling, and Mining Data for Investigation",Managing Cyber Threats,10.1007/0-387-24230-9_12,Springer,2005-01-01,"This chapter describes a collaborative project between the San Diego Supercomputer Center (SDSC) and the Automated Regional Justice Information System (ARJIS) entitled P 3 ELE (Public-Private-Partnership Enabling Law Enforcement). The project is focused on developing a model research infrastructure for the management, analysis and visualization of public and private multidimensional data. This includes addressing the technical and analytical models, methods, tools and techniques to effectively integrate and correlate law enforcement information with public, cyber-based information. This framework will enable researchers to study the impact of this expanded dimensional information on the efficient remediation and proactive capabilities of law enforcement, and ultimately, will enhance the operational capabilities of justice professionals in our digital society.",http://dx.doi.org/10.1007/0-387-24230-9_12,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-25739-X_15,Semantic Text Parsing for Patient Records,Medical Informatics,10.1007/0-387-25739-X_15,Springer,2005-01-01,"Accessibility to a comprehensive variety of different types of structured patient data is critical to improvement in the health care process, yet most patient information is in the form of narrative text. Semantic methods are needed to interpret and map clinical information to a structured form so that the information will be accessible to other automated applications. This chapter focuses on semantic methods that map narrative patient information to a structured coded form.",http://dx.doi.org/10.1007/0-387-25739-X_15,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-84628-284-5_1,Knowledge Discovery and Data Mining,Advanced Methods for Knowledge Discovery from Complex Data,10.1007/1-84628-284-5_1,Springer,2005-01-01,"Knowledge discovery and data mining has recently emerged as an important research direction for extracting useful information from vast repositories of data of various types. This chapter discusses some of the basic concepts and issues involved in this process with special emphasis on different data mining tasks. The major challenges in data mining are mentioned. Finally, the recent trends in data mining are described and an extensive bibliography is provided.",http://dx.doi.org/10.1007/1-84628-284-5_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-4020-3037-1_6,Uncertain and Statistical Data Mining,Knowledge Discovery from Legal Databases,10.1007/1-4020-3037-1_6,Springer,2005-01-01,,http://dx.doi.org/10.1007/1-4020-3037-1_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/0-387-25846-9_6,Supporting Technologies for Knowledge Management,Knowledge Management and Management Learning,10.1007/0-387-25846-9_6,Springer,2005-01-01,,http://dx.doi.org/10.1007/0-387-25846-9_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11536406_25,Re-using Implicit Knowledge in Short-Term Information Profiles for Context-Sensitive Tasks,Case-Based Reasoning Research and Development,10.1007/11536406_25,Springer,2005-01-01,"Typically, case-based recommender systems recommend single items to the on-line customer. In this paper we introduce the idea of recommending a user-defined collection of items where the user has implicitly encoded the relationships between the items. Automated collaborative filtering (ACF), a socalled ‘contentless’ technique, has been widely used as a recommendation strategy for music items. However, its reliance on a global model of the user’s interests makes it unsuited to catering for the user’s local interests. We consider the context-sensitive task of building a compilation, a user-defined collection of music tracks. In our analysis, a collection is a case that captures a specific shortterm information/music need. In an offline evaluation, we demonstrate how a case-completion strategy that uses short-term representations is significantly more effective than the ACF technique. We then consider the problem of recommending a compilation according to the user’s most recent listening preferences. Using a novel on-line evaluation where two algorithms compete for the user’s attention, we demonstrate how a knowledge-light case-based reasoning strategy successfully addresses this problem.",http://dx.doi.org/10.1007/11536406_25,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-27430-8_5,Mass Customization of Software Products,Growing Modular,10.1007/3-540-27430-8_5,Springer,2005-01-01,,http://dx.doi.org/10.1007/3-540-27430-8_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4020-7829-3_9,Security Technologies to Guarantee Safe Business Processes in Smart Organizations,Intelligent Knowledge-Based Systems,10.1007/978-1-4020-7829-3_9,Springer,2005-01-01,"The developments in the fields of information technology, telecommunication and consumer electronics are extremely fast. The ability of different network platforms to carry essentially similar kinds of services and the coming together of consumer devices such as the telephone, television and personal computer is called “technology convergence” [ 1 ]. The ICT (Information and Communication Technology), the “infocom” technology covers the fields of telecommunication, informatics, broadcasting and e-media. A very fast developing field of telecommunication, the wireless (mobile and Wi-Fi) communication gets a growing role in many fields as well. The connection of mobile devices to the Internet established basically new possibilities, services for the users.",http://dx.doi.org/10.1007/978-1-4020-7829-3_9,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11546849_52,Data Warehousing and Knowledge Discovery: A Chronological View of Research Challenges,Data Warehousing and Knowledge Discovery,10.1007/11546849_52,Springer,2005-01-01,"Data Warehousing and Knowledge Discovery has been widely accepted as a key technology for enterprises to improve their abilities in data analysis, decision support, and the automatic extraction of knowledge from data. Historically, the phrase knowledge discovery in databases was coined at the first KDD (Knowledge Discovery and Data Mining) workshop in 1989 to emphasize that knowledge is the end-product of a data-driven discovery process. Since then, much research has been accomplished in this field. This paper which is written as an epilogue of the DaWaK 2005 proceedings by the programme committee chairpersons together with Nguyen Manh Tho, should reflect the past development of DaWaK-results and other significant research outcomes in the area and above all should deliver a rough sketch of the current development and possible future work.",http://dx.doi.org/10.1007/11546849_52,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11168-004-7430-4,LinGO Redwoods,Research on Language and Computation,10.1007/s11168-004-7430-4,Springer,2004-12-01,"Reflecting an increased need for stochastic parse selection models over hand-built linguistic grammars and a lack of appropriately detailed training material, we present the Linguistic Grammars On-Line (LinGo) Redwoods initiative, a seed activity in the design and development of a new type of treebank. LinGo Redwoods aims at the development of a novel treebanking methodology, (i) rich in nature and dynamic in both (ii) the ways linguistic data can be retrieved from the treebank in varying granularity and (iii) the constant evolution and regular updating of the treebank itself, synchronized to the development of ideas in syntactic theory. Starting in June 2001, the project has been working to build the foundations for this new type of treebank, develop a basic set of tools required for treebank construction and maintenance, and construct an initial set of 10,000 annotated trees to be distributed together with the tools under an open-source license.",http://dx.doi.org/10.1007/s11168-004-7430-4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:AGNT.0000038027.29035.7c,A Manifesto for Agent Technology: Towards Next Generation Computing,Autonomous Agents and Multi-Agent Systems,10.1023/B:AGNT.0000038027.29035.7c,Springer,2004-11-01,"The European Commission's eEurope initiative aims to bring every citizen, home, school, business and administration online to create a digitally literate Europe. The value lies not in the objective itself, but in its ability to facilitate the advance of Europe into new ways of living and working. Just as in the first literacy revolution, our lives will change in ways never imagined. The vision of eEurope is underpinned by a technological infrastructure that is now taken for granted. Yet it provides us with the ability to pioneer radical new ways of doing business, of undertaking science, and, of managing our everyday activities. Key to this step change is the development of appropriate mechanisms to automate and improve existing tasks, to anticipate desired actions on our behalf (as human users) and to undertake them, while at the same time enabling us to stay involved and retain as much control as required. For many, these mechanisms are now being realised by agent technologies, which are already providing dramatic and sustained benefits in several business and industry domains, including B2B exchanges, supply chain management, car manufacturing, and so on. While there are many real successes of agent technologies to report, there is still much to be done in research and development for the full benefits to be achieved. This is especially true in the context of environments of pervasive computing devices that are envisaged in coming years. This paper describes the current state-of-the-art of agent technologies and identifies trends and challenges that will need to be addressed over the next 10 years to progress the field and realise the benefits. It offers a roadmap that is the result of discussions among participants from over 150 organisations including universities, research institutions, large multinational corporations and smaller IT start-up companies. The roadmap identifies successes and challenges, and points to future possibilities and demands; agent technologies are fundamental to the realisation of next generation computing.",http://dx.doi.org/10.1023/B:AGNT.0000038027.29035.7c,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:MACH.0000035473.11134.83,Lessons and Challenges from Mining Retail E-Commerce Data,Machine Learning,10.1023/B:MACH.0000035473.11134.83,Springer,2004-10-01,"The architecture of Blue Martini Software's e-commerce suite has supported data collection, data transformation, and data mining since its inception. With clickstreams being collected at the application-server layer, high-level events being logged, and data automatically transformed into a data warehouse using meta-data, common problems plaguing data mining using weblogs (e.g., sessionization and conflating multi-sourced data) were obviated, thus allowing us to concentrate on actual data mining goals. The paper briefly reviews the architecture and discusses many lessons learned over the last four years and the challenges that still need to be addressed. The lessons and challenges are presented across two dimensions: business-level vs. technical, and throughout the data mining lifecycle stages of data collection, data warehouse construction, business intelligence, and deployment. The lessons and challenges are also widely applicable to data mining domains outside retail e-commerce.",http://dx.doi.org/10.1023/B:MACH.0000035473.11134.83,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/B:MACH.0000035516.74817.51,Introduction: Lessons Learned from Data Mining Applications and Collaborative Problem Solving,Machine Learning,10.1023/B:MACH.0000035516.74817.51,Springer,2004-10-01,"This introductory paper to the special issue on Data Mining Lessons Learned presents lessons from data mining applications, including experience from science, business, and knowledge management in a collaborative data mining setting.",http://dx.doi.org/10.1023/B:MACH.0000035516.74817.51,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-40003-5_11,Bibliography,Intelligent Techniques in E-Commerce,10.1007/978-3-540-40003-5_11,Springer,2004-01-01,,http://dx.doi.org/10.1007/978-3-540-40003-5_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-39988-9_11,Web Mining in Soft Computing Framework: A Survey,Fuzzy Logic and the Internet,10.1007/978-3-540-39988-9_11,Springer,2004-01-01,"The chapter deals with use of different soft computing tools to achieve web intelligence. It summarizes different characteristics of web data, the basic components of web mining and its different types, and their current states of the art. The reason for considering web mining, a separate field from data mining, is explained. The limitations of some of the existing web mining methods and tools are enunciated, and the significance of soft computing (comprising fuzzy logic, artificial neural networks, genetic algorithms and rough sets) highlighted. A survey of the existing literature on ‘soft web mining’ is provided along with the commercially available systems. The prospective areas of web mining where the application of soft computing needs immediate attention are outlined with justification. Scope for future research in developing ‘soft web mining’ systems is explained. An extensive bibliography is also provided.",http://dx.doi.org/10.1007/978-3-540-39988-9_11,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-39925-4_2,Data Mining using Learning Classifier Systems,Applications of Learning Classifier Systems,10.1007/978-3-540-39925-4_2,Springer,2004-01-01,"Walsh and Ungson ([105]) identify that information within organizations can be considered in terms of “Organizational Memories” ...the scattered fragments of data, interpreted by individuals as information, that exists in many forms (written, social, roles, images, ...) throughout an organization. Large volumes of data are now available to organizations, and increasing volumes are being collected — the world’s data is estimated to be doubling every 20 months ([106]). However, for data to have value to the organization (for the data to become part of the “Organizational Memory”) it must be transformed into information. Information is gained when data values can be interpreted to extract meaning or meaningful patterns through the application of conceptual knowledge. With current and anticipated volumes of data, it is increasingly unlikely that data will contribute to knowledge unless the analysis of data to identify relationships within that data can be automated to a significant extent.",http://dx.doi.org/10.1007/978-3-540-39925-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-09083-1_5,Applications,Ontologies,10.1007/978-3-662-09083-1_5,Springer,2004-01-01,"A technology can only be justified by successful applications. Therefore, there is a clear need to talk about the interesting application areas of ontology technology. However, the fast iteration of marketing waves makes it a quite hard to see the real and stable ground. The need for ontologies arises from (electronic) information sharing and reuse. Therefore, we will take the triangle of intranet, Internet, and extranet (see Fig. 33) as our organizing metaphor when talking about application areas. Not all of them are typical of just one network type, however, it helps to reduce the chaos of the overall picture. Let us first characterize the three different types of networks: Intranet : closed user community, company- or organization-wide use. Internet : open access; worldwide user community. Extranet : limited access from the outside (Internet) to an intranet.",http://dx.doi.org/10.1007/978-3-662-09083-1_5,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-662-07952-2_19,"Soft Computing Pattern Recognition, Data Mining and Web Intelligence",Intelligent Technologies for Information Analysis,10.1007/978-3-662-07952-2_19,Springer,2004-01-01,"The relevance of fuzzy logic, artificial neural networks, genetic algorithms, and rough sets to pattern recognition problems is described through examples. Different integrations of these soft computing tools are illustrated. The significance of the soft computing approach in data mining, knowledge discovery, and Web mining is discussed. Various existing algorithms and tools in this regard are reviewed. Finally, some research challenges and the scope of future research are outlined.",http://dx.doi.org/10.1007/978-3-662-07952-2_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-40003-5_4,Intelligent Agents and Multiagent Systems,Intelligent Techniques in E-Commerce,10.1007/978-3-540-40003-5_4,Springer,2004-01-01,"This chapter is the third chapter in the Part I of the book. It is also the basis for Chapter 7 and 8, as shown in the shaded area of Fig. 4.1. This chapter will briefly investigate basic features and architectures of intelligent agents, intelligent brokers, and multiagent systems (MASs). It also examines the relationship between intelligent agents and expert systems (ESs) as well as MASs, in which a knowledge-based model of integrating ESs in MAS is proposed. Then it proposes a multiagent-based architecture for information brokering as an example of the architecture of MAS, which can help customers to access information on the Internet.",http://dx.doi.org/10.1007/978-3-540-40003-5_4,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-30498-2_24,Collaborative Filtering Based on Modal Symbolic User Profiles: Knowing You in the First Meeting,Advances in Artificial Intelligence – IBERAMIA 2004,10.1007/978-3-540-30498-2_24,Springer,2004-01-01,"Recommender systems seek to furnish personalized suggestions automatically based on user preferences. These systems use information filtering techniques to recommend new items which has been classified according to one of the three approaches: Content Based Filtering, Collaborative Filtering or hybrid filtering methods . This paper presents a new hybrid filtering approach getting the better qualities of the kNN Collaborative Filtering method with the content filtering one based on Modal Symbolic Data . The main idea is comparing modal symbolic descriptions of users profiles in order to compute the neighborhood of some user in the Collaborative Filtering algorithm. This new approach outperforms, concerning the Find Good Items task measured by half-life utility metric, other three systems: content filtering based on Modal Symbolic Data , kNN Collaborative Filtering based on Pearson Correlation and hybrid Content-Boosted Collaborative approach.",http://dx.doi.org/10.1007/978-3-540-30498-2_24,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-39972-8_7,Building Intelligent Legal Decision Support Systems: Past Practice and Future Challenges,Applied Intelligent Systems,10.1007/978-3-540-39972-8_7,Springer,2004-01-01,"In [91] Susskind outlines the past use of Information Technology (IT), and indicates probable future uses of IT by the legal profession. He indicates that until recently, there was only limited use of IT by legal professionals. Whilst the use of word processing, office, automation, case management tools, client and case databases, electronic data/document interchange tools and fax machines is now standard, only recently have legal firms commenced using knowledge management techniques. The use of applied legal decision support systems is in its infancy.",http://dx.doi.org/10.1007/978-3-540-39972-8_7,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/1-4020-8090-5_19,Cognitive Hacking,Economics of Information Security,10.1007/1-4020-8090-5_19,Springer,2004-01-01,,http://dx.doi.org/10.1007/1-4020-8090-5_19,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-540-24750-0_22,Ontologies for Knowledge Management,Handbook on Ontologies,10.1007/978-3-540-24750-0_22,Springer,2004-01-01,"Since the term ontologies in AI was coined within the Knowledge Sharing and Reuse Effort [68] for engineering of knowledge–based systems ([40, 41]), it is not surprising that it heavily entered Knowledge Management ([21, 25], KM) research: Sharing and reuse— in this case of organizational knowledge—are among the core knowledge processes tackled within every KM endeavor. In this chapter we briefly introduce the main ideas of KM and the role and requirements for information technology (IT) in KM. We then discuss the potential of ontologies as main elements in IT solutions for KM. We characterize their current role in research and practice, derive a working focus for the near future, and conclude with an outlook on possible future trends in KM software and their implications on ontologies.",http://dx.doi.org/10.1007/978-3-540-24750-0_22,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-24605-3_20,Abstraction-Driven SAT-based Analysis of Security Protocols,Theory and Applications of Satisfiability Testing,10.1007/978-3-540-24605-3_20,Springer,2004-01-01,"In previous work we proposed an approach to the automatic translation of protocol insecurity problems into propositional logic with the ultimate goal of building an automatic model-checker for security protocols based on state-of-the-art SAT solvers. In this paper we present an improved procedure based on an abstraction/refinement strategy which, by interleaving the encoding and solving phases, leads to a significant improvement of the overall performance of our model-checker.",http://dx.doi.org/10.1007/978-3-540-24605-3_20,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-28631-8_52,Analysing Similarity Essence for Case Based Recommendation,Advances in Case-Based Reasoning,10.1007/978-3-540-28631-8_52,Springer,2004-01-01,"Initial successes in the area of recommender systems have led to considerable early optimism. However as a research community, we are still in the early days of our understanding of these applications and their capabilities. Evaluation metrics continue to be refined but we still need to account for the relative contributions of the various knowledge elements that play a part in the recommendation process. In this paper, we make a fine-grained analysis of a successful case-based recommendation approach, providing an ablation study of similarity knowledge and similarity metric contributions to improved system performance. In particular, we extend our earlier analyses to examine how measures of interestingness can be used to identify and analyse relative contributions of segments of similarity knowledge. We gauge the strengths and weaknesses of knowledge components and discuss future work as well as implications for research in the area.",http://dx.doi.org/10.1007/978-3-540-28631-8_52,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1026238916441,Web Usage Mining as a Tool for Personalization: A Survey,User Modeling and User-Adapted Interaction,10.1023/A:1026238916441,Springer,2003-11-01,"This paper is a survey of recent work in the field of web usage mining for the benefitof research on the personalization of Web-based information services. The essence of personalization is the adaptability of information systems to the needs of their users. This issue is becoming increasingly important on the Web, as non-expert users are overwhelmed by the quantity of information available online, while commercial Web sites strive to add value to their services in order to create loyal relationships with their visitors-customers. This article views Web personalization through the prism of personalization policies adopted by Web sites and implementing a variety of functions. In this context, the area of Web usage mining is a valuable source of ideas and methods for the implementation of personalization functionality. We therefore present a survey of the most recent work in the field of Web usage mining, focusing on the problemsthat have been identified and the solutions that have been proposed.",http://dx.doi.org/10.1023/A:1026238916441,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1024867820235,Towards a Structured Design of Electronic Negotiations,Group Decision and Negotiation,10.1023/A:1024867820235,Springer,2003-07-01,"Global communication networks and advances in information technology enable the design of information systems facilitating effective formulation and efficient resolution of negotiation problems. Increasingly, these systems guide negotiators in clarifying the relevant issues, provide media for offer formulation and exchange, and help in achieving an agreement. In practice, the task of analysing, modelling, designing and implementing electronic negotiation media demands a systematic, traceable and reproducible approach. An engineering approach to media specification and construction has these characteristics. In this paper, we provide a rationale for the engineering approach that allows pragmatic adoption of economic and social sciences perspectives on negotiated decisions for the purpose of supporting and undertaking electronic negotiations. Similarities and differences of different theories that underlie on-going studies of electronic negotiations are identified. This provides a basis for integration of different theories and approaches for the specific purpose of the design of effective electronic negotiations. Drawing on diverse streams of literature in different fields such as economics, management, computer, and behavioural sciences, we present an example of an integration of three significant streams of theoretical and applied research involving negotiations, traditional auctions and on-line auctions.",http://dx.doi.org/10.1023/A:1024867820235,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1021819901281,Studying Recommendation Algorithms by Graph Analysis,Journal of Intelligent Information Systems,10.1023/A:1021819901281,Springer,2003-03-01,"We present a novel framework for studying recommendation algorithms in terms of the 'jumps' that they make to connect people to artifacts. This approach emphasizes reachability via an algorithm within the implicit graph structure underlying a recommender dataset and allows us to consider questions relating algorithmic parameters to properties of the datasets. For instance, given a particular algorithm 'jump,' what is the average path length from a person to an artifact? Or, what choices of minimum ratings and jumps maintain a connected graph? We illustrate the approach with a common jump called the 'hammock' using movie recommender datasets.",http://dx.doi.org/10.1023/A:1021819901281,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1024072706526,Multi-Agent Multi-User Modeling in I-Help,User Modeling and User-Adapted Interaction,10.1023/A:1024072706526,Springer,2003-02-01,"This paper describesthe user modeling approach applied in I-Help, a distributed multi-agent based collaborative environment for peer help. There is a multitude of user modeling information in I-Help, developed by the various software agents populating the environment. These ‘user model fragments’ have been created in a variety of specific contexts to help achieve various goals. They are inherently inconsistent with one another and reflect not only characteristics of the users, but also certain social relationships among them. The paper explores some of the implications of multi-agent user modeling in distributed environments.",http://dx.doi.org/10.1023/A:1024072706526,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45006-8_6,Case-Based Ranking for Decision Support Systems,Case-Based Reasoning Research and Development,10.1007/3-540-45006-8_6,Springer,2003-01-01,"Very often a planning problem can be formulated as a ranking problem: i.e. to find an order relation over a set of alternatives. The ranking of a finite set of alternatives can be designed as a preference elicitation problem. While the casebased preference elicitation approach is more effective with respect to the first principle methods, still the scaling problem remains an open issue because the elicitation effort has a quadratic relation with the number of alternative cases. In this paper we propose a solution based on the machine learning techniques. We illustrate how a boosting algorithm can effectively estimate pairwise preferences and reduce the effort of the elicitation process. Experimental results, both on artificial data and a realworld problem in the domain of civil defence, showed that a good trade-off can be achieved between the accuracy of the estimated preferences, and the elicitation effort of the end user.",http://dx.doi.org/10.1007/3-540-45006-8_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-0445-0_3,Converging Trends Towards Human-Centerednes and Enabling Theories,Human-Centered e-Business,10.1007/978-1-4615-0445-0_3,Springer,2003-01-01,"In the past decade human-centeredness has become an important enabling concept in information system development. The fast growth of the Internet and WWW and partial failure of the dot corns has further accelerated development in this area. The need for human-centeredness has been felt in practically all areas of information systems and computer science. These include e-business, intelligent systems (traditional and web-based), software engineering, multimedia data modeling, data mining, enterprise modeling and human-computer interaction. In this chapter we discuss the pragmatic issues leading to human-centeredness in these areas and the enabling theories which are converging towards human-centered system development. These enabling theories include theories in philosophy, cognitive science, psychology and work-oriented design for human-centered e-business system development framework. We conclude the chapter with a discussion section that outlines the foundations of the human-centered system development framework described in the next chapter.",http://dx.doi.org/10.1007/978-1-4615-0445-0_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4757-3739-4_2,Advances in Information Extraction,Knowledge-Based Information Retrieval and Filtering from the Web,10.1007/978-1-4757-3739-4_2,Springer,2003-01-01,"Nowadays, knowledge relevant to business of any kind is mainly transmitted through free-text documents. Latest trends in information technology such as Information Extraction (IE) provide dramatic improvements in conversion of the overflow of raw textual information into valuable and structured data. This chapter gives a comprehensive introduction to information extraction technology including design, processing natural language, and evaluation issues of IE systems. Further, we present a retrospective overview of IE systems which have been successfully applied in real-world business applications which deal with processing vast amount of textual data, and we discuss current trends. Finally, we demonstrate an enormous indexing potential of lightweight linguistic text processing techniques in other areas of information technology closely related to IE.",http://dx.doi.org/10.1007/978-1-4757-3739-4_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-35617-4_36,Agent-based Bidding in Electronic Markets,Towards the Knowledge Society,10.1007/978-0-387-35617-4_36,Springer,2003-01-01,"The overall change in computing from manipulation to delegation was already predicted in the mid-90s but hitherto remains a bold vision. Although software agents have the potential of fully automating processes, real world agent-based applications are very limited in number. Even in the case of electronic markets software agents are rarely employed, albeit they can act as autonomous representatives of human negotiators. The prototypical approach presented in this paper seizes the idea of an agent-based electronic marketplace and describes multilateral negotiations as a core of an electronic trading system. Owing to their open format (i.e. open bidding), agent-based multilateral negotiations are expected to reduce transaction costs and to improve the negotiation outcome. The multilateral negotiations are presented in two different environments: in AMTRAS, an agent-based marketplace for bonds, as well as in VTR, a web-based trading system for stocks. Two key features of these negotiations are the revelation of all bids, and the anonymous nature of trading. The information released in the negotiation constitutes the basis for further research such that the agents are capable of deploying own strategies inferred from the other’s bidding behavior. The paper concludes with some recommendations as to how automation of the bidding process can be achieved using software agents’ intelligence.",http://dx.doi.org/10.1007/978-0-387-35617-4_36,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44864-0_38,Simulating Sellers’ Behavior in a Reverse Auction B2B Exchange,Computational Science — ICCS 2003,10.1007/3-540-44864-0_38,Springer,2003-01-01,"Previous research in reverse auction B2B exchanges found that in an environment where sellers collectively can cater to the total demand, with the final (i.e. the highest-priced bidding) seller catering to a residual, the sellers resort to a mixed strategy equilibrium [2]. While price randomization in industrial bids is an accepted norm, it may be argued that managers in reality do not resort to advanced game theoretic calculations to bid for an order. What is more likely is that managers learn that strategy and over time finally converge towards the theoretic equilibrium. To test this assertion, we model the two-player game in a synthetic environment, where the agents use a simple reinforcement learning algorithm to put progressively more weights on selecting price bands where they make higher profits. We find that after a sufficient number of iterations, the agents do indeed converge towards the theoretic equilibrium.",http://dx.doi.org/10.1007/3-540-44864-0_38,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-0-387-35617-4_3,Using Competitive Intelligence to Develop an Automated Visa Approval System,Towards the Knowledge Society,10.1007/978-0-387-35617-4_3,Springer,2003-01-01,"The use of competitive intelligence techniques identified the need for an automated visa approval system to streamline straightforward visa decisions that allows analysts more time for problematic applications. Such a system facilitates the capture and use of lessons learned and encourages knowledge sharing to support global terrorism risk management. However, automation of visa approvals raises issues related to human rights, data quantity and quality, choice of models and the correct interpretation of contextualized results.",http://dx.doi.org/10.1007/978-0-387-35617-4_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-0035-5_3,"Collaborative Filtering: Supporting Social Navigation in Large, Crowded Infospaces",Designing Information Spaces: The Social Navigation Approach,10.1007/978-1-4471-0035-5_3,Springer,2003-01-01,"The advent of the web has made possible the publication of vast amounts of new information. Information spaces have become more and more crowded with information. Web users are faced with the daunting task of sorting out from among all of the available information that which is most valuable to them. Social navigation systems have emerged as a broad array of techniques that enable people to work together to help each other find their way through the crowded spaces. In a social navigation system, each user who visits a web site does a small amount of work to untangle which of the paths from that web site are most valuable. Early users leave information signposts that help later users make sense of the wealth of alternatives available to them. Later users benefit from the signposts, because they are able to direct their attention to the parts of the site that are most valuable to them.",http://dx.doi.org/10.1007/978-1-4471-0035-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1016383418977,User Modeling for Personalized City Tours,Artificial Intelligence Review,10.1023/A:1016383418977,Springer,2002-09-01,"Several current support systems for travel and tourism are aimed at providing information in a personalized manner, taking users' interests and preferences into account. In this vein, personalized systems observe users' behavior and, based thereon, make generalizations and predictions about them. This article describes a user modeling server that offers services to personalized systems with regard to the analysis of user actions, the representation of assumptions about the user, and the inference of additional assumptions based on domain knowledge and characteristics of similar users. The system is open and compliant with major standards, allowing it to be easily accessed by clients that need personalization services.",http://dx.doi.org/10.1023/A:1016383418977,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1015386522883,Using Markets to Engineer Resource Management for the Information Grid,Information Systems Frontiers,10.1023/A:1015386522883,Springer,2002-04-01,"Information systems are continually expanding as evidenced by the doubling of Internet connections every year. Similar growth is exhibited by information systems in defense. The Air Force's goals to achieve global awareness, dynamic planning/execution, and global information exchange involve the technologies to provide information to the warrior anywhere, anytime, and for any mission. This far-reaching enterprise will necessarily span multiple networks and computing domains of both the commercial and military varieties. As a result, many users with different goals and priorities vie for the communication and computing resources of the information grid. Managing this vast system to assure dependable operation that maintains users' quality of service levels has led researchers to propose economic models to solve the resource management problem. Information technology has begun to fundamentally alter the way business is conducted, and there is synergy between e-commerce and the management of the underlying information resources on which it runs. This paper examines the envisioned market-based, large-scale information systems for defense. Due to their criticality, these systems must also manage resources to provide survivability in the presence of information attacks. This potential for technology transfer from the defense sector to the commercial sector are described. Conversely, the leveraging of research performed in the non-military realm of e-commerce to reach the Air Force's goals will also be explored.",http://dx.doi.org/10.1023/A:1015386522883,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/3-540-46131-0_2,Data Mining of Association Rules and the Process of Knowledge Discovery in Databases,Advances in Data Mining,10.1007/3-540-46131-0_2,Springer,2002-01-01,"In this paper we deal with association rule mining in the context of a complex, interactive and iterative knowledge discovery process. After a general introduction covering the basics of association rule mining and of the knowledge discovery process in databases we draw the attention to the problematic aspects concerning the integration of both. Actually, we come to the conclusion that with regard to human involvement and interactivity the current situation is far from being satisfying. In our paper we tackle this problem on three sides: First of all there is the algorithmic complexity. Although today’s algorithms efficiently prune the immense search space the achieved run times do not allow true interactivity. Nevertheless we present a rule caching schema that significantly reduces the number of mining runs. This schema helps to gain interactivity even in the presence of extreme run times of the mining algorithms. Second, today the mining data is typically stored in a relational database management system. We present an efficient integration with modern database systems which is one of the key factors in practical mining applications. Third, interesting rules must be picked from the set of generated rules. This might be quite costly because the generated rule sets normally are quite large whereas the percentage of useful rules is typically only a very small fraction. We enhance the traditional association rule mining framework in order to cope with this situation.",http://dx.doi.org/10.1007/3-540-46131-0_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45640-6_6,A Framework for Efficient and Anonymous Web Usage Mining Based on Client-Side Tracking,WEBKDD 2001 — Mining Web Log Data Across All Customers Touch Points,10.1007/3-540-45640-6_6,Springer,2002-01-01,"Web Usage Mining (WUM) , a natural application of data mining techniques to the data collected from user interactions with the web, has greatly concerned both academia and industry in recent years. Through WUM, we are able to gain a better understanding of both the web and web user access patterns; a knowledge that is crucial for realization of full economic potential of the web. In this chapter, we describe a framework for WUM that particularly satisfies the challenging requirements of the web personalization applications. For on-line and anonymous web personalization to be effective, WUM must be accomplished in real-time as accurately as possible. On the other hand, the analysis tier of the WUM system should allow compromise between scalability and accuracy to be applicable to real-life web-sites with numerous visitors. Within our WUM framework, we introduce a distributed user tracking approach for accurate, efficient, and scalable collection of the usage data. We also propose a new model, the Feature Matrices (FM) model, to capture and analyze users access patterns. With FM, various features of the usage data can be captured with flexible precision so that we can trade off accuracy for scalability based on the specific application requirements. Moreover, due to low update complexity of the model, FM can adapt to user behavior changes in real-time. Finally, we define a novel similarity measure based on FM that is specifically designed for accurate classification of partial navigation patterns in real-time. Our extensive experiments with both synthetic and real data verify correctness and efficacy of our WUM framework for efficient web personalization.",http://dx.doi.org/10.1007/3-540-45640-6_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-56262-4_6,E,Information Technology Encyclopedia and Acronyms,10.1007/978-3-642-56262-4_6,Springer,2002-01-01,"E — Exa. A prefix meaning one quintillion (10 18 ). In computing, which is based on the binary numbering system, Exa has a value which is a power of 2 (2 60 ).",http://dx.doi.org/10.1007/978-3-642-56262-4_6,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-0925-7_2,Ontology — Definition & Overview,Ontology Learning for the Semantic Web,10.1007/978-1-4615-0925-7_2,Springer,2002-01-01,"“Ontology” is a philosophical discipline, a branch of philosophy that deals with the nature and the organization of being. The term “Ontology” has been introduced by Aristotle in Metaphysics, IV, 1. In the context of research on “Ontology”, philosophers try to answer questions “what being is?” and “what are the features common to all beings?”.",http://dx.doi.org/10.1007/978-1-4615-0925-7_2,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4471-0217-5_8,Future Directions,User-Centred Requirements Engineering,10.1007/978-1-4471-0217-5_8,Springer,2002-01-01,"In this final chapter I will speculate on the future courses that requirements engineering may take. This is not a matter of imagining the impact that future technology may have on RE, however; rather, it is motivated by revisiting the fundamental problems of RE: communicating, understanding and transforming needs into designs. RE will face more pressing problems as systems become more complex, distributed and ubiquitous. It will become increasingly difficult for any one person to understand such complexity and then specify requirements for it. We therefore have a dilemma of what I call the horizon of knowability : as technology advances so does our ability to design more complex systems, yet our ability to understand such systems is finite. We are limited by our cognitive capacity and the time taken to understand complex systems; this capacity can only change slowly as we devise better methods. In contrast, the rate of technological change is exponential, as it feeds progressively on its own baseline. We tend to acknowledge this as the accelerating pace of change in society. So where does the answer lie? I will argue that we should look in two possible directions: first toward artificial intelligence and learning machines , and secondly towards automated design environments that communicate with us in natural language and graphics. Both have a common implication: in the future, requirements engineering will become progressively concerned with the design environment, while what we currently consider to be requirements analysis will either be learned automatically or achieved by conversation with an application generator machine.",http://dx.doi.org/10.1007/978-1-4471-0217-5_8,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s005210170012,"
              An Electronic Commerce Application of the Bayesian Framework for MLPs: The Effect of Marginalisation and ARD
            ",Neural Computing & Applications,10.1007/s005210170012,Springer,2001-04-01,"Automatic Relevance Determination (ARD), with multiple regularisation terms. A real-world classification problem, concerning the discrimination of online purchasers and non-purchasers using Internet’s WWW users’ opinions, is the test-bed for this assessment.",http://dx.doi.org/10.1007/s005210170012,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1011187500863,Generic User Modeling Systems,User Modeling and User-Adapted Interaction,10.1023/A:1011187500863,Springer,2001-03-01,"The paper reviews the development of generic user modeling systems over the past twenty years. It describes their purposes, their services within user-adaptive systems, and the different design requirements for research prototypes and commercially deployed servers. It discusses the architectures that have been explored so far, namely shell systems that form part of the application, central server systems that communicate with several applications, and possible future user modeling agents that physically follow the user. Several implemented research prototypes and commercial systems are briefly described.",http://dx.doi.org/10.1023/A:1011187500863,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-1627-9_1,Applications of Data Mining to Electronic Commerce,Applications of Data Mining to Electronic Commerce,10.1007/978-1-4615-1627-9_1,Springer,2001-01-01,"Electronic commerce is emerging as the killer domain for data—mining technology. Is there support for such a bold statement? Data—mining technologies have been around for decades, without moving significantly beyond the domain of computer scientists, statisticians, and hard-core business analysts. Why are electronic commerce systems any different from other data—mining applications?",http://dx.doi.org/10.1007/978-1-4615-1627-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45244-3_3,Refined Time Stamps for Concept Drift Detection During Mining for Classification Rules,"Temporal, Spatial, and Spatio-Temporal Data Mining",10.1007/3-540-45244-3_3,Springer,2001-01-01,"In many application areas where databases are mined for classification rules, the latter may be subject to concept drift , that is change over time. Mining without taking this into account can result in severe degradation of the acquired classifier’s performance. This is especially the case when mining is conducted incrementally to maintain knowledge used by an on-line system. The TSAR methodology detects and copes with drift in such situations through the use of a time stamp attribute, applied to incoming batches of data, as an integral part of the mining process. Here we extend the use of TSAR by employing more refined time stamps: first to individual batches, then to individual examples within a batch. We develop two new decision tree based TSAR algorithms, CD4 and CD5 and compare these to our original TSAR algorithm CD3.",http://dx.doi.org/10.1007/3-540-45244-3_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1009840925866,Applications of Data Mining to Electronic Commerce,Data Mining and Knowledge Discovery,10.1023/A:1009840925866,Springer,2001-01-01,,http://dx.doi.org/10.1023/A:1009840925866,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-44593-5_3,Why Case-Based Reasoning is Attractive for Image Interpretation,Case-Based Reasoning Research and Development,10.1007/3-540-44593-5_3,Springer,2001-01-01,"The development of image interpretation systems is concerned with tricky problems such as a limited number of observations, environmental influence, and noise. Recent systems lack robustness, accuracy, and flexibility. The introduction of case-based reasoning (CBR) strategies can help to overcome these drawbacks. The special type of information (i.e., images) and the problems mentioned above provide special requirements for CBR strategies. In this paper we review what has been achieved so far and research topics concerned with case-based image interpretation. We introduce a new approach for an image interpretation system and review its components.",http://dx.doi.org/10.1007/3-540-44593-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-45336-9_27,Evolutionary Negotiation in Agent-Mediated Commerce,Active Media Technology,10.1007/3-540-45336-9_27,Springer,2001-01-01,"Automated negotiation has become increasingly important since the advent of electronic commerce. In an efficient market, goods are not necessarily traded in a fixed price, and instead buyers and sellers negotiate among themselves to reach a deal that maximizes the payoffs of both parties. In this paper, a genetic agent-based model for bilateral, multi-issue negotiation is studied. The negotiation agent employs genetic algorithms and attempts to learn its opponent’s preferences according to the history of the counter offers based upon the stochastic approximation. We also consider two types of agents: level- 0 agents are only concerned with their own interest while level-1 agents consider also their opponents’ utility. Our goal is to develop an automated negotiator that guides the negotiation process so as to maximize both parties’ payoff.",http://dx.doi.org/10.1007/3-540-45336-9_27,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008372122567,Tailoring the Interaction with Users in Web Stores,User Modeling and User-Adapted Interaction,10.1023/A:1008372122567,Springer,2000-12-01,"We describe the user modeling and personalization techniques adopted in SETA, a prototype toolkit for the construction of adaptive Web stores which customize the interaction with users. The Web stores created using SETA suggest the items best fitting the customers' needs and adapt the layout and the description of the store catalog to their preferences and expertise. SETA uses stereotypical information to handle the user models and applies personalization rules to dynamically generate the hypertextual pages presenting products. The system adapts the graphical aspect, length and terminology used in the descriptions to parameters like the user's receptivity, expertise and interests. Moreover, it maintains a model associated with each person the goods are selected for; in this way, multiple criteria can be applied for tailoring the selection of items to the preferences of their beneficiaries.",http://dx.doi.org/10.1023/A:1008372122567,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1026597308943,A Review and Analysis of Commercial User Modeling Servers for Personalization on the World Wide Web,User Modeling and User-Adapted Interaction,10.1023/A:1026597308943,Springer,2000-06-01,"The aim of this article is to present and discuss selected commercial user modeling systems against the background of deployment requirements in real-world environments. Following the recent trend towards personalization on the World Wide Web, these systems are mainly aimed at supporting e-commerce including customer relationship management. In order to guide and structure our review, we define a requirements catalogue that comprises the main dimensions of functionality, data acquisition, representation, extensibility and flexibility, integration of external user-related information, compliance with standards, concern for privacy, and system architecture. Apart from the novelty of such a comparison both inside and outside the classical user modeling literature, a presentation of the core features of these commercial systems may provide a source of information and inspiration for the design, implementation, and deployment of future user modeling systems in research and commercial environments.",http://dx.doi.org/10.1023/A:1026597308943,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4615-4335-0_1,Knowledge Discovery,Soft Computing for Knowledge Discovery,10.1007/978-1-4615-4335-0_1,Springer,2000-01-01,"Since the introduction of the first operational modern computer (Heath Robinson) in 1940 by Alan Turing’s team, scientists and engineers have tried, with varying degrees of success, to increase its usefulness to mankind through the development of systems with high MIQ (Machine Intelligence Quotient) [Zadeh 1994b]. This desire to increase the computers’ usefulness to mankind has led to the birth of many computer-related disciplines. One such discipline is knowledge discovery (KD) whose main emphasis is on using algorithms that exploit computational power and resources to automatically discover general properties and principles (knowledge) from historical data (and background knowledge), that permit a computer to perform a task autonomously or that assist a human perform a task more successfully, efficiently or in a more value-added way.",http://dx.doi.org/10.1007/978-1-4615-4335-0_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4757-3196-5_3,Pragmatic Considerations and Enabling Theories,Intelligent Multimedia Multi-Agent Systems,10.1007/978-1-4757-3196-5_3,Springer,2000-01-01,"Human-centered system development is not a revolutionary concept in computer science and information systems but an evolutionary and enabling one. In this chapter we look at how some areas in computer science and information systems are evolving or moving towards human-centeredness. These areas include intelligent systems, electronic commerce, software engineering, multimedia databases, data mining, enterprise modeling and human-computer interaction. This evolution is based on the need for addressing pragmatic issues in these areas. We follow these pragmatic issues with enabling theories in philosophy, cognitive science, psychology and work-oriented design for human-centered system development framework. These theories are described and discussed in terms of their contributions toward human-centered system development framework. We conclude the chapter with a discussion section that outlines the foundations of the human-centered system development framework described in the chapter.",http://dx.doi.org/10.1007/978-1-4757-3196-5_3,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-58327-8_17,Intelligent Software Agents for Electronic Commerce,Handbook on Electronic Commerce,10.1007/978-3-642-58327-8_17,Springer,2000-01-01,This chapter is a survey of intelligent software agents in general and more specifically electronic commerce agents (ECAs). We begin with basic definitions and discuss the history and economic reasoning motivating the development of software agents. This is followed by a description of agent characteristics and a taxonomy showing where ECAs fit into the landscape of software agent research. How agents accomplish their goal seeking is described along with the learning and action mechanisms. Specific examples of electronic agents are given along with the economic and ethical impacts they are currently having on the market place and the potential impacts they may have in the future.,http://dx.doi.org/10.1007/978-3-642-58327-8_17,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-58418-3_1,Future Communication Networks using Software Agents,Software Agents for Future Communication Systems,10.1007/978-3-642-58418-3_1,Springer,1999-01-01,"Envisage automated communications networks of the future, which are managed by both stationary and mobile software entities, collecting network state information and which possess the innate ability to invoke effective changes to switch controllers, without the explicit interaction of a human operator. This is the model emerging from research and development in technologies, such as TINA-C (Telecommunications Information Networking Architecture — Consortium) [URL 1] and Active Networks [URL 31], (Tennenhouse et al, 1997). To make this vision reality, telecommunications platforms are embracing the relatively new paradigm of Software Agents. Some developers argue that without this adoption, the potential advantages that new broadband technologies offer, (rapid service deployment, logical configuration flexibility and management scalability) will not materialize (Weihmayer and Velthuijsen, 1995). In this chapter, we will describe some of the reasons why the adoption of software agent technology will benefit both the network operator and the end user, so that communications systems can be efficiently maintained, can benefit from increased business productivity, and provide improved Value Added Services (VAS). Before we delve into the latest developments in software agent technology it is important to provide an introduction to some of the problems the telecommunications domain is currently facing. The next few sections will describe some of the architectures and models that have been deployed within this network management area and how some of the changes disseminating from the computing arena, particularly Internet technologies, will hopefully lead to a “high speed, ubiquitous information highway” (Decina and Trecordi 1997).",http://dx.doi.org/10.1007/978-3-642-58418-3_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-48835-9_1,Building Electronic Marketplaces with the ZEUS Agent Tool-Kit,Agent Mediated Electronic Commerce,10.1007/3-540-48835-9_1,Springer,1999-01-01,"The increasing popularity of the Internet provides personal computer users with direct access to a wealth of information sources and services, and potentially a massive global marketplace. Unfortunately current home shopping systems are primitive; what the consumer wants is a personal shopping agent — an intelligent, reliable proxy who is aware of personal preferences, and who can take over the tedious task of searching the Internet for the best possible deal. Likewise retailers would like to use the Internet to attract a much larger volume of potential customers, who could be serviced quickly and efficiently at a much lower cost. This vision is seductive, so why has it not yet been realised? This paper considers why agent-based commerce is inherently difficult, and advocates collaborative agent technology as a means of more easily building distributed marketplaces. To illustrate this principle we have built a proto-type multi-agent virtual marketplace with ZEUS, a generic collaborative agent tool-kit.",http://dx.doi.org/10.1007/3-540-48835-9_1,springer,e-commerce,'e-commerce' AND 'machine learning' AND ('real-world' AND 'deploy')
